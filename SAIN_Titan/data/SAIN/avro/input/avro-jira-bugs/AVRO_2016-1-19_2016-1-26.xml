<!--
RSS generated by JIRA (7.6.3#76005-sha1:8a4e38d34af948780dbf52044e7aafb13a7cae58) at Mon Jan 21 19:22:56 UTC 2019

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<!-- If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
    <channel>
        <title>ASF JIRA</title>
        <link>https://issues.apache.org/jira/issues/?jql=project+%3D+AVRO+AND+created+%3E%3D+2016-1-19+AND+created+%3C%3D+2016-1-26+ORDER+BY+key+ASC</link>
        <description>An XML representation of a search request</description>
                <language>en-uk</language>
                        <issue start="0" end="3" total="3"/>
                <build-info>
            <version>7.6.3</version>
            <build-number>76005</build-number>
            <build-date>09-01-2018</build-date>
        </build-info>

<item>
            <title>[AVRO-1785] Ruby: schema_normalization.rb is incompatible with Ruby 1.8.7</title>
                <link>https://issues.apache.org/jira/browse/AVRO-1785</link>
                <project id="12310911" key="AVRO">Apache Avro</project>
                    <description>&lt;p&gt;I was just checking &lt;a href=&quot;https://issues.apache.org/jira/browse/AVRO-1775&quot; title=&quot;Running unit tests on Ruby 2.2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;AVRO-1775&quot;&gt;&lt;del&gt;AVRO-1775&lt;/del&gt;&lt;/a&gt; in 1.8.7 and ran into compile errors. The schema_normalization.rb code that was introduced by &lt;a href=&quot;https://issues.apache.org/jira/browse/AVRO-1694&quot; title=&quot;Support for schema fingerprints in the Ruby library&quot; class=&quot;issue-link&quot; data-issue-key=&quot;AVRO-1694&quot;&gt;&lt;del&gt;AVRO-1694&lt;/del&gt;&lt;/a&gt; is not compatible with Ruby 1.8.7 because it uses the &quot;new&quot; hash syntax in method definitions.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;blue@work:~/workspace/avro/lang/ruby$ bundle exec rake test
/home/blue/workspace/avro/lang/ruby/Rakefile:19: warning: already initialized constant VERSION
/home/blue/.rvm/rubies/ruby-1.8.7-p374/bin/ruby -I&lt;span class=&quot;code-quote&quot;&gt;&quot;lib:ext:bin:test&quot;&lt;/span&gt; -I&lt;span class=&quot;code-quote&quot;&gt;&quot;/home/blue/.rvm/gems/ruby-1.8.7-p374/gems/rake-10.4.2/lib&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/blue/.rvm/gems/ruby-1.8.7-p374/gems/rake-10.4.2/lib/rake/rake_test_loader.rb&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;test/test_help.rb&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;test/test_socket_transport.rb&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;test/test_fingerprints.rb&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;test/test_schema_normalization.rb&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;test/test_schema.rb&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;test/test_datafile.rb&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;test/test_io.rb&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;test/test_protocol.rb&quot;&lt;/span&gt; 
./lib/avro/schema_normalization.rb:67: warning: &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; without rescue is useless
./lib/avro.rb:42:in `require&lt;span class=&quot;code-quote&quot;&gt;&apos;: ./lib/avro/schema_normalization.rb:50: syntax error, unexpected &apos;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&apos;, expecting &apos;&lt;/span&gt;)&apos; (SyntaxError)
        normalize_named_type(schema, fields: fields)
                                            ^
./lib/avro/schema_normalization.rb:52: syntax error, unexpected &lt;span class=&quot;code-quote&quot;&gt;&apos;:&apos;&lt;/span&gt;, expecting &lt;span class=&quot;code-quote&quot;&gt;&apos;)&apos;&lt;/span&gt;
        normalize_named_type(schema, symbols: schema.symbols)
                                             ^
./lib/avro/schema_normalization.rb:52: syntax error, unexpected &lt;span class=&quot;code-quote&quot;&gt;&apos;)&apos;&lt;/span&gt;, expecting kEND
./lib/avro/schema_normalization.rb:54: syntax error, unexpected &lt;span class=&quot;code-quote&quot;&gt;&apos;:&apos;&lt;/span&gt;, expecting &lt;span class=&quot;code-quote&quot;&gt;&apos;)&apos;&lt;/span&gt;
        normalize_named_type(schema, size: schema.size)
                                          ^
./lib/avro/schema_normalization.rb:54: syntax error, unexpected &lt;span class=&quot;code-quote&quot;&gt;&apos;)&apos;&lt;/span&gt;, expecting kEND
./lib/avro/schema_normalization.rb:56: odd number list &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Hash
        { type: type, items: normalize_schema(schema.items) }
               ^
./lib/avro/schema_normalization.rb:56: syntax error, unexpected &lt;span class=&quot;code-quote&quot;&gt;&apos;:&apos;&lt;/span&gt;, expecting &lt;span class=&quot;code-quote&quot;&gt;&apos;}&apos;&lt;/span&gt;
        { type: type, items: normalize_schema(schema.items) }
               ^
./lib/avro/schema_normalization.rb:56: syntax error, unexpected &lt;span class=&quot;code-quote&quot;&gt;&apos;:&apos;&lt;/span&gt;, expecting &lt;span class=&quot;code-quote&quot;&gt;&apos;=&apos;&lt;/span&gt;
        { type: type, items: normalize_schema(schema.items) }
                            ^
./lib/avro/schema_normalization.rb:56: syntax error, unexpected &lt;span class=&quot;code-quote&quot;&gt;&apos;}&apos;&lt;/span&gt;, expecting kEND
./lib/avro/schema_normalization.rb:58: odd number list &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Hash
        { type: type, values: normalize_schema(schema.values) }
               ^
./lib/avro/schema_normalization.rb:58: syntax error, unexpected &lt;span class=&quot;code-quote&quot;&gt;&apos;:&apos;&lt;/span&gt;, expecting &lt;span class=&quot;code-quote&quot;&gt;&apos;}&apos;&lt;/span&gt;
        { type: type, values: normalize_schema(schema.values) }
               ^
./lib/avro/schema_normalization.rb:58: syntax error, unexpected &lt;span class=&quot;code-quote&quot;&gt;&apos;:&apos;&lt;/span&gt;, expecting &lt;span class=&quot;code-quote&quot;&gt;&apos;=&apos;&lt;/span&gt;
        { type: type, values: normalize_schema(schema.values) }
                             ^
./lib/avro/schema_normalization.rb:58: syntax error, unexpected &lt;span class=&quot;code-quote&quot;&gt;&apos;}&apos;&lt;/span&gt;, expecting kEND
./lib/avro/schema_normalization.rb:72: odd number list &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Hash
        name: field.name,
             ^
./lib/avro/schema_normalization.rb:72: syntax error, unexpected &lt;span class=&quot;code-quote&quot;&gt;&apos;:&apos;&lt;/span&gt;, expecting &lt;span class=&quot;code-quote&quot;&gt;&apos;}&apos;&lt;/span&gt;
        name: field.name,
             ^
./lib/avro/schema_normalization.rb:73: syntax error, unexpected &lt;span class=&quot;code-quote&quot;&gt;&apos;:&apos;&lt;/span&gt;, expecting &lt;span class=&quot;code-quote&quot;&gt;&apos;=&apos;&lt;/span&gt;
        type: normalize_schema(field.type)
             ^
./lib/avro/schema_normalization.rb:74: syntax error, unexpected &lt;span class=&quot;code-quote&quot;&gt;&apos;}&apos;&lt;/span&gt;, expecting kEND
./lib/avro/schema_normalization.rb:80: odd number list &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Hash
      { name: name, type: schema.type_sym.to_s }.merge(attributes)
             ^
./lib/avro/schema_normalization.rb:80: syntax error, unexpected &lt;span class=&quot;code-quote&quot;&gt;&apos;:&apos;&lt;/span&gt;, expecting &lt;span class=&quot;code-quote&quot;&gt;&apos;}&apos;&lt;/span&gt;
      { name: name, type: schema.type_sym.to_s }.merge(attributes)
             ^
./lib/avro/schema_normalization.rb:80: syntax error, unexpected &lt;span class=&quot;code-quote&quot;&gt;&apos;:&apos;&lt;/span&gt;, expecting &lt;span class=&quot;code-quote&quot;&gt;&apos;=&apos;&lt;/span&gt;
      { name: name, type: schema.type_sym.to_s }.merge(attributes)
                         ^
./lib/avro/schema_normalization.rb:80: syntax error, unexpected &lt;span class=&quot;code-quote&quot;&gt;&apos;}&apos;&lt;/span&gt;, expecting kEND
      { name: name, type: schema.type_sym.to_s }.merge(attributes)
                                                ^
        from ./lib/avro.rb:42
        from /home/blue/workspace/avro/lang/ruby/test/test_help.rb:22:in `require&apos;
        from /home/blue/workspace/avro/lang/ruby/test/test_help.rb:22
        from /home/blue/.rvm/gems/ruby-1.8.7-p374/gems/rake-10.4.2/lib/rake/rake_test_loader.rb:15:in `require&apos;
        from /home/blue/.rvm/gems/ruby-1.8.7-p374/gems/rake-10.4.2/lib/rake/rake_test_loader.rb:15
        from /home/blue/.rvm/gems/ruby-1.8.7-p374/gems/rake-10.4.2/lib/rake/rake_test_loader.rb:4:in `select&apos;
        from /home/blue/.rvm/gems/ruby-1.8.7-p374/gems/rake-10.4.2/lib/rake/rake_test_loader.rb:4
rake aborted!
Command failed with status (1): [ruby -I&lt;span class=&quot;code-quote&quot;&gt;&quot;lib:ext:bin:test&quot;&lt;/span&gt; -I&lt;span class=&quot;code-quote&quot;&gt;&quot;/home/blue/.rvm/gems/ruby-1.8.7-p374/gems/rake-10.4.2/lib&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/blue/.rvm/gems/ruby-1.8.7-p374/gems/rake-10.4.2/lib/rake/rake_test_loader.rb&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;test/test_help.rb&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;test/test_socket_transport.rb&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;test/test_fingerprints.rb&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;test/test_schema_normalization.rb&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;test/test_schema.rb&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;test/test_datafile.rb&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;test/test_io.rb&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;test/test_protocol.rb&quot;&lt;/span&gt; ]
/home/blue/.rvm/gems/ruby-1.8.7-p374/gems/echoe-4.6.6/lib/echoe.rb:749:in `define_tasks&apos;
/home/blue/.rvm/gems/ruby-1.8.7-p374/bin/ruby_executable_hooks:15
Tasks: TOP =&amp;gt; test_inner
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12932552">AVRO-1785</key>
            <summary>Ruby: schema_normalization.rb is incompatible with Ruby 1.8.7</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="rdblue">Ryan Blue</reporter>
                        <labels>
                    </labels>
                <created>Tue, 19 Jan 2016 22:29:47 +0000</created>
                <updated>Fri, 22 Jan 2016 17:52:24 +0000</updated>
                            <resolved>Fri, 22 Jan 2016 17:52:24 +0000</resolved>
                                    <version>1.8.0</version>
                                                    <component>ruby</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="15107628" author="rdblue" created="Tue, 19 Jan 2016 22:55:57 +0000"  >&lt;p&gt;It&apos;s easy enough to fix the syntax errors, but then Rake&apos;s test runner fails with different errors depending on the version of Rake I try. I used the oldest version of rake supported by echoe, but that fails with another compatibility problem.&lt;/p&gt;

&lt;p&gt;Next, I tried to avoid rake by running tests with &lt;tt&gt;ruby -Itest -Ilib test/test_schema_normalization.rb&lt;/tt&gt;. Tests then fail with 2 general problems: the order of map keys doesn&apos;t match the test so schema strings aren&apos;t equal (IIRC, later versions of ruby always return insertion order) and primitive types aren&apos;t handled correctly because the case statement uses a splat for primitive types.&lt;/p&gt;

&lt;p&gt;My take-away is that &lt;a href=&quot;https://www.ruby-lang.org/en/news/2013/06/30/we-retire-1-8-7/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;we should let 1.8.7 go&lt;/a&gt;. Thoughts?&lt;/p&gt;</comment>
                            <comment id="15108255" author="martinkl" created="Wed, 20 Jan 2016 09:11:59 +0000"  >&lt;p&gt;+1 on dropping support for Ruby 1.8.7. If there is someone still using 1.8.7, not being able to use the latest version of Avro will be the least of their worries. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15110777" author="busbey" created="Thu, 21 Jan 2016 15:32:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/AVRO-1783&quot; title=&quot;Gracefully handle strings with wrong character encoding&quot; class=&quot;issue-link&quot; data-issue-key=&quot;AVRO-1783&quot;&gt;&lt;del&gt;AVRO-1783&lt;/del&gt;&lt;/a&gt; now also makes use of a Ruby 1.9+ method.&lt;/p&gt;</comment>
                            <comment id="15112778" author="rdblue" created="Fri, 22 Jan 2016 17:52:24 +0000"  >&lt;p&gt;I&apos;m resolving this as &quot;Won&apos;t Fix&quot; since I think the consensus is to drop support for 1.8.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12843182">AVRO-1694</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 20 Jan 2016 09:11:59 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2rpjr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[AVRO-1786] Strange IndexOutofBoundException in GenericDatumReader.readString</title>
                <link>https://issues.apache.org/jira/browse/AVRO-1786</link>
                <project id="12310911" key="AVRO">Apache Avro</project>
                    <description>&lt;p&gt;Our production cluster is CENTOS 6.5 (2.6.32-358.14.1.el6.x86_64), running IBM BigInsight V3.0.0.2. In Apache term, it is Hadoop 2.2.0 with MRV1(no yarn), and comes with AVRO 1.7.4, running with IBM J9 VM (build 2.7, JRE 1.7.0 Linux amd64-64 Compressed References 20140515_199835 (JIT enabled, AOT enabled). Not sure if the JDK matters, but it is NOT Oracle JVM.&lt;/p&gt;

&lt;p&gt;We have a ETL implemented in a chain of MR jobs. In one MR job, it is going to merge 2 sets of AVRO data. Dataset1 is in HDFS location A, and Dataset2 is in HDFS location B, and both contains the AVRO records binding to the same AVRO schema. The record contains an unique id field, and a timestamp field. The MR job is to merge the records based on the ID, and use the later timestamp record to replace previous timestamp record, and omit the final AVRO record out. Very straightforward.&lt;/p&gt;

&lt;p&gt;Now we faced a problem that one reducer keeps failing with the following stacktrace on JobTracker:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;java.lang.IndexOutOfBoundsException
	at java.io.ByteArrayInputStream.read(ByteArrayInputStream.java:191)
	at java.io.DataInputStream.read(DataInputStream.java:160)
	at org.apache.avro.io.DirectBinaryDecoder.doReadBytes(DirectBinaryDecoder.java:184)
	at org.apache.avro.io.BinaryDecoder.readString(BinaryDecoder.java:263)
	at org.apache.avro.io.ValidatingDecoder.readString(ValidatingDecoder.java:107)
	at org.apache.avro.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.GenericDatumReader.readString(GenericDatumReader.java:348)
	at org.apache.avro.reflect.ReflectDatumReader.readString(ReflectDatumReader.java:143)
	at org.apache.avro.reflect.ReflectDatumReader.readString(ReflectDatumReader.java:125)
	at org.apache.avro.reflect.ReflectDatumReader.readString(ReflectDatumReader.java:121)
	at org.apache.avro.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.GenericDatumReader.read(GenericDatumReader.java:154)
	at org.apache.avro.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.GenericDatumReader.readRecord(GenericDatumReader.java:177)
	at org.apache.avro.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.GenericDatumReader.read(GenericDatumReader.java:148)
	at org.apache.avro.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.GenericDatumReader.read(GenericDatumReader.java:139)
	at org.apache.avro.hadoop.io.AvroDeserializer.deserialize(AvroDeserializer.java:108)
	at org.apache.avro.hadoop.io.AvroDeserializer.deserialize(AvroDeserializer.java:48)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:142)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:117)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:297)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:165)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:652)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:420)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:255)
	at java.security.AccessController.doPrivileged(AccessController.java:366)
	at javax.security.auth.Subject.doAs(Subject.java:572)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1502)
	at org.apache.hadoop.mapred.Child.main(Child.java:249)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here is the my Mapper and Reducer methods:&lt;br/&gt;
Mapper:&lt;br/&gt;
public void map(AvroKey&amp;lt;SpecificRecord&amp;gt; key, NullWritable value, Context context) throws IOException, InterruptedException &lt;br/&gt;
Reducer:&lt;br/&gt;
protected void reduce(CustomPartitionKeyClass key, Iterable&amp;lt;AvroValue&amp;lt;SpecificRecord&amp;gt;&amp;gt; values, Context context) throws IOException, InterruptedException &lt;/p&gt;

&lt;p&gt;What bother me are the following facts:&lt;br/&gt;
1) All the mappers finish without error&lt;br/&gt;
2) Most of the reducers finish without error, but one reducer keeps failing with the above error.&lt;br/&gt;
3) It looks like caused by the data? But keep in mind that all the avro records passed the mapper side, but failed in one reducer. &lt;br/&gt;
4) From the stacktrace, it looks like our reducer code was NOT invoked yet, but failed before that. So my guess is that all the AVRO records pass through the mapper side, but AVRO complains the intermediate result generated by the one mapper? In my understanding, that will be a Sequence file generated by Hadoop, and value part will be the AVRO bytes. Is the above error meaning that AVRO cannot deserialize the value part from the sequence file?&lt;br/&gt;
5) Our ETL run fine for more than one year, but suddenly got this error starting from one day, and kept getting this problem after that. &lt;br/&gt;
6) If it helps, here is the schema for the avro record:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;{
    &lt;span class=&quot;code-quote&quot;&gt;&quot;namespace&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;company name&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;record&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;Lists&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;fields&quot;&lt;/span&gt; : [
        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;account_id&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;&quot;&lt;/span&gt;},
        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;list_id&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;string&quot;&lt;/span&gt;},
        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;sequence_id&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : [&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;]} ,
        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : [&lt;span class=&quot;code-quote&quot;&gt;&quot;string&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;]},
        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;state&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : [&lt;span class=&quot;code-quote&quot;&gt;&quot;string&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;]},
        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;description&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : [&lt;span class=&quot;code-quote&quot;&gt;&quot;string&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;]},
        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;dynamic_filtered_list&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : [&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;]},
        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;filter_criteria&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : [&lt;span class=&quot;code-quote&quot;&gt;&quot;string&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;]},
        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;created_at&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : [&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;]},
        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;updated_at&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : [&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;]},
        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;deleted_at&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : [&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;]},
        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;favorite&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : [&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;]},
        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;delta&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : [&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;]},
        {
            &lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;list_memberships&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : {
                &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;array&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;items&quot;&lt;/span&gt; : {
                    &lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;ListMembership&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;record&quot;&lt;/span&gt;,
                    &lt;span class=&quot;code-quote&quot;&gt;&quot;fields&quot;&lt;/span&gt; : [
                        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;channel_id&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;string&quot;&lt;/span&gt;},
                        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;created_at&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : [&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;]},
                        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;created_source&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : [&lt;span class=&quot;code-quote&quot;&gt;&quot;string&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;]},
                        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;deleted_at&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : [&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;]},
                        {&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;sequence_id&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;type&quot;&lt;/span&gt; : [&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;]}
                    ]
                }
            }
        }
    ]
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment>&lt;p&gt;CentOS 6.5 Linux x64, 2.6.32-358.14.1.el6.x86_64&lt;br/&gt;
Use IBM JVM:&lt;br/&gt;
IBM J9 VM (build 2.7, JRE 1.7.0 Linux amd64-64 Compressed References 20140515_199835 (JIT enabled, AOT enabled)&lt;/p&gt;</environment>
        <key id="12932875">AVRO-1786</key>
            <summary>Strange IndexOutofBoundException in GenericDatumReader.readString</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="java8964">Yong Zhang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 20 Jan 2016 21:51:45 +0000</created>
                <updated>Fri, 11 Aug 2017 16:53:25 +0000</updated>
                                            <version>1.7.4</version>
                    <version>1.7.7</version>
                                                    <component>java</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="15112664" author="java8964" created="Fri, 22 Jan 2016 16:52:57 +0000"  >&lt;p&gt;With lots of time debugging this, I found out some interested facts, and want to know if any one can provide more information related to this.&lt;/p&gt;

&lt;p&gt;In our AVRO schema, if the &quot;list_id&quot;, which is a UUID, contain the following characters &quot;3a3ffb10be8b11e3977ad4ae5284344f&quot;, that record will cause this exception.&lt;/p&gt;

&lt;p&gt;In this case, if you check the following Avro class: BinaryDecoder.java, from here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/avro/blob/release-1.7.4/lang/java/avro/src/main/java/org/apache/avro/io/BinaryDecoder.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/avro/blob/release-1.7.4/lang/java/avro/src/main/java/org/apache/avro/io/BinaryDecoder.java&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The above link is pointing to release 1.7.4, and &lt;br/&gt;
starting from line 259:&lt;/p&gt;

&lt;p&gt;int length = readInt();&lt;br/&gt;
Utf8 result = (old != null ? old : new Utf8());&lt;br/&gt;
    result.setByteLength(length);&lt;br/&gt;
    if (0 != length) &lt;/p&gt;
{
      doReadBytes(result.getBytes(), 0, length);
    }
&lt;p&gt;In this case when the exception happens, the length in fact is &quot;-51&quot;, which is calculated from method &quot;readInt()&quot;, causing IndexOutOfBoundsException.&lt;/p&gt;

&lt;p&gt;Based on &lt;a href=&quot;https://issues.apache.org/jira/browse/AVRO-1198&quot; title=&quot;Malformed Avro data may cause confusing ArrayIndexOutOfBoundsException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;AVRO-1198&quot;&gt;&lt;del&gt;AVRO-1198&lt;/del&gt;&lt;/a&gt;, when a negative value return in this case, it means the the data is Malformed, and this JIRA even patched a message to show it in the Exception.&lt;/p&gt;

&lt;p&gt;But in my case:&lt;/p&gt;

&lt;p&gt;The avro data is NOT malformed. Why? I can query the whole ready to merge data set in the Hive without any issue, even for the complained records.&lt;br/&gt;
In my case, the real runtime object is &quot;DirectBinaryDecoder&quot;, as you can see the stacktrace, doReadBytes method indeed point to this class.&lt;br/&gt;
So the ReadInt() method returns &quot;-51&quot; in this case, must be from DirectBinaryDecoder class, which I list here:&lt;br/&gt;
           &lt;a href=&quot;https://github.com/apache/avro/blob/release-1.7.4/lang/java/avro/src/main/java/org/apache/avro/io/DirectBinaryDecoder.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/avro/blob/release-1.7.4/lang/java/avro/src/main/java/org/apache/avro/io/DirectBinaryDecoder.java&lt;/a&gt;&lt;br/&gt;
           starting from line 97, but I really don&apos;t know why in my case, it return &quot;-51&quot;.&lt;br/&gt;
I tested with AVRO 1.7.7 (The latest release of 1.7.x), the same problem still happens.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="15112809" author="java8964" created="Fri, 22 Jan 2016 18:14:10 +0000"  >&lt;p&gt;I modify the DirectBinaryDecorder class to add the following line from 116, at runtime to dump more information about it:&lt;/p&gt;

&lt;p&gt;if (((n &amp;gt;&amp;gt;&amp;gt; 1 ^ -(n &amp;amp; 1)) &amp;lt; 0) {&lt;br/&gt;
    System.out.println(&quot;Got ((n &amp;gt;&amp;gt;&amp;gt; 1 ^ -(n &amp;amp; 1)) = &quot; + ((n &amp;gt;&amp;gt;&amp;gt; 1 ^ -(n &amp;amp; 1)));&lt;br/&gt;
    System.out.println(&quot;And b = &quot; + b);&lt;br/&gt;
    System.out.println(&quot;And shift = &quot; + shift);&lt;br/&gt;
    System.out.println(&quot;And n = &quot; + n);&lt;br/&gt;
}&lt;/p&gt;

&lt;p&gt;Here is the output:&lt;br/&gt;
Got ((n &amp;gt;&amp;gt;&amp;gt; 1) ^ -(n &amp;amp; 1)) = -51&lt;br/&gt;
And b = 101&lt;br/&gt;
And shift = 0&lt;br/&gt;
And n = 101&lt;/p&gt;

&lt;p&gt;Not sure what do these values mean, but does it help to prove this is a bug?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="15115766" author="java8964" created="Mon, 25 Jan 2016 18:57:27 +0000"  >&lt;p&gt;It looks like AVRO assume the length byte for utf8 is an even number, but in this case, the byte coming from the data is an odd number (101), but the avro data in this case is read in Hive without any issue. Under what case this will happen?&lt;/p&gt;</comment>
                            <comment id="15116032" author="rdblue" created="Mon, 25 Jan 2016 20:58:55 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=java8964&quot; class=&quot;user-hover&quot; rel=&quot;java8964&quot;&gt;Yong Zhang&lt;/a&gt;. From that stack trace, it looks like the problem is when the reducer is reading data written out by the mapper. That&apos;s why you can read the source data just fine, the problem is in the job&apos;s intermediate data. As far as why this happens on just one reducer, can you post the job counters? This could be explained by there only being one output key or just one reduce task.&lt;/p&gt;

&lt;p&gt;This sort of error usually happens when an Avro file is corrupt, or when another binary format is read as Avro. Since this fails before calling your reducer, it looks like none of the data values are readable so I think it may be a configuration problem between your mapper and reducer. Could you post the code for where you set up this job?&lt;/p&gt;</comment>
                            <comment id="15116151" author="java8964" created="Mon, 25 Jan 2016 21:52:54 +0000"  >&lt;p&gt;Hi, Ryan:&lt;/p&gt;

&lt;p&gt;I listed the Mapper and Reducer method signature in the ticket, and just listed here briefly for more explaining:&lt;/p&gt;

&lt;p&gt;Mapper side&lt;br/&gt;
public void map(AvroKey&amp;lt;SpecificRecord&amp;gt; key, NullWritable value, Context context) throws IOException, InterruptedException {&lt;br/&gt;
   SpecificRecord specificRecord = key.datum();&lt;br/&gt;
   context.write(outputKey, new AvroValue(lists));&lt;br/&gt;
}&lt;br/&gt;
// So we know that the mapper doesn&apos;t complain anything about the Avor record&lt;/p&gt;

&lt;p&gt;    @Override&lt;br/&gt;
    protected void reduce(PartitionKey key, Iterable&amp;lt;AvroValue&amp;lt;SpecificRecord&amp;gt;&amp;gt; values, Context context) throws IOException, InterruptedException {&lt;br/&gt;
    }&lt;br/&gt;
// The PartitionKey object is a customer class to partition the value based on the ID, and also do the 2nd sort, to sort the data based on the timestamp.&lt;br/&gt;
// I know the key part is fine, as the KeyDeserializer in the ReduceContextImpl works fine.&lt;/p&gt;

&lt;p&gt;The problem happened in the ValueDeserializer.deserialize(value), which indeed throws exception from AVRO codebase. I even hack the hadoop code to dump the key when the exception happens.&lt;br/&gt;
Yes, I understand the exception is for the intermediate data, but I don&apos;t know why in this case AVRO treat this intermediate data as invalid AVRO data. In this case, most of the data are fine, as most reducers finished successfully, but from the dump, I can see at least 3 records throw exception in this case, then I stopped dumping more exception records.&lt;br/&gt;
Our schema may change before (I will check that), but the new schema should be always compatible with the old data. For example, if the trouble data is in fact generated by old schema, it is still read fine in the Hive (which is defined as the latest schema) for these 3 records.&lt;/p&gt;

&lt;p&gt;What I am going to do next is:&lt;/p&gt;

&lt;p&gt;1) I will dump one good AVRO record + one bad AVRO record (I had the 3 ids) out, and just store them in a different AVRO file, then to see if I can still reproduce this problem, and then compare what is the difference between these 2 records.&lt;br/&gt;
2) I will try to check the MR counter during this test.&lt;/p&gt;</comment>
                            <comment id="15116166" author="rdblue" created="Mon, 25 Jan 2016 22:06:27 +0000"  >&lt;p&gt;The mapper and reducer code is less helpful than your job setup code. There are a few things that could be happening here and that job setup code is the most likely place for the problem to be. Is this a project in github you could point us to?&lt;/p&gt;</comment>
                            <comment id="15116180" author="java8964" created="Mon, 25 Jan 2016 22:16:59 +0000"  >&lt;p&gt;Sorry, the code base is in my company&apos;s github, which is NOT accessible from outside.&lt;/p&gt;

&lt;p&gt;I understand your concern, here is the brief code of the Driver class to start this MR job:&lt;/p&gt;

&lt;p&gt;            Job mergeJob = new Job(getConf());&lt;br/&gt;
            mergeJob.setJarByClass(MergeDriver.class);&lt;br/&gt;
            Path internalOutputPath = new Path(new Path(new Path(baseDir, ETLConstants.WORKING_DIR), epoch), ETLConstants.MERGE_DIR);&lt;br/&gt;
            FileOutputFormat.setOutputPath(mergeJob, internalOutputPath);&lt;br/&gt;
                mergeJob.setJobName(&quot;Delta Lists merge Job&quot;);&lt;br/&gt;
                AvroJob.setInputKeySchema(mergeJob, Lists.SCHEMA$);&lt;br/&gt;
                AvroJob.setOutputKeySchema(mergeJob, Lists.SCHEMA$);&lt;br/&gt;
                AvroJob.setMapOutputValueSchema(mergeJob, Lists.SCHEMA$);&lt;br/&gt;
                AvroKeyInputFormat.addInputPath(mergeJob, new Path(new Path(baseDir, ETLConstants.DATA_DIR), ETLConstants.MULTI_OUTPUT_NAME_LISTS));&lt;br/&gt;
          mergeJob.setOutputFormatClass(AvroKeyOutputFormat.class);&lt;br/&gt;
            // Add the input data&lt;br/&gt;
            AvroKeyInputFormat.addInputPath(mergeJob, new Path(new Path(new Path(baseDir, ETLConstants.WORKING_DIR), epoch), ETLConstants.DETAL_DIR));&lt;br/&gt;
            mergeJob.setInputFormatClass(AvroKeyInputFormat.class);&lt;br/&gt;
            mergeJob.getConfiguration().set(ETLConstants.BASE_DIR, baseDir.toString());&lt;br/&gt;
            mergeJob.getConfiguration().set(ETLConstants.ETL_RUNTIME_EPOCH, epoch);&lt;br/&gt;
            mergeJob.setMapperClass(Contact2ETLMergeMapper.class);&lt;br/&gt;
            mergeJob.setReducerClass(Contact2ETLMergeReducer.class);&lt;br/&gt;
            mergeJob.setMapOutputKeyClass(Contact2MergePartitionKey.class);&lt;br/&gt;
            mergeJob.setMapOutputValueClass(AvroValue.class);&lt;br/&gt;
            mergeJob.setPartitionerClass(Contact2MergePartitioner.class);&lt;br/&gt;
            mergeJob.setSortComparatorClass(Contact2MergePartitionKey.Contact2MergePartitionKeyComparator.class);&lt;br/&gt;
            mergeJob.setGroupingComparatorClass(Contact2MergePartitionKey.Contact2MergePartitionGroupComparator.class);&lt;/p&gt;

&lt;p&gt;            logger.info(&quot;Start running merge job...&quot;);&lt;br/&gt;
            if (mergeJob.waitForCompletion(true)) {&lt;br/&gt;
            }&lt;/p&gt;
</comment>
                            <comment id="15116195" author="java8964" created="Mon, 25 Jan 2016 22:25:38 +0000"  >&lt;p&gt;One more thing. When I mean the other reducers finished successfully, I didn&apos;t mean these reducers didn&apos;t process any data. &lt;/p&gt;

&lt;p&gt;This source of this ETL job is to process hundred of M of records, and I can see all the output of other reducers in HDFS. To summary, for millions of AVRO records, most of them can pass this MR job without any issue, but some of records (so far I can find at least 3, and they just happened to send to the same reducer, and the first one will fail the reducer).&lt;/p&gt;</comment>
                            <comment id="15116203" author="java8964" created="Mon, 25 Jan 2016 22:30:46 +0000"  >&lt;p&gt;So right now, I can find this one AVRO file, (which is about 900M, compressed with Snappy, still too big), which contains at least one of the AVRO record will cause this this issue.&lt;/p&gt;

&lt;p&gt;I will try to dump this bad record, plus any good one record, and generate a new AVRO file, and if I can reproduce this problem with this small file, so I will attached in this ticket, so any of your AVRO expect can verify if this problem happened in your environment, or not.&lt;/p&gt;</comment>
                            <comment id="15116522" author="java8964" created="Tue, 26 Jan 2016 02:27:23 +0000"  >&lt;p&gt;Here is what I did, and here is the output result. I really don&apos;t know if this is an AVRO issue, or hadoop MR issue.&lt;/p&gt;

&lt;p&gt;I have this 900M avor file, and I know when this exception happened for my MR job, the reducer is trying to deserialize a value with key = &apos;3a410d00656911e3ac0bd4ae52986b44&apos;, which is the list id in my schema.&lt;/p&gt;

&lt;p&gt;Now if I change my mapper, only omit the three key value pairs: one of them is the above key, and 2 more randomly pick up keys. To my surprise, I didn&apos;t get this exception in the reducer of MR job.&lt;/p&gt;

&lt;p&gt;If I remove the this filter, I will get this exception in MR job.&lt;/p&gt;

&lt;p&gt;So with more key/value pairs in the intermediate result, I will get this exception consistently for this key. But if I explicit pick up this avro record, and 2 other records, I cannot reproduce this problem.&lt;/p&gt;

&lt;p&gt;I can confirm the list id is unique in this AVRO file, and I also changed the ReducerContextImpl of Hadoop 2.2.0 codebase, to dump the key when the value deserialize failed like following:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/hadoop/blob/release-2.2.0/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/ReduceContextImpl.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hadoop/blob/release-2.2.0/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/ReduceContextImpl.java&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;line 145 ==&amp;gt; value = valueDeserializer.deserialize(value);&lt;/p&gt;

&lt;p&gt;So right now, I am stuck to simplify the data, any idea how should I debug this issue? Thanks&lt;br/&gt;
to ==&amp;gt; try &lt;/p&gt;
{   value = valueDeserializer.deserialize(value); }
&lt;p&gt; catch (RuntimeException re) &lt;/p&gt;
{ System.out.println(&quot;key = &quot; + key); throw re }</comment>
                            <comment id="15117352" author="java8964" created="Tue, 26 Jan 2016 15:08:39 +0000"  >&lt;p&gt;I copied the this 900M AVRO file to our DEV cluster, which has identical OS and software as our production cluster, but less nodes. &lt;/p&gt;

&lt;p&gt;I can reproduce this problem on another cluster, so this is a software issue, not related to environment.&lt;/p&gt;

&lt;p&gt;If in my mapper, I filter out other AVRO records, and only omit the 3 AVRO records as my previous test, I cannot trigger this exception. &lt;/p&gt;

&lt;p&gt;In this case, I can some different values of local variable of &quot;b&quot; in readInt() method of DirectBinaryDecorder, but none of them is &quot;101&quot;, and of course, no negative value ever generated by this method.&lt;/p&gt;

&lt;p&gt;If I don&apos;t filter out any AVRO records, I will get this exception, and hit the &quot;b&quot; = 101 case. But there are too many records to track.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="15119898" author="rdblue" created="Wed, 27 Jan 2016 18:04:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=java8964&quot; class=&quot;user-hover&quot; rel=&quot;java8964&quot;&gt;Yong Zhang&lt;/a&gt;, when you get a chance, can you post the counters from your test jobs? Results from the successful run (with the filter) would be helpful as well.&lt;/p&gt;

&lt;p&gt;Any information you have on the values that cause this problem would be great. This looks suspiciously like a schema evolution change that was inconsistently applied. Did you change your schema lately?&lt;/p&gt;</comment>
                            <comment id="15122312" author="java8964" created="Thu, 28 Jan 2016 21:09:15 +0000"  >&lt;p&gt;Hi, Ryan:&lt;/p&gt;

&lt;p&gt;First, I think this bug&apos;s priority should be Minor, as it is a vary rare case. So I changed it.&lt;/p&gt;

&lt;p&gt;In this test, I changed the class of &lt;a href=&quot;https://github.com/apache/hadoop/blob/release-2.2.0/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/ReduceContextImpl.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hadoop/blob/release-2.2.0/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/ReduceContextImpl.java&lt;/a&gt;, and add the following lines right after line 144:&lt;br/&gt;
if (key.toString().contains(&quot;xxxxx&quot;)) {&lt;br/&gt;
  System.out.println(&quot;current key length = &quot; + (nextKey.getLength() - nextKey.getPosition()));&lt;br/&gt;
  System.out.println(&quot;current value length = &quot; + (nextVal.getLength() - nextVal.getPosition()));&lt;br/&gt;
}&lt;/p&gt;

&lt;p&gt;// in the above code &quot;xxxx&quot; is the key I know in the bad case, next line &quot;value = valueDeserializer.deserialize(value)&quot; will throw out exception. I want to check the value&apos;s length as bytes changed or not in both cases.&lt;/p&gt;

&lt;p&gt;Anyway, here is the count in the good case, which means the mapper only omit 3 records, include the &quot;xxxxx&quot; record:&lt;/p&gt;

&lt;p&gt;16/01/28 14:03:58 INFO mapred.JobClient: Job complete: job_201512111403_1109&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient: Counters: 31&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:   File System Counters&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     FILE: BYTES_READ=524&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     FILE: BYTES_WRITTEN=1888562&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     HDFS: BYTES_READ=965292334&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     HDFS: BYTES_WRITTEN=1508&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:   org.apache.hadoop.mapreduce.JobCounter&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     TOTAL_LAUNCHED_MAPS=9&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     TOTAL_LAUNCHED_REDUCES=1&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     DATA_LOCAL_MAPS=9&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS=415253&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES=24692&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     FALLOW_SLOTS_MILLIS_MAPS=0&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     FALLOW_SLOTS_MILLIS_REDUCES=0&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:   org.apache.hadoop.mapreduce.TaskCounter&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     MAP_INPUT_RECORDS=234962&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     MAP_OUTPUT_RECORDS=3&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     MAP_OUTPUT_BYTES=822&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     MAP_OUTPUT_MATERIALIZED_BYTES=717&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     SPLIT_RAW_BYTES=1461&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     COMBINE_INPUT_RECORDS=0&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     COMBINE_OUTPUT_RECORDS=0&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     REDUCE_INPUT_GROUPS=3&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     REDUCE_SHUFFLE_BYTES=717&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     REDUCE_INPUT_RECORDS=3&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     REDUCE_OUTPUT_RECORDS=3&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     SPILLED_RECORDS=6&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     CPU_MILLISECONDS=346620&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     PHYSICAL_MEMORY_BYTES=10232893440&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     VIRTUAL_MEMORY_BYTES=43124248576&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     COMMITTED_HEAP_BYTES=13987872768&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:   ETLCounter$CounterType&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     REDUCER_OUTPUT_RECORD=3&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     VALID_RECORD=3&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:   File Input Format Counters&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     Bytes Read=965224378&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:   org.apache.hadoop.mapreduce.lib.output.FileOutputFormat$Counter&lt;br/&gt;
16/01/28 14:03:58 INFO mapred.JobClient:     BYTES_WRITTEN=1508&lt;br/&gt;
16/01/28 14:03:58 INFO mapreduce.Contact2ETLDeltaDriver: Merge job done!&lt;/p&gt;

&lt;p&gt;In this case, I got the following in the log:&lt;/p&gt;

&lt;p&gt;current key length = 34&lt;br/&gt;
current value length = 402681&lt;/p&gt;

&lt;p&gt;It looks like the value&apos;s length is 402681.&lt;/p&gt;

&lt;p&gt;Then I run the same MR job again, but in this case, I am omitting all the records out, instead of just 3, and got the following in the log:&lt;/p&gt;

&lt;p&gt;current key length = 34&lt;br/&gt;
current value length = 403167&lt;br/&gt;
Got ((n &amp;gt;&amp;gt;&amp;gt; 1) ^ -(n &amp;amp; 1)) = -51&lt;br/&gt;
And b = 101&lt;br/&gt;
And shift = 0&lt;br/&gt;
And n = 101&lt;/p&gt;

&lt;p&gt;So this case, for the same avro record, shipped to reducer from the mapper, but the length of value changes to 403167, which will also cause the readInt method return &quot;-51&quot;.&lt;/p&gt;

&lt;p&gt;Even I am not 100% sure about how the intermediate data of MR job generated, but for the same AVRO record, should the value&apos;s length be the same in the ReduceContextImpl stage? Why the length will change? Is this correct?&lt;/p&gt;</comment>
                            <comment id="15122325" author="java8964" created="Thu, 28 Jan 2016 21:21:59 +0000"  >&lt;p&gt;And in this dataset, I don&apos;t think we ever change the schema.&lt;/p&gt;</comment>
                            <comment id="16089823" author="belugabehr" created="Mon, 17 Jul 2017 13:32:34 +0000"  >&lt;p&gt;May be experiencing this issue as well.... trying to collect more information...&lt;/p&gt;</comment>
                            <comment id="16110083" author="belugabehr" created="Wed, 2 Aug 2017 01:07:46 +0000"  >&lt;p&gt;I created a Fuzzer to test random combinations of values to try to reproduce this issue, but no luck.  During my investigation, I hit &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-11678&quot; title=&quot;AvroSerializer buffers output in violation of contract for Serializer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-11678&quot;&gt;HADOOP-11678&lt;/a&gt; because I forgot to set the Serializer to use &lt;tt&gt;org.apache.avro.hadoop.io.AvroSerialization&lt;/tt&gt; and I was instead getting the default Hadoop Avro Serialization class of &lt;tt&gt;org.apache.hadoop.io.serializer.avro.AvroSerialization&lt;/tt&gt; which is very broken because it&apos;s erroneously buffering data.  However, during the time I was not setting the Serialization class correctly, I was getting some failures with stack traces that are very similar to the one reported here.  So, it makes me think that there may be a buffer that isn&apos;t being flushed during serialization.  Once i corrected the mistake, my Fuzzer ran for several hours and did not encounter any issues serializing or deserializing the random data.  I was serializing the data directly to an &lt;a href=&quot;https://github.com/apache/hadoop/blob/f67237cbe7bc48a1b9088e990800b37529f1db2a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/IFile.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;IFile&lt;/a&gt; Writer and then using the IFile Reader to deserialize the back into objects.&lt;/p&gt;

&lt;p&gt;We are observing the same behaviors:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;All Mappers finish without error&lt;/li&gt;
	&lt;li&gt;Most of the reducers finish without error, but one reducer keeps failing with the above error.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Interestingly, our Map Input and Output are the same classes.  That is to say, the Mappers filter and normalize the data, they don&apos;t create it.  The &lt;tt&gt;AvroKey&lt;/tt&gt; and &lt;tt&gt;AvroValue&lt;/tt&gt; parameters passed to the Mapper are then returned by the Mapper.  There are no &lt;tt&gt;AvroKey&lt;/tt&gt; or &lt;tt&gt;AvroValue&lt;/tt&gt; classes instantiated in the Mapper.  They are passed directly through the Map method.  This demonstrates that the entire data set can be read by the Avro serialization framework, but something goes wrong during the intermediate file stage.  This may be an issue with how the Hadoop MapReduce framework interacts with Avro&apos;s library.&lt;/p&gt;</comment>
                            <comment id="16112014" author="belugabehr" created="Thu, 3 Aug 2017 01:05:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cutting&quot; class=&quot;user-hover&quot; rel=&quot;cutting&quot;&gt;Doug Cutting&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rdblue&quot; class=&quot;user-hover&quot; rel=&quot;rdblue&quot;&gt;Ryan Blue&lt;/a&gt; I&apos;ve been tearing through the code of Avro and MapReduce to find a chink in the armor, but not luck.  Any thoughts on where I can focus my search?&lt;/p&gt;</comment>
                            <comment id="16114574" author="belugabehr" created="Fri, 4 Aug 2017 16:16:06 +0000"  >&lt;p&gt;In regards to the original case, it is interesting to note that the Reducer failed while &lt;a href=&quot;https://github.com/apache/hadoop/blob/f67237cbe7bc48a1b9088e990800b37529f1db2a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/ReduceContextImpl.java#L142&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;deserializing the key&lt;/a&gt;.  However, the Map output key is of type &lt;tt&gt;mergeJob.setMapOutputKeyClass(Contact2MergePartitionKey.class)&lt;/tt&gt; which is not an &lt;tt&gt;AvroKey&lt;/tt&gt; class.  So, I&apos;m not sure why the Avro deserializer is in play here at all.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12779778">HADOOP-11678</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12697142">MAPREDUCE-5767</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 25 Jan 2016 20:58:55 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 24 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2rrjj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            </customfields>
    </item>


<item>
            <title>[AVRO-1787] Add support of directories &amp; globs to concat and cat</title>
                <link>https://issues.apache.org/jira/browse/AVRO-1787</link>
                <project id="12310911" key="AVRO">Apache Avro</project>
                    <description>&lt;p&gt;While answering &lt;a href=&quot;http://stackoverflow.com/questions/34856838/concat-avro-files-using-avro-tools/34899425#34899425&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;this question&lt;/a&gt; on stack overflow, I noticed that the concat tool does not support directories or glob patterns as &quot;input-file&quot;.&lt;/p&gt;

&lt;p&gt; OP&apos;s use case seems very valid but accepting only files as input push the burden on users.&lt;/p&gt;

&lt;p&gt;I think that it makes sense to also accept directories as input like cat does. Supporting glob patterns seems also useful if one want to concatenate the output of a MR job (in this case passing the directory won&apos;t work because of the &lt;tt&gt;_SUCESS&lt;/tt&gt; file).&lt;/p&gt;

&lt;p&gt;I have quickly patched &lt;tt&gt;concat&lt;/tt&gt; to support files, directories and glob patterns. Support of glob patterns has been added to &lt;tt&gt;cat&lt;/tt&gt; since it seems useful too.&lt;/p&gt;

&lt;p&gt;This change should not introduce regression for users. But any feedback about glob patterns is welcome.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12933165">AVRO-1787</key>
            <summary>Add support of directories &amp; globs to concat and cat</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="clement@unportant.info">Cl&#233;ment MATHIEU</assignee>
                                    <reporter username="clement@unportant.info">Cl&#233;ment MATHIEU</reporter>
                        <labels>
                    </labels>
                <created>Thu, 21 Jan 2016 20:43:47 +0000</created>
                <updated>Fri, 27 Jan 2017 16:59:16 +0000</updated>
                            <resolved>Fri, 27 Jan 2017 16:59:11 +0000</resolved>
                                    <version>1.7.7</version>
                                    <fixVersion>1.9.0</fixVersion>
                                    <component>java</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="15843118" author="jira-bot" created="Fri, 27 Jan 2017 16:58:33 +0000"  >&lt;p&gt;Commit f8c70a3a9fe5a410363544493a03dc2d10340cbd in avro&apos;s branch refs/heads/master from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=clement%40unportant.info&quot; class=&quot;user-hover&quot; rel=&quot;clement@unportant.info&quot;&gt;Cl&#233;ment MATHIEU&lt;/a&gt;&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=avro.git;h=f8c70a3&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=avro.git;h=f8c70a3&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/AVRO-1787&quot; title=&quot;Add support of directories &amp;amp; globs to concat and cat&quot; class=&quot;issue-link&quot; data-issue-key=&quot;AVRO-1787&quot;&gt;&lt;del&gt;AVRO-1787&lt;/del&gt;&lt;/a&gt; Add support of directories &amp;amp; globs to concat and cat. Contributed by Cl&#233;ment MATHIEU.&lt;/p&gt;

&lt;p&gt;Signed-off-by: Sean Busbey &amp;lt;busbey@apache.org&amp;gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13003173">AVRO-1909</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12974272">AVRO-1856</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12783667" name="AVRO-1787.patch" size="10214" author="clement@unportant.info" created="Thu, 21 Jan 2016 20:45:31 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 27 Jan 2017 16:58:33 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 51 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2rtbz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>
</channel>
</rss>
