<!--
RSS generated by JIRA (7.6.3#76005-sha1:8a4e38d34af948780dbf52044e7aafb13a7cae58) at Tue Jan 22 15:17:54 UTC 2019

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<!-- If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
    <channel>
        <title>ASF JIRA</title>
        <link>https://issues.apache.org/jira/issues/?jql=project+%3D+HIVE+AND+created+%3E%3D+2011-3-28+AND+created+%3C%3D+2011-4-6+ORDER+BY+key+ASC</link>
        <description>An XML representation of a search request</description>
                <language>en-uk</language>
                        <issue start="0" end="17" total="17"/>
                <build-info>
            <version>7.6.3</version>
            <build-number>76005</build-number>
            <build-date>09-01-2018</build-date>
        </build-info>

<item>
            <title>[HIVE-2079] The warehouse directory shouldn&apos;t be 777&apos;ed</title>
                <link>https://issues.apache.org/jira/browse/HIVE-2079</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The warehouse directory is created with a permissions of 777. This is to allow any user to successfully create database/table directories there. The security issue is that anyone can delete any directory in the warehouse. We should fix this hole.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12502643">HIVE-2079</key>
            <summary>The warehouse directory shouldn&apos;t be 777&apos;ed</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="macyang">Mac Yang</assignee>
                                    <reporter username="devaraj">Devaraj Das</reporter>
                        <labels>
                    </labels>
                <created>Tue, 29 Mar 2011 00:45:56 +0000</created>
                <updated>Tue, 13 Sep 2011 23:02:46 +0000</updated>
                                                                            <component>Metastore</component>
                    <component>Security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13012994" author="appodictic" created="Wed, 30 Mar 2011 14:47:51 +0000"  >&lt;p&gt;Really? What should it be? Any why? How does this apply to deployments outside yours? &lt;/p&gt;</comment>
                            <comment id="13013557" author="devaraj" created="Wed, 30 Mar 2011 17:51:08 +0000"  >&lt;p&gt;Edward, at Yahoo!, we run the thrift server as a standalone metastore server, and there the problem can be handled. The solution is still under investigation but here is the flow of the directory creations and permission settings:&lt;br/&gt;
1) Have the real warehouse directory owned by the hive-thrift-server user and let that have 755 permissions.&lt;br/&gt;
2) Have a temp warehouse directory for staging the creation of tables/databases, and let that have 777 permissions.&lt;br/&gt;
3) When a user issues a create_table/database command, the hive-thrift-server creates the corresponding directory in the temp location. This operation happens as the user in question and the directory ends up getting owned by the user.&lt;br/&gt;
4) The hive-thrift-server then moves the directory to the real warehouse directory. This operation is done as the hive-thrift-server user.Since the temp directory has 777 permissions, and the real warehouse directory is owned by the hive-thrift-server user, the move will succeed.&lt;/p&gt;

&lt;p&gt;With all the work that has been done in mostly &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1842&quot; title=&quot;Add the local flag to all the map red tasks, if the query is running locally.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1842&quot;&gt;&lt;del&gt;HIVE-1842&lt;/del&gt;&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1696&quot; title=&quot;Add delegation token support to metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1696&quot;&gt;&lt;del&gt;HIVE-1696&lt;/del&gt;&lt;/a&gt;, the above seems possible.&lt;/p&gt;

&lt;p&gt;Granted, this won&apos;t work when hive runs in the fat-client mode. So, most likely, we will make the above be based on whether metastore is running in the local mode or not (hive.metastore.local config).&lt;/p&gt;

&lt;p&gt;Makes sense ?&lt;/p&gt;</comment>
                            <comment id="13013604" author="appodictic" created="Wed, 30 Mar 2011 19:27:51 +0000"  >&lt;p&gt;Ok thanks that clears it up. This only effects those using hive-server and fat client is exempt. This should not be very difficult. Hive always works in side effect files and then does moves as the last step. So your technique to do elsewhere and then copy in and chown makes sense. +1&lt;/p&gt;</comment>
                            <comment id="13104063" author="ashutoshc" created="Tue, 13 Sep 2011 23:02:46 +0000"  >&lt;p&gt;Apart from permissions of warehouse dir, ownership of warehouse dir also needs to be fixed. On a fresh install, warehouse directory doesn&apos;t get created while metastore server is starting and first client doing any filesystem operation ends up being its owner. We already have checkForDefaultDb(), we similarly need checkForWarehouseDir().&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 30 Mar 2011 14:47:51 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>35812</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 19 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i06aov:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>34663</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-2080] Few code improvements in the ql and serde packages.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-2080</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Few code improvements in the ql and serde packages.&lt;br/&gt;
1) Little performance Improvements &lt;br/&gt;
2) Null checks to avoid NPEs&lt;br/&gt;
3) Effective varaible management.&lt;/p&gt;</description>
                <environment>&lt;p&gt;Hadoop 0.20.1, Hive0.7.0 and SUSE Linux Enterprise Server 10 SP2 (i586) - Kernel 2.6.16.60-0.21-smp (5).&lt;/p&gt;</environment>
        <key id="12502662">HIVE-2080</key>
            <summary>Few code improvements in the ql and serde packages.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="chinnalalam">Chinna Rao Lalam</assignee>
                                    <reporter username="chinnalalam">Chinna Rao Lalam</reporter>
                        <labels>
                    </labels>
                <created>Tue, 29 Mar 2011 06:42:52 +0000</created>
                <updated>Fri, 16 Dec 2011 23:56:39 +0000</updated>
                            <resolved>Fri, 29 Jul 2011 18:52:04 +0000</resolved>
                                    <version>0.7.0</version>
                                    <fixVersion>0.8.0</fixVersion>
                                    <component>Query Processor</component>
                    <component>Serializers/Deserializers</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13012800" author="namit" created="Wed, 30 Mar 2011 01:02:47 +0000"  >&lt;p&gt;Can you provide a review board request ?&lt;/p&gt;</comment>
                            <comment id="13014005" author="jiraposter@reviews.apache.org" created="Thu, 31 Mar 2011 15:14:53 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/535/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/535/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for hive.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Few code improvements in the ql and serde packages.&lt;br/&gt;
1) Little performance Improvements &lt;br/&gt;
2) Null checks to avoid NPEs&lt;br/&gt;
3) Effective varaible management.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2080&quot; title=&quot;Few code improvements in the ql and serde packages.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2080&quot;&gt;&lt;del&gt;HIVE-2080&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2080&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2080&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/CommonJoinOperator.java 1086514 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java 1086514 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FilterOperator.java 1086514 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java 1086514 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java 1086514 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java 1086514 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java 1086514 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java 1086514 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/TaskFactory.java 1086514 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/UnionOperator.java 1086514 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ASTNode.java 1086514 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java 1086514 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseContext.java 1086514 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java 1086514 &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/dynamic_type/DynamicSerDeField.java 1086514 &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/dynamic_type/DynamicSerDeFieldType.java 1086514 &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/dynamic_type/DynamicSerDeFunction.java 1086514 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/535/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/535/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Ran the tests. All tests passed&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;chinna&lt;/p&gt;
</comment>
                            <comment id="13028220" author="chinnalalam" created="Tue, 3 May 2011 13:29:36 +0000"  >&lt;p&gt;Added in review board:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/535/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/535/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13061525" author="jvs" created="Thu, 7 Jul 2011 19:32:25 +0000"  >&lt;p&gt;Sorry, this one has gone stale...could you rebase against trunk?&lt;/p&gt;</comment>
                            <comment id="13068404" author="jiraposter@reviews.apache.org" created="Wed, 20 Jul 2011 14:34:58 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/1144/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/1144/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for hive.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Few code improvements in the ql and serde packages.&lt;br/&gt;
1) Little performance Improvements &lt;br/&gt;
2) Null checks to avoid NPEs&lt;br/&gt;
3) Effective varaible management.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2080&quot; title=&quot;Few code improvements in the ql and serde packages.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2080&quot;&gt;&lt;del&gt;HIVE-2080&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2080&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2080&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/CommonJoinOperator.java 1148179 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java 1148179 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FilterOperator.java 1148179 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java 1148179 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java 1148179 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java 1148179 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java 1148179 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java 1148179 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/TaskFactory.java 1148179 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/UnionOperator.java 1148179 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ASTNode.java 1148179 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java 1148179 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseContext.java 1148179 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java 1148179 &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/dynamic_type/DynamicSerDeField.java 1148179 &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/dynamic_type/DynamicSerDeFieldType.java 1148179 &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/dynamic_type/DynamicSerDeFunction.java 1148179 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/1144/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/1144/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;All unit test passed&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;chinna&lt;/p&gt;
</comment>
                            <comment id="13071332" author="jvs" created="Tue, 26 Jul 2011 20:18:48 +0000"  >&lt;p&gt;Hit a merge conflict in FileSinkOperator.java.&lt;/p&gt;</comment>
                            <comment id="13072196" author="jiraposter@reviews.apache.org" created="Thu, 28 Jul 2011 06:13:09 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/1144/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/1144/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2011-07-28 06:11:18.101615)&lt;/p&gt;


&lt;p&gt;Review request for hive.&lt;/p&gt;


&lt;p&gt;Changes&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Patch rebased&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Few code improvements in the ql and serde packages.&lt;br/&gt;
1) Little performance Improvements &lt;br/&gt;
2) Null checks to avoid NPEs&lt;br/&gt;
3) Effective varaible management.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2080&quot; title=&quot;Few code improvements in the ql and serde packages.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2080&quot;&gt;&lt;del&gt;HIVE-2080&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2080&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2080&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/CommonJoinOperator.java 1151731 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java 1151731 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FilterOperator.java 1151731 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java 1151731 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java 1151731 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java 1151731 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java 1151731 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java 1151731 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/TaskFactory.java 1151731 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/UnionOperator.java 1151731 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ASTNode.java 1151731 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java 1151731 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseContext.java 1151731 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java 1151731 &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/dynamic_type/DynamicSerDeField.java 1151731 &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/dynamic_type/DynamicSerDeFieldType.java 1151731 &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/dynamic_type/DynamicSerDeFunction.java 1151731 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/1144/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/1144/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;All unit test passed&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;chinna&lt;/p&gt;
</comment>
                            <comment id="13072969" author="cwsteinbach" created="Fri, 29 Jul 2011 18:50:32 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13072971" author="cwsteinbach" created="Fri, 29 Jul 2011 18:52:04 +0000"  >&lt;p&gt;Committed to trunk. Thanks Chinna!&lt;/p&gt;</comment>
                            <comment id="13073066" author="hudson" created="Fri, 29 Jul 2011 23:27:42 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #860 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/860/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/860/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2080&quot; title=&quot;Few code improvements in the ql and serde packages.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2080&quot;&gt;&lt;del&gt;HIVE-2080&lt;/del&gt;&lt;/a&gt;. Few code improvements in the ql and serde packages (Chinna Rao Lalam via cws)&lt;/p&gt;

&lt;p&gt;cws : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1152338&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1152338&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/TaskFactory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ASTNode.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/dynamic_type/DynamicSerDeField.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseContext.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/dynamic_type/DynamicSerDeFieldType.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FilterOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/UnionOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/CommonJoinOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/dynamic_type/DynamicSerDeFunction.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12487156" name="HIVE-2080.1.Patch" size="19072" author="chinnalalam" created="Wed, 20 Jul 2011 14:32:01 +0000"/>
                            <attachment id="12488063" name="HIVE-2080.2.Patch" size="12926" author="chinnalalam" created="Thu, 28 Jul 2011 06:06:23 +0000"/>
                            <attachment id="12474890" name="HIVE-2080.Patch" size="19709" author="chinnalalam" created="Tue, 29 Mar 2011 15:43:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 30 Mar 2011 01:02:47 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>43520</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 26 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lic7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123621</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-2081] Prevent automatic indexing from creating worse queries</title>
                <link>https://issues.apache.org/jira/browse/HIVE-2081</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;We want to make sure that automatically using indexes doesn&apos;t make the query worse.  For example, after scanning the index table, it might still need to scan the whole base table.  In this case, we would much rather just kill the index job and go back and scan the whole base table.&lt;/p&gt;

&lt;p&gt;This can be done by adding a conditional task and a backup task. You can detect whether the index is good or not by monitoring the index job&apos;s number of input records and number of output records, and comparing them. As an initial example, if the ratio is &amp;gt;50, do not use the index, and go back to scanning the whole base table.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12502671">HIVE-2081</key>
            <summary>Prevent automatic indexing from creating worse queries</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="rmelick">Russell Melick</reporter>
                        <labels>
                    </labels>
                <created>Tue, 29 Mar 2011 07:13:22 +0000</created>
                <updated>Thu, 2 May 2013 02:29:37 +0000</updated>
                                            <version>0.8.0</version>
                                                    <component>Indexing</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="13012361" author="rmelick" created="Tue, 29 Mar 2011 07:14:17 +0000"  >&lt;p&gt;Followup to Yongqiang&apos;s comment&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12474222">HIVE-1644</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42281</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 44 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i010d3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3824</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-2082] Reduce memory consumption in preparing MapReduce job</title>
                <link>https://issues.apache.org/jira/browse/HIVE-2082</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Hive client side consume a lot of memory when the number of input partitions is large. One reason is that each partition maintains a list of FieldSchema which are intended to deal with schema evolution. However they are not used currently and Hive uses the table level schema for all partitions. This will be fixed in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2050&quot; title=&quot;batch processing partition pruning process&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2050&quot;&gt;&lt;del&gt;HIVE-2050&lt;/del&gt;&lt;/a&gt;. The memory consumption by this part will be reduced by almost half (1.2GB to 700BM for 20k partitions). &lt;/p&gt;

&lt;p&gt;Another large chunk of memory consumption is in the MapReduce job setup phase when a PartitionDesc is created from each Partition object. A property object is maintained in PartitionDesc which contains a full list of columns and types. Due to the same reason, these should be the same as in the table level schema. Also the deserializer initialization takes large amount of memory, which should be avoided. My initial testing for these optimizations cut the memory consumption in half (700MB to 300MB for 20k partitions). &lt;/p&gt;</description>
                <environment></environment>
        <key id="12502774">HIVE-2082</key>
            <summary>Reduce memory consumption in preparing MapReduce job</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nzhang">Ning Zhang</assignee>
                                    <reporter username="nzhang">Ning Zhang</reporter>
                        <labels>
                    </labels>
                <created>Tue, 29 Mar 2011 23:45:02 +0000</created>
                <updated>Fri, 16 Dec 2011 23:56:37 +0000</updated>
                            <resolved>Thu, 7 Apr 2011 16:34:23 +0000</resolved>
                                                    <fixVersion>0.8.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13016401" author="nzhang" created="Wed, 6 Apr 2011 15:06:23 +0000"  >&lt;p&gt;Uploading a patch for review. The review board request is here: &lt;a href=&quot;https://reviews.apache.org/r/556/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/556/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It also passed all unit tests. &lt;/p&gt;</comment>
                            <comment id="13016402" author="nzhang" created="Wed, 6 Apr 2011 15:08:12 +0000"  >&lt;p&gt;Attaching a patch for review. The review board: &lt;a href=&quot;https://reviews.apache.org/r/556/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/556/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It also passed all unit tests. &lt;/p&gt;</comment>
                            <comment id="13016403" author="nzhang" created="Wed, 6 Apr 2011 15:10:34 +0000"  >&lt;p&gt;Attaching a patch for review. The review board is at &lt;a href=&quot;https://reviews.apache.org/r/556/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/556/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This patch also passed all unit tests. &lt;/p&gt;</comment>
                            <comment id="13016435" author="appodictic" created="Wed, 6 Apr 2011 17:10:01 +0000"  >&lt;p&gt;I am curious as to how this is compatible with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1913&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1913&lt;/a&gt;. &lt;/p&gt;</comment>
                            <comment id="13016450" author="namit" created="Wed, 6 Apr 2011 17:25:55 +0000"  >&lt;p&gt;Edward, I havent reviewed the patch in detail - but the general idea is as follows:&lt;/p&gt;

&lt;p&gt;Partition inherits some properties from the Table (for eg. columns), and&lt;br/&gt;
others can be overwritten (for eg. serde).&lt;/p&gt;

&lt;p&gt;Today, we treat all the properties similarly - this patch should optimize&lt;br/&gt;
for the inherited properties by maintaining just 1 copy.&lt;/p&gt;</comment>
                            <comment id="13016461" author="nzhang" created="Wed, 6 Apr 2011 17:43:24 +0000"  >&lt;p&gt;@Edward, &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1913&quot; title=&quot;use partition level serde properties&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1913&quot;&gt;&lt;del&gt;HIVE-1913&lt;/del&gt;&lt;/a&gt; fixed a bug in PartitionDesc where previously table properties are returned even if partition properties are present. This patch doesn&apos;t change that. &lt;/p&gt;

&lt;p&gt;What this patch changed is how the PartitionDesc.properties is constructed. Previously properties is constructed using part.getSchema(), which will construct a new Properties object for each partition. The most memory consuming part is the colNames, colTypes and partStrings (see MetaStoreUtils.getSchema()). Since they are constructed using the table level StorageDescriptor, all partitions have the same colNames, colTypes and partStrings. So we could use the same objects for all partitions. &lt;/p&gt;

&lt;p&gt;This patch introduces a new PartitionDesc constructor with an additional TableDesc argument. The properties is constructed by using part.getSchemaFromTableSchema(tblDesc.getProperties()), which construct the properties by cloning the table level properties to the partiton level properties first and then overwrite it with partition specific arguments. Basically all except the colNames, colTypes and partStrings will be overwritten with the partition level Properties. &lt;/p&gt;</comment>
                            <comment id="13016515" author="namit" created="Wed, 6 Apr 2011 20:36:51 +0000"  >&lt;p&gt;minor comments in review board&lt;/p&gt;</comment>
                            <comment id="13016590" author="namit" created="Wed, 6 Apr 2011 22:37:35 +0000"  >&lt;p&gt;OK&lt;/p&gt;

&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13017032" author="namit" created="Thu, 7 Apr 2011 16:34:23 +0000"  >&lt;p&gt;Committed. Thanks Ning&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12475595" name="HIVE-2082.patch" size="292724" author="nzhang" created="Wed, 6 Apr 2011 15:10:33 +0000"/>
                            <attachment id="12475594" name="HIVE-2082.patch" size="292724" author="nzhang" created="Wed, 6 Apr 2011 15:08:12 +0000"/>
                            <attachment id="12475593" name="HIVE-2082.patch" size="292724" author="nzhang" created="Wed, 6 Apr 2011 15:06:23 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 6 Apr 2011 17:10:01 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>66846</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 42 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0licf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123622</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-2083] Bug: RowContainer was set to 1 in JoinUtils.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-2083</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;This cause the skew join super slow because the row container dump every record to disk before using them.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12502782">HIVE-2083</key>
            <summary>Bug: RowContainer was set to 1 in JoinUtils.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="he yongqiang">He Yongqiang</assignee>
                                    <reporter username="he yongqiang">He Yongqiang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 30 Mar 2011 00:53:51 +0000</created>
                <updated>Fri, 16 Dec 2011 23:56:59 +0000</updated>
                            <resolved>Thu, 31 Mar 2011 00:58:59 +0000</resolved>
                                                    <fixVersion>0.8.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="13012797" author="he yongqiang" created="Wed, 30 Mar 2011 00:56:24 +0000"  >&lt;p&gt;And also in our internal env, the FS.listStatus can return NULL instead of zero length array. Added a fix for this also.&lt;/p&gt;</comment>
                            <comment id="13012799" author="namit" created="Wed, 30 Mar 2011 01:01:14 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13013770" author="namit" created="Thu, 31 Mar 2011 00:58:59 +0000"  >&lt;p&gt;Committed. Thanks Yongqiang&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12474945" name="HIVE-2083.1.patch" size="3431" author="he yongqiang" created="Wed, 30 Mar 2011 00:56:52 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 30 Mar 2011 01:01:14 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>69567</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 43 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0licn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123623</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-2084] Upgrade datanucleus from 2.0.3 to a more recent version (3.?)</title>
                <link>https://issues.apache.org/jira/browse/HIVE-2084</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;It seems the datanucleus 2.2.3 does a better join in caching. The time it takes to get the same set of partition objects takes about 1/4 of the time it took for the first time. While with 2.0.3, it took almost the same amount of time in the second execution. We should retest the test case mentioned in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1853&quot; title=&quot;downgrade JDO version&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1853&quot;&gt;&lt;del&gt;HIVE-1853&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1862&quot; title=&quot;Revive partition filtering in the Hive MetaStore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1862&quot;&gt;&lt;del&gt;HIVE-1862&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12502784">HIVE-2084</key>
            <summary>Upgrade datanucleus from 2.0.3 to a more recent version (3.?)</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sushanth">Sushanth Sowmyan</assignee>
                                    <reporter username="nzhang">Ning Zhang</reporter>
                        <labels>
                            <label>datanucleus</label>
                    </labels>
                <created>Wed, 30 Mar 2011 00:59:27 +0000</created>
                <updated>Tue, 15 Oct 2013 23:30:21 +0000</updated>
                            <resolved>Fri, 26 Jul 2013 15:36:44 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Metastore</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>26</watches>
                                                                <comments>
                            <comment id="13013851" author="nzhang" created="Thu, 31 Mar 2011 06:24:20 +0000"  >&lt;p&gt;review board: &lt;a href=&quot;https://reviews.apache.org/r/537/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/537/&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing using the script provided by &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1862&quot; title=&quot;Revive partition filtering in the Hive MetaStore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1862&quot;&gt;&lt;del&gt;HIVE-1862&lt;/del&gt;&lt;/a&gt; while adding partitions to the input table. Test has been going on for several hours and so far so good.&lt;/p&gt;</comment>
                            <comment id="13013852" author="nzhang" created="Thu, 31 Mar 2011 06:27:33 +0000"  >&lt;p&gt;Devaraj/Mac, could you also test this patch on your production environment if you have other testing scripts? I&apos;m testing the script uploaded by Namit in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1862&quot; title=&quot;Revive partition filtering in the Hive MetaStore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1862&quot;&gt;&lt;del&gt;HIVE-1862&lt;/del&gt;&lt;/a&gt; and this patch seems working fine so far. &lt;/p&gt;</comment>
                            <comment id="13014090" author="macyang" created="Thu, 31 Mar 2011 17:33:40 +0000"  >&lt;p&gt;Ning, I will test this patch with our usual set up and let you know how it goes.&lt;/p&gt;</comment>
                            <comment id="13014166" author="namit" created="Thu, 31 Mar 2011 19:50:08 +0000"  >&lt;p&gt;@Ning/Paul, do you know if data nucleus 2.2.3 has the ability to &lt;br/&gt;
support filter pushdown for predicates for non-equality.&lt;/p&gt;</comment>
                            <comment id="13014168" author="namit" created="Thu, 31 Mar 2011 19:51:07 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;The code changes look good, but I will wait from a confirmation by&lt;br/&gt;
Mac before checking it in.&lt;/p&gt;</comment>
                            <comment id="13014182" author="nzhang" created="Thu, 31 Mar 2011 20:21:41 +0000"  >&lt;p&gt;@Namit, yeah, 2.2.3 support filter push down for non-equality. Even the older version of 2.0.3 supposes it too. Mac&apos;s patch actually supports range queries, but since range queries could be complicated on multiple partition columns (what if the range is on the column that is not the top partition column), I didn&apos;t dig deep into it, but it the push down filtering criteria can certainly be relaxed. &lt;/p&gt;

&lt;p&gt;Having said that, my test results shows that JDO filter pushing down may not be the dominate factor (comparing to the patch in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2050&quot; title=&quot;batch processing partition pruning process&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2050&quot;&gt;&lt;del&gt;HIVE-2050&lt;/del&gt;&lt;/a&gt;). In the experiments I&apos;ve done for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2050&quot; title=&quot;batch processing partition pruning process&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2050&quot;&gt;&lt;del&gt;HIVE-2050&lt;/del&gt;&lt;/a&gt;, listing partition names and filtering partitions in the Hive client side may take 10 sec, but retrieving all Partition objects takes about 10 mins in total. The best of pushing down JDO filtering can only reduce the 10 sec to 0, but the 10 mins overhead is still there. We need to find a way to optimize that away.&lt;/p&gt;</comment>
                            <comment id="13014189" author="cwsteinbach" created="Thu, 31 Mar 2011 20:41:58 +0000"  >&lt;p&gt;@Ning: Why did you modify the class mapping in package.jdo? Does this require a metastore upgrade script?&lt;/p&gt;</comment>
                            <comment id="13014240" author="nzhang" created="Thu, 31 Mar 2011 22:14:59 +0000"  >&lt;p&gt;@Carl, one change (at line 49) in package.jdo is to fix a bug that was not exposed by the old datanucleus version. Without the change datanucleus will throw an exception in runtime (FCOMMENT is not a column of COLUMNS table). I guess the old version of datanucleus didn&apos;t check MFieldSchema mapping in package.jdo, by only retrieving the columns mentioned in the &amp;lt;embedded&amp;gt; elements. The other changes are to make the legacy mappings to confirm to the current relational schema (e.g., MFieldSchema.FNAME should be mapped to COLUMNS.COLUMN_NAME). They currently does not cause any runtime exceptions, but I guess it&apos;s better to fix it proactively if we are sure the relational mapping is wrong. &lt;/p&gt;</comment>
                            <comment id="13014294" author="cwsteinbach" created="Thu, 31 Mar 2011 23:40:16 +0000"  >&lt;blockquote&gt;&lt;p&gt;One change (at line 49) in package.jdo is to fix a bug that was not exposed by the old datanucleus version. Without the change datanucleus will throw an exception in runtime (FCOMMENT is not a column of COLUMNS table). I guess the old version of datanucleus didn&apos;t check MFieldSchema mapping in package.jdo, by only retrieving the columns mentioned in the &amp;lt;embedded&amp;gt; elements.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yup, looks like that&apos;s the case. It also looks like Datanucleus was ignoring the size of the FCOMMENTS field, so the older versions of TYPE_FIELDS.COMMENT and COLUMNS.COMMENT have size 256, which must be the default value. In the new schema these fields both get bumped to 4000 bytes, which is the correct size. Can you please include upgrade scripts that update the size of these columns accordingly?&lt;/p&gt;

&lt;p&gt;Also, as far as I can tell the change to the MOrder mapping has no effect since it is only referenced by the SORT_COLS table, which overrides the name to COLUMN_NAME instead.&lt;/p&gt;</comment>
                            <comment id="13014302" author="macyang" created="Thu, 31 Mar 2011 23:47:17 +0000"  >&lt;p&gt;Test has been running for about six hours without failure. Looks good.&lt;/p&gt;</comment>
                            <comment id="13014711" author="nzhang" created="Fri, 1 Apr 2011 16:04:09 +0000"  >&lt;p&gt;Thank Mac for the update. &lt;/p&gt;

&lt;p&gt;@Carl, I&apos;ll change the field size if they do not match with the relational schema. BTW, we don&apos;t need to upgrade the relational schema. I&apos;m trying to update the object-to-relational mapping in package.jdo to match with the relational schema. &lt;/p&gt;

&lt;p&gt;Also there are some tests failing. I&apos;m working on that and will upload a new patch all together. &lt;/p&gt;</comment>
                            <comment id="13114507" author="cwsteinbach" created="Mon, 26 Sep 2011 07:31:43 +0000"  >&lt;p&gt;DataNucleus 3.0.1 was released last month. We should probably try to go upgrade to&lt;br/&gt;
that since it will make it possible to fix &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2015&quot; title=&quot;Eliminate bogus Datanucleus.Plugin Bundle ERROR log messages&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2015&quot;&gt;&lt;del&gt;HIVE-2015&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13114647" author="andy" created="Mon, 26 Sep 2011 13:11:51 +0000"  >&lt;p&gt;Regarding upgrading to DN 3.0, follow this link &lt;a href=&quot;http://www.datanucleus.org/products/accessplatform_3_0/migration.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.datanucleus.org/products/accessplatform_3_0/migration.html&lt;/a&gt;&lt;br/&gt;
3.0.2 will be out in a week, but no API changes involved from 3.0.1 to 3.0.2&lt;/p&gt;</comment>
                            <comment id="13117781" author="cwsteinbach" created="Fri, 30 Sep 2011 00:31:16 +0000"  >&lt;p&gt;Attached patch upgrades DN dependency to v3.0.1. Running tests now.&lt;/p&gt;</comment>
                            <comment id="13117788" author="jiraposter@reviews.apache.org" created="Fri, 30 Sep 2011 00:37:45 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/2127/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/2127/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for hive and John Sichi.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;This patch upgrades Hive&apos;s Datanucleus dependency from v2.0.3 to v3.0.1.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2084&quot; title=&quot;Upgrade datanucleus from 2.0.3 to a more recent version (3.?)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2084&quot;&gt;&lt;del&gt;HIVE-2084&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2084&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2084&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  conf/hive-default.xml 683b417 &lt;br/&gt;
  ivy/libraries.properties adde3cb &lt;br/&gt;
  metastore/ivy.xml 2e5331d &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java 983e1d5 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/2127/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/2127/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Carl&lt;/p&gt;
</comment>
                            <comment id="13117816" author="jvs" created="Fri, 30 Sep 2011 01:39:20 +0000"  >&lt;p&gt;Any stress retesting needed in case of regression from 2.2.3 to 3.0.1?&lt;/p&gt;</comment>
                            <comment id="13117818" author="cwsteinbach" created="Fri, 30 Sep 2011 01:43:50 +0000"  >&lt;p&gt;@John: Sounds like a good idea. Do you know if @Ning still has the scripts he used earlier?&lt;/p&gt;</comment>
                            <comment id="13118198" author="cwsteinbach" created="Fri, 30 Sep 2011 17:06:07 +0000"  >&lt;p&gt;There are failures in the auth and indexing tests. I&apos;m investigating.&lt;/p&gt;</comment>
                            <comment id="13204978" author="ashutoshc" created="Thu, 9 Feb 2012 22:44:26 +0000"  >&lt;p&gt;This upgrade may resolve &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2473&quot; title=&quot;Hive throws an NPE when $HADOOP_HOME points to a tarball install directory that contains a build/ subdirectory.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2473&quot;&gt;&lt;del&gt;HIVE-2473&lt;/del&gt;&lt;/a&gt; too.&lt;/p&gt;</comment>
                            <comment id="13233353" author="sushanth" created="Tue, 20 Mar 2012 11:16:19 +0000"  >&lt;p&gt;Updated patch, and changed to Datanucleus v3.0.8. Does anyone still have any failing tests with this upgrade?&lt;/p&gt;</comment>
                            <comment id="13233670" author="cwsteinbach" created="Tue, 20 Mar 2012 19:12:41 +0000"  >&lt;p&gt;@Sushanth: Can you please submit a review request on phabricator? Thanks. &lt;a href=&quot;https://cwiki.apache.org/Hive/phabricatorcodereview.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/Hive/phabricatorcodereview.html&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13233927" author="phabricator@reviews.facebook.net" created="Tue, 20 Mar 2012 23:13:37 +0000"  >&lt;p&gt;khorgath requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2084&quot; title=&quot;Upgrade datanucleus from 2.0.3 to a more recent version (3.?)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2084&quot;&gt;&lt;del&gt;HIVE-2084&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Upgrade datanucleus from 2.0.3 to 3.0.1&quot;.&lt;br/&gt;
Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;  Updated &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2084&quot; title=&quot;Upgrade datanucleus from 2.0.3 to a more recent version (3.?)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2084&quot;&gt;&lt;del&gt;HIVE-2084&lt;/del&gt;&lt;/a&gt; to work off DataNucleus release 3.0.8&lt;/p&gt;

&lt;p&gt;  It seems the datanucleus 2.2.3 does a better join in caching. The time it takes to get the same set of partition objects takes about 1/4 of the time it took for the first time. While with 2.0.3, it took almost the same amount of time in the second execution. We should retest the test case mentioned in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1853&quot; title=&quot;downgrade JDO version&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1853&quot;&gt;&lt;del&gt;HIVE-1853&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1862&quot; title=&quot;Revive partition filtering in the Hive MetaStore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1862&quot;&gt;&lt;del&gt;HIVE-1862&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  existing tests (this is a library dep upgrade)&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D2397&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D2397&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;br/&gt;
  conf/hive-default.xml.template&lt;br/&gt;
  ivy/libraries.properties&lt;br/&gt;
  metastore/ivy.xml&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD DIFFERENTIAL RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/5367/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/5367/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Tip: use the X-Herald-Rules header to filter Herald messages in your client.&lt;/p&gt;</comment>
                            <comment id="13233928" author="sushanth" created="Tue, 20 Mar 2012 23:13:58 +0000"  >&lt;p&gt;Updated : &lt;a href=&quot;https://reviews.facebook.net/D2397&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D2397&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(Also, please ignore the patch file I&apos;d attached here before, I&apos;d generated it from the hcatalog root dir, so it contains extra directory structure)&lt;/p&gt;
</comment>
                            <comment id="13235260" author="alangates" created="Thu, 22 Mar 2012 00:42:18 +0000"  >&lt;p&gt;When I apply this patch all of the Hive end-to-end tests I have pass, as well as the HCatalog ones (including the ones added in &lt;a href=&quot;https://issues.apache.org/jira/browse/HCATALOG-209&quot; title=&quot;Support for partition-range queries from HCat command-line.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HCATALOG-209&quot;&gt;&lt;del&gt;HCATALOG-209&lt;/del&gt;&lt;/a&gt; to test this issue).&lt;/p&gt;</comment>
                            <comment id="13235266" author="namit" created="Thu, 22 Mar 2012 00:55:18 +0000"  >&lt;p&gt;@Alan, I cant seem to find the test which was failing for the old JDO upgrade.&lt;br/&gt;
There was some problem when we upgraded last time.&lt;/p&gt;</comment>
                            <comment id="13235268" author="namit" created="Thu, 22 Mar 2012 00:56:49 +0000"  >&lt;p&gt;OK, it is &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1862&quot; title=&quot;Revive partition filtering in the Hive MetaStore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1862&quot;&gt;&lt;del&gt;HIVE-1862&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
Did you run that test with the new JDO ?&lt;/p&gt;</comment>
                            <comment id="13246759" author="sushanth" created="Wed, 4 Apr 2012 21:47:12 +0000"  >&lt;p&gt;Hi Namit,&lt;/p&gt;

&lt;p&gt;I&apos;ve run a fair number of iterations of tests against the DN versions, and I find that the test that you posted up on that jira still fails a few times with DataNucleus 3.0.8 about 0.5% of the time saying that the table was not found. With DN 2.0.3, I have no failures.&lt;/p&gt;

&lt;p&gt;However, if I increase the parallelism, from 5 concurrent runs, to, say, about 20, all 3 versions of DN wind up showing those kinds of &apos;table not found&apos; error, and quite often (10-20% of the time) and occur even with simpler statements like &apos;describe table&apos; and &apos;show partitions extended&apos;. I think we may have a case of timeouts that are being incorrectly reported.&lt;/p&gt;</comment>
                            <comment id="13250161" author="ashutoshc" created="Mon, 9 Apr 2012 20:42:40 +0000"  >&lt;p&gt;@Sushanth, &lt;/p&gt;

&lt;p&gt;You have two patches up, one via phabricator another directly on jira and they have quite bit of differences among them. Which one you are proposing for review?&lt;/p&gt;</comment>
                            <comment id="13251051" author="sushanth" created="Tue, 10 Apr 2012 20:47:21 +0000"  >&lt;p&gt;@Ashutosh : As per above comment of mine, ignore the one directly on jira - that was generated from hcatalog with a bunch of other unnecessary directory structures associated with it ( hive/external/ ). Please check the one on phabricator.&lt;/p&gt;</comment>
                            <comment id="13414882" author="andy" created="Mon, 16 Jul 2012 06:52:22 +0000"  >&lt;p&gt;No idea what your &quot;table not found&quot; problem is, but if this is at startup logic would suggest passing all classes to DataNucleus via an auto-start mechanism, or using a persistence.xml. If using persistence.xml then make sure you also have persistence property &quot;datanucleus.PersistenceUnitLoadClasses&quot; set to true. That way, all classes are known about once started, and the store knows about these classes too (hence knows of their tables). There are no outstanding issues reported around tables not being found, so if you have something then you need to generate a reproduceable testcase and report it.&lt;/p&gt;

&lt;p&gt;DataNucleus 2.x versions haven&apos;t been supported for some time. DataNucleus 3.0 is now not being updated (except for commercial requests), since DataNucleus 3.1 will be out in &amp;lt; 2 weeks.&lt;/p&gt;</comment>
                            <comment id="13445528" author="cwsteinbach" created="Fri, 31 Aug 2012 00:52:13 +0000"  >&lt;p&gt;@Sushanth: Looks like this patch fell out of sync with trunk. Would you be willing to rebase and post a new copy? Thanks.&lt;/p&gt;</comment>
                            <comment id="13446183" author="sushanth" created="Fri, 31 Aug 2012 18:02:33 +0000"  >&lt;p&gt;@Carl : There&apos;s actually another issue I discovered with this patch, that I&apos;m currently looking at where unit tests that use indexes start failing. (With different versions of datanucleus, I find a different number of rollbackTransaction() being called from the ObjectStore) I almost have the root cause, so I&apos;ll update this patch with that and bumping it to 3.1.0 in another day or two.&lt;/p&gt;</comment>
                            <comment id="13449514" author="sushanth" created="Thu, 6 Sep 2012 08:19:05 +0000"  >&lt;p&gt;@Carl : As an update, I discovered that with the newer DataNucleus, what&apos;s happening is that Map types with null values cannot be persisted. This is a problem because we stamp a comment field in the parametersMap irrespective of whether a comment was provided or not, and this causes a failure during index creation.&lt;/p&gt;

&lt;p&gt;This is also the same issue that I refer to in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2800&quot; title=&quot;NPE in &amp;quot;create index&amp;quot; without comment clause in external metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2800&quot;&gt;&lt;del&gt;HIVE-2800&lt;/del&gt;&lt;/a&gt; where thrift has similar issues, where the fix is the same.&lt;/p&gt;</comment>
                            <comment id="13449528" author="andy" created="Thu, 6 Sep 2012 08:42:50 +0000"  >&lt;p&gt;Obviously DataNucleus has testcases that persist Maps with null values, and they work (since all tests pass with every release), so clearly down to your map and how you&apos;re doing things.&lt;/p&gt;</comment>
                            <comment id="13461627" author="rohithsharma" created="Mon, 24 Sep 2012 06:39:07 +0000"  >&lt;p&gt;Could anyone please update on this issue.? &lt;/p&gt;</comment>
                            <comment id="13461680" author="cwsteinbach" created="Mon, 24 Sep 2012 08:44:47 +0000"  >&lt;p&gt;@Andy: I&apos;d like to take a look at these tests that persist maps with null values. Can you please tell us where they are located? Thanks.&lt;/p&gt;</comment>
                            <comment id="13461784" author="andy" created="Mon, 24 Sep 2012 13:29:52 +0000"  >&lt;p&gt;@Carl, &lt;a href=&quot;http://datanucleus.svn.sourceforge.net/viewvc/datanucleus/test/accessplatform/trunk/test.jdo.datastore/src/test/org/datanucleus/tests/types/SCOMapTests.java?revision=15499&amp;amp;content-type=text%2Fplain&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://datanucleus.svn.sourceforge.net/viewvc/datanucleus/test/accessplatform/trunk/test.jdo.datastore/src/test/org/datanucleus/tests/types/SCOMapTests.java?revision=15499&amp;amp;content-type=text%2Fplain&lt;/a&gt;&lt;br/&gt;
look for &quot;checkPutNullValues&quot;. Always has passed for me since we started supporting null map values (2 or 3 years ago at a guess), most recently with datanucleus-core-3.1.2, datanucleus-api-jdo-3.1.2, datanucleus-rdbms-3.1.1. Since your problem description provides no information of the circumstances (such as log entries, persistence code etc) then cannot speculate as to what you have&lt;/p&gt;</comment>
                            <comment id="13461992" author="cwsteinbach" created="Mon, 24 Sep 2012 18:48:08 +0000"  >&lt;p&gt;@Andy: Thanks for the pointer.&lt;/p&gt;</comment>
                            <comment id="13463266" author="phabricator@reviews.facebook.net" created="Tue, 25 Sep 2012 21:58:07 +0000"  >&lt;p&gt;khorgath requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2084&quot; title=&quot;Upgrade datanucleus from 2.0.3 to a more recent version (3.?)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2084&quot;&gt;&lt;del&gt;HIVE-2084&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Upgrade datanucleus from 2.0.3 to 3.0.1&quot;.&lt;br/&gt;
Reviewers: JIRA, cwsteinbach&lt;/p&gt;

&lt;p&gt;  Updated for 3.1, rebasing to head, and making changes needed to continue building&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  Existing tests&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D5685&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D5685&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;br/&gt;
  conf/hive-default.xml.template&lt;br/&gt;
  ivy/libraries.properties&lt;br/&gt;
  metastore/ivy.xml&lt;br/&gt;
  ql/ivy.xml&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD DIFFERENTIAL RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/13353/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/13353/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, cwsteinbach, khorgath&lt;/p&gt;</comment>
                            <comment id="13463271" author="sushanth" created="Tue, 25 Sep 2012 22:10:49 +0000"  >&lt;p&gt;Andy, thanks for the pointer, I&apos;ll try to see what&apos;s different about our use of Maps.&lt;/p&gt;

&lt;p&gt;I&apos;ve rebased and updated the patch, but unfortunately, I&apos;m not entirely conversant with phabricator yet, and wound up creating a new &quot;review&quot; while updating. It&apos;s now up on &lt;a href=&quot;https://reviews.facebook.net/D5685&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D5685&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The easiest way to test out the difference I allude to is to run the following with and without this patch:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ant clean &amp;amp;&amp;amp; ant very-clean &amp;amp;&amp;amp; ant package &amp;amp;&amp;amp; ant test -Dtestcase=TestCliDriver -Dtest.silent=false -Dqfile=alter_index.q
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If I dig through the stack trace with prints, the eventual error that&apos;s thrown now has an error code of 056063, which localization-maps to &quot;Null values not allowed in persistent maps.&quot;&lt;/p&gt;</comment>
                            <comment id="13463274" author="phabricator@reviews.facebook.net" created="Tue, 25 Sep 2012 22:16:07 +0000"  >&lt;p&gt;khorgath has abandoned the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2084&quot; title=&quot;Upgrade datanucleus from 2.0.3 to a more recent version (3.?)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2084&quot;&gt;&lt;del&gt;HIVE-2084&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Upgrade datanucleus from 2.0.3 to 3.0.1&quot;.&lt;/p&gt;

&lt;p&gt;  Replaced by D5685 : &lt;a href=&quot;https://reviews.facebook.net/D5685&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D5685&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D2397&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D2397&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, khorgath&lt;/p&gt;</comment>
                            <comment id="13463321" author="sushanth" created="Tue, 25 Sep 2012 23:04:20 +0000"  >&lt;p&gt;@Andy : I guess the primary difference is in the allowNulls flag (as used in org.datanucleus.store.rdbms.scostore.AbstractMapStore), which seems to be false in our application. I see ways to turn that on through query hints, but is there any way to turn that on at an application level - i.e. through any java property?&lt;/p&gt;</comment>
                            <comment id="13463840" author="andy" created="Wed, 26 Sep 2012 14:06:09 +0000"  >&lt;p&gt;&quot;allowNulls&quot; can either be set in metadata (XML,annotation) for the container field or it can default to what the particular &quot;java.util&quot; type does so, for example, HashMap/HashSet/LinkedHashSet/any-type-of-list default to allowNulls=true, and all others default to false currently. Only you know what type is your map&lt;/p&gt;</comment>
                            <comment id="13500682" author="kevinwilfong" created="Mon, 19 Nov 2012 22:14:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sushanth&quot; class=&quot;user-hover&quot; rel=&quot;sushanth&quot;&gt;Sushanth Sowmyan&lt;/a&gt; It looks like that problem is a symptom of a large one with the way Hive creates indexes from the CLI.  The version of datanucleus we currently use just ignores a null value in the map so it works when the metastore is local, Thrift does not though, so this problem already causes problems when the metastore is remote.&lt;/p&gt;

&lt;p&gt;I filed &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3722&quot; title=&quot;Create index fails on CLI using remote metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3722&quot;&gt;&lt;del&gt;HIVE-3722&lt;/del&gt;&lt;/a&gt; to fix the problem, I think it should also fix the issue you&apos;re seeing.&lt;/p&gt;</comment>
                            <comment id="13501608" author="sushanth" created="Wed, 21 Nov 2012 00:24:51 +0000"  >&lt;p&gt;Kevin, yeah - the issues seem to be related.&lt;/p&gt;</comment>
                            <comment id="13539634" author="deepesh" created="Wed, 26 Dec 2012 18:42:04 +0000"  >&lt;p&gt;After upgrading the datanucleus I ran into the runtime exception FCOMMENT invalid column name in COLUMNS_V2, this happens only when hive schema is pre-created with the upgrade SQL scripts (i.e. datanucleus.autoCreateSchema=false). So on MySQL, the workaround was to start with a blank schema and set datanucleus.autoCreateSchema=true but this turned out to be a problem on Oracle as the automatic creation of schema fails for the table TBLS (see &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2928&quot; title=&quot;Support for Oracle-backed Hive-Metastore (&amp;quot;longvarchar&amp;quot; to &amp;quot;clob&amp;quot; in package.jdo)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2928&quot;&gt;&lt;del&gt;HIVE-2928&lt;/del&gt;&lt;/a&gt;). To get around this on Oracle I pre-created the table TBLS and couple of other datanucleus tables (SEQUENCE_TABLE &amp;amp; NUCLEUS_TABLES) and let the server automatically create the other missing tables. If required, I can attach the patch for the SQL script I used for Oracle.&lt;/p&gt;</comment>
                            <comment id="13604835" author="navis" created="Mon, 18 Mar 2013 01:51:42 +0000"  >&lt;p&gt;Is there any progress on this? With hiveserver2, I&apos;ve seen 100% CPU problem (seemed to be &lt;a href=&quot;http://www.datanucleus.org/servlet/jira/browse/NUCCORE-559&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.datanucleus.org/servlet/jira/browse/NUCCORE-559&lt;/a&gt;) more frequently. &lt;/p&gt;</comment>
                            <comment id="13699318" author="ashutoshc" created="Wed, 3 Jul 2013 18:55:29 +0000"  >&lt;p&gt;Yeah.. I think we need to move forward on this. Based on Deepesh&apos;s comments and Ning&apos;s comment earlier in thread, it seems like we need to provide an upgrade script for folks who already have their metastore created with 2.x version of DN. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; wondering if you have done some investigation on that ?&lt;/p&gt;</comment>
                            <comment id="13699625" author="navis" created="Thu, 4 Jul 2013 00:18:52 +0000"  >&lt;p&gt;We&apos;ve just upgraded datanucleus with a small step in two months ago and nothing bad happened till now.&lt;/p&gt;

&lt;p&gt;datanucleus-connectionpool-2.0.3.jar&lt;br/&gt;
datanucleus-core-2.2.3.jar&lt;br/&gt;
datanucleus-enhancer-2.1.3.jar&lt;br/&gt;
datanucleus-rdbms-2.2.3.jar&lt;/p&gt;

&lt;p&gt;Datanucleus seemed too hard for me to investigate.&lt;/p&gt;</comment>
                            <comment id="13713294" author="appodictic" created="Fri, 19 Jul 2013 03:03:00 +0000"  >&lt;p&gt;The metastore upgrades are not my favourite part of hive. Our metastore is a fairly large database in the 20GB. The upgrade scripts cause rather long read-only periods which make our applications very sad. I realize that we have to do them from time to time but they really are a bother.&lt;/p&gt;</comment>
                            <comment id="13713303" author="appodictic" created="Fri, 19 Jul 2013 03:31:20 +0000"  >&lt;p&gt;I am actually under the option we should branch DN or switch to hibernate. I find it unbelievable that an object mapping framework is not compatible with itself between versions. What if you have large databases that can not accept downtime? &lt;/p&gt;</comment>
                            <comment id="13713319" author="xuefuz" created="Fri, 19 Jul 2013 04:08:48 +0000"  >&lt;p&gt;I&apos;m actually working on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3632&quot; title=&quot;Upgrade datanucleus to support JDK7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3632&quot;&gt;&lt;del&gt;HIVE-3632&lt;/del&gt;&lt;/a&gt;, which is similar to this, yet having a different motivation. I&apos;m yet to be convinced that a DB upgrade is required, and even if so, it seems unrelated to DN upgrade (but rather out of a bug in the metastore schema definition). That is yet to be seen, as review goes on for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3632&quot; title=&quot;Upgrade datanucleus to support JDK7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3632&quot;&gt;&lt;del&gt;HIVE-3632&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As far as Hibernate is concerned, I think it was excluded at very beginning due to incompatible license.&lt;/p&gt;</comment>
                            <comment id="13714085" author="sershe" created="Fri, 19 Jul 2013 21:15:12 +0000"  >&lt;p&gt;As far as I saw from DN 2 and DN 3 databases, the schema upgrade might indeed be required. However, we do want to upgrade occasionally... DN 3 fixes a number of visible and less-visible bugs, so it will allow us to improve metastore in more ways.&lt;/p&gt;</comment>
                            <comment id="13720890" author="ashutoshc" created="Fri, 26 Jul 2013 15:36:44 +0000"  >&lt;p&gt;This has been fixed via &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3632&quot; title=&quot;Upgrade datanucleus to support JDK7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3632&quot;&gt;&lt;del&gt;HIVE-3632&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13796013" author="ashutoshc" created="Tue, 15 Oct 2013 23:30:21 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12500610">HIVE-2029</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12500017">HIVE-2015</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12525383">HIVE-2473</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12658681">HIVE-4888</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12613843">HIVE-3632</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12609073">GIRAPH-343</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12532680">HIVE-2609</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12519148" name="ASF.LICENSE.NOT.GRANTED--HIVE-2084.D2397.1.patch" size="4988" author="phabricator@reviews.facebook.net" created="Tue, 20 Mar 2012 23:13:41 +0000"/>
                            <attachment id="12497097" name="HIVE-2084.1.patch.txt" size="3283" author="cwsteinbach" created="Fri, 30 Sep 2011 00:31:16 +0000"/>
                            <attachment id="12519061" name="HIVE-2084.2.patch.txt" size="5368" author="sushanth" created="Tue, 20 Mar 2012 11:16:19 +0000"/>
                            <attachment id="12546594" name="HIVE-2084.D5685.1.patch" size="6092" author="phabricator@reviews.facebook.net" created="Tue, 25 Sep 2012 21:58:07 +0000"/>
                            <attachment id="12475063" name="HIVE-2084.patch" size="5642" author="nzhang" created="Thu, 31 Mar 2011 06:24:20 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 31 Mar 2011 17:33:40 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3299</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08ni7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>48407</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-2085] Document GenericUD(A|T)F</title>
                <link>https://issues.apache.org/jira/browse/HIVE-2085</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;GenericUDFs are very poorly documented, this includes everything they relate to:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;ObjectInspector (JavaDoc not really helpful for someone not familiar with Hive)&lt;/li&gt;
	&lt;li&gt;ObjectInspectorFactory&lt;/li&gt;
	&lt;li&gt;ObjectInspectorConverters&lt;/li&gt;
	&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;An example would help as well as a unit test for one of the built in GenericUDFs. Writing a normal UDF is pretty well documented but GenericUDFs (and UDTF/UDAF) require more knowledge about the inner workings of Hive and that could be documented better.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12502854">HIVE-2085</key>
            <summary>Document GenericUD(A|T)F</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="4" iconUrl="https://issues.apache.org/jira/images/icons/statuses/reopened.png" description="This issue was once resolved, but the resolution was deemed incorrect. From here issues are either marked assigned or resolved.">Reopened</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="lars_francke">Lars Francke</reporter>
                        <labels>
                    </labels>
                <created>Wed, 30 Mar 2011 09:30:16 +0000</created>
                <updated>Wed, 30 Mar 2011 20:29:48 +0000</updated>
                                                                            <component>Documentation</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13012992" author="appodictic" created="Wed, 30 Mar 2011 14:45:34 +0000"  >&lt;p&gt;What are you saying? Do you want more Java Doc? Hive currently uses a wiki that all our free to edit. I do not think we should be opening up Jira&apos;s for documentation. Hive already has enough issues assigned to no one, to be completed never.&lt;/p&gt;</comment>
                            <comment id="13012997" author="lars_francke" created="Wed, 30 Mar 2011 14:54:20 +0000"  >&lt;p&gt;What&apos;s the &quot;Documentation&quot; component for then?&lt;/p&gt;

&lt;p&gt;The Wiki is nice but it&apos;s currently not a very good source of information beyond the very basic things. It is also not complete and I guess probably not up-to-date either on every page.&lt;/p&gt;

&lt;p&gt;The nature of this issue also requires someone with more knowledge about Hive to take a look it at than a regular user. So I think it&apos;s a bad idea closing this issue just because there are other unassigned issues. This is an issue tracker after all.&lt;/p&gt;</comment>
                            <comment id="13013021" author="appodictic" created="Wed, 30 Mar 2011 15:31:29 +0000"  >&lt;p&gt;Lars&lt;br/&gt;
I understand that no one likes to see issues closed as &quot;WONT FIX&quot; (I am not trying to be snotty). Hive currently has hundreds of Open Issues. Opening an issue like &quot;Document X&quot; is vague. You are correct in saying this is an issue tracker, but it is quite common to first come on the IRC or ML and discuss the feature you want. &lt;/p&gt;

&lt;p&gt;IMHO. What this boils down to is if the developers had more time to document they would. If we had to open an issue for each thing that needed more documentation Jira would be unusable (Many things need documentation).&lt;br/&gt;
Generally, if the user submitting the request is not willing to assign it to themselves there is little chance of it getting done by anyone else (as evidenced by the number of opened unassigned tickets).  These issues should be actionable in the near term. If no one is going to actively work on the issue we do not get anything from having a ticket open on it.&lt;/p&gt;
</comment>
                            <comment id="13013026" author="lars_francke" created="Wed, 30 Mar 2011 15:45:20 +0000"  >&lt;p&gt;I tried to add details about what and why should be documented so I had hoped it wouldn&apos;t be vague. Let me know what needs clarifying and I&apos;ll gladly do it.&lt;/p&gt;

&lt;p&gt;I&apos;ve been on IRC and the mailing list and we&apos;ve asked questions about these things and tried to figure it out on our own that&apos;s why I decided to open the ticket.&lt;/p&gt;

&lt;p&gt;I didn&apos;t assign the issue to myself because I don&apos;t feel like I have any idea about what&apos;s going on there. And I also don&apos;t agree on the value of open and unassigned tickets. It gives an overview of what needs to be done still and perhaps one of these days someone&apos;s going to focus on documentation and I think it would be helpful then to know what&apos;s missing.&lt;/p&gt;

&lt;p&gt;But I&apos;ll leave this issue alone now to not take any more time. Thanks for looking at it anyway. One of your GenericUDFs can be found on Google and that&apos;s about the only documentation/example I could find so you&apos;ve already helped &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13013545" author="patrickangeles" created="Wed, 30 Mar 2011 17:04:28 +0000"  >&lt;p&gt;FWIW, +1 on better documentation, particularly on extension points like UD*Fs, SerDes and StorageHandlers. These are things that are worth taking on up front because it increases user engagement and adoption and reduces the burden of support/education on core committers in the long term.&lt;/p&gt;</comment>
                            <comment id="13013549" author="appodictic" created="Wed, 30 Mar 2011 17:11:14 +0000"  >&lt;p&gt;The best way to currently learn about these features is to look through the unit tests, code, and .q files. There other UDFs like atan easy to follow. There is a UDFT for example that splits a URL into parts. Looking at the split() or case() UDF&apos;s give you an idea of some of the more complex things that can be done. Looking at struct() or list() udfs shows you a lot about how to use object inspectors to detect and return different types. If you want to come on IRC I can help with specific questions.&lt;/p&gt;</comment>
                            <comment id="13013553" author="hammer" created="Wed, 30 Mar 2011 17:33:17 +0000"  >&lt;p&gt;It&apos;s ridiculous to close an issue as &quot;Won&apos;t Fix&quot; that many people think should be fixed.&lt;/p&gt;</comment>
                            <comment id="13013631" author="appodictic" created="Wed, 30 Mar 2011 20:29:48 +0000"  >&lt;p&gt;I do not care that much. I just dislike seeing things stay open forever that no one is going to work on.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-29&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-29&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 30 Mar 2011 14:45:34 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42280</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 43 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08owf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>48633</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-2086] Add test coverage for external table data loss issue</title>
                <link>https://issues.apache.org/jira/browse/HIVE-2086</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Data loss when using &quot;create external table like&quot; statement. &lt;/p&gt;

&lt;p&gt;1) Set up an external table S, point to location L. Populate data in S.&lt;br/&gt;
2) Create another external table T, using statement like this:&lt;br/&gt;
    create external table T like S location L&lt;br/&gt;
   Make sure table T point to the same location as the original table S.&lt;br/&gt;
3) Query table T, see the same set of data in S.&lt;br/&gt;
4) drop table T.&lt;br/&gt;
5) Query table S will return nothing, and location L is deleted. &lt;/p&gt;</description>
                <environment>&lt;p&gt;Amazon  elastics mapreduce cluster&lt;/p&gt;</environment>
        <key id="12503051">HIVE-2086</key>
            <summary>Add test coverage for external table data loss issue</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="natty">Jonathan Natkins</assignee>
                                    <reporter username="qlong">Q Long</reporter>
                        <labels>
                    </labels>
                <created>Thu, 31 Mar 2011 18:05:43 +0000</created>
                <updated>Fri, 16 Dec 2011 23:57:00 +0000</updated>
                            <resolved>Thu, 21 Jul 2011 19:32:02 +0000</resolved>
                                    <version>0.7.0</version>
                                    <fixVersion>0.8.0</fixVersion>
                                    <component>Metastore</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13014109" author="appodictic" created="Thu, 31 Mar 2011 18:11:38 +0000"  >&lt;p&gt;Dropping an external table should not delete data. Are you saying that &apos;create table like&apos; does not preserver the external property?&lt;/p&gt;</comment>
                            <comment id="13014126" author="qlong" created="Thu, 31 Mar 2011 18:28:46 +0000"  >&lt;p&gt;It seems that &quot;create external table like&quot;  does not preserve the external property.  &lt;/p&gt;

&lt;p&gt;Note that both the original table S and the new table T are external, and data loss will only occur when creating T using statement&lt;br/&gt;
&quot;create external table T like S location L&quot;.  No data loss if T with full table definitions (i.e, does not use like statement)&lt;/p&gt;
</comment>
                            <comment id="13020157" author="natty" created="Fri, 15 Apr 2011 01:34:59 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/604/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/604/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13020158" author="jiraposter@reviews.apache.org" created="Fri, 15 Apr 2011 01:35:05 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/604/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/604/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for hive.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Review request for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2086&quot; title=&quot;Add test coverage for external table data loss issue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2086&quot;&gt;&lt;del&gt;HIVE-2086&lt;/del&gt;&lt;/a&gt;.  The external parameters were being set, but then being zeroed out by a call to params.clear(), resulting in an external table that wasn&apos;t marked as external.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2086&quot; title=&quot;Add test coverage for external table data loss issue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2086&quot;&gt;&lt;del&gt;HIVE-2086&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2086&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2086&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  build-common.xml 9f21a69 &lt;br/&gt;
  data/files/ext_test/test.dat PRE-CREATION &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 9d8919c &lt;br/&gt;
  ql/src/test/queries/clientpositive/create_like.q 2edde83 &lt;br/&gt;
  ql/src/test/results/clientpositive/create_like.q.out 63a8939 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/604/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/604/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Automated tests added&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Jonathan&lt;/p&gt;
</comment>
                            <comment id="13022268" author="jiraposter@reviews.apache.org" created="Wed, 20 Apr 2011 18:19:05 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/604/#review507&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/604/#review507&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;



&lt;p&gt;ql/src/test/queries/clientpositive/create_like.q&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/604/#comment1031&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/604/#comment1031&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    the $var is cool!&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Ning&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;On 2011-04-15 01:34:56, Jonathan Natkins wrote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This is an automatically generated e-mail. To reply, visit:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/604/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/604/&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;(Updated 2011-04-15 01:34:56)&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Review request for hive.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Summary&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Review request for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2086&quot; title=&quot;Add test coverage for external table data loss issue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2086&quot;&gt;&lt;del&gt;HIVE-2086&lt;/del&gt;&lt;/a&gt;.  The external parameters were being set, but then being zeroed out by a call to params.clear(), resulting in an external table that wasn&apos;t marked as external.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2086&quot; title=&quot;Add test coverage for external table data loss issue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2086&quot;&gt;&lt;del&gt;HIVE-2086&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2086&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2086&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diffs&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;build-common.xml 9f21a69 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;data/files/ext_test/test.dat PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 9d8919c &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;ql/src/test/queries/clientpositive/create_like.q 2edde83 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;ql/src/test/results/clientpositive/create_like.q.out 63a8939 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/604/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/604/diff&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Testing&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Automated tests added&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Jonathan&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
</comment>
                            <comment id="13022269" author="jiraposter@reviews.apache.org" created="Wed, 20 Apr 2011 18:19:06 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/604/#review508&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/604/#review508&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Ship it!&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Ning&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;On 2011-04-15 01:34:56, Jonathan Natkins wrote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This is an automatically generated e-mail. To reply, visit:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/604/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/604/&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;(Updated 2011-04-15 01:34:56)&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Review request for hive.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Summary&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Review request for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2086&quot; title=&quot;Add test coverage for external table data loss issue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2086&quot;&gt;&lt;del&gt;HIVE-2086&lt;/del&gt;&lt;/a&gt;.  The external parameters were being set, but then being zeroed out by a call to params.clear(), resulting in an external table that wasn&apos;t marked as external.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2086&quot; title=&quot;Add test coverage for external table data loss issue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2086&quot;&gt;&lt;del&gt;HIVE-2086&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2086&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2086&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diffs&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;build-common.xml 9f21a69 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;data/files/ext_test/test.dat PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 9d8919c &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;ql/src/test/queries/clientpositive/create_like.q 2edde83 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;ql/src/test/results/clientpositive/create_like.q.out 63a8939 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/604/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/604/diff&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Testing&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Automated tests added&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Jonathan&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
</comment>
                            <comment id="13022270" author="nzhang" created="Wed, 20 Apr 2011 18:20:35 +0000"  >&lt;p&gt;+1. Will commit if tests pass. &lt;/p&gt;</comment>
                            <comment id="13022615" author="nzhang" created="Thu, 21 Apr 2011 05:10:59 +0000"  >&lt;p&gt;Jonathan, there are a few diffs in the unit tests (1 in TestHBaseCliDriver and 6 in TestCliDriver). Can you take a look?&lt;/p&gt;</comment>
                            <comment id="13025862" author="natty" created="Wed, 27 Apr 2011 16:02:01 +0000"  >&lt;p&gt;Sorry about that, I&apos;ve updated the diffs.  This time, there shouldn&apos;t be any failures&lt;/p&gt;</comment>
                            <comment id="13025863" author="jiraposter@reviews.apache.org" created="Wed, 27 Apr 2011 16:02:03 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/604/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/604/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2011-04-27 16:00:50.150750)&lt;/p&gt;


&lt;p&gt;Review request for hive.&lt;/p&gt;


&lt;p&gt;Changes&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Fixing test diffs&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Review request for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2086&quot; title=&quot;Add test coverage for external table data loss issue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2086&quot;&gt;&lt;del&gt;HIVE-2086&lt;/del&gt;&lt;/a&gt;.  The external parameters were being set, but then being zeroed out by a call to params.clear(), resulting in an external table that wasn&apos;t marked as external.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2086&quot; title=&quot;Add test coverage for external table data loss issue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2086&quot;&gt;&lt;del&gt;HIVE-2086&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2086&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2086&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  build-common.xml 00c3680 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 22fde53 &lt;br/&gt;
  ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java 06a0447 &lt;br/&gt;
  ql/src/test/queries/clientpositive/create_like.q 2edde83 &lt;br/&gt;
  ql/src/test/results/clientpositive/create_like.q.out 63a8939 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/604/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/604/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Automated tests added&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Jonathan&lt;/p&gt;
</comment>
                            <comment id="13027424" author="nzhang" created="Sun, 1 May 2011 04:37:39 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13027736" author="nzhang" created="Mon, 2 May 2011 17:26:23 +0000"  >&lt;p&gt;@Johnathan, there are some tests failing. In particular the newly added test also failed (the output attached). Can you take a look and see if it is caused by newly committed patches (I&apos;ve tested on the lasted trunk). &lt;/p&gt;</comment>
                            <comment id="13054550" author="vaggarw" created="Fri, 24 Jun 2011 17:03:31 +0000"  >&lt;p&gt;Has this patch been committed or is anyone still working on this particular patch?&lt;/p&gt;</comment>
                            <comment id="13067522" author="natty" created="Tue, 19 Jul 2011 05:55:08 +0000"  >&lt;p&gt;It looks like this was actually just fixed today, as a part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1218&quot; title=&quot;CREATE TABLE t LIKE some_view should create a new empty base table, but instead creates a copy of view&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1218&quot;&gt;&lt;del&gt;HIVE-1218&lt;/del&gt;&lt;/a&gt;.  However, that fix didn&apos;t add any regression tests for this bug, so I&apos;m going to prepare an updated patch once I finish running the test suite.&lt;/p&gt;</comment>
                            <comment id="13067833" author="jiraposter@reviews.apache.org" created="Tue, 19 Jul 2011 16:50:58 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/604/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/604/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2011-07-19 16:50:07.742470)&lt;/p&gt;


&lt;p&gt;Review request for hive.&lt;/p&gt;


&lt;p&gt;Changes&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;The bug was fixed as a part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1218&quot; title=&quot;CREATE TABLE t LIKE some_view should create a new empty base table, but instead creates a copy of view&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1218&quot;&gt;&lt;del&gt;HIVE-1218&lt;/del&gt;&lt;/a&gt;, and this diff adds some regression tests for this particular issue.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Review request for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2086&quot; title=&quot;Add test coverage for external table data loss issue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2086&quot;&gt;&lt;del&gt;HIVE-2086&lt;/del&gt;&lt;/a&gt;.  The external parameters were being set, but then being zeroed out by a call to params.clear(), resulting in an external table that wasn&apos;t marked as external.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2086&quot; title=&quot;Add test coverage for external table data loss issue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2086&quot;&gt;&lt;del&gt;HIVE-2086&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2086&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2086&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  build-common.xml b6807fa &lt;br/&gt;
  data/files/ext_test/test.dat PRE-CREATION &lt;br/&gt;
  ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java 6d742e5 &lt;br/&gt;
  ql/src/test/queries/clientpositive/create_like.q 3f8e58d &lt;br/&gt;
  ql/src/test/results/clientpositive/create_like.q.out 118235e &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/604/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/604/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Automated tests added&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Jonathan&lt;/p&gt;
</comment>
                            <comment id="13067835" author="natty" created="Tue, 19 Jul 2011 16:51:34 +0000"  >&lt;p&gt;Just regression tests&lt;/p&gt;</comment>
                            <comment id="13068007" author="cwsteinbach" created="Tue, 19 Jul 2011 21:55:23 +0000"  >&lt;p&gt;+1. Will commit if tests pass.&lt;/p&gt;</comment>
                            <comment id="13069148" author="cwsteinbach" created="Thu, 21 Jul 2011 19:32:02 +0000"  >&lt;p&gt;Committed to trunk. Thanks Natty!&lt;/p&gt;</comment>
                            <comment id="13069164" author="hudson" created="Thu, 21 Jul 2011 19:53:37 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #841 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/841/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/841/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2086&quot; title=&quot;Add test coverage for external table data loss issue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2086&quot;&gt;&lt;del&gt;HIVE-2086&lt;/del&gt;&lt;/a&gt;. Add test coverage for external table data loss issue (Jonathan Natkins via cws)&lt;/p&gt;

&lt;p&gt;cws : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1149331&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1149331&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/data/files/ext_test&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/create_like.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/create_like.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/data/files/ext_test/test.dat&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/build-common.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12458597">HIVE-1218</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12476404" name="HIVE-2086.1.patch" size="18045" author="natty" created="Fri, 15 Apr 2011 01:35:10 +0000"/>
                            <attachment id="12477560" name="HIVE-2086.2.patch" size="17817" author="natty" created="Wed, 27 Apr 2011 16:02:17 +0000"/>
                            <attachment id="12487028" name="HIVE-2086.3.patch" size="14277" author="natty" created="Tue, 19 Jul 2011 16:52:19 +0000"/>
                            <attachment id="12477972" name="create_like.q.out" size="13926" author="nzhang" created="Mon, 2 May 2011 17:26:23 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 31 Mar 2011 18:11:38 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>67231</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 27 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lid3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123625</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>data loss external table create like</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-2087] Dynamic partition insert performance problem</title>
                <link>https://issues.apache.org/jira/browse/HIVE-2087</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Create an external(backed by S3) table T, make it partitioned by column P. Populate table T so it has large number of partitions (say 100). Execute statement like&lt;/p&gt;

&lt;p&gt;insert overwrite table T partition (p) select * from another_table&lt;/p&gt;

&lt;p&gt;check hive server log, and it will show that all existing partitions will be read and loaded before any mapper starts working. This feels excessive, given that the insert statement may only create or overwrite a very small number of partitions. Is there other reason that insert using dynamic partition requires loading the whole table?&lt;/p&gt;
</description>
                <environment>&lt;p&gt;Amazon EMR, S3&lt;/p&gt;</environment>
        <key id="12503057">HIVE-2087</key>
            <summary>Dynamic partition insert performance problem</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="qlong">Q Long</reporter>
                        <labels>
                    </labels>
                <created>Thu, 31 Mar 2011 18:22:12 +0000</created>
                <updated>Mon, 9 May 2011 18:04:12 +0000</updated>
                                            <version>0.7.0</version>
                                                    <component>Metastore</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13030836" author="slider" created="Mon, 9 May 2011 18:04:12 +0000"  >&lt;p&gt;This problem seems to happen only when there is no static partition column.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 9 May 2011 18:04:12 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42279</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 38 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lidb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123626</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>dynamic partition peformace</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-2088] Improve Hive Query split calculation performance over large partitions (potentially 5x speedup)</title>
                <link>https://issues.apache.org/jira/browse/HIVE-2088</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;While working on improving start up time for query spanning over large number of partitions I found a particular inefficiency in CombineHiveInputFormat.&lt;/p&gt;

&lt;p&gt;It seems that for each input partition we create a CombineFilter to make sure that files are combined within a particular partition.&lt;/p&gt;

&lt;p&gt;CombineHiveInputFormat:&lt;/p&gt;

&lt;p&gt;  Path filterPath = path;&lt;br/&gt;
  if (!poolSet.contains(filterPath)) &lt;/p&gt;
{
        LOG.info(&quot;CombineHiveInputSplit creating pool for &quot; + path +
            &quot;; using filter path &quot; + filterPath);
        combine.createPool(job, new CombineFilter(filterPath));
        poolSet.add(filterPath);
  }

&lt;p&gt;These filters are passed then passed to CombineFileInputFormat along with all the input paths.&lt;br/&gt;
CombineFileInputFormat computes a list of all the files in the input paths.&lt;br/&gt;
It them loops over each filter and then checks whether a particular file belongs to a particular filter.&lt;/p&gt;

&lt;p&gt;ConbineFileInputFormat:&lt;/p&gt;

&lt;p&gt;for (MultiPathFilter onepool : pools) {&lt;br/&gt;
      ArrayList&amp;lt;Path&amp;gt; myPaths = new ArrayList&amp;lt;Path&amp;gt;();&lt;/p&gt;

&lt;p&gt;      // pick one input path. If it matches all the filters in a pool,&lt;br/&gt;
      // add it to the output set&lt;br/&gt;
      for (int i = 0; i &amp;lt; paths.length; i++) {&lt;br/&gt;
      ...&lt;/p&gt;

&lt;p&gt;This results in computation of the order O(p*f) where p is the number of partitions and f is the total number of files in all partitions.&lt;br/&gt;
For a case of 10,000 partitions with 10 files in each partition, this results in 1,000,000,000 iterations.&lt;/p&gt;

&lt;p&gt;We can replace this code with processing splits for one input path at a time without passing any filters at all.&lt;/p&gt;

&lt;p&gt;Do you happen to see a case where this approach will not work?&lt;/p&gt;</description>
                <environment></environment>
        <key id="12503085">HIVE-2088</key>
            <summary>Improve Hive Query split calculation performance over large partitions (potentially 5x speedup)</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="vaggarw">Vaibhav Aggarwal</assignee>
                                    <reporter username="vaggarw">Vaibhav Aggarwal</reporter>
                        <labels>
                    </labels>
                <created>Fri, 1 Apr 2011 01:18:33 +0000</created>
                <updated>Mon, 24 Oct 2011 18:35:47 +0000</updated>
                            <resolved>Mon, 24 Oct 2011 18:35:47 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13133720" author="ashutoshc" created="Sun, 23 Oct 2011 20:01:58 +0000"  >&lt;p&gt;@Vaibhav,&lt;br/&gt;
Looks like this could be a very useful thing if we can make it work. If you got a chance to experiment with this, it will be good to post your observations here.&lt;/p&gt;</comment>
                            <comment id="13134337" author="vaggarw" created="Mon, 24 Oct 2011 18:35:36 +0000"  >&lt;p&gt;Actually this was fixed as a part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2299&quot; title=&quot;Optimize Hive query startup time for multiple partitions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2299&quot;&gt;&lt;del&gt;HIVE-2299&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
I think I can resolve this issue.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 23 Oct 2011 20:01:58 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42278</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 14 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lidj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123627</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-2089] Add a new input format to be able to combine multiple .gz text files</title>
                <link>https://issues.apache.org/jira/browse/HIVE-2089</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;For files that is not splittable, CombineHiveInputFormat won&apos;t help. This jira is to add a new inputformat to support this feature. This is very useful for partitions with tens of thousands of .gz files.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12503358">HIVE-2089</key>
            <summary>Add a new input format to be able to combine multiple .gz text files</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="he yongqiang">He Yongqiang</reporter>
                        <labels>
                    </labels>
                <created>Tue, 5 Apr 2011 00:09:00 +0000</created>
                <updated>Fri, 27 Jun 2014 17:25:34 +0000</updated>
                            <resolved>Fri, 27 Jun 2014 17:25:34 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13015706" author="he yongqiang" created="Tue, 5 Apr 2011 01:19:27 +0000"  >&lt;p&gt;Actually just found that the recent hadoop&apos;s combineFileInputFormat support not splittable files as input. So it won&apos;t be a problem for .gz files if the hadoop has the feature checked in.&lt;/p&gt;

&lt;p&gt;Another use case for it is Hive&apos;s SymlinkInputFormat, which may point to too many .gz files.&lt;/p&gt;</comment>
                            <comment id="13465788" author="slider" created="Fri, 28 Sep 2012 17:56:36 +0000"  >&lt;p&gt;I think Yongquiang was referring to &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-1597&quot; title=&quot;combinefileinputformat does not work with non-splittable files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-1597&quot;&gt;&lt;del&gt;MAPREDUCE-1597&lt;/del&gt;&lt;/a&gt; in his comment. If you have &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-1597&quot; title=&quot;combinefileinputformat does not work with non-splittable files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-1597&quot;&gt;&lt;del&gt;MAPREDUCE-1597&lt;/del&gt;&lt;/a&gt; and set hive.hadoop.supports.splittable.combineinputformat=true, you don&apos;t need &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2089&quot; title=&quot;Add a new input format to be able to combine multiple .gz text files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2089&quot;&gt;&lt;del&gt;HIVE-2089&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14046170" author="ksumit" created="Fri, 27 Jun 2014 17:25:34 +0000"  >&lt;p&gt;I verified &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=slider&quot; class=&quot;user-hover&quot; rel=&quot;slider&quot;&gt;Steven K. Wong&lt;/a&gt;&apos;s observation. It indeed works. Marking this JIRA as &quot;Won&apos;t Fix&quot;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310051">
                    <name>Supercedes</name>
                                                                <inwardlinks description="is superceded by">
                                        <issuelink>
            <issuekey id="12458980">MAPREDUCE-1597</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12475448" name="HIVE-2089.1.patch" size="46181" author="he yongqiang" created="Tue, 5 Apr 2011 01:19:50 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 28 Sep 2012 17:56:36 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42277</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 30 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lidr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123628</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-2090] Add &quot;DROP DATABASE ... CASCADE/RESTRICT&quot;</title>
                <link>https://issues.apache.org/jira/browse/HIVE-2090</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;A &quot;DROP DATABASE ... FORCE&quot; will be useful, when we use a database for isolation when doing some tests. Being able to force cleaning up the database will make test cleaning up easier.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12503359">HIVE-2090</key>
            <summary>Add &quot;DROP DATABASE ... CASCADE/RESTRICT&quot;</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sdong">Siying Dong</assignee>
                                    <reporter username="sdong">Siying Dong</reporter>
                        <labels>
                    </labels>
                <created>Tue, 5 Apr 2011 00:58:54 +0000</created>
                <updated>Fri, 9 Feb 2018 16:41:29 +0000</updated>
                            <resolved>Mon, 25 Apr 2011 07:52:47 +0000</resolved>
                                                    <fixVersion>0.8.0</fixVersion>
                                    <component>Metastore</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13015717" author="cwsteinbach" created="Tue, 5 Apr 2011 01:56:33 +0000"  >&lt;p&gt;It doesn&apos;t seem valid to extend the semantics of HiveQL simply to support a use case motivated by Hive&apos;s testing infrastructure.&lt;/p&gt;

&lt;p&gt;Also, from a user perspective, how do you plan to explain the difference between &quot;DROP DATABASE x&quot; and &quot;DROP DATABASE x FORCE&quot;? Should I use the former if I&apos;m not really serious about dropping the database?&lt;/p&gt;</comment>
                            <comment id="13015724" author="sdong" created="Tue, 5 Apr 2011 02:08:46 +0000"  >&lt;p&gt;Carl, it&apos;s just like there is &quot;rm&quot; and there is &quot;rm -r&quot;. It&apos;s not for supporting Hive&apos;s testing. It&apos;s to support testing applications that built on top of Hive. Imagine you have a daily ETL query that does some transformation from one table to another. It is natural to create a test database and do all the tests there. In the end, it will be simpler to just  run a query to clean whatever on the database.&lt;/p&gt;</comment>
                            <comment id="13015730" author="cwsteinbach" created="Tue, 5 Apr 2011 02:37:08 +0000"  >&lt;p&gt;Is the purpose of this ticket to make &quot;DROP DATABASE x FORCE&quot; behave like the ANSI version of &quot;DROP DATABASE x&quot;, e.g. delete x along with any tables in x? As I recall the reason that DROP DATABASE does not currently adhere to ANSI semantics is that we were worried about providing in the absence of a working authorization system. Now that the authorization system exists, it seems like &quot;DROP DATABASE x FORCE&quot; should be the default behavior, and the current behavior should be something that you can enable via a configuration parameter, e.g. hive.exec.drop.ignorenonempty=false.&lt;/p&gt;

&lt;p&gt;Also, I the change to DDLTask.dropDatabase() introduces concurrency problems since you&apos;re not operating in a transaction.&lt;/p&gt;</comment>
                            <comment id="13015736" author="sdong" created="Tue, 5 Apr 2011 03:19:50 +0000"  >&lt;p&gt;Looks like &quot;drop database&quot; have concurrency problem today too if another concurrent query creates table on the database, since it acquires no lock. Don&apos;t know how to resolve it. But to this patch, at least I can acquire locks to all tables on the database. It doesn&apos;t resolve today&apos;s concurrency problem though.&lt;/p&gt;</comment>
                            <comment id="13015759" author="jvs" created="Tue, 5 Apr 2011 05:06:09 +0000"  >&lt;p&gt;ANSI standard is DROP SCHEMA CASCADE/RESTRICT (with default RESTRICT).&lt;/p&gt;

&lt;p&gt;Carl, I think you&apos;re referring to MySQL DROP DATABASE, which blows everything away.&lt;/p&gt;</comment>
                            <comment id="13015765" author="cwsteinbach" created="Tue, 5 Apr 2011 05:27:59 +0000"  >&lt;p&gt;@John: You&apos;re right, my mistake. Do people think we should do it the MySQL way or follow the ANSI standard. I&apos;m fine either way.&lt;/p&gt;</comment>
                            <comment id="13016059" author="jvs" created="Tue, 5 Apr 2011 18:16:37 +0000"  >&lt;p&gt;I&apos;d say go with default RESTRICT for safety.&lt;/p&gt;</comment>
                            <comment id="13016116" author="sdong" created="Tue, 5 Apr 2011 20:59:53 +0000"  >&lt;p&gt;This is an in-progress patch. It fixed the syntax to &quot;CASCADE/RESTRICT&quot; instead of &quot;FORCE&quot;. While we had some discussion offline and decided to do the logic in object store level, so I need to make some more changes. We&apos;ll open other issues for fixing concurrency and authorization around dropping and creating databases.&lt;/p&gt;</comment>
                            <comment id="13016200" author="he yongqiang" created="Wed, 6 Apr 2011 00:30:21 +0000"  >&lt;p&gt;can you add authorization check for drop database in this jira?&lt;/p&gt;</comment>
                            <comment id="13016203" author="sdong" created="Wed, 6 Apr 2011 00:41:51 +0000"  >&lt;p&gt;Moved the logic of dropping tables to ObjectStore level. The concurrency bug will be handled in separate JIRAs, &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; title=&quot;create/drop database should populate inputs/outputs and check concurrency and user permission&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2093&quot;&gt;&lt;del&gt;HIVE-2093&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2094&quot; title=&quot;CREATE and DROP DATABASE doesn&amp;#39;t check user permission for doing it&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2094&quot;&gt;HIVE-2094&lt;/a&gt;. &lt;/p&gt;</comment>
                            <comment id="13016204" author="sdong" created="Wed, 6 Apr 2011 00:43:51 +0000"  >&lt;p&gt;Yongqiang, adding authorization check for dropping and creating databases can take more efforts then this. I&apos;ll see whether it is easy to finish it in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; title=&quot;create/drop database should populate inputs/outputs and check concurrency and user permission&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2093&quot;&gt;&lt;del&gt;HIVE-2093&lt;/del&gt;&lt;/a&gt; together with concurrency check. It doesn&apos;t sound belonging to this JIRA.&lt;/p&gt;</comment>
                            <comment id="13016205" author="jiraposter@reviews.apache.org" created="Wed, 6 Apr 2011 01:01:14 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/551/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for hive.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12475548/HIVE-2090.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12475548/HIVE-2090.3.patch&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2090&quot; title=&quot;Add &amp;quot;DROP DATABASE ... CASCADE/RESTRICT&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2090&quot;&gt;&lt;del&gt;HIVE-2090&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2090&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2090&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/metastore/if/hive_metastore.thrift 1088810 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.h 1088810 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp 1088810 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore_server.skeleton.cpp 1088810 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java 1088810 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-php/hive_metastore/ThriftHiveMetastore.php 1088810 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore-remote 1088810 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore.py 1088810 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-rb/thrift_hive_metastore.rb 1088810 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1088810 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java 1088810 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/IMetaStoreClient.java 1088810 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1088810 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java 1088810 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1088810 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1088810 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/DropDatabaseDesc.java 1088810 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/database.q 1088810 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/database.q.out 1088810 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/551/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Carl&lt;/p&gt;
</comment>
                            <comment id="13016209" author="sdong" created="Wed, 6 Apr 2011 01:15:03 +0000"  >&lt;p&gt;One thing to notice. When dropping all tables on a database, all files on the warehouse root of the DB are deleted. Data from tables/partitions on locations that are not under that root won&apos;t be deleted. This is kind of similar to the current approach of dropping table &amp;#8211; data in partitions won&apos;t be deleted if their locations are not under table&apos;s locations.&lt;/p&gt;</comment>
                            <comment id="13019119" author="he yongqiang" created="Tue, 12 Apr 2011 23:53:11 +0000"  >&lt;p&gt;2 nitpick:&lt;/p&gt;

&lt;p&gt;1, do not remove the existing  constructor &quot;DropDatabaseDesc(String databaseName, boolean ifExists) {&quot;&lt;/p&gt;

&lt;p&gt;2, remove TOK_RESTRICT if it has the same meaning with TOK_CASCADE. Use just one of them.  &quot;if (null != ast.getFirstChildWithType(TOK_CASCADE))&quot; seems only checked TOK_CASCADE. &lt;/p&gt;

&lt;p&gt;3. there is no testcase?&lt;/p&gt;</comment>
                            <comment id="13019120" author="he yongqiang" created="Tue, 12 Apr 2011 23:54:03 +0000"  >&lt;p&gt;sorry, just noticed that there is one testcase. pls ignore 3.&lt;/p&gt;</comment>
                            <comment id="13019134" author="he yongqiang" created="Wed, 13 Apr 2011 00:26:11 +0000"  >&lt;p&gt;ok. got that TOK_RESTRICT has different meaning with TOK_CASCADE.&lt;/p&gt;

&lt;p&gt;will start running tests.&lt;/p&gt;</comment>
                            <comment id="13019135" author="he yongqiang" created="Wed, 13 Apr 2011 00:27:50 +0000"  >&lt;p&gt;can you just rebase?&lt;/p&gt;</comment>
                            <comment id="13019140" author="sdong" created="Wed, 13 Apr 2011 00:39:27 +0000"  >&lt;p&gt;add constructor DropdatabaseDesc(String databaseName, boolean ifExists) and rebase.&lt;/p&gt;</comment>
                            <comment id="13019147" author="jiraposter@reviews.apache.org" created="Wed, 13 Apr 2011 00:49:05 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/551/#review393&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/#review393&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;



&lt;p&gt;trunk/metastore/if/hive_metastore.thrift&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/551/#comment743&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/#comment743&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Does changing the Thrift IDL like this break backwards compatibility with older clients?&lt;/p&gt;



&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/551/#comment744&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/#comment744&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Missing &quot;@param force...&quot;&lt;/p&gt;



&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Carl&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;On 2011-04-06 01:01:26, Carl Steinbach wrote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This is an automatically generated e-mail. To reply, visit:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/551/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;(Updated 2011-04-06 01:01:26)&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Review request for hive.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Summary&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12475548/HIVE-2090.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12475548/HIVE-2090.3.patch&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2090&quot; title=&quot;Add &amp;quot;DROP DATABASE ... CASCADE/RESTRICT&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2090&quot;&gt;&lt;del&gt;HIVE-2090&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2090&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2090&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diffs&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/if/hive_metastore.thrift 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.h 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore_server.skeleton.cpp 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/gen/thrift/gen-php/hive_metastore/ThriftHiveMetastore.php 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore-remote 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore.py 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/gen/thrift/gen-rb/thrift_hive_metastore.rb 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/IMetaStoreClient.java 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/DropDatabaseDesc.java 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientpositive/database.q 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/database.q.out 1088810 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/551/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/diff&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Testing&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Carl&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
</comment>
                            <comment id="13019153" author="sdong" created="Wed, 13 Apr 2011 00:59:08 +0000"  >&lt;p&gt;add parameter description in comment of dropDatabase()&lt;/p&gt;</comment>
                            <comment id="13019158" author="jiraposter@reviews.apache.org" created="Wed, 13 Apr 2011 01:05:05 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/551/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2011-04-13 01:04:53.612739)&lt;/p&gt;


&lt;p&gt;Review request for hive.&lt;/p&gt;


&lt;p&gt;Changes&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Updating diff with &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12476195/HIVE-2090.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12476195/HIVE-2090.4.patch&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12475548/HIVE-2090.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12475548/HIVE-2090.3.patch&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2090&quot; title=&quot;Add &amp;quot;DROP DATABASE ... CASCADE/RESTRICT&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2090&quot;&gt;&lt;del&gt;HIVE-2090&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2090&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2090&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/metastore/if/hive_metastore.thrift 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.h 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore_server.skeleton.cpp 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-php/hive_metastore/ThriftHiveMetastore.php 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore-remote 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore.py 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-rb/thrift_hive_metastore.rb 1091617 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1091617 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java 1091617 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/IMetaStoreClient.java 1091617 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1091617 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java 1091617 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1091617 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1091617 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/DropDatabaseDesc.java 1091617 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/database.q 1091617 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/database.q.out 1091617 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/551/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Carl&lt;/p&gt;
</comment>
                            <comment id="13019621" author="he yongqiang" created="Thu, 14 Apr 2011 00:13:32 +0000"  >&lt;p&gt;carl, can you help review and commit this patch?&lt;/p&gt;</comment>
                            <comment id="13019622" author="jiraposter@reviews.apache.org" created="Thu, 14 Apr 2011 00:18:05 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/551/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2011-04-14 00:17:09.433334)&lt;/p&gt;


&lt;p&gt;Review request for hive.&lt;/p&gt;


&lt;p&gt;Changes&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Updating diff with &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12476199/HIVE-2090.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12476199/HIVE-2090.5.patch&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Summary (updated)&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12476199/HIVE-2090.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12476199/HIVE-2090.5.patch&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2090&quot; title=&quot;Add &amp;quot;DROP DATABASE ... CASCADE/RESTRICT&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2090&quot;&gt;&lt;del&gt;HIVE-2090&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2090&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2090&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/metastore/if/hive_metastore.thrift 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.h 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore_server.skeleton.cpp 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-php/hive_metastore/ThriftHiveMetastore.php 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore-remote 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore.py 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-rb/thrift_hive_metastore.rb 1091617 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1091617 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java 1091617 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/IMetaStoreClient.java 1091617 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1091617 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java 1091617 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1091617 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1091617 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/DropDatabaseDesc.java 1091617 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/database.q 1091617 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/database.q.out 1091617 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/551/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Carl&lt;/p&gt;
</comment>
                            <comment id="13019626" author="cwsteinbach" created="Thu, 14 Apr 2011 00:23:26 +0000"  >&lt;p&gt;@Yongqiang: Will do. I updated the diff on reviewboard and will have comments ready by tomorrow.&lt;/p&gt;

&lt;p&gt;In the meantime, can we get an answer about the concerns I raised with modifying the Thrift IDL? I think adding a parameter to drop_database() breaks backwards compatibility with older versions since Thrift doesn&apos;t support method overloading. Can anyone confirm that this is accurate?&lt;/p&gt;</comment>
                            <comment id="13019641" author="sdong" created="Thu, 14 Apr 2011 00:46:00 +0000"  >&lt;p&gt;Thrift should handle it automatically by adding a default value to missing parameter. I&apos;ll make change to make the new parameter &quot;optional&quot; anyway. I&apos;ll upload a new patch soon.&lt;/p&gt;</comment>
                            <comment id="13019644" author="cwsteinbach" created="Thu, 14 Apr 2011 00:50:20 +0000"  >&lt;p&gt;So it sounds like downversion clients can talk to upversion servers, but what about the reverse? If the client sends a message that includes the force parameter, will a downversion server simply ignore the additional parameter?&lt;/p&gt;</comment>
                            <comment id="13019647" author="sdong" created="Thu, 14 Apr 2011 01:00:28 +0000"  >&lt;p&gt;According to this doc: &lt;a href=&quot;http://diwakergupta.github.com/thrift-missing-guide/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://diwakergupta.github.com/thrift-missing-guide/&lt;/a&gt; , adding an &apos;optional&apos; keyword will solve the problem. However, when I tried to add it, it shows &apos;&lt;span class=&quot;error&quot;&gt;&amp;#91;WARNING:/data/users/sdong/www/open-source-hive3/metastore/if/hive_metastore.thrift:212&amp;#93;&lt;/span&gt; optional keyword is ignored in argument lists.&apos;. My guess is that it is automatically handled by Thrift. I&apos;ll double check with more people about it.&lt;/p&gt;</comment>
                            <comment id="13019648" author="sdong" created="Thu, 14 Apr 2011 01:01:04 +0000"  >&lt;p&gt;Shall we support the reverse? when Thrift clients have been upgraded but Thrift servers didn&apos;t?&lt;/p&gt;</comment>
                            <comment id="13019651" author="sdong" created="Thu, 14 Apr 2011 01:09:42 +0000"  >&lt;p&gt;I just checked with someone familiar with Thrift. For a higher version client calling RPC to a slower version server, the extra parameter will just be simply ignored.&lt;/p&gt;</comment>
                            <comment id="13019673" author="cwsteinbach" created="Thu, 14 Apr 2011 02:57:27 +0000"  >&lt;p&gt;@Siying: The examples in that document seem only to apply to Thrift structs. It doesn&apos;t explicitly say that this also works with parameter lists. Can you try testing out the two scenarios (downversion client/upversion server and downversion server/upversion client) and let us know if they work?&lt;/p&gt;

&lt;p&gt;The section at the end that discusses Versioning/Compatibility talks about adding extra fields to structs, so maybe if this doesn&apos;t work we should try to transition to a Thrift API where each method takes a single struct as input, and just wrap the list of input parameters in that struct.&lt;/p&gt;</comment>
                            <comment id="13020072" author="sdong" created="Thu, 14 Apr 2011 22:35:24 +0000"  >&lt;p&gt;@Carl, I just tried both compatibility cases. Both cases work. &lt;/p&gt;</comment>
                            <comment id="13020094" author="cwsteinbach" created="Thu, 14 Apr 2011 23:20:55 +0000"  >&lt;p&gt;@Siying: Have you attached the most recent version of this patch? I thought you were going to modify the IDL so that the force parameter is listed as optional and has a default value explicitly set.&lt;/p&gt;</comment>
                            <comment id="13020096" author="sdong" created="Thu, 14 Apr 2011 23:25:27 +0000"  >&lt;p&gt;@Carl, with or without the parameter, thrift generates the same codes with a warning:&lt;/p&gt;

&lt;p&gt;     &lt;span class=&quot;error&quot;&gt;&amp;#91;echo&amp;#93;&lt;/span&gt; Executing ...l/thrift/bin/thrift on metastore/if/hive_metastore.thrift&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; .../metastore/if/hive_metastore.thrift:212] optional keyword is ignored in argument lists.&lt;/p&gt;

&lt;p&gt;I guess it doesn&apos;t makes a different. You think it&apos;s better to keep the warning or keep the &apos;optional&apos; keyword?&lt;/p&gt;</comment>
                            <comment id="13020102" author="cwsteinbach" created="Thu, 14 Apr 2011 23:36:20 +0000"  >&lt;p&gt;@Siying: Please see my comments on reviewboard&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/551/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13020103" author="jiraposter@reviews.apache.org" created="Thu, 14 Apr 2011 23:37:06 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/551/#review462&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/#review462&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;



&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/551/#comment886&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/#comment886&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Doesn&apos;t look like this list is referenced anywhere. Please remove.&lt;/p&gt;



&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/551/#comment887&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/#comment887&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    The message should be &quot;restrict or cascade clause&quot;, not &quot;if force clause&quot;. You may also want to consider splitting this into two different rules so that we can output either &quot;restrict clause&quot; or &quot;cascade clause&quot;.&lt;/p&gt;



&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/DropDatabaseDesc.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/551/#comment888&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/#comment888&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Please replace instances of &quot;force&quot; with &quot;cascade&quot; in this file and everywhere else so that the code is aligned with the HQL grammar.&lt;/p&gt;



&lt;p&gt;trunk/ql/src/test/queries/clientpositive/database.q&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/551/#comment889&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/#comment889&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Please add a brief comment for each block explaining what you are testing (see earlier examples in this same test).&lt;/p&gt;



&lt;p&gt;trunk/ql/src/test/queries/clientpositive/database.q&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/551/#comment890&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/#comment890&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Please add a negative test case that attempts to drop a non-empty DB with the RESTRICT clause set. You can probably copy the HQL code in database_drop_not_empty.q&lt;/p&gt;



&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Carl&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;On 2011-04-14 00:17:09, Carl Steinbach wrote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This is an automatically generated e-mail. To reply, visit:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/551/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;(Updated 2011-04-14 00:17:09)&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Review request for hive.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Summary&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12476199/HIVE-2090.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12476199/HIVE-2090.5.patch&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2090&quot; title=&quot;Add &amp;quot;DROP DATABASE ... CASCADE/RESTRICT&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2090&quot;&gt;&lt;del&gt;HIVE-2090&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2090&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2090&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diffs&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/if/hive_metastore.thrift 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.h 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore_server.skeleton.cpp 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/gen/thrift/gen-php/hive_metastore/ThriftHiveMetastore.php 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore-remote 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore.py 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/gen/thrift/gen-rb/thrift_hive_metastore.rb 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/IMetaStoreClient.java 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/DropDatabaseDesc.java 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientpositive/database.q 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/database.q.out 1091617 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/551/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/diff&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Testing&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Carl&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
</comment>
                            <comment id="13020111" author="cwsteinbach" created="Thu, 14 Apr 2011 23:51:45 +0000"  >&lt;blockquote&gt;&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; .../metastore/if/hive_metastore.thrift:212] optional keyword is ignored in argument lists.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Looks like this was added here:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;commit 7816572784c7ddafc2c4350b221469af12d198fc
Author: Mark Slee &amp;lt;mcslee@apache.org&amp;gt;
Date:   Mon Sep 10 22:08:49 2007 +0000

Modify Thrift parser to disallow optional/required keywords in argument lists
    
Reviewed By: dreiss
    
Test Plan: Toss an optional/required in an arg list,
check that it&apos;s ignored and compiler spits a warning
    
    
git-svn-id: https:&lt;span class=&quot;code-comment&quot;&gt;//svn.apache.org/repos/asf/incubator/thrift/trunk@665255 
&lt;/span&gt;13f79535-47bb-0310-9956-ffa450edef68
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The comments seem to indicate that Thrift does not actually support optional parameters or default parameter values for optional parameters, which implies that we&apos;re depending on undocumented and unintended behavior that can change at any time. Can you please ask Mark or David about this checkin and see what they say?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
</comment>
                            <comment id="13020125" author="dreiss" created="Fri, 15 Apr 2011 00:19:00 +0000"  >&lt;p&gt;Jumping in here with minimal context.  This looks safe.  See section 5 (specifically 5.3) of the original Thrift whitepaper.  If the parameter is missing on the wire (because the client has not been updated), the server will see the default value (false in C++/Java, None/null in Python/PHP).&lt;/p&gt;

&lt;p&gt;We explicitly disallow the optional keyword in argument lists, because people thought it would allow them to continue writing drop_database(&quot;foo&quot;, true) even after updating their generated code, which is not the case.  When clients pull in this update, they will need to update their call sites.&lt;/p&gt;</comment>
                            <comment id="13020142" author="sdong" created="Fri, 15 Apr 2011 00:59:01 +0000"  >&lt;p&gt;new patch addressed Carl&apos;s comments.&lt;/p&gt;</comment>
                            <comment id="13021189" author="jiraposter@reviews.apache.org" created="Mon, 18 Apr 2011 19:31:05 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/551/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2011-04-18 19:30:43.636903)&lt;/p&gt;


&lt;p&gt;Review request for hive.&lt;/p&gt;


&lt;p&gt;Summary (updated)&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12476401/HIVE-2090.6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12476401/HIVE-2090.6.patch&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2090&quot; title=&quot;Add &amp;quot;DROP DATABASE ... CASCADE/RESTRICT&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2090&quot;&gt;&lt;del&gt;HIVE-2090&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2090&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2090&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/metastore/if/hive_metastore.thrift 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.h 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore.cpp 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-cpp/ThriftHiveMetastore_server.skeleton.cpp 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-php/hive_metastore/ThriftHiveMetastore.php 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore-remote 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-py/hive_metastore/ThriftHiveMetastore.py 1091617 &lt;br/&gt;
  trunk/metastore/src/gen/thrift/gen-rb/thrift_hive_metastore.rb 1091617 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1091617 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java 1091617 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/IMetaStoreClient.java 1091617 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1091617 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java 1091617 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1091617 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1091617 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/DropDatabaseDesc.java 1091617 &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/database_drop_not_empty_restrict.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/database.q 1091617 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/database_drop_not_empty_restrict.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/database.q.out 1091617 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/551/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/551/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Carl&lt;/p&gt;
</comment>
                            <comment id="13022625" author="cwsteinbach" created="Thu, 21 Apr 2011 06:10:43 +0000"  >&lt;p&gt;+1. Will commit if tests pass.&lt;/p&gt;</comment>
                            <comment id="13022626" author="cwsteinbach" created="Thu, 21 Apr 2011 06:14:17 +0000"  >&lt;p&gt;@Siying: I&apos;m getting errors in DDLSemanticAnalyzer when I try to apply the patch. Can you please rebase it to trunk? Thanks!&lt;/p&gt;</comment>
                            <comment id="13022877" author="sdong" created="Thu, 21 Apr 2011 19:15:43 +0000"  >&lt;p&gt;rebase&lt;/p&gt;</comment>
                            <comment id="13022880" author="cwsteinbach" created="Thu, 21 Apr 2011 19:30:11 +0000"  >&lt;p&gt;I&apos;m running tests now.&lt;/p&gt;</comment>
                            <comment id="13024734" author="cwsteinbach" created="Mon, 25 Apr 2011 07:52:47 +0000"  >&lt;p&gt;Committed to trunk. Thanks Siying!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13137483">HIVE-18670</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12475447" name="HIVE-2090.1.patch" size="37614" author="sdong" created="Tue, 5 Apr 2011 01:05:30 +0000"/>
                            <attachment id="12475526" name="HIVE-2090.2.patch" size="41040" author="sdong" created="Tue, 5 Apr 2011 20:59:53 +0000"/>
                            <attachment id="12475548" name="HIVE-2090.3.patch" size="72724" author="sdong" created="Wed, 6 Apr 2011 00:37:05 +0000"/>
                            <attachment id="12476195" name="HIVE-2090.4.patch" size="72771" author="sdong" created="Wed, 13 Apr 2011 00:38:24 +0000"/>
                            <attachment id="12476199" name="HIVE-2090.5.patch" size="72930" author="sdong" created="Wed, 13 Apr 2011 00:59:08 +0000"/>
                            <attachment id="12476401" name="HIVE-2090.6.patch" size="76053" author="sdong" created="Fri, 15 Apr 2011 00:57:43 +0000"/>
                            <attachment id="12477026" name="HIVE-2090.7.patch" size="73183" author="sdong" created="Thu, 21 Apr 2011 19:15:43 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 5 Apr 2011 01:56:33 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72561</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 40 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lidz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123629</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-2091] Test scripts rcfile_columnar.q and join_filters.q   need to be made deterministic in their output</title>
                <link>https://issues.apache.org/jira/browse/HIVE-2091</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently this 2 query scripts generate non-deterministic output: &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;ql/src/test/queries/clientpositive/rcfile_columnar.q&lt;/li&gt;
	&lt;li&gt;ql/src/test/queries/clientpositive/join_filters.q&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The suggestion is to use ORDER BY statement.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12503413">HIVE-2091</key>
            <summary>Test scripts rcfile_columnar.q and join_filters.q   need to be made deterministic in their output</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="rvs">Roman Shaposhnik</reporter>
                        <labels>
                    </labels>
                <created>Tue, 5 Apr 2011 16:15:24 +0000</created>
                <updated>Wed, 6 Apr 2011 20:20:48 +0000</updated>
                                            <version>0.7.0</version>
                                                    <component>Testing Infrastructure</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="13016062" author="rvs" created="Tue, 5 Apr 2011 18:23:34 +0000"  >&lt;p&gt;Please take a look at the attached patch&lt;/p&gt;</comment>
                            <comment id="13016270" author="cwsteinbach" created="Wed, 6 Apr 2011 05:45:48 +0000"  >&lt;p&gt;@Roman: Changes look good, but your patch is based against branch-0.7. Can you please rebase the patch to trunk? Thanks!&lt;/p&gt;</comment>
                            <comment id="13016508" author="rvs" created="Wed, 6 Apr 2011 20:20:48 +0000"  >&lt;p&gt;Patch against trunk (the previous one was against 0.7.0 branch)&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12475621" name="HIVE-2091-trunk.patch" size="140754" author="rvs" created="Wed, 6 Apr 2011 20:20:48 +0000"/>
                            <attachment id="12475517" name="HIVE-2091.patch" size="140351" author="rvs" created="Tue, 5 Apr 2011 18:25:15 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 6 Apr 2011 05:45:48 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42276</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 42 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lie7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123630</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-2092] support &apos;drop database &lt;DBNAME&gt; force&apos;;</title>
                <link>https://issues.apache.org/jira/browse/HIVE-2092</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently, the above command fails if the database is not empty.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12503447">HIVE-2092</key>
            <summary>support &apos;drop database &lt;DBNAME&gt; force&apos;;</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="sdong">Siying Dong</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Tue, 5 Apr 2011 20:33:34 +0000</created>
                <updated>Tue, 5 Apr 2011 20:41:06 +0000</updated>
                            <resolved>Tue, 5 Apr 2011 20:41:06 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="13016109" author="cwsteinbach" created="Tue, 5 Apr 2011 20:41:06 +0000"  >&lt;p&gt;Duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2090&quot; title=&quot;Add &amp;quot;DROP DATABASE ... CASCADE/RESTRICT&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2090&quot;&gt;&lt;del&gt;HIVE-2090&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 5 Apr 2011 20:41:06 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72560</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 42 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lief:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123631</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-2093] create/drop database should populate inputs/outputs and check concurrency and user permission</title>
                <link>https://issues.apache.org/jira/browse/HIVE-2093</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;concurrency and authorization are needed for create/drop table. Also to make concurrency work, it&apos;s better to have LOCK/UNLOCK DATABASE and SHOW LOCKS DATABASE&lt;/p&gt;</description>
                <environment></environment>
        <key id="12503448">HIVE-2093</key>
            <summary>create/drop database should populate inputs/outputs and check concurrency and user permission</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Tue, 5 Apr 2011 20:34:29 +0000</created>
                <updated>Fri, 13 Dec 2013 03:23:34 +0000</updated>
                            <resolved>Fri, 13 Dec 2013 03:23:34 +0000</resolved>
                                                    <fixVersion>0.13.0</fixVersion>
                                    <component>Authorization</component>
                    <component>Locking</component>
                    <component>Metastore</component>
                    <component>Security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13016672" author="sdong" created="Thu, 7 Apr 2011 03:44:48 +0000"  >&lt;p&gt;1.ReadEntity and WriteEntity to support database as an entity&lt;br/&gt;
2.acquire locks for database in inputs and outputs&lt;br/&gt;
3.if database in outputs, user must have All permission to execute the query.&lt;br/&gt;
4.fix a small bug in security code that querying user-level privilege always returns null.&lt;/p&gt;</comment>
                            <comment id="13017034" author="namit" created="Thu, 7 Apr 2011 16:39:51 +0000"  >&lt;p&gt;The changes to inputs/outputs look good - &lt;br/&gt;
Yongqiang, can you confirm the authorization changes ?&lt;/p&gt;

&lt;p&gt;If we are supporting this, we should also support&lt;br/&gt;
LOCK DATABASE &amp;lt;DB_NAME&amp;gt; in the same patch.&lt;/p&gt;

&lt;p&gt;Also, can you add a negative test with LOCK DATABASE &amp;lt;..&amp;gt; ?&lt;/p&gt;</comment>
                            <comment id="13017097" author="sdong" created="Thu, 7 Apr 2011 19:34:27 +0000"  >&lt;p&gt;Namit, do you mean we should add LOCK DATABASE? Looks like we don&apos;t have the syntax at all.&lt;/p&gt;</comment>
                            <comment id="13017115" author="he yongqiang" created="Thu, 7 Apr 2011 20:06:19 +0000"  >&lt;p&gt;Siying, can you add cleanup of db/user privilege in QTestUtils?&lt;/p&gt;</comment>
                            <comment id="13017252" author="sdong" created="Fri, 8 Apr 2011 03:22:31 +0000"  >&lt;p&gt;added:&lt;br/&gt;
LOCK DATABASE xxx&lt;br/&gt;
SHOW LOCKS DATABASE xxx&lt;br/&gt;
UNLOCK DATABASE xxx&lt;/p&gt;

&lt;p&gt;added negative tests.&lt;br/&gt;
fix bugs&lt;/p&gt;

&lt;p&gt;I still need to update some tests results, as inputs and outputs changed&lt;/p&gt;</comment>
                            <comment id="13017253" author="sdong" created="Fri, 8 Apr 2011 03:27:29 +0000"  >&lt;p&gt;created review board: &lt;a href=&quot;https://reviews.apache.org/r/566&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13017254" author="jiraposter@reviews.apache.org" created="Fri, 8 Apr 2011 03:28:05 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/566/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for hive, Yongqiang He and namit jain.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Still need to change some old tests&apos; outputs.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; title=&quot;create/drop database should populate inputs/outputs and check concurrency and user permission&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2093&quot;&gt;&lt;del&gt;HIVE-2093&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2093&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/ql/src/test/results/clientnegative/lockneg8.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/lockneg9.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/add_part_exist.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/alter1.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/lockneg7.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/lockneg6.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/lockneg9.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/database.q 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/authorization_fail_create_db.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/authorization_fail_drop_db.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/database_create_already_exists.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/database_create_invalid_name.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/database_drop_does_not_exist.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/database_drop_not_empty.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/authorization_fail_create_db.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/lockneg6.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/lockneg7.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/lockneg8.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ShowLocksDesc.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1089697 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/hooks/ReadEntity.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/alter2.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/alter3.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/alter4.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/authorization_5.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/database.q.out 1089697 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/566/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Siying&lt;/p&gt;
</comment>
                            <comment id="13017325" author="sdong" created="Fri, 8 Apr 2011 07:16:35 +0000"  >&lt;p&gt;fix test outputs.&lt;/p&gt;</comment>
                            <comment id="13017327" author="jiraposter@reviews.apache.org" created="Fri, 8 Apr 2011 07:19:05 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/566/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2011-04-08 07:19:12.088932)&lt;/p&gt;


&lt;p&gt;Review request for hive, Yongqiang He and namit jain.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Still need to change some old tests&apos; outputs.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; title=&quot;create/drop database should populate inputs/outputs and check concurrency and user permission&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2093&quot;&gt;&lt;del&gt;HIVE-2093&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2093&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/hooks/ReadEntity.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java 1089697 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ShowLocksDesc.java 1089697 &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/authorization_fail_create_db.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/lockneg6.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/lockneg7.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/lockneg8.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/lockneg9.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/database.q 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/authorization_fail_create_db.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/authorization_fail_drop_db.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/database_create_already_exists.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/database_create_invalid_name.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/database_drop_does_not_exist.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/database_drop_not_empty.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_01_nonpart_over_loaded.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_02_all_part_over_overlap.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_03_nonpart_noncompat_colschema.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_04_nonpart_noncompat_colnumber.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_05_nonpart_noncompat_coltype.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_06_nonpart_noncompat_storage.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_07_nonpart_noncompat_ifof.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_08_nonpart_noncompat_serde.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_09_nonpart_noncompat_serdeparam.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_10_nonpart_noncompat_bucketing.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_11_nonpart_noncompat_sorting.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_13_nonnative_import.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_14_nonpart_part.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_15_part_nonpart.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_16_part_noncompat_schema.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_17_part_spec_underspec.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_18_part_spec_missing.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_19_external_over_existing.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_20_managed_location_over_existing.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_21_part_managed_external.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_23_import_exist_authfail.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_24_import_part_authfail.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_25_import_nonexist_authfail.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/lockneg6.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/lockneg7.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/lockneg8.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/lockneg9.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/add_part_exist.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/alter1.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/alter2.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/alter3.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/alter4.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/authorization_5.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/database.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/database_properties.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_00_nonpart_empty.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_01_nonpart.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_02_00_part_empty.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_02_part.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_03_nonpart_over_compat.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_04_all_part.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_04_evolved_parts.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_05_some_part.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_06_one_part.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_07_all_part_over_nonoverlap.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_08_nonpart_rename.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_09_part_spec_nonoverlap.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_10_external_managed.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_11_managed_external.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_12_external_location.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_13_managed_location.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_14_managed_location_over_existing.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_15_external_part.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_16_part_external.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_17_part_managed.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_18_part_external.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_19_part_external_location.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_20_part_managed_location.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_22_import_exist_authsuccess.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_23_import_part_authsuccess.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_24_import_nonexist_authsuccess.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/lock1.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/lock2.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/lock3.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/rename_column.q.out 1089697 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/show_tables.q.out 1089697 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/566/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Siying&lt;/p&gt;
</comment>
                            <comment id="13021502" author="he yongqiang" created="Tue, 19 Apr 2011 09:10:24 +0000"  >&lt;p&gt;The change looks good to me. Siying, can you rebase? &lt;/p&gt;

&lt;p&gt;(Carl, since you are looking at the other one, can you please also take a look at this one as well?)&lt;/p&gt;</comment>
                            <comment id="13021743" author="jiraposter@reviews.apache.org" created="Tue, 19 Apr 2011 19:26:05 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/566/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2011-04-19 19:25:22.632716)&lt;/p&gt;


&lt;p&gt;Review request for hive, Yongqiang He and namit jain.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Still need to change some old tests&apos; outputs.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; title=&quot;create/drop database should populate inputs/outputs and check concurrency and user permission&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2093&quot;&gt;&lt;del&gt;HIVE-2093&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2093&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1095164 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java 1095164 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1095164 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/hooks/ReadEntity.java 1095164 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java 1095164 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java 1095164 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1095164 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1095164 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java 1095164 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java 1095164 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java 1095164 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/LockDatabaseDesc.java PRE-CREATION &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ShowLocksDesc.java 1095164 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/UnlockDatabaseDesc.java PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/authorization_fail_create_db.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/authorization_fail_drop_db.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/lockneg6.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/lockneg7.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/lockneg8.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/lockneg9.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/database.q 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/authorization_fail_create_db.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/authorization_fail_drop_db.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/database_create_already_exists.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/database_create_invalid_name.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/database_drop_does_not_exist.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/database_drop_not_empty.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_01_nonpart_over_loaded.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_02_all_part_over_overlap.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_03_nonpart_noncompat_colschema.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_04_nonpart_noncompat_colnumber.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_05_nonpart_noncompat_coltype.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_06_nonpart_noncompat_storage.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_07_nonpart_noncompat_ifof.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_08_nonpart_noncompat_serde.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_09_nonpart_noncompat_serdeparam.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_10_nonpart_noncompat_bucketing.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_11_nonpart_noncompat_sorting.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_13_nonnative_import.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_14_nonpart_part.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_15_part_nonpart.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_16_part_noncompat_schema.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_17_part_spec_underspec.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_18_part_spec_missing.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_19_external_over_existing.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_20_managed_location_over_existing.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_21_part_managed_external.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_23_import_exist_authfail.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_24_import_part_authfail.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_25_import_nonexist_authfail.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/lockneg6.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/lockneg7.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/lockneg8.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/lockneg9.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/add_part_exist.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/alter1.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/alter2.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/alter3.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/alter4.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/authorization_5.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/database.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/database_properties.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_00_nonpart_empty.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_01_nonpart.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_02_00_part_empty.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_02_part.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_03_nonpart_over_compat.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_04_all_part.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_04_evolved_parts.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_05_some_part.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_06_one_part.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_07_all_part_over_nonoverlap.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_08_nonpart_rename.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_09_part_spec_nonoverlap.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_10_external_managed.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_11_managed_external.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_12_external_location.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_13_managed_location.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_14_managed_location_over_existing.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_15_external_part.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_16_part_external.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_17_part_managed.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_18_part_external.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_19_part_external_location.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_20_part_managed_location.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_22_import_exist_authsuccess.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_23_import_part_authsuccess.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_24_import_nonexist_authsuccess.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/lock1.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/lock2.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/lock3.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/rename_column.q.out 1095164 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/show_tables.q.out 1095164 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/566/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Siying&lt;/p&gt;
</comment>
                            <comment id="13022669" author="cwsteinbach" created="Thu, 21 Apr 2011 07:42:04 +0000"  >&lt;p&gt;@Siying: Looks good for the most part. Please see my comments on RB. Thanks.&lt;/p&gt;</comment>
                            <comment id="13022670" author="jiraposter@reviews.apache.org" created="Thu, 21 Apr 2011 07:42:05 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/566/#review517&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/#review517&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;



&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/566/#comment1053&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/#comment1053&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Spelling&lt;/p&gt;



&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/566/#comment1058&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/#comment1058&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Why not make this a boolean function? I understand that the convention in this class is to have functions that return 0, or something more than 0, but it looks like all of the other functions can be boolean valued as well. Returning an integer in this situation is confusing.&lt;/p&gt;



&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/566/#comment1059&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/#comment1059&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Same deal here. Can you change this to return a boolean value?&lt;/p&gt;



&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/566/#comment1061&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/#comment1061&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    You can eliminate a couple lines of code by using foreach syntax instead of an explicit iterator.&lt;/p&gt;



&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/hooks/ReadEntity.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/566/#comment1062&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/#comment1062&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    I draw the line at nested ternary statements. Can you please use if/else instead?&lt;/p&gt;



&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/566/#comment1063&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/#comment1063&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Nice to have: move DATABASE to the beginning of the list.&lt;/p&gt;



&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/566/#comment1064&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/#comment1064&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Why do you need to initialize the lock manager here, but not above in analyzeLockDatabase()?&lt;/p&gt;



&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/566/#comment1065&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/#comment1065&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    should be &quot;unlock database statement&quot;&lt;/p&gt;





&lt;p&gt;trunk/ql/src/test/queries/clientnegative/lockneg6.q&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/566/#comment1066&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/#comment1066&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Please add some comments explaining what it is you&apos;re trying to test so that I can quickly tell how this differs from lockneg5, lockneg7, etc, etc. Please also consider changing the name of the file to something more descriptive so that I don&apos;t even have to read the comments.&lt;/p&gt;



&lt;p&gt;trunk/ql/src/test/results/clientnegative/authorization_fail_create_db.q.out&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/566/#comment1067&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/#comment1067&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Please make this less ambiguous and easier to parse by capitalizing SHOW GRANT.&lt;/p&gt;



&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_15_part_nonpart.q.out&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/566/#comment1068&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/#comment1068&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Any chance I can get a look at closed-source-hive? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Carl&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;On 2011-04-19 19:25:22, Siying Dong wrote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This is an automatically generated e-mail. To reply, visit:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/566/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;(Updated 2011-04-19 19:25:22)&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Review request for hive, Yongqiang He and namit jain.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Summary&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Still need to change some old tests&apos; outputs.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; title=&quot;create/drop database should populate inputs/outputs and check concurrency and user permission&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2093&quot;&gt;&lt;del&gt;HIVE-2093&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2093&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diffs&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/hooks/ReadEntity.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/LockDatabaseDesc.java PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ShowLocksDesc.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/UnlockDatabaseDesc.java PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientnegative/authorization_fail_create_db.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientnegative/authorization_fail_drop_db.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientnegative/lockneg6.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientnegative/lockneg7.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientnegative/lockneg8.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientnegative/lockneg9.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientpositive/database.q 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/authorization_fail_create_db.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/authorization_fail_drop_db.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/database_create_already_exists.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/database_create_invalid_name.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/database_drop_does_not_exist.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/database_drop_not_empty.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_01_nonpart_over_loaded.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_02_all_part_over_overlap.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_03_nonpart_noncompat_colschema.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_04_nonpart_noncompat_colnumber.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_05_nonpart_noncompat_coltype.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_06_nonpart_noncompat_storage.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_07_nonpart_noncompat_ifof.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_08_nonpart_noncompat_serde.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_09_nonpart_noncompat_serdeparam.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_10_nonpart_noncompat_bucketing.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_11_nonpart_noncompat_sorting.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_13_nonnative_import.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_14_nonpart_part.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_15_part_nonpart.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_16_part_noncompat_schema.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_17_part_spec_underspec.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_18_part_spec_missing.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_19_external_over_existing.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_20_managed_location_over_existing.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_21_part_managed_external.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_23_import_exist_authfail.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_24_import_part_authfail.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_25_import_nonexist_authfail.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/lockneg6.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/lockneg7.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/lockneg8.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/lockneg9.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/add_part_exist.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/alter1.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/alter2.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/alter3.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/alter4.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/authorization_5.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/database.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/database_properties.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_00_nonpart_empty.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_01_nonpart.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_02_00_part_empty.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_02_part.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_03_nonpart_over_compat.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_04_all_part.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_04_evolved_parts.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_05_some_part.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_06_one_part.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_07_all_part_over_nonoverlap.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_08_nonpart_rename.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_09_part_spec_nonoverlap.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_10_external_managed.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_11_managed_external.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_12_external_location.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_13_managed_location.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_14_managed_location_over_existing.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_15_external_part.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_16_part_external.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_17_part_managed.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_18_part_external.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_19_part_external_location.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_20_part_managed_location.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_22_import_exist_authsuccess.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_23_import_part_authsuccess.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_24_import_nonexist_authsuccess.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/lock1.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/lock2.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/lock3.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/rename_column.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/show_tables.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/566/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/diff&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Testing&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Siying&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
</comment>
                            <comment id="13022946" author="sdong" created="Thu, 21 Apr 2011 22:11:48 +0000"  >&lt;p&gt;address Carl&apos;s comments.&lt;/p&gt;</comment>
                            <comment id="13022958" author="jiraposter@reviews.apache.org" created="Thu, 21 Apr 2011 22:22:06 +0000"  >

&lt;blockquote&gt;&lt;p&gt;On 2011-04-21 07:41:22, Carl Steinbach wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java, line 2080&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/566/diff/3/?file=15972#file15972line2080&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/diff/3/?file=15972#file15972line2080&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Same deal here. Can you change this to return a boolean value?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m going to follow convention this time, instead of making radical changes in such a JIRA. If you feel we should cleaning them up, we should open a separate JIRA.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2011-04-21 07:41:22, Carl Steinbach wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java, line 699&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/566/diff/3/?file=15976#file15976line699&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/diff/3/?file=15976#file15976line699&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Why do you need to initialize the lock manager here, but not above in analyzeLockDatabase()?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If inputs and outputs are not empty, lock manager will automatically start. I look at the codes again. We probably don&apos;t need to put Db in inputs and outputs in such query, so that I remove them and set this value.&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Siying&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/566/#review517&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/#review517&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


&lt;p&gt;On 2011-04-19 19:25:22, Siying Dong wrote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This is an automatically generated e-mail. To reply, visit:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/566/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;(Updated 2011-04-19 19:25:22)&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Review request for hive, Yongqiang He and namit jain.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Summary&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Still need to change some old tests&apos; outputs.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; title=&quot;create/drop database should populate inputs/outputs and check concurrency and user permission&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2093&quot;&gt;&lt;del&gt;HIVE-2093&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2093&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diffs&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/hooks/ReadEntity.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/LockDatabaseDesc.java PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ShowLocksDesc.java 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/UnlockDatabaseDesc.java PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientnegative/authorization_fail_create_db.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientnegative/authorization_fail_drop_db.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientnegative/lockneg6.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientnegative/lockneg7.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientnegative/lockneg8.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientnegative/lockneg9.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientpositive/database.q 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/authorization_fail_create_db.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/authorization_fail_drop_db.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/database_create_already_exists.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/database_create_invalid_name.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/database_drop_does_not_exist.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/database_drop_not_empty.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_01_nonpart_over_loaded.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_02_all_part_over_overlap.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_03_nonpart_noncompat_colschema.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_04_nonpart_noncompat_colnumber.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_05_nonpart_noncompat_coltype.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_06_nonpart_noncompat_storage.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_07_nonpart_noncompat_ifof.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_08_nonpart_noncompat_serde.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_09_nonpart_noncompat_serdeparam.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_10_nonpart_noncompat_bucketing.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_11_nonpart_noncompat_sorting.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_13_nonnative_import.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_14_nonpart_part.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_15_part_nonpart.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_16_part_noncompat_schema.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_17_part_spec_underspec.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_18_part_spec_missing.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_19_external_over_existing.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_20_managed_location_over_existing.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_21_part_managed_external.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_23_import_exist_authfail.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_24_import_part_authfail.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/exim_25_import_nonexist_authfail.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/lockneg6.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/lockneg7.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/lockneg8.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientnegative/lockneg9.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/add_part_exist.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/alter1.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/alter2.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/alter3.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/alter4.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/authorization_5.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/database.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/database_properties.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_00_nonpart_empty.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_01_nonpart.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_02_00_part_empty.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_02_part.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_03_nonpart_over_compat.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_04_all_part.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_04_evolved_parts.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_05_some_part.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_06_one_part.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_07_all_part_over_nonoverlap.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_08_nonpart_rename.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_09_part_spec_nonoverlap.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_10_external_managed.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_11_managed_external.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_12_external_location.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_13_managed_location.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_14_managed_location_over_existing.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_15_external_part.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_16_part_external.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_17_part_managed.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_18_part_external.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_19_part_external_location.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_20_part_managed_location.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_22_import_exist_authsuccess.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_23_import_part_authsuccess.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/exim_24_import_nonexist_authsuccess.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/lock1.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/lock2.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/lock3.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/rename_column.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/show_tables.q.out 1095164 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/566/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/diff&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Testing&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Siying&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
</comment>
                            <comment id="13022959" author="jiraposter@reviews.apache.org" created="Thu, 21 Apr 2011 22:22:06 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/566/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2011-04-21 22:21:03.518662)&lt;/p&gt;


&lt;p&gt;Review request for hive, Yongqiang He and namit jain.&lt;/p&gt;


&lt;p&gt;Changes&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;addressing most of Carl&apos;s comments except incline.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Still need to change some old tests&apos; outputs.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; title=&quot;create/drop database should populate inputs/outputs and check concurrency and user permission&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2093&quot;&gt;&lt;del&gt;HIVE-2093&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-2093&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1095795 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java 1095795 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1095795 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/hooks/ReadEntity.java 1095795 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java 1095795 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java 1095795 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1095795 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1095795 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java 1095795 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java 1095795 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java 1095795 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/LockDatabaseDesc.java PRE-CREATION &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ShowLocksDesc.java 1095795 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/UnlockDatabaseDesc.java PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/authorization_fail_create_db.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/authorization_fail_drop_db.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/lockneg_query_tbl_in_locked_db.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/lockneg_try_db_lock_conflict.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/lockneg_try_drop_locked_db.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/lockneg_try_lock_db_in_use.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/database.q 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/authorization_fail_2.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/authorization_fail_3.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/authorization_fail_4.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/authorization_fail_5.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/authorization_fail_6.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/authorization_fail_7.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/authorization_fail_create_db.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/authorization_fail_drop_db.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/authorization_part.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/database_create_already_exists.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/database_create_invalid_name.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/database_drop_does_not_exist.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/database_drop_not_empty.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_01_nonpart_over_loaded.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_02_all_part_over_overlap.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_03_nonpart_noncompat_colschema.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_04_nonpart_noncompat_colnumber.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_05_nonpart_noncompat_coltype.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_06_nonpart_noncompat_storage.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_07_nonpart_noncompat_ifof.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_08_nonpart_noncompat_serde.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_09_nonpart_noncompat_serdeparam.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_10_nonpart_noncompat_bucketing.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_11_nonpart_noncompat_sorting.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_13_nonnative_import.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_14_nonpart_part.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_15_part_nonpart.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_16_part_noncompat_schema.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_17_part_spec_underspec.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_18_part_spec_missing.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_19_external_over_existing.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_20_managed_location_over_existing.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_21_part_managed_external.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_22_export_authfail.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_23_import_exist_authfail.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_24_import_part_authfail.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/exim_25_import_nonexist_authfail.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/load_exist_part_authfail.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/load_nonpart_authfail.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/load_part_authfail.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/lockneg_query_tbl_in_locked_db.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/lockneg_try_db_lock_conflict.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/lockneg_try_drop_locked_db.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/lockneg_try_lock_db_in_use.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/add_part_exist.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/alter1.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/alter2.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/alter3.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/alter4.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/authorization_5.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/database.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/database_properties.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_00_nonpart_empty.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_01_nonpart.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_02_00_part_empty.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_02_part.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_03_nonpart_over_compat.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_04_all_part.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_04_evolved_parts.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_05_some_part.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_06_one_part.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_07_all_part_over_nonoverlap.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_08_nonpart_rename.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_09_part_spec_nonoverlap.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_10_external_managed.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_11_managed_external.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_12_external_location.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_13_managed_location.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_14_managed_location_over_existing.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_15_external_part.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_16_part_external.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_17_part_managed.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_18_part_external.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_19_part_external_location.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_20_part_managed_location.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_22_import_exist_authsuccess.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_23_import_part_authsuccess.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/exim_24_import_nonexist_authsuccess.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/lock1.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/lock2.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/lock3.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/rename_column.q.out 1095795 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/show_tables.q.out 1095795 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/566/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/566/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Siying&lt;/p&gt;
</comment>
                            <comment id="13024738" author="cwsteinbach" created="Mon, 25 Apr 2011 08:03:31 +0000"  >&lt;p&gt;+1. Will commit if tests pass.&lt;/p&gt;</comment>
                            <comment id="13025461" author="sdong" created="Tue, 26 Apr 2011 21:55:47 +0000"  >&lt;p&gt;rebase&lt;/p&gt;</comment>
                            <comment id="13043046" author="he yongqiang" created="Thu, 2 Jun 2011 21:08:02 +0000"  >&lt;p&gt;any update on this one?&lt;/p&gt;</comment>
                            <comment id="13060997" author="cwsteinbach" created="Thu, 7 Jul 2011 02:10:08 +0000"  >&lt;p&gt;@Siying: Sorry I let this go stale. Can you please rebase the patch and resubmit? I will look at it ASAP. Thanks.&lt;/p&gt;</comment>
                            <comment id="13761630" author="navis" created="Mon, 9 Sep 2013 05:26:54 +0000"  >&lt;p&gt;I think we need this. Rebased to trunk.&lt;/p&gt;</comment>
                            <comment id="13761631" author="phabricator@reviews.facebook.net" created="Mon, 9 Sep 2013 05:27:53 +0000"  >&lt;p&gt;navis requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; title=&quot;create/drop database should populate inputs/outputs and check concurrency and user permission&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2093&quot;&gt;&lt;del&gt;HIVE-2093&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; create/drop database should populate inputs/outputs and check concurrency and user permission&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;concurrency and authorization are needed for create/drop table. Also to make concurrency work, it&apos;s better to have LOCK/UNLOCK DATABASE and SHOW LOCKS DATABASE&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12807&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12807&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/Driver.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/hooks/ReadEntity.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/ExportSemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/LockDatabaseDesc.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ShowLocksDesc.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/UnlockDatabaseDesc.java&lt;br/&gt;
  ql/src/test/queries/clientnegative/authorization_fail_create_db.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/authorization_fail_drop_db.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/lockneg_query_tbl_in_locked_db.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/lockneg_try_db_lock_conflict.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/lockneg_try_drop_locked_db.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/lockneg_try_lock_db_in_use.q&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_2.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_3.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_4.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_5.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_6.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_7.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_create_db.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_drop_db.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_part.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/database_create_already_exists.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/database_create_invalid_name.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/database_drop_does_not_exist.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/database_drop_not_empty.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/database_drop_not_empty_restrict.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/desc_failure3.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/drop_table_failure3.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_01_nonpart_over_loaded.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_02_all_part_over_overlap.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_03_nonpart_noncompat_colschema.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_04_nonpart_noncompat_colnumber.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_05_nonpart_noncompat_coltype.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_06_nonpart_noncompat_storage.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_07_nonpart_noncompat_ifof.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_08_nonpart_noncompat_serde.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_09_nonpart_noncompat_serdeparam.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_10_nonpart_noncompat_bucketing.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_11_nonpart_noncompat_sorting.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_13_nonnative_import.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_14_nonpart_part.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_15_part_nonpart.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_16_part_noncompat_schema.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_17_part_spec_underspec.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_18_part_spec_missing.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_19_external_over_existing.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_20_managed_location_over_existing.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_21_part_managed_external.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_22_export_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_23_import_exist_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_24_import_part_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_25_import_nonexist_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/join_nonexistent_part.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/load_exist_part_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/load_nonpart_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/load_part_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/lockneg_query_tbl_in_locked_db.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/lockneg_try_db_lock_conflict.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/lockneg_try_drop_locked_db.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/lockneg_try_lock_db_in_use.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/show_columns3.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/add_part_exist.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/alter1.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/alter2.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/alter3.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/alter4.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/alter5.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/alter_rename_partition.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/authorization_5.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/ctas_uses_database_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/database.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/database_drop.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/database_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/database_properties.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/describe_database_json.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/describe_syntax.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/drop_database_removes_partition_dirs.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_00_nonpart_empty.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_01_nonpart.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_02_00_part_empty.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_02_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_03_nonpart_over_compat.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_04_all_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_04_evolved_parts.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_05_some_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_06_one_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_07_all_part_over_nonoverlap.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_08_nonpart_rename.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_09_part_spec_nonoverlap.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_10_external_managed.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_11_managed_external.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_12_external_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_13_managed_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_14_managed_location_over_existing.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_15_external_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_16_part_external.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_17_part_managed.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_18_part_external.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_19_part_external_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_20_part_managed_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_22_import_exist_authsuccess.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_23_import_part_authsuccess.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_24_import_nonexist_authsuccess.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/input46.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/insert1.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/insert2_overwrite_partitions.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/rename_column.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/show_columns.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/show_create_table_db_table.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/show_tables.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/view.q.out&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/30705/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/30705/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13761676" author="hiveqa" created="Mon, 9 Sep 2013 07:36:17 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12602091/HIVE-2093.D12807.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12602091/HIVE-2093.D12807.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 25 failed/errored test(s), 3092 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hcatalog.security.TestHdfsAuthorizationProvider.testDropDatabaseFail1
org.apache.hive.hcatalog.security.TestHdfsAuthorizationProvider.testShowDatabases
org.apache.hcatalog.security.TestHdfsAuthorizationProvider.testDropDatabaseFail2
org.apache.hive.hcatalog.security.TestHdfsAuthorizationProvider.testDropTableFail4
org.apache.hive.hcatalog.fileformats.TestOrcDynamicPartitioned.testHCatDynamicPartitionedTable
org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatDynamicPartitionedTable
org.apache.hcatalog.security.TestHdfsAuthorizationProvider.testShowDatabases
org.apache.hive.hcatalog.security.TestHdfsAuthorizationProvider.testShowTablesFail
org.apache.hcatalog.security.TestHdfsAuthorizationProvider.testShowTablesFail
org.apache.hcatalog.pig.TestHCatLoaderComplexSchema.testMapWithComplexData
org.apache.hive.hcatalog.security.TestHdfsAuthorizationProvider.testDropDatabaseFail1
org.apache.hcatalog.security.TestHdfsAuthorizationProvider.testDatabaseOps
org.apache.hive.hcatalog.security.TestHdfsAuthorizationProvider.testTableOps
org.apache.hcatalog.security.TestHdfsAuthorizationProvider.testDescSwitchDatabaseFail
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_exim_19_00_part_external_location
org.apache.hcatalog.security.TestHdfsAuthorizationProvider.testCreateTableFail4
org.apache.hive.hcatalog.security.TestHdfsAuthorizationProvider.testDropDatabaseFail2
org.apache.hive.hcatalog.security.TestHdfsAuthorizationProvider.testCreateTableFail4
org.apache.hcatalog.security.TestHdfsAuthorizationProvider.testDropTableFail4
org.apache.hive.hcatalog.security.TestHdfsAuthorizationProvider.testDatabaseOps
org.apache.hive.hcatalog.security.TestHdfsAuthorizationProvider.testDescSwitchDatabaseFail
org.apache.hive.hcatalog.security.TestHdfsAuthorizationProvider.testCreateTableFail3
org.apache.hcatalog.security.TestHdfsAuthorizationProvider.testCreateTableFail3
org.apache.hcatalog.security.TestHdfsAuthorizationProvider.testTableOps
org.apache.hadoop.hive.cli.TestHBaseNegativeCliDriver.testCliDriver_cascade_dbdrop_hadoop20
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/666/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/666/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/666/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/666/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 25 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13762594" author="navis" created="Tue, 10 Sep 2013 01:38:49 +0000"  >&lt;p&gt;create table/partition does not have input/output entities in PREHOOK stage. IMO, database should act in same manner.&lt;/p&gt;</comment>
                            <comment id="13762604" author="phabricator@reviews.facebook.net" created="Tue, 10 Sep 2013 01:45:55 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; title=&quot;create/drop database should populate inputs/outputs and check concurrency and user permission&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2093&quot;&gt;&lt;del&gt;HIVE-2093&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; create/drop database should populate inputs/outputs and check concurrency and user permission&quot;.&lt;/p&gt;

&lt;p&gt;  Fix test fails &amp;amp; remove adding entities for create database&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12807&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12807&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12807?vs=39741&amp;amp;id=39813#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12807?vs=39741&amp;amp;id=39813#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  hbase-handler/src/test/results/negative/cascade_dbdrop_hadoop20.q.out&lt;br/&gt;
  hcatalog/core/src/main/java/org/apache/hcatalog/security/HdfsAuthorizationProvider.java&lt;br/&gt;
  hcatalog/core/src/main/java/org/apache/hive/hcatalog/security/HdfsAuthorizationProvider.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/Driver.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/hooks/ReadEntity.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/ExportSemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/LockDatabaseDesc.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ShowLocksDesc.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/UnlockDatabaseDesc.java&lt;br/&gt;
  ql/src/test/queries/clientnegative/authorization_fail_create_db.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/authorization_fail_drop_db.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/lockneg_query_tbl_in_locked_db.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/lockneg_try_db_lock_conflict.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/lockneg_try_drop_locked_db.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/lockneg_try_lock_db_in_use.q&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_2.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_3.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_4.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_5.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_6.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_7.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_create_db.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_drop_db.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_part.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/database_create_already_exists.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/database_create_invalid_name.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/database_drop_does_not_exist.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/database_drop_not_empty.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/database_drop_not_empty_restrict.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/desc_failure3.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/drop_table_failure3.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_01_nonpart_over_loaded.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_02_all_part_over_overlap.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_03_nonpart_noncompat_colschema.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_04_nonpart_noncompat_colnumber.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_05_nonpart_noncompat_coltype.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_06_nonpart_noncompat_storage.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_07_nonpart_noncompat_ifof.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_08_nonpart_noncompat_serde.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_09_nonpart_noncompat_serdeparam.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_10_nonpart_noncompat_bucketing.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_11_nonpart_noncompat_sorting.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_13_nonnative_import.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_14_nonpart_part.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_15_part_nonpart.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_16_part_noncompat_schema.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_17_part_spec_underspec.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_18_part_spec_missing.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_19_external_over_existing.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_20_managed_location_over_existing.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_21_part_managed_external.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_22_export_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_23_import_exist_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_24_import_part_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_25_import_nonexist_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/join_nonexistent_part.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/load_exist_part_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/load_nonpart_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/load_part_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/lockneg_query_tbl_in_locked_db.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/lockneg_try_db_lock_conflict.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/lockneg_try_drop_locked_db.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/lockneg_try_lock_db_in_use.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/show_columns3.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/alter1.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/alter2.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/alter4.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/authorization_5.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/database.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/database_drop.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/describe_database_json.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/drop_database_removes_partition_dirs.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_00_nonpart_empty.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_01_nonpart.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_02_00_part_empty.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_02_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_03_nonpart_over_compat.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_04_all_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_04_evolved_parts.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_05_some_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_06_one_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_07_all_part_over_nonoverlap.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_08_nonpart_rename.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_09_part_spec_nonoverlap.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_10_external_managed.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_11_managed_external.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_12_external_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_13_managed_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_14_managed_location_over_existing.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_15_external_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_16_part_external.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_17_part_managed.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_18_part_external.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_19_00_part_external_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_19_part_external_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_20_part_managed_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_22_import_exist_authsuccess.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_23_import_part_authsuccess.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_24_import_nonexist_authsuccess.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/input46.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/insert2_overwrite_partitions.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/show_create_table_db_table.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13796310" author="phabricator@reviews.facebook.net" created="Wed, 16 Oct 2013 01:42:44 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; title=&quot;create/drop database should populate inputs/outputs and check concurrency and user permission&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2093&quot;&gt;&lt;del&gt;HIVE-2093&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; create/drop database should populate inputs/outputs and check concurrency and user permission&quot;.&lt;/p&gt;

&lt;p&gt;  Rebased to trunk&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12807&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12807&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12807?vs=39813&amp;amp;id=41577#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12807?vs=39813&amp;amp;id=41577#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  hbase-handler/src/test/results/negative/cascade_dbdrop_hadoop20.q.out&lt;br/&gt;
  hcatalog/core/src/main/java/org/apache/hcatalog/security/HdfsAuthorizationProvider.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/Driver.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/hooks/ReadEntity.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/ExportSemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/LockDatabaseDesc.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ShowLocksDesc.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/UnlockDatabaseDesc.java&lt;br/&gt;
  ql/src/test/queries/clientnegative/authorization_fail_create_db.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/authorization_fail_drop_db.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/lockneg_query_tbl_in_locked_db.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/lockneg_try_db_lock_conflict.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/lockneg_try_drop_locked_db.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/lockneg_try_lock_db_in_use.q&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_2.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_3.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_4.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_5.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_6.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_7.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_create_db.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_drop_db.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_part.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/database_drop_does_not_exist.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/database_drop_not_empty.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/database_drop_not_empty_restrict.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_22_export_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_23_import_exist_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_24_import_part_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_25_import_nonexist_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/join_nonexistent_part.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/load_exist_part_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/load_nonpart_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/load_part_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/lockneg_query_tbl_in_locked_db.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/lockneg_try_db_lock_conflict.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/lockneg_try_drop_locked_db.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/lockneg_try_lock_db_in_use.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/alter1.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/alter2.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/alter4.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/authorization_5.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/database.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/database_drop.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/describe_database_json.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/drop_database_removes_partition_dirs.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_00_nonpart_empty.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_01_nonpart.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_02_00_part_empty.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_02_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_03_nonpart_over_compat.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_04_all_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_04_evolved_parts.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_05_some_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_06_one_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_07_all_part_over_nonoverlap.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_08_nonpart_rename.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_09_part_spec_nonoverlap.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_10_external_managed.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_11_managed_external.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_12_external_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_13_managed_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_14_managed_location_over_existing.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_15_external_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_16_part_external.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_17_part_managed.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_18_part_external.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_19_00_part_external_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_19_part_external_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_20_part_managed_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_22_import_exist_authsuccess.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_23_import_part_authsuccess.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_24_import_nonexist_authsuccess.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/input46.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/insert2_overwrite_partitions.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/show_create_table_db_table.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13796808" author="hiveqa" created="Wed, 16 Oct 2013 14:00:01 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12608631/D12807.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12608631/D12807.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/1142/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/1142/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/1142/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/1142/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-1142/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java&apos;
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf build hcatalog/build hcatalog/core/build hcatalog/storage-handlers/hbase/build hcatalog/server-extensions/build hcatalog/webhcat/svr/build hcatalog/webhcat/java-client/build hcatalog/hcatalog-pig-adapter/build common/src/gen
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1532764.

At revision 1532764.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file hbase-handler/src/test/results/negative/cascade_dbdrop_hadoop20.q.out
patching file hcatalog/core/src/main/java/org/apache/hcatalog/security/HdfsAuthorizationProvider.java
patching file ql/src/java/org/apache/hadoop/hive/ql/Driver.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java
patching file ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java
patching file ql/src/java/org/apache/hadoop/hive/ql/hooks/ReadEntity.java
patching file ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/ExportSemanticAnalyzer.java
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/LockDatabaseDesc.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/ShowLocksDesc.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/UnlockDatabaseDesc.java
patching file ql/src/test/queries/clientnegative/authorization_fail_create_db.q
patching file ql/src/test/queries/clientnegative/authorization_fail_drop_db.q
patching file ql/src/test/queries/clientnegative/lockneg_query_tbl_in_locked_db.q
patching file ql/src/test/queries/clientnegative/lockneg_try_db_lock_conflict.q
patching file ql/src/test/queries/clientnegative/lockneg_try_drop_locked_db.q
patching file ql/src/test/queries/clientnegative/lockneg_try_lock_db_in_use.q
patching file ql/src/test/results/clientnegative/authorization_fail_2.q.out
patching file ql/src/test/results/clientnegative/authorization_fail_3.q.out
patching file ql/src/test/results/clientnegative/authorization_fail_4.q.out
patching file ql/src/test/results/clientnegative/authorization_fail_5.q.out
patching file ql/src/test/results/clientnegative/authorization_fail_6.q.out
patching file ql/src/test/results/clientnegative/authorization_fail_7.q.out
patching file ql/src/test/results/clientnegative/authorization_fail_create_db.q.out
patching file ql/src/test/results/clientnegative/authorization_fail_drop_db.q.out
patching file ql/src/test/results/clientnegative/authorization_part.q.out
patching file ql/src/test/results/clientnegative/database_drop_does_not_exist.q.out
patching file ql/src/test/results/clientnegative/database_drop_not_empty.q.out
patching file ql/src/test/results/clientnegative/database_drop_not_empty_restrict.q.out
patching file ql/src/test/results/clientnegative/exim_22_export_authfail.q.out
patching file ql/src/test/results/clientnegative/exim_23_import_exist_authfail.q.out
patching file ql/src/test/results/clientnegative/exim_24_import_part_authfail.q.out
patching file ql/src/test/results/clientnegative/exim_25_import_nonexist_authfail.q.out
patching file ql/src/test/results/clientnegative/join_nonexistent_part.q.out
patching file ql/src/test/results/clientnegative/load_exist_part_authfail.q.out
patching file ql/src/test/results/clientnegative/load_nonpart_authfail.q.out
patching file ql/src/test/results/clientnegative/load_part_authfail.q.out
patching file ql/src/test/results/clientnegative/lockneg_query_tbl_in_locked_db.q.out
patching file ql/src/test/results/clientnegative/lockneg_try_db_lock_conflict.q.out
patching file ql/src/test/results/clientnegative/lockneg_try_drop_locked_db.q.out
patching file ql/src/test/results/clientnegative/lockneg_try_lock_db_in_use.q.out
patching file ql/src/test/results/clientpositive/alter1.q.out
patching file ql/src/test/results/clientpositive/alter2.q.out
patching file ql/src/test/results/clientpositive/alter4.q.out
patching file ql/src/test/results/clientpositive/authorization_5.q.out
patching file ql/src/test/results/clientpositive/database.q.out
patching file ql/src/test/results/clientpositive/database_drop.q.out
patching file ql/src/test/results/clientpositive/describe_database_json.q.out
patching file ql/src/test/results/clientpositive/drop_database_removes_partition_dirs.q.out
patching file ql/src/test/results/clientpositive/exim_00_nonpart_empty.q.out
patching file ql/src/test/results/clientpositive/exim_01_nonpart.q.out
patching file ql/src/test/results/clientpositive/exim_02_00_part_empty.q.out
patching file ql/src/test/results/clientpositive/exim_02_part.q.out
patching file ql/src/test/results/clientpositive/exim_03_nonpart_over_compat.q.out
patching file ql/src/test/results/clientpositive/exim_04_all_part.q.out
patching file ql/src/test/results/clientpositive/exim_04_evolved_parts.q.out
patching file ql/src/test/results/clientpositive/exim_05_some_part.q.out
patching file ql/src/test/results/clientpositive/exim_06_one_part.q.out
patching file ql/src/test/results/clientpositive/exim_07_all_part_over_nonoverlap.q.out
patching file ql/src/test/results/clientpositive/exim_08_nonpart_rename.q.out
patching file ql/src/test/results/clientpositive/exim_09_part_spec_nonoverlap.q.out
patching file ql/src/test/results/clientpositive/exim_10_external_managed.q.out
patching file ql/src/test/results/clientpositive/exim_11_managed_external.q.out
patching file ql/src/test/results/clientpositive/exim_12_external_location.q.out
patching file ql/src/test/results/clientpositive/exim_13_managed_location.q.out
patching file ql/src/test/results/clientpositive/exim_14_managed_location_over_existing.q.out
patching file ql/src/test/results/clientpositive/exim_15_external_part.q.out
patching file ql/src/test/results/clientpositive/exim_16_part_external.q.out
patching file ql/src/test/results/clientpositive/exim_17_part_managed.q.out
patching file ql/src/test/results/clientpositive/exim_18_part_external.q.out
patching file ql/src/test/results/clientpositive/exim_19_00_part_external_location.q.out
patching file ql/src/test/results/clientpositive/exim_19_part_external_location.q.out
patching file ql/src/test/results/clientpositive/exim_20_part_managed_location.q.out
patching file ql/src/test/results/clientpositive/exim_22_import_exist_authsuccess.q.out
patching file ql/src/test/results/clientpositive/exim_23_import_part_authsuccess.q.out
patching file ql/src/test/results/clientpositive/exim_24_import_nonexist_authsuccess.q.out
patching file ql/src/test/results/clientpositive/input46.q.out
patching file ql/src/test/results/clientpositive/insert2_overwrite_partitions.q.out
patching file ql/src/test/results/clientpositive/show_create_table_db_table.q.out
+ [[ true == \t\r\u\e ]]
+ rm -rf /data/hive-ptest/working/ivy /data/hive-ptest/working/maven
+ mkdir /data/hive-ptest/working/ivy /data/hive-ptest/working/maven
+ ant -Dtest.continue.on.failure=true -Dtest.silent=false -Divy.default.ivy.user.dir=/data/hive-ptest/working/ivy -Dmvn.local.repo=/data/hive-ptest/working/maven clean package test -Dtestcase=nothing
Buildfile: /data/hive-ptest/working/apache-svn-trunk-source/build.xml

clean:
     [echo] Project: hive

clean:
     [echo] Project: anttasks

clean:
     [echo] Project: shims

clean:
     [echo] Project: common

clean:
     [echo] Project: serde

clean:
     [echo] Project: metastore

clean:
     [echo] Project: ql

clean:
     [echo] Project: contrib

clean:
     [echo] Project: service

clean:
     [echo] Project: cli

clean:
     [echo] Project: jdbc

clean:
     [echo] Project: beeline

clean:
     [echo] Project: hwi

clean:
     [echo] Project: hbase-handler

clean:
     [echo] Project: testutils

clean:
     [echo] hcatalog

clean:
     [echo] hcatalog-core

clean:
     [echo] hcatalog-pig-adapter

clean:
     [echo] hcatalog-server-extensions

clean:
     [echo] webhcat

clean:
     [echo] webhcat-java-client

clean:

clean:
     [echo] Project: odbc
     [exec] rm -rf /data/hive-ptest/working/apache-svn-trunk-source/build/odbc /data/hive-ptest/working/apache-svn-trunk-source/build/service/objs /data/hive-ptest/working/apache-svn-trunk-source/build/ql/objs /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/objs

clean-online:
     [echo] Project: hive

clean-offline:

ivy-init-dirs:
     [echo] Project: hive
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/maven

ivy-download:
     [echo] Project: hive
      [get] Getting: http://repo2.maven.org/maven2/org/apache/ivy/ivy/2.3.0/ivy-2.3.0.jar
      [get] To: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/ivy-2.3.0.jar

ivy-probe-antlib:
     [echo] Project: hive

ivy-init-antlib:
     [echo] Project: hive

compile-ant-tasks:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jexl/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

ivy-init-settings:
     [echo] Project: anttasks

ivy-resolve:
     [echo] Project: anttasks
[ivy:resolve] :: Apache Ivy 2.3.0 - 20130110142753 :: http://ant.apache.org/ivy/ ::
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-anttasks;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found velocity#velocity;1.5 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-lang/commons-lang/2.4/commons-lang-2.4.jar ...
[ivy:resolve] ..... (255kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-lang#commons-lang;2.4!commons-lang.jar (29ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/velocity/velocity/1.5/velocity-1.5.jar ...
[ivy:resolve] ....... (382kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] velocity#velocity;1.5!velocity.jar (32ms)
[ivy:resolve] :: resolution report :: resolve 4687ms :: artifacts dl 81ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-anttasks-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-anttasks-default.html

ivy-retrieve:
     [echo] Project: anttasks
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-anttasks
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	2 artifacts copied, 0 already retrieved (638kB/10ms)

compile:
     [echo] anttasks
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ant/build.xml:38: warning: &apos;includeantruntime&apos; was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds
    [javac] Compiling 5 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.

deploy-ant-tasks:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

ivy-init-settings:
     [echo] Project: anttasks

ivy-resolve:
     [echo] Project: anttasks
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-anttasks;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found velocity#velocity;1.5 in maven2
[ivy:resolve] :: resolution report :: resolve 489ms :: artifacts dl 2ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-anttasks-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-anttasks-default.html

ivy-retrieve:
     [echo] Project: anttasks
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-anttasks
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	0 artifacts copied, 2 already retrieved (0kB/10ms)

compile:
     [echo] anttasks
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ant/build.xml:38: warning: &apos;includeantruntime&apos; was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds

jar:
     [echo] anttasks
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes/org/apache/hadoop/hive/ant
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/hive-anttasks-0.13.0-SNAPSHOT.jar

init:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

create-dirs:
     [echo] Project: shims
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/test/resources does not exist.

init:
     [echo] Project: shims

create-dirs:
     [echo] Project: common
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/resources
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/resources

init:
     [echo] Project: common

create-dirs:
     [echo] Project: serde
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources does not exist.

init:
     [echo] Project: serde

create-dirs:
     [echo] Project: metastore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources does not exist.

init:
     [echo] Project: metastore

create-dirs:
     [echo] Project: ql
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/resources
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/resources

init:
     [echo] Project: ql

create-dirs:
     [echo] Project: contrib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources does not exist.

init:
     [echo] Project: contrib

create-dirs:
     [echo] Project: service
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources does not exist.

init:
     [echo] Project: service

create-dirs:
     [echo] Project: cli
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/resources does not exist.

init:
     [echo] Project: cli

create-dirs:
     [echo] Project: jdbc
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/test/resources does not exist.

init:
     [echo] Project: jdbc

create-dirs:
     [echo] Project: beeline
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/test/resources does not exist.

init:
     [echo] Project: beeline

create-dirs:
     [echo] Project: hwi
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources does not exist.

init:
     [echo] Project: hwi

create-dirs:
     [echo] Project: hbase-handler
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources does not exist.

init:
     [echo] Project: hbase-handler

create-dirs:
     [echo] Project: testutils
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources does not exist.

init:
     [echo] Project: testutils

init:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build/hcatalog-0.13.0-SNAPSHOT
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/gen/vector/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/gen/vector/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/src/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
[vectorcodegen] Generating vector expression code
[vectorcodegen] Generating vector expression test code

jar:
     [echo] Project: hive

ivy-init-settings:
     [echo] Project: shims

check-ivy:
     [echo] Project: shims

ivy-resolve:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.zookeeper#zookeeper;3.4.3 in maven2
[ivy:resolve] 	found org.apache.thrift#libthrift;0.9.0 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging-api;1.0.4 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.4 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar ...
[ivy:resolve] .............. (749kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.3!zookeeper.jar (19ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar ...
[ivy:resolve] ....... (339kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.thrift#libthrift;0.9.0!libthrift.jar (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar ...
[ivy:resolve] .. (59kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-logging#commons-logging;1.1.1!commons-logging.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging-api/1.0.4/commons-logging-api-1.0.4.jar ...
[ivy:resolve] .. (25kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-logging#commons-logging-api;1.0.4!commons-logging-api.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar ...
[ivy:resolve] ..... (222kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-core-asl;1.8.8!jackson-core-asl.jar (19ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar ...
[ivy:resolve] ............ (652kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-mapper-asl;1.8.8!jackson-mapper-asl.jar (20ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/log4j/log4j/1.2.16/log4j-1.2.16.jar ...
[ivy:resolve] ......... (470kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] log4j#log4j;1.2.16!log4j.jar(bundle) (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/guava/guava/11.0.2/guava-11.0.2.jar ...
[ivy:resolve] ............................ (1609kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.guava#guava;11.0.2!guava.jar (36ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-io/commons-io/2.4/commons-io-2.4.jar ...
[ivy:resolve] .... (180kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-io#commons-io;2.4!commons-io.jar (10ms)
[ivy:resolve] :: resolution report :: resolve 42701ms :: artifacts dl 183ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   9   |   9   |   0   ||   9   |   9   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-shims-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-shims-default.html

make-pom:
     [echo] Project: shims
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: shims
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/test/resources does not exist.

init:
     [echo] Project: shims

ivy-retrieve:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	9 artifacts copied, 0 already retrieved (4309kB/31ms)

compile:
     [echo] Project: shims
     [echo] Building shims 0.20

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20/java against hadoop 0.20.2 (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-0.20.2)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.20.shim]
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-core;0.20.2 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.0.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.3 in maven2
[ivy:resolve] 	found commons-net#commons-net;1.4.1 in maven2
[ivy:resolve] 	found oro#oro;2.0.8 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api-2.5;6.1.14 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.12 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.12 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-api-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.eclipse.jdt#core;3.1.1 in maven2
[ivy:resolve] 	found ant#ant;1.6.5 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.7.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found net.sf.kosmosfs#kfs;0.3 in maven2
[ivy:resolve] 	found junit#junit;4.5 in maven2
[ivy:resolve] 	found hsqldb#hsqldb;1.8.0.10 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-tools;0.20.2 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-test;0.20.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftplet-api;1.0.0 in maven2
[ivy:resolve] 	found org.apache.mina#mina-core;2.0.0-M5 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.5.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-core;1.0.0 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-codec/commons-codec/1.4/commons-codec-1.4.jar ...
[ivy:resolve] .. (56kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-codec#commons-codec;1.4!commons-codec.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-core/0.20.2/hadoop-core-0.20.2.jar ...
[ivy:resolve] .............................................. (2624kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-core;0.20.2!hadoop-core.jar (52ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-tools/0.20.2/hadoop-tools-0.20.2.jar ...
[ivy:resolve] ... (68kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-tools;0.20.2!hadoop-tools.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-test/0.20.2/hadoop-test-0.20.2.jar ...
[ivy:resolve] ......................... (1527kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-test;0.20.2!hadoop-test.jar (56ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-cli/commons-cli/1.2/commons-cli-1.2.jar ...
[ivy:resolve] .. (40kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-cli#commons-cli;1.2!commons-cli.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/xmlenc/xmlenc/0.52/xmlenc-0.52.jar ...
[ivy:resolve] .. (14kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] xmlenc#xmlenc;0.52!xmlenc.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar ...
[ivy:resolve] ...... (273kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-httpclient#commons-httpclient;3.0.1!commons-httpclient.jar (18ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar ...
[ivy:resolve] .... (176kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-net#commons-net;1.4.1!commons-net.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty/6.1.14/jetty-6.1.14.jar ...
[ivy:resolve] ......... (504kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty;6.1.14!jetty.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.14/jetty-util-6.1.14.jar ...
[ivy:resolve] .... (159kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty-util;6.1.14!jetty-util.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar ...
[ivy:resolve] ... (74kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-runtime;5.5.12!jasper-runtime.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar ...
[ivy:resolve] ........ (395kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-compiler;5.5.12!jasper-compiler.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar ...
[ivy:resolve] .... (131kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jsp-api-2.1;6.1.14!jsp-api-2.1.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar ...
[ivy:resolve] .................. (1000kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jsp-2.1;6.1.14!jsp-2.1.jar (27ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-el/commons-el/1.0/commons-el-1.0.jar ...
[ivy:resolve] ... (109kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-el#commons-el;1.0!commons-el.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar ...
[ivy:resolve] ....... (368kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.java.dev.jets3t#jets3t;0.7.1!jets3t.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar ...
[ivy:resolve] .... (129kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#servlet-api-2.5;6.1.14!servlet-api-2.5.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar ...
[ivy:resolve] .. (11kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.sf.kosmosfs#kfs;0.3!kfs.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/4.5/junit-4.5.jar ...
[ivy:resolve] ..... (194kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] junit#junit;4.5!junit.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar ...
[ivy:resolve] ............. (690kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] hsqldb#hsqldb;1.8.0.10!hsqldb.jar (18ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/oro/oro/2.0.8/oro-2.0.8.jar ...
[ivy:resolve] .. (63kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] oro#oro;2.0.8!oro.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar ...
[ivy:resolve] ........................................................................................... (3483kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.eclipse.jdt#core;3.1.1!core.jar (72ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/ant/ant/1.6.5/ant-1.6.5.jar ...
[ivy:resolve] .................. (1009kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] ant#ant;1.6.5!ant.jar (24ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftplet-api/1.0.0/ftplet-api-1.0.0.jar ...
[ivy:resolve] .. (22kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftplet-api;1.0.0!ftplet-api.jar(bundle) (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/mina/mina-core/2.0.0-M5/mina-core-2.0.0-M5.jar ...
[ivy:resolve] ........... (622kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.mina#mina-core;2.0.0-M5!mina-core.jar(bundle) (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftpserver-core/1.0.0/ftpserver-core-1.0.0.jar ...
[ivy:resolve] ...... (264kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftpserver-core;1.0.0!ftpserver-core.jar(bundle) (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftpserver-deprecated/1.0.0-M2/ftpserver-deprecated-1.0.0-M2.jar ...
[ivy:resolve] .. (31kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2!ftpserver-deprecated.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.5.2/slf4j-api-1.5.2.jar ...
[ivy:resolve] .. (16kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-api;1.5.2!slf4j-api.jar (6ms)
[ivy:resolve] :: resolution report :: resolve 97396ms :: artifacts dl 551ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	junit#junit;3.8.1 by [junit#junit;4.5] in [hadoop0.20.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.0.3 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20.shim]
[ivy:resolve] 	commons-httpclient#commons-httpclient;3.1 by [commons-httpclient#commons-httpclient;3.0.1] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M4 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.ftpserver#ftplet-api;1.0.0-M2 by [org.apache.ftpserver#ftplet-api;1.0.0] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.ftpserver#ftpserver-core;1.0.0-M2 by [org.apache.ftpserver#ftpserver-core;1.0.0] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M2 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20.shim]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|  hadoop0.20.shim |   36  |   29  |   29  |   7   ||   29  |   28  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.20.shim]
[ivy:retrieve] 	29 artifacts copied, 0 already retrieved (14126kB/66ms)
    [javac] Compiling 17 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [echo] Building shims 0.20S

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/common-secure/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20S/java against hadoop 1.1.2 (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-1.1.2)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.20S.shim]
[ivy:resolve] 	found org.apache.hadoop#hadoop-core;1.1.2 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-core;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-json;1.8 in maven2
[ivy:resolve] 	found org.codehaus.jettison#jettison;1.1 in maven2
[ivy:resolve] 	found stax#stax-api;1.0.1 in maven2
[ivy:resolve] 	found com.sun.xml.bind#jaxb-impl;2.2.3-1 in maven2
[ivy:resolve] 	found javax.xml.bind#jaxb-api;2.2.2 in maven2
[ivy:resolve] 	found javax.xml.stream#stax-api;1.0-2 in maven2
[ivy:resolve] 	found javax.activation#activation;1.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-jaxrs;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-xc;1.7.1 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-server;1.8 in maven2
[ivy:resolve] 	found asm#asm;3.1 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.1 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.0.1 in maven2
[ivy:resolve] 	found junit#junit;3.8.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.3 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.commons#commons-math;2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found commons-digester#commons-digester;1.8 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils;1.7.0 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils-core;1.8.0 in maven2
[ivy:resolve] 	found commons-net#commons-net;1.4.1 in maven2
[ivy:resolve] 	found oro#oro;2.0.8 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api;2.5-20081211 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.12 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.12 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-api-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api-2.5;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.eclipse.jdt#core;3.1.1 in maven2
[ivy:resolve] 	found ant#ant;1.6.5 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.6.1 in maven2
[ivy:resolve] 	found hsqldb#hsqldb;1.8.0.10 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-tools;1.1.2 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-test;1.1.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftplet-api;1.0.0 in maven2
[ivy:resolve] 	found org.apache.mina#mina-core;2.0.0-M5 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.5.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-core;1.0.0 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-core/1.1.2/hadoop-core-1.1.2.jar ...
[ivy:resolve] .......................................................................................................... (3941kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-core;1.1.2!hadoop-core.jar (79ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-tools/1.1.2/hadoop-tools-1.1.2.jar ...
[ivy:resolve] ...... (299kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-tools;1.1.2!hadoop-tools.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-test/1.1.2/hadoop-test-1.1.2.jar ...
[ivy:resolve] ...................................................... (2712kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-test;1.1.2!hadoop-test.jar (55ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar ...
[ivy:resolve] ........ (447kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-core;1.8!jersey-core.jar(bundle) (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar ...
[ivy:resolve] .... (144kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-json;1.8!jersey-json.jar(bundle) (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar ...
[ivy:resolve] ............. (678kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-server;1.8!jersey-server.jar(bundle) (27ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-io/commons-io/2.1/commons-io-2.1.jar ...
[ivy:resolve] .... (159kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-io#commons-io;2.1!commons-io.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-math/2.1/commons-math-2.1.jar ...
[ivy:resolve] ............... (812kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.commons#commons-math;2.1!commons-math.jar (20ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar ...
[ivy:resolve] ...... (291kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-configuration#commons-configuration;1.6!commons-configuration.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar ...
[ivy:resolve] .......... (527kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty;6.1.26!jetty.jar (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar ...
[ivy:resolve] .... (172kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty-util;6.1.26!jetty-util.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar ...
[ivy:resolve] ...... (314kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.java.dev.jets3t#jets3t;0.6.1!jets3t.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar ...
[ivy:resolve] ... (66kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jettison#jettison;1.1!jettison.jar(bundle) (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar ...
[ivy:resolve] ................ (869kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.xml.bind#jaxb-impl;2.2.3-1!jaxb-impl.jar (21ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.7.1/jackson-jaxrs-1.7.1.jar ...
[ivy:resolve] .. (17kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-jaxrs;1.7.1!jackson-jaxrs.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar ...
[ivy:resolve] .. (30kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-xc;1.7.1!jackson-xc.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/stax/stax-api/1.0.1/stax-api-1.0.1.jar ...
[ivy:resolve] .. (25kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] stax#stax-api;1.0.1!stax-api.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar ...
[ivy:resolve] ... (102kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.xml.bind#jaxb-api;2.2.2!jaxb-api.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar ...
[ivy:resolve] .. (22kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.xml.stream#stax-api;1.0-2!stax-api.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/activation/activation/1.1/activation-1.1.jar ...
[ivy:resolve] .. (61kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.activation#activation;1.1!activation.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/asm/asm/3.1/asm-3.1.jar ...
[ivy:resolve] .. (42kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] asm#asm;3.1!asm.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/3.8.1/junit-3.8.1.jar ...
[ivy:resolve] ... (118kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] junit#junit;3.8.1!junit.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar ...
[ivy:resolve] .......... (561kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-collections#commons-collections;3.2.1!commons-collections.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-digester/commons-digester/1.8/commons-digester-1.8.jar ...
[ivy:resolve] .... (140kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-digester#commons-digester;1.8!commons-digester.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar ...
[ivy:resolve] ..... (201kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-beanutils#commons-beanutils-core;1.8.0!commons-beanutils-core.jar (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar ...
[ivy:resolve] .... (184kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-beanutils#commons-beanutils;1.7.0!commons-beanutils.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar ...
[ivy:resolve] .... (130kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#servlet-api;2.5-20081211!servlet-api.jar (10ms)
[ivy:resolve] :: resolution report :: resolve 40064ms :: artifacts dl 540ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	org.codehaus.jackson#jackson-core-asl;1.7.1 by [org.codehaus.jackson#jackson-core-asl;1.8.8] in [hadoop0.20S.shim]
[ivy:resolve] 	org.codehaus.jackson#jackson-mapper-asl;1.7.1 by [org.codehaus.jackson#jackson-mapper-asl;1.8.8] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.0.3 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-codec#commons-codec;1.2 by [commons-codec#commons-codec;1.4] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.1 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-codec#commons-codec;1.3 by [commons-codec#commons-codec;1.4] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-httpclient#commons-httpclient;3.1 by [commons-httpclient#commons-httpclient;3.0.1] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M4 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.ftpserver#ftplet-api;1.0.0-M2 by [org.apache.ftpserver#ftplet-api;1.0.0] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.ftpserver#ftpserver-core;1.0.0-M2 by [org.apache.ftpserver#ftpserver-core;1.0.0] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M2 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20S.shim]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	| hadoop0.20S.shim |   62  |   29  |   29  |   11  ||   51  |   27  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.20S.shim]
[ivy:retrieve] 	51 artifacts copied, 0 already retrieved (22876kB/110ms)
    [javac] Compiling 15 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [echo] Building shims 0.23

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/common-secure/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.23/java against hadoop 2.1.0-beta (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-2.1.0-beta)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.23.shim]
[ivy:resolve] 	found org.apache.hadoop#hadoop-common;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-annotations;2.1.0-beta in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-math;2.1 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.1 in maven2
[ivy:resolve] 	found commons-net#commons-net;3.1 in maven2
[ivy:resolve] 	found javax.servlet#servlet-api;2.5 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.26 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-core;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-json;1.8 in maven2
[ivy:resolve] 	found org.codehaus.jettison#jettison;1.1 in maven2
[ivy:resolve] 	found stax#stax-api;1.0.1 in maven2
[ivy:resolve] 	found com.sun.xml.bind#jaxb-impl;2.2.3-1 in maven2
[ivy:resolve] 	found javax.xml.bind#jaxb-api;2.2.2 in maven2
[ivy:resolve] 	found javax.activation#activation;1.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-jaxrs;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-xc;1.8.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-server;1.8 in maven2
[ivy:resolve] 	found asm#asm;3.2 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.17 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.6.1 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.5 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-digester#commons-digester;1.8 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils;1.7.0 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils-core;1.8.0 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.5.3 in maven2
[ivy:resolve] 	found com.thoughtworks.paranamer#paranamer;2.3 in maven2
[ivy:resolve] 	found org.xerial.snappy#snappy-java;1.0.3.2 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.5.0 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-auth;2.1.0-beta in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found com.jcraft#jsch;0.1.42 in maven2
[ivy:resolve] 	found org.apache.zookeeper#zookeeper;3.4.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.23 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.23 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found javax.servlet.jsp#jsp-api;2.1 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-core;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-common;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-api;2.1.0-beta in maven2
[ivy:resolve] 	found com.google.inject.extensions#guice-servlet;3.0 in maven2
[ivy:resolve] 	found com.google.inject#guice;3.0 in maven2
[ivy:resolve] 	found javax.inject#javax.inject;1 in maven2
[ivy:resolve] 	found aopalliance#aopalliance;1.0 in maven2
[ivy:resolve] 	found org.sonatype.sisu.inject#cglib;2.2.1-v20090111 in maven2
[ivy:resolve] 	found io.netty#netty;3.5.11.Final in maven2
[ivy:resolve] 	found com.sun.jersey.jersey-test-framework#jersey-test-framework-grizzly2;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey.contribs#jersey-guice;1.8 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-archives;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-hdfs;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-common;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-client;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-common;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-tests;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-nodemanager;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-resourcemanager;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-web-proxy;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-app;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-hs;2.1.0-beta in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.1.0-beta/hadoop-common-2.1.0-beta.jar ...
[ivy:resolve] ............................................. (2656kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-common;2.1.0-beta!hadoop-common.jar (68ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.1.0-beta/hadoop-common-2.1.0-beta-tests.jar ...
[ivy:resolve] ....................... (1321kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-common;2.1.0-beta!hadoop-common.jar(tests) (37ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-core/2.1.0-beta/hadoop-mapreduce-client-core-2.1.0-beta.jar ...
[ivy:resolve] ....................... (1340kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-core;2.1.0-beta!hadoop-mapreduce-client-core.jar (45ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-archives/2.1.0-beta/hadoop-archives-2.1.0-beta.jar ...
[ivy:resolve] .. (20kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-archives;2.1.0-beta!hadoop-archives.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.1.0-beta/hadoop-hdfs-2.1.0-beta.jar ...
[ivy:resolve] ................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. (5092kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs;2.1.0-beta!hadoop-hdfs.jar (369ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.1.0-beta/hadoop-hdfs-2.1.0-beta-tests.jar ...
[ivy:resolve] ................................ (1897kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs;2.1.0-beta!hadoop-hdfs.jar(tests) (48ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.1.0-beta/hadoop-mapreduce-client-jobclient-2.1.0-beta.jar ...
[ivy:resolve] .. (33kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.1.0-beta!hadoop-mapreduce-client-jobclient.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.1.0-beta/hadoop-mapreduce-client-jobclient-2.1.0-beta-tests.jar ...
[ivy:resolve] ........................ (1395kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.1.0-beta!hadoop-mapreduce-client-jobclient.jar(tests) (43ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-common/2.1.0-beta/hadoop-mapreduce-client-common-2.1.0-beta.jar ...
[ivy:resolve] ........... (638kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-common;2.1.0-beta!hadoop-mapreduce-client-common.jar (22ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-tests/2.1.0-beta/hadoop-yarn-server-tests-2.1.0-beta-tests.jar ...
[ivy:resolve] .. (33kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-tests;2.1.0-beta!hadoop-yarn-server-tests.jar(tests) (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-app/2.1.0-beta/hadoop-mapreduce-client-app-2.1.0-beta.jar ...
[ivy:resolve] ......... (461kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-app;2.1.0-beta!hadoop-mapreduce-client-app.jar (27ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-hs/2.1.0-beta/hadoop-mapreduce-client-hs-2.1.0-beta.jar ...
[ivy:resolve] ... (113kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-hs;2.1.0-beta!hadoop-mapreduce-client-hs.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-annotations/2.1.0-beta/hadoop-annotations-2.1.0-beta.jar ...
[ivy:resolve] .. (16kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-annotations;2.1.0-beta!hadoop-annotations.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar ...
[ivy:resolve] ...... (297kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-httpclient#commons-httpclient;3.1!commons-httpclient.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-net/commons-net/3.1/commons-net-3.1.jar ...
[ivy:resolve] ...... (266kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-net#commons-net;3.1!commons-net.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar ...
[ivy:resolve] ... (102kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.servlet#servlet-api;2.5!servlet-api.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/log4j/log4j/1.2.17/log4j-1.2.17.jar ...
[ivy:resolve] ......... (478kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] log4j#log4j;1.2.17!log4j.jar(bundle) (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-lang/commons-lang/2.5/commons-lang-2.5.jar ...
[ivy:resolve] ...... (272kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-lang#commons-lang;2.5!commons-lang.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar ...
[ivy:resolve] .. (24kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-api;1.6.1!slf4j-api.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro/1.5.3/avro-1.5.3.jar ...
[ivy:resolve] ...... (257kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro;1.5.3!avro.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar ...
[ivy:resolve] .......... (520kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.protobuf#protobuf-java;2.5.0!protobuf-java.jar(bundle) (31ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-auth/2.1.0-beta/hadoop-auth-2.1.0-beta.jar ...
[ivy:resolve] .. (46kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-auth;2.1.0-beta!hadoop-auth.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar ...
[ivy:resolve] .... (181kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.jcraft#jsch;0.1.42!jsch.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.2/zookeeper-3.4.2.jar ...
[ivy:resolve] ............. (746kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.2!zookeeper.jar (19ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-compress/1.4/commons-compress-1.4.jar ...
[ivy:resolve] ..... (233kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.commons#commons-compress;1.4!commons-compress.jar (27ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar ...
[ivy:resolve] .. (32kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.code.findbugs#jsr305;1.3.9!jsr305.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.8.8/jackson-jaxrs-1.8.8.jar ...
[ivy:resolve] .. (17kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-jaxrs;1.8.8!jackson-jaxrs.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.8.8/jackson-xc-1.8.8.jar ...
[ivy:resolve] .. (31kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-xc;1.8.8!jackson-xc.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/asm/asm/3.2/asm-3.2.jar ...
[ivy:resolve] .. (42kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] asm#asm;3.2!asm.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar ...
[ivy:resolve] .. (28kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.3!paranamer.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.0.3.2/snappy-java-1.0.3.2.jar ...
[ivy:resolve] ................. (972kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.0.3.2!snappy-java.jar(bundle) (22ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar ...
[ivy:resolve] .. (9kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-log4j12;1.6.1!slf4j-log4j12.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/tukaani/xz/1.0/xz-1.0.jar ...
[ivy:resolve] ... (92kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.tukaani#xz;1.0!xz.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar ...
[ivy:resolve] ........ (398kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-compiler;5.5.23!jasper-compiler.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar ...
[ivy:resolve] ... (75kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-runtime;5.5.23!jasper-runtime.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar ...
[ivy:resolve] ... (98kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.servlet.jsp#jsp-api;2.1!jsp-api.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-common/2.1.0-beta/hadoop-yarn-common-2.1.0-beta.jar ...
[ivy:resolve] ..................... (1263kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-common;2.1.0-beta!hadoop-yarn-common.jar (44ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar ...
[ivy:resolve] .. (63kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.inject.extensions#guice-servlet;3.0!guice-servlet.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/io/netty/netty/3.5.11.Final/netty-3.5.11.Final.jar ...
[ivy:resolve] ................... (1106kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] io.netty#netty;3.5.11.Final!netty.jar(bundle) (26ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-api/2.1.0-beta/hadoop-yarn-api-2.1.0-beta.jar ...
[ivy:resolve] ................... (1125kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-api;2.1.0-beta!hadoop-yarn-api.jar (29ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/inject/guice/3.0/guice-3.0.jar ...
[ivy:resolve] ............ (693kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.inject#guice;3.0!guice.jar (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-test-framework/jersey-test-framework-grizzly2/1.8/jersey-test-framework-grizzly2-1.8.jar ...
[ivy:resolve] .. (12kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey.jersey-test-framework#jersey-test-framework-grizzly2;1.8!jersey-test-framework-grizzly2.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/contribs/jersey-guice/1.8/jersey-guice-1.8.jar ...
[ivy:resolve] .. (14kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey.contribs#jersey-guice;1.8!jersey-guice.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/inject/javax.inject/1/javax.inject-1.jar ...
[ivy:resolve] .. (2kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.inject#javax.inject;1!javax.inject.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/aopalliance/aopalliance/1.0/aopalliance-1.0.jar ...
[ivy:resolve] .. (4kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] aopalliance#aopalliance;1.0!aopalliance.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/sonatype/sisu/inject/cglib/2.2.1-v20090111/cglib-2.2.1-v20090111.jar ...
[ivy:resolve] ...... (272kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.sonatype.sisu.inject#cglib;2.2.1-v20090111!cglib.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-client/2.1.0-beta/hadoop-yarn-client-2.1.0-beta.jar ...
[ivy:resolve] ... (84kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-client;2.1.0-beta!hadoop-yarn-client.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-common/2.1.0-beta/hadoop-yarn-server-common-2.1.0-beta.jar ...
[ivy:resolve] .... (171kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-common;2.1.0-beta!hadoop-yarn-server-common.jar (26ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.1.0-beta/hadoop-yarn-server-nodemanager-2.1.0-beta.jar ...
[ivy:resolve] ......... (451kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-nodemanager;2.1.0-beta!hadoop-yarn-server-nodemanager.jar (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.1.0-beta/hadoop-yarn-server-resourcemanager-2.1.0-beta.jar ...
[ivy:resolve] ........... (585kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-resourcemanager;2.1.0-beta!hadoop-yarn-server-resourcemanager.jar (20ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.1.0-beta/hadoop-yarn-server-web-proxy-2.1.0-beta.jar ...
[ivy:resolve] .. (24kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-web-proxy;2.1.0-beta!hadoop-yarn-server-web-proxy.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.1.0-beta/hadoop-mapreduce-client-shuffle-2.1.0-beta.jar ...
[ivy:resolve] .. (21kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.1.0-beta!hadoop-mapreduce-client-shuffle.jar (74ms)
[ivy:resolve] :: resolution report :: resolve 81228ms :: artifacts dl 1422ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|  hadoop0.23.shim |   75  |   49  |   49  |   0   ||   78  |   52  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.23.shim]
[ivy:retrieve] 	78 artifacts copied, 0 already retrieved (34675kB/132ms)
    [javac] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.23/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.

jar:
     [echo] Project: shims
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Wed Oct 16 09:57:42 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-shims
[ivy:publish] 	published hive-shims to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.13.0-SNAPSHOT/jars/hive-shims.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: common

check-ivy:
     [echo] Project: common

ivy-resolve:
     [echo] Project: common
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-common;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.13.0-SNAPSHOT/jars/hive-shims.jar ...
[ivy:resolve] .... (145kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-shims;0.13.0-SNAPSHOT!hive-shims.jar (4ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar ...
[ivy:resolve] ..... (235kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.commons#commons-compress;1.4.1!commons-compress.jar (9ms)
[ivy:resolve] :: resolution report :: resolve 1668ms :: artifacts dl 19ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   6   |   2   |   2   |   0   ||   6   |   2   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-common-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-common-default.html

make-pom:
     [echo] Project: common
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/common/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: common

init:
     [echo] Project: common

setup:
     [echo] Project: common

ivy-retrieve:
     [echo] Project: common
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-common
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	4 artifacts copied, 2 already retrieved (513kB/14ms)

compile:
     [echo] Project: common
    [javac] Compiling 27 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/common/src/java/org/apache/hadoop/hive/common/ObjectPair.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes

jar:
     [echo] Project: common
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/common/hive-common-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-common;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Wed Oct 16 09:57:48 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/common/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-common
[ivy:publish] 	published hive-common to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.13.0-SNAPSHOT/jars/hive-common.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: serde

check-ivy:
     [echo] Project: serde

ivy-resolve:
     [echo] Project: serde
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-serde;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-common;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.13.0-SNAPSHOT/jars/hive-common.jar ...
[ivy:resolve] ... (98kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-common;0.13.0-SNAPSHOT!hive-common.jar (4ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar ...
[ivy:resolve] ...................... (1315kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mockito#mockito-all;1.8.2!mockito-all.jar (28ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar ...
[ivy:resolve] ...... (268kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.thrift#libfb303;0.9.0!libfb303.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro/1.7.1/avro-1.7.1.jar ...
[ivy:resolve] ...... (290kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro;1.7.1!avro.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar ...
[ivy:resolve] .... (164kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro-mapred;1.7.1!avro-mapred.jar (18ms)
[ivy:resolve] :: resolution report :: resolve 9287ms :: artifacts dl 82ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   14  |   5   |   5   |   0   ||   14  |   5   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-serde-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-serde-default.html

make-pom:
     [echo] Project: serde
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: serde
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources does not exist.

init:
     [echo] Project: serde

ivy-retrieve:
     [echo] Project: serde
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-serde
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	8 artifacts copied, 6 already retrieved (2230kB/18ms)

dynamic-serde:

compile:
     [echo] Project: serde
    [javac] Compiling 338 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes/org/apache/hadoop/hive/serde2/typeinfo/package-info.class

jar:
     [echo] Project: serde
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/hive-serde-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-serde;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Wed Oct 16 09:58:10 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-serde
[ivy:publish] 	published hive-serde to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.13.0-SNAPSHOT/jars/hive-serde.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: metastore

check-ivy:
     [echo] Project: metastore

ivy-resolve:
     [echo] Project: metastore
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-metastore;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.13.0-SNAPSHOT/jars/hive-serde.jar ...
[ivy:resolve] ............ (687kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-serde;0.13.0-SNAPSHOT!hive-serde.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/antlr/3.4/antlr-3.4.jar ...
[ivy:resolve] .................. (1086kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.antlr#antlr;3.4!antlr.jar (26ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar ...
[ivy:resolve] .... (160kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.antlr#antlr-runtime;3.4!antlr-runtime.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/ST4/4.0.4/ST4-4.0.4.jar ...
[ivy:resolve] ..... (231kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.antlr#ST4;4.0.4!ST4.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar ...
[ivy:resolve] ... (112kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.jolbox#bonecp;0.7.1.RELEASE!bonecp.jar(bundle) (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar ...
[ivy:resolve] ... (93kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-pool#commons-pool;1.5.4!commons-pool.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar ...
[ivy:resolve] ....... (329kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.datanucleus#datanucleus-api-jdo;3.2.1!datanucleus-api-jdo.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar ...
[ivy:resolve] .............................. (1759kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.datanucleus#datanucleus-core;3.2.2!datanucleus-core.jar (36ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar ...
[ivy:resolve] ............................. (1728kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.datanucleus#datanucleus-rdbms;3.2.1!datanucleus-rdbms.jar (45ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar ...
[ivy:resolve] ..... (196kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.jdo#jdo-api;3.0.1!jdo-api.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar ...
[ivy:resolve] ........................................ (2389kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.derby#derby;10.4.2.0!derby.jar (46ms)
[ivy:resolve] :: resolution report :: resolve 13644ms :: artifacts dl 237ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   26  |   11  |   11  |   1   ||   25  |   11  |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-metastore-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-metastore-default.html

make-pom:
     [echo] Project: metastore
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: metastore
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources does not exist.

init:
     [echo] Project: metastore

metastore-init:
     [echo] Project: metastore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/gen/antlr/gen-java/org/apache/hadoop/hive/metastore/parser

ivy-retrieve:
     [echo] Project: metastore
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-metastore
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	11 artifacts copied, 14 already retrieved (8775kB/37ms)

build-grammar:
     [echo] Project: metastore
     [echo] Building Grammar /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g  ....

model-compile:
     [echo] Project: metastore
    [javac] Compiling 25 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes

core-compile:
     [echo] Project: metastore
    [javac] Compiling 107 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes/org/apache/hadoop/hive/metastore/parser/package-info.class

model-enhance:
     [echo] Project: metastore
[datanucleusenhancer] log4j:WARN No appenders could be found for logger (DataNucleus.General).
[datanucleusenhancer] log4j:WARN Please initialize the log4j system properly.
[datanucleusenhancer] log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
[datanucleusenhancer] DataNucleus Enhancer (version 3.2.2) for API &quot;JDO&quot; using JRE &quot;1.6&quot;
[datanucleusenhancer] DataNucleus Enhancer : Classpath
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/hive-anttasks-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/common/hive-common-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/serde/hive-serde-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/activation-1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ant-1.6.5.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/asm-3.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-beanutils-1.7.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-beanutils-core-1.8.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-cli-1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-codec-1.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-collections-3.2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-configuration-1.6.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-digester-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-el-1.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-httpclient-3.0.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-io-2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-lang-2.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-logging-1.1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-math-2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-net-1.4.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/core-3.1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftplet-api-1.0.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftpserver-core-1.0.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftpserver-deprecated-1.0.0-M2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-core-1.1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-test-1.1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-tools-1.1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hsqldb-1.8.0.10.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-core-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-jaxrs-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-mapper-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-xc-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jasper-compiler-5.5.12.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jasper-runtime-5.5.12.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jaxb-api-2.2.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jaxb-impl-2.2.3-1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-core-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-json-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-server-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jets3t-0.6.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jettison-1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jetty-6.1.26.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jetty-util-6.1.26.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jsp-2.1-6.1.14.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jsp-api-2.1-6.1.14.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/junit-3.8.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/mina-core-2.0.0-M5.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/oro-2.0.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/servlet-api-2.5-20081211.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/servlet-api-2.5-6.1.14.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/slf4j-api-1.5.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/stax-api-1.0-2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/stax-api-1.0.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/xmlenc-0.52.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/ST4-4.0.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/antlr-3.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/antlr-runtime-3.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-mapred-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/bonecp-0.7.1.RELEASE.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-cli-1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-codec-1.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-compress-1.4.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-io-2.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-lang-2.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-logging-1.1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-logging-api-1.0.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-pool-1.5.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-api-jdo-3.2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-core-3.2.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-rdbms-3.2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/derby-10.4.2.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/guava-11.0.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-common-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-serde-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-shims-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-core-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-mapper-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jdo-api-3.0.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libfb303-0.9.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libthrift-0.9.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/log4j-1.2.16.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/mockito-all-1.8.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/slf4j-api-1.6.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/slf4j-log4j12-1.6.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/velocity-1.5.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/xz-1.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/zookeeper-3.4.3.jar
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDatabase
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFieldSchema
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MType
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTable
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MOrder
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStringList
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartition
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MIndex
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRole
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRoleMap
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MMasterKey
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDelegationToken
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MVersionTable
[datanucleusenhancer] DataNucleus Enhancer completed with success for 25 classes. Timings : input=702 ms, enhance=1169 ms, total=1871 ms. Consult the log for full details

compile:
     [echo] Project: metastore

jar:
     [echo] Project: metastore
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/hive-metastore-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-metastore;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Wed Oct 16 09:58:53 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-metastore
[ivy:publish] 	published hive-metastore to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.13.0-SNAPSHOT/jars/hive-metastore.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: ql

check-ivy:
     [echo] Project: ql

ivy-resolve:
     [echo] Project: ql
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-exec;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.5.0 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found com.esotericsoftware.kryo#kryo;2.22 in maven2
[ivy:resolve] 	found org.codehaus.groovy#groovy-all;2.1.6 in maven2
[ivy:resolve] 	found org.apache.ant#ant;1.8.4 in maven2
[ivy:resolve] 	found org.apache.ant#ant-launcher;1.8.4 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.13.0-SNAPSHOT/jars/hive-metastore.jar ...
[ivy:resolve] ...................................................... (3330kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-metastore;0.13.0-SNAPSHOT!hive-metastore.jar (80ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/iq80/snappy/snappy/0.2/snappy-0.2.jar ...
[ivy:resolve] .. (47kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.iq80.snappy#snappy;0.2!snappy.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/esotericsoftware/kryo/kryo/2.22/kryo-2.22.jar ...
[ivy:resolve] ........ (432kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.esotericsoftware.kryo#kryo;2.22!kryo.jar(bundle) (21ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/groovy/groovy-all/2.1.6/groovy-all-2.1.6.jar ...
[ivy:resolve] ......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................... (6227kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.groovy#groovy-all;2.1.6!groovy-all.jar (479ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ant/ant/1.8.4/ant-1.8.4.jar ...
[ivy:resolve] ................................ (1896kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ant#ant;1.8.4!ant.jar (54ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/json/json/20090211/json-20090211.jar ...
[ivy:resolve] .. (44kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.json#json;20090211!json.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar ...
[ivy:resolve] .. (16kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.googlecode.javaewah#JavaEWAH;0.3.2!JavaEWAH.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javolution/javolution/5.5.1/javolution-5.5.1.jar ...
[ivy:resolve] ........ (385kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javolution#javolution;5.5.1!javolution.jar(bundle) (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/jline/jline/0.9.94/jline-0.9.94.jar ...
[ivy:resolve] ... (85kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] jline#jline;0.9.94!jline.jar (51ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ant/ant-launcher/1.8.4/ant-launcher-1.8.4.jar ...
[ivy:resolve] .. (17kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ant#ant-launcher;1.8.4!ant-launcher.jar (20ms)
[ivy:resolve] :: resolution report :: resolve 21584ms :: artifacts dl 778ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   40  |   10  |   10  |   1   ||   39  |   10  |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-exec-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-exec-default.html

make-pom:
     [echo] Project: ql
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: ql

init:
     [echo] Project: ql

ql-init:
     [echo] Project: ql
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/gen/antlr/gen-java/org/apache/hadoop/hive/ql/parse

ivy-retrieve:
     [echo] Project: ql
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-exec
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	13 artifacts copied, 26 already retrieved (13860kB/43ms)

build-grammar:
     [echo] Project: ql
     [echo] Building Grammar /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g  ....
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:872:5: 
     [java] Decision can match input such as &quot;Identifier KW_RENAME KW_TO&quot; using multiple alternatives: 1, 10
     [java] 
     [java] As a result, alternative(s) 10 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:5: 
     [java] Decision can match input such as &quot;KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:5: 
     [java] Decision can match input such as &quot;KW_ORCFILE&quot; using multiple alternatives: 4, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:5: 
     [java] Decision can match input such as &quot;KW_RCFILE&quot; using multiple alternatives: 3, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:5: 
     [java] Decision can match input such as &quot;KW_TEXTFILE&quot; using multiple alternatives: 2, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1190:23: 
     [java] Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1190:23: 
     [java] Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1190:23: 
     [java] Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1197:23: 
     [java] Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1197:23: 
     [java] Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1197:23: 
     [java] Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
     [java] Decision can match input such as &quot;KW_PRETTY Identifier&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
     [java] Decision can match input such as &quot;KW_PRETTY KW_PARTITION&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
     [java] Decision can match input such as &quot;KW_FORMATTED {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
     [java] Decision can match input such as &quot;KW_PRETTY {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
     [java] Decision can match input such as &quot;KW_FORMATTED Identifier&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
     [java] Decision can match input such as &quot;KW_FORMATTED KW_PARTITION&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1499:116: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_DIRECTORIES&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1622:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_RCFILE&quot; using multiple alternatives: 3, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1622:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1622:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_INPUTFORMAT&quot; using multiple alternatives: 5, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1622:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_TEXTFILE&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1622:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_ORCFILE&quot; using multiple alternatives: 4, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): SelectClauseParser.g:149:5: 
     [java] Decision can match input such as &quot;KW_NULL DOT Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): SelectClauseParser.g:149:5: 
     [java] Decision can match input such as &quot;KW_NULL DOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:127:2: 
     [java] Decision can match input such as &quot;KW_LATERAL KW_VIEW KW_OUTER&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:25: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral EQUAL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:25: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral RPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:25: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral COMMA&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL EQUAL_NS&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL EQUAL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LESSTHANOREQUALTO&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL NOTEQUAL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL GREATERTHANOREQUALTO&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LESSTHAN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL GREATERTHAN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL {DIV..DIVIDE, MOD, STAR}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL {MINUS, PLUS}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_IN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL DOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL RPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL AMPERSAND&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_DATE StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_BETWEEN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_IS&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL {KW_LIKE, KW_REGEXP, KW_RLIKE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LSQUARE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN CharSetName CharSetLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_WHEN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL BITWISEXOR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CAST LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_AND&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_OR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL BITWISEOR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:108:5: 
     [java] Decision can match input such as &quot;KW_ORDER KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:121:5: 
     [java] Decision can match input such as &quot;KW_CLUSTER KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:133:5: 
     [java] Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:144:5: 
     [java] Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:155:5: 
     [java] Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:172:7: 
     [java] Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:185:5: 
     [java] Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): IdentifiersParser.g:185:5: 
     [java] Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): IdentifiersParser.g:185:5: 
     [java] Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_DATE StringLiteral&quot; using multiple alternatives: 2, 3
     [java] 
     [java] As a result, alternative(s) 3 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 3, 8
     [java] 
     [java] As a result, alternative(s) 8 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 3, 8
     [java] 
     [java] As a result, alternative(s) 8 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 8
     [java] 
     [java] As a result, alternative(s) 8 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 6, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:514:5: 
     [java] Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3
     [java] 
     [java] As a result, alternative(s) 3 were disabled for that input

compile:
     [echo] Project: ql
    [javac] Compiling 1351 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java:1230: cannot find symbol
    [javac] symbol  : method getCurrentDatabase()
    [javac] location: class org.apache.hadoop.hive.ql.metadata.Hive
    [javac]     return getTable(db.getCurrentDatabase(), tblName, throwException);
    [javac]                       ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java:1236: cannot find symbol
    [javac] symbol  : method getCurrentDatabase()
    [javac] location: class org.apache.hadoop.hive.ql.metadata.Hive
    [javac]       return getTable(db.getCurrentDatabase(), qnName, throwException);
    [javac]                         ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] 2 errors

BUILD FAILED
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:338: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:166: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:168: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/ql/build.xml:198: Compile failed; see the compiler error output for details.

Total time: 7 minutes 9 seconds
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13839983" author="hiveqa" created="Thu, 5 Dec 2013 09:54:25 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12617123/HIVE-2093.7.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12617123/HIVE-2093.7.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 4463 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestHBaseNegativeCliDriver.testCliDriver_cascade_dbdrop_hadoop20
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/529/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/529/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/529/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/529/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12617123&lt;/p&gt;</comment>
                            <comment id="13840943" author="phabricator@reviews.facebook.net" created="Fri, 6 Dec 2013 04:05:37 +0000"  >&lt;p&gt;thejas has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; title=&quot;create/drop database should populate inputs/outputs and check concurrency and user permission&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2093&quot;&gt;&lt;del&gt;HIVE-2093&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; create/drop database should populate inputs/outputs and check concurrency and user permission&quot;.&lt;/p&gt;

&lt;p&gt;  I have reviewed half of it, looks good mostly. I will complete the review tomorrow.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/Driver.java:510 What is the basis of the SQLState value ? what does it mean?&lt;br/&gt;
  Isn&apos;t class 01 warning ? But this is an error.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/Driver.java:737 can you update the javadoc for this param ?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12807&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12807&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: thejas&lt;/p&gt;</comment>
                            <comment id="13841015" author="hiveqa" created="Fri, 6 Dec 2013 06:11:50 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12617281/HIVE-2093.8.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12617281/HIVE-2093.8.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4436 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/539/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/539/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/539/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/539/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12617281&lt;/p&gt;</comment>
                            <comment id="13841839" author="phabricator@reviews.facebook.net" created="Fri, 6 Dec 2013 22:55:39 +0000"  >&lt;p&gt;thejas has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; title=&quot;create/drop database should populate inputs/outputs and check concurrency and user permission&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2093&quot;&gt;&lt;del&gt;HIVE-2093&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; create/drop database should populate inputs/outputs and check concurrency and user permission&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java:257 why not return the location uri here ?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java:1233 what qnName means becomes clear only after reading the code, can you expand the variable name or add a javadoc comment ?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java:2290 can you update comment to say &quot;SHOW LOCKS DATABASE &lt;span class=&quot;error&quot;&gt;&amp;#91;database&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;extended&amp;#93;&lt;/span&gt;&quot;&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/ExportSemanticAnalyzer.java:104 you can use - new Path(toURI)&lt;br/&gt;
  Its there since hadoop 0.20.2&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java:83 why is this block of changes needed ?&lt;br/&gt;
  It does not seem to be used anyway. I think the separation between entity and privileges is a good thing.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12807&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12807&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: thejas&lt;/p&gt;</comment>
                            <comment id="13841841" author="thejas" created="Fri, 6 Dec 2013 22:56:48 +0000"  >&lt;p&gt;I have added some comments on reviewboard.&lt;br/&gt;
Is there a way to grant these permissions for the database ? Specifically the global create permission needed for creating databases. Is that a follow-up work ?&lt;/p&gt;</comment>
                            <comment id="13841854" author="thejas" created="Fri, 6 Dec 2013 23:09:48 +0000"  >&lt;p&gt;btw, thanks for these changes to improve the authorization codebase!&lt;/p&gt;</comment>
                            <comment id="13843900" author="phabricator@reviews.facebook.net" created="Tue, 10 Dec 2013 03:24:27 +0000"  >&lt;p&gt;navis has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; title=&quot;create/drop database should populate inputs/outputs and check concurrency and user permission&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2093&quot;&gt;&lt;del&gt;HIVE-2093&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; create/drop database should populate inputs/outputs and check concurrency and user permission&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/Driver.java:510 I&apos;ve copied it from somewhere, forget where it was. Could you suggest better state code?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/Driver.java:737 Ah, sure.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java:257 This method seemed not used in anywhere in current codebase, so it&apos;s hard to say the intent of initial contributor(Siying Dong). But this method seemed useful and I&apos;ll change it to return URI for database, too.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java:83 Some complex operations like &quot;import&quot; need different privilege checks with that of initiative operation. I think this part is from &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2818&quot; title=&quot;Create table should check privilege of target database, not default database&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2818&quot;&gt;&lt;del&gt;HIVE-2818&lt;/del&gt;&lt;/a&gt; and mistakenly mixed with this issue. I&apos;ll remove it.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java:2290 ok.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java:1233 ok.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/ExportSemanticAnalyzer.java:104 ok.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12807&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12807&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: thejas&lt;/p&gt;</comment>
                            <comment id="13843998" author="phabricator@reviews.facebook.net" created="Tue, 10 Dec 2013 06:26:15 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; title=&quot;create/drop database should populate inputs/outputs and check concurrency and user permission&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2093&quot;&gt;&lt;del&gt;HIVE-2093&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; create/drop database should populate inputs/outputs and check concurrency and user permission&quot;.&lt;/p&gt;

&lt;p&gt;  addressed comments&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12807&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12807&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12807?vs=41577&amp;amp;id=45177#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12807?vs=41577&amp;amp;id=45177#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  hbase-handler/src/test/results/negative/cascade_dbdrop_hadoop20.q.out&lt;br/&gt;
  hcatalog/core/src/main/java/org/apache/hcatalog/security/HdfsAuthorizationProvider.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/Driver.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/hooks/ReadEntity.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/hooks/WriteEntity.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/ExportSemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/LockDatabaseDesc.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ShowLocksDesc.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/UnlockDatabaseDesc.java&lt;br/&gt;
  ql/src/test/queries/clientnegative/authorization_fail_create_db.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/authorization_fail_drop_db.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/lockneg_query_tbl_in_locked_db.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/lockneg_try_db_lock_conflict.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/lockneg_try_drop_locked_db.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/lockneg_try_lock_db_in_use.q&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_2.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_3.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_4.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_5.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_6.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_7.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_create_db.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_fail_drop_db.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/authorization_part.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/database_drop_does_not_exist.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/database_drop_not_empty.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/database_drop_not_empty_restrict.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_22_export_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_23_import_exist_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_24_import_part_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/exim_25_import_nonexist_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/join_nonexistent_part.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/load_exist_part_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/load_nonpart_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/load_part_authfail.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/lockneg_query_tbl_in_locked_db.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/lockneg_try_db_lock_conflict.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/lockneg_try_drop_locked_db.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/lockneg_try_lock_db_in_use.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/alter1.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/alter2.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/alter4.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/authorization_5.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/database.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/database_drop.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/describe_database_json.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/drop_database_removes_partition_dirs.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_00_nonpart_empty.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_01_nonpart.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_02_00_part_empty.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_02_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_03_nonpart_over_compat.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_04_all_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_04_evolved_parts.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_05_some_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_06_one_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_07_all_part_over_nonoverlap.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_08_nonpart_rename.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_09_part_spec_nonoverlap.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_10_external_managed.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_11_managed_external.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_12_external_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_13_managed_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_14_managed_location_over_existing.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_15_external_part.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_16_part_external.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_17_part_managed.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_18_part_external.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_19_00_part_external_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_19_part_external_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_20_part_managed_location.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_22_import_exist_authsuccess.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_23_import_part_authsuccess.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/exim_24_import_nonexist_authsuccess.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/input46.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/insert2_overwrite_partitions.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/show_create_table_db_table.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: thejas&lt;/p&gt;</comment>
                            <comment id="13844138" author="hiveqa" created="Tue, 10 Dec 2013 09:39:10 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12617996/D12807.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12617996/D12807.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 4767 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.ql.security.TestClientSideAuthorizationProvider.testSimplePrivileges
org.apache.hadoop.hive.ql.security.TestMetastoreAuthorizationProvider.testSimplePrivileges
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/596/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/596/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/596/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/596/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12617996&lt;/p&gt;</comment>
                            <comment id="13845148" author="hiveqa" created="Wed, 11 Dec 2013 07:18:35 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12618162/HIVE-2093.9.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12618162/HIVE-2093.9.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4768 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/608/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/608/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/608/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/608/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12618162&lt;/p&gt;</comment>
                            <comment id="13846046" author="phabricator@reviews.facebook.net" created="Thu, 12 Dec 2013 04:03:14 +0000"  >&lt;p&gt;thejas has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2093&quot; title=&quot;create/drop database should populate inputs/outputs and check concurrency and user permission&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2093&quot;&gt;&lt;del&gt;HIVE-2093&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; create/drop database should populate inputs/outputs and check concurrency and user permission&quot;.&lt;/p&gt;

&lt;p&gt;  +1&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12807&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12807&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: thejas&lt;/p&gt;</comment>
                            <comment id="13846956" author="thejas" created="Fri, 13 Dec 2013 00:14:10 +0000"  >&lt;p&gt;Patch committed to trunk. Thanks for the contribution &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt;!&lt;br/&gt;
Can you please update the release note section so that we can add that to wiki docs ? (If you prefer, you can also update the wiki docs directly)&lt;/p&gt;</comment>
                            <comment id="13847104" author="hagleitn" created="Fri, 13 Dec 2013 03:14:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; This is breaking the build. I think you might have forgotten to add some files (UnlockDatabaseDesc/LockDatabaseDesc)?&lt;/p&gt;</comment>
                            <comment id="13847110" author="hagleitn" created="Fri, 13 Dec 2013 03:21:27 +0000"  >&lt;p&gt;I think it&apos;s just the two files. I will commit those (from patch .9)&lt;/p&gt;</comment>
                            <comment id="13847113" author="hagleitn" created="Fri, 13 Dec 2013 03:23:14 +0000"  >&lt;p&gt;Committed UnlockDatabaseDesc and LockDatabaseDesc. Build is working again for me.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12543930">HIVE-2818</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12542958">HIVE-2809</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12608631" name="D12807.3.patch" size="103279" author="phabricator@reviews.facebook.net" created="Wed, 16 Oct 2013 01:42:44 +0000"/>
                            <attachment id="12617996" name="D12807.4.patch" size="104990" author="phabricator@reviews.facebook.net" created="Tue, 10 Dec 2013 06:26:15 +0000"/>
                            <attachment id="12477447" name="HIVE-2093.6.patch" size="399097" author="sdong" created="Tue, 26 Apr 2011 21:55:47 +0000"/>
                            <attachment id="12617123" name="HIVE-2093.7.patch.txt" size="113287" author="navis" created="Thu, 5 Dec 2013 07:20:29 +0000"/>
                            <attachment id="12617281" name="HIVE-2093.8.patch.txt" size="113307" author="navis" created="Fri, 6 Dec 2013 00:45:06 +0000"/>
                            <attachment id="12618162" name="HIVE-2093.9.patch.txt" size="116154" author="navis" created="Wed, 11 Dec 2013 02:04:44 +0000"/>
                            <attachment id="12602091" name="HIVE-2093.D12807.1.patch" size="146746" author="phabricator@reviews.facebook.net" created="Mon, 9 Sep 2013 05:27:53 +0000"/>
                            <attachment id="12602258" name="HIVE-2093.D12807.2.patch" size="115416" author="phabricator@reviews.facebook.net" created="Tue, 10 Sep 2013 01:45:55 +0000"/>
                            <attachment id="12475660" name="HIVE.2093.1.patch" size="38107" author="sdong" created="Thu, 7 Apr 2011 03:44:48 +0000"/>
                            <attachment id="12475777" name="HIVE.2093.2.patch" size="174709" author="sdong" created="Fri, 8 Apr 2011 03:22:31 +0000"/>
                            <attachment id="12475796" name="HIVE.2093.3.patch" size="373135" author="sdong" created="Fri, 8 Apr 2011 07:16:35 +0000"/>
                            <attachment id="12476760" name="HIVE.2093.4.patch" size="374182" author="sdong" created="Tue, 19 Apr 2011 19:22:34 +0000"/>
                            <attachment id="12477047" name="HIVE.2093.5.patch" size="396747" author="sdong" created="Thu, 21 Apr 2011 22:13:50 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>13.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 7 Apr 2011 03:44:48 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42275</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 6 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i06aon:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>34662</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-2094] CREATE and DROP DATABASE doesn&apos;t check user permission for doing it</title>
                <link>https://issues.apache.org/jira/browse/HIVE-2094</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;We need to make sure only users with system permission to do it.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12503452">HIVE-2094</key>
            <summary>CREATE and DROP DATABASE doesn&apos;t check user permission for doing it</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="he yongqiang">He Yongqiang</assignee>
                                    <reporter username="sdong">Siying Dong</reporter>
                        <labels>
                    </labels>
                <created>Tue, 5 Apr 2011 21:05:31 +0000</created>
                <updated>Thu, 4 Oct 2012 16:25:28 +0000</updated>
                                                                            <component>Authorization</component>
                    <component>Metastore</component>
                    <component>Security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42274</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 42 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0119z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3972</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-2095] auto convert map join bug</title>
                <link>https://issues.apache.org/jira/browse/HIVE-2095</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;1) &lt;br/&gt;
when considering to choose one table as the big table candidate for a map join, if at compile time, hive can find out that the total known size of all other tables excluding the big table in consideration is bigger than a configured value, this big table candidate is a bad one, and should not put into plan. Otherwise, at runtime to filter this out may cause more time.&lt;/p&gt;

&lt;p&gt;2)&lt;br/&gt;
added a null check for back up tasks. Otherwise will see NullPointerException&lt;/p&gt;

&lt;p&gt;3)&lt;br/&gt;
CommonJoinResolver needs to know a full mapping of pathToAliases. Otherwise it will make wrong decision.&lt;/p&gt;

&lt;p&gt;4)&lt;br/&gt;
changes made to the ConditionalResolverCommonJoin: added pathToAliases, aliasToSize (alias&apos;s input size that is known at compile time, by inputSummary), and intermediate dir path.&lt;br/&gt;
So the logic is, go over all the pathToAliases, and for each path, if it is from intermediate dir path, add this path&apos;s size to all aliases. And finally based on the size information and others like aliasToTask to choose the big table. &lt;/p&gt;

&lt;p&gt;5)&lt;br/&gt;
Conditional task&apos;s children contains wrong options, which may cause join fail or incorrect results. Basically when getting all possible children for the conditional task, should use a whitelist of big tables. Only tables in this while list can be considered as a big table.&lt;br/&gt;
Here is the logic:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Get a list of big table candidates. Only the tables in the returned set can be used as big table in the join operation.&lt;/li&gt;
	&lt;li&gt;The logic here is to scan the join condition array from left to right.
	&lt;ul&gt;
		&lt;li&gt;If see a inner join and the bigTableCandidates is empty, add both side of this inner join to big table candidates.&lt;/li&gt;
		&lt;li&gt;If see a left outer join, and the bigTableCandidates is empty, add the left side to it, and&lt;/li&gt;
		&lt;li&gt;if the bigTableCandidates is not empty, do nothing (which means the bigTableCandidates is from left side).&lt;/li&gt;
		&lt;li&gt;If see a right outer join, clear the bigTableCandidates, and add right side to the bigTableCandidates, it means the right side of a right outer join always win.&lt;/li&gt;
		&lt;li&gt;If see a full outer join, return null immediately (no one can be the big table, can not do a mapjoin).&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
        <key id="12503460">HIVE-2095</key>
            <summary>auto convert map join bug</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="he yongqiang">He Yongqiang</assignee>
                                    <reporter username="he yongqiang">He Yongqiang</reporter>
                        <labels>
                    </labels>
                <created>Tue, 5 Apr 2011 21:42:49 +0000</created>
                <updated>Mon, 12 Nov 2012 21:01:13 +0000</updated>
                            <resolved>Fri, 8 Apr 2011 22:00:09 +0000</resolved>
                                    <version>0.7.0</version>
                                    <fixVersion>0.8.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13016871" author="liyin" created="Thu, 7 Apr 2011 15:19:16 +0000"  >&lt;p&gt;I will take a look&lt;/p&gt;</comment>
                            <comment id="13017049" author="namit" created="Thu, 7 Apr 2011 17:11:21 +0000"  >&lt;p&gt;Can you also create a review-board request ?&lt;/p&gt;</comment>
                            <comment id="13017064" author="he yongqiang" created="Thu, 7 Apr 2011 17:43:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/559/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/559/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13017208" author="liyin" created="Thu, 7 Apr 2011 23:59:41 +0000"  >&lt;p&gt;it looks good to me. Thanks Yongqiang&lt;/p&gt;</comment>
                            <comment id="13017291" author="he yongqiang" created="Fri, 8 Apr 2011 05:25:20 +0000"  >&lt;p&gt;Uploading a new patch to address namit&apos;s comments.&lt;/p&gt;

&lt;p&gt;Note, there is an existing bug in hive that cause results of auto_join29.q is not correct. &lt;br/&gt;
Let&apos;s file another jira for it.&lt;br/&gt;
basically, if the outer join filter is enabled, the query &quot;SELECT /&lt;b&gt;+mapjoin(src1, src2)&lt;/b&gt;/ * FROM src src1 RIGHT OUTER JOIN src src2 ON (src1.key = src2.key AND src1.key &amp;lt; 10 AND src2.key &amp;gt; 10) JOIN src src3 ON (src2.key = src3.key AND src3.key &amp;lt; 10) SORT BY src1.key, src1.value, src2.key, src2.value, src3.key, src3.value;&quot; will give wrong results in today&apos;s hive.&lt;/p&gt;</comment>
                            <comment id="13017683" author="namit" created="Fri, 8 Apr 2011 22:00:09 +0000"  >&lt;p&gt;Committed. Thanks Yongqiang&lt;/p&gt;</comment>
                            <comment id="13449933" author="mkleiderman" created="Thu, 6 Sep 2012 18:48:30 +0000"  >&lt;p&gt;I think I&apos;m hitting this issue with an 0.7.1 installation - can you provide information about how big the tables need to be in order to trigger the NullPointerException?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12475691" name="HIVE-2095.1.patch" size="505711" author="he yongqiang" created="Thu, 7 Apr 2011 09:22:04 +0000"/>
                            <attachment id="12475785" name="HIVE-2095.2.patch" size="509331" author="he yongqiang" created="Fri, 8 Apr 2011 05:22:41 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 7 Apr 2011 15:19:16 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72559</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 20 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0jwnr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>114221</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>
</channel>
</rss>
