<!--
RSS generated by JIRA (7.6.3#76005-sha1:8a4e38d34af948780dbf52044e7aafb13a7cae58) at Tue Jan 22 15:12:23 UTC 2019

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<!-- If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
    <channel>
        <title>ASF JIRA</title>
        <link>https://issues.apache.org/jira/issues/?jql=project+%3D+HIVE+AND+created+%3E%3D+2008-11-25+AND+created+%3C%3D+2008-12-2+ORDER+BY+key+ASC</link>
        <description>An XML representation of a search request</description>
                <language>en-uk</language>
                        <issue start="0" end="14" total="14"/>
                <build-info>
            <version>7.6.3</version>
            <build-number>76005</build-number>
            <build-date>09-01-2018</build-date>
        </build-info>

<item>
            <title>[HIVE-79] Print number of rows inserted to table(s) when  the query is finished.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-79</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;It is good to print the number of rows inserted into each table at end of query. &lt;br/&gt;
insert overwrite table tab1 select a.* from tab2 a where a.col1 = 10;&lt;/p&gt;

&lt;p&gt;This query can print something like:&lt;br/&gt;
tab1 rows=100&lt;/p&gt;</description>
                <environment></environment>
        <key id="12409226">HIVE-79</key>
            <summary>Print number of rows inserted to table(s) when  the query is finished.</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="santony73">Suresh Antony</assignee>
                                    <reporter username="santony73">Suresh Antony</reporter>
                        <labels>
                    </labels>
                <created>Tue, 25 Nov 2008 23:27:23 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:26 +0000</updated>
                            <resolved>Thu, 26 Feb 2009 08:41:57 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Logging</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="12668758" author="santony73" created="Fri, 30 Jan 2009 05:45:46 +0000"  >&lt;p&gt;This path logs inserted row count to hive query log.  &lt;br/&gt;
Logged format will be:&lt;br/&gt;
TaskEnd TASK_ROWS_INSERTED=&quot;tmp_suresh_12:181687,tmp_suresh_13:181687&quot;&lt;/p&gt;

&lt;p&gt;Made changes to semantic analyzer keep tack id-table name map.&lt;/p&gt;

&lt;p&gt;HiveHistory converts id back to table name and writes to structured query log.&lt;/p&gt;</comment>
                            <comment id="12668965" author="namit" created="Fri, 30 Jan 2009 18:22:55 +0000"  >&lt;p&gt;The id&apos;s in genFilesinkPlan() are always incremented. fileSinkDesc is created twice for evey table (in the common case of column pruning).&lt;/p&gt;

&lt;p&gt;So, although, the FileSinkOperator has counters till 15, most of the tables will be doube-counted in the common case and logging wont happen when there are more than 8 tables.&lt;br/&gt;
Moreoever, this can get worse with more optimizer features.&lt;/p&gt;

&lt;p&gt;clear the (id-&amp;gt;name) map in reset()  and set the counter back to 0&lt;/p&gt;</comment>
                            <comment id="12669050" author="santony73" created="Fri, 30 Jan 2009 22:05:14 +0000"  >&lt;p&gt;Implemented the feedback by namit.&lt;br/&gt;
Reseting the id and map in the reset() call.&lt;/p&gt;
</comment>
                            <comment id="12672035" author="jsensarma" created="Mon, 9 Feb 2009 22:19:40 +0000"  >&lt;p&gt;Hey Namit - isn&apos;t there a new SemanticAnalyzer object getting created for each pass of the ColumnPruner? Just checking if the id wastage issue is resolved.&lt;/p&gt;

&lt;p&gt;Also - it would be great if we could actually get this printed out on the cli as well (one for each table perhaps).&lt;/p&gt;</comment>
                            <comment id="12672040" author="jsensarma" created="Mon, 9 Feb 2009 22:36:53 +0000"  >&lt;p&gt;we should also do this for insert overwrite directory case as well (from user perspective - i think it&apos;s equally useful to know row counts when extracting from hive).&lt;/p&gt;

&lt;p&gt;from hivehistory perspective - these counters are query properties (and not properties of map-reduce jobs).&lt;/p&gt;</comment>
                            <comment id="12672041" author="prasadc" created="Mon, 9 Feb 2009 22:40:45 +0000"  >&lt;p&gt;got tired of seeing raws&lt;/p&gt;</comment>
                            <comment id="12673119" author="santony73" created="Fri, 13 Feb 2009 02:20:00 +0000"  >&lt;p&gt;1. Added printing row count to output&lt;br/&gt;
2.  Also added row count to Query hisory&lt;br/&gt;
3.  Changing the the test outputs because fileSinkDesc changed. Added table Id to file Sink Descriptor.&lt;/p&gt;</comment>
                            <comment id="12673793" author="jsensarma" created="Mon, 16 Feb 2009 05:34:13 +0000"  >&lt;p&gt;can you please add a test (perhaps to testhivehistory?) that checks that the counter is correct for some insert operation.&lt;/p&gt;

&lt;p&gt;otherwise looks good (the interplay between parseCtx and semanticanalyzer is pretty hard to understand - but seems like an orthogonal issue).&lt;/p&gt;</comment>
                            <comment id="12673919" author="santony73" created="Mon, 16 Feb 2009 16:20:33 +0000"  >&lt;p&gt;Trying to add test case ...&lt;br/&gt;
We run our test cases in local mode.&lt;br/&gt;
Looks like there are no counters getting created in local mode. Need to investigate more.&lt;/p&gt;</comment>
                            <comment id="12674041" author="jsensarma" created="Mon, 16 Feb 2009 19:28:23 +0000"  >&lt;p&gt;yeah - local mode is weird. in that case - we can punt and add the test once we move to minimr for testing.&lt;/p&gt;</comment>
                            <comment id="12674327" author="santony73" created="Tue, 17 Feb 2009 19:31:22 +0000"  >&lt;p&gt;if so can I commit this patch.&lt;/p&gt;</comment>
                            <comment id="12674371" author="jsensarma" created="Tue, 17 Feb 2009 22:02:00 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="12675768" author="dhruba" created="Mon, 23 Feb 2009 05:44:23 +0000"  >&lt;p&gt;This should go into trunk and not into any branch, right?&lt;/p&gt;</comment>
                            <comment id="12675816" author="jsensarma" created="Mon, 23 Feb 2009 08:42:26 +0000"  >&lt;p&gt;yeah - only trunk ..&lt;/p&gt;</comment>
                            <comment id="12676191" author="dhruba" created="Tue, 24 Feb 2009 05:38:28 +0000"  >&lt;p&gt;This patch does not merge with hive trunk. &lt;/p&gt;

&lt;p&gt;@Suresh: can you pl upload a new patch? Thanks.&lt;/p&gt;</comment>
                            <comment id="12676373" author="santony73" created="Tue, 24 Feb 2009 19:31:22 +0000"  >&lt;p&gt;Resolved the conflicts&lt;/p&gt;</comment>
                            <comment id="12676458" author="dhruba" created="Wed, 25 Feb 2009 00:26:13 +0000"  >&lt;p&gt;This  fails unit test:&lt;/p&gt;

&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Tests run: 144, Failures: 1, Errors: 0, Time elapsed: 760.913 sec^M&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Test org.apache.hadoop.hive.cli.TestCliDriver FAILED&lt;/p&gt;</comment>
                            <comment id="12676663" author="santony73" created="Wed, 25 Feb 2009 14:34:45 +0000"  >&lt;p&gt;Test failed yesterday because a new test was added.   The patch changes plan for filesink operator. A new test case will fail the unit test.&lt;/p&gt;</comment>
                            <comment id="12676918" author="zshao" created="Thu, 26 Feb 2009 08:41:57 +0000"  >&lt;p&gt;I fixed the test error and committed to trunk.&lt;br/&gt;
Committed revision 748058.&lt;br/&gt;
Thanks Suresh!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12410734">HIVE-176</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12399100" name="patch_79_1.txt" size="12495" author="santony73" created="Fri, 30 Jan 2009 05:45:46 +0000"/>
                            <attachment id="12399170" name="patch_79_2.txt" size="12712" author="santony73" created="Fri, 30 Jan 2009 22:05:14 +0000"/>
                            <attachment id="12400138" name="patch_79_3.txt" size="243131" author="santony73" created="Fri, 13 Feb 2009 02:20:00 +0000"/>
                            <attachment id="12400873" name="patch_79_4.txt" size="247045" author="santony73" created="Tue, 24 Feb 2009 19:31:22 +0000"/>
                            <attachment id="12400945" name="patch_79_5.txt" size="247636" author="santony73" created="Wed, 25 Feb 2009 14:34:45 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 30 Jan 2009 18:22:55 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73797</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 48 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7pr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121900</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-79&quot; title=&quot;Print number of rows inserted to table(s) when  the query is finished.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-79&quot;&gt;&lt;strike&gt;HIVE-79&lt;/strike&gt;&lt;/a&gt;. Print number of rows inserted to table(s) (Suresh Antony via zshao)</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-80] Add testcases for concurrent query execution</title>
                <link>https://issues.apache.org/jira/browse/HIVE-80</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Can use one driver object per query.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12409298">HIVE-80</key>
            <summary>Add testcases for concurrent query execution</summary>
                <type id="6" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/requirement.png">Test</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="rsm">Raghotham Murthy</reporter>
                        <labels>
                            <label>concurrency</label>
                    </labels>
                <created>Wed, 26 Nov 2008 19:22:05 +0000</created>
                <updated>Sat, 6 Dec 2014 09:59:04 +0000</updated>
                                                                            <component>Query Processor</component>
                    <component>Server Infrastructure</component>
                        <due></due>
                            <votes>6</votes>
                                    <watches>26</watches>
                                                                <comments>
                            <comment id="12681572" author="athusoo" created="Fri, 13 Mar 2009 01:12:26 +0000"  >&lt;p&gt;Downgrading to critical as HiveServer has a bunch of other fixes and is at best experimental right now.&lt;/p&gt;</comment>
                            <comment id="12700954" author="neilconway" created="Mon, 20 Apr 2009 21:40:22 +0000"  >&lt;p&gt;A reasonable way to implement this might be as follows:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Change the HiveServer#execute() method to return a unique ID for each active query (this can just be QueryPlan#getQueryId()).&lt;/li&gt;
	&lt;li&gt;Change the rest of the HiveServer methods to be parameterized by the query ID&lt;/li&gt;
	&lt;li&gt;Inside HiveServer, create a separate Driver object for each active query&lt;/li&gt;
	&lt;li&gt;Perhaps add a HiveServer#close() method that clients can use when they&apos;re finished executing a query&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;One issue is that if a client dies spontaneously, it might not call close(), which would leak resources at the server.&lt;/p&gt;

&lt;p&gt;Comments? If you&apos;re not working on this right now Raghu, I&apos;d be happy to take a crack at it.&lt;/p&gt;</comment>
                            <comment id="12700962" author="rsm" created="Mon, 20 Apr 2009 22:07:29 +0000"  >&lt;p&gt;Neil, please go ahead and take this over. Your plan sounds good.&lt;/p&gt;

&lt;p&gt;A few comments:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;This change would mean breaking compatibility of the hive service. It might be better to just add additional methods that use the queryId and deprecate the old methods.&lt;/li&gt;
	&lt;li&gt;Inside the HiveServerHandler, I am assuming, you would just use a map of queryid to driver (instead of a single driver object)&lt;/li&gt;
	&lt;li&gt;If a client dies, thrift will time out and release the handler. So, that should not cause problems.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12700974" author="neilconway" created="Mon, 20 Apr 2009 22:25:58 +0000"  >&lt;p&gt;Raghu, thanks for the feedback.&lt;/p&gt;

&lt;p&gt;Maintaining backward compatibility for the hive service is important, then? Okay, I can just add new methods rather than changing the existing ones.&lt;/p&gt;

&lt;p&gt;WRT the map of queryId =&amp;gt; driver, that&apos;s correct.&lt;/p&gt;</comment>
                            <comment id="12700994" author="neilconway" created="Tue, 21 Apr 2009 00:12:30 +0000"  >&lt;p&gt;BTW, is there any documentation on how to regenerate the Thrift-generated source files? I made a trivial change to service/if/hive_service.thrift, and then reran&lt;/p&gt;

&lt;p&gt;$ cd service&lt;br/&gt;
$ ant thriftif&lt;/p&gt;

&lt;p&gt;However, the resulting Thrift-generated code fails to compile. The first few of the many compile errors are:&lt;/p&gt;

&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;javac&amp;#93;&lt;/span&gt; Compiling 4 source files to /Users/neilconway/hive-trunk/build/service/classes&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;javac&amp;#93;&lt;/span&gt; /Users/neilconway/hive-trunk/service/src/gen-javabean/org/apache/hadoop/hive/service/ThriftHive.java:46: cannot find symbol&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;javac&amp;#93;&lt;/span&gt; symbol  : constructor Client(org.apache.thrift.protocol.TProtocol,org.apache.thrift.protocol.TProtocol)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;javac&amp;#93;&lt;/span&gt; location: class org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore.Client&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;javac&amp;#93;&lt;/span&gt;       super(iprot, oprot);&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;javac&amp;#93;&lt;/span&gt;       ^&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;javac&amp;#93;&lt;/span&gt; /Users/neilconway/hive-trunk/service/src/gen-javabean/org/apache/hadoop/hive/service/ThriftHive.java:57: writeMessageBegin(com.facebook.thrift.protocol.TMessage) in com.facebook.thrift.protocol.TProtocol cannot be applied to (org.apache.thrift.protocol.TMessage)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;javac&amp;#93;&lt;/span&gt;       oprot_.writeMessageBegin(new TMessage(&quot;compile&quot;, TMessageType.CALL, seqid_));&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;javac&amp;#93;&lt;/span&gt;             ^&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;javac&amp;#93;&lt;/span&gt; /Users/neilconway/hive-trunk/service/src/gen-javabean/org/apache/hadoop/hive/service/ThriftHive.java:60: write(org.apache.thrift.protocol.TProtocol) in org.apache.hadoop.hive.service.ThriftHive.compile_args cannot be applied to (com.facebook.thrift.protocol.TProtocol)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;javac&amp;#93;&lt;/span&gt;       args.write(oprot_);&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;javac&amp;#93;&lt;/span&gt;           ^&lt;/p&gt;

&lt;p&gt;So I&apos;m guessing I need to be using an old version of Thrift? Any info on which version to use or which procedure to follow would be very helpful.&lt;/p&gt;</comment>
                            <comment id="12701009" author="rsm" created="Tue, 21 Apr 2009 01:07:04 +0000"  >&lt;p&gt;We have not really recorded the thrift version used to generate the files. Can you try one of the instant releases at: &lt;a href=&quot;http://instant.thrift-rpc.org&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://instant.thrift-rpc.org&lt;/a&gt; ? I was able to run ant thriftif with r760184 of thrift at &lt;a href=&quot;http://gitweb.thrift-rpc.org/?p=thrift.git;spfx=thrift-instant-r760184;a=snapshot;h=b1139424416009c980a9634c44f2806f469f8c1c;sf=tgz&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://gitweb.thrift-rpc.org/?p=thrift.git;spfx=thrift-instant-r760184;a=snapshot;h=b1139424416009c980a9634c44f2806f469f8c1c;sf=tgz&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="12701053" author="neilconway" created="Tue, 21 Apr 2009 04:49:36 +0000"  >&lt;p&gt;Raghu: Well, running &quot;ant thriftif&quot; works with the trunk release of thrift, as well &amp;#8211; but the generated code doesn&apos;t compile; same results for r760184 and r758922. I&apos;ll do a binary search tomorrow to find a version of Thrift that works with hive, unless anyone knows of one offhand ...?&lt;/p&gt;</comment>
                            <comment id="12701118" author="rsm" created="Tue, 21 Apr 2009 09:42:57 +0000"  >&lt;p&gt;Actually, right after I commented on this jira, I realized that the problem is with the incompatible change between thrift in apache vs thrift we had used originally. The following changes have to be made in hive to get it working with any thrift in apache.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;change libthrift.jar&lt;/li&gt;
	&lt;li&gt;change com.facebook.thrift to org.apache.thrift&lt;/li&gt;
	&lt;li&gt;handle some incompatible changes&lt;/li&gt;
	&lt;li&gt;fix some of the warnings&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&apos;ll create a new jira for this.&lt;/p&gt;</comment>
                            <comment id="12701889" author="rsm" created="Thu, 23 Apr 2009 10:45:18 +0000"  >&lt;p&gt;Neil, you can get the patch that Zheng posted to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-438&quot; title=&quot;Make hive work with apache thrift&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-438&quot;&gt;&lt;del&gt;HIVE-438&lt;/del&gt;&lt;/a&gt; and copy over the libthrift.jar and libfb303.jar (also attached). That should get you moving with this jira. &lt;/p&gt;</comment>
                            <comment id="12703446" author="neilconway" created="Mon, 27 Apr 2009 23:48:42 +0000"  >&lt;p&gt;Raghu, thanks for your work on 438. In the short term, we&apos;re planning to implement the MQO prototype using multiple Drivers embedded directly in a client program. That means there&apos;s no short-term dependency on getting this ticket resolved. I should have the cycles to look at this in ~2 weeks &amp;#8211; but if someone else would like to do it first, by all means go ahead.&lt;/p&gt;</comment>
                            <comment id="12706248" author="neilconway" created="Tue, 5 May 2009 23:34:36 +0000"  >&lt;p&gt;BTW, one issue we&apos;ve run into when running multiple queries by using multiple Drivers in a client program is that HiveInputFormat seems to be dependent on a static &quot;JobConf&quot; variable, so there&apos;s a race condition when running multiple queries concurrently.&lt;/p&gt;</comment>
                            <comment id="12707470" author="athusoo" created="Fri, 8 May 2009 19:01:52 +0000"  >&lt;p&gt;hmm...&lt;/p&gt;

&lt;p&gt;We do generate a new JobConf in ExecDriver. I think the static can be dropped in HiveInputFormat. I don&apos;t think that is needed at all. Have you done that to get around this issue?&lt;/p&gt;</comment>
                            <comment id="12707480" author="neilconway" created="Fri, 8 May 2009 19:20:21 +0000"  >&lt;p&gt;I quickly hacked this patch together to see if it fixed the problem by removing the static JobConf variable. It seemed to fix the races, but it looked like the execution of multiple queries was still serialized. I haven&apos;t had a chance to look into it further...&lt;/p&gt;</comment>
                            <comment id="12708527" author="namit" created="Tue, 12 May 2009 17:38:21 +0000"  >&lt;p&gt;The patch looks OK - I don&apos;t know why job was static to start with.&lt;/p&gt;</comment>
                            <comment id="12749365" author="cresnick" created="Mon, 31 Aug 2009 03:29:51 +0000"  >&lt;p&gt;I&apos;m attaching a patch to org.apache.hadoop.hive.ql.exec.Utilities. Currently this class has a static field instance of type mapredWork. Changing the reference to ThreadLocal has eliminated the race conditions we found while executing several concurrent queries through a simple HiveConnection pool. &lt;/p&gt;</comment>
                            <comment id="12753098" author="mpest06" created="Wed, 9 Sep 2009 14:05:14 +0000"  >&lt;p&gt;Patch Attached.&lt;/p&gt;</comment>
                            <comment id="12756766" author="cresnick" created="Thu, 17 Sep 2009 20:36:25 +0000"  >&lt;p&gt;This fixes a broken patch previously submitted&lt;/p&gt;</comment>
                            <comment id="12757249" author="namit" created="Fri, 18 Sep 2009 16:39:07 +0000"  >&lt;p&gt;The unit tests are failing with this patch&lt;/p&gt;</comment>
                            <comment id="12757489" author="cresnick" created="Fri, 18 Sep 2009 22:27:16 +0000"  >&lt;p&gt;The ThreadLocal fix won&apos;t work with the unit tests, which is run an embedded mapreduce on a separate thread. In a real-world scenario perhaps it&apos;s a worthwhile hack - it does work for us -  but there are certainly better options. &lt;/p&gt;

&lt;p&gt;After 0.4 release, if HiveConnection is still not threadsafe I will delve more into this. In the meantime I&apos;m removing the patch.&lt;/p&gt;</comment>
                            <comment id="12867693" author="aprabhakar" created="Fri, 14 May 2010 21:53:26 +0000"  >&lt;p&gt;I wanted to fix this JIRA and so started looking at it. From what I have observed it appears that the &lt;tt&gt;HiveServer&lt;/tt&gt; &lt;b&gt;is&lt;/b&gt; multi-thread capable. Specifically:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;The &lt;tt&gt;HiveServer&lt;/tt&gt; is using a &lt;tt&gt;TThreadPoolServer&lt;/tt&gt; which is multi-threaded.&lt;/li&gt;
	&lt;li&gt;The &lt;tt&gt;ThriftHiveProcessorFactory&lt;/tt&gt; overrides the &lt;tt&gt;getProcessor()&lt;/tt&gt; call and returns a new instance of &lt;tt&gt;HiveServerHandler&lt;/tt&gt; on every invokation.&lt;/li&gt;
	&lt;li&gt;Every instance of &lt;tt&gt;HiveServerHandler&lt;/tt&gt; has its own thread local session state and a private driver instance.&lt;/li&gt;
	&lt;li&gt;Query execution is thread safe thanks to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-77&quot; title=&quot;thread safe query execution&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-77&quot;&gt;&lt;del&gt;HIVE-77&lt;/del&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Give the above, I believe that this JIRA should be marked closed and resolved. If you think I missed something in my analysis, can you please point that out?&lt;/p&gt;</comment>
                            <comment id="12871992" author="jvs" created="Wed, 26 May 2010 22:39:54 +0000"  >&lt;p&gt;From internal discussions at Facebook, the best I can gather is that there may still be some thread-unsafe code, but no one knows for sure.  Given that, the only approach may be to do as much review as possible (e.g. grep for statics that shouldn&apos;t be there), ask everyone to add any known issues here, and then set up a testbed and see what turns up.&lt;/p&gt;</comment>
                            <comment id="12872024" author="nzhang" created="Wed, 26 May 2010 23:53:31 +0000"  >&lt;p&gt;I think after &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-549&quot; title=&quot;Parallel Execution Mechanism&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-549&quot;&gt;&lt;del&gt;HIVE-549&lt;/del&gt;&lt;/a&gt; (parallel execution) was committed, Driver allows more than one tasks running in parallel. So this JIRA may be fixed as a by-product. But we never tried it yet. It may make sense to try it on trunk or release 0.5. &lt;/p&gt;</comment>
                            <comment id="12872240" author="athusoo" created="Thu, 27 May 2010 15:01:54 +0000"  >&lt;p&gt;yes I think what Ning is saying is correct. We should however add a test case to the unit tests to check that. I am not sure that we added a test case for the parallel execution stuff.&lt;/p&gt;</comment>
                            <comment id="12872254" author="nzhang" created="Thu, 27 May 2010 15:24:57 +0000"  >&lt;p&gt;Yes we should add more test cases for parallel execution. There is an open issue &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1019&quot; title=&quot;java.io.FileNotFoundException: HIVE_PLAN (No such file or directory)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1019&quot;&gt;&lt;del&gt;HIVE-1019&lt;/del&gt;&lt;/a&gt; for parallel execution. The HIVE_PLAN* file name need to be unique rather than relying on timestamp. &lt;/p&gt;</comment>
                            <comment id="12872282" author="aprabhakar" created="Thu, 27 May 2010 16:39:38 +0000"  >&lt;p&gt;This sounds like a good plan. If Neil is not actively working on this issue, I can move this to my queue and start working on it. &lt;/p&gt;</comment>
                            <comment id="12872294" author="neilconway" created="Thu, 27 May 2010 17:26:50 +0000"  >&lt;p&gt;Arvind, I&apos;m not actively working on it, so please go ahead.&lt;/p&gt;</comment>
                            <comment id="12933378" author="zjffdu" created="Thu, 18 Nov 2010 09:53:10 +0000"  >&lt;p&gt;Does anyone know whether Driver is thread-safe ? If so, each query can been executed by one Driver.&lt;br/&gt;
And I notice that in HWI for each session there is one Driver, it seems Driver should be thread-safe, just want to ensure about it.&lt;/p&gt;
</comment>
                            <comment id="12933386" author="svenkat" created="Thu, 18 Nov 2010 10:28:12 +0000"  >&lt;p&gt;&amp;gt; Does anyone know whether Driver is thread-safe?&lt;br/&gt;
Driver is not thread safe.&lt;/p&gt;</comment>
                            <comment id="12987607" author="fdiaconeasa" created="Thu, 27 Jan 2011 15:38:54 +0000"  >&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I&apos;m thinking about writing a Hive client in order to handle some of the queries that i wish to run and the dependencies between them.&lt;/p&gt;

&lt;p&gt;From what i read on the Hive wiki ( &lt;a href=&quot;http://wiki.apache.org/hadoop/Hive/HiveServer&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Hive/HiveServer&lt;/a&gt; ) it appears that the hive server is single threaded.&lt;/p&gt;

&lt;p&gt;I might be mistaking, but this is what i understand from that text: if i launch 2 requests from my client towards the hive server, the hive server will not handle them in parallel and the hadoop requests done by hive itself will run one after another, not in parallel.&lt;/p&gt;

&lt;p&gt;Is this right? If (hopefully) not &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; , could someone please clarify that for me, if possible?&lt;/p&gt;

&lt;p&gt;Thank you.&lt;/p&gt;</comment>
                            <comment id="13057396" author="franklovecchio" created="Wed, 29 Jun 2011 18:49:20 +0000"  >&lt;p&gt;We have tested multiple client connections submitting jobs rapidly to a single hiveserver (running on a Brisk implementation); I would not recommend doing this unless you have a que of some sort on your end.  Otherwise, you will see this:&lt;/p&gt;

&lt;p&gt;ERROR in runJob&lt;br/&gt;
org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused&lt;/p&gt;

&lt;p&gt;Has anyone used multiple hiveservers for managing multiple connections?  (something like Amazon&apos;s cloud map/reduce, where they spin up a temporary instance?)  &lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13062628" author="franklovecchio" created="Sat, 9 Jul 2011 21:15:39 +0000"  >&lt;p&gt;Edit: I put up some test results for different scenarios, including multiple connections threaded, here:  &lt;a href=&quot;https://github.com/franklovecchio/hiveserver-loadtest&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/franklovecchio/hiveserver-loadtest&lt;/a&gt; .  Multi-threaded jobs = wonky.&lt;/p&gt;</comment>
                            <comment id="13062631" author="alexvk@cloudera.com" created="Sat, 9 Jul 2011 21:18:00 +0000"  >&lt;p&gt;I will be out of office July 9-22, 2011.  If you have anything urgent,&lt;br/&gt;
please contact my manager Omer Trajman omer@cloudera.com.&lt;/p&gt;

&lt;p&gt;&amp;#8211; &lt;br/&gt;
&amp;#8211;&lt;br/&gt;
Alex Kozlov&lt;br/&gt;
Solutions Architect&lt;br/&gt;
Cloudera, Inc&lt;/p&gt;

&lt;p&gt;Hadoop World 2011 in New York&lt;br/&gt;
City&amp;lt;&lt;a href=&quot;http://www.cloudera.com/company/events/hadoop-world-2011/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.cloudera.com/company/events/hadoop-world-2011/&lt;/a&gt;&amp;gt;&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://www.cloudera.com/company/press-center/hadoop-world-nyc/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.cloudera.com/company/press-center/hadoop-world-nyc/&lt;/a&gt;&amp;gt;&lt;/p&gt;</comment>
                            <comment id="13150193" author="cos" created="Tue, 15 Nov 2011 02:25:53 +0000"  >&lt;p&gt;Perhaps my question is bigger than this issue or shall be asked somewhere else, but looking at Hive code I couldn&apos;t help noticing that it is essentially build as a singleton i.e. only a single instance of Hive object is allowed to exist. &lt;/p&gt;

&lt;p&gt;What was/is a design motivation behind of this? Why Hive can&apos;t be instantiated at will by the client so different instances can be independently for query analysis, job submissions, etc.? This will make Hive much more flexible and extendable from Hive client applications perspective, won&apos;t it?&lt;/p&gt;</comment>
                            <comment id="13249465" author="cwsteinbach" created="Sun, 8 Apr 2012 03:11:16 +0000"  >&lt;p&gt;HiveServer can&apos;t support concurrent connections due to a limitation of the current HiveServer Thrift API. There&apos;s a proposal for a new HiveServer2 Thrift API which fixes these problems located here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Thrift+API&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Thrift+API&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12409031">HIVE-77</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12428950">HIVE-584</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12550255">HIVE-2935</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12519372">HIVE-2395</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12410953">HIVE-187</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12407649" name="hive_input_format_race-2.patch" size="4105" author="neilconway" created="Fri, 8 May 2009 19:20:21 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 13 Mar 2009 01:12:26 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42903</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 42 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7pz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121901</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-81] Make forrest docs for Hive web site along the lines of http://hadoop.apache.org/core/</title>
                <link>https://issues.apache.org/jira/browse/HIVE-81</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Hive should ship with documentation, like Hadoop, instead of using the wiki as the official documentation repository. To get there, we&apos;ll need a set of xml files to grind through forrest, if we want to reuse the same mechanisms as the other sites.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12409346">HIVE-81</key>
            <summary>Make forrest docs for Hive web site along the lines of http://hadoop.apache.org/core/</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hammer">Jeff Hammerbacher</assignee>
                                    <reporter username="hammer">Jeff Hammerbacher</reporter>
                        <labels>
                    </labels>
                <created>Wed, 26 Nov 2008 23:44:48 +0000</created>
                <updated>Sat, 17 Dec 2011 00:09:04 +0000</updated>
                            <resolved>Thu, 4 Dec 2008 01:06:35 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Documentation</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="12651242" author="hammer" created="Thu, 27 Nov 2008 04:27:30 +0000"  >&lt;p&gt;NOTE: this patch generated by an svn diff against a base hive checkout (svn co &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive&lt;/a&gt; hive-base).&lt;/p&gt;

&lt;p&gt;Full Hive site and initial build with Apache Forrest. Suprisingly nontrivial to build, but I basically ripped off the HBase site, thanks guys!&lt;/p&gt;

&lt;p&gt;I listed Ashish, Zheng, and Dhruba under credits.xml. Let&apos;s get this baby up ASAP!&lt;/p&gt;

&lt;p&gt;Later,&lt;br/&gt;
Jeff&lt;/p&gt;</comment>
                            <comment id="12651243" author="jsensarma" created="Thu, 27 Nov 2008 04:31:00 +0000"  >&lt;p&gt;Ashish and I talked about this earlier this week.&lt;/p&gt;

&lt;p&gt;Another option (simpler than forrest) seems to be apt (wiki like). We can compile apt files via Maven. See:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://maven.apache.org/guides/mini/guide-site.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://maven.apache.org/guides/mini/guide-site.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;and &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://maven.apache.org/doxia/references/apt-format.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://maven.apache.org/doxia/references/apt-format.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;thoughts?&lt;/p&gt;

&lt;p&gt;one thing we noticed was that Google does not actually show up hadoop official documentation on search queries. Javadocs rank really high (probably because of all the hyper links and i have personally found package headers to be really good documentation for hadoop (but on the other hand - hadoop does not have much declarative stuff). (perhaps this is a second order problem - but i am concerned that the documentation we create painstakingly will be the one that users actually refer to)&lt;/p&gt;</comment>
                            <comment id="12651244" author="hammer" created="Thu, 27 Nov 2008 04:49:33 +0000"  >&lt;p&gt;Introducing another dynamic documentation generator to the project seems like a larger decision that I wouldn&apos;t want to block on.&lt;/p&gt;

&lt;p&gt;Good catch on rankings for Google search results: having fixed urls for the latest documentation would help. Second order problem though: I say we toss this bad boy up and open a new ticket to discuss making the web site for Hive better. I&apos;m more of a fan of PHP/Python/real web development languages rather thank hacky XSLT stuff, but when in Rome...&lt;/p&gt;</comment>
                            <comment id="12652144" author="cutting" created="Mon, 1 Dec 2008 20:34:33 +0000"  >&lt;p&gt;&amp;gt; Google does not actually show up hadoop official documentation on search queries.&lt;/p&gt;

&lt;p&gt;Can you give some examples?  Y! or Google searches for &quot;HDFS&quot; both find:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://hadoop.apache.org/core/docs/current/hdfs_design.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hadoop.apache.org/core/docs/current/hdfs_design.html&lt;/a&gt;&lt;/p&gt;
</comment>
                            <comment id="12652258" author="jsensarma" created="Tue, 2 Dec 2008 03:39:32 +0000"  >&lt;p&gt;depends a lot on the query. don&apos;t remember what i tried the other day - but u are right - we get the hdfs arch document. but what we should have gotten in many cases are the dfs command manual.&lt;/p&gt;

&lt;p&gt;for example: query=&quot;hadoop set file system replication level&quot; (or try variants)&lt;/p&gt;

&lt;p&gt;the best answer is probably: &lt;a href=&quot;http://hadoop.apache.org/core/docs/r0.19.0/hdfs_shell.html#setrep&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hadoop.apache.org/core/docs/r0.19.0/hdfs_shell.html#setrep&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;but this doesn&apos;t show up in the top 10 results (at least on goog)&lt;/p&gt;

&lt;p&gt;i guess we can have examples both ways and perhaps this is a case of premature optimization. we should just get the docs in first - but the format question is still interesting (like wiki like format for apt).&lt;/p&gt;</comment>
                            <comment id="12652263" author="zshao" created="Tue, 2 Dec 2008 04:11:53 +0000"  >&lt;p&gt;I would say for consistency we would prefer forrest. All other sub projects are also using forrest. At least it gives the same look-and-feel.&lt;/p&gt;

&lt;p&gt;If later all people believe apt wiki-like format is better, we should switch all sub projects.&lt;/p&gt;

&lt;p&gt;It seems to me it is really important to get this out asap. The page could be simple (e.g. don&apos;t overlap with the existing README file in the hive package) but can serve as a single entry point for new users.&lt;/p&gt;</comment>
                            <comment id="12652285" author="hammer" created="Tue, 2 Dec 2008 05:55:57 +0000"  >&lt;p&gt;The attached patch generates a simple Hive website with the same look and feel of the rest of the Hadoop subprojects using Apache Forrest. Let me know if we&apos;re ready to move forward and I can hit &quot;Submit Patch&quot; any time. &lt;/p&gt;</comment>
                            <comment id="12652315" author="zshao" created="Tue, 2 Dec 2008 08:44:55 +0000"  >&lt;p&gt;I tried to do &quot;ant&quot;. 3 image files are missing. Is that because svn diff/patch does not accept binary files?&lt;/p&gt;

&lt;p&gt;     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; X &lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;                                     images/hadoop-logo.jpg    BROKEN: /xxx/apache-hadoop-hive-readonly/site/author/src/documentation/content/xdocs/images.hadoop-logo.jpg (No such file or directory)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; * &lt;span class=&quot;error&quot;&gt;&amp;#91;13/10&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;1/18&amp;#93;&lt;/span&gt;    0.253s 6.4Kb   credits.html&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; X &lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;                                     images/hive_small.jpg     BROKEN: /xxx/apache-hadoop-hive-readonly/site/author/src/documentation/content/xdocs/images.hive_small.jpg (No such file or directory)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; * &lt;span class=&quot;error&quot;&gt;&amp;#91;15/8&amp;#93;&lt;/span&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;0/0&amp;#93;&lt;/span&gt;     0.111s 4.6Kb   credits.pdf&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; X &lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;                                     images/favicon.ico        BROKEN: /xxx/apache-hadoop-hive-readonly/site/author/src/documentation/content/xdocs/images.favicon.ico (No such file or directory)&lt;/p&gt;
</comment>
                            <comment id="12652343" author="athusoo" created="Tue, 2 Dec 2008 11:50:19 +0000"  >&lt;p&gt;We talked about this a bit more. Considering that forrest is used by hadoop, we are fine with following the same route though the advantages of generating documents in the wiki style, that are available through doxia and maven are also quite neat. As Zheng mentions, we can address that later, though my guess is that it will be difficult to make a case to switch to another CMS for the other subprojects. Anyway, we do not need to reinvent the wheel here so I am fine with using forrest.&lt;/p&gt;

&lt;p&gt;Will take a look at this in the afternoon today and send in my comments. Preliminarily, I think we should not check in generated code (which I think this patch is doing) and instead just check in the basic sources. Otherwise, we will have the same problem that Doug mentioned in a separate thread about small doc changes generating huge checkins and overwhelming the commit mails and svn etc...&lt;/p&gt;

&lt;p&gt;Can you make the necessary changes so that the docs are created in the build directory (maybe build/docs and build/site).&lt;/p&gt;

&lt;p&gt;Thanks...&lt;/p&gt;</comment>
                            <comment id="12652447" author="hammer" created="Tue, 2 Dec 2008 18:24:33 +0000"  >&lt;p&gt;All of the other Hadoop subprojects check in the latest version of the generated code under publish/; I&apos;m just following convention by checking that in.&lt;/p&gt;

&lt;p&gt;There are no docs generated at build time, so I&apos;m not sure that adding a &quot;docs&quot; target to put these in docs/ makes sense right now. There&apos;s another ticket open for when there&apos;s actual documentation, rather than just the website. &lt;/p&gt;

&lt;p&gt;I will attach the static files, as it appears they aren&apos;t included as the output of a patch.&lt;/p&gt;</comment>
                            <comment id="12652462" author="athusoo" created="Tue, 2 Dec 2008 19:16:37 +0000"  >&lt;p&gt;I know that all the subprojects are doing this and the convention is to checkin the generated file, but I do think it makes more sense not to do that and just generate the code when the publish target is called. I am not sure that there are any significant advantages of checking in generated code but there seem to be a lot of disadvantages. This is also something that is being discussed in the larger hadoop context. The thread where this is being discussed is as follows:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://mail-archives.apache.org/mod_mbox/hadoop-core-dev/200812.mbox/browser&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://mail-archives.apache.org/mod_mbox/hadoop-core-dev/200812.mbox/browser&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Clearly even there the preference is not to check in the generated docs.&lt;/p&gt;</comment>
                            <comment id="12652481" author="cutting" created="Tue, 2 Dec 2008 19:56:34 +0000"  >&lt;p&gt;In Core, we are moving away from checking in versioned end-user documentation.  But we still intend to checkin the project website.  Apache infrastructure prefers this.  Versioned documentation will be extracted from release tarballs and posted to the website as part of the release process.&lt;/p&gt;</comment>
                            <comment id="12653081" author="hammer" created="Thu, 4 Dec 2008 00:18:28 +0000"  >&lt;p&gt;Given Doug&apos;s comments, are there any other modifications to the patch required to get this patch committed?&lt;/p&gt;</comment>
                            <comment id="12653096" author="cutting" created="Thu, 4 Dec 2008 01:06:35 +0000"  >&lt;p&gt;I just committed this.  Thanks, Jeff!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12409348">HADOOP-4736</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12394808" name="HIVE-81.patch" size="217774" author="hammer" created="Thu, 27 Nov 2008 04:27:30 +0000"/>
                            <attachment id="12395106" name="favicon.ico" size="766" author="hammer" created="Tue, 2 Dec 2008 18:25:19 +0000"/>
                            <attachment id="12395107" name="hadoop-logo.jpg" size="9443" author="hammer" created="Tue, 2 Dec 2008 18:25:37 +0000"/>
                            <attachment id="12395109" name="hive_small.jpg" size="3104" author="hammer" created="Tue, 2 Dec 2008 18:25:48 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 27 Nov 2008 04:31:00 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73796</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 8 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7qf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121903</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-82] Augment build.xml with a target to build the forrest docs and javadocs</title>
                <link>https://issues.apache.org/jira/browse/HIVE-82</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;See hadoop&apos;s build.xml, especially the targets &quot;docs&quot; and &quot;javadoc-dev&quot;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12409367">HIVE-82</key>
            <summary>Augment build.xml with a target to build the forrest docs and javadocs</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="athusoo">Ashish Thusoo</assignee>
                                    <reporter username="hammer">Jeff Hammerbacher</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Nov 2008 03:09:51 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:35 +0000</updated>
                            <resolved>Fri, 10 Apr 2009 06:14:51 +0000</resolved>
                                    <version>0.3.0</version>
                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Build Infrastructure</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12668700" author="appodictic" created="Fri, 30 Jan 2009 01:34:46 +0000"  >&lt;p&gt;We can also use the Hive-Web-Interface to display the javadoc. If we create a folder $HIVE_HOME/doc the hive web server can load it as a static context.&lt;/p&gt;</comment>
                            <comment id="12697357" author="athusoo" created="Thu, 9 Apr 2009 01:40:06 +0000"  >&lt;p&gt;Need this for creating the the tar for the release. Have mostly copied this from hadoop. This only has javadocs for now. The naming convention right now is&lt;/p&gt;

&lt;p&gt;hive-&amp;lt;version&amp;gt;&lt;del&gt;hadoop&lt;/del&gt;&amp;lt;version&amp;gt;.tar.gz&lt;/p&gt;

&lt;p&gt;and &lt;/p&gt;

&lt;p&gt;hive-&amp;lt;version&amp;gt;&lt;del&gt;hadoop&lt;/del&gt;&amp;lt;version&amp;gt;-bin.tar.gz&lt;/p&gt;
</comment>
                            <comment id="12697358" author="athusoo" created="Thu, 9 Apr 2009 01:40:27 +0000"  >&lt;p&gt;submitting.&lt;/p&gt;</comment>
                            <comment id="12697360" author="athusoo" created="Thu, 9 Apr 2009 01:40:57 +0000"  >&lt;p&gt;Blocker as this is needed for the release tar ball.&lt;/p&gt;</comment>
                            <comment id="12697386" author="zshao" created="Thu, 9 Apr 2009 04:21:37 +0000"  >&lt;p&gt;I saw some hard-coded 0.4.0 version numbers in build-common.xml and build.xml.&lt;br/&gt;
We may want to consolidate it into a single variable in build.xml.&lt;/p&gt;

</comment>
                            <comment id="12697568" author="athusoo" created="Thu, 9 Apr 2009 17:19:40 +0000"  >&lt;p&gt;yes. there are a duplication of the properties that appear in build-common.xml and build.xml. We need to find a way to address all that. I think I can perhaps put them all in a properties file. The reason that these are duplicated was because build.xml does not get called if ant is called from within ql or other top level directories. Anyway let me see how I can address it.&lt;/p&gt;

&lt;p&gt;Also wanted to find out that all the changes to .java files was because I had to fix a ton of javadocs warnings.&lt;/p&gt;</comment>
                            <comment id="12697602" author="namit" created="Thu, 9 Apr 2009 18:56:33 +0000"  >&lt;p&gt;Seems to have bugs in the generated javadoc.&lt;/p&gt;

&lt;p&gt;For eg: &lt;br/&gt;
api/index.html only show hwi&lt;br/&gt;
api/overview-frame.html only shows ql&lt;br/&gt;
api/package-list only shows hwi&lt;/p&gt;</comment>
                            <comment id="12697637" author="namit" created="Thu, 9 Apr 2009 20:23:58 +0000"  >&lt;p&gt;Should package depend on javadoc ? It takes ~5 min. now instead of ~30 seconds&lt;/p&gt;</comment>
                            <comment id="12697719" author="athusoo" created="Fri, 10 Apr 2009 03:21:21 +0000"  >&lt;p&gt;Fixed the bugs and the general cleanup. Now all the javadoc generation is in the top most build.xml.&lt;br/&gt;
The binary .tar.gz has a directory structure&lt;br/&gt;
/bin&lt;br/&gt;
/lib&lt;br/&gt;
/examples&lt;br/&gt;
/lib&lt;br/&gt;
README.txt&lt;/p&gt;

&lt;p&gt;where as the dev .tar.gz has an additional&lt;br/&gt;
/src&lt;/p&gt;

&lt;p&gt;which contains all the sources.&lt;/p&gt;</comment>
                            <comment id="12697722" author="rsm" created="Fri, 10 Apr 2009 03:44:29 +0000"  >&lt;p&gt;looks like the src dir in the tar has the build directory as well.&lt;/p&gt;</comment>
                            <comment id="12697723" author="athusoo" created="Fri, 10 Apr 2009 03:47:22 +0000"  >&lt;p&gt;Fixed. The new patch is attached.&lt;/p&gt;</comment>
                            <comment id="12697730" author="athusoo" created="Fri, 10 Apr 2009 04:32:53 +0000"  >&lt;p&gt;One more with changes that were breaking javadocs due to globbing.&lt;/p&gt;</comment>
                            <comment id="12697734" author="athusoo" created="Fri, 10 Apr 2009 04:55:56 +0000"  >&lt;p&gt;This one also has the Hive logo for the changes.txt&lt;/p&gt;</comment>
                            <comment id="12697736" author="rsm" created="Fri, 10 Apr 2009 05:06:47 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;looks good. will commit if tests pass.&lt;/p&gt;</comment>
                            <comment id="12697750" author="rsm" created="Fri, 10 Apr 2009 05:59:31 +0000"  >&lt;p&gt;Committed. Thanks a lot very much Ashish!!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12405141" name="hive-logo.jpg" size="3104" author="athusoo" created="Fri, 10 Apr 2009 04:55:56 +0000"/>
                            <attachment id="12405029" name="patch-82.txt" size="75520" author="athusoo" created="Thu, 9 Apr 2009 01:40:06 +0000"/>
                            <attachment id="12405134" name="patch-82_2.txt" size="74481" author="athusoo" created="Fri, 10 Apr 2009 03:21:21 +0000"/>
                            <attachment id="12405136" name="patch-82_3.txt" size="74521" author="athusoo" created="Fri, 10 Apr 2009 03:47:22 +0000"/>
                            <attachment id="12405138" name="patch-82_4.txt" size="74975" author="athusoo" created="Fri, 10 Apr 2009 04:32:53 +0000"/>
                            <attachment id="12405140" name="patch-82_5.txt" size="75526" author="athusoo" created="Fri, 10 Apr 2009 04:55:56 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 30 Jan 2009 01:34:46 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73795</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 42 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7qn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121904</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-83] Set up a continuous build of Hive with Hudson</title>
                <link>https://issues.apache.org/jira/browse/HIVE-83</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Other projects like Zookeeper and HBase are leveraging Apache&apos;s hosted Hudson server (&lt;a href=&quot;http://hudson.zones.apache.org/hudson/view/HBase&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/view/HBase&lt;/a&gt;). Perhaps Hive should as well?&lt;/p&gt;</description>
                <environment></environment>
        <key id="12409368">HIVE-83</key>
            <summary>Set up a continuous build of Hive with Hudson</summary>
                <type id="3" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21148&amp;avatarType=issuetype">Task</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="johanoskarsson">Johan Oskarsson</assignee>
                                    <reporter username="hammer">Jeff Hammerbacher</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Nov 2008 03:16:48 +0000</created>
                <updated>Sat, 17 Dec 2011 00:09:00 +0000</updated>
                            <resolved>Tue, 7 Apr 2009 09:23:25 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Build Infrastructure</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="12652070" author="athusoo" created="Mon, 1 Dec 2008 17:31:30 +0000"  >&lt;p&gt;We are going to set this up soon.&lt;/p&gt;</comment>
                            <comment id="12653754" author="johanoskarsson" created="Fri, 5 Dec 2008 11:30:01 +0000"  >&lt;p&gt;Is there an apache infrastructure jira ticket those of us who are interested can keep an eye on?&lt;/p&gt;</comment>
                            <comment id="12653830" author="athusoo" created="Fri, 5 Dec 2008 15:34:19 +0000"  >&lt;p&gt;I have filed one at&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/INFRA-1813&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/INFRA-1813&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We were initially planning to open up our internal CABIE based continuous build system for external commits, but I guess having this through Hudson would help as well and be the more standard way.&lt;/p&gt;</comment>
                            <comment id="12658523" author="johanoskarsson" created="Mon, 22 Dec 2008 12:33:05 +0000"  >&lt;p&gt;Comment from Nigel Daley in the &lt;a href=&quot;https://issues.apache.org/jira/browse/INFRA-1813&quot; title=&quot;Enable Hudson builds for Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;INFRA-1813&quot;&gt;&lt;del&gt;INFRA-1813&lt;/del&gt;&lt;/a&gt; ticket:&lt;br/&gt;
Hive PMC member can request an account on hudson.zones.apache.org and setup the builds themselves. Instructions for request access are here:&lt;br/&gt;
&lt;a href=&quot;http://wiki.apache.org/general/Hudson&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/general/Hudson&lt;/a&gt; &lt;/p&gt;</comment>
                            <comment id="12672739" author="dhruba" created="Wed, 11 Feb 2009 19:32:35 +0000"  >&lt;p&gt;I have got an hudson account named &quot;dhruba&quot;. However, this account will be used by Johan to setup the Hive-Hudson builds. &lt;/p&gt;</comment>
                            <comment id="12676295" author="johanoskarsson" created="Tue, 24 Feb 2009 14:31:02 +0000"  >&lt;p&gt;I have set up three nightly builds for Hive against different Hadoop versions:&lt;br/&gt;
&lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hive-trunk-h0.17/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hive-trunk-h0.17/&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hive-trunk-h0.18/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hive-trunk-h0.18/&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hive-trunk-h0.19/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hive-trunk-h0.19/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&apos;m going to leave this ticket open and work on setting up a patch build like Hadoop as soon as the nightly builds actually succeeds.&lt;/p&gt;</comment>
                            <comment id="12696448" author="johanoskarsson" created="Tue, 7 Apr 2009 09:23:25 +0000"  >&lt;p&gt;Created a new  ticket for patch build: &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-392&quot; title=&quot;Create a patch build on Hudson&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-392&quot;&gt;HIVE-392&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 1 Dec 2008 17:31:30 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73794</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 43 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7qv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121905</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-84] MetaStore Client is not thread safe</title>
                <link>https://issues.apache.org/jira/browse/HIVE-84</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;when running DDL Tasks in concurrent threads - the following exception trace is observed:&lt;/p&gt;

&lt;p&gt;java.sql.SQLIntegrityConstraintViolationException: The statement was aborted because it would have caused a duplicate ke\ y value in a unique or primary key constraint or unique index identified by &apos;UNIQUETABLE&apos; defined on &apos;TBLS&apos;.&lt;br/&gt;
  at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:207)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:209)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.Driver.run(Driver.java:174)&lt;br/&gt;
  at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:185)&lt;br/&gt;
  at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:210)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:390)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.QTestUtil$QTRunner.run(QTestUtil.java:681)&lt;br/&gt;
  at java.lang.Thread.run(Thread.java:619)&lt;br/&gt;
Caused by: javax.jdo.JDODataStoreException: Insert of object &quot;org.apache.hadoop.hive.metastore.model.MTable@3bc8d400&quot; us\ ing statement &quot;INSERT INTO TBLS (TBL_ID,CREATE_TIME,DB_ID,RETENTION,TBL_NAME,SD_ID,OWNER,LAST_ACCESS_TIME) VALUES (?,?,?\ ,?,?,?,?,?)&quot; failed : The statement was aborted because it would have caused a duplicate key value in a unique or primar\ y key constraint or unique index identified by &apos;UNIQUETABLE&apos; defined on &apos;TBLS&apos;.&lt;br/&gt;
NestedThrowables:&lt;br/&gt;
java.sql.SQLIntegrityConstraintViolationException: The statement was aborted because it would have caused a duplicate ke\ y value in a unique or primary key constraint or unique index identified by &apos;UNIQUETABLE&apos; defined on &apos;TBLS&apos;.&lt;br/&gt;
  at org.jpox.jdo.JPOXJDOHelper.getJDOExceptionForJPOXException(JPOXJDOHelper.java:291)&lt;br/&gt;
  at org.jpox.jdo.AbstractPersistenceManager.jdoMakePersistent(AbstractPersistenceManager.java:671)&lt;br/&gt;
  at org.jpox.jdo.AbstractPersistenceManager.makePersistent(AbstractPersistenceManager.java:691)&lt;br/&gt;
  at org.apache.hadoop.hive.metastore.ObjectStore.createTable(ObjectStore.java:479)&lt;br/&gt;
  at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_table(HiveMetaStore.java:292)&lt;br/&gt;
  at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:252)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:205)&lt;br/&gt;
  ... 7 more&lt;br/&gt;
Caused by: java.sql.SQLIntegrityConstraintViolationException: The statement was aborted because it would have caused a d\ uplicate key value in a unique or primary key constraint or unique index identified by &apos;UNIQUETABLE&apos; defined on &apos;TBLS&apos;.&lt;br/&gt;
  at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source)&lt;br/&gt;
  at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)&lt;br/&gt;
  at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)&lt;br/&gt;
  at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)&lt;br/&gt;
  at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)&lt;br/&gt;
  at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)&lt;br/&gt;
  at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)&lt;br/&gt;
  at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeStatement(Unknown Source)&lt;br/&gt;
  at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeUpdate(Unknown Source)&lt;br/&gt;
  at org.jpox.store.rdbms.SQLController.executeStatementUpdate(SQLController.java:396)&lt;br/&gt;
  at org.jpox.store.rdbms.request.InsertRequest.execute(InsertRequest.java:370)&lt;br/&gt;
  at org.jpox.store.rdbms.RDBMSPersistenceHandler.insertTable(RDBMSPersistenceHandler.java:157)&lt;br/&gt;
  at org.jpox.store.rdbms.RDBMSPersistenceHandler.insertObject(RDBMSPersistenceHandler.java:136)&lt;br/&gt;
  at org.jpox.state.JDOStateManagerImpl.internalMakePersistent(JDOStateManagerImpl.java:3082)&lt;br/&gt;
  at org.jpox.state.JDOStateManagerImpl.makePersistent(JDOStateManagerImpl.java:3062)&lt;br/&gt;
  at org.jpox.ObjectManagerImpl.persistObjectInternal(ObjectManagerImpl.java:1231)&lt;br/&gt;
  at org.jpox.ObjectManagerImpl.persistObject(ObjectManagerImpl.java:1077)&lt;br/&gt;
  at org.jpox.jdo.AbstractPersistenceManager.jdoMakePersistent(AbstractPersistenceManager.java:666)&lt;br/&gt;
  ... 12 more&lt;br/&gt;
Caused by: java.sql.SQLException: The statement was aborted because it would have caused a duplicate key value in a uniq\ ue or primary key constraint or unique index identified by &apos;UNIQUETABLE&apos; defined on &apos;TBLS&apos;.&lt;br/&gt;
  at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)&lt;br/&gt;
  at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source)&lt;br/&gt;
  ... 30 more&lt;br/&gt;
Caused by: ERROR 23505: The statement was aborted because it would have caused a duplicate key value in a unique or prim\ ary key constraint or unique index identified by &apos;UNIQUETABLE&apos; defined on &apos;TBLS&apos;.&lt;br/&gt;
  at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)&lt;br/&gt;
  at org.apache.derby.impl.sql.execute.IndexChanger.insertAndCheckDups(Unknown Source)&lt;br/&gt;
  at org.apache.derby.impl.sql.execute.IndexChanger.doInsert(Unknown Source)&lt;br/&gt;
  at org.apache.derby.impl.sql.execute.IndexChanger.insert(Unknown Source)&lt;br/&gt;
  at org.apache.derby.impl.sql.execute.IndexSetChanger.insert(Unknown Source)&lt;br/&gt;
  at org.apache.derby.impl.sql.execute.RowChangerImpl.insertRow(Unknown Source)&lt;br/&gt;
  at org.apache.derby.impl.sql.execute.InsertResultSet.normalInsertCore(Unknown Source)&lt;br/&gt;
  at org.apache.derby.impl.sql.execute.InsertResultSet.open(Unknown Source)&lt;/p&gt;

&lt;p&gt;when running normal select queries as well - one hits exception, stack trace:&lt;/p&gt;

&lt;p&gt;2008-11-27 01:54:00,216 ERROR metadata.Hive (Hive.java:getTable(275)) - NoSuchObjectException(message:default.dummySrc t\&lt;br/&gt;
able not found)&lt;br/&gt;
  at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:347)&lt;br/&gt;
  at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:433)&lt;br/&gt;
  at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:472)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:272)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:254)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getMetaData(SemanticAnalyzer.java:544)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:3192)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:73)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.QTestUtil.analyzeAST(QTestUtil.java:672)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_unknown_table1(TestParseNegative.java:231)&lt;br/&gt;
  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
  at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
  at junit.framework.TestCase.runTest(TestCase.java:154)&lt;br/&gt;
  at junit.framework.TestCase.runBare(TestCase.java:127)&lt;br/&gt;
  at junit.framework.TestResult$1.protect(TestResult.java:106)&lt;br/&gt;
  at junit.framework.TestResult.runProtected(TestResult.java:124)&lt;br/&gt;
  at junit.framework.TestResult.run(TestResult.java:109)&lt;br/&gt;
  at junit.framework.TestCase.run(TestCase.java:118)&lt;br/&gt;
  at junit.framework.TestSuite.runTest(TestSuite.java:208)&lt;br/&gt;
  at junit.framework.TestSuite.run(TestSuite.java:203)&lt;br/&gt;
  at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:297)&lt;br/&gt;
  at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:672)&lt;br/&gt;
  at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:567)&lt;/p&gt;
</description>
                <environment>&lt;p&gt;with patch for hive-77 - run:&lt;/p&gt;

&lt;p&gt;ant -lib ./testlibs -Dtestcase=TestMTQueries test&lt;/p&gt;</environment>
        <key id="12409386">HIVE-84</key>
            <summary>MetaStore Client is not thread safe</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="prasadc">Prasad Chakka</assignee>
                                    <reporter username="jsensarma">Joydeep Sen Sarma</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Nov 2008 11:03:48 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:31 +0000</updated>
                            <resolved>Tue, 6 Jan 2009 22:03:49 +0000</resolved>
                                    <version>0.6.0</version>
                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Metastore</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12658075" author="prasadc" created="Fri, 19 Dec 2008 12:41:04 +0000"  >&lt;p&gt;I think each thread here needs a separate Hive db since each thread will have its own database session (transaction). Metastore Client (s0 Hive.java) is never intended to be thread-safe. I am not sure how the problem went away in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-77&quot; title=&quot;thread safe query execution&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-77&quot;&gt;&lt;del&gt;HIVE-77&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;
</comment>
                            <comment id="12660169" author="prasadc" created="Thu, 1 Jan 2009 01:30:24 +0000"  >&lt;p&gt;in the patch, Hive.java maintains metastore client in tss which makes it thread safe. Also it provides a new function to refresh the HiveConf. &lt;/p&gt;</comment>
                            <comment id="12660785" author="athusoo" created="Mon, 5 Jan 2009 15:21:20 +0000"  >&lt;p&gt;Do you still need the needsRefresh code in SessionState.java&lt;/p&gt;

&lt;p&gt;Also why just check for the refresh stuff only for MetaVars and why not do it for all the vars? Why the special case?&lt;/p&gt;</comment>
                            <comment id="12660840" author="prasadc" created="Mon, 5 Jan 2009 18:30:38 +0000"  >&lt;p&gt;I don&apos;t think needsRefresh code is needed in SessionState.java&lt;/p&gt;

&lt;p&gt;I think only these variables are needed to check whether connection to metadata server is needs to reset. But would it be safe to change conf to whatever passed in through Hive.get() function and refresh only when meta vars change?&lt;/p&gt;</comment>
                            <comment id="12660877" author="prasadc" created="Mon, 5 Jan 2009 19:54:09 +0000"  >&lt;p&gt;ok, i take back my previous comment about needsRefresh code not being needed in SessionState.java. That is the only place where a copy of the current metastore options stored. So even if HiveConf object is directly changed, we would know what these options were for the current connection.&lt;/p&gt;</comment>
                            <comment id="12661007" author="athusoo" created="Tue, 6 Jan 2009 00:53:50 +0000"  >&lt;p&gt;Prasad explained to me why this is needed in SessionState.java.&lt;/p&gt;

&lt;p&gt;So &lt;/p&gt;

&lt;p&gt;+1 on this modulo cleanups. I think we can refactor the code a bit so that all the refresh logic is at one place. Please file a separate JIRA for that.&lt;/p&gt;</comment>
                            <comment id="12661358" author="dhruba" created="Tue, 6 Jan 2009 22:03:49 +0000"  >&lt;p&gt;I just committed this. Thanks Prasad!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12396987" name="hive-84.patch" size="14982" author="prasadc" created="Thu, 1 Jan 2009 01:29:05 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 19 Dec 2008 12:41:04 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73793</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 3 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7r3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121906</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-85] separate compression options for different output types</title>
                <link>https://issues.apache.org/jira/browse/HIVE-85</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;currently hive uses mapred.output.compress to determine compression for all output files. however not all files are final output. at least three different kinds of output files are generated:&lt;br/&gt;
1. intermediate output files for next map-reduce job&lt;br/&gt;
2. files targeted for result hdfs directories or hive tables/partitions (which are just hdfs dirs)&lt;br/&gt;
3. files written to user local directories (downloading results)&lt;/p&gt;

&lt;p&gt;the plan is to provide three separate options for controlling 1,2,3 separately. we may want to split (2) in case compression is determined by table metadata (and not session options).&lt;/p&gt;</description>
                <environment></environment>
        <key id="12409406">HIVE-85</key>
            <summary>separate compression options for different output types</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jsensarma">Joydeep Sen Sarma</assignee>
                                    <reporter username="jsensarma">Joydeep Sen Sarma</reporter>
                        <labels>
                            <label>compression</label>
                    </labels>
                <created>Thu, 27 Nov 2008 18:59:09 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:55 +0000</updated>
                            <resolved>Fri, 5 Dec 2008 09:37:42 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12651917" author="jsensarma" created="Mon, 1 Dec 2008 06:50:14 +0000"  >&lt;p&gt;two new options are provided:  hive.exec.compress.output and hive.exec.compress.intermediate. documentation is included in conf/hive-default.xml&lt;/p&gt;

&lt;p&gt;patch includes some testing related changes as well (which i found necessary for this stuff):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;update to QTestUtil to only overwrite files on -Doverwrite=true iff the files actually differ&lt;/li&gt;
	&lt;li&gt;update to SemanticAnalyzer to display boolean fields in explain plan. this is causing some additional items to show up in explain plan outputs that were not previously.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12652600" author="athusoo" created="Tue, 2 Dec 2008 23:49:48 +0000"  >&lt;p&gt;When I try to apply  the patch I get the following error&lt;/p&gt;

&lt;p&gt;patch: **** malformed patch at line 93: \ No newline at end of fil&lt;/p&gt;

&lt;p&gt;I think this is because there is some binary data in the patch. Can you upload those separately?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="12652622" author="jsensarma" created="Wed, 3 Dec 2008 00:30:03 +0000"  >&lt;p&gt;this should go in data/files/lt100.txt.deflate&lt;/p&gt;</comment>
                            <comment id="12652980" author="jsensarma" created="Wed, 3 Dec 2008 21:29:10 +0000"  >&lt;p&gt;attached new version of the last patch that does not have the entry for the binary file. &lt;/p&gt;</comment>
                            <comment id="12653025" author="jsensarma" created="Wed, 3 Dec 2008 22:49:56 +0000"  >&lt;p&gt;yet another one after resolving stuff from Namit&apos;s changes to genmapredtasks. can we please review/commit this today?&lt;/p&gt;</comment>
                            <comment id="12653086" author="athusoo" created="Thu, 4 Dec 2008 00:42:57 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="12653102" author="jsensarma" created="Thu, 4 Dec 2008 01:12:31 +0000"  >&lt;p&gt;once more - with MORE javadocs&lt;/p&gt;</comment>
                            <comment id="12653713" author="zshao" created="Fri, 5 Dec 2008 09:37:42 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-85&quot; title=&quot;separate compression options for different output types&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-85&quot;&gt;&lt;del&gt;HIVE-85&lt;/del&gt;&lt;/a&gt;. New compression options for Hive. (Joydeep Sarma through zshao)&lt;/p&gt;</comment>
                            <comment id="12653714" author="zshao" created="Fri, 5 Dec 2008 09:37:57 +0000"  >&lt;p&gt;Committed. svn revision 723687.&lt;br/&gt;
Thanks Joydeep.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12394990" name="hive-85.patch.1" size="138183" author="jsensarma" created="Mon, 1 Dec 2008 06:38:53 +0000"/>
                            <attachment id="12394991" name="hive-85.patch.2" size="139300" author="jsensarma" created="Mon, 1 Dec 2008 06:48:46 +0000"/>
                            <attachment id="12395214" name="hive-85.patch.3" size="140088" author="jsensarma" created="Wed, 3 Dec 2008 21:28:26 +0000"/>
                            <attachment id="12395221" name="hive-85.patch.4" size="141558" author="jsensarma" created="Wed, 3 Dec 2008 22:49:56 +0000"/>
                            <attachment id="12395241" name="hive-85.patch.5" size="142621" author="jsensarma" created="Thu, 4 Dec 2008 01:12:31 +0000"/>
                            <attachment id="12395149" name="lt100.txt.deflate" size="267" author="jsensarma" created="Wed, 3 Dec 2008 00:30:03 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 2 Dec 2008 23:49:48 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73792</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 8 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7rj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121908</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-86] drop table should not delete data for external tables</title>
                <link>https://issues.apache.org/jira/browse/HIVE-86</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;We should not delete data for external tables.  &lt;/p&gt;</description>
                <environment></environment>
        <key id="12409464">HIVE-86</key>
            <summary>drop table should not delete data for external tables</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jsensarma">Joydeep Sen Sarma</reporter>
                        <labels>
                    </labels>
                <created>Sat, 29 Nov 2008 00:01:21 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:55 +0000</updated>
                            <resolved>Wed, 3 Dec 2008 23:19:27 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="12652057" author="athusoo" created="Mon, 1 Dec 2008 16:59:07 +0000"  >&lt;p&gt;Assigning component.&lt;/p&gt;</comment>
                            <comment id="12652421" author="johanoskarsson" created="Tue, 2 Dec 2008 16:38:02 +0000"  >&lt;p&gt;A first attempt at a patch for this issue. Please review and point me in the right direction. Since I haven&apos;t worked much with Hive I&apos;m having trouble seeing how the different components work together. It seems like there are two places where the data in a dropped table can be deleted, once in RWTable.java and one in HiveMetaStoreClient.java. Any reason for this duplication?&lt;br/&gt;
What role does the different *Store objects in the metastore java dir have?&lt;/p&gt;

&lt;p&gt;This patch does not make sure that a partition drop doesn&apos;t delete the original data. Shall I open up a new issue for that?&lt;/p&gt;</comment>
                            <comment id="12652660" author="jsensarma" created="Wed, 3 Dec 2008 02:57:50 +0000"  >&lt;p&gt;thx! Patch looks pretty good.&lt;/p&gt;

&lt;p&gt;Couple of concerns:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;i think we can just have one version of the isExternal command. The ql/.../Table.java has a metastore.api.Table object - and we can have an isExternal definition over that which can be shared in both places.&lt;/li&gt;
	&lt;li&gt;other concern is that the isExternal setting is being checked by the client side code. it seems to me that the server side should be enforcing this setting (otherwise any thrift client can come and delete data based on the thrift api regardless of the external setting). So we should (as a safety measure) be enforcing this check in HiveMetaStore.java:drop_table as well (regardless of the delete_data setting.)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;regarding RWTable versus HiveMetaStoreClient - sorry for all the confusion. The thing is that there are two implementations of the MetaStore available - one db backed which is the new one that we use normally. There is an old one that&apos;s file based and RWTable is used by that one (AFAIK).&lt;/p&gt;</comment>
                            <comment id="12652751" author="johanoskarsson" created="Wed, 3 Dec 2008 12:06:25 +0000"  >&lt;p&gt;I&apos;ve updated the patch to do all the checks server side as suggested, much cleaner.&lt;br/&gt;
The reason I didn&apos;t override the deleteData boolean in the previous patch is that I thought it might be useful if someone wanted to force delete an external table for whatever reason. It&apos;s probably better to be safe then sorry though.&lt;br/&gt;
I left in the changes in RWTable, but I assume those file based metastore will be removed eventually? It would help reduce confusion. Perhaps open a ticket for it?&lt;/p&gt;</comment>
                            <comment id="12653000" author="jsensarma" created="Wed, 3 Dec 2008 22:11:40 +0000"  >&lt;p&gt;+1. looks good.&lt;/p&gt;

&lt;p&gt;Ashish or Zheng - can you please commit this?&lt;/p&gt;</comment>
                            <comment id="12653013" author="zshao" created="Wed, 3 Dec 2008 22:36:42 +0000"  >&lt;p&gt;Applied the patch. Rerunning the test now. Will commit both internally and in apache.&lt;/p&gt;</comment>
                            <comment id="12653042" author="zshao" created="Wed, 3 Dec 2008 23:18:49 +0000"  >&lt;p&gt;Committed. svn revision 723124.&lt;/p&gt;</comment>
                            <comment id="12653043" author="zshao" created="Wed, 3 Dec 2008 23:19:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-86&quot; title=&quot;drop table should not delete data for external tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-86&quot;&gt;&lt;del&gt;HIVE-86&lt;/del&gt;&lt;/a&gt;. Drop table should not delete data for external tables.&lt;br/&gt;
(Johan Oskarsson through zshao)&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12395179" name="HIVE-86.patch" size="7778" author="johanoskarsson" created="Wed, 3 Dec 2008 12:06:25 +0000"/>
                            <attachment id="12395102" name="HIVE-86.patch" size="7256" author="johanoskarsson" created="Tue, 2 Dec 2008 16:38:02 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 1 Dec 2008 16:59:07 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73791</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 8 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7rr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121909</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-87] Clean up thrift-related files</title>
                <link>https://issues.apache.org/jira/browse/HIVE-87</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;1. Add &quot;thrift.dir&quot; configuration paramter to build.xml. The default path should be /usr/local/share. Then remove metastore/include.&lt;/p&gt;

&lt;p&gt;2. Remove the following directories from svn. They don&apos;t have to be checked in as they are generated by thrift. &lt;br/&gt;
metastore/src/gen-javabean&lt;br/&gt;
metastore/src/gen-php&lt;br/&gt;
metastore/src/gen-py&lt;/p&gt;</description>
                <environment></environment>
        <key id="12409485">HIVE-87</key>
            <summary>Clean up thrift-related files</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="michim">Michi Mutsuzaki</reporter>
                        <labels>
                    </labels>
                <created>Sun, 30 Nov 2008 05:09:36 +0000</created>
                <updated>Thu, 17 Dec 2009 23:59:42 +0000</updated>
                                                                            <component>Build Infrastructure</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12651789" author="michim" created="Sun, 30 Nov 2008 06:06:25 +0000"  >&lt;p&gt;hive-87.0.patch&lt;/p&gt;

&lt;p&gt;1. build-common.xml: Added &quot;thrift.dir&quot; property. You need these 2 files installed to compile metastore. &lt;/p&gt;

&lt;p&gt;    ${thrift.dir}/fb303/if/fb303.thrift&lt;br/&gt;
    ${thrift.dir}/thrift/if/reflection_limited.thrift&lt;/p&gt;

&lt;p&gt;2. metastore/build.xml: Modified core-compile target to depend on thriftif. Added clean target to remove src/gen-* directories.&lt;/p&gt;

&lt;p&gt;After applying this patch, you can remove metastore/include and metastore/src/gen-* directories and everything should work. &lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12408847">HIVE-73</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12394940" name="hive-87.0.patch" size="2327" author="michim" created="Sun, 30 Nov 2008 06:06:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42902</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 9 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08p4f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>48669</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-88] hadoop doesn&apos;t use conf/hive-log4j.properties</title>
                <link>https://issues.apache.org/jira/browse/HIVE-88</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;hadoop-0.20.0-dev-core.jar contains log4j.properties file, and I think that&apos;s the one hadoop is picking up. I modified both conf/hive-log4j.properties and hadoopcore/conf/log4j.properties, but hadoop still printed INFO messages to stderr.&lt;/p&gt;

&lt;p&gt;Pasting relevant posts from the mailing list below:&lt;/p&gt;

&lt;p&gt;Michi Mutsuzaki &amp;lt;michi@cs.stanford.edu&amp;gt; 	Fri, Nov 28, 2008 at 7:14 PM&lt;br/&gt;
To: hive-users@publists.facebook.com&lt;br/&gt;
Hello,&lt;/p&gt;

&lt;p&gt;When I do &quot;ant test&quot; under ql directory, I get many log messages to stderr.&lt;/p&gt;

&lt;p&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 08/11/28 19:04:14 INFO exec.MapOperator: Got partitions: null&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 08/11/28 19:04:14 INFO exec.ReduceSinkOperator: Initializing Self&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 08/11/28 19:04:14 INFO exec.ReduceSinkOperator: Using tag = -1&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 08/11/28 19:04:14 INFO thrift.TBinarySortableProtocol:&lt;br/&gt;
Sort order is &quot;&quot;&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 08/11/28 19:04:14 INFO thrift.TBinarySortableProtocol:&lt;br/&gt;
Sort order is &quot;&quot;&lt;br/&gt;
   ....&lt;/p&gt;

&lt;p&gt;I tried setting log level to ERROR in conf/hive-log4j.properties, but these info lines still show up. How can I get rid of them?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;br/&gt;
--Michi&lt;/p&gt;

&lt;p&gt;Joydeep Sen Sarma &amp;lt;jssarma@facebook.com&amp;gt; 	Fri, Nov 28, 2008 at 10:49 PM&lt;br/&gt;
To: &quot;michi@cs.stanford.edu&quot; &amp;lt;michi@cs.stanford.edu&amp;gt;, &quot;hive-users@publists.facebook.com&quot; &amp;lt;hive-users@publists.facebook.com&amp;gt;&lt;br/&gt;
When we run the tests - we run in hadoop &apos;local&apos; mode - and in this mode, we run map-reduce jobs by invoking &apos;hadoop jar ... ExecDriver&apos; cmd line. this was done because we had some issues submitting map-reduce jobs directly (from same jvm) in local mode that we could not resolve.&lt;/p&gt;

&lt;p&gt;The issue is that when we invoke &apos;hadoop jar ... ExecDriver&apos; - we don&apos;t control log4j via hive-log4j. one thing u can try is changing the hadoop&apos;s log4j.properties that hive is picking up (probably hadoopcore/conf/log4j.properties).&lt;/p&gt;

&lt;p&gt;Revisiting this after a long time - I think this can be fixed with some changes to MapRedTask.java (need to add hive-log4j.properties to hadoop classpath here and then reset log4j using this in execdriver). Feel free to file a jira if this is too irritating ..&lt;/p&gt;</description>
                <environment></environment>
        <key id="12409528">HIVE-88</key>
            <summary>hadoop doesn&apos;t use conf/hive-log4j.properties</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="jsensarma">Joydeep Sen Sarma</assignee>
                                    <reporter username="michim">Michi Mutsuzaki</reporter>
                        <labels>
                    </labels>
                <created>Mon, 1 Dec 2008 06:53:47 +0000</created>
                <updated>Fri, 11 Jun 2010 07:07:03 +0000</updated>
                            <resolved>Fri, 11 Jun 2010 07:05:52 +0000</resolved>
                                                                    <component>Configuration</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                    <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12427161">HIVE-543</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12426390">HIVE-517</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12427161">HIVE-543</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73790</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 9 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7rz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121910</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-89] avg() min() max() will get error message</title>
                <link>https://issues.apache.org/jira/browse/HIVE-89</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;When I run select min() , max() or avg() ,I will get error message&lt;/p&gt;

&lt;p&gt;Test table : data rows: 15835023&lt;/p&gt;

&lt;p&gt;error message: FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.ExecDriver&lt;/p&gt;

&lt;p&gt;Hadoop web:50030 message&lt;/p&gt;

&lt;p&gt;From reduce process&lt;/p&gt;


&lt;p&gt;java.io.IOException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.reflect.InvocationTargetException&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.ExecReducer.reduce(ExecReducer.java:173)&lt;br/&gt;
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:391)&lt;br/&gt;
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2122)&lt;br/&gt;
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.reflect.InvocationTargetException&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.process(GroupByOperator.java:243)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.ExecReducer.reduce(ExecReducer.java:168)&lt;br/&gt;
	... 2 more&lt;br/&gt;
Caused by: java.lang.reflect.InvocationTargetException&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.updateAggregations(GroupByOperator.java:210)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.processAggr(GroupByOperator.java:297)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.process(GroupByOperator.java:240)&lt;br/&gt;
	... 3 more&lt;br/&gt;
Caused by: java.lang.NumberFormatException: For input string: &quot;2004-12-22&quot;&lt;br/&gt;
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1224)&lt;br/&gt;
	at java.lang.Double.parseDouble(Double.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.udf.UDAFAvg.aggregate(UDAFAvg.java:42)&lt;br/&gt;
	... 10 more&lt;/p&gt;

</description>
                <environment>&lt;p&gt;hadoop 0.17.2.1 hive 0.17.0&lt;/p&gt;</environment>
        <key id="12409532">HIVE-89</key>
            <summary>avg() min() max() will get error message</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="zshao">Zheng Shao</assignee>
                                    <reporter username="yihuey">YihueyChyi</reporter>
                        <labels>
                    </labels>
                <created>Mon, 1 Dec 2008 07:51:42 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:35 +0000</updated>
                            <resolved>Wed, 10 Dec 2008 06:29:26 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="12651939" author="zshao" created="Mon, 1 Dec 2008 08:58:46 +0000"  >&lt;p&gt;Based on the error message, one row of the data has &quot;2004-12-22&quot; in the column for computing max/min/avg.&lt;/p&gt;

&lt;p&gt;I will change the UDAFs to detect it and treat these numbers as NULL.&lt;/p&gt;</comment>
                            <comment id="12652290" author="yihuey" created="Tue, 2 Dec 2008 06:31:03 +0000"  >&lt;p&gt;Thank you a lot.&lt;/p&gt;
</comment>
                            <comment id="12652294" author="yihuey" created="Tue, 2 Dec 2008 06:47:26 +0000"  >&lt;p&gt;Hi Zheng Shao,&lt;/p&gt;

&lt;p&gt;    But min , max  can&apos;t for date type .It&apos;s very useful function for date type .  &lt;/p&gt;

&lt;p&gt;    Can you have plan for this demand?  &lt;/p&gt;</comment>
                            <comment id="12655111" author="zshao" created="Wed, 10 Dec 2008 06:29:16 +0000"  >&lt;p&gt;It&apos;s already fixed in the new hive code from &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;YihuieyChyi, one temporary way to do min/max for the date is to extract the year, month and day out of the date using predefined functions provided by Hive.&lt;/p&gt;

&lt;p&gt;can you open a new ticket for the direct support of the date type functions?&lt;/p&gt;</comment>
                            <comment id="12655112" author="yihuey" created="Wed, 10 Dec 2008 06:33:26 +0000"  >&lt;p&gt;Thank you a lot . &lt;br/&gt;
I&apos;ll try it ,and give you feedback.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 1 Dec 2008 08:58:46 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>66887</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 7 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7s7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121911</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-90] TestGetDBs assumes a specific File.list() order</title>
                <link>https://issues.apache.org/jira/browse/HIVE-90</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;In the latest trunk TestGetDBs fail on my ubuntu machine. The reason is that it assumes the result from FileStore.getDatabases returns the databases in a specific order. getDatabases() in turn gets the output from File.list() that doesn&apos;t guarantee the order.&lt;br/&gt;
&lt;a href=&quot;http://java.sun.com/javase/6/docs/api/java/io/File.html#list(&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://java.sun.com/javase/6/docs/api/java/io/File.html#list(&lt;/a&gt;)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12409542">HIVE-90</key>
            <summary>TestGetDBs assumes a specific File.list() order</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="johanoskarsson">Johan Oskarsson</assignee>
                                    <reporter username="johanoskarsson">Johan Oskarsson</reporter>
                        <labels>
                    </labels>
                <created>Mon, 1 Dec 2008 11:16:40 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:42 +0000</updated>
                            <resolved>Mon, 8 Dec 2008 20:27:03 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Testing Infrastructure</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12651973" author="johanoskarsson" created="Mon, 1 Dec 2008 11:30:59 +0000"  >&lt;p&gt;Makes sure the unit test doesn&apos;t check the order of the dbs in the list&lt;/p&gt;</comment>
                            <comment id="12652741" author="johanoskarsson" created="Wed, 3 Dec 2008 11:00:55 +0000"  >&lt;p&gt;Notice that there&apos;s a similar issue in TestGetTables, attached new patch that fixes that class too.&lt;/p&gt;</comment>
                            <comment id="12654127" author="johanoskarsson" created="Sat, 6 Dec 2008 16:36:41 +0000"  >&lt;p&gt;Could someone review this please, it&apos;s a very minimal change.&lt;/p&gt;</comment>
                            <comment id="12654171" author="athusoo" created="Sun, 7 Dec 2008 04:06:32 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;looks good to me.&lt;/p&gt;</comment>
                            <comment id="12654555" author="zshao" created="Mon, 8 Dec 2008 20:18:47 +0000"  >&lt;p&gt;Committed. Thanks Johan!&lt;/p&gt;</comment>
                            <comment id="12654557" author="zshao" created="Mon, 8 Dec 2008 20:26:47 +0000"  >&lt;p&gt;svn revision: 724465&lt;/p&gt;</comment>
                            <comment id="12654558" author="zshao" created="Mon, 8 Dec 2008 20:27:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-90&quot; title=&quot;TestGetDBs assumes a specific File.list() order&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-90&quot;&gt;&lt;del&gt;HIVE-90&lt;/del&gt;&lt;/a&gt;. Fixed TestGetDBs for File.list() order. (Johan Oskarsson through zshao)&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12395177" name="HIVE-90.patch" size="1829" author="johanoskarsson" created="Wed, 3 Dec 2008 11:00:55 +0000"/>
                            <attachment id="12395011" name="HIVE-90.patch" size="805" author="johanoskarsson" created="Mon, 1 Dec 2008 11:30:59 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 7 Dec 2008 04:06:32 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73789</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 8 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7sf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121912</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-91] Allow external tables with different partition directory structure</title>
                <link>https://issues.apache.org/jira/browse/HIVE-91</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;A lot of users have datasets in a directory structures similar to this in hdfs: /dataset/yyyy/MM/dd/&amp;lt;one or more files&amp;gt;&lt;br/&gt;
Instead of loading these into Hive the normal way it would be useful to create an external table with the /dataset location and then one partition per yyyy/mm/dd. This would require the partition &quot;naming to directory&quot;-function to be made more flexible.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12409565">HIVE-91</key>
            <summary>Allow external tables with different partition directory structure</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="johanoskarsson">Johan Oskarsson</assignee>
                                    <reporter username="johanoskarsson">Johan Oskarsson</reporter>
                        <labels>
                    </labels>
                <created>Mon, 1 Dec 2008 17:45:44 +0000</created>
                <updated>Fri, 15 Jun 2012 22:50:29 +0000</updated>
                            <resolved>Thu, 22 Jan 2009 20:14:39 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Metastore</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="12652074" author="johanoskarsson" created="Mon, 1 Dec 2008 17:46:42 +0000"  >&lt;p&gt;Comment from Joydeep Sen Sarma on the mailinglist:&lt;br/&gt;
&quot;Or we could have a &apos;format&apos; spec in the create table command for how the directories are named. By default it&apos;s &apos;%key=%value&apos;, but in this case it&apos;s &apos;%value&apos;. this might make it more flexible if we encounter other kinds of directory layouts.&quot;&lt;/p&gt;</comment>
                            <comment id="12655354" author="jsensarma" created="Wed, 10 Dec 2008 21:01:30 +0000"  >&lt;p&gt;one thing is not clear to me:&lt;/p&gt;

&lt;p&gt;when an external table is created pointing to a location - do the subdirectories automatically get registered into corresponding partitions in Hive? similarly - when new subdirectories are added - what happens - does Hive recognize them automatically. (the only other alternative would be to call &apos;load data ...&apos;  where the data directory and the target directory will be the same  - which would probably work - but i don&apos;t think we have tried it out).&lt;/p&gt;

&lt;p&gt;(this is kind of relevant to hive-126 - since we are getting rid of the logic that recognizes partitions based on hdfs contents).&lt;/p&gt;

&lt;p&gt;this seems like a usability issue. if the directories already exist and you are unwilling to alter them (so that hive can convert it into internal table directory structure) - then i presume that there are other apps that work directly against the directory namespace - and perhaps there is already a pipeline to populate these directories on an ongoing basis. this would suggest that hive should just learn about partitions from the hdfs namespace - rather than burden those pipelines to call &apos;load data&apos; and &apos;drop partition&apos; on subdir creation/deletion.&lt;/p&gt;

&lt;p&gt;comments?&lt;/p&gt;</comment>
                            <comment id="12655646" author="johanoskarsson" created="Thu, 11 Dec 2008 14:11:19 +0000"  >&lt;p&gt;My approach would be to have a command to add partitions manually, I have created a jira ticket for it: &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-115&quot; title=&quot;Command for adding partition without loading data&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-115&quot;&gt;&lt;del&gt;HIVE-115&lt;/del&gt;&lt;/a&gt;. There&apos;s also already a method for this in the metastore thrift interface if I&apos;m not mistaken. For us it would be fairly simple to add another command after loading our data into hdfs.&lt;br/&gt;
It would also be a bit tricky to automatically find partitions from HDFS if they have a custom format. I can&apos;t think of a way off the top of my head if you have directories like so: /dataset/2008/12/10/spain where 2008/12/11 is one partition and spain is another. Then we&apos;d have to save more information on the exact directory structure for each partition and it seems to get more complex then it has to at this stage.&lt;/p&gt;</comment>
                            <comment id="12658076" author="prasadc" created="Fri, 19 Dec 2008 12:53:55 +0000"  >&lt;p&gt;can&apos;t this be achieved by adding location (or suffix) parameter to &apos;create or load partition&apos; command. this may even exist right now. How does one define the definition (or template) of the flexible partition naming function? a partition key might have sub-components or order of keys could be different. This is doable but the effort required is not necessary for this functionality. &lt;/p&gt;</comment>
                            <comment id="12658080" author="johanoskarsson" created="Fri, 19 Dec 2008 13:09:29 +0000"  >&lt;p&gt;Do you mean something along the lines of:&lt;br/&gt;
ALTER TABLE table_name ADD PARTITIONS (partition_col = &apos;2008/12/04&apos;, another=&apos;spain&apos;) location (&apos;/wherever/2008/12/04/spain&apos;)&lt;/p&gt;

&lt;p&gt;That would certainly work for our case and looks like a cleaner solution.&lt;/p&gt;</comment>
                            <comment id="12658126" author="prasadc" created="Fri, 19 Dec 2008 17:12:03 +0000"  >&lt;p&gt;yeah that is what i meant. optionally the user can give relative path to the table&apos;s location instead of the complete path.&lt;/p&gt;

&lt;p&gt;alternatively, determining the partition path can be made customizable through a configurable class (the usual way extensions are done in Hadoop world). this path is also cleaner which leaves the implementation to the user who can customize it for each table differently.&lt;/p&gt;

&lt;p&gt;if specifying location everytime a partition is created or loaded could be cumbersome then we can do the above. &lt;/p&gt;</comment>
                            <comment id="12663402" author="johanoskarsson" created="Tue, 13 Jan 2009 18:28:34 +0000"  >&lt;p&gt;This patch allows a user to specify a location when adding a partition as seen in the example query above. The location is relative to the table location. There&apos;s also a unit test included.&lt;/p&gt;</comment>
                            <comment id="12663520" author="prasadc" created="Tue, 13 Jan 2009 22:43:51 +0000"  >&lt;p&gt;Hive.java:&lt;br/&gt;
Can you move the logic of creating new partition into Partition.java (as a new constructor method)? I would like to isolate partition creation code into single class.&lt;br/&gt;
559:560 -&amp;gt; use log for printing and also throw an exception back&lt;/p&gt;

&lt;p&gt;DDLSemanticAnalyzer.java:&lt;br/&gt;
In semantic analysis of the query we just build up the description of the input into a temporary structure and leave the actual creation of Partition objects into DDLTask. Look at analyzeCreateTable method. &lt;/p&gt;

&lt;p&gt;DDLTask.java:&lt;br/&gt;
Usually hive.metastore interfaces are not exposed to hive.ql except for hive.ql.metadata. Rest of hive.ql just use hive.ql.metadata to access metadata functionality (there are couple of instances where we hive.metastore is directly used in hive.ql but they shouldn&apos;t be unless they are simple model objects without any logic). It may be cleaner if DDLTask calls Hive.addPartition(tbl, part_vals, location) and let Hive.java take care of creating partition object and making metastore call. &lt;/p&gt;

&lt;p&gt;Also, tbl.isExternal() can be moved out of the for loop. BTB, why do we want to restrict this to external tables only? The same code can be used in cases where user creates the partition data in the location that internal tables expect but wants to add metadata right?&lt;/p&gt;

</comment>
                            <comment id="12663855" author="johanoskarsson" created="Wed, 14 Jan 2009 19:06:13 +0000"  >&lt;p&gt;Updated patch with the suggestions mentioned. Prasad, can you have a look and make sure I got everything right?&lt;br/&gt;
Also removed the constraint that it has to be an external table.&lt;/p&gt;</comment>
                            <comment id="12665202" author="prasadc" created="Mon, 19 Jan 2009 19:41:27 +0000"  >&lt;p&gt;I should have mentioned this before but could you add some clipositive tests for the grammar changes? (both regular and external)&lt;/p&gt;

&lt;p&gt;TestAddPartition.java&lt;br/&gt;
53: this has not effect. SerializationLib should be set using ql.metadata.Table.setSerializationLib() but it doesn&apos;t matter in this test though.&lt;/p&gt;

&lt;p&gt;Otherwise everything looks good.&lt;/p&gt;</comment>
                            <comment id="12665845" author="johanoskarsson" created="Wed, 21 Jan 2009 15:01:19 +0000"  >&lt;p&gt;Updated patch to include clipositive tests, I have left the rest of the patch as is.&lt;br/&gt;
I left the code TestAddPartition.java:53 there because I get an NPE if I remove it.&lt;/p&gt;</comment>
                            <comment id="12665928" author="prasadc" created="Wed, 21 Jan 2009 19:28:33 +0000"  >&lt;p&gt;looks good. +1&lt;/p&gt;

&lt;p&gt;could post the NPE that you get when line 53 is changed to setSerializationLib()? it shouldn&apos;t be happenning (TestHiveMetaStore.java does similar thing) and i am curious as to why that is happening. but this things needn&apos;t delay the check-in though.&lt;/p&gt;</comment>
                            <comment id="12665951" author="athusoo" created="Wed, 21 Jan 2009 20:11:14 +0000"  >&lt;p&gt;TestAddPartiton failed in the test run...&lt;/p&gt;

&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Running org.apache.hadoop.hive.ql.plan.TestAddPartition&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; FAILED: Error in metadata: MetaException(message:java.lang.NullPointerException null)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Tests run: 1, Failures: 1, Errors: 0, Time elapsed: 7.01 sec&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Test org.apache.hadoop.hive.ql.plan.TestAddPartition FAILED&lt;/p&gt;
</comment>
                            <comment id="12665989" author="prasadc" created="Wed, 21 Jan 2009 22:23:38 +0000"  >&lt;p&gt;could you post the entire stack trace for the exception?&lt;/p&gt;</comment>
                            <comment id="12666108" author="johanoskarsson" created="Thu, 22 Jan 2009 10:10:03 +0000"  >&lt;p&gt;Sorry for the confusion, it seems I uploaded an older version of the patch. This is the right one.&lt;/p&gt;

&lt;p&gt;Prasad: I meant that the NPE appears if I don&apos;t set the serialization lib. This latest patch does it using setSerializationLib in SerDeInfo.&lt;/p&gt;</comment>
                            <comment id="12666277" author="athusoo" created="Thu, 22 Jan 2009 20:14:39 +0000"  >&lt;p&gt;committed. Thanks Johan!!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12410092">HIVE-126</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                            <outwardlinks description="incorporates">
                                        <issuelink>
            <issuekey id="12409976">HIVE-115</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                            <outwardlinks description="breaks">
                                        <issuelink>
            <issuekey id="12560842">HIVE-3148</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12398454" name="HIVE-91.patch" size="40932" author="johanoskarsson" created="Thu, 22 Jan 2009 10:10:03 +0000"/>
                            <attachment id="12398404" name="HIVE-91.patch" size="40845" author="johanoskarsson" created="Wed, 21 Jan 2009 15:01:18 +0000"/>
                            <attachment id="12397906" name="HIVE-91.patch" size="32812" author="johanoskarsson" created="Wed, 14 Jan 2009 19:06:13 +0000"/>
                            <attachment id="12397803" name="HIVE-91.patch" size="30484" author="johanoskarsson" created="Tue, 13 Jan 2009 18:28:34 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 10 Dec 2008 21:01:30 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73788</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 1 week, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7sn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121913</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-92] union all has a problem if no embedding select is present</title>
                <link>https://issues.apache.org/jira/browse/HIVE-92</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;select s2.key as key, s2.value as value from src s2&lt;br/&gt;
  UNION  ALL&lt;br/&gt;
select s1.key as key, s1.value as value from src s1;&lt;/p&gt;


&lt;p&gt;does not work.&lt;/p&gt;

&lt;p&gt;The code assumes that either it is a join or only one source is present&lt;/p&gt;</description>
                <environment></environment>
        <key id="12409597">HIVE-92</key>
            <summary>union all has a problem if no embedding select is present</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="namit">Namit Jain</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Mon, 1 Dec 2008 23:59:45 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:32 +0000</updated>
                            <resolved>Fri, 12 Dec 2008 18:50:26 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12652488" author="namit" created="Tue, 2 Dec 2008 20:09:57 +0000"  >&lt;p&gt;during semantic analysis phase,  treat&lt;/p&gt;

&lt;p&gt;subq1 union subq2 as&lt;/p&gt;

&lt;p&gt;select * from (subq1 union subq2) dummysubq&lt;/p&gt;

</comment>
                            <comment id="12654562" author="namit" created="Mon, 8 Dec 2008 20:45:53 +0000"  >&lt;p&gt;for now, catch this and throw and error during semantic analysis - this should be supported later&lt;/p&gt;</comment>
                            <comment id="12654567" author="athusoo" created="Mon, 8 Dec 2008 20:58:31 +0000"  >&lt;p&gt;Looks good to me. &lt;/p&gt;

&lt;p&gt;I would however fix the error message to say use subquery for union &lt;/p&gt;

&lt;p&gt;instead of union value.&lt;/p&gt;

&lt;p&gt;Please file a separate enhancement for the full union fix...&lt;/p&gt;</comment>
                            <comment id="12654568" author="rsm" created="Mon, 8 Dec 2008 20:59:02 +0000"  >&lt;p&gt;+1 &lt;/p&gt;

&lt;p&gt;looks good. Maybe file another jira to allow subq1 union subq2?&lt;/p&gt;</comment>
                            <comment id="12654621" author="namit" created="Mon, 8 Dec 2008 22:47:44 +0000"  >&lt;p&gt;Raghu, can you accept again: changed error mesg to not have the column name at the end&lt;/p&gt;</comment>
                            <comment id="12654624" author="rsm" created="Mon, 8 Dec 2008 22:50:30 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;Note to committer: The patch file patch-union.1.txt does not appear as the last file in the attachments.&lt;/p&gt;</comment>
                            <comment id="12656112" author="zshao" created="Fri, 12 Dec 2008 18:49:56 +0000"  >&lt;p&gt;Committed revision 724577.&lt;br/&gt;
Thanks Namit!&lt;/p&gt;</comment>
                            <comment id="12656113" author="zshao" created="Fri, 12 Dec 2008 18:50:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-92&quot; title=&quot;union all has a problem if no embedding select is present&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-92&quot;&gt;&lt;del&gt;HIVE-92&lt;/del&gt;&lt;/a&gt;. Fixed union all for non-embedded query. (Namit Jain through zshao)&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12395598" name="patch-union.1.txt" size="2360" author="namit" created="Mon, 8 Dec 2008 22:47:07 +0000"/>
                            <attachment id="12395590" name="patch-union.txt" size="2379" author="namit" created="Mon, 8 Dec 2008 20:45:01 +0000"/>
                            <attachment id="12395121" name="patch1.txt" size="21654" author="namit" created="Tue, 2 Dec 2008 20:09:16 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 8 Dec 2008 20:58:31 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73787</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 7 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7sv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121914</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>
</channel>
</rss>
