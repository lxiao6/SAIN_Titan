<!--
RSS generated by JIRA (7.6.3#76005-sha1:8a4e38d34af948780dbf52044e7aafb13a7cae58) at Tue Jan 22 03:24:29 UTC 2019

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<!-- If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
    <channel>
        <title>ASF JIRA</title>
        <link>https://issues.apache.org/jira/issues/?jql=project+%3D+HIVE+AND+created+%3E%3D+2013-8-21+AND+created+%3C%3D+2013-8-28+ORDER+BY+key+ASC</link>
        <description>An XML representation of a search request</description>
                <language>en-uk</language>
                        <issue start="0" end="37" total="37"/>
                <build-info>
            <version>7.6.3</version>
            <build-number>76005</build-number>
            <build-date>09-01-2018</build-date>
        </build-info>

<item>
            <title>[HIVE-5127] Upgrade xerces and xalan for WebHCat</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5127</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently webhcat log files are full of exceptions like this, which obscures the real output and may cause perf issues.&lt;/p&gt;

&lt;p&gt;Upgrading to more recent versions of xerces/xalan fixes this.&lt;/p&gt;

&lt;p&gt;Add the following to hive/hcatalog/webhcat/svr/pom.xml&lt;br/&gt;
        &amp;lt;dependency&amp;gt;&lt;br/&gt;
            &amp;lt;groupId&amp;gt;xerces&amp;lt;/groupId&amp;gt;&lt;br/&gt;
            &amp;lt;artifactId&amp;gt;xercesImpl&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
            &amp;lt;version&amp;gt;2.9.1&amp;lt;/version&amp;gt;&lt;br/&gt;
        &amp;lt;/dependency&amp;gt;&lt;/p&gt;

&lt;p&gt;13/08/20 16:54:04 ERROR conf.Configuration: Failed to set setXIncludeAware(true) for parser org.apache.xerces.jaxp.DocumentBuilderFactoryImpl@48dbb335:java.lang.UnsupportedOperationException: This parser does not support specification &quot;null&quot; version &quot;null&quot;&lt;br/&gt;
java.lang.UnsupportedOperationException: This parser does not support specification &quot;null&quot; version &quot;null&quot;&lt;br/&gt;
        at javax.xml.parsers.DocumentBuilderFactory.setXIncludeAware(DocumentBuilderFactory.java:590)&lt;br/&gt;
        at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:1892)&lt;br/&gt;
        at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:1861)&lt;br/&gt;
        at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:1778)&lt;br/&gt;
        at org.apache.hadoop.conf.Configuration.get(Configuration.java:870)&lt;br/&gt;
        at org.apache.hadoop.fs.FileSystem.getDefaultUri(FileSystem.java:171)&lt;br/&gt;
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:305)&lt;br/&gt;
        at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:288)&lt;br/&gt;
        at org.apache.hadoop.util.GenericOptionsParser.validateFiles(GenericOptionsParser.java:383)&lt;br/&gt;
        at org.apache.hadoop.util.GenericOptionsParser.processGeneralOptions(GenericOptionsParser.java:281)&lt;br/&gt;
        at org.apache.hadoop.util.GenericOptionsParser.parseGeneralOptions(GenericOptionsParser.java:422)&lt;br/&gt;
        at org.apache.hadoop.util.GenericOptionsParser.&amp;lt;init&amp;gt;(GenericOptionsParser.java:168)&lt;br/&gt;
        at org.apache.hadoop.util.GenericOptionsParser.&amp;lt;init&amp;gt;(GenericOptionsParser.java:151)&lt;br/&gt;
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:64)&lt;br/&gt;
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)&lt;br/&gt;
        at org.apache.hcatalog.templeton.LauncherDelegator$1.run(LauncherDelegator.java:99)&lt;br/&gt;
        at org.apache.hcatalog.templeton.LauncherDelegator$1.run(LauncherDelegator.java:95)&lt;br/&gt;
        at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
        at javax.security.auth.Subject.doAs(Subject.java:396)&lt;br/&gt;
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1441)&lt;br/&gt;
        at org.apache.hcatalog.templeton.LauncherDelegator.queueAsUser(LauncherDelegator.java:95)&lt;br/&gt;
        at org.apache.hcatalog.templeton.LauncherDelegator.enqueueController(LauncherDelegator.java:77)&lt;br/&gt;
        at org.apache.hcatalog.templeton.JarDelegator.run(JarDelegator.java:52)&lt;br/&gt;
        at org.apache.hcatalog.templeton.StreamingDelegator.run(StreamingDelegator.java:53)&lt;br/&gt;
        at org.apache.hcatalog.templeton.Server.mapReduceStreaming(Server.java:596)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)&lt;br/&gt;
        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)&lt;br/&gt;
        at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)&lt;br/&gt;
        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)&lt;br/&gt;
        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)&lt;br/&gt;
        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)&lt;br/&gt;
        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)&lt;br/&gt;
        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)&lt;br/&gt;
        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1480)&lt;br/&gt;
        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1411)&lt;br/&gt;
        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1360)&lt;br/&gt;
        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1350)&lt;br/&gt;
        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)&lt;br/&gt;
        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:538)&lt;br/&gt;
        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:716)&lt;br/&gt;
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:847)&lt;br/&gt;
        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:565)&lt;br/&gt;
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1360)&lt;br/&gt;
        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:384)&lt;br/&gt;
        at org.apache.hadoop.hdfs.web.AuthFilter.doFilter(AuthFilter.java:85)&lt;br/&gt;
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1331)&lt;br/&gt;
        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:477)&lt;br/&gt;
        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1031)&lt;br/&gt;
        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:406)&lt;br/&gt;
        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:965)&lt;br/&gt;
        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:117)&lt;br/&gt;
        at org.eclipse.jetty.server.handler.HandlerList.handle(HandlerList.java:47)&lt;br/&gt;
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:111)&lt;br/&gt;
        at org.eclipse.jetty.server.Server.handle(Server.java:349)&lt;br/&gt;
        at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:449)&lt;br/&gt;
        at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.content(AbstractHttpConnection.java:925)&lt;br/&gt;
        at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:857)&lt;br/&gt;
        at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)&lt;br/&gt;
        at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:76)&lt;br/&gt;
        at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:609)&lt;br/&gt;
        at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:45)&lt;br/&gt;
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:599)&lt;br/&gt;
        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:534)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:680)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12664743">HIVE-5127</key>
            <summary>Upgrade xerces and xalan for WebHCat</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ekoifman">Eugene Koifman</assignee>
                                    <reporter username="ekoifman">Eugene Koifman</reporter>
                        <labels>
                    </labels>
                <created>Wed, 21 Aug 2013 00:07:22 +0000</created>
                <updated>Tue, 21 Jan 2014 18:39:10 +0000</updated>
                            <resolved>Fri, 13 Sep 2013 22:30:41 +0000</resolved>
                                    <version>0.12.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                    <component>WebHCat</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13760844" author="ekoifman" created="Sat, 7 Sep 2013 01:22:17 +0000"  >&lt;p&gt;Turns out only Xerces needs to be upgrade.  Ran WebHCat e2e tests - exception is gone.&lt;/p&gt;</comment>
                            <comment id="13760890" author="hiveqa" created="Sat, 7 Sep 2013 02:52:31 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12601945/HIVE-5127.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12601945/HIVE-5127.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/653/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/653/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/653/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/653/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-653/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1520721.

At revision 1520721.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file hcatalog/webhcat/svr/pom.xml
+ [[ true == \t\r\u\e ]]
+ rm -rf /data/hive-ptest/working/ivy /data/hive-ptest/working/maven
+ mkdir /data/hive-ptest/working/ivy /data/hive-ptest/working/maven
+ ant -Dtest.continue.on.failure=true -Dtest.silent=false -Divy.default.ivy.user.dir=/data/hive-ptest/working/ivy -Dmvn.local.repo=/data/hive-ptest/working/maven clean package test -Dtestcase=nothing
Buildfile: /data/hive-ptest/working/apache-svn-trunk-source/build.xml

clean:
     [echo] Project: hive

clean:
     [echo] Project: anttasks

clean:
     [echo] Project: shims

clean:
     [echo] Project: common

clean:
     [echo] Project: serde

clean:
     [echo] Project: metastore

clean:
     [echo] Project: ql

clean:
     [echo] Project: contrib

clean:
     [echo] Project: service

clean:
     [echo] Project: cli

clean:
     [echo] Project: jdbc

clean:
     [echo] Project: beeline

clean:
     [echo] Project: hwi

clean:
     [echo] Project: hbase-handler

clean:
     [echo] Project: testutils

clean:
     [echo] hcatalog

clean:
     [echo] hcatalog-core

clean:
     [echo] hcatalog-pig-adapter

clean:
     [echo] hcatalog-server-extensions

clean:
     [echo] webhcat

clean:
     [echo] webhcat-java-client

clean:

clean:
     [echo] Project: odbc
     [exec] rm -rf /data/hive-ptest/working/apache-svn-trunk-source/build/odbc /data/hive-ptest/working/apache-svn-trunk-source/build/service/objs /data/hive-ptest/working/apache-svn-trunk-source/build/ql/objs /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/objs

clean-online:
     [echo] Project: hive

clean-offline:

ivy-init-dirs:
     [echo] Project: hive
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/maven

ivy-download:
     [echo] Project: hive
      [get] Getting: http://repo2.maven.org/maven2/org/apache/ivy/ivy/2.3.0/ivy-2.3.0.jar
      [get] To: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/ivy-2.3.0.jar

ivy-probe-antlib:
     [echo] Project: hive

ivy-init-antlib:
     [echo] Project: hive

compile-ant-tasks:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jexl/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

ivy-init-settings:
     [echo] Project: anttasks

ivy-resolve:
     [echo] Project: anttasks
[ivy:resolve] :: Apache Ivy 2.3.0 - 20130110142753 :: http://ant.apache.org/ivy/ ::
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-anttasks;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found velocity#velocity;1.5 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-lang/commons-lang/2.4/commons-lang-2.4.jar ...
[ivy:resolve] ..... (255kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-lang#commons-lang;2.4!commons-lang.jar (38ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/velocity/velocity/1.5/velocity-1.5.jar ...
[ivy:resolve] ....... (382kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] velocity#velocity;1.5!velocity.jar (36ms)
[ivy:resolve] :: resolution report :: resolve 5465ms :: artifacts dl 95ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-anttasks-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-anttasks-default.html

ivy-retrieve:
     [echo] Project: anttasks
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-anttasks
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	2 artifacts copied, 0 already retrieved (638kB/7ms)

compile:
     [echo] anttasks
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ant/build.xml:38: warning: &apos;includeantruntime&apos; was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds
    [javac] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.

deploy-ant-tasks:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

ivy-init-settings:
     [echo] Project: anttasks

ivy-resolve:
     [echo] Project: anttasks
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-anttasks;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found velocity#velocity;1.5 in maven2
[ivy:resolve] :: resolution report :: resolve 498ms :: artifacts dl 3ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-anttasks-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-anttasks-default.html

ivy-retrieve:
     [echo] Project: anttasks
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-anttasks
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	0 artifacts copied, 2 already retrieved (0kB/7ms)

compile:
     [echo] anttasks
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ant/build.xml:38: warning: &apos;includeantruntime&apos; was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds

jar:
     [echo] anttasks
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes/org/apache/hadoop/hive/ant
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/hive-anttasks-0.13.0-SNAPSHOT.jar

init:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

create-dirs:
     [echo] Project: shims
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/test/resources does not exist.

init:
     [echo] Project: shims

create-dirs:
     [echo] Project: common
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/resources
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/resources

init:
     [echo] Project: common

create-dirs:
     [echo] Project: serde
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources does not exist.

init:
     [echo] Project: serde

create-dirs:
     [echo] Project: metastore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources does not exist.

init:
     [echo] Project: metastore

create-dirs:
     [echo] Project: ql
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/resources
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/resources

init:
     [echo] Project: ql

create-dirs:
     [echo] Project: contrib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources does not exist.

init:
     [echo] Project: contrib

create-dirs:
     [echo] Project: service
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources does not exist.

init:
     [echo] Project: service

create-dirs:
     [echo] Project: cli
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/resources does not exist.

init:
     [echo] Project: cli

create-dirs:
     [echo] Project: jdbc
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/test/resources does not exist.

init:
     [echo] Project: jdbc

create-dirs:
     [echo] Project: beeline
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/test/resources does not exist.

init:
     [echo] Project: beeline

create-dirs:
     [echo] Project: hwi
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources does not exist.

init:
     [echo] Project: hwi

create-dirs:
     [echo] Project: hbase-handler
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources does not exist.

init:
     [echo] Project: hbase-handler

create-dirs:
     [echo] Project: testutils
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources does not exist.

init:
     [echo] Project: testutils

init:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build/hcatalog-0.12.0-SNAPSHOT

jar:
     [echo] Project: hive

ivy-init-settings:
     [echo] Project: shims

check-ivy:
     [echo] Project: shims

ivy-resolve:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.zookeeper#zookeeper;3.4.3 in maven2
[ivy:resolve] 	found org.apache.thrift#libthrift;0.9.0 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.4 in maven2
[ivy:resolve] 	found commons-logging#commons-logging-api;1.0.4 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.4 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar ...
[ivy:resolve] .............. (749kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.3!zookeeper.jar (39ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar ...
[ivy:resolve] ....... (339kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.thrift#libthrift;0.9.0!libthrift.jar (29ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging/1.0.4/commons-logging-1.0.4.jar ...
[ivy:resolve] .. (37kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-logging#commons-logging;1.0.4!commons-logging.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging-api/1.0.4/commons-logging-api-1.0.4.jar ...
[ivy:resolve] .. (25kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-logging#commons-logging-api;1.0.4!commons-logging-api.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar ...
[ivy:resolve] ..... (222kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-core-asl;1.8.8!jackson-core-asl.jar (27ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar ...
[ivy:resolve] ............. (652kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-mapper-asl;1.8.8!jackson-mapper-asl.jar (38ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/log4j/log4j/1.2.16/log4j-1.2.16.jar ...
[ivy:resolve] ......... (470kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] log4j#log4j;1.2.16!log4j.jar(bundle) (31ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/guava/guava/11.0.2/guava-11.0.2.jar ...
[ivy:resolve] ............................ (1609kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.guava#guava;11.0.2!guava.jar (50ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-io/commons-io/2.4/commons-io-2.4.jar ...
[ivy:resolve] .... (180kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-io#commons-io;2.4!commons-io.jar (26ms)
[ivy:resolve] :: resolution report :: resolve 9410ms :: artifacts dl 318ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   9   |   9   |   0   ||   9   |   9   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-shims-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-shims-default.html

make-pom:
     [echo] Project: shims
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: shims
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/test/resources does not exist.

init:
     [echo] Project: shims

ivy-retrieve:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	9 artifacts copied, 0 already retrieved (4287kB/19ms)

compile:
     [echo] Project: shims
     [echo] Building shims 0.20

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20/java against hadoop 0.20.2 (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-0.20.2)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.20.shim]
[ivy:resolve] 	found org.apache.hadoop#hadoop-core;0.20.2 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.0.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.3 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.3 in maven2
[ivy:resolve] 	found commons-net#commons-net;1.4.1 in maven2
[ivy:resolve] 	found oro#oro;2.0.8 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api-2.5;6.1.14 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.12 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.12 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-api-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.eclipse.jdt#core;3.1.1 in maven2
[ivy:resolve] 	found ant#ant;1.6.5 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.7.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found net.sf.kosmosfs#kfs;0.3 in maven2
[ivy:resolve] 	found junit#junit;4.5 in maven2
[ivy:resolve] 	found hsqldb#hsqldb;1.8.0.10 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-tools;0.20.2 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-test;0.20.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftplet-api;1.0.0 in maven2
[ivy:resolve] 	found org.apache.mina#mina-core;2.0.0-M5 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.5.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-core;1.0.0 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-core/0.20.2/hadoop-core-0.20.2.jar ...
[ivy:resolve] ............................................. (2624kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-core;0.20.2!hadoop-core.jar (91ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-tools/0.20.2/hadoop-tools-0.20.2.jar ...
[ivy:resolve] ... (68kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-tools;0.20.2!hadoop-tools.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-test/0.20.2/hadoop-test-0.20.2.jar ...
[ivy:resolve] .......................... (1527kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-test;0.20.2!hadoop-test.jar (32ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-cli/commons-cli/1.2/commons-cli-1.2.jar ...
[ivy:resolve] .. (40kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-cli#commons-cli;1.2!commons-cli.jar (35ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/xmlenc/xmlenc/0.52/xmlenc-0.52.jar ...
[ivy:resolve] .. (14kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] xmlenc#xmlenc;0.52!xmlenc.jar (34ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar ...
[ivy:resolve] ...... (273kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-httpclient#commons-httpclient;3.0.1!commons-httpclient.jar (38ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-codec/commons-codec/1.3/commons-codec-1.3.jar ...
[ivy:resolve] .. (45kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-codec#commons-codec;1.3!commons-codec.jar (34ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar ...
[ivy:resolve] .... (176kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-net#commons-net;1.4.1!commons-net.jar (39ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty/6.1.14/jetty-6.1.14.jar ...
[ivy:resolve] ......... (504kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty;6.1.14!jetty.jar (43ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.14/jetty-util-6.1.14.jar ...
[ivy:resolve] .... (159kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty-util;6.1.14!jetty-util.jar (50ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar ...
[ivy:resolve] ... (74kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-runtime;5.5.12!jasper-runtime.jar (37ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar ...
[ivy:resolve] ........ (395kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-compiler;5.5.12!jasper-compiler.jar (47ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar ...
[ivy:resolve] .... (131kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jsp-api-2.1;6.1.14!jsp-api-2.1.jar (36ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar ...
[ivy:resolve] .................. (1000kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jsp-2.1;6.1.14!jsp-2.1.jar (57ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-el/commons-el/1.0/commons-el-1.0.jar ...
[ivy:resolve] ... (109kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-el#commons-el;1.0!commons-el.jar (41ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar ...
[ivy:resolve] ....... (368kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.java.dev.jets3t#jets3t;0.7.1!jets3t.jar (64ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar ...
[ivy:resolve] .... (129kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#servlet-api-2.5;6.1.14!servlet-api-2.5.jar (38ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar ...
[ivy:resolve] .. (11kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.sf.kosmosfs#kfs;0.3!kfs.jar (37ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/4.5/junit-4.5.jar ...
[ivy:resolve] ..... (194kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] junit#junit;4.5!junit.jar (38ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar ...
[ivy:resolve] ............ (690kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] hsqldb#hsqldb;1.8.0.10!hsqldb.jar (47ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/oro/oro/2.0.8/oro-2.0.8.jar ...
[ivy:resolve] .. (63kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] oro#oro;2.0.8!oro.jar (34ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar ...
[ivy:resolve] .................................................................................................. (3483kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.eclipse.jdt#core;3.1.1!core.jar (100ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/ant/ant/1.6.5/ant-1.6.5.jar ...
[ivy:resolve] ................. (1009kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] ant#ant;1.6.5!ant.jar (53ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar ...
[ivy:resolve] .. (59kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-logging#commons-logging;1.1.1!commons-logging.jar (42ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftplet-api/1.0.0/ftplet-api-1.0.0.jar ...
[ivy:resolve] .. (22kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftplet-api;1.0.0!ftplet-api.jar(bundle) (38ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/mina/mina-core/2.0.0-M5/mina-core-2.0.0-M5.jar ...
[ivy:resolve] ........... (622kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.mina#mina-core;2.0.0-M5!mina-core.jar(bundle) (47ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftpserver-core/1.0.0/ftpserver-core-1.0.0.jar ...
[ivy:resolve] ...... (264kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftpserver-core;1.0.0!ftpserver-core.jar(bundle) (78ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftpserver-deprecated/1.0.0-M2/ftpserver-deprecated-1.0.0-M2.jar ...
[ivy:resolve] .. (31kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2!ftpserver-deprecated.jar (59ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.5.2/slf4j-api-1.5.2.jar ...
[ivy:resolve] .. (16kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-api;1.5.2!slf4j-api.jar (34ms)
[ivy:resolve] :: resolution report :: resolve 38865ms :: artifacts dl 1435ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	junit#junit;3.8.1 by [junit#junit;4.5] in [hadoop0.20.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.0.3 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20.shim]
[ivy:resolve] 	commons-codec#commons-codec;1.2 by [commons-codec#commons-codec;1.3] in [hadoop0.20.shim]
[ivy:resolve] 	commons-httpclient#commons-httpclient;3.1 by [commons-httpclient#commons-httpclient;3.0.1] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M4 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.ftpserver#ftplet-api;1.0.0-M2 by [org.apache.ftpserver#ftplet-api;1.0.0] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.ftpserver#ftpserver-core;1.0.0-M2 by [org.apache.ftpserver#ftpserver-core;1.0.0] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M2 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20.shim]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|  hadoop0.20.shim |   37  |   30  |   30  |   8   ||   29  |   29  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.20.shim]
[ivy:retrieve] 	29 artifacts copied, 0 already retrieved (14115kB/94ms)
    [javac] Compiling 17 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [echo] Building shims 0.20S

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/common-secure/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20S/java against hadoop 1.1.2 (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-1.1.2)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.20S.shim]
[ivy:resolve] 	found org.apache.hadoop#hadoop-core;1.1.2 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-core;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-json;1.8 in maven2
[ivy:resolve] 	found org.codehaus.jettison#jettison;1.1 in maven2
[ivy:resolve] 	found stax#stax-api;1.0.1 in maven2
[ivy:resolve] 	found com.sun.xml.bind#jaxb-impl;2.2.3-1 in maven2
[ivy:resolve] 	found javax.xml.bind#jaxb-api;2.2.2 in maven2
[ivy:resolve] 	found javax.xml.stream#stax-api;1.0-2 in maven2
[ivy:resolve] 	found javax.activation#activation;1.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-jaxrs;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-xc;1.7.1 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-server;1.8 in maven2
[ivy:resolve] 	found asm#asm;3.1 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.1 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.0.1 in maven2
[ivy:resolve] 	found junit#junit;3.8.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.3 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.commons#commons-math;2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found commons-digester#commons-digester;1.8 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils;1.7.0 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils-core;1.8.0 in maven2
[ivy:resolve] 	found commons-net#commons-net;1.4.1 in maven2
[ivy:resolve] 	found oro#oro;2.0.8 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api;2.5-20081211 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.12 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.12 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-api-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api-2.5;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.eclipse.jdt#core;3.1.1 in maven2
[ivy:resolve] 	found ant#ant;1.6.5 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.6.1 in maven2
[ivy:resolve] 	found hsqldb#hsqldb;1.8.0.10 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-tools;1.1.2 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-test;1.1.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftplet-api;1.0.0 in maven2
[ivy:resolve] 	found org.apache.mina#mina-core;2.0.0-M5 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.5.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-core;1.0.0 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-core/1.1.2/hadoop-core-1.1.2.jar ...
[ivy:resolve] .......................................................................................................... (3941kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-core;1.1.2!hadoop-core.jar (95ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-tools/1.1.2/hadoop-tools-1.1.2.jar ...
[ivy:resolve] ...... (299kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-tools;1.1.2!hadoop-tools.jar (19ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-test/1.1.2/hadoop-test-1.1.2.jar ...
[ivy:resolve] ...................................................... (2712kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-test;1.1.2!hadoop-test.jar (57ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar ...
[ivy:resolve] ........ (447kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-core;1.8!jersey-core.jar(bundle) (43ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar ...
[ivy:resolve] .... (144kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-json;1.8!jersey-json.jar(bundle) (37ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar ...
[ivy:resolve] ............ (678kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-server;1.8!jersey-server.jar(bundle) (53ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-io/commons-io/2.1/commons-io-2.1.jar ...
[ivy:resolve] .... (159kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-io#commons-io;2.1!commons-io.jar (38ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-codec/commons-codec/1.4/commons-codec-1.4.jar ...
[ivy:resolve] .. (56kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-codec#commons-codec;1.4!commons-codec.jar (37ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-math/2.1/commons-math-2.1.jar ...
[ivy:resolve] ............... (812kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.commons#commons-math;2.1!commons-math.jar (49ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar ...
[ivy:resolve] ...... (291kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-configuration#commons-configuration;1.6!commons-configuration.jar (44ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar ...
[ivy:resolve] .......... (527kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty;6.1.26!jetty.jar (45ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar ...
[ivy:resolve] .... (172kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty-util;6.1.26!jetty-util.jar (42ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar ...
[ivy:resolve] ...... (314kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.java.dev.jets3t#jets3t;0.6.1!jets3t.jar (44ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar ...
[ivy:resolve] ... (66kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jettison#jettison;1.1!jettison.jar(bundle) (37ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar ...
[ivy:resolve] ................ (869kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.xml.bind#jaxb-impl;2.2.3-1!jaxb-impl.jar (48ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.7.1/jackson-jaxrs-1.7.1.jar ...
[ivy:resolve] .. (17kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-jaxrs;1.7.1!jackson-jaxrs.jar (59ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar ...
[ivy:resolve] .. (30kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-xc;1.7.1!jackson-xc.jar (51ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/stax/stax-api/1.0.1/stax-api-1.0.1.jar ...
[ivy:resolve] .. (25kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] stax#stax-api;1.0.1!stax-api.jar (55ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar ...
[ivy:resolve] ... (102kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.xml.bind#jaxb-api;2.2.2!jaxb-api.jar (36ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar ...
[ivy:resolve] .. (22kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.xml.stream#stax-api;1.0-2!stax-api.jar (39ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/activation/activation/1.1/activation-1.1.jar ...
[ivy:resolve] .. (61kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.activation#activation;1.1!activation.jar (37ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/asm/asm/3.1/asm-3.1.jar ...
[ivy:resolve] .. (42kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] asm#asm;3.1!asm.jar (35ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/3.8.1/junit-3.8.1.jar ...
[ivy:resolve] ... (118kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] junit#junit;3.8.1!junit.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar ...
[ivy:resolve] ........... (561kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-collections#commons-collections;3.2.1!commons-collections.jar (48ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-digester/commons-digester/1.8/commons-digester-1.8.jar ...
[ivy:resolve] .... (140kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-digester#commons-digester;1.8!commons-digester.jar (43ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar ...
[ivy:resolve] ..... (201kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-beanutils#commons-beanutils-core;1.8.0!commons-beanutils-core.jar (38ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar ...
[ivy:resolve] .... (184kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-beanutils#commons-beanutils;1.7.0!commons-beanutils.jar (48ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar ...
[ivy:resolve] .... (130kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#servlet-api;2.5-20081211!servlet-api.jar (57ms)
[ivy:resolve] :: resolution report :: resolve 36181ms :: artifacts dl 1329ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	org.codehaus.jackson#jackson-core-asl;1.7.1 by [org.codehaus.jackson#jackson-core-asl;1.8.8] in [hadoop0.20S.shim]
[ivy:resolve] 	org.codehaus.jackson#jackson-mapper-asl;1.7.1 by [org.codehaus.jackson#jackson-mapper-asl;1.8.8] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.0.3 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-codec#commons-codec;1.2 by [commons-codec#commons-codec;1.4] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.1 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-codec#commons-codec;1.3 by [commons-codec#commons-codec;1.4] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-httpclient#commons-httpclient;3.1 by [commons-httpclient#commons-httpclient;3.0.1] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M4 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.ftpserver#ftplet-api;1.0.0-M2 by [org.apache.ftpserver#ftplet-api;1.0.0] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.ftpserver#ftpserver-core;1.0.0-M2 by [org.apache.ftpserver#ftpserver-core;1.0.0] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M2 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20S.shim]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	| hadoop0.20S.shim |   62  |   30  |   30  |   11  ||   51  |   28  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.20S.shim]
[ivy:retrieve] 	51 artifacts copied, 0 already retrieved (22876kB/75ms)
    [javac] Compiling 15 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [echo] Building shims 0.23

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/common-secure/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.23/java against hadoop 2.0.5-alpha (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-2.0.5-alpha)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.23.shim]
[ivy:resolve] 	found org.apache.hadoop#hadoop-common;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-annotations;2.0.5-alpha in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-math;2.1 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.1 in maven2
[ivy:resolve] 	found commons-net#commons-net;3.1 in maven2
[ivy:resolve] 	found javax.servlet#servlet-api;2.5 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.26 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-core;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-json;1.8 in maven2
[ivy:resolve] 	found org.codehaus.jettison#jettison;1.1 in maven2
[ivy:resolve] 	found stax#stax-api;1.0.1 in maven2
[ivy:resolve] 	found com.sun.xml.bind#jaxb-impl;2.2.3-1 in maven2
[ivy:resolve] 	found javax.xml.bind#jaxb-api;2.2.2 in maven2
[ivy:resolve] 	found javax.activation#activation;1.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-jaxrs;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-xc;1.8.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-server;1.8 in maven2
[ivy:resolve] 	found asm#asm;3.2 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.17 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.6.1 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.5 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-digester#commons-digester;1.8 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils;1.7.0 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils-core;1.8.0 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.5.3 in maven2
[ivy:resolve] 	found com.thoughtworks.paranamer#paranamer;2.3 in maven2
[ivy:resolve] 	found org.xerial.snappy#snappy-java;1.0.3.2 in maven2
[ivy:resolve] 	found net.sf.kosmosfs#kfs;0.3 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.0a in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-auth;2.0.5-alpha in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found com.jcraft#jsch;0.1.42 in maven2
[ivy:resolve] 	found org.apache.zookeeper#zookeeper;3.4.2 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.23 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.23 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found javax.servlet.jsp#jsp-api;2.1 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-core;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-common;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-api;2.0.5-alpha in maven2
[ivy:resolve] 	found com.google.inject.extensions#guice-servlet;3.0 in maven2
[ivy:resolve] 	found com.google.inject#guice;3.0 in maven2
[ivy:resolve] 	found javax.inject#javax.inject;1 in maven2
[ivy:resolve] 	found aopalliance#aopalliance;1.0 in maven2
[ivy:resolve] 	found org.sonatype.sisu.inject#cglib;2.2.1-v20090111 in maven2
[ivy:resolve] 	found io.netty#netty;3.5.11.Final in maven2
[ivy:resolve] 	found com.sun.jersey.jersey-test-framework#jersey-test-framework-grizzly2;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey.contribs#jersey-guice;1.8 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-archives;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-hdfs;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-common;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-client;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-common;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-tests;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-nodemanager;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-resourcemanager;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-web-proxy;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-app;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-hs;2.0.5-alpha in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.0.5-alpha/hadoop-common-2.0.5-alpha.jar ...
[ivy:resolve] ....................................... (2295kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-common;2.0.5-alpha!hadoop-common.jar (47ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.0.5-alpha/hadoop-common-2.0.5-alpha-tests.jar ...
[ivy:resolve] .................... (1151kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-common;2.0.5-alpha!hadoop-common.jar(tests) (26ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-core/2.0.5-alpha/hadoop-mapreduce-client-core-2.0.5-alpha.jar ...
[ivy:resolve] ...................... (1325kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-core;2.0.5-alpha!hadoop-mapreduce-client-core.jar (27ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-archives/2.0.5-alpha/hadoop-archives-2.0.5-alpha.jar ...
[ivy:resolve] .. (20kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-archives;2.0.5-alpha!hadoop-archives.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.0.5-alpha/hadoop-hdfs-2.0.5-alpha.jar ...
[ivy:resolve] ........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................ (4241kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs;2.0.5-alpha!hadoop-hdfs.jar (298ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.0.5-alpha/hadoop-hdfs-2.0.5-alpha-tests.jar ...
[ivy:resolve] ............................ (1631kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs;2.0.5-alpha!hadoop-hdfs.jar(tests) (35ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.0.5-alpha/hadoop-mapreduce-client-jobclient-2.0.5-alpha-tests.jar ...
[ivy:resolve] ....................... (1350kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.0.5-alpha!hadoop-mapreduce-client-jobclient.jar(tests) (30ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.0.5-alpha/hadoop-mapreduce-client-jobclient-2.0.5-alpha.jar ...
[ivy:resolve] .. (32kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.0.5-alpha!hadoop-mapreduce-client-jobclient.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-common/2.0.5-alpha/hadoop-mapreduce-client-common-2.0.5-alpha.jar ...
[ivy:resolve] ........... (579kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-common;2.0.5-alpha!hadoop-mapreduce-client-common.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-tests/2.0.5-alpha/hadoop-yarn-server-tests-2.0.5-alpha-tests.jar ...
[ivy:resolve] .. (39kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-tests;2.0.5-alpha!hadoop-yarn-server-tests.jar(tests) (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-app/2.0.5-alpha/hadoop-mapreduce-client-app-2.0.5-alpha.jar ...
[ivy:resolve] ......... (463kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-app;2.0.5-alpha!hadoop-mapreduce-client-app.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-hs/2.0.5-alpha/hadoop-mapreduce-client-hs-2.0.5-alpha.jar ...
[ivy:resolve] ... (111kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-hs;2.0.5-alpha!hadoop-mapreduce-client-hs.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-annotations/2.0.5-alpha/hadoop-annotations-2.0.5-alpha.jar ...
[ivy:resolve] .. (16kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-annotations;2.0.5-alpha!hadoop-annotations.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar ...
[ivy:resolve] ...... (297kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-httpclient#commons-httpclient;3.1!commons-httpclient.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-net/commons-net/3.1/commons-net-3.1.jar ...
[ivy:resolve] ...... (266kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-net#commons-net;3.1!commons-net.jar (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar ...
[ivy:resolve] ... (102kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.servlet#servlet-api;2.5!servlet-api.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/log4j/log4j/1.2.17/log4j-1.2.17.jar ...
[ivy:resolve] ......... (478kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] log4j#log4j;1.2.17!log4j.jar(bundle) (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-lang/commons-lang/2.5/commons-lang-2.5.jar ...
[ivy:resolve] ...... (272kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-lang#commons-lang;2.5!commons-lang.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar ...
[ivy:resolve] .. (24kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-api;1.6.1!slf4j-api.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro/1.5.3/avro-1.5.3.jar ...
[ivy:resolve] ...... (257kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro;1.5.3!avro.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.4.0a/protobuf-java-2.4.0a.jar ...
[ivy:resolve] ........ (439kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.protobuf#protobuf-java;2.4.0a!protobuf-java.jar (39ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-auth/2.0.5-alpha/hadoop-auth-2.0.5-alpha.jar ...
[ivy:resolve] .. (46kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-auth;2.0.5-alpha!hadoop-auth.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar ...
[ivy:resolve] .... (181kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.jcraft#jsch;0.1.42!jsch.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.2/zookeeper-3.4.2.jar ...
[ivy:resolve] .............. (746kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.2!zookeeper.jar (24ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar ...
[ivy:resolve] .. (32kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.code.findbugs#jsr305;1.3.9!jsr305.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.8.8/jackson-jaxrs-1.8.8.jar ...
[ivy:resolve] .. (17kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-jaxrs;1.8.8!jackson-jaxrs.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.8.8/jackson-xc-1.8.8.jar ...
[ivy:resolve] .. (31kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-xc;1.8.8!jackson-xc.jar (31ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/asm/asm/3.2/asm-3.2.jar ...
[ivy:resolve] .. (42kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] asm#asm;3.2!asm.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar ...
[ivy:resolve] .. (28kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.3!paranamer.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.0.3.2/snappy-java-1.0.3.2.jar ...
[ivy:resolve] ................. (972kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.0.3.2!snappy-java.jar(bundle) (28ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar ...
[ivy:resolve] .. (9kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-log4j12;1.6.1!slf4j-log4j12.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar ...
[ivy:resolve] ........ (398kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-compiler;5.5.23!jasper-compiler.jar (18ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar ...
[ivy:resolve] ... (75kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-runtime;5.5.23!jasper-runtime.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar ...
[ivy:resolve] ... (98kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.servlet.jsp#jsp-api;2.1!jsp-api.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-common/2.0.5-alpha/hadoop-yarn-common-2.0.5-alpha.jar ...
[ivy:resolve] .................. (1050kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-common;2.0.5-alpha!hadoop-yarn-common.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar ...
[ivy:resolve] .. (63kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.inject.extensions#guice-servlet;3.0!guice-servlet.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/io/netty/netty/3.5.11.Final/netty-3.5.11.Final.jar ...
[ivy:resolve] ................... (1106kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] io.netty#netty;3.5.11.Final!netty.jar(bundle) (24ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-api/2.0.5-alpha/hadoop-yarn-api-2.0.5-alpha.jar ...
[ivy:resolve] .................. (1014kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-api;2.0.5-alpha!hadoop-yarn-api.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/inject/guice/3.0/guice-3.0.jar ...
[ivy:resolve] ............ (693kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.inject#guice;3.0!guice.jar (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-test-framework/jersey-test-framework-grizzly2/1.8/jersey-test-framework-grizzly2-1.8.jar ...
[ivy:resolve] .. (12kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey.jersey-test-framework#jersey-test-framework-grizzly2;1.8!jersey-test-framework-grizzly2.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/contribs/jersey-guice/1.8/jersey-guice-1.8.jar ...
[ivy:resolve] .. (14kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey.contribs#jersey-guice;1.8!jersey-guice.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/inject/javax.inject/1/javax.inject-1.jar ...
[ivy:resolve] .. (2kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.inject#javax.inject;1!javax.inject.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/aopalliance/aopalliance/1.0/aopalliance-1.0.jar ...
[ivy:resolve] .. (4kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] aopalliance#aopalliance;1.0!aopalliance.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/sonatype/sisu/inject/cglib/2.2.1-v20090111/cglib-2.2.1-v20090111.jar ...
[ivy:resolve] ...... (272kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.sonatype.sisu.inject#cglib;2.2.1-v20090111!cglib.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-client/2.0.5-alpha/hadoop-yarn-client-2.0.5-alpha.jar ...
[ivy:resolve] .. (28kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-client;2.0.5-alpha!hadoop-yarn-client.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-common/2.0.5-alpha/hadoop-yarn-server-common-2.0.5-alpha.jar ...
[ivy:resolve] .... (148kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-common;2.0.5-alpha!hadoop-yarn-server-common.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.0.5-alpha/hadoop-yarn-server-nodemanager-2.0.5-alpha.jar ...
[ivy:resolve] ........ (404kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-nodemanager;2.0.5-alpha!hadoop-yarn-server-nodemanager.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.0.5-alpha/hadoop-yarn-server-resourcemanager-2.0.5-alpha.jar ...
[ivy:resolve] .......... (517kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-resourcemanager;2.0.5-alpha!hadoop-yarn-server-resourcemanager.jar (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.0.5-alpha/hadoop-yarn-server-web-proxy-2.0.5-alpha.jar ...
[ivy:resolve] .. (24kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-web-proxy;2.0.5-alpha!hadoop-yarn-server-web-proxy.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.0.5-alpha/hadoop-mapreduce-client-shuffle-2.0.5-alpha.jar ...
[ivy:resolve] .. (20kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.0.5-alpha!hadoop-mapreduce-client-shuffle.jar (5ms)
[ivy:resolve] :: resolution report :: resolve 64293ms :: artifacts dl 1139ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|  hadoop0.23.shim |   74  |   47  |   47  |   0   ||   77  |   50  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.23.shim]
[ivy:retrieve] 	77 artifacts copied, 0 already retrieved (31997kB/108ms)
    [javac] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.23/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.

jar:
     [echo] Project: shims
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:48:50 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-shims
[ivy:publish] 	published hive-shims to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.13.0-SNAPSHOT/jars/hive-shims.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: common

check-ivy:
     [echo] Project: common

ivy-resolve:
     [echo] Project: common
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-common;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.13.0-SNAPSHOT/jars/hive-shims.jar ...
[ivy:resolve] .... (140kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-shims;0.13.0-SNAPSHOT!hive-shims.jar (4ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar ...
[ivy:resolve] ..... (235kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.commons#commons-compress;1.4.1!commons-compress.jar (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/tukaani/xz/1.0/xz-1.0.jar ...
[ivy:resolve] ... (92kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.tukaani#xz;1.0!xz.jar (12ms)
[ivy:resolve] :: resolution report :: resolve 9206ms :: artifacts dl 36ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   6   |   3   |   3   |   0   ||   6   |   3   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-common-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-common-default.html

make-pom:
     [echo] Project: common
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/common/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: common

init:
     [echo] Project: common

setup:
     [echo] Project: common

ivy-retrieve:
     [echo] Project: common
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-common
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	4 artifacts copied, 2 already retrieved (508kB/6ms)

compile:
     [echo] Project: common
    [javac] Compiling 25 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/common/src/java/org/apache/hadoop/hive/common/ObjectPair.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes

jar:
     [echo] Project: common
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/common/hive-common-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-common;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:49:19 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/common/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-common
[ivy:publish] 	published hive-common to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.13.0-SNAPSHOT/jars/hive-common.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: serde

check-ivy:
     [echo] Project: serde

ivy-resolve:
     [echo] Project: serde
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-serde;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-common;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.13.0-SNAPSHOT/jars/hive-common.jar ...
[ivy:resolve] ... (95kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-common;0.13.0-SNAPSHOT!hive-common.jar (3ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar ...
[ivy:resolve] ...................... (1315kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mockito#mockito-all;1.8.2!mockito-all.jar (27ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar ...
[ivy:resolve] ...... (268kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.thrift#libfb303;0.9.0!libfb303.jar (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro/1.7.1/avro-1.7.1.jar ...
[ivy:resolve] ...... (290kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro;1.7.1!avro.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar ...
[ivy:resolve] .... (164kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro-mapred;1.7.1!avro-mapred.jar (8ms)
[ivy:resolve] :: resolution report :: resolve 7401ms :: artifacts dl 74ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   14  |   5   |   5   |   0   ||   14  |   5   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-serde-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-serde-default.html

make-pom:
     [echo] Project: serde
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: serde
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources does not exist.

init:
     [echo] Project: serde

ivy-retrieve:
     [echo] Project: serde
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-serde
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	8 artifacts copied, 6 already retrieved (2227kB/25ms)

dynamic-serde:

compile:
     [echo] Project: serde
    [javac] Compiling 325 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes/org/apache/hadoop/hive/serde2/typeinfo/package-info.class

jar:
     [echo] Project: serde
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/hive-serde-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-serde;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:49:38 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-serde
[ivy:publish] 	published hive-serde to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.13.0-SNAPSHOT/jars/hive-serde.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: metastore

check-ivy:
     [echo] Project: metastore

ivy-resolve:
     [echo] Project: metastore
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-metastore;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.13.0-SNAPSHOT/jars/hive-serde.jar ...
[ivy:resolve] ............ (663kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-serde;0.13.0-SNAPSHOT!hive-serde.jar (19ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/antlr/3.4/antlr-3.4.jar ...
[ivy:resolve] ................... (1086kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.antlr#antlr;3.4!antlr.jar (38ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar ...
[ivy:resolve] .... (160kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.antlr#antlr-runtime;3.4!antlr-runtime.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/ST4/4.0.4/ST4-4.0.4.jar ...
[ivy:resolve] ..... (231kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.antlr#ST4;4.0.4!ST4.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar ...
[ivy:resolve] ... (112kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.jolbox#bonecp;0.7.1.RELEASE!bonecp.jar(bundle) (36ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar ...
[ivy:resolve] ... (93kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-pool#commons-pool;1.5.4!commons-pool.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar ...
[ivy:resolve] ....... (329kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.datanucleus#datanucleus-api-jdo;3.2.1!datanucleus-api-jdo.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar ...
[ivy:resolve] ............................. (1759kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.datanucleus#datanucleus-core;3.2.2!datanucleus-core.jar (36ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar ...
[ivy:resolve] ............................. (1728kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.datanucleus#datanucleus-rdbms;3.2.1!datanucleus-rdbms.jar (35ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar ...
[ivy:resolve] ..... (196kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.jdo#jdo-api;3.0.1!jdo-api.jar (38ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar ...
[ivy:resolve] ....................................... (2389kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.derby#derby;10.4.2.0!derby.jar (85ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/guava/guava/r08/guava-r08.jar ...
[ivy:resolve] ................... (1088kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.guava#guava;r08!guava.jar (72ms)
[ivy:resolve] :: resolution report :: resolve 10845ms :: artifacts dl 419ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   27  |   12  |   12  |   1   ||   26  |   12  |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-metastore-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-metastore-default.html

make-pom:
     [echo] Project: metastore
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: metastore
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources does not exist.

init:
     [echo] Project: metastore

metastore-init:
     [echo] Project: metastore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/gen/antlr/gen-java/org/apache/hadoop/hive/metastore/parser

ivy-retrieve:
     [echo] Project: metastore
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-metastore
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	12 artifacts copied, 14 already retrieved (9838kB/31ms)

build-grammar:
     [echo] Project: metastore
     [echo] Building Grammar /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g  ....

model-compile:
     [echo] Project: metastore
    [javac] Compiling 24 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes

core-compile:
     [echo] Project: metastore
    [javac] Compiling 104 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes/org/apache/hadoop/hive/metastore/parser/package-info.class

model-enhance:
     [echo] Project: metastore
[datanucleusenhancer] log4j:WARN No appenders could be found for logger (DataNucleus.General).
[datanucleusenhancer] log4j:WARN Please initialize the log4j system properly.
[datanucleusenhancer] log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
[datanucleusenhancer] DataNucleus Enhancer (version 3.2.2) for API &quot;JDO&quot; using JRE &quot;1.6&quot;
[datanucleusenhancer] DataNucleus Enhancer : Classpath
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/hive-anttasks-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/common/hive-common-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/serde/hive-serde-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/activation-1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ant-1.6.5.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/asm-3.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-beanutils-1.7.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-beanutils-core-1.8.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-cli-1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-codec-1.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-collections-3.2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-configuration-1.6.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-digester-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-el-1.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-httpclient-3.0.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-io-2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-lang-2.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-logging-1.1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-math-2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-net-1.4.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/core-3.1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftplet-api-1.0.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftpserver-core-1.0.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftpserver-deprecated-1.0.0-M2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-core-1.1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-test-1.1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-tools-1.1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hsqldb-1.8.0.10.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-core-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-jaxrs-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-mapper-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-xc-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jasper-compiler-5.5.12.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jasper-runtime-5.5.12.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jaxb-api-2.2.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jaxb-impl-2.2.3-1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-core-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-json-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-server-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jets3t-0.6.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jettison-1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jetty-6.1.26.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jetty-util-6.1.26.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jsp-2.1-6.1.14.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jsp-api-2.1-6.1.14.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/junit-3.8.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/mina-core-2.0.0-M5.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/oro-2.0.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/servlet-api-2.5-20081211.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/servlet-api-2.5-6.1.14.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/slf4j-api-1.5.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/stax-api-1.0-2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/stax-api-1.0.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/xmlenc-0.52.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/ST4-4.0.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/antlr-3.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/antlr-runtime-3.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-mapred-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/bonecp-0.7.1.RELEASE.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-cli-1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-codec-1.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-compress-1.4.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-io-2.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-lang-2.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-logging-1.0.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-logging-api-1.0.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-pool-1.5.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-api-jdo-3.2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-core-3.2.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-rdbms-3.2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/derby-10.4.2.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/guava-11.0.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/guava-r08.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-common-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-serde-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-shims-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-core-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-mapper-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jdo-api-3.0.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libfb303-0.9.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libthrift-0.9.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/log4j-1.2.16.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/mockito-all-1.8.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/slf4j-api-1.6.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/slf4j-log4j12-1.6.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/velocity-1.5.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/xz-1.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/zookeeper-3.4.3.jar
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDatabase
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFieldSchema
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MType
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTable
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MOrder
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStringList
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartition
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MIndex
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRole
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRoleMap
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MMasterKey
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDelegationToken
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics
[datanucleusenhancer] DataNucleus Enhancer completed with success for 24 classes. Timings : input=688 ms, enhance=1171 ms, total=1859 ms. Consult the log for full details

compile:
     [echo] Project: metastore

jar:
     [echo] Project: metastore
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/hive-metastore-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-metastore;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:50:18 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-metastore
[ivy:publish] 	published hive-metastore to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.13.0-SNAPSHOT/jars/hive-metastore.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: ql

check-ivy:
     [echo] Project: ql

ivy-resolve:
     [echo] Project: ql
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-exec;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.13.0-SNAPSHOT/jars/hive-metastore.jar ...
[ivy:resolve] ..................................................... (3268kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-metastore;0.13.0-SNAPSHOT!hive-metastore.jar (44ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.4.1/protobuf-java-2.4.1.jar ...
[ivy:resolve] ........ (439kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.protobuf#protobuf-java;2.4.1!protobuf-java.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/iq80/snappy/snappy/0.2/snappy-0.2.jar ...
[ivy:resolve] .. (47kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.iq80.snappy#snappy;0.2!snappy.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/json/json/20090211/json-20090211.jar ...
[ivy:resolve] .. (44kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.json#json;20090211!json.jar (22ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar ...
[ivy:resolve] .. (16kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.googlecode.javaewah#JavaEWAH;0.3.2!JavaEWAH.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javolution/javolution/5.5.1/javolution-5.5.1.jar ...
[ivy:resolve] ........ (385kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javolution#javolution;5.5.1!javolution.jar(bundle) (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/jline/jline/0.9.94/jline-0.9.94.jar ...
[ivy:resolve] ... (85kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] jline#jline;0.9.94!jline.jar (120ms)
[ivy:resolve] :: resolution report :: resolve 10685ms :: artifacts dl 246ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   38  |   7   |   7   |   2   ||   36  |   7   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-exec-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-exec-default.html

make-pom:
     [echo] Project: ql
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: ql

init:
     [echo] Project: ql

ql-init:
     [echo] Project: ql
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/gen/antlr/gen-java/org/apache/hadoop/hive/ql/parse

ivy-retrieve:
     [echo] Project: ql
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-exec
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	10 artifacts copied, 26 already retrieved (5174kB/24ms)

build-grammar:
     [echo] Project: ql
     [echo] Building Grammar /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g  ....
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:866:5: 
     [java] Decision can match input such as &quot;Identifier KW_RENAME KW_TO&quot; using multiple alternatives: 1, 10
     [java] 
     [java] As a result, alternative(s) 10 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1167:5: 
     [java] Decision can match input such as &quot;KW_TEXTFILE&quot; using multiple alternatives: 2, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1167:5: 
     [java] Decision can match input such as &quot;KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1167:5: 
     [java] Decision can match input such as &quot;KW_ORCFILE&quot; using multiple alternatives: 4, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1167:5: 
     [java] Decision can match input such as &quot;KW_RCFILE&quot; using multiple alternatives: 3, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1180:23: 
     [java] Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1180:23: 
     [java] Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1180:23: 
     [java] Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:23: 
     [java] Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:23: 
     [java] Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:23: 
     [java] Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_PRETTY KW_PARTITION&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_PRETTY {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_PRETTY Identifier&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_FORMATTED {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_FORMATTED KW_PARTITION&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_FORMATTED Identifier&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1476:116: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_DIRECTORIES&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_INPUTFORMAT&quot; using multiple alternatives: 5, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_ORCFILE&quot; using multiple alternatives: 4, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_RCFILE&quot; using multiple alternatives: 3, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_TEXTFILE&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): SelectClauseParser.g:149:5: 
     [java] Decision can match input such as &quot;KW_NULL DOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): SelectClauseParser.g:149:5: 
     [java] Decision can match input such as &quot;KW_NULL DOT Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:127:2: 
     [java] Decision can match input such as &quot;KW_LATERAL KW_VIEW KW_OUTER&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:25: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral RPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:25: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral EQUAL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:25: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral COMMA&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL GREATERTHAN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL GREATERTHANOREQUALTO&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LESSTHAN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LESSTHANOREQUALTO&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL DOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL NOTEQUAL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL EQUAL_NS&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL {DIV..DIVIDE, MOD, STAR}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL BITWISEXOR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL EQUAL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL RPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_AND&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CAST LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL BITWISEOR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_BETWEEN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_IN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL AMPERSAND&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LSQUARE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL {KW_LIKE, KW_REGEXP, KW_RLIKE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL {MINUS, PLUS}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN CharSetName CharSetLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_WHEN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_IS&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_DATE StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_OR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:108:5: 
     [java] Decision can match input such as &quot;KW_ORDER KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:121:5: 
     [java] Decision can match input such as &quot;KW_CLUSTER KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:133:5: 
     [java] Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:144:5: 
     [java] Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:155:5: 
     [java] Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:172:7: 
     [java] Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:185:5: 
     [java] Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): IdentifiersParser.g:185:5: 
     [java] Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): IdentifiersParser.g:185:5: 
     [java] Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 8
     [java] 
     [java] As a result, alternative(s) 8 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_DATE StringLiteral&quot; using multiple alternatives: 2, 3
     [java] 
     [java] As a result, alternative(s) 3 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 3, 8
     [java] 
     [java] As a result, alternative(s) 8 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 3, 8
     [java] 
     [java] As a result, alternative(s) 8 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 6, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:514:5: 
     [java] Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3
     [java] 
     [java] As a result, alternative(s) 3 were disabled for that input

compile:
     [echo] Project: ql
    [javac] Compiling 918 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/exec/package-info.class
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/io/orc/package-info.class
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/udf/generic/package-info.class
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/exec/errors/package-info.class
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/lockmgr/package-info.class
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes

jar:
     [echo] Project: ql
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libthrift-0.9.0.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/thrift/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-lang-2.4.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/commons-lang/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/json-20090211.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/json/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/JavaEWAH-0.3.2.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/javaewah/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-1.7.1.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/avro/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-mapred-1.7.1.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/avro-mapred/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/javolution-5.5.1.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/javolution/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/protobuf-java-2.4.1.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/protobuf-java/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/guava-11.0.2.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/guava/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/snappy-0.2.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/snappy/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-core-asl-1.8.8.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/jackson-core-asl/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-mapper-asl-1.8.8.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/jackson-mapper-asl/classes
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/hive-exec-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-exec;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:51:20 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-exec
[ivy:publish] 	published hive-exec to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-exec/0.13.0-SNAPSHOT/jars/hive-exec.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-exec/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: contrib

check-ivy:
     [echo] Project: contrib

ivy-resolve:
     [echo] Project: contrib
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-contrib;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-exec;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-exec/0.13.0-SNAPSHOT/jars/hive-exec.jar ...
[ivy:resolve] ............................................................................................................................................ (8837kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-exec;0.13.0-SNAPSHOT!hive-exec.jar (123ms)
[ivy:resolve] :: resolution report :: resolve 7013ms :: artifacts dl 141ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   39  |   1   |   1   |   2   ||   37  |   1   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-contrib-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-contrib-default.html

make-pom:
     [echo] Project: contrib
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: contrib
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources does not exist.

init:
     [echo] Project: contrib

setup:
     [echo] Project: contrib

ivy-retrieve:
     [echo] Project: contrib
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-contrib
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	1 artifacts copied, 36 already retrieved (8837kB/59ms)

compile:
     [echo] Project: contrib
    [javac] Compiling 39 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/java/org/apache/hadoop/hive/contrib/udf/example/UDFExampleStructPrint.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/java/conf does not exist.

jar:
     [echo] Project: contrib
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/hive-contrib-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-contrib;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:51:28 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-contrib
[ivy:publish] 	published hive-contrib to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-contrib/0.13.0-SNAPSHOT/jars/hive-contrib.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-contrib/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: service

check-ivy:
     [echo] Project: service

ivy-resolve:
     [echo] Project: service
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-service;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-exec;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] :: resolution report :: resolve 6867ms :: artifacts dl 17ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   39  |   0   |   0   |   2   ||   37  |   0   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-service-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-service-default.html

make-pom:
     [echo] Project: service
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/service/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: service
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources does not exist.

init:
     [echo] Project: service

ivy-retrieve:
     [echo] Project: service
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-service
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	0 artifacts copied, 37 already retrieved (0kB/20ms)

compile:
     [echo] Project: service
    [javac] Compiling 151 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.

jar:
     [echo] Project: service
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/service/hive-service-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-service;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:51:41 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/service/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-service
[ivy:publish] 	published hive-service to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-service/0.13.0-SNAPSHOT/jars/hive-service.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-service/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: cli

check-ivy:
     [echo] Project: cli

ivy-resolve:
     [echo] Project: cli
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-cli;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-service;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-exec;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-service/0.13.0-SNAPSHOT/jars/hive-service.jar ...
[ivy:resolve] ........................ (1469kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-service;0.13.0-SNAPSHOT!hive-service.jar (21ms)
[ivy:resolve] :: resolution report :: resolve 6800ms :: artifacts dl 39ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   40  |   1   |   1   |   2   ||   38  |   1   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-cli-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-cli-default.html

make-pom:
     [echo] Project: cli
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/cli/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: cli
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/resources does not exist.

init:
     [echo] Project: cli

setup:
     [echo] Project: cli

ivy-retrieve:
     [echo] Project: cli
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-cli
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	1 artifacts copied, 37 already retrieved (1469kB/14ms)

compile:
     [echo] Project: cli
    [javac] Compiling 4 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:71: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac] import sun.misc.Signal;
    [javac]                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:72: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac] import sun.misc.SignalHandler;
    [javac]                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:362: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac]     SignalHandler oldSignal = null;
    [javac]     ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:363: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]     Signal interupSignal = null;
    [javac]     ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:368: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]       interupSignal = new Signal(&quot;INT&quot;);
    [javac]                           ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:369: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac]       oldSignal = Signal.handle(interupSignal, new SignalHandler() {
    [javac]                                                    ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:369: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac]       oldSignal = Signal.handle(interupSignal, new SignalHandler() {
    [javac]                                                    ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:374: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]         public void handle(Signal signal) {
    [javac]                            ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:369: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]       oldSignal = Signal.handle(interupSignal, new SignalHandler() {
    [javac]                   ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:430: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]         Signal.handle(interupSignal, oldSignal);
    [javac]         ^
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/RCFileCat.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] 10 warnings

jar:
     [echo] Project: cli
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/hive-cli-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-cli;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:51:48 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/cli/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-cli
[ivy:publish] 	published hive-cli to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-cli/0.13.0-SNAPSHOT/jars/hive-cli.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-cli/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: jdbc

check-ivy:
     [echo] Project: jdbc

ivy-resolve:
     [echo] Project: jdbc
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-jdbc;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-cli;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-service;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-exec;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-cli/0.13.0-SNAPSHOT/jars/hive-cli.jar ...
[ivy:resolve] .. (33kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-cli;0.13.0-SNAPSHOT!hive-cli.jar (3ms)
[ivy:resolve] :: resolution report :: resolve 6738ms :: artifacts dl 21ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   41  |   1   |   1   |   2   ||   39  |   1   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-jdbc-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-jdbc-default.html

make-pom:
     [echo] Project: jdbc
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: jdbc
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/test/resources does not exist.

init:
     [echo] Project: jdbc

ivy-retrieve:
     [echo] Project: jdbc
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-jdbc
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	1 artifacts copied, 38 already retrieved (33kB/21ms)

compile:
     [echo] Project: jdbc
    [javac] Compiling 28 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.

jar:
     [echo] Project: jdbc
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/hive-jdbc-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-jdbc;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:51:57 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-jdbc
[ivy:publish] 	published hive-jdbc to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-jdbc/0.13.0-SNAPSHOT/jars/hive-jdbc.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-jdbc/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: beeline

check-ivy:
     [echo] Project: beeline

ivy-resolve:
     [echo] Project: beeline
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-beeline;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-service;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-exec;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.4 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.4 in maven2
[ivy:resolve] 	found commons-logging#commons-logging-api;1.0.4 in maven2
[ivy:resolve] 	found org.apache.thrift#libthrift;0.9.0 in maven2
[ivy:resolve] :: resolution report :: resolve 7662ms :: artifacts dl 26ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   44  |   0   |   0   |   2   ||   42  |   0   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-beeline-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-beeline-default.html

make-pom:
     [echo] Project: beeline
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: beeline
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/test/resources does not exist.

init:
     [echo] Project: beeline

setup:
     [echo] Project: beeline

ivy-retrieve:
     [echo] Project: beeline
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-beeline
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	0 artifacts copied, 42 already retrieved (0kB/23ms)

compile:
     [echo] Project: beeline
    [javac] Compiling 29 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:28: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac] import sun.misc.Signal;
    [javac]                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:29: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac] import sun.misc.SignalHandler;
    [javac]                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:31: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac] public class SunSignalHandler implements BeeLineSignalHandler, SignalHandler {
    [javac]                                                                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:44: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]   public void handle (Signal signal) {
    [javac]                       ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:37: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]     Signal.handle (new Signal (&quot;INT&quot;), this);
    [javac]                        ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:37: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]     Signal.handle (new Signal (&quot;INT&quot;), this);
    [javac]     ^
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] 6 warnings
     [copy] Copying 2 files to /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes

jar:
     [echo] Project: beeline
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/hive-beeline-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-beeline;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:52:05 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-beeline
[ivy:publish] 	published hive-beeline to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-beeline/0.13.0-SNAPSHOT/jars/hive-beeline.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-beeline/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: hwi

check-ivy:
     [echo] Project: hwi

ivy-resolve:
     [echo] Project: hwi
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-hwi;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-cli;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-service;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-exec;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api;2.5-20081211 in maven2
[ivy:resolve] :: resolution report :: resolve 7125ms :: artifacts dl 19ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   44  |   0   |   0   |   2   ||   42  |   0   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-hwi-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-hwi-default.html

make-pom:
     [echo] Project: hwi
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: hwi
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources does not exist.

init:
     [echo] Project: hwi

setup:
     [echo] Project: hwi

ivy-retrieve:
     [echo] Project: hwi
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-hwi
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	3 artifacts copied, 39 already retrieved (831kB/14ms)

war:
     [echo] Project: hwi
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/hive-hwi-0.13.0-SNAPSHOT.war

compile:
     [echo] Project: hwi
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hwi/build.xml:67: warning: &apos;includeantruntime&apos; was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds
    [javac] Compiling 6 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes

jar:
     [echo] Project: hwi
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/hive-hwi-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-hwi;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:52:13 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-hwi
[ivy:publish] 	published hive-hwi to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-hwi/0.13.0-SNAPSHOT/jars/hive-hwi.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-hwi/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: hbase-handler

check-ivy:
     [echo] Project: hbase-handler

ivy-resolve:
     [echo] Project: hbase-handler
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-hbase-handler;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-exec;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] 	found org.apache.hbase#hbase;0.94.6.1 in maven2
[ivy:resolve] 	found com.github.stephenc.high-scale-lib#high-scale-lib;1.1.1 in maven2
[ivy:resolve] 	found com.yammer.metrics#metrics-core;2.1.2 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-jaxrs;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-xc;1.8.8 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hbase/hbase/0.94.6.1/hbase-0.94.6.1-tests.jar ...
[ivy:resolve] ........................................ (2360kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hbase#hbase;0.94.6.1!hbase.jar(test-jar) (49ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hbase/hbase/0.94.6.1/hbase-0.94.6.1.jar ...
[ivy:resolve] ......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................... (4952kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hbase#hbase;0.94.6.1!hbase.jar (455ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/github/stephenc/high-scale-lib/high-scale-lib/1.1.1/high-scale-lib-1.1.1.jar ...
[ivy:resolve] ... (93kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.github.stephenc.high-scale-lib#high-scale-lib;1.1.1!high-scale-lib.jar (22ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/yammer/metrics/metrics-core/2.1.2/metrics-core-2.1.2.jar ...
[ivy:resolve] ... (80kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.yammer.metrics#metrics-core;2.1.2!metrics-core.jar (6ms)
[ivy:resolve] :: resolution report :: resolve 10622ms :: artifacts dl 557ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   46  |   3   |   3   |   2   ||   45  |   4   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-hbase-handler-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-hbase-handler-default.html

make-pom:
     [echo] Project: hbase-handler
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: hbase-handler
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources does not exist.

init:
     [echo] Project: hbase-handler

setup:
     [echo] Project: hbase-handler

ivy-retrieve:
     [echo] Project: hbase-handler
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-hbase-handler
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	6 artifacts copied, 39 already retrieved (7536kB/44ms)

compile:
     [echo] Project: hbase-handler
    [javac] Compiling 13 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes/org/apache/hadoop/hive/hbase/package-info.class
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/java/conf does not exist.

jar:
     [echo] Project: hbase-handler
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/hive-hbase-handler-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-hbase-handler;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:52:25 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-hbase-handler
[ivy:publish] 	published hive-hbase-handler to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-hbase-handler/0.13.0-SNAPSHOT/jars/hive-hbase-handler.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-hbase-handler/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: testutils

check-ivy:
     [echo] Project: testutils

ivy-resolve:
     [echo] Project: testutils
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-testutils;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found junit#junit;4.10 in maven2
[ivy:resolve] 	found org.hamcrest#hamcrest-core;1.1 in maven2
[ivy:resolve] 	found com.google.code.tempus-fugit#tempus-fugit;1.1 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/4.10/junit-4.10.jar ...
[ivy:resolve] ..... (247kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] junit#junit;4.10!junit.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/code/tempus-fugit/tempus-fugit/1.1/tempus-fugit-1.1.jar ...
[ivy:resolve] .. (54kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.code.tempus-fugit#tempus-fugit;1.1!tempus-fugit.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/hamcrest/hamcrest-core/1.1/hamcrest-core-1.1.jar ...
[ivy:resolve] ... (74kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.hamcrest#hamcrest-core;1.1!hamcrest-core.jar (6ms)
[ivy:resolve] :: resolution report :: resolve 2155ms :: artifacts dl 33ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	junit#junit;4.7 by [junit#junit;4.10] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   4   |   3   |   3   |   1   ||   3   |   3   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-testutils-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-testutils-default.html

make-pom:
     [echo] Project: testutils
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: testutils
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources does not exist.

init:
     [echo] Project: testutils

setup:
     [echo] Project: testutils

ivy-retrieve:
     [echo] Project: testutils
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-testutils
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	3 artifacts copied, 0 already retrieved (376kB/4ms)

compile:
     [echo] Project: testutils
    [javac] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/classes
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/java/conf does not exist.

jar:
     [echo] Project: testutils
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/hive-testutils-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-testutils;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Fri Sep 06 22:52:28 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-testutils
[ivy:publish] 	published hive-testutils to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-testutils/0.13.0-SNAPSHOT/jars/hive-testutils.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-testutils/0.13.0-SNAPSHOT/ivys/ivy.xml

init:

jar:

mvn-init:
     [echo] hcatalog-core
      [get] Getting: http://repo2.maven.org/maven2/org/apache/maven/maven-ant-tasks/2.1.3/maven-ant-tasks-2.1.3.jar
      [get] To: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build/maven-ant-tasks-2.1.3.jar

hive-mvn-publish:
     [echo] Installing local artifact for maven : shims
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.13.0-SNAPSHOT/hive-shims-0.13.0-SNAPSHOT.jar
[artifact:install] An error has occurred while processing the Maven artifact tasks.
[artifact:install]  Diagnosis:
[artifact:install] 
[artifact:install] Error installing artifact &apos;org.apache.hive:hive-shims:jar&apos;: Error installing artifact: File /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.12.0-SNAPSHOT.jar does not exist

BUILD FAILED
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:327: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:166: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:168: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build.xml:68: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build-support/ant/deploy.xml:81: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build-support/ant/deploy.xml:57: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build-support/ant/deploy.xml:48: Error installing artifact &apos;org.apache.hive:hive-shims:jar&apos;: Error installing artifact: File /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.12.0-SNAPSHOT.jar does not exist

Total time: 6 minutes 37 seconds
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13766163" author="thejas" created="Fri, 13 Sep 2013 01:52:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ekoifman&quot; class=&quot;user-hover&quot; rel=&quot;ekoifman&quot;&gt;Eugene Koifman&lt;/a&gt; Did the patch accidentally get created as a reverse patch ?&lt;/p&gt;</comment>
                            <comment id="13766241" author="ekoifman" created="Fri, 13 Sep 2013 04:51:08 +0000"  >&lt;p&gt;no, the patch is fine.  There was a block of text commented out.  Now it just adds a latest version of Xerces as a dependency.&lt;/p&gt;</comment>
                            <comment id="13766288" author="thejas" created="Fri, 13 Sep 2013 06:59:46 +0000"  >&lt;p&gt;Got it now. I failed to notice the comment being removed!&lt;br/&gt;
+1 Will be useful to have this in 0.12 as well.&lt;/p&gt;</comment>
                            <comment id="13767070" author="thejas" created="Fri, 13 Sep 2013 22:30:41 +0000"  >&lt;p&gt;The hcat unit tests passed. Committed to trunk and 0.12 branch. Thanks for the contribution Eugene!&lt;/p&gt;</comment>
                            <comment id="13767426" author="hudson" created="Sat, 14 Sep 2013 09:32:55 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-h0.21 #2331 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2331/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2331/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5127&quot; title=&quot;Upgrade xerces and xalan for WebHCat&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5127&quot;&gt;&lt;del&gt;HIVE-5127&lt;/del&gt;&lt;/a&gt;: Upgrade xerces and xalan for WebHCat (Eugene Koifman via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1523134&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1523134&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/pom.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13767660" author="hudson" created="Sun, 15 Sep 2013 02:50:42 +0000"  >&lt;p&gt;ABORTED: Integrated in Hive-trunk-hadoop2 #428 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/428/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/428/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5127&quot; title=&quot;Upgrade xerces and xalan for WebHCat&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5127&quot;&gt;&lt;del&gt;HIVE-5127&lt;/del&gt;&lt;/a&gt;: Upgrade xerces and xalan for WebHCat (Eugene Koifman via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1523134&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1523134&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/pom.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13767743" author="hudson" created="Sun, 15 Sep 2013 09:33:09 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #97 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/97/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/97/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5127&quot; title=&quot;Upgrade xerces and xalan for WebHCat&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5127&quot;&gt;&lt;del&gt;HIVE-5127&lt;/del&gt;&lt;/a&gt;: Upgrade xerces and xalan for WebHCat (Eugene Koifman via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1523134&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1523134&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/pom.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13767752" author="hudson" created="Sun, 15 Sep 2013 09:34:53 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #164 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/164/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/164/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5127&quot; title=&quot;Upgrade xerces and xalan for WebHCat&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5127&quot;&gt;&lt;del&gt;HIVE-5127&lt;/del&gt;&lt;/a&gt;: Upgrade xerces and xalan for WebHCat (Eugene Koifman via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1523134&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1523134&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/pom.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13796155" author="ashutoshc" created="Tue, 15 Oct 2013 23:31:23 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12601945" name="HIVE-5127.patch" size="736" author="ekoifman" created="Sat, 7 Sep 2013 01:22:17 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 7 Sep 2013 02:52:31 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344686</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nfv3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344986</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5128] Direct SQL for view is failing </title>
                <link>https://issues.apache.org/jira/browse/HIVE-5128</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;I cannot sure of this, but dropping views, (it rolls back to JPA and works fine)&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;etastore.ObjectStore: Direct SQL failed, falling back to ORM
MetaException(message:Unexpected null for one of the IDs, SD null, column null, serde null)
	at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.getPartitionsViaSqlFilterInternal(MetaStoreDirectSql.java:195)
	at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.getPartitionsViaSqlFilter(MetaStoreDirectSql.java:98)
	at org.apache.hadoop.hive.metastore.ObjectStore.getPartitionsByFilter(ObjectStore.java:1758)
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Should it be disabled for views or can be fixed?&lt;/p&gt;</description>
                <environment></environment>
        <key id="12664748">HIVE-5128</key>
            <summary>Direct SQL for view is failing </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.svg">Trivial</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sershe">Sergey Shelukhin</assignee>
                                    <reporter username="navis">Navis</reporter>
                        <labels>
                    </labels>
                <created>Wed, 21 Aug 2013 01:46:01 +0000</created>
                <updated>Tue, 15 Oct 2013 23:31:40 +0000</updated>
                            <resolved>Wed, 28 Aug 2013 15:13:36 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13745707" author="navis" created="Wed, 21 Aug 2013 01:48:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt; Could you check this? I&apos;ve seen that testing &quot;create_view_partitioned.q&quot;&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;CREATE VIEW vp1 PARTITIONED ON (value) AS SELECT key, value FROM src WHERE key=86;
ALTER VIEW vp1 ADD PARTITION (value=&apos;val_86&apos;) PARTITION (value=&apos;val_xyz&apos;);
ALTER VIEW vp1 DROP PARTITION (value=&apos;val_xyz&apos;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13747145" author="sershe" created="Thu, 22 Aug 2013 01:51:43 +0000"  >&lt;p&gt;let me check today/tomorrow&lt;/p&gt;</comment>
                            <comment id="13747169" author="sershe" created="Thu, 22 Aug 2013 02:30:02 +0000"  >&lt;p&gt;it may be bad code in a sense that we expect these things to be set, and they are correctly not set for views. Maybe it should handle that.&lt;/p&gt;</comment>
                            <comment id="13747967" author="phabricator@reviews.facebook.net" created="Thu, 22 Aug 2013 22:12:52 +0000"  >&lt;p&gt;sershe requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5128&quot; title=&quot;Direct SQL for view is failing &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5128&quot;&gt;&lt;del&gt;HIVE-5128&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Direct SQL for view is failing&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;Adding the checks for the view, and support for absence of SD, CD and SERDE&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12465&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12465&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/29853/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/29853/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, sershe&lt;/p&gt;</comment>
                            <comment id="13748194" author="navis" created="Fri, 23 Aug 2013 01:48:52 +0000"  >&lt;p&gt;After applying patch, &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;CREATE VIEW vp1 PARTITIONED ON (value) AS SELECT key, value FROM src WHERE key=86;
ALTER VIEW vp1 ADD PARTITION (value=&apos;val_86&apos;) PARTITION (value=&apos;val_xyz&apos;);
DROP VIEW vp1;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Fails with&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;javax.jdo.JDODataStoreException: Error executing SQL query &quot;select TBL_TYPE from TBLS where TBLS.TBL_NAME = ? and DBS.NAME = ?&quot;.
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:451)
	at org.datanucleus.api.jdo.JDOQuery.executeWithArray(JDOQuery.java:321)
	at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.isViewTable(MetaStoreDirectSql.java:109)
	at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.getPartitionsViaSqlFilterInternal(MetaStoreDirectSql.java:209)
	at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.getPartitionsViaSqlFilter(MetaStoreDirectSql.java:82)
	at org.apache.hadoop.hive.metastore.ObjectStore.getPartitionsByNames(ObjectStore.java:1672)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hive.metastore.RetryingRawStore.invoke(RetryingRawStore.java:111)
	at $Proxy8.getPartitionsByNames(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_partitions_by_names(HiveMetaStore.java:3340)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:103)
	at $Proxy9.get_partitions_by_names(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartitionsByNames(HiveMetaStoreClient.java:830)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:89)
	at $Proxy10.getPartitionsByNames(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.getPartitionsByNames(Hive.java:1834)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3313)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:276)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:151)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:65)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1430)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1210)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1015)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:884)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:259)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:413)
	at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:781)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:675)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:614)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:197)
NestedThrowablesStackTrace:
java.sql.SQLSyntaxErrorException: Column &apos;DBS.NAME&apos; is either not in any table in the FROM list or appears within a join specification and is outside the scope of the join specification or appears in a HAVING clause and is not in the GROUP BY list. If this is a CREATE or ALTER TABLE  statement then &apos;DBS.NAME&apos; is not a column in the target table.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.&amp;lt;init&amp;gt;(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement20.&amp;lt;init&amp;gt;(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement30.&amp;lt;init&amp;gt;(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement40.&amp;lt;init&amp;gt;(Unknown Source)
	at org.apache.derby.jdbc.Driver40.newEmbedPreparedStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:974)
	at org.datanucleus.store.rdbms.SQLController.getStatementForQuery(SQLController.java:350)
	at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getPreparedStatementForQuery(RDBMSQueryUtils.java:195)
	at org.datanucleus.store.rdbms.query.SQLQuery.performExecute(SQLQuery.java:267)
	at org.datanucleus.store.query.Query.executeQuery(Query.java:1786)
	at org.datanucleus.store.query.AbstractSQLQuery.executeWithArray(AbstractSQLQuery.java:331)
	at org.datanucleus.api.jdo.JDOQuery.executeWithArray(JDOQuery.java:312)
	at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.isViewTable(MetaStoreDirectSql.java:109)
	at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.getPartitionsViaSqlFilterInternal(MetaStoreDirectSql.java:209)
	at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.getPartitionsViaSqlFilter(MetaStoreDirectSql.java:82)
	at org.apache.hadoop.hive.metastore.ObjectStore.getPartitionsByNames(ObjectStore.java:1672)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hive.metastore.RetryingRawStore.invoke(RetryingRawStore.java:111)
	at $Proxy8.getPartitionsByNames(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_partitions_by_names(HiveMetaStore.java:3340)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:103)
	at $Proxy9.get_partitions_by_names(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartitionsByNames(HiveMetaStoreClient.java:830)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:89)
	at $Proxy10.getPartitionsByNames(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.getPartitionsByNames(Hive.java:1834)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3313)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:276)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:151)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:65)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1430)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1210)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1015)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:884)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:259)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:413)
	at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:781)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:675)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:614)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:197)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Could you look at that, too?&lt;/p&gt;</comment>
                            <comment id="13748233" author="sershe" created="Fri, 23 Aug 2013 02:38:37 +0000"  >&lt;p&gt;Sorry this is the wrong patch.&lt;/p&gt;</comment>
                            <comment id="13750711" author="phabricator@reviews.facebook.net" created="Mon, 26 Aug 2013 23:14:54 +0000"  >&lt;p&gt;sershe updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5128&quot; title=&quot;Direct SQL for view is failing &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5128&quot;&gt;&lt;del&gt;HIVE-5128&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Direct SQL for view is failing&quot;.&lt;/p&gt;

&lt;p&gt;  Updated the patch. I tested the example, seems to work now on my setup.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12465&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12465&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12465?vs=38727&amp;amp;id=39039#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12465?vs=38727&amp;amp;id=39039#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;/p&gt;

&lt;p&gt;To: JIRA, sershe&lt;/p&gt;</comment>
                            <comment id="13752061" author="phabricator@reviews.facebook.net" created="Wed, 28 Aug 2013 03:18:53 +0000"  >&lt;p&gt;ashutoshc has accepted the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5128&quot; title=&quot;Direct SQL for view is failing &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5128&quot;&gt;&lt;del&gt;HIVE-5128&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Direct SQL for view is failing&quot;.&lt;/p&gt;

&lt;p&gt;  +1&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12465&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12465&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5128&quot; title=&quot;Direct SQL for view is failing &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5128&quot;&gt;&lt;del&gt;HIVE-5128&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, sershe&lt;/p&gt;</comment>
                            <comment id="13752491" author="ashutoshc" created="Wed, 28 Aug 2013 15:13:36 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Sergey!&lt;/p&gt;</comment>
                            <comment id="13752530" author="hudson" created="Wed, 28 Aug 2013 16:10:48 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #74 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/74/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/74/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5128&quot; title=&quot;Direct SQL for view is failing &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5128&quot;&gt;&lt;del&gt;HIVE-5128&lt;/del&gt;&lt;/a&gt; : Direct SQL for view is failing (Sergey Shelukhin via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1518258&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1518258&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13752553" author="hudson" created="Wed, 28 Aug 2013 16:30:56 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #142 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/142/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/142/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5128&quot; title=&quot;Direct SQL for view is failing &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5128&quot;&gt;&lt;del&gt;HIVE-5128&lt;/del&gt;&lt;/a&gt; : Direct SQL for view is failing (Sergey Shelukhin via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1518258&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1518258&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13753308" author="hudson" created="Thu, 29 Aug 2013 05:14:02 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hive-trunk-h0.21 #2295 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2295/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2295/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5128&quot; title=&quot;Direct SQL for view is failing &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5128&quot;&gt;&lt;del&gt;HIVE-5128&lt;/del&gt;&lt;/a&gt; : Direct SQL for view is failing (Sergey Shelukhin via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1518258&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1518258&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13753366" author="hudson" created="Thu, 29 Aug 2013 06:33:44 +0000"  >&lt;p&gt;ABORTED: Integrated in Hive-trunk-hadoop2 #387 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/387/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/387/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5128&quot; title=&quot;Direct SQL for view is failing &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5128&quot;&gt;&lt;del&gt;HIVE-5128&lt;/del&gt;&lt;/a&gt; : Direct SQL for view is failing (Sergey Shelukhin via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1518258&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1518258&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13796189" author="ashutoshc" created="Tue, 15 Oct 2013 23:31:40 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12662706">HIVE-5029</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12599517" name="HIVE-5128.D12465.1.patch" size="7482" author="phabricator@reviews.facebook.net" created="Thu, 22 Aug 2013 22:12:52 +0000"/>
                            <attachment id="12600043" name="HIVE-5128.D12465.2.patch" size="7572" author="phabricator@reviews.facebook.net" created="Mon, 26 Aug 2013 23:14:54 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 22 Aug 2013 01:51:43 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344691</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nfw7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344991</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5129] Multiple table insert fails on count(distinct)</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5129</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Hive fails with a class cast exception on queries of the form:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;from studenttab10k
insert overwrite table multi_insert_2_1
select name, avg(age) as avgage
group by name

insert overwrite table multi_insert_2_2
select name, age, sum(gpa) as sumgpa
group by name, age

insert overwrite table multi_insert_2_3
select name, count(distinct age) as distage
group by name;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12664754">HIVE-5129</key>
            <summary>Multiple table insert fails on count(distinct)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vikram.dixit">Vikram Dixit K</assignee>
                                    <reporter username="vikram.dixit">Vikram Dixit K</reporter>
                        <labels>
                    </labels>
                <created>Wed, 21 Aug 2013 02:28:46 +0000</created>
                <updated>Wed, 16 Oct 2013 01:23:59 +0000</updated>
                            <resolved>Tue, 3 Sep 2013 17:34:15 +0000</resolved>
                                    <version>0.11.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13745731" author="vikram.dixit" created="Wed, 21 Aug 2013 02:32:46 +0000"  >&lt;p&gt;Test and relevant data. Put the data files in the data/files directory in the source folder.&lt;/p&gt;</comment>
                            <comment id="13745735" author="vikram.dixit" created="Wed, 21 Aug 2013 02:39:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; This issue is related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4692&quot; title=&quot;Constant agg parameters will be replaced by ExprNodeColumnDesc with single-sourced multi-gby cases&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4692&quot;&gt;&lt;del&gt;HIVE-4692&lt;/del&gt;&lt;/a&gt;. I have attached a patch which retains the same behavior as was before that patch without affecting the test added as part of it. However, I am not sure what else is affected by this down stream. I have started to run the unit tests to make sure I haven&apos;t broken other things. It would be great if you could take a look and provide feedback on this. Please let me know if you have a better approach in mind.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;</comment>
                            <comment id="13745739" author="vikram.dixit" created="Wed, 21 Aug 2013 02:45:32 +0000"  >&lt;p&gt;Review board request:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/13697/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/13697/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13745873" author="navis" created="Wed, 21 Aug 2013 08:38:53 +0000"  >&lt;p&gt;mGBY-1RS optimization is really confusing with distinct functions. IMHO, it should not be allowed to mix distinct and non-distinct cases into one group. For example, &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;from src tablesample (10 ROWS)
insert overwrite table src_a select key, count(distinct key) + count(distinct value) group by key;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;makes 20 rows for src_a, and,&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;from src tablesample (10 ROWS)
insert overwrite table src_b select key, count(value) group by key, value;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;makes 10 rows for src_b, but,&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;from src tablesample (10 ROWS)
insert overwrite table src_a select key, count(distinct key) + count(distinct value) group by key
insert overwrite table src_b select key, count(value) group by key, value;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;makes 20 rows for src_a and src_b, and lastly,&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;from src tablesample (10 ROWS)
insert overwrite table src_b select key, count(value) group by key, value
insert overwrite table src_a select key, count(distinct key) + count(distinct value) group by key;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;is not working as described in this issue. After applying your patch, it succeeded with 10 rows for both.&lt;/p&gt;</comment>
                            <comment id="13747159" author="vikram.dixit" created="Thu, 22 Aug 2013 02:15:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; I think this patch addresses what you intended. Could you please take a look. I ran some tests on it and it looks ok. I will include your query above in the test and upload once I have your feedback.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Vikram.&lt;/p&gt;</comment>
                            <comment id="13747173" author="navis" created="Thu, 22 Aug 2013 02:33:33 +0000"  >&lt;p&gt;It seemed current distinct implementation has flaw.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;select key, count(distinct key) + count(distinct value) from src tablesample (10 ROWS) group by key;

100	1
val_100	1
165	1
val_165	1
238	1
val_238	1
255	1
val_255	1
27	1
val_27	1
278	1
val_278	1
311	1
val_311	1
409	1
val_409	1
86	1
val_86	1
98	1
val_98	1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;this does not make sense.&lt;/p&gt;</comment>
                            <comment id="13748687" author="vikram.dixit" created="Fri, 23 Aug 2013 16:36:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; I looked into this some more and I feel that the issue you have raised is valid but, is independent of this issue. Would it be OK to raise another jira for addressing that issue?&lt;/p&gt;

&lt;p&gt;I have updated the patch to retain as much of the parallelism as possible and added a test case for the same. Please take a look and let me know your feedback.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Vikram.&lt;/p&gt;</comment>
                            <comment id="13748951" author="rhbutani" created="Fri, 23 Aug 2013 20:10:40 +0000"  >&lt;p&gt;Looks good. Can you add a test that has different distincts, which will cause multiple Jobs to be genned.&lt;br/&gt;
We should look at combining such clauses in the future.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; we think your e.g. is a separate issue. What we observe is that the Key OI setup in your e.g. has only 1 field which is the Union Filed for key and value columns.&lt;br/&gt;
For some reason the key column from the group by is removed from the Key OI. So what happens is each spray instance of the original row is being output.&lt;br/&gt;
So can we look at this in a separate jira.&lt;/p&gt;</comment>
                            <comment id="13749096" author="vikram.dixit" created="Fri, 23 Aug 2013 22:40:15 +0000"  >&lt;p&gt;Addressed Harish&apos;s comments. Ran related unit tests.&lt;/p&gt;</comment>
                            <comment id="13755324" author="rhbutani" created="Sat, 31 Aug 2013 01:07:41 +0000"  >&lt;p&gt;+1&lt;br/&gt;
will commit if tests pass&lt;/p&gt;</comment>
                            <comment id="13755344" author="vikram.dixit" created="Sat, 31 Aug 2013 01:53:35 +0000"  >&lt;p&gt;Updated extension so that unit tests can run.&lt;/p&gt;</comment>
                            <comment id="13755407" author="hiveqa" created="Sat, 31 Aug 2013 04:50:27 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12600910/HIVE-5129.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12600910/HIVE-5129.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 2903 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/581/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/581/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/581/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/581/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13756812" author="rhbutani" created="Tue, 3 Sep 2013 17:33:51 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Vikram!&lt;/p&gt;</comment>
                            <comment id="13756916" author="hudson" created="Tue, 3 Sep 2013 18:57:44 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2 #401 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/401/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/401/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5129&quot; title=&quot;Multiple table insert fails on count(distinct)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5129&quot;&gt;&lt;del&gt;HIVE-5129&lt;/del&gt;&lt;/a&gt; Multiple table insert fails on count distinct (Vikram Dixit via Harish Butani) (rhbutani: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519764&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519764&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/multi_insert_gby3.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/multi_insert_gby3.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13757851" author="hudson" created="Wed, 4 Sep 2013 15:16:14 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #83 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/83/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/83/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5129&quot; title=&quot;Multiple table insert fails on count(distinct)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5129&quot;&gt;&lt;del&gt;HIVE-5129&lt;/del&gt;&lt;/a&gt; Multiple table insert fails on count distinct (Vikram Dixit via Harish Butani) (rhbutani: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519764&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519764&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/multi_insert_gby3.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/multi_insert_gby3.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13757954" author="hudson" created="Wed, 4 Sep 2013 17:03:16 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #150 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/150/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/150/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5129&quot; title=&quot;Multiple table insert fails on count(distinct)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5129&quot;&gt;&lt;del&gt;HIVE-5129&lt;/del&gt;&lt;/a&gt; Multiple table insert fails on count distinct (Vikram Dixit via Harish Butani) (rhbutani: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519764&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519764&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/multi_insert_gby3.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/multi_insert_gby3.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13758024" author="hudson" created="Wed, 4 Sep 2013 17:43:11 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hive-trunk-h0.21 #2309 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2309/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2309/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5129&quot; title=&quot;Multiple table insert fails on count(distinct)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5129&quot;&gt;&lt;del&gt;HIVE-5129&lt;/del&gt;&lt;/a&gt; Multiple table insert fails on count distinct (Vikram Dixit via Harish Butani) (rhbutani: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519764&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519764&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/multi_insert_gby3.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/multi_insert_gby3.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13795906" author="ashutoshc" created="Tue, 15 Oct 2013 23:29:31 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12674040">HIVE-5560</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12599095" name="HIVE-5129.1.patch.txt" size="1485" author="vikram.dixit" created="Wed, 21 Aug 2013 02:36:19 +0000"/>
                            <attachment id="12599340" name="HIVE-5129.2.WIP.patch.txt" size="1966" author="vikram.dixit" created="Thu, 22 Aug 2013 02:15:20 +0000"/>
                            <attachment id="12599652" name="HIVE-5129.3.patch.txt" size="41798" author="vikram.dixit" created="Fri, 23 Aug 2013 16:36:50 +0000"/>
                            <attachment id="12600910" name="HIVE-5129.4.patch" size="62628" author="vikram.dixit" created="Sat, 31 Aug 2013 01:53:35 +0000"/>
                            <attachment id="12599728" name="HIVE-5129.4.patch.txt" size="62628" author="vikram.dixit" created="Fri, 23 Aug 2013 22:45:15 +0000"/>
                            <attachment id="12599091" name="aggrTestMultiInsert.q" size="1421" author="vikram.dixit" created="Wed, 21 Aug 2013 02:32:46 +0000"/>
                            <attachment id="12599092" name="aggrTestMultiInsertData.txt" size="49" author="vikram.dixit" created="Wed, 21 Aug 2013 02:32:46 +0000"/>
                            <attachment id="12599093" name="aggrTestMultiInsertData1.txt" size="61" author="vikram.dixit" created="Wed, 21 Aug 2013 02:32:46 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 21 Aug 2013 08:38:53 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344697</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nfxj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344997</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4692&quot; title=&quot;Constant agg parameters will be replaced by ExprNodeColumnDesc with single-sourced multi-gby cases&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4692&quot;&gt;&lt;strike&gt;HIVE-4692&lt;/strike&gt;&lt;/a&gt;</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5130] Document Correlation Optimizer in Hive wiki</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5130</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12664756">HIVE-5130</key>
            <summary>Document Correlation Optimizer in Hive wiki</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12614802">HIVE-3667</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="yhuai">Yin Huai</assignee>
                                    <reporter username="yhuai">Yin Huai</reporter>
                        <labels>
                    </labels>
                <created>Wed, 21 Aug 2013 02:53:46 +0000</created>
                <updated>Mon, 14 Jul 2014 07:48:54 +0000</updated>
                                                                            <component>Documentation</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="14060292" author="yhuai" created="Mon, 14 Jul 2014 03:37:06 +0000"  >&lt;p&gt;Design doc in Hive wiki: &lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Correlation+Optimizer&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/Correlation+Optimizer&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14060340" author="lefty@hortonworks.com" created="Mon, 14 Jul 2014 05:17:21 +0000"  >&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yhuai&quot; class=&quot;user-hover&quot; rel=&quot;yhuai&quot;&gt;Yin Huai&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;The doc needs to be listed on the Design Docs page.  I can put it there, but does it belong in the &quot;Completed&quot; section (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2206&quot; title=&quot;add a new optimizer for query correlation discovery and optimization&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2206&quot;&gt;&lt;del&gt;HIVE-2206&lt;/del&gt;&lt;/a&gt;) or is it &quot;In Progress&quot; (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3667&quot; title=&quot;Umbrella jira for Correlation Optimizer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3667&quot;&gt;HIVE-3667&lt;/a&gt;, umbrella jira)?&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/DesignDocs&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Design Docs &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14060355" author="yhuai" created="Mon, 14 Jul 2014 05:36:12 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=leftylev&quot; class=&quot;user-hover&quot; rel=&quot;leftylev&quot;&gt;Lefty Leverenz&lt;/a&gt; Let&apos;s put it in the &quot;Completed&quot; section. &lt;/p&gt;</comment>
                            <comment id="14060412" author="lefty@hortonworks.com" created="Mon, 14 Jul 2014 07:48:54 +0000"  >&lt;p&gt;Done:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/DesignDocs#DesignDocs-Completed&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Design Docs &amp;#8211; Completed &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 14 Jul 2014 05:17:21 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344699</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 28 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nfxz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344999</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-5131] JDBC client&apos;s hive variables are not passed to HS2</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5131</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2914&quot; title=&quot;HiveConnection constructor ignores passed-in properties object&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2914&quot;&gt;HIVE-2914&lt;/a&gt;. However, &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2914&quot; title=&quot;HiveConnection constructor ignores passed-in properties object&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2914&quot;&gt;HIVE-2914&lt;/a&gt; seems addressing Hive CLI only. JDBC clients suffer the same problem. This was identified in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4568&quot; title=&quot;Beeline needs to support resolving variables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4568&quot;&gt;&lt;del&gt;HIVE-4568&lt;/del&gt;&lt;/a&gt;. I decided it might be better to separate issue from a different issue.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12664772">HIVE-5131</key>
            <summary>JDBC client&apos;s hive variables are not passed to HS2</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="xuefuz">Xuefu Zhang</assignee>
                                    <reporter username="xuefuz">Xuefu Zhang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 21 Aug 2013 05:28:56 +0000</created>
                <updated>Tue, 15 Oct 2013 23:29:47 +0000</updated>
                            <resolved>Fri, 6 Sep 2013 00:39:37 +0000</resolved>
                                    <version>0.11.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                    <component>JDBC</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13745792" author="xuefuz" created="Wed, 21 Aug 2013 05:36:08 +0000"  >&lt;p&gt;Attach patch extracted from that for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4568&quot; title=&quot;Beeline needs to support resolving variables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4568&quot;&gt;&lt;del&gt;HIVE-4568&lt;/del&gt;&lt;/a&gt;. Will work on a test case.&lt;/p&gt;</comment>
                            <comment id="13746075" author="xuefuz" created="Wed, 21 Aug 2013 14:22:17 +0000"  >&lt;p&gt;Patch updated with test case&lt;/p&gt;</comment>
                            <comment id="13756933" author="thejas" created="Tue, 3 Sep 2013 19:07:01 +0000"  >&lt;p&gt;The changes look good. For the unit test, instead of making change to the url used by all tests in TestBeeLineWithArgs, can you change it so that the url can be customized per test ? &lt;br/&gt;
Maybe something like this - &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; BASE_JDBC_URL = BeeLine.BEELINE_DEFAULT_JDBC_URL + &lt;span class=&quot;code-quote&quot;&gt;&quot;localhost:10000&quot;&lt;/span&gt;
&lt;span class=&quot;code-comment&quot;&gt;// set JDBC_URL to something &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; in test &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; it needs to be customized
&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; JDBC_URL = BASE_JDBC_URL;

&lt;span class=&quot;code-comment&quot;&gt;// Use JDBC_URL to connect&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13756936" author="thejas" created="Tue, 3 Sep 2013 19:08:47 +0000"  >&lt;p&gt;While you are at it, can you also make a minor change to javadoc of TestBeeLineWithArgs.testScriptFile ?&lt;br/&gt;
Change &quot; @param expecttedPattern Text to look for in command output&quot; to  &quot;@param expecttedPattern Text to look for in command output/error&quot;&lt;/p&gt;</comment>
                            <comment id="13757014" author="xuefuz" created="Tue, 3 Sep 2013 20:16:09 +0000"  >&lt;p&gt;Patch is updated based on review comments.&lt;/p&gt;</comment>
                            <comment id="13757027" author="thejas" created="Tue, 3 Sep 2013 20:24:19 +0000"  >&lt;p&gt;+1 . Making it patch available to kick off the tests.&lt;/p&gt;</comment>
                            <comment id="13757043" author="thejas" created="Tue, 3 Sep 2013 20:39:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;Xuefu Zhang&lt;/a&gt; This was never documented in the doc page. So this is actually adding the new feature. Can you add the documentation for this part url format in the release note of the jira ? Once this is committed it can be moved to the wiki page as an upcoming 0.12 feature.&lt;br/&gt;
The wiki page - &lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Clients&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Clients&lt;/a&gt;&lt;/p&gt;
</comment>
                            <comment id="13757258" author="xuefuz" created="Tue, 3 Sep 2013 23:47:31 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; I have updated the release note for this JIRA, and let me know if it suffices. Thanks.&lt;/p&gt;</comment>
                            <comment id="13757409" author="hiveqa" created="Wed, 4 Sep 2013 02:53:51 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12601225/HIVE-5131.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12601225/HIVE-5131.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 2910 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hcatalog.templeton.tool.TestTempletonUtils.testHadoopFsPath
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_smb_mapjoin_8
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/598/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/598/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/598/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/598/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13758215" author="xuefuz" created="Wed, 4 Sep 2013 19:12:06 +0000"  >&lt;p&gt;The test failures seemed random and unrelated. Nevertheless, manually reran them and they both passed locally with the patch.&lt;/p&gt;</comment>
                            <comment id="13758297" author="thejas" created="Wed, 4 Sep 2013 20:29:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; Do you also want to take a look at this patch, since this is very similar to your change in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4354&quot; title=&quot;Configurations on connection url for jdbc2 is not working&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4354&quot;&gt;HIVE-4354&lt;/a&gt; .&lt;br/&gt;
The key difference I see in that patch is that in embedded mode it starts the hiveserver2 with the modified hiveconf. Did you have any use case in mind for that ?&lt;/p&gt;</comment>
                            <comment id="13758622" author="navis" created="Thu, 5 Sep 2013 01:11:46 +0000"  >&lt;p&gt;HiveConf specified in URL for embedded mode is not applied to underlying hive infra, which should be fixed regardless of use case. And.. statement of hive jdbc2 is not reusable, so it would throw exception if two or more conf/var is specified.&lt;/p&gt;</comment>
                            <comment id="13759606" author="xuefuz" created="Thu, 5 Sep 2013 23:10:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; Since this patch has no contradiction with Navis&apos; patch, could we proceed as this blocks &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4568&quot; title=&quot;Beeline needs to support resolving variables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4568&quot;&gt;&lt;del&gt;HIVE-4568&lt;/del&gt;&lt;/a&gt;? As to Navis additional fixes (which I believe valid), it will come to the time when the patch is reviewed.&lt;/p&gt;</comment>
                            <comment id="13759677" author="thejas" created="Fri, 6 Sep 2013 00:34:28 +0000"  >&lt;blockquote&gt;&lt;p&gt;statement of hive jdbc2 is not reusable&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I was not aware of such an issue. Looks like this and the config overlay are two issues that we need to create jiras for.&lt;/p&gt;


&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;Xuefu Zhang&lt;/a&gt; We can investigate the re-use of statement issue in a separate jira. I will commit this patch.&lt;/p&gt;</comment>
                            <comment id="13759685" author="thejas" created="Fri, 6 Sep 2013 00:39:37 +0000"  >&lt;p&gt;Patch committed to trunk. Thanks Xuefu!&lt;/p&gt;</comment>
                            <comment id="13759995" author="hudson" created="Fri, 6 Sep 2013 06:57:04 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-h0.21 #2313 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2313/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2313/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5131&quot; title=&quot;JDBC client&amp;#39;s hive variables are not passed to HS2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5131&quot;&gt;&lt;del&gt;HIVE-5131&lt;/del&gt;&lt;/a&gt;: JDBC client&apos;s hive variables are not passed to HS2 (Xuefu Zhang via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1520465&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1520465&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/beeline/src/test/org/apache/hive/beeline/src/test/TestBeeLineWithArgs.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13760189" author="hudson" created="Fri, 6 Sep 2013 13:01:00 +0000"  >&lt;p&gt;ABORTED: Integrated in Hive-trunk-hadoop2 #409 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/409/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/409/&lt;/a&gt;)&lt;/p&gt;</comment>
                            <comment id="13760197" author="hudson" created="Fri, 6 Sep 2013 13:11:57 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #152 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/152/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/152/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5131&quot; title=&quot;JDBC client&amp;#39;s hive variables are not passed to HS2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5131&quot;&gt;&lt;del&gt;HIVE-5131&lt;/del&gt;&lt;/a&gt;: JDBC client&apos;s hive variables are not passed to HS2 (Xuefu Zhang via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1520465&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1520465&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/beeline/src/test/org/apache/hive/beeline/src/test/TestBeeLineWithArgs.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13760876" author="hudson" created="Sat, 7 Sep 2013 02:43:09 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #85 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/85/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/85/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5131&quot; title=&quot;JDBC client&amp;#39;s hive variables are not passed to HS2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5131&quot;&gt;&lt;del&gt;HIVE-5131&lt;/del&gt;&lt;/a&gt;: JDBC client&apos;s hive variables are not passed to HS2 (Xuefu Zhang via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1520465&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1520465&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/beeline/src/test/org/apache/hive/beeline/src/test/TestBeeLineWithArgs.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13795928" author="ashutoshc" created="Tue, 15 Oct 2013 23:29:47 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12642474">HIVE-4354</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12548857">HIVE-2914</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12647849">HIVE-4568</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12601225" name="HIVE-5131.1.patch" size="2991" author="xuefuz" created="Tue, 3 Sep 2013 20:16:09 +0000"/>
                            <attachment id="12599198" name="HIVE-5131.patch" size="2336" author="xuefuz" created="Wed, 21 Aug 2013 14:22:17 +0000"/>
                            <attachment id="12599115" name="HIVE-5131.patch" size="1178" author="xuefuz" created="Wed, 21 Aug 2013 05:36:08 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 3 Sep 2013 19:07:01 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344715</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ng1j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345015</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>We haven&amp;#39;t documented the usage in which hive variables may be specified at hive JDBC url, which can be used to substitute parameters present in user query. For instance, jdbc:&lt;a href=&quot;hive2://localhost:10000#D_TBL=dummy_t&quot;&gt;hive2://localhost:10000#D_TBL=dummy_t&lt;/a&gt; specifies a hive variable D_TBL with a value dummy_t. In user query, ${D_TBL} or ${hivevar:D_TBL} can be used to refer to the value dummy_t. Thus, a DDL, &amp;quot;create table ${D_TBL} (d int);&amp;quot; will create a table named dummy_t.&lt;br/&gt;
&lt;br/&gt;
The functionality was there for hive embedded mode. This JIRA will make this available for Hive remote mode as well.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5132] Can&apos;t access to hwi due to &quot;No Java compiler available&quot;</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5132</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;I want to use hwi to submit hive queries, but after start hwi successfully, I can&apos;t open the web page of it.&lt;/p&gt;

&lt;p&gt;I noticed that someone also met the same issue in hive-0.10.&lt;/p&gt;

&lt;p&gt;Reproduce steps:&lt;br/&gt;
--------------------------&lt;br/&gt;
1. start hwi&lt;br/&gt;
bin/hive --config $HIVE_CONF_DIR --service hwi&lt;/p&gt;

&lt;p&gt;2. access to http://&amp;lt;hive_hwi_node&amp;gt;:9999/hwi via browser&lt;/p&gt;

&lt;p&gt;got the following error message:&lt;/p&gt;

&lt;p&gt;HTTP ERROR 500&lt;br/&gt;
Problem accessing /hwi/. Reason: &lt;/p&gt;

&lt;p&gt;    No Java compiler available&lt;/p&gt;

&lt;p&gt;Caused by:&lt;br/&gt;
java.lang.IllegalStateException: No Java compiler available&lt;br/&gt;
	at org.apache.jasper.JspCompilationContext.createCompiler(JspCompilationContext.java:225)&lt;br/&gt;
	at org.apache.jasper.JspCompilationContext.compile(JspCompilationContext.java:560)&lt;br/&gt;
	at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:299)&lt;br/&gt;
	at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:315)&lt;br/&gt;
	at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:265)&lt;br/&gt;
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)&lt;br/&gt;
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)&lt;br/&gt;
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:401)&lt;br/&gt;
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)&lt;br/&gt;
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)&lt;br/&gt;
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)&lt;br/&gt;
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)&lt;br/&gt;
	at org.mortbay.jetty.servlet.Dispatcher.forward(Dispatcher.java:327)&lt;br/&gt;
	at org.mortbay.jetty.servlet.Dispatcher.forward(Dispatcher.java:126)&lt;br/&gt;
	at org.mortbay.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:503)&lt;br/&gt;
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)&lt;br/&gt;
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)&lt;br/&gt;
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)&lt;br/&gt;
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:401)&lt;br/&gt;
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)&lt;br/&gt;
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)&lt;br/&gt;
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)&lt;br/&gt;
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)&lt;br/&gt;
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)&lt;br/&gt;
	at org.mortbay.jetty.handler.RequestLogHandler.handle(RequestLogHandler.java:49)&lt;br/&gt;
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)&lt;br/&gt;
	at org.mortbay.jetty.Server.handle(Server.java:326)&lt;br/&gt;
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)&lt;br/&gt;
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)&lt;br/&gt;
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)&lt;br/&gt;
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)&lt;br/&gt;
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)&lt;br/&gt;
	at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)&lt;br/&gt;
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)&lt;/p&gt;
</description>
                <environment>&lt;p&gt;JDK1.6, hadoop 2.0.4-alpha&lt;/p&gt;</environment>
        <key id="12664773">HIVE-5132</key>
            <summary>Can&apos;t access to hwi due to &quot;No Java compiler available&quot;</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="libing">Bing Li</assignee>
                                    <reporter username="libing">Bing Li</reporter>
                        <labels>
                            <label>TODOC10</label>
                            <label>TODOC13</label>
                    </labels>
                <created>Wed, 21 Aug 2013 05:38:22 +0000</created>
                <updated>Fri, 5 Dec 2014 22:49:06 +0000</updated>
                            <resolved>Mon, 21 Oct 2013 21:49:36 +0000</resolved>
                                    <version>0.10.0</version>
                    <version>0.11.0</version>
                                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                <comments>
                            <comment id="13745798" author="libing" created="Wed, 21 Aug 2013 05:40:57 +0000"  >&lt;p&gt;I already set the following properties in hive-site.xml&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;hive.hwi.listen.host&lt;/li&gt;
	&lt;li&gt;hive.hwi.listen.port&lt;/li&gt;
	&lt;li&gt;hive.hwi.war.file&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;And copied two jasper jars into hive/lib:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;jasper-compiler-5.5.23.jar&lt;/li&gt;
	&lt;li&gt;jasper-runtime-5.5.23.jar&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;But above didn&apos;t work for this issue.&lt;/p&gt;</comment>
                            <comment id="13749963" author="libing" created="Mon, 26 Aug 2013 10:09:35 +0000"  >&lt;p&gt;The root cause of this failure is that ANT_LIB is NOT setting in hwi server.&lt;/p&gt;

&lt;p&gt;But I can resolve this failure when copy the following two ant jars into $HIVE_HOME/lib&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ant-launcher.jar&lt;/li&gt;
	&lt;li&gt;ant.jar&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I think we can add ant as the runtime dependency of hive.&lt;/p&gt;</comment>
                            <comment id="13750219" author="libing" created="Mon, 26 Aug 2013 16:38:13 +0000"  >&lt;p&gt;add ant.jar and ant-launcher.jar as the runtime dependencies of hive&lt;/p&gt;</comment>
                            <comment id="13750220" author="libing" created="Mon, 26 Aug 2013 16:39:12 +0000"  >&lt;p&gt;The patch is generated against the latest trunk.&lt;/p&gt;</comment>
                            <comment id="13768008" author="appodictic" created="Mon, 16 Sep 2013 02:18:05 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13801204" author="brocknoland" created="Mon, 21 Oct 2013 21:49:36 +0000"  >&lt;p&gt;I have committed this to trunk! Thank you for your contribution Bing and review Edward!&lt;/p&gt;</comment>
                            <comment id="13801561" author="hudson" created="Tue, 22 Oct 2013 07:23:04 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #147 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/147/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/147/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5132&quot; title=&quot;Can&amp;#39;t access to hwi due to &amp;quot;No Java compiler available&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5132&quot;&gt;&lt;del&gt;HIVE-5132&lt;/del&gt;&lt;/a&gt; - Can&apos;t access to hwi due to &apos;No Java compiler available&apos; (Bing Li via Edward Capriolo) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1534392&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1534392&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hwi/ivy.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13801567" author="hudson" created="Tue, 22 Oct 2013 07:26:19 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #210 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/210/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/210/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5132&quot; title=&quot;Can&amp;#39;t access to hwi due to &amp;quot;No Java compiler available&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5132&quot;&gt;&lt;del&gt;HIVE-5132&lt;/del&gt;&lt;/a&gt; - Can&apos;t access to hwi due to &apos;No Java compiler available&apos; (Bing Li via Edward Capriolo) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1534392&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1534392&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hwi/ivy.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13801749" author="hudson" created="Tue, 22 Oct 2013 12:00:43 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-h0.21 #2413 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2413/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2413/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5132&quot; title=&quot;Can&amp;#39;t access to hwi due to &amp;quot;No Java compiler available&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5132&quot;&gt;&lt;del&gt;HIVE-5132&lt;/del&gt;&lt;/a&gt; - Can&apos;t access to hwi due to &apos;No Java compiler available&apos; (Bing Li via Edward Capriolo) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1534392&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1534392&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hwi/ivy.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13801768" author="hudson" created="Tue, 22 Oct 2013 12:36:28 +0000"  >&lt;p&gt;ABORTED: Integrated in Hive-trunk-hadoop2 #515 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/515/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/515/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5132&quot; title=&quot;Can&amp;#39;t access to hwi due to &amp;quot;No Java compiler available&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5132&quot;&gt;&lt;del&gt;HIVE-5132&lt;/del&gt;&lt;/a&gt; - Can&apos;t access to hwi due to &apos;No Java compiler available&apos; (Bing Li via Edward Capriolo) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1534392&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1534392&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hwi/ivy.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14063336" author="xinshengjun" created="Wed, 16 Jul 2014 09:51:29 +0000"  >&lt;p&gt;We meet the same issue and copy jasper-compiler-jdt.jar to $HIVE_HOME/lib can resolve this issue, the error log is:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Unable to find a javac compiler;
com.sun.tools.javac.Main is not on the classpath.
Perhaps JAVA_HOME does not point to the JDK.
It is currently set to &lt;span class=&quot;code-quote&quot;&gt;&quot;/usr/java/jdk1.7.0_45/jre&quot;&lt;/span&gt;
	at org.apache.tools.ant.taskdefs.compilers.CompilerAdapterFactory.getCompiler(CompilerAdapterFactory.java:129)
	at org.apache.tools.ant.taskdefs.Javac.findSupportedFileExtensions(Javac.java:979)
	at org.apache.tools.ant.taskdefs.Javac.scanDir(Javac.java:956)
	at org.apache.tools.ant.taskdefs.Javac.execute(Javac.java:927)
	at org.apache.jasper.compiler.AntCompiler.generateClass(AntCompiler.java:220)
	at org.apache.jasper.compiler.&lt;span class=&quot;code-object&quot;&gt;Compiler&lt;/span&gt;.compile(&lt;span class=&quot;code-object&quot;&gt;Compiler&lt;/span&gt;.java:298)
	at org.apache.jasper.compiler.&lt;span class=&quot;code-object&quot;&gt;Compiler&lt;/span&gt;.compile(&lt;span class=&quot;code-object&quot;&gt;Compiler&lt;/span&gt;.java:277)
	at org.apache.jasper.compiler.&lt;span class=&quot;code-object&quot;&gt;Compiler&lt;/span&gt;.compile(&lt;span class=&quot;code-object&quot;&gt;Compiler&lt;/span&gt;.java:265)
	at org.apache.jasper.JspCompilationContext.compile(JspCompilationContext.java:564)
	at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:299)
	at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:315)
	at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:265)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:401)
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
	at org.mortbay.jetty.servlet.Dispatcher.forward(Dispatcher.java:327)
	at org.mortbay.jetty.servlet.Dispatcher.forward(Dispatcher.java:126)
	at org.mortbay.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:503)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:401)
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.handler.RequestLogHandler.handle(RequestLogHandler.java:49)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:326)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
	at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14063773" author="lefty@hortonworks.com" created="Wed, 16 Jul 2014 17:38:37 +0000"  >&lt;p&gt;Should this be documented in the HWI wiki?&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/HiveWebInterface#HiveWebInterface-Configuration&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Hive Web Interface &amp;#8211; Configuartion &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14235384" author="guxiaobo1982" created="Fri, 5 Dec 2014 11:17:00 +0000"  >&lt;p&gt;Hi Shengjun,&lt;/p&gt;

&lt;p&gt;Which version of jasper-compiler-dt.jar do you use? where can I download it ?&lt;/p&gt;</comment>
                            <comment id="14235386" author="guxiaobo1982" created="Fri, 5 Dec 2014 11:18:38 +0000"  >&lt;p&gt;Is this patch is only one to apply to get this problem resolved?&lt;br/&gt;
I failed to apply it to the $HIVE_SRC_HOME/hwi/pom.xml of version 0.13.1. &lt;/p&gt;</comment>
                            <comment id="14236255" author="lefty@hortonworks.com" created="Fri, 5 Dec 2014 22:49:06 +0000"  >&lt;p&gt;Added TODOC10 and TODOC13 labels because this affects versions 0.10 &amp;amp; 0.11 (&amp;amp; presumably 0.12) and was fixed in 0.13.  If no documentation is needed, please remove the TODOC labels.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/HiveWebInterface#HiveWebInterface-Configuration&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Hive Web Interface &amp;#8211; Configuartion &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12708492">HIVE-6912</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12749372">HIVE-8525</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12721302">HIVE-7233</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12599971" name="HIVE-5132-01.patch" size="624" author="libing" created="Mon, 26 Aug 2013 16:38:13 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 16 Sep 2013 02:18:05 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344716</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 7 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ng1r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345016</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>hwi</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5133] webhcat jobs that need to access metastore fails in secure mode</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5133</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Webhcat job submission requests result in the pig/hive/mr job being run from a map task that it launches. In secure mode, for the pig/hive/mr job that is run to be authorized to perform actions on metastore, it has to have the delegation tokens from the hive metastore.&lt;br/&gt;
In case of pig/MR job this is needed if hcatalog is being used in the script/job.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12664774">HIVE-5133</key>
            <summary>webhcat jobs that need to access metastore fails in secure mode</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ekoifman">Eugene Koifman</assignee>
                                    <reporter username="thejas">Thejas M Nair</reporter>
                        <labels>
                    </labels>
                <created>Wed, 21 Aug 2013 05:40:22 +0000</created>
                <updated>Mon, 22 Sep 2014 23:36:25 +0000</updated>
                            <resolved>Fri, 18 Oct 2013 22:43:25 +0000</resolved>
                                    <version>0.11.0</version>
                                    <fixVersion>0.13.0</fixVersion>
                                    <component>WebHCat</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                            <comments>
                            <comment id="13748882" author="ekoifman" created="Fri, 23 Aug 2013 19:08:36 +0000"  >&lt;p&gt;1. Server#pig() &amp;amp; Server#mapReduceJar() - the JavaDoc lists all the parameters but no explanation of what each means.  At the very least new params should be documented.  Saying that it matches REST API isn&#8217;t really useful since &lt;a href=&quot;http://hive.apache.org/docs/hcat_r0.5.0/pig.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hive.apache.org/docs/hcat_r0.5.0/pig.html&lt;/a&gt; doesn&#8217;t describe all of them, especially the parameter just added.&lt;br/&gt;
2. PigDelegator#hasPigArgUseHcat() - would be useful to add a comment about what -useHCatalog does (or a URL)&lt;br/&gt;
3. I think MSTokenCleanOutputFormat is missing from the patch&lt;br/&gt;
4. In TempletonControllerJob - wouldn&#8217;t be cleaner to pass a variable in TCJ c&#8217;tor() that says delegation token is needed rather than passing via args and having to remove it?&lt;br/&gt;
5. Why does TempletonControllerJob#run() use UserGroupInformation.getCurrentUser(), but TempletonControllerJob#buildHCatDeletgationToken() uses UgiFactory.  Is there specific reason for this?&lt;br/&gt;
6. I think it would be really useful to add 10-20 lines of JavaDoc that explains why this whole thing is implemented/how it&#8217;s designed.  It would be a big help for maintainers (and doc writes)&lt;/p&gt;</comment>
                            <comment id="13753882" author="thejas" created="Thu, 29 Aug 2013 18:01:59 +0000"  >&lt;p&gt;Thanks for the feedback, I will create a new patch addressing these comments. I also need to add e2e tests.&lt;/p&gt;

&lt;p&gt;Note about the patch - With this change for submitting pig or MR jobs you need to specify usehcatalog=true as a POST param. (in curl command &quot; -d usehcatalog=true&quot; ). In case of pig this argument is option, it is sufficient that you have a  arg=&apos;-useHCatalog&apos; POST param.&lt;/p&gt;</comment>
                            <comment id="13755052" author="deepesh" created="Fri, 30 Aug 2013 19:23:32 +0000"  >&lt;p&gt;The current patch does fix the Pig but the MR job would fail to find missing HCat classes in classpath, see &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5188&quot; title=&quot;MR job launched through WebHCat fails to find additional jars in classpath&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5188&quot;&gt;HIVE-5188&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13755056" author="deepesh" created="Fri, 30 Aug 2013 19:28:02 +0000"  >&lt;p&gt;Attaching a supplementary patch containing the E2E test for running a Pig job using HCatLoader/HCatStorer through WebHCat.&lt;/p&gt;</comment>
                            <comment id="13763731" author="thejas" created="Tue, 10 Sep 2013 23:48:59 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5133&quot; title=&quot;webhcat jobs that need to access metastore fails in secure mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5133&quot;&gt;&lt;del&gt;HIVE-5133&lt;/del&gt;&lt;/a&gt;.2.patch - patch rebased for trunk, includes the tests contributed by Deepesh. I still need to address Eugene&apos;s comments.&lt;/p&gt;

&lt;p&gt;Thanks for creating the e2e tests &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=deepesh&quot; class=&quot;user-hover&quot; rel=&quot;deepesh&quot;&gt;Deepesh Khandelwal&lt;/a&gt;!&lt;/p&gt;</comment>
                            <comment id="13765697" author="deepesh" created="Thu, 12 Sep 2013 17:53:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt;, your latest patch is missing the test artifact hcatalog/src/test/e2e/templeton/inpdir/hcatloadstore.pig. Can you please include that in your patch?&lt;/p&gt;</comment>
                            <comment id="13767952" author="thejas" created="Sun, 15 Sep 2013 23:47:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5133&quot; title=&quot;webhcat jobs that need to access metastore fails in secure mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5133&quot;&gt;&lt;del&gt;HIVE-5133&lt;/del&gt;&lt;/a&gt;.3.patch - patch with hcatloadstore.pig. Thanks Deepesh for pointing out that it was missing!&lt;/p&gt;</comment>
                            <comment id="13774727" author="ekoifman" created="Mon, 23 Sep 2013 17:04:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5133&quot; title=&quot;webhcat jobs that need to access metastore fails in secure mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5133&quot;&gt;&lt;del&gt;HIVE-5133&lt;/del&gt;&lt;/a&gt;.3.patch has additional issue:&lt;/p&gt;

&lt;p&gt;org.apache.hive.hcatalog.templeton.tool.TempletonControllerJob and org.apache.hive.hcatalog.templeton.tool.MSTokenCleanOutputFormat are using org.apache.hcatalog.common.HCatUtil;&lt;br/&gt;
they should be using org.apache.hive.hcatalog.common.HCatUtil&lt;/p&gt;</comment>
                            <comment id="13796652" author="hiveqa" created="Wed, 16 Oct 2013 10:48:48 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12608625/HIVE-5133.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12608625/HIVE-5133.5.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 4411 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_script_broken_pipe1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/1138/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/1138/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/1138/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/1138/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13798646" author="thejas" created="Fri, 18 Oct 2013 00:12:32 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13799616" author="daijy" created="Fri, 18 Oct 2013 22:43:25 +0000"  >&lt;p&gt;Patch committed to trunk.&lt;/p&gt;</comment>
                            <comment id="13799673" author="hiveqa" created="Sat, 19 Oct 2013 00:04:58 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12609078/HIVE-5133.6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12609078/HIVE-5133.6.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/1162/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/1162/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/1162/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/1162/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-1162/source-prep.txt
+ [[ true == \t\r\u\e ]]
+ rm -rf ivy maven
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&apos;
Reverted &apos;common/src/java/org/apache/hadoop/hive/common/ObjectPair.java&apos;
Reverted &apos;ql/src/test/results/clientpositive/auto_sortmerge_join_9.q.out&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/PhysicalOptimizer.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/plan/ExplainWork.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/ExplainSemanticAnalyzer.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/ExplainTask.java&apos;
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf build hcatalog/build hcatalog/core/build hcatalog/storage-handlers/hbase/build hcatalog/server-extensions/build hcatalog/webhcat/svr/build hcatalog/webhcat/java-client/build hcatalog/hcatalog-pig-adapter/build common/src/gen ql/src/test/results/clientpositive/explain_rearrange.q.out ql/src/test/queries/clientpositive/explain_rearrange.q ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/StageIDsRearranger.java
+ svn update
U    hcatalog/src/test/e2e/templeton/tests/jobsubmission.conf
A    hcatalog/src/test/e2e/templeton/inpdir/hcatloadstore.pig
U    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CompleteDelegator.java
U    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JarDelegator.java
U    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/PigDelegator.java
U    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HiveDelegator.java
U    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/LauncherDelegator.java
A    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/DelegationTokenCache.java
U    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java
U    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/Server.java
U    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/StreamingDelegator.java
U    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/SecureProxySupport.java

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
Updated external to revision 1533667.

Updated to revision 1533667.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0 to p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13799683" author="ekoifman" created="Sat, 19 Oct 2013 00:24:41 +0000"  >&lt;p&gt;not sure what the issue is here.  I just checkout &lt;a href=&quot;https://github.com/apache/hive/commit/f7f32f2d9e5e29227ad800ed830d8f711b5dbd7a&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hive/commit/f7f32f2d9e5e29227ad800ed830d8f711b5dbd7a&lt;/a&gt; and applied this patch - it applies cleanly&lt;/p&gt;</comment>
                            <comment id="13799691" author="thejas" created="Sat, 19 Oct 2013 00:32:13 +0000"  >&lt;p&gt;Thats because the test applies patch to latest trunk.&lt;/p&gt;</comment>
                            <comment id="13799701" author="ekoifman" created="Sat, 19 Oct 2013 00:36:31 +0000"  >&lt;p&gt;this link is the latest trunk (before Danie&apos;s checkin of this patch)&lt;/p&gt;</comment>
                            <comment id="13799923" author="hudson" created="Sat, 19 Oct 2013 15:34:21 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-h0.21 #2408 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2408/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2408/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5133&quot; title=&quot;webhcat jobs that need to access metastore fails in secure mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5133&quot;&gt;&lt;del&gt;HIVE-5133&lt;/del&gt;&lt;/a&gt;: webhcat jobs that need to access metastore fails in secure mode (Eugene Koifman via Daniel Dai) (daijy: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1533658&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1533658&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/src/test/e2e/templeton/inpdir/hcatloadstore.pig&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/src/test/e2e/templeton/tests/jobsubmission.conf&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CompleteDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HiveDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JarDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/LauncherDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/PigDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/SecureProxySupport.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/Server.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/StreamingDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/DelegationTokenCache.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13800006" author="hudson" created="Sat, 19 Oct 2013 21:44:12 +0000"  >&lt;p&gt;ABORTED: Integrated in Hive-trunk-hadoop2 #511 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/511/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/511/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5133&quot; title=&quot;webhcat jobs that need to access metastore fails in secure mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5133&quot;&gt;&lt;del&gt;HIVE-5133&lt;/del&gt;&lt;/a&gt;: webhcat jobs that need to access metastore fails in secure mode (Eugene Koifman via Daniel Dai) (daijy: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1533658&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1533658&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/src/test/e2e/templeton/inpdir/hcatloadstore.pig&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/src/test/e2e/templeton/tests/jobsubmission.conf&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CompleteDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HiveDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JarDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/LauncherDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/PigDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/SecureProxySupport.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/Server.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/StreamingDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/DelegationTokenCache.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13800073" author="hudson" created="Sun, 20 Oct 2013 03:38:13 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #145 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/145/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/145/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5133&quot; title=&quot;webhcat jobs that need to access metastore fails in secure mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5133&quot;&gt;&lt;del&gt;HIVE-5133&lt;/del&gt;&lt;/a&gt;: webhcat jobs that need to access metastore fails in secure mode (Eugene Koifman via Daniel Dai) (daijy: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1533658&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1533658&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/src/test/e2e/templeton/inpdir/hcatloadstore.pig&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/src/test/e2e/templeton/tests/jobsubmission.conf&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CompleteDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HiveDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JarDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/LauncherDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/PigDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/SecureProxySupport.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/Server.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/StreamingDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/DelegationTokenCache.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13800081" author="hudson" created="Sun, 20 Oct 2013 05:10:46 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hive-trunk-hadoop1-ptest #208 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/208/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/208/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5133&quot; title=&quot;webhcat jobs that need to access metastore fails in secure mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5133&quot;&gt;&lt;del&gt;HIVE-5133&lt;/del&gt;&lt;/a&gt;: webhcat jobs that need to access metastore fails in secure mode (Eugene Koifman via Daniel Dai) (daijy: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1533658&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1533658&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/src/test/e2e/templeton/inpdir/hcatloadstore.pig&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/src/test/e2e/templeton/tests/jobsubmission.conf&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CompleteDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HiveDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JarDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/LauncherDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/PigDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/SecureProxySupport.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/Server.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/StreamingDelegator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/DelegationTokenCache.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12673155">HIVE-5511</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12666373">HIVE-5188</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12670396">HIVE-5353</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12673933">HIVE-5547</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12670991">HIVE-5384</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12599239" name="HIVE-5133.1.patch" size="31952" author="thejas" created="Wed, 21 Aug 2013 18:16:46 +0000"/>
                            <attachment id="12600842" name="HIVE-5133.1.test.patch" size="2679" author="deepesh" created="Fri, 30 Aug 2013 19:28:02 +0000"/>
                            <attachment id="12602469" name="HIVE-5133.2.patch" size="37771" author="thejas" created="Tue, 10 Sep 2013 23:48:59 +0000"/>
                            <attachment id="12603257" name="HIVE-5133.3.patch" size="39088" author="thejas" created="Sun, 15 Sep 2013 23:56:34 +0000"/>
                            <attachment id="12608625" name="HIVE-5133.5.patch" size="47066" author="ekoifman" created="Wed, 16 Oct 2013 01:00:55 +0000"/>
                            <attachment id="12609078" name="HIVE-5133.6.patch" size="46983" author="ekoifman" created="Fri, 18 Oct 2013 01:37:53 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12675312">HIVE-5627</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 23 Aug 2013 19:08:36 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344717</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ng1z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345017</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5134] add tests to partition filter JDO pushdown for like and make sure it works, or remove it</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5134</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;There&apos;s a mailing list thread. Partition filtering w/JDO pushdown using LIKE is not used by Hive due to client check (in PartitionPruner); after enabling it seems to be broken. We need to fix and enable it, or remove it.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12664939">HIVE-5134</key>
            <summary>add tests to partition filter JDO pushdown for like and make sure it works, or remove it</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="sershe">Sergey Shelukhin</assignee>
                                    <reporter username="sershe">Sergey Shelukhin</reporter>
                        <labels>
                    </labels>
                <created>Wed, 21 Aug 2013 23:29:16 +0000</created>
                <updated>Mon, 7 Oct 2013 23:44:25 +0000</updated>
                                                                            <component>Metastore</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13747152" author="sershe" created="Thu, 22 Aug 2013 01:56:41 +0000"  >&lt;p&gt;Here&apos;s an example test (with some implementation), on top of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4914&quot; title=&quot;filtering via partition name should be done inside metastore server (implementation)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4914&quot;&gt;&lt;del&gt;HIVE-4914&lt;/del&gt;&lt;/a&gt;, that is not going to work.&lt;/p&gt;

&lt;p&gt;If I remove the custom implementation and switch to UDFLike::likePatternToRegExp (moved into common to access from metastore), even fewer patterns from this test work.&lt;/p&gt;

&lt;p&gt;We should be able to add this test and make it work in some way, or remove the code.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12659223">HIVE-4914</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12599338" name="HIVE-5134-does-not-work.patch" size="15755" author="sershe" created="Thu, 22 Aug 2013 01:56:41 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344881</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 22 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nh2n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345182</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-5135] HCatalog test TestE2EScenarios fails with hadoop 2.x</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5135</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4388&quot; title=&quot;Upgrade HBase to 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4388&quot;&gt;&lt;del&gt;HIVE-4388&lt;/del&gt;&lt;/a&gt; makes a first couple of changes needed to fix unit tests with hadoop 2.x, and also modifies TestE2EScenarios to bring it up to date to use Shims, but TestE2EScenarios still fails because TaskAttemptId being instantiated with no arguments fails under hadoop 2.x.&lt;/p&gt;

&lt;p&gt;I&apos;m attaching a patch here which sits on top of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4388&quot; title=&quot;Upgrade HBase to 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4388&quot;&gt;&lt;del&gt;HIVE-4388&lt;/del&gt;&lt;/a&gt; to fix the test under hadoop 2.x, but is a WIP. After &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4388&quot; title=&quot;Upgrade HBase to 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4388&quot;&gt;&lt;del&gt;HIVE-4388&lt;/del&gt;&lt;/a&gt; gets committed, I will revisit this to check if we need to shim out TaskAttemptID or not, and test across versions.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12664956">HIVE-5135</key>
            <summary>HCatalog test TestE2EScenarios fails with hadoop 2.x</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="sushanth">Sushanth Sowmyan</assignee>
                                    <reporter username="sushanth">Sushanth Sowmyan</reporter>
                        <labels>
                    </labels>
                <created>Thu, 22 Aug 2013 00:53:28 +0000</created>
                <updated>Wed, 4 Sep 2013 17:22:53 +0000</updated>
                            <resolved>Wed, 4 Sep 2013 17:22:46 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13757504" author="sushanth" created="Wed, 4 Sep 2013 06:50:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5197&quot; title=&quot;TestE2EScenerios.createTaskAttempt should use MapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5197&quot;&gt;&lt;del&gt;HIVE-5197&lt;/del&gt;&lt;/a&gt; just got committed. It calls HCatMapredUtil.createTaskAttemptContext to create a task attempt context, need to verify if this solves the problem observed here.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12666716">HIVE-5197</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12643803">HIVE-4388</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12599326" name="e2e.wip.patch" size="3273" author="sushanth" created="Thu, 22 Aug 2013 00:55:12 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344898</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 20 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nh6f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345199</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5136] HCatalog HBase Storage handler fails test with protbuf2.5</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5136</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;With &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5112&quot; title=&quot;Upgrade protobuf to 2.5 from 2.4&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5112&quot;&gt;&lt;del&gt;HIVE-5112&lt;/del&gt;&lt;/a&gt; updating protobuf to 2.5, RevisionManagerEndpointProtos.java brought in by &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4388&quot; title=&quot;Upgrade HBase to 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4388&quot;&gt;&lt;del&gt;HIVE-4388&lt;/del&gt;&lt;/a&gt; in HCat needs to be updated and recompiled with protobuf2.5&lt;/p&gt;</description>
                <environment></environment>
        <key id="12664965">HIVE-5136</key>
            <summary>HCatalog HBase Storage handler fails test with protbuf2.5</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="sushanth">Sushanth Sowmyan</assignee>
                                    <reporter username="sushanth">Sushanth Sowmyan</reporter>
                        <labels>
                    </labels>
                <created>Thu, 22 Aug 2013 02:48:39 +0000</created>
                <updated>Tue, 10 Sep 2013 18:14:35 +0000</updated>
                            <resolved>Tue, 10 Sep 2013 18:14:28 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13760660" author="sushanth" created="Fri, 6 Sep 2013 21:34:52 +0000"  >&lt;p&gt;I&apos;m not setting this as patch available because it&apos;ll break things until &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4388&quot; title=&quot;Upgrade HBase to 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4388&quot;&gt;&lt;del&gt;HIVE-4388&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5112&quot; title=&quot;Upgrade protobuf to 2.5 from 2.4&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5112&quot;&gt;&lt;del&gt;HIVE-5112&lt;/del&gt;&lt;/a&gt; are committed. I&apos;ll regenerate this patch after they&apos;re committed and then set it to patch-available.&lt;/p&gt;</comment>
                            <comment id="13763119" author="brocknoland" created="Tue, 10 Sep 2013 15:29:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sushanth&quot; class=&quot;user-hover&quot; rel=&quot;sushanth&quot;&gt;Sushanth Sowmyan&lt;/a&gt; with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5112&quot; title=&quot;Upgrade protobuf to 2.5 from 2.4&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5112&quot;&gt;&lt;del&gt;HIVE-5112&lt;/del&gt;&lt;/a&gt; committed I&apos;d like to commit this. &lt;/p&gt;

&lt;p&gt;Any chance you can upgrade hadoop in the hcatalog pom to match &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5112&quot; title=&quot;Upgrade protobuf to 2.5 from 2.4&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5112&quot;&gt;&lt;del&gt;HIVE-5112&lt;/del&gt;&lt;/a&gt; and regenerate the Complexpb file you found in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5112&quot; title=&quot;Upgrade protobuf to 2.5 from 2.4&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5112&quot;&gt;&lt;del&gt;HIVE-5112&lt;/del&gt;&lt;/a&gt;? That way we&apos;d have all this fixed in one go.&lt;/p&gt;</comment>
                            <comment id="13763172" author="brocknoland" created="Tue, 10 Sep 2013 16:23:32 +0000"  >&lt;p&gt;Oh wait, nevermind. I see this is patch on top of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4388&quot; title=&quot;Upgrade HBase to 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4388&quot;&gt;&lt;del&gt;HIVE-4388&lt;/del&gt;&lt;/a&gt;. In that case I think we can close this because I will just regenerate the file in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4388&quot; title=&quot;Upgrade HBase to 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4388&quot;&gt;&lt;del&gt;HIVE-4388&lt;/del&gt;&lt;/a&gt;. It needs some work anyway because it&apos;s going against a moving target (pre-release hbase 0.96).&lt;/p&gt;</comment>
                            <comment id="13763313" author="sushanth" created="Tue, 10 Sep 2013 18:12:08 +0000"  >&lt;p&gt;Yup, I think that makes sense to regenerate this in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4388&quot; title=&quot;Upgrade HBase to 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4388&quot;&gt;&lt;del&gt;HIVE-4388&lt;/del&gt;&lt;/a&gt; itself. We should be able to close this.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12643803">HIVE-4388</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12643803">HIVE-4388</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12664130">HIVE-5112</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12599345" name="hbase-protobuf-update.patch" size="562141" author="sushanth" created="Thu, 22 Aug 2013 02:52:09 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 10 Sep 2013 15:29:36 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344907</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 19 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nh8f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345208</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Marking as WONTFIX, and tracking this change in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4388&quot; title=&quot;Upgrade HBase to 0.96&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4388&quot;&gt;&lt;strike&gt;HIVE-4388&lt;/strike&gt;&lt;/a&gt; itself.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5137] A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5137</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently, a query like &quot;create table if not exists t2 as select * from t1&quot; sets the hasResultSet to true in SQLOperation and in turn, the query returns a result set. However, as a DDL command, this should ideally not return a result set.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665001">HIVE-5137</key>
            <summary>A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vgumashta">Vaibhav Gumashta</assignee>
                                    <reporter username="vgumashta">Vaibhav Gumashta</reporter>
                        <labels>
                    </labels>
                <created>Thu, 22 Aug 2013 08:23:31 +0000</created>
                <updated>Tue, 15 Oct 2013 23:30:41 +0000</updated>
                            <resolved>Tue, 3 Sep 2013 03:44:58 +0000</resolved>
                                    <version>0.11.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                    <component>HiveServer2</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13747368" author="phabricator@reviews.facebook.net" created="Thu, 22 Aug 2013 08:42:52 +0000"  >&lt;p&gt;vaibhavgumashta requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTaskSQL&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt;, WIP patch 1 for reviewing the progress. testExplainStmt in TestJdbcDriver2 will need a relook, commented out for now.&lt;/p&gt;

&lt;p&gt;Currently, a query like &quot;create table if not exists t2 as select * from t1&quot; sets the hasResultSet to true in SQLOperation and in turn, the query returns a result set. However, as a DDL command, this should ideally not return a result set.&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java&lt;br/&gt;
  service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/29799/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/29799/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, vaibhavgumashta&lt;/p&gt;</comment>
                            <comment id="13747376" author="phabricator@reviews.facebook.net" created="Thu, 22 Aug 2013 08:52:53 +0000"  >&lt;p&gt;vaibhavgumashta updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTaskSQL&quot;.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Eclipse removed unused imports on commenting out testExplainStmt. Adding back&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453?vs=38625&amp;amp;id=38631#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453?vs=38625&amp;amp;id=38631#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  bin/hive&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/common/ObjectPair.java&lt;br/&gt;
  conf/hive-default.xml.template&lt;br/&gt;
  hcatalog/core/src/main/java/org/apache/hcatalog/data/schema/HCatFieldSchema.java&lt;br/&gt;
  hcatalog/core/src/test/java/org/apache/hcatalog/data/schema/TestHCatSchema.java&lt;br/&gt;
  jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/ExprProcCtx.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/ExprProcFactory.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/OpProcFactory.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/OpWalkerCtx.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartExprEvalUtils.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/MetaDataExportListener.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/ParseContext.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/udf/UDFBaseCompare.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToDate.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/udf/UDFUnixTimeStamp.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/create_udaf.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/list_bucket_dml_7.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/list_bucket_dml_8.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/orc_dictionary_threshold.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/udf4.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/udf_pmod.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/udf_to_boolean.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/udf_to_byte.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/udf_to_double.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/udf_to_float.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/udf_to_long.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/udf_to_short.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/udf_to_string.q&lt;br/&gt;
  ql/src/test/results/clientpositive/create_udaf.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/infer_bucket_sort_list_bucket.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/list_bucket_dml_7.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/list_bucket_dml_8.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/orc_dictionary_threshold.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/stats_noscan_2.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/udf4.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/udf_pmod.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/udf_to_boolean.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/udf_to_byte.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/udf_to_double.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/udf_to_float.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/udf_to_long.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/udf_to_short.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/udf_to_string.q.out&lt;br/&gt;
  service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java&lt;/p&gt;

&lt;p&gt;To: JIRA, vaibhavgumashta&lt;/p&gt;</comment>
                            <comment id="13747382" author="phabricator@reviews.facebook.net" created="Thu, 22 Aug 2013 09:01:01 +0000"  >&lt;p&gt;vaibhavgumashta updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTaskSQL&quot;.&lt;/p&gt;

&lt;p&gt;  Updating the accidental push.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453?vs=38631&amp;amp;id=38655#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453?vs=38631&amp;amp;id=38655#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java&lt;br/&gt;
  service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java&lt;/p&gt;

&lt;p&gt;To: JIRA, vaibhavgumashta&lt;/p&gt;</comment>
                            <comment id="13747385" author="phabricator@reviews.facebook.net" created="Thu, 22 Aug 2013 09:06:53 +0000"  >&lt;p&gt;vaibhavgumashta updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTaskSQL&quot;.&lt;/p&gt;

&lt;p&gt;  Eclipse import related fix.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453?vs=38655&amp;amp;id=38661#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453?vs=38655&amp;amp;id=38661#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java&lt;br/&gt;
  service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java&lt;/p&gt;

&lt;p&gt;To: JIRA, vaibhavgumashta&lt;/p&gt;</comment>
                            <comment id="13747389" author="phabricator@reviews.facebook.net" created="Thu, 22 Aug 2013 09:12:53 +0000"  >&lt;p&gt;vaibhavgumashta updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTaskSQL&quot;.&lt;/p&gt;

&lt;p&gt;  Final fix.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453?vs=38661&amp;amp;id=38679#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453?vs=38661&amp;amp;id=38679#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java&lt;br/&gt;
  service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java&lt;/p&gt;

&lt;p&gt;To: JIRA, vaibhavgumashta&lt;/p&gt;</comment>
                            <comment id="13747924" author="phabricator@reviews.facebook.net" created="Thu, 22 Aug 2013 21:50:53 +0000"  >&lt;p&gt;thejas has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTaskSQL&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java:473 I think writing it to stderr is better. Maybe create a function for this -&lt;/p&gt;

&lt;p&gt;        e.printStackTrace();&lt;br/&gt;
        fail(e.toString());&lt;br/&gt;
  jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java:468 a function for this will make it more readable -&lt;br/&gt;
  Something like -&lt;br/&gt;
  checkResultsAvailable(String[] setupStmts, String stmt, boolean resultsExpected)&lt;br/&gt;
  jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java:267 We need to look at ways to get explain statement giving results as well.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, vaibhavgumashta&lt;br/&gt;
Cc: thejas&lt;/p&gt;</comment>
                            <comment id="13747995" author="phabricator@reviews.facebook.net" created="Thu, 22 Aug 2013 22:30:53 +0000"  >&lt;p&gt;thejas has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTaskSQL&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java:262 can you also add a testcase that uses executeQuery() with a query that does not produce result, and verify that it throws an exception ?&lt;br/&gt;
  service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java:102 it will be more better to check for getFetchTask in the if condition, then assert the condtions on the schema within the if {} block&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, vaibhavgumashta&lt;br/&gt;
Cc: thejas&lt;/p&gt;</comment>
                            <comment id="13748163" author="phabricator@reviews.facebook.net" created="Fri, 23 Aug 2013 00:50:52 +0000"  >&lt;p&gt;thejas has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTaskSQL&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java:103 Explain is the only case that I found that is not making use of fetch task.  It using the Context file/dir, but unlike other tasks, it does not add a fetch task for the read. Long term, I think we should make it consistent by using fetchtask for that as well. But for now we can just check for ExplainTask in the plan.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, vaibhavgumashta&lt;br/&gt;
Cc: thejas&lt;/p&gt;</comment>
                            <comment id="13749262" author="phabricator@reviews.facebook.net" created="Sat, 24 Aug 2013 02:34:52 +0000"  >&lt;p&gt;vaibhavgumashta updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTaskSQL&quot;.&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt;: Refactoring of TestJdbcDriver2, added condition to set hasResultSet true for an explain query.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453?vs=38679&amp;amp;id=38973#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453?vs=38679&amp;amp;id=38973#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java&lt;br/&gt;
  service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java&lt;/p&gt;

&lt;p&gt;To: JIRA, vaibhavgumashta&lt;br/&gt;
Cc: thejas&lt;/p&gt;</comment>
                            <comment id="13749276" author="phabricator@reviews.facebook.net" created="Sat, 24 Aug 2013 02:56:52 +0000"  >&lt;p&gt;thejas has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTaskSQL&quot;.&lt;/p&gt;

&lt;p&gt;  Looks good. Just 2 minor nits.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java:113 Can you make it something like &quot;&quot;Error running query: Schema and FieldSchema should be set when query plan has a FetchTask&quot;&lt;br/&gt;
  service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java:109 I think its a little easier to read to write it this way-&lt;br/&gt;
  if(driver.getPlan().getFetchTask() != null) {&lt;br/&gt;
   //Schema has to be set&lt;br/&gt;
   if(not schema set)&lt;/p&gt;
{
      throw error;
   }
&lt;p&gt;    ..&lt;br/&gt;
    setHasResultSet(true);&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, vaibhavgumashta&lt;br/&gt;
Cc: thejas&lt;/p&gt;</comment>
                            <comment id="13749298" author="phabricator@reviews.facebook.net" created="Sat, 24 Aug 2013 04:34:54 +0000"  >&lt;p&gt;vaibhavgumashta updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTaskSQL&quot;.&lt;/p&gt;

&lt;p&gt;  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt;: minor refactoring&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453?vs=38973&amp;amp;id=38979#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453?vs=38973&amp;amp;id=38979#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java&lt;br/&gt;
  service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java&lt;/p&gt;

&lt;p&gt;To: JIRA, vaibhavgumashta&lt;br/&gt;
Cc: thejas&lt;/p&gt;</comment>
                            <comment id="13749311" author="phabricator@reviews.facebook.net" created="Sat, 24 Aug 2013 05:02:53 +0000"  >&lt;p&gt;thejas has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTaskSQL&quot;.&lt;/p&gt;

&lt;p&gt;  LGTM +1&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12453&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12453&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, vaibhavgumashta&lt;br/&gt;
Cc: thejas&lt;/p&gt;</comment>
                            <comment id="13753796" author="vgumashta" created="Thu, 29 Aug 2013 16:43:38 +0000"  >&lt;p&gt;Uploading a copy of same patch to kickoff tests&lt;/p&gt;</comment>
                            <comment id="13755302" author="vgumashta" created="Sat, 31 Aug 2013 00:39:16 +0000"  >&lt;p&gt;Cancelling to upload the patch in a valid format&lt;/p&gt;</comment>
                            <comment id="13755389" author="hiveqa" created="Sat, 31 Aug 2013 03:12:00 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12600903/HIVE-5137.D12453.8.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12600903/HIVE-5137.D12453.8.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 2904 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/580/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/580/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/580/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/580/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13756338" author="thejas" created="Tue, 3 Sep 2013 03:44:58 +0000"  >&lt;p&gt;Patch committed to trunk. Vaibhav, thanks for the contribution!&lt;/p&gt;</comment>
                            <comment id="13756400" author="hudson" created="Tue, 3 Sep 2013 06:57:45 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #82 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/82/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/82/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt;: A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask (Vaibhav Gumashta via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519547&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519547&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13756465" author="hudson" created="Tue, 3 Sep 2013 08:56:35 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hive-trunk-hadoop1-ptest #149 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/149/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/149/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt;: A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask (Vaibhav Gumashta via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519547&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519547&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13756583" author="hudson" created="Tue, 3 Sep 2013 12:57:08 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2 #399 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/399/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/399/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt;: A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask (Vaibhav Gumashta via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519547&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519547&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13756671" author="hudson" created="Tue, 3 Sep 2013 14:51:10 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-h0.21 #2307 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2307/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2307/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5137&quot; title=&quot;A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5137&quot;&gt;&lt;del&gt;HIVE-5137&lt;/del&gt;&lt;/a&gt;: A Hive SQL query should not return a ResultSet when the underlying plan does not include a FetchTask (Vaibhav Gumashta via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519547&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519547&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13756680" author="appodictic" created="Tue, 3 Sep 2013 15:01:05 +0000"  >&lt;p&gt;If you call fetchAll() does it return empty List or throw exception? There may be some users calling fetchAll() regardless of the query.&lt;/p&gt;</comment>
                            <comment id="13756723" author="thejas" created="Tue, 3 Sep 2013 16:02:21 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=appodictic&quot; class=&quot;user-hover&quot; rel=&quot;appodictic&quot;&gt;Edward Capriolo&lt;/a&gt; I didn&apos;t understand your comment. fetchAll() method of which class ?&lt;/p&gt;</comment>
                            <comment id="13756730" author="appodictic" created="Tue, 3 Sep 2013 16:07:18 +0000"  >&lt;p&gt;HiveInterface.fetchAll(). I know we have scripts that call FetchAll() or fetchOne() on queries that probably do not have one. I wanted to make sure this will not be a breaking change to existing code. &lt;/p&gt;</comment>
                            <comment id="13756739" author="thejas" created="Tue, 3 Sep 2013 16:15:41 +0000"  >&lt;p&gt;HiveInterface is specific to hiveserver1, so this HS2 change will have no impact.&lt;/p&gt;</comment>
                            <comment id="13756845" author="appodictic" created="Tue, 3 Sep 2013 18:01:59 +0000"  >&lt;p&gt;Ok makes sense. &lt;/p&gt;</comment>
                            <comment id="13796057" author="ashutoshc" created="Tue, 15 Oct 2013 23:30:41 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12599386" name="HIVE-5137.D12453.1.patch" size="5128" author="phabricator@reviews.facebook.net" created="Thu, 22 Aug 2013 08:42:52 +0000"/>
                            <attachment id="12599390" name="HIVE-5137.D12453.2.patch" size="125123" author="phabricator@reviews.facebook.net" created="Thu, 22 Aug 2013 08:52:53 +0000"/>
                            <attachment id="12599392" name="HIVE-5137.D12453.3.patch" size="5030" author="phabricator@reviews.facebook.net" created="Thu, 22 Aug 2013 09:01:01 +0000"/>
                            <attachment id="12599393" name="HIVE-5137.D12453.4.patch" size="5128" author="phabricator@reviews.facebook.net" created="Thu, 22 Aug 2013 09:06:53 +0000"/>
                            <attachment id="12599399" name="HIVE-5137.D12453.5.patch" size="4686" author="phabricator@reviews.facebook.net" created="Thu, 22 Aug 2013 09:12:53 +0000"/>
                            <attachment id="12599779" name="HIVE-5137.D12453.6.patch" size="5438" author="phabricator@reviews.facebook.net" created="Sat, 24 Aug 2013 02:34:52 +0000"/>
                            <attachment id="12599784" name="HIVE-5137.D12453.7.patch" size="5413" author="phabricator@reviews.facebook.net" created="Sat, 24 Aug 2013 04:34:54 +0000"/>
                            <attachment id="12600903" name="HIVE-5137.D12453.8.patch" size="5413" author="vgumashta" created="Sat, 31 Aug 2013 00:42:23 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 22 Aug 2013 08:42:52 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344942</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nhg7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345243</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5138] Streaming - Web HCat  API</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5138</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12665159">HIVE-5138</key>
            <summary>Streaming - Web HCat  API</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12637360">HIVE-4196</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="roshan_naik">Roshan Naik</assignee>
                                    <reporter username="roshan_naik">Roshan Naik</reporter>
                        <labels>
                    </labels>
                <created>Fri, 23 Aug 2013 00:39:45 +0000</created>
                <updated>Tue, 24 Sep 2013 23:55:35 +0000</updated>
                                                                            <component>HCatalog</component>
                    <component>Metastore</component>
                    <component>WebHCat</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13748165" author="roshan_naik" created="Fri, 23 Aug 2013 00:52:10 +0000"  >&lt;p&gt;Implement Webhcat API to: &lt;/p&gt;


&lt;p&gt;1) Enable and Disable streaming on a table&lt;/p&gt;

&lt;p&gt;2) Check streaming status&lt;/p&gt;

&lt;p&gt;3) Transaction Support:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Get a Chunk File&lt;/li&gt;
	&lt;li&gt;Commit a Chunk File&lt;/li&gt;
	&lt;li&gt;Abort the chunk&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;4) Roll Partition: To roll the committed chunks from streaming partition to a new standard partition&lt;/p&gt;</comment>
                            <comment id="13760862" author="roshan_naik" created="Sat, 7 Sep 2013 01:58:07 +0000"  >&lt;p&gt;Patch v2 is based on git commit version 9e9e711&lt;/p&gt;</comment>
                            <comment id="13760863" author="roshan_naik" created="Sat, 7 Sep 2013 01:59:27 +0000"  >&lt;p&gt;Patch v2 addresses the review comments from &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4196?focusedCommentId=13714235&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13714235&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-4196?focusedCommentId=13714235&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13714235&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13762146" author="ekoifman" created="Mon, 9 Sep 2013 18:46:44 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=roshan_naik&quot; class=&quot;user-hover&quot; rel=&quot;roshan_naik&quot;&gt;Roshan Naik&lt;/a&gt; A couple of comments on this patch:&lt;br/&gt;
1. All delegators in WebHCat take the &apos;user&apos; as determined by Server.java and use that to make secure calls to JobTrakcer, HDFS etc.  HCatStreamingDelegator ignores it.  Why is that?&lt;br/&gt;
2. Most operations in HCatStreamingDelegator do multiple things (like modify metadata, create some HDFS file, etc.).  It sounds like every one of these operations should be atomic.  For example, say for some reason 2 identical calls to partitionRoll() happen at the same time.  How is this atomicity achieved?&lt;/p&gt;</comment>
                            <comment id="13769209" author="roshan_naik" created="Tue, 17 Sep 2013 05:20:12 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ekoifman&quot; class=&quot;user-hover&quot; rel=&quot;ekoifman&quot;&gt;Eugene Koifman&lt;/a&gt; for the comments:&lt;/p&gt;

&lt;h5&gt;&lt;a name=&quot;OnPt1.&quot;&gt;&lt;/a&gt;On Pt 1.&lt;/h5&gt;
&lt;p&gt; Thanks. I need to take a closer look at this.&lt;/p&gt;


&lt;h5&gt;&lt;a name=&quot;OnPt2.&quot;&gt;&lt;/a&gt;On Pt 2.&lt;/h5&gt;
&lt;p&gt; I think you mean &apos;safe to invoke concurrently&apos; instead of &apos;atomic&apos;, since the intermediate states are going to be visible when an operation spans both file system and meta store. Here is a summary of the reasons why each operation is concurrency safe:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;b&gt;streamingStatus&lt;/b&gt; : Readonly metastore operation&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;chunkGet&lt;/b&gt; : This is an atomic metastore operation&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;chunkAbort&lt;/b&gt; : Just deletes a file. So no concurrency issues here.&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;chunkCommit&lt;/b&gt; : Just renames a file. So only one of concurrent operations will succeed.&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;disableStreaming&lt;/b&gt; : This is an atomic metastore operation&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;enableStreaming&lt;/b&gt; : Does a couple of mkdirs (for setup) followed by an atomic metastore operation. mkdirs() is idempotent, so all concurrent calls succeed. All concurrent invocations enter a transaction to do the metastore update atomically...only one should update metastore.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;b&gt;partitionRoll&lt;/b&gt; : Creates empty dir for the new current partition &amp;amp; then atomically updates metastore as follows:
	&lt;ol&gt;
		&lt;li&gt;Make note of this new current partition dir&lt;/li&gt;
		&lt;li&gt;Do an addPartition() on the previous current partition.&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;If concurrent partitionRoll() invocations use same arguments, the addPartition() step will fail on all but one. If arguments are not same in concurrent invocations, they all succeed and updates made by the last invocation to exit the metastore transaction would override the others.&lt;/li&gt;
&lt;/ul&gt;


</comment>
                            <comment id="13769784" author="ekoifman" created="Tue, 17 Sep 2013 18:28:11 +0000"  >&lt;p&gt;OK, makes sense.  It would be useful to add some javadoc about concurrency (or rather why it&apos;s not an issue)&lt;/p&gt;</comment>
                            <comment id="13770191" author="roshan_naik" created="Wed, 18 Sep 2013 00:01:25 +0000"  >&lt;p&gt;Patch address comments from Eugene, additional unit test, some additional checks in partitionRoll for better error reporting.&lt;/p&gt;</comment>
                            <comment id="13776946" author="roshan_naik" created="Tue, 24 Sep 2013 23:50:28 +0000"  >&lt;p&gt;Capturing API related comments from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt; noted &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4196?focusedCommentId=13770314&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13770314&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt; in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4196&quot; title=&quot;Support for Streaming Partitions in Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4196&quot;&gt;&lt;del&gt;HIVE-4196&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We should try to eliminate the need of intermediate staging area while rolling on new partitions. Seems like there should not be any gotchas while moving data from streaming dir to partition dir directly.&lt;br/&gt;
We should make thrift apis in metastore forward compatible. One way to do that is to use struct (which contains all parameters) instead of passing in list of arguments.&lt;br/&gt;
We should try to leave TBLS table untouched in backend db. That will simplify upgrade story. One way to do that is to have all new columns in a new table and than add constraints for this new table.&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="13776954" author="roshan_naik" created="Tue, 24 Sep 2013 23:55:35 +0000"  >&lt;blockquote&gt;&lt;p&gt;We should try to eliminate the need of intermediate staging area while rolling on new partitions. Seems like there should not be any gotchas while moving data from streaming dir to partition dir directly.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks. That change is already part of the patch.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We should make thrift apis in metastore forward compatible. One way to do that is to use struct (which contains all parameters) instead of passing in list of arguments.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hate it .. but Ok. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;We should try to leave TBLS table untouched in backend db. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Sure. Will move them to a new table.&lt;/p&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12601954" name="HIVE-4196.v2.patch" size="2632621" author="roshan_naik" created="Sat, 7 Sep 2013 01:58:07 +0000"/>
                            <attachment id="12603720" name="HIVE-5138.v1.patch" size="2645973" author="roshan_naik" created="Wed, 18 Sep 2013 00:01:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 9 Sep 2013 18:46:44 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345100</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 17 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nif3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345401</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-5139] Streaming - DDL support for enabling and disabling streaming</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5139</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12665161">HIVE-5139</key>
            <summary>Streaming - DDL support for enabling and disabling streaming</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12637360">HIVE-4196</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="roshan_naik">Roshan Naik</assignee>
                                    <reporter username="roshan_naik">Roshan Naik</reporter>
                        <labels>
                            <label>ddl</label>
                            <label>streaming</label>
                    </labels>
                <created>Fri, 23 Aug 2013 00:40:53 +0000</created>
                <updated>Fri, 23 Aug 2013 00:46:18 +0000</updated>
                                                                            <component>Database/Schema</component>
                    <component>HCatalog</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13748149" author="roshan_naik" created="Fri, 23 Aug 2013 00:46:18 +0000"  >&lt;p&gt;Task is to implement support for enabling and disabling streaming functionality on a Hive table via DDL.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345102</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 22 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nifj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345403</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-5140] Streaming - Active agent for rolling a streaming partition into a standard partition</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5140</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The task is to implement an entity which rolls all the committed transactions from the streaming partition into a new standard partition atomically.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665163">HIVE-5140</key>
            <summary>Streaming - Active agent for rolling a streaming partition into a standard partition</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12637360">HIVE-4196</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="roshan_naik">Roshan Naik</assignee>
                                    <reporter username="roshan_naik">Roshan Naik</reporter>
                        <labels>
                            <label>Streaming</label>
                    </labels>
                <created>Fri, 23 Aug 2013 00:44:18 +0000</created>
                <updated>Fri, 23 Aug 2013 00:44:18 +0000</updated>
                                                                            <component>Database/Schema</component>
                    <component>HCatalog</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345104</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 22 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nifz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345405</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Streaming</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-5141] insert from another table, data get implicit converted when column type is different</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5141</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;describe t1;&lt;br/&gt;
i smallint&lt;/p&gt;

&lt;p&gt;describe t2;&lt;br/&gt;
i bigint&lt;/p&gt;

&lt;p&gt;select * from t2;&lt;br/&gt;
9&lt;br/&gt;
9999999999&lt;/p&gt;

&lt;p&gt;insert overwrite table t1 select * from t2;&lt;br/&gt;
select * from t1;&lt;br/&gt;
9&lt;br/&gt;
-7169&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665164">HIVE-5141</key>
            <summary>insert from another table, data get implicit converted when column type is different</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="xguo27">Xiu (Joe) Guo</reporter>
                        <labels>
                    </labels>
                <created>Fri, 23 Aug 2013 00:51:53 +0000</created>
                <updated>Fri, 23 Aug 2013 00:51:53 +0000</updated>
                                            <version>0.9.0</version>
                                                    <component>CLI</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345105</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 22 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nig7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345406</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-5142] Streaming - Query committed chunks</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5142</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Task is to enable queries to read through the chunks committed into the streaming partition.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665165">HIVE-5142</key>
            <summary>Streaming - Query committed chunks</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12637360">HIVE-4196</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="roshan_naik">Roshan Naik</assignee>
                                    <reporter username="roshan_naik">Roshan Naik</reporter>
                        <labels>
                    </labels>
                <created>Fri, 23 Aug 2013 00:56:07 +0000</created>
                <updated>Fri, 23 Aug 2013 00:56:20 +0000</updated>
                                                                            <component>Database/Schema</component>
                    <component>HCatalog</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345106</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 22 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nigf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345407</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-5143] Streaming - Compaction of partitions</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5143</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Task is to support compaction of partitions.&lt;/p&gt;

&lt;p&gt;Rationale: Streaming partitions are composed of a large number of small files (each commit is one file). Since compaction can be a potentially expensive operation (for e.g. converting to single ORC file), we do not compact the streaming partition at the time of rolling it into a standard partition. This allows rolling to be quick and atomic.&lt;/p&gt;

&lt;p&gt;Compaction will be performed at a later time. The streaming partition is converted as is (typically with a many small files) into a standard partition. This new standard partition will be queued up for compaction by a separate job.&lt;/p&gt;

&lt;p&gt;This decouples the compaction feature from streaming support, and makes it more generally available for any partitions.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665166">HIVE-5143</key>
            <summary>Streaming - Compaction of partitions</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12637360">HIVE-4196</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="roshan_naik">Roshan Naik</assignee>
                                    <reporter username="roshan_naik">Roshan Naik</reporter>
                        <labels>
                            <label>compaction</label>
                            <label>streaming</label>
                    </labels>
                <created>Fri, 23 Aug 2013 01:08:02 +0000</created>
                <updated>Fri, 23 Aug 2013 01:08:02 +0000</updated>
                                                                            <component>Database/Schema</component>
                    <component>HCatalog</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345107</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 22 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nign:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345408</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>streaming compaction</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-5144] HashTableSink allocates empty new Object[] arrays &amp; OOMs - use a static emptyRow instead</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5144</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The map-join hashtable sink in the local-task creates an in-memory hashtable with the following code.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[] value = JoinUtil.computeMapJoinValues(row, joinValues[alias],
...
 MapJoinRowContainer rowContainer = tableContainer.get(key);
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (rowContainer == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
      rowContainer = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; MapJoinRowContainer();
      rowContainer.add(value);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But for a query where the joinValues&lt;span class=&quot;error&quot;&gt;&amp;#91;alias&amp;#93;&lt;/span&gt;.size() == 0, this results in a large number of unnecessary allocations which would be better served with a copy-on-write default value container &amp;amp; a pre-allocated zero object array which is immutable (the only immutable array there is in java).&lt;/p&gt;

&lt;p&gt;The query tested is roughly the following to scan all of customer_demographics in the hash-sink&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
select c_salutation, count(1)
 from customer
      JOIN customer_demographics ON customer.c_current_cdemo_sk = customer_demographics.cd_demo_sk
 group by c_salutation
 limit 10
;

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When running with current trunk, the code results in an OOM with 512Mb ram.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2013-08-23 05:11:26	Processing rows:	1400000	Hashtable size:	1399999	Memory usage:	292418944	percentage:	0.579

Execution failed with exit status: 3
Obtaining error information
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</description>
                <environment>&lt;p&gt;Ubuntu LXC + -Xmx512m client opts&lt;/p&gt;</environment>
        <key id="12665264">HIVE-5144</key>
            <summary>HashTableSink allocates empty new Object[] arrays &amp; OOMs - use a static emptyRow instead</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gopalv">Gopal V</assignee>
                                    <reporter username="gopalv">Gopal V</reporter>
                        <labels>
                            <label>perfomance</label>
                    </labels>
                <created>Fri, 23 Aug 2013 17:15:49 +0000</created>
                <updated>Tue, 15 Oct 2013 23:30:49 +0000</updated>
                            <resolved>Tue, 27 Aug 2013 16:48:54 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13748737" author="gopalv" created="Fri, 23 Aug 2013 17:21:36 +0000"  >&lt;p&gt;With the attached patch, the memory usage drops from 199 Mb per million rows to approx 99 Mb per million rows.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2013-08-23 05:14:06	Processing rows:	1900000	Hashtable size:	1899999	Memory usage:	197394288	percentage:	0.391
...
OK
	2475
Dr.	40003
Mrs.	16612
Ms.	16617
Mr.	23590
Miss	16368
Sir	23394
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13748749" author="gopalv" created="Fri, 23 Aug 2013 17:29:33 +0000"  >&lt;p&gt;Tests running with `ant test -Dmodule=ql -Dresolvers=internal -Dtestcase=TestCliDriver -Dqfile_pattern=&lt;b&gt;mapjoin&lt;/b&gt;`&lt;/p&gt;

&lt;p&gt;Submit-patch for full QA run.&lt;/p&gt;</comment>
                            <comment id="13748839" author="ashutoshc" created="Fri, 23 Aug 2013 18:31:34 +0000"  >&lt;p&gt;Nice findings, Gopal!&lt;/p&gt;

&lt;p&gt;Couple of comments:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Shall we do initialization of empty row and container in the constructor?&lt;/li&gt;
	&lt;li&gt;Also mark these fields as transient.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13748846" author="gopalv" created="Fri, 23 Aug 2013 18:45:05 +0000"  >&lt;p&gt;I followed the pattern from MapJoinKey and MapJoinRowContainer which both use static final EMPTY_OBJECT_ARRAY[].&lt;/p&gt;

&lt;p&gt;And since the empty items are immutable, I followed the same pattern.&lt;/p&gt;
</comment>
                            <comment id="13748896" author="gopalv" created="Fri, 23 Aug 2013 19:26:35 +0000"  >&lt;p&gt;Test case run finished, auto_join30.q fails. &lt;/p&gt;

&lt;p&gt;Cancelling patch.&lt;/p&gt;</comment>
                            <comment id="13750158" author="gopalv" created="Mon, 26 Aug 2013 15:46:23 +0000"  >&lt;p&gt;Bad merge in patch.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;-    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;((hasFilter(alias) &amp;amp;&amp;amp; joinFilters[alias].size() &amp;gt; 0) || joinValues[alias]
+    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;((hasFilter(alias) &amp;amp;&amp;amp; filterMaps[alias].length &amp;gt; 0) || joinValues[alias].
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The check is supposed to be on filterMaps not joinFilters.&lt;/p&gt;

&lt;p&gt;This fixes test-failures found in the last run.&lt;/p&gt;</comment>
                            <comment id="13750182" author="ashutoshc" created="Mon, 26 Aug 2013 16:06:32 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13751426" author="ashutoshc" created="Tue, 27 Aug 2013 16:48:54 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Gopal!&lt;/p&gt;</comment>
                            <comment id="13751824" author="hudson" created="Tue, 27 Aug 2013 22:42:55 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #73 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/73/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/73/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5144&quot; title=&quot;HashTableSink allocates empty new Object[] arrays &amp;amp; OOMs - use a static emptyRow instead&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5144&quot;&gt;&lt;del&gt;HIVE-5144&lt;/del&gt;&lt;/a&gt; : HashTableSink allocates empty new Object[] arrays &amp;amp; OOMs - use a static emptyRow instead (Gopal V via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517877&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517877&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableSinkOperator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13752025" author="hudson" created="Wed, 28 Aug 2013 01:56:23 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #141 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/141/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/141/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5144&quot; title=&quot;HashTableSink allocates empty new Object[] arrays &amp;amp; OOMs - use a static emptyRow instead&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5144&quot;&gt;&lt;del&gt;HIVE-5144&lt;/del&gt;&lt;/a&gt; : HashTableSink allocates empty new Object[] arrays &amp;amp; OOMs - use a static emptyRow instead (Gopal V via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517877&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517877&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableSinkOperator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13752072" author="hudson" created="Wed, 28 Aug 2013 03:32:00 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hive-trunk-h0.21 #2294 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2294/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2294/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5144&quot; title=&quot;HashTableSink allocates empty new Object[] arrays &amp;amp; OOMs - use a static emptyRow instead&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5144&quot;&gt;&lt;del&gt;HIVE-5144&lt;/del&gt;&lt;/a&gt; : HashTableSink allocates empty new Object[] arrays &amp;amp; OOMs - use a static emptyRow instead (Gopal V via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517877&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517877&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableSinkOperator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13752349" author="hudson" created="Wed, 28 Aug 2013 12:42:19 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2 #386 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/386/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/386/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5144&quot; title=&quot;HashTableSink allocates empty new Object[] arrays &amp;amp; OOMs - use a static emptyRow instead&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5144&quot;&gt;&lt;del&gt;HIVE-5144&lt;/del&gt;&lt;/a&gt; : HashTableSink allocates empty new Object[] arrays &amp;amp; OOMs - use a static emptyRow instead (Gopal V via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517877&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517877&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableSinkOperator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13796081" author="ashutoshc" created="Tue, 15 Oct 2013 23:30:49 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12599661" name="HIVE-5144.01.patch" size="2363" author="gopalv" created="Fri, 23 Aug 2013 17:21:36 +0000"/>
                            <attachment id="12599958" name="HIVE-5144.02.patch" size="2362" author="gopalv" created="Mon, 26 Aug 2013 15:46:23 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 23 Aug 2013 18:31:34 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345204</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nj27:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345505</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Save memory in HashTableSink for key-only map-joins, by reusing a single EMPTY_ROW_CONTAINER object</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5145] Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5145</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;there is some determinism related to the output of list_bucket_query_multiskew_2.q test case. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12665352">HIVE-5145</key>
            <summary>Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="prasanth_j">Prasanth Jayachandran</assignee>
                                    <reporter username="prasanth_j">Prasanth Jayachandran</reporter>
                        <labels>
                    </labels>
                <created>Sat, 24 Aug 2013 00:37:23 +0000</created>
                <updated>Tue, 15 Oct 2013 23:28:58 +0000</updated>
                            <resolved>Mon, 26 Aug 2013 20:15:24 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Tests</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13749204" author="prasanth_j" created="Sat, 24 Aug 2013 00:40:05 +0000"  >&lt;p&gt;Added order by to the queries to get a deterministic output. Regenerated the golden file as well. &lt;/p&gt;

&lt;p&gt;Will mark patch as available to trigger the pre-commit tests.&lt;/p&gt;</comment>
                            <comment id="13749436" author="ashutoshc" created="Sat, 24 Aug 2013 18:12:00 +0000"  >&lt;p&gt;Since the test is run only on 23, I think regen&apos;ing the golden file suffices.&lt;/p&gt;</comment>
                            <comment id="13750264" author="prasanth_j" created="Mon, 26 Aug 2013 17:19:06 +0000"  >&lt;p&gt;Removed the order by from the previous patch and regenerated the golden file.&lt;/p&gt;</comment>
                            <comment id="13750302" author="ashutoshc" created="Mon, 26 Aug 2013 17:46:44 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13750498" author="ashutoshc" created="Mon, 26 Aug 2013 20:15:24 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Prasanth!&lt;/p&gt;</comment>
                            <comment id="13750599" author="prasanth_j" created="Mon, 26 Aug 2013 21:49:23 +0000"  >&lt;p&gt;I think this patch should also fail in Ubuntu (similar to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4750&quot; title=&quot;Fix TestCliDriver.list_bucket_dml_{6,7,8}.q on 0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4750&quot;&gt;&lt;del&gt;HIVE-4750&lt;/del&gt;&lt;/a&gt;) as the results are dependent on the order of subdirectories under a partition. Can you please revert the 2nd patch and apply the 1st patch since first patch has order by clause which makes the result consistent across OSes.&lt;/p&gt;</comment>
                            <comment id="13750734" author="hudson" created="Mon, 26 Aug 2013 23:28:18 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #139 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/139/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/139/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5145&quot; title=&quot;Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5145&quot;&gt;&lt;del&gt;HIVE-5145&lt;/del&gt;&lt;/a&gt; : Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23 (Prasanth J via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517682&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517682&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/list_bucket_query_multiskew_2.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13750890" author="hudson" created="Tue, 27 Aug 2013 02:05:36 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #71 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/71/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/71/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5145&quot; title=&quot;Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5145&quot;&gt;&lt;del&gt;HIVE-5145&lt;/del&gt;&lt;/a&gt; : Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23 (Prasanth J via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517682&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517682&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/list_bucket_query_multiskew_2.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13751066" author="hudson" created="Tue, 27 Aug 2013 08:01:40 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2 #384 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/384/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/384/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5145&quot; title=&quot;Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5145&quot;&gt;&lt;del&gt;HIVE-5145&lt;/del&gt;&lt;/a&gt; : Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23 (Prasanth J via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517682&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517682&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/list_bucket_query_multiskew_2.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13751192" author="hudson" created="Tue, 27 Aug 2013 11:33:49 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-h0.21 #2291 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2291/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2291/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5145&quot; title=&quot;Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5145&quot;&gt;&lt;del&gt;HIVE-5145&lt;/del&gt;&lt;/a&gt; : Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23 (Prasanth J via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517682&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517682&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/list_bucket_query_multiskew_2.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13751224" author="brocknoland" created="Tue, 27 Aug 2013 12:39:52 +0000"  >&lt;p&gt;I also think the order by is probably required for jdk7  &lt;/p&gt;</comment>
                            <comment id="13757127" author="ashutoshc" created="Tue, 3 Sep 2013 21:47:34 +0000"  >&lt;p&gt;I reverted .2 and applied first patch. Tested it on both MacOS and ubuntu. Passed on both OS, so committed that. Thanks, Prasanth! &lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt; I don&apos;t have jdk7, so couldn&apos;t get to test it there.&lt;/p&gt;</comment>
                            <comment id="13757777" author="hudson" created="Wed, 4 Sep 2013 13:52:47 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2 #403 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/403/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/403/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5145&quot; title=&quot;Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5145&quot;&gt;&lt;del&gt;HIVE-5145&lt;/del&gt;&lt;/a&gt; : Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23 (Prasanth J via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519862&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519862&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/list_bucket_query_multiskew_2.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/list_bucket_query_multiskew_2.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13757853" author="hudson" created="Wed, 4 Sep 2013 15:16:14 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #83 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/83/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/83/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5145&quot; title=&quot;Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5145&quot;&gt;&lt;del&gt;HIVE-5145&lt;/del&gt;&lt;/a&gt; : Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23 (Prasanth J via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519862&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519862&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/list_bucket_query_multiskew_2.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/list_bucket_query_multiskew_2.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13757956" author="hudson" created="Wed, 4 Sep 2013 17:03:16 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #150 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/150/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/150/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5145&quot; title=&quot;Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5145&quot;&gt;&lt;del&gt;HIVE-5145&lt;/del&gt;&lt;/a&gt; : Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23 (Prasanth J via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519862&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519862&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/list_bucket_query_multiskew_2.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/list_bucket_query_multiskew_2.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13758026" author="hudson" created="Wed, 4 Sep 2013 17:43:12 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hive-trunk-h0.21 #2309 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2309/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2309/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5145&quot; title=&quot;Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5145&quot;&gt;&lt;del&gt;HIVE-5145&lt;/del&gt;&lt;/a&gt; : Fix TestCliDriver.list_bucket_query_multiskew_2.q on hadoop 0.23 (Prasanth J via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519862&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519862&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/list_bucket_query_multiskew_2.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/list_bucket_query_multiskew_2.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13795832" author="ashutoshc" created="Tue, 15 Oct 2013 23:28:58 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12599978" name="HIVE-5145.2.patch" size="826" author="prasanth_j" created="Mon, 26 Aug 2013 17:18:06 +0000"/>
                            <attachment id="12599758" name="HIVE-5145.patch" size="19225" author="prasanth_j" created="Sat, 24 Aug 2013 00:38:42 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 24 Aug 2013 18:12:00 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345292</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1njlr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345593</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5146] FilterExprOrExpr changes the order of the rows</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5146</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;FilterExprOrExpr changes the order of the rows which might break some UDFs that assume an order in data.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665356">HIVE-5146</key>
            <summary>FilterExprOrExpr changes the order of the rows</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jnp">Jitendra Nath Pandey</assignee>
                                    <reporter username="jnp">Jitendra Nath Pandey</reporter>
                        <labels>
                    </labels>
                <created>Sat, 24 Aug 2013 01:48:13 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:12 +0000</updated>
                            <resolved>Tue, 27 Aug 2013 17:04:23 +0000</resolved>
                                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13749240" author="jnp" created="Sat, 24 Aug 2013 01:59:47 +0000"  >&lt;p&gt;Patch uploaded.&lt;/p&gt;</comment>
                            <comment id="13749810" author="jnp" created="Mon, 26 Aug 2013 03:00:53 +0000"  >&lt;p&gt;Updated patch with fixes in the tests. Some tests need to be fixed because of change in the order of rows. Also, due to the change in order, double computations return slightly different results. &lt;br/&gt;
 With this patch, the expected results match exactly with non-vector mode computation.&lt;/p&gt;</comment>
                            <comment id="13750248" author="anthony.murphy" created="Mon, 26 Aug 2013 17:08:13 +0000"  >&lt;p&gt;+1 these changes look good. Thanks Jitendra.&lt;/p&gt;</comment>
                            <comment id="13751448" author="ashutoshc" created="Tue, 27 Aug 2013 17:04:23 +0000"  >&lt;p&gt;Committed to branch. Thanks, Jitendra!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12660754">HIVE-4959</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12599774" name="HIVE-5146.1.patch" size="4698" author="jnp" created="Sat, 24 Aug 2013 01:59:47 +0000"/>
                            <attachment id="12599865" name="HIVE-5146.2.patch" size="25046" author="jnp" created="Mon, 26 Aug 2013 03:00:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 26 Aug 2013 17:08:13 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345296</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 21 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1njmn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345597</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5147] Newly added test TestSessionHooks is failing on trunk</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5147</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;This was recently added via &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4588&quot; title=&quot;Support session level hooks for HiveServer2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4588&quot;&gt;&lt;del&gt;HIVE-4588&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665406">HIVE-5147</key>
            <summary>Newly added test TestSessionHooks is failing on trunk</summary>
                <type id="6" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/requirement.png">Test</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis</assignee>
                                    <reporter username="ashutoshc">Ashutosh Chauhan</reporter>
                        <labels>
                    </labels>
                <created>Sun, 25 Aug 2013 07:59:46 +0000</created>
                <updated>Tue, 15 Oct 2013 23:29:58 +0000</updated>
                            <resolved>Tue, 27 Aug 2013 16:44:51 +0000</resolved>
                                    <version>0.12.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Tests</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13750010" author="navis" created="Mon, 26 Aug 2013 11:24:54 +0000"  >&lt;p&gt;Sorry, I&apos;ve committed wrong version of patch, which I&apos;ve modified. I&apos;ll rollback that.&lt;/p&gt;</comment>
                            <comment id="13750012" author="phabricator@reviews.facebook.net" created="Mon, 26 Aug 2013 11:28:53 +0000"  >&lt;p&gt;navis requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5147&quot; title=&quot;Newly added test TestSessionHooks is failing on trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5147&quot;&gt;&lt;del&gt;HIVE-5147&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Newly added test TestSessionHooks is failing on trunk&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5147&quot; title=&quot;Newly added test TestSessionHooks is failing on trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5147&quot;&gt;&lt;del&gt;HIVE-5147&lt;/del&gt;&lt;/a&gt; Newly added test TestSessionHooks is failing on trunk&lt;/p&gt;

&lt;p&gt;This was recently added via &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4588&quot; title=&quot;Support session level hooks for HiveServer2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4588&quot;&gt;&lt;del&gt;HIVE-4588&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12543&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12543&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  service/src/java/org/apache/hive/service/cli/session/HiveSessionHookContext.java&lt;br/&gt;
  service/src/java/org/apache/hive/service/cli/session/HiveSessionHookContextImpl.java&lt;br/&gt;
  service/src/java/org/apache/hive/service/cli/session/SessionManager.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/30087/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/30087/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13750115" author="phabricator@reviews.facebook.net" created="Mon, 26 Aug 2013 14:42:51 +0000"  >&lt;p&gt;ashutoshc has accepted the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5147&quot; title=&quot;Newly added test TestSessionHooks is failing on trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5147&quot;&gt;&lt;del&gt;HIVE-5147&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Newly added test TestSessionHooks is failing on trunk&quot;.&lt;/p&gt;

&lt;p&gt;  +1&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12543&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12543&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5147&quot; title=&quot;Newly added test TestSessionHooks is failing on trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5147&quot;&gt;&lt;del&gt;HIVE-5147&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;/p&gt;</comment>
                            <comment id="13751420" author="ashutoshc" created="Tue, 27 Aug 2013 16:44:51 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Navis!&lt;/p&gt;</comment>
                            <comment id="13751825" author="hudson" created="Tue, 27 Aug 2013 22:42:55 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #73 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/73/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/73/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5147&quot; title=&quot;Newly added test TestSessionHooks is failing on trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5147&quot;&gt;&lt;del&gt;HIVE-5147&lt;/del&gt;&lt;/a&gt; : Newly added test TestSessionHooks is failing on trunk (Navis via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517873&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517873&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/session/HiveSessionHookContext.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/session/HiveSessionHookContextImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/session/SessionManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13752026" author="hudson" created="Wed, 28 Aug 2013 01:56:23 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #141 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/141/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/141/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5147&quot; title=&quot;Newly added test TestSessionHooks is failing on trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5147&quot;&gt;&lt;del&gt;HIVE-5147&lt;/del&gt;&lt;/a&gt; : Newly added test TestSessionHooks is failing on trunk (Navis via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517873&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517873&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/session/HiveSessionHookContext.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/session/HiveSessionHookContextImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/session/SessionManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13752073" author="hudson" created="Wed, 28 Aug 2013 03:32:00 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hive-trunk-h0.21 #2294 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2294/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2294/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5147&quot; title=&quot;Newly added test TestSessionHooks is failing on trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5147&quot;&gt;&lt;del&gt;HIVE-5147&lt;/del&gt;&lt;/a&gt; : Newly added test TestSessionHooks is failing on trunk (Navis via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517873&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517873&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/session/HiveSessionHookContext.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/session/HiveSessionHookContextImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/session/SessionManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13752350" author="hudson" created="Wed, 28 Aug 2013 12:42:20 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2 #386 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/386/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/386/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5147&quot; title=&quot;Newly added test TestSessionHooks is failing on trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5147&quot;&gt;&lt;del&gt;HIVE-5147&lt;/del&gt;&lt;/a&gt; : Newly added test TestSessionHooks is failing on trunk (Navis via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517873&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1517873&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/session/HiveSessionHookContext.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/session/HiveSessionHookContextImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/session/SessionManager.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13795948" author="ashutoshc" created="Tue, 15 Oct 2013 23:29:58 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12599931" name="HIVE-5147.D12543.1.patch" size="2861" author="phabricator@reviews.facebook.net" created="Mon, 26 Aug 2013 11:28:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 26 Aug 2013 11:24:54 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345346</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1njxj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345647</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5148] Jam sessions w/ Tez</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5148</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Tez introduced a session api that let&apos;s you reuse certain resources during a session (AM, localized files, etc).&lt;/p&gt;

&lt;p&gt;Hive needs to tie these into hive sessions (for both CLI and HS2)&lt;/p&gt;

&lt;p&gt;NO PRECOMMIT TESTS (this is wip for the tez branch)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665434">HIVE-5148</key>
            <summary>Jam sessions w/ Tez</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hagleitn">Gunther Hagleitner</assignee>
                                    <reporter username="hagleitn">Gunther Hagleitner</reporter>
                        <labels>
                    </labels>
                <created>Sun, 25 Aug 2013 21:58:57 +0000</created>
                <updated>Mon, 23 Dec 2013 12:41:01 +0000</updated>
                            <resolved>Mon, 26 Aug 2013 20:37:27 +0000</resolved>
                                                    <fixVersion>tez-branch</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13750515" author="hagleitn" created="Mon, 26 Aug 2013 20:37:28 +0000"  >&lt;p&gt;committed to branch&lt;/p&gt;</comment>
                            <comment id="13855333" author="mauzhang" created="Mon, 23 Dec 2013 01:55:05 +0000"  >&lt;p&gt;It seems that I have to set &quot;hive.optimize.true&quot; to true otherwise I get an NPE when quitting hive CLI. That&apos;s because Hive SessionState doesn&apos;t check whether TezSessionState is NULL before closing it. &lt;/p&gt;</comment>
                            <comment id="13855603" author="hagleitn" created="Mon, 23 Dec 2013 12:41:01 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mauzhang&quot; class=&quot;user-hover&quot; rel=&quot;mauzhang&quot;&gt;Manu Zhang&lt;/a&gt;. I&apos;ve opened &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6097&quot; title=&quot;Sessions on Tez NPE when quitting CLI&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6097&quot;&gt;&lt;del&gt;HIVE-6097&lt;/del&gt;&lt;/a&gt;. I&apos;ve changed the session handling slightly recently and broke this.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12651047">HIVE-4660</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12686139">HIVE-6097</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12662284">TEZ-349</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12599852" name="HIVE-5148.1.patch" size="24266" author="hagleitn" created="Sun, 25 Aug 2013 22:02:24 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 23 Dec 2013 01:55:05 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345374</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 5 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nk3r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345675</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5149] ReduceSinkDeDuplication can pick the wrong partitioning columns</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5149</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://mail-archives.apache.org/mod_mbox/hive-user/201308.mbox/%3CCAG6Lhyex5XPwszpihKqkPRpzri2k=m4QGc+cpAR5yVR8SJtM4Q@mail.gmail.com%3E&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://mail-archives.apache.org/mod_mbox/hive-user/201308.mbox/%3CCAG6Lhyex5XPwszpihKqkPRpzri2k=m4QGc+cpAR5yVR8SJtM4Q@mail.gmail.com%3E&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665443">HIVE-5149</key>
            <summary>ReduceSinkDeDuplication can pick the wrong partitioning columns</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="yhuai">Yin Huai</assignee>
                                    <reporter username="yhuai">Yin Huai</reporter>
                        <labels>
                    </labels>
                <created>Mon, 26 Aug 2013 01:35:43 +0000</created>
                <updated>Tue, 15 Oct 2013 23:29:00 +0000</updated>
                            <resolved>Tue, 3 Sep 2013 19:34:18 +0000</resolved>
                                    <version>0.11.0</version>
                    <version>0.12.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13750551" author="pala" created="Mon, 26 Aug 2013 21:07:22 +0000"  >&lt;p&gt;Currently, there is a workaround to avoid this bug, by turning off all reduce deduplication optimization: hive.optimize.reducededuplication = false. However, that will affect other valid deduplications also, so the user has to be educated enough to turn it off selectively, or we turn it off globally in hive-site.xml, but give up performance in other cases.&lt;/p&gt;

&lt;p&gt;So, using this config is only a short term workaround.&lt;/p&gt;</comment>
                            <comment id="13750878" author="yhuai" created="Tue, 27 Aug 2013 01:59:19 +0000"  >&lt;p&gt;Suppose that we have a parent RS and a child RS. If the child RS can be removed, ReduceSinkDeDuplication always assigns the more specific partitioning columns to the parent RS. For example, if we have &quot;GROUP BY a, b DISTRIBUTE BY a&quot;, in the single MR job, the RS uses &quot;a&quot; and &quot;b&quot; as partitioning columns. Seems we need to change ReduceSinkDeDuplication to use the more general partitioning columns. I mean we need to use &quot;a&quot; as the partition column. This change can limit the parallelism of the reduce phase. &lt;/p&gt;</comment>
                            <comment id="13751502" author="yhuai" created="Tue, 27 Aug 2013 17:56:08 +0000"  >&lt;p&gt;Another example, in reduce_deduplicate_extended.q, there is &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-sql&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;explain&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;from&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;key&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;from&lt;/span&gt; src &lt;span class=&quot;code-keyword&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;key&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;value&lt;/span&gt;) s &lt;span class=&quot;code-keyword&quot;&gt;select&lt;/span&gt; s.&lt;span class=&quot;code-keyword&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;by&lt;/span&gt; s.&lt;span class=&quot;code-keyword&quot;&gt;key&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The plan is &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -&amp;gt; Map Operator Tree:
        s:src 
          TableScan
            alias: src
            Select Operator
              expressions:
                    expr: key
                    type: string
                    expr: value
                    type: string
              outputColumnNames: key, value
              Group By Operator
                bucketGroup: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
                keys:
                      expr: key
                      type: string
                      expr: value
                      type: string
                mode: hash
                outputColumnNames: _col0, _col1
                Reduce Output Operator
                  key expressions:
                        expr: _col0
                        type: string
                        expr: _col1
                        type: string
                  sort order: ++
                  Map-reduce partition columns:
                        expr: _col0
                        type: string
                        expr: _col1
                        type: string
                  tag: -1
      Reduce Operator Tree:
        Group By Operator
          bucketGroup: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
          keys:
                expr: KEY._col0
                type: string
                expr: KEY._col1
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Select Operator
            expressions:
                  expr: _col0
                  type: string
            outputColumnNames: _col0
            Group By Operator
              bucketGroup: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
              keys:
                    expr: _col0
                    type: string
              mode: complete
              outputColumnNames: _col0
              Select Operator
                expressions:
                      expr: _col0
                      type: string
                outputColumnNames: _col0
                File Output Operator
                  compressed: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
                  GlobalTableId: 0
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

  Stage: Stage-0
    Fetch Operator
      limit: -1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I think the plan is wrong. We should use key as the partitioning column to make sure all rows associated with the same key will be assigned to the same reducer.&lt;/p&gt;</comment>
                            <comment id="13751569" author="yhuai" created="Tue, 27 Aug 2013 18:44:22 +0000"  >&lt;p&gt;Add link to review board&lt;/p&gt;</comment>
                            <comment id="13754042" author="ashutoshc" created="Thu, 29 Aug 2013 20:55:25 +0000"  >&lt;p&gt;Thanks, Yin for working on this! Can you add a test case which exposes this bug. If I am reading it right, following query will expose it:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;SELECT key, COUNT( * )
FROM
(
SELECT key, value, COUNT( * )
FROM src
GROUP BY key, value
) a
GROUP BY key;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13754076" author="yhuai" created="Thu, 29 Aug 2013 21:24:28 +0000"  >&lt;p&gt;Right, we should only use key as the partitioning column.&lt;/p&gt;

&lt;p&gt;Actually, the example I posted above is from test file &quot;reduce_deduplicate_extended.q&quot;. The plan of &quot;explain from (select key, value from src group by key, value) s select s.key group by s.key&quot; in hive trunk is wrong. &lt;/p&gt;</comment>
                            <comment id="13754165" author="ashutoshc" created="Thu, 29 Aug 2013 22:57:51 +0000"  >&lt;p&gt;Ah.. right! I missed that. I will take a look at the patch!&lt;/p&gt;</comment>
                            <comment id="13755911" author="ashutoshc" created="Mon, 2 Sep 2013 05:32:32 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yhuai&quot; class=&quot;user-hover&quot; rel=&quot;yhuai&quot;&gt;Yin Huai&lt;/a&gt; Thanks for adding comments. I think we should throw an exception in case pRS partitioning cols are more specific but cRS partitioning cols are null or empty. That seems to me like an error condition. I left comment for it on RB.&lt;br/&gt;
Other than that, looks good.&lt;/p&gt;</comment>
                            <comment id="13755914" author="ashutoshc" created="Mon, 2 Sep 2013 05:40:23 +0000"  >&lt;p&gt;Also another sanity check is good to put in, so we dont set sort order if sort columns are not set.&lt;/p&gt;</comment>
                            <comment id="13756286" author="yhuai" created="Tue, 3 Sep 2013 00:29:33 +0000"  >&lt;p&gt;addressed Ashutosh&apos;s comments&lt;/p&gt;</comment>
                            <comment id="13756289" author="hiveqa" created="Tue, 3 Sep 2013 00:48:13 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12601093/HIVE-5149.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12601093/HIVE-5149.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/589/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/589/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/589/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/589/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-589/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
++ egrep -v &apos;^X|^Performing status on external&apos;
++ awk &apos;{print $2}&apos;
++ svn status --no-ignore
+ rm -rf build hcatalog/build hcatalog/core/build common/src/gen
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1519534.

At revision 1519534.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/ReduceSinkDeDuplication.java
patching file ql/src/test/results/clientpositive/groupby2_map_skew.q.out
patching file ql/src/test/results/clientpositive/groupby_cube1.q.out
patching file ql/src/test/results/clientpositive/groupby_rollup1.q.out
patching file ql/src/test/results/clientpositive/reduce_deduplicate_extended.q.out
+ [[ true == \t\r\u\e ]]
+ rm -rf /data/hive-ptest/working/ivy /data/hive-ptest/working/maven
+ mkdir /data/hive-ptest/working/ivy /data/hive-ptest/working/maven
+ ant -Dtest.continue.on.failure=true -Dtest.silent=false -Divy.default.ivy.user.dir=/data/hive-ptest/working/ivy -Dmvn.local.repo=/data/hive-ptest/working/maven clean package test -Dtestcase=nothing
Buildfile: /data/hive-ptest/working/apache-svn-trunk-source/build.xml

clean:
     [echo] Project: hive

clean:
     [echo] Project: anttasks

clean:
     [echo] Project: shims

clean:
     [echo] Project: common

clean:
     [echo] Project: serde

clean:
     [echo] Project: metastore

clean:
     [echo] Project: ql

clean:
     [echo] Project: contrib

clean:
     [echo] Project: service

clean:
     [echo] Project: cli

clean:
     [echo] Project: jdbc

clean:
     [echo] Project: beeline

clean:
     [echo] Project: hwi

clean:
     [echo] Project: hbase-handler

clean:
     [echo] Project: testutils

clean:
     [echo] hcatalog

clean:
     [echo] hcatalog-core

clean:
     [echo] hcatalog-pig-adapter

clean:
     [echo] hcatalog-server-extensions

clean:
     [echo] webhcat

clean:
     [echo] webhcat-java-client

clean:

clean:
     [echo] Project: odbc
     [exec] rm -rf /data/hive-ptest/working/apache-svn-trunk-source/build/odbc /data/hive-ptest/working/apache-svn-trunk-source/build/service/objs /data/hive-ptest/working/apache-svn-trunk-source/build/ql/objs /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/objs

clean-online:
     [echo] Project: hive

clean-offline:

ivy-init-dirs:
     [echo] Project: hive
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/maven

ivy-download:
     [echo] Project: hive
      [get] Getting: http://repo2.maven.org/maven2/org/apache/ivy/ivy/2.3.0/ivy-2.3.0.jar
      [get] To: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/ivy-2.3.0.jar

ivy-probe-antlib:
     [echo] Project: hive

ivy-init-antlib:
     [echo] Project: hive

compile-ant-tasks:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jexl/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

ivy-init-settings:
     [echo] Project: anttasks

ivy-resolve:
     [echo] Project: anttasks
[ivy:resolve] :: Apache Ivy 2.3.0 - 20130110142753 :: http://ant.apache.org/ivy/ ::
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-anttasks;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found velocity#velocity;1.5 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-lang/commons-lang/2.4/commons-lang-2.4.jar ...
[ivy:resolve] ..... (255kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-lang#commons-lang;2.4!commons-lang.jar (30ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/velocity/velocity/1.5/velocity-1.5.jar ...
[ivy:resolve] ....... (382kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] velocity#velocity;1.5!velocity.jar (26ms)
[ivy:resolve] :: resolution report :: resolve 4811ms :: artifacts dl 76ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-anttasks-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-anttasks-default.html

ivy-retrieve:
     [echo] Project: anttasks
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-anttasks
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	2 artifacts copied, 0 already retrieved (638kB/7ms)

compile:
     [echo] anttasks
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ant/build.xml:38: warning: &apos;includeantruntime&apos; was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds
    [javac] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.

deploy-ant-tasks:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

ivy-init-settings:
     [echo] Project: anttasks

ivy-resolve:
     [echo] Project: anttasks
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-anttasks;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found velocity#velocity;1.5 in maven2
[ivy:resolve] :: resolution report :: resolve 484ms :: artifacts dl 2ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-anttasks-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-anttasks-default.html

ivy-retrieve:
     [echo] Project: anttasks
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-anttasks
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	0 artifacts copied, 2 already retrieved (0kB/7ms)

compile:
     [echo] anttasks
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ant/build.xml:38: warning: &apos;includeantruntime&apos; was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds

jar:
     [echo] anttasks
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes/org/apache/hadoop/hive/ant
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/hive-anttasks-0.12.0-SNAPSHOT.jar

init:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

create-dirs:
     [echo] Project: shims
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/test/resources does not exist.

init:
     [echo] Project: shims

create-dirs:
     [echo] Project: common
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/resources
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/resources

init:
     [echo] Project: common

create-dirs:
     [echo] Project: serde
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources does not exist.

init:
     [echo] Project: serde

create-dirs:
     [echo] Project: metastore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources does not exist.

init:
     [echo] Project: metastore

create-dirs:
     [echo] Project: ql
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/resources
     [copy] Copying 3 files to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/resources

init:
     [echo] Project: ql

create-dirs:
     [echo] Project: contrib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources does not exist.

init:
     [echo] Project: contrib

create-dirs:
     [echo] Project: service
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources does not exist.

init:
     [echo] Project: service

create-dirs:
     [echo] Project: cli
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/resources does not exist.

init:
     [echo] Project: cli

create-dirs:
     [echo] Project: jdbc
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/test/resources does not exist.

init:
     [echo] Project: jdbc

create-dirs:
     [echo] Project: beeline
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/test/resources does not exist.

init:
     [echo] Project: beeline

create-dirs:
     [echo] Project: hwi
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources does not exist.

init:
     [echo] Project: hwi

create-dirs:
     [echo] Project: hbase-handler
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources does not exist.

init:
     [echo] Project: hbase-handler

create-dirs:
     [echo] Project: testutils
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources does not exist.

init:
     [echo] Project: testutils

init:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build/hcatalog-0.12.0-SNAPSHOT

jar:
     [echo] Project: hive

ivy-init-settings:
     [echo] Project: shims

check-ivy:
     [echo] Project: shims

ivy-resolve:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.zookeeper#zookeeper;3.4.3 in maven2
[ivy:resolve] 	found org.apache.thrift#libthrift;0.9.0 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.4 in maven2
[ivy:resolve] 	found commons-logging#commons-logging-api;1.0.4 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.4 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar ...
[ivy:resolve] .............. (749kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.3!zookeeper.jar (37ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar ...
[ivy:resolve] ....... (339kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.thrift#libthrift;0.9.0!libthrift.jar (21ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging/1.0.4/commons-logging-1.0.4.jar ...
[ivy:resolve] .. (37kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-logging#commons-logging;1.0.4!commons-logging.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging-api/1.0.4/commons-logging-api-1.0.4.jar ...
[ivy:resolve] .. (25kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-logging#commons-logging-api;1.0.4!commons-logging-api.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar ...
[ivy:resolve] ..... (222kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-core-asl;1.8.8!jackson-core-asl.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar ...
[ivy:resolve] ............ (652kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-mapper-asl;1.8.8!jackson-mapper-asl.jar (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/log4j/log4j/1.2.16/log4j-1.2.16.jar ...
[ivy:resolve] ......... (470kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] log4j#log4j;1.2.16!log4j.jar(bundle) (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/guava/guava/11.0.2/guava-11.0.2.jar ...
[ivy:resolve] ............................ (1609kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.guava#guava;11.0.2!guava.jar (38ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-io/commons-io/2.4/commons-io-2.4.jar ...
[ivy:resolve] .... (180kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-io#commons-io;2.4!commons-io.jar (9ms)
[ivy:resolve] :: resolution report :: resolve 8618ms :: artifacts dl 213ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   9   |   9   |   0   ||   9   |   9   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-shims-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-shims-default.html

make-pom:
     [echo] Project: shims
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: shims
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/test/resources does not exist.

init:
     [echo] Project: shims

ivy-retrieve:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	9 artifacts copied, 0 already retrieved (4287kB/19ms)

compile:
     [echo] Project: shims
     [echo] Building shims 0.20

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20/java against hadoop 0.20.2 (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-0.20.2)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.20.shim]
[ivy:resolve] 	found org.apache.hadoop#hadoop-core;0.20.2 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.0.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.3 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.3 in maven2
[ivy:resolve] 	found commons-net#commons-net;1.4.1 in maven2
[ivy:resolve] 	found oro#oro;2.0.8 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api-2.5;6.1.14 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.12 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.12 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-api-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.eclipse.jdt#core;3.1.1 in maven2
[ivy:resolve] 	found ant#ant;1.6.5 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.7.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found net.sf.kosmosfs#kfs;0.3 in maven2
[ivy:resolve] 	found junit#junit;4.5 in maven2
[ivy:resolve] 	found hsqldb#hsqldb;1.8.0.10 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-tools;0.20.2 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-test;0.20.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftplet-api;1.0.0 in maven2
[ivy:resolve] 	found org.apache.mina#mina-core;2.0.0-M5 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.5.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-core;1.0.0 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-core/0.20.2/hadoop-core-0.20.2.jar ...
[ivy:resolve] ............................................ (2624kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-core;0.20.2!hadoop-core.jar (51ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-tools/0.20.2/hadoop-tools-0.20.2.jar ...
[ivy:resolve] ... (68kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-tools;0.20.2!hadoop-tools.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-test/0.20.2/hadoop-test-0.20.2.jar ...
[ivy:resolve] .......................... (1527kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-test;0.20.2!hadoop-test.jar (32ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-cli/commons-cli/1.2/commons-cli-1.2.jar ...
[ivy:resolve] .. (40kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-cli#commons-cli;1.2!commons-cli.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/xmlenc/xmlenc/0.52/xmlenc-0.52.jar ...
[ivy:resolve] .. (14kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] xmlenc#xmlenc;0.52!xmlenc.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar ...
[ivy:resolve] ...... (273kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-httpclient#commons-httpclient;3.0.1!commons-httpclient.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-codec/commons-codec/1.3/commons-codec-1.3.jar ...
[ivy:resolve] .. (45kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-codec#commons-codec;1.3!commons-codec.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar ...
[ivy:resolve] .... (176kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-net#commons-net;1.4.1!commons-net.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty/6.1.14/jetty-6.1.14.jar ...
[ivy:resolve] ......... (504kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty;6.1.14!jetty.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.14/jetty-util-6.1.14.jar ...
[ivy:resolve] .... (159kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty-util;6.1.14!jetty-util.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar ...
[ivy:resolve] ... (74kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-runtime;5.5.12!jasper-runtime.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar ...
[ivy:resolve] ........ (395kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-compiler;5.5.12!jasper-compiler.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar ...
[ivy:resolve] .... (131kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jsp-api-2.1;6.1.14!jsp-api-2.1.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar ...
[ivy:resolve] .................. (1000kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jsp-2.1;6.1.14!jsp-2.1.jar (27ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-el/commons-el/1.0/commons-el-1.0.jar ...
[ivy:resolve] ... (109kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-el#commons-el;1.0!commons-el.jar (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar ...
[ivy:resolve] ....... (368kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.java.dev.jets3t#jets3t;0.7.1!jets3t.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar ...
[ivy:resolve] .... (129kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#servlet-api-2.5;6.1.14!servlet-api-2.5.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar ...
[ivy:resolve] .. (11kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.sf.kosmosfs#kfs;0.3!kfs.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/4.5/junit-4.5.jar ...
[ivy:resolve] ..... (194kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] junit#junit;4.5!junit.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar ...
[ivy:resolve] ............ (690kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] hsqldb#hsqldb;1.8.0.10!hsqldb.jar (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/oro/oro/2.0.8/oro-2.0.8.jar ...
[ivy:resolve] .. (63kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] oro#oro;2.0.8!oro.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar ...
[ivy:resolve] ........................................................................................... (3483kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.eclipse.jdt#core;3.1.1!core.jar (70ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/ant/ant/1.6.5/ant-1.6.5.jar ...
[ivy:resolve] ................. (1009kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] ant#ant;1.6.5!ant.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar ...
[ivy:resolve] .. (59kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-logging#commons-logging;1.1.1!commons-logging.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftplet-api/1.0.0/ftplet-api-1.0.0.jar ...
[ivy:resolve] .. (22kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftplet-api;1.0.0!ftplet-api.jar(bundle) (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/mina/mina-core/2.0.0-M5/mina-core-2.0.0-M5.jar ...
[ivy:resolve] ............ (622kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.mina#mina-core;2.0.0-M5!mina-core.jar(bundle) (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftpserver-core/1.0.0/ftpserver-core-1.0.0.jar ...
[ivy:resolve] ...... (264kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftpserver-core;1.0.0!ftpserver-core.jar(bundle) (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftpserver-deprecated/1.0.0-M2/ftpserver-deprecated-1.0.0-M2.jar ...
[ivy:resolve] .. (31kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2!ftpserver-deprecated.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.5.2/slf4j-api-1.5.2.jar ...
[ivy:resolve] .. (16kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-api;1.5.2!slf4j-api.jar (7ms)
[ivy:resolve] :: resolution report :: resolve 33953ms :: artifacts dl 529ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	junit#junit;3.8.1 by [junit#junit;4.5] in [hadoop0.20.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.0.3 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20.shim]
[ivy:resolve] 	commons-codec#commons-codec;1.2 by [commons-codec#commons-codec;1.3] in [hadoop0.20.shim]
[ivy:resolve] 	commons-httpclient#commons-httpclient;3.1 by [commons-httpclient#commons-httpclient;3.0.1] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M4 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.ftpserver#ftplet-api;1.0.0-M2 by [org.apache.ftpserver#ftplet-api;1.0.0] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.ftpserver#ftpserver-core;1.0.0-M2 by [org.apache.ftpserver#ftpserver-core;1.0.0] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M2 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20.shim]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|  hadoop0.20.shim |   37  |   30  |   30  |   8   ||   29  |   29  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.20.shim]
[ivy:retrieve] 	29 artifacts copied, 0 already retrieved (14115kB/96ms)
    [javac] Compiling 17 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [echo] Building shims 0.20S

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/common-secure/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20S/java against hadoop 1.1.2 (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-1.1.2)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.20S.shim]
[ivy:resolve] 	found org.apache.hadoop#hadoop-core;1.1.2 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-core;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-json;1.8 in maven2
[ivy:resolve] 	found org.codehaus.jettison#jettison;1.1 in maven2
[ivy:resolve] 	found stax#stax-api;1.0.1 in maven2
[ivy:resolve] 	found com.sun.xml.bind#jaxb-impl;2.2.3-1 in maven2
[ivy:resolve] 	found javax.xml.bind#jaxb-api;2.2.2 in maven2
[ivy:resolve] 	found javax.xml.stream#stax-api;1.0-2 in maven2
[ivy:resolve] 	found javax.activation#activation;1.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-jaxrs;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-xc;1.7.1 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-server;1.8 in maven2
[ivy:resolve] 	found asm#asm;3.1 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.1 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.0.1 in maven2
[ivy:resolve] 	found junit#junit;3.8.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.3 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.commons#commons-math;2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found commons-digester#commons-digester;1.8 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils;1.7.0 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils-core;1.8.0 in maven2
[ivy:resolve] 	found commons-net#commons-net;1.4.1 in maven2
[ivy:resolve] 	found oro#oro;2.0.8 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api;2.5-20081211 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.12 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.12 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-api-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api-2.5;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.eclipse.jdt#core;3.1.1 in maven2
[ivy:resolve] 	found ant#ant;1.6.5 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.6.1 in maven2
[ivy:resolve] 	found hsqldb#hsqldb;1.8.0.10 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-tools;1.1.2 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-test;1.1.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftplet-api;1.0.0 in maven2
[ivy:resolve] 	found org.apache.mina#mina-core;2.0.0-M5 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.5.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-core;1.0.0 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-core/1.1.2/hadoop-core-1.1.2.jar ...
[ivy:resolve] ................................................................................................. (3941kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-core;1.1.2!hadoop-core.jar (80ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-tools/1.1.2/hadoop-tools-1.1.2.jar ...
[ivy:resolve] ...... (299kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-tools;1.1.2!hadoop-tools.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-test/1.1.2/hadoop-test-1.1.2.jar ...
[ivy:resolve] ................................................................. (2712kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-test;1.1.2!hadoop-test.jar (56ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar ...
[ivy:resolve] ........ (447kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-core;1.8!jersey-core.jar(bundle) (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar ...
[ivy:resolve] .... (144kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-json;1.8!jersey-json.jar(bundle) (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar ...
[ivy:resolve] ............. (678kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-server;1.8!jersey-server.jar(bundle) (18ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-io/commons-io/2.1/commons-io-2.1.jar ...
[ivy:resolve] .... (159kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-io#commons-io;2.1!commons-io.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-codec/commons-codec/1.4/commons-codec-1.4.jar ...
[ivy:resolve] .. (56kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-codec#commons-codec;1.4!commons-codec.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-math/2.1/commons-math-2.1.jar ...
[ivy:resolve] ............... (812kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.commons#commons-math;2.1!commons-math.jar (20ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar ...
[ivy:resolve] ...... (291kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-configuration#commons-configuration;1.6!commons-configuration.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar ...
[ivy:resolve] .......... (527kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty;6.1.26!jetty.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar ...
[ivy:resolve] .... (172kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty-util;6.1.26!jetty-util.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar ...
[ivy:resolve] ...... (314kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.java.dev.jets3t#jets3t;0.6.1!jets3t.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar ...
[ivy:resolve] ... (66kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jettison#jettison;1.1!jettison.jar(bundle) (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar ...
[ivy:resolve] ............... (869kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.xml.bind#jaxb-impl;2.2.3-1!jaxb-impl.jar (20ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.7.1/jackson-jaxrs-1.7.1.jar ...
[ivy:resolve] .. (17kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-jaxrs;1.7.1!jackson-jaxrs.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar ...
[ivy:resolve] .. (30kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-xc;1.7.1!jackson-xc.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/stax/stax-api/1.0.1/stax-api-1.0.1.jar ...
[ivy:resolve] .. (25kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] stax#stax-api;1.0.1!stax-api.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar ...
[ivy:resolve] ... (102kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.xml.bind#jaxb-api;2.2.2!jaxb-api.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar ...
[ivy:resolve] .. (22kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.xml.stream#stax-api;1.0-2!stax-api.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/activation/activation/1.1/activation-1.1.jar ...
[ivy:resolve] .. (61kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.activation#activation;1.1!activation.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/asm/asm/3.1/asm-3.1.jar ...
[ivy:resolve] .. (42kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] asm#asm;3.1!asm.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/3.8.1/junit-3.8.1.jar ...
[ivy:resolve] ... (118kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] junit#junit;3.8.1!junit.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar ...
[ivy:resolve] .......... (561kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-collections#commons-collections;3.2.1!commons-collections.jar (33ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-digester/commons-digester/1.8/commons-digester-1.8.jar ...
[ivy:resolve] .... (140kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-digester#commons-digester;1.8!commons-digester.jar (18ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar ...
[ivy:resolve] ..... (201kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-beanutils#commons-beanutils-core;1.8.0!commons-beanutils-core.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar ...
[ivy:resolve] .... (184kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-beanutils#commons-beanutils;1.7.0!commons-beanutils.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar ...
[ivy:resolve] .... (130kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#servlet-api;2.5-20081211!servlet-api.jar (7ms)
[ivy:resolve] :: resolution report :: resolve 31530ms :: artifacts dl 529ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	org.codehaus.jackson#jackson-core-asl;1.7.1 by [org.codehaus.jackson#jackson-core-asl;1.8.8] in [hadoop0.20S.shim]
[ivy:resolve] 	org.codehaus.jackson#jackson-mapper-asl;1.7.1 by [org.codehaus.jackson#jackson-mapper-asl;1.8.8] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.0.3 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-codec#commons-codec;1.2 by [commons-codec#commons-codec;1.4] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.1 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-codec#commons-codec;1.3 by [commons-codec#commons-codec;1.4] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-httpclient#commons-httpclient;3.1 by [commons-httpclient#commons-httpclient;3.0.1] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M4 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.ftpserver#ftplet-api;1.0.0-M2 by [org.apache.ftpserver#ftplet-api;1.0.0] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.ftpserver#ftpserver-core;1.0.0-M2 by [org.apache.ftpserver#ftpserver-core;1.0.0] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M2 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20S.shim]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	| hadoop0.20S.shim |   62  |   30  |   30  |   11  ||   51  |   28  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.20S.shim]
[ivy:retrieve] 	51 artifacts copied, 0 already retrieved (22876kB/77ms)
    [javac] Compiling 15 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [echo] Building shims 0.23

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/common-secure/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.23/java against hadoop 2.0.5-alpha (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-2.0.5-alpha)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.23.shim]
[ivy:resolve] 	found org.apache.hadoop#hadoop-common;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-annotations;2.0.5-alpha in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-math;2.1 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.1 in maven2
[ivy:resolve] 	found commons-net#commons-net;3.1 in maven2
[ivy:resolve] 	found javax.servlet#servlet-api;2.5 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.26 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-core;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-json;1.8 in maven2
[ivy:resolve] 	found org.codehaus.jettison#jettison;1.1 in maven2
[ivy:resolve] 	found stax#stax-api;1.0.1 in maven2
[ivy:resolve] 	found com.sun.xml.bind#jaxb-impl;2.2.3-1 in maven2
[ivy:resolve] 	found javax.xml.bind#jaxb-api;2.2.2 in maven2
[ivy:resolve] 	found javax.activation#activation;1.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-jaxrs;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-xc;1.8.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-server;1.8 in maven2
[ivy:resolve] 	found asm#asm;3.2 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.17 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.6.1 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.5 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-digester#commons-digester;1.8 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils;1.7.0 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils-core;1.8.0 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.5.3 in maven2
[ivy:resolve] 	found com.thoughtworks.paranamer#paranamer;2.3 in maven2
[ivy:resolve] 	found org.xerial.snappy#snappy-java;1.0.3.2 in maven2
[ivy:resolve] 	found net.sf.kosmosfs#kfs;0.3 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.0a in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-auth;2.0.5-alpha in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found com.jcraft#jsch;0.1.42 in maven2
[ivy:resolve] 	found org.apache.zookeeper#zookeeper;3.4.2 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.23 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.23 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found javax.servlet.jsp#jsp-api;2.1 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-core;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-common;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-api;2.0.5-alpha in maven2
[ivy:resolve] 	found com.google.inject.extensions#guice-servlet;3.0 in maven2
[ivy:resolve] 	found com.google.inject#guice;3.0 in maven2
[ivy:resolve] 	found javax.inject#javax.inject;1 in maven2
[ivy:resolve] 	found aopalliance#aopalliance;1.0 in maven2
[ivy:resolve] 	found org.sonatype.sisu.inject#cglib;2.2.1-v20090111 in maven2
[ivy:resolve] 	found io.netty#netty;3.5.11.Final in maven2
[ivy:resolve] 	found com.sun.jersey.jersey-test-framework#jersey-test-framework-grizzly2;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey.contribs#jersey-guice;1.8 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-archives;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-hdfs;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-common;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-client;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-common;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-tests;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-nodemanager;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-resourcemanager;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-web-proxy;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-app;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-hs;2.0.5-alpha in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.0.5-alpha/hadoop-common-2.0.5-alpha.jar ...
[ivy:resolve] ........................................ (2295kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-common;2.0.5-alpha!hadoop-common.jar (47ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.0.5-alpha/hadoop-common-2.0.5-alpha-tests.jar ...
[ivy:resolve] .................... (1151kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-common;2.0.5-alpha!hadoop-common.jar(tests) (26ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-core/2.0.5-alpha/hadoop-mapreduce-client-core-2.0.5-alpha.jar ...
[ivy:resolve] ....................... (1325kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-core;2.0.5-alpha!hadoop-mapreduce-client-core.jar (28ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-archives/2.0.5-alpha/hadoop-archives-2.0.5-alpha.jar ...
[ivy:resolve] .. (20kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-archives;2.0.5-alpha!hadoop-archives.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.0.5-alpha/hadoop-hdfs-2.0.5-alpha.jar ...
[ivy:resolve] ................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. (4241kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs;2.0.5-alpha!hadoop-hdfs.jar (360ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.0.5-alpha/hadoop-hdfs-2.0.5-alpha-tests.jar ...
[ivy:resolve] ........................... (1631kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs;2.0.5-alpha!hadoop-hdfs.jar(tests) (36ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.0.5-alpha/hadoop-mapreduce-client-jobclient-2.0.5-alpha-tests.jar ...
[ivy:resolve] ....................... (1350kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.0.5-alpha!hadoop-mapreduce-client-jobclient.jar(tests) (29ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.0.5-alpha/hadoop-mapreduce-client-jobclient-2.0.5-alpha.jar ...
[ivy:resolve] .. (32kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.0.5-alpha!hadoop-mapreduce-client-jobclient.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-common/2.0.5-alpha/hadoop-mapreduce-client-common-2.0.5-alpha.jar ...
[ivy:resolve] ........... (579kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-common;2.0.5-alpha!hadoop-mapreduce-client-common.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-tests/2.0.5-alpha/hadoop-yarn-server-tests-2.0.5-alpha-tests.jar ...
[ivy:resolve] .. (39kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-tests;2.0.5-alpha!hadoop-yarn-server-tests.jar(tests) (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-app/2.0.5-alpha/hadoop-mapreduce-client-app-2.0.5-alpha.jar ...
[ivy:resolve] ......... (463kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-app;2.0.5-alpha!hadoop-mapreduce-client-app.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-hs/2.0.5-alpha/hadoop-mapreduce-client-hs-2.0.5-alpha.jar ...
[ivy:resolve] ... (111kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-hs;2.0.5-alpha!hadoop-mapreduce-client-hs.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-annotations/2.0.5-alpha/hadoop-annotations-2.0.5-alpha.jar ...
[ivy:resolve] .. (16kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-annotations;2.0.5-alpha!hadoop-annotations.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar ...
[ivy:resolve] ...... (297kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-httpclient#commons-httpclient;3.1!commons-httpclient.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-net/commons-net/3.1/commons-net-3.1.jar ...
[ivy:resolve] ...... (266kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-net#commons-net;3.1!commons-net.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar ...
[ivy:resolve] ... (102kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.servlet#servlet-api;2.5!servlet-api.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/log4j/log4j/1.2.17/log4j-1.2.17.jar ...
[ivy:resolve] ......... (478kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] log4j#log4j;1.2.17!log4j.jar(bundle) (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-lang/commons-lang/2.5/commons-lang-2.5.jar ...
[ivy:resolve] ...... (272kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-lang#commons-lang;2.5!commons-lang.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar ...
[ivy:resolve] .. (24kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-api;1.6.1!slf4j-api.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro/1.5.3/avro-1.5.3.jar ...
[ivy:resolve] ...... (257kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro;1.5.3!avro.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.4.0a/protobuf-java-2.4.0a.jar ...
[ivy:resolve] ........ (439kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.protobuf#protobuf-java;2.4.0a!protobuf-java.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-auth/2.0.5-alpha/hadoop-auth-2.0.5-alpha.jar ...
[ivy:resolve] .. (46kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-auth;2.0.5-alpha!hadoop-auth.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar ...
[ivy:resolve] .... (181kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.jcraft#jsch;0.1.42!jsch.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.2/zookeeper-3.4.2.jar ...
[ivy:resolve] ............. (746kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.2!zookeeper.jar (18ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar ...
[ivy:resolve] .. (32kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.code.findbugs#jsr305;1.3.9!jsr305.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.8.8/jackson-jaxrs-1.8.8.jar ...
[ivy:resolve] .. (17kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-jaxrs;1.8.8!jackson-jaxrs.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.8.8/jackson-xc-1.8.8.jar ...
[ivy:resolve] .. (31kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-xc;1.8.8!jackson-xc.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/asm/asm/3.2/asm-3.2.jar ...
[ivy:resolve] .. (42kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] asm#asm;3.2!asm.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar ...
[ivy:resolve] .. (28kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.3!paranamer.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.0.3.2/snappy-java-1.0.3.2.jar ...
[ivy:resolve] .................. (972kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.0.3.2!snappy-java.jar(bundle) (22ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar ...
[ivy:resolve] .. (9kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-log4j12;1.6.1!slf4j-log4j12.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar ...
[ivy:resolve] ........ (398kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-compiler;5.5.23!jasper-compiler.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar ...
[ivy:resolve] ... (75kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-runtime;5.5.23!jasper-runtime.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar ...
[ivy:resolve] ... (98kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.servlet.jsp#jsp-api;2.1!jsp-api.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-common/2.0.5-alpha/hadoop-yarn-common-2.0.5-alpha.jar ...
[ivy:resolve] ................... (1050kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-common;2.0.5-alpha!hadoop-yarn-common.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar ...
[ivy:resolve] .. (63kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.inject.extensions#guice-servlet;3.0!guice-servlet.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/io/netty/netty/3.5.11.Final/netty-3.5.11.Final.jar ...
[ivy:resolve] ................... (1106kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] io.netty#netty;3.5.11.Final!netty.jar(bundle) (25ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-api/2.0.5-alpha/hadoop-yarn-api-2.0.5-alpha.jar ...
[ivy:resolve] .................. (1014kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-api;2.0.5-alpha!hadoop-yarn-api.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/inject/guice/3.0/guice-3.0.jar ...
[ivy:resolve] ............. (693kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.inject#guice;3.0!guice.jar (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-test-framework/jersey-test-framework-grizzly2/1.8/jersey-test-framework-grizzly2-1.8.jar ...
[ivy:resolve] .. (12kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey.jersey-test-framework#jersey-test-framework-grizzly2;1.8!jersey-test-framework-grizzly2.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/contribs/jersey-guice/1.8/jersey-guice-1.8.jar ...
[ivy:resolve] .. (14kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey.contribs#jersey-guice;1.8!jersey-guice.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/inject/javax.inject/1/javax.inject-1.jar ...
[ivy:resolve] .. (2kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.inject#javax.inject;1!javax.inject.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/aopalliance/aopalliance/1.0/aopalliance-1.0.jar ...
[ivy:resolve] .. (4kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] aopalliance#aopalliance;1.0!aopalliance.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/sonatype/sisu/inject/cglib/2.2.1-v20090111/cglib-2.2.1-v20090111.jar ...
[ivy:resolve] ...... (272kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.sonatype.sisu.inject#cglib;2.2.1-v20090111!cglib.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-client/2.0.5-alpha/hadoop-yarn-client-2.0.5-alpha.jar ...
[ivy:resolve] .. (28kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-client;2.0.5-alpha!hadoop-yarn-client.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-common/2.0.5-alpha/hadoop-yarn-server-common-2.0.5-alpha.jar ...
[ivy:resolve] .... (148kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-common;2.0.5-alpha!hadoop-yarn-server-common.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.0.5-alpha/hadoop-yarn-server-nodemanager-2.0.5-alpha.jar ...
[ivy:resolve] ........ (404kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-nodemanager;2.0.5-alpha!hadoop-yarn-server-nodemanager.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.0.5-alpha/hadoop-yarn-server-resourcemanager-2.0.5-alpha.jar ...
[ivy:resolve] .......... (517kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-resourcemanager;2.0.5-alpha!hadoop-yarn-server-resourcemanager.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.0.5-alpha/hadoop-yarn-server-web-proxy-2.0.5-alpha.jar ...
[ivy:resolve] .. (24kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-web-proxy;2.0.5-alpha!hadoop-yarn-server-web-proxy.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.0.5-alpha/hadoop-mapreduce-client-shuffle-2.0.5-alpha.jar ...
[ivy:resolve] .. (20kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.0.5-alpha!hadoop-mapreduce-client-shuffle.jar (6ms)
[ivy:resolve] :: resolution report :: resolve 65224ms :: artifacts dl 1082ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|  hadoop0.23.shim |   74  |   47  |   47  |   0   ||   77  |   50  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.23.shim]
[ivy:retrieve] 	77 artifacts copied, 0 already retrieved (31997kB/123ms)
    [javac] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.23/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.

jar:
     [echo] Project: shims
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-shims;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 20:43:58 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-shims
[ivy:publish] 	published hive-shims to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.12.0-SNAPSHOT/jars/hive-shims.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: common

check-ivy:
     [echo] Project: common

ivy-resolve:
     [echo] Project: common
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-common;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.12.0-SNAPSHOT/jars/hive-shims.jar ...
[ivy:resolve] .... (140kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-shims;0.12.0-SNAPSHOT!hive-shims.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar ...
[ivy:resolve] ..... (235kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.commons#commons-compress;1.4.1!commons-compress.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/tukaani/xz/1.0/xz-1.0.jar ...
[ivy:resolve] ... (92kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.tukaani#xz;1.0!xz.jar (7ms)
[ivy:resolve] :: resolution report :: resolve 2095ms :: artifacts dl 30ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   6   |   3   |   3   |   0   ||   6   |   3   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-common-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-common-default.html

make-pom:
     [echo] Project: common
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/common/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: common

init:
     [echo] Project: common

setup:
     [echo] Project: common

ivy-retrieve:
     [echo] Project: common
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-common
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	4 artifacts copied, 2 already retrieved (508kB/5ms)

compile:
     [echo] Project: common
    [javac] Compiling 25 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/common/src/java/org/apache/hadoop/hive/common/ObjectPair.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes

jar:
     [echo] Project: common
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/common/hive-common-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-common;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 20:44:03 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/common/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-common
[ivy:publish] 	published hive-common to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.12.0-SNAPSHOT/jars/hive-common.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: serde

check-ivy:
     [echo] Project: serde

ivy-resolve:
     [echo] Project: serde
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-serde;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.12.0-SNAPSHOT/jars/hive-common.jar ...
[ivy:resolve] ... (95kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-common;0.12.0-SNAPSHOT!hive-common.jar (4ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar ...
[ivy:resolve] ...................... (1315kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mockito#mockito-all;1.8.2!mockito-all.jar (27ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar ...
[ivy:resolve] ...... (268kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.thrift#libfb303;0.9.0!libfb303.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro/1.7.1/avro-1.7.1.jar ...
[ivy:resolve] ...... (290kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro;1.7.1!avro.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar ...
[ivy:resolve] .... (164kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro-mapred;1.7.1!avro-mapred.jar (8ms)
[ivy:resolve] :: resolution report :: resolve 6250ms :: artifacts dl 70ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   14  |   5   |   5   |   0   ||   14  |   5   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-serde-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-serde-default.html

make-pom:
     [echo] Project: serde
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: serde
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources does not exist.

init:
     [echo] Project: serde

ivy-retrieve:
     [echo] Project: serde
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-serde
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	8 artifacts copied, 6 already retrieved (2227kB/24ms)

dynamic-serde:

compile:
     [echo] Project: serde
    [javac] Compiling 325 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes/org/apache/hadoop/hive/serde2/typeinfo/package-info.class

jar:
     [echo] Project: serde
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/hive-serde-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-serde;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 20:44:22 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-serde
[ivy:publish] 	published hive-serde to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.12.0-SNAPSHOT/jars/hive-serde.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: metastore

check-ivy:
     [echo] Project: metastore

ivy-resolve:
     [echo] Project: metastore
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-metastore;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.12.0-SNAPSHOT/jars/hive-serde.jar ...
[ivy:resolve] ............ (662kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-serde;0.12.0-SNAPSHOT!hive-serde.jar (21ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/antlr/3.4/antlr-3.4.jar ...
[ivy:resolve] .................. (1086kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.antlr#antlr;3.4!antlr.jar (24ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar ...
[ivy:resolve] .... (160kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.antlr#antlr-runtime;3.4!antlr-runtime.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/ST4/4.0.4/ST4-4.0.4.jar ...
[ivy:resolve] ..... (231kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.antlr#ST4;4.0.4!ST4.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar ...
[ivy:resolve] ... (112kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.jolbox#bonecp;0.7.1.RELEASE!bonecp.jar(bundle) (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar ...
[ivy:resolve] ... (93kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-pool#commons-pool;1.5.4!commons-pool.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar ...
[ivy:resolve] ....... (329kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.datanucleus#datanucleus-api-jdo;3.2.1!datanucleus-api-jdo.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar ...
[ivy:resolve] ............................. (1759kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.datanucleus#datanucleus-core;3.2.2!datanucleus-core.jar (34ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar ...
[ivy:resolve] ............................. (1728kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.datanucleus#datanucleus-rdbms;3.2.1!datanucleus-rdbms.jar (34ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar ...
[ivy:resolve] ..... (196kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.jdo#jdo-api;3.0.1!jdo-api.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar ...
[ivy:resolve] ........................................ (2389kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.derby#derby;10.4.2.0!derby.jar (45ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/guava/guava/r08/guava-r08.jar ...
[ivy:resolve] .................... (1088kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.guava#guava;r08!guava.jar (25ms)
[ivy:resolve] :: resolution report :: resolve 9900ms :: artifacts dl 275ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   27  |   12  |   12  |   1   ||   26  |   12  |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-metastore-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-metastore-default.html

make-pom:
     [echo] Project: metastore
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: metastore
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources does not exist.

init:
     [echo] Project: metastore

metastore-init:
     [echo] Project: metastore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/gen/antlr/gen-java/org/apache/hadoop/hive/metastore/parser

ivy-retrieve:
     [echo] Project: metastore
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-metastore
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	12 artifacts copied, 14 already retrieved (9837kB/33ms)

build-grammar:
     [echo] Project: metastore
     [echo] Building Grammar /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g  ....

model-compile:
     [echo] Project: metastore
    [javac] Compiling 24 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes

core-compile:
     [echo] Project: metastore
    [javac] Compiling 104 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes/org/apache/hadoop/hive/metastore/parser/package-info.class

model-enhance:
     [echo] Project: metastore
[datanucleusenhancer] log4j:WARN No appenders could be found for logger (DataNucleus.General).
[datanucleusenhancer] log4j:WARN Please initialize the log4j system properly.
[datanucleusenhancer] log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
[datanucleusenhancer] DataNucleus Enhancer (version 3.2.2) for API &quot;JDO&quot; using JRE &quot;1.6&quot;
[datanucleusenhancer] DataNucleus Enhancer : Classpath
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/hive-anttasks-0.12.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/common/hive-common-0.12.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/serde/hive-serde-0.12.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.12.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/activation-1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ant-1.6.5.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/asm-3.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-beanutils-1.7.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-beanutils-core-1.8.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-cli-1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-codec-1.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-collections-3.2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-configuration-1.6.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-digester-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-el-1.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-httpclient-3.0.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-io-2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-lang-2.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-logging-1.1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-math-2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-net-1.4.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/core-3.1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftplet-api-1.0.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftpserver-core-1.0.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftpserver-deprecated-1.0.0-M2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-core-1.1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-test-1.1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-tools-1.1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hsqldb-1.8.0.10.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-core-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-jaxrs-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-mapper-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-xc-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jasper-compiler-5.5.12.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jasper-runtime-5.5.12.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jaxb-api-2.2.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jaxb-impl-2.2.3-1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-core-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-json-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-server-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jets3t-0.6.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jettison-1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jetty-6.1.26.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jetty-util-6.1.26.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jsp-2.1-6.1.14.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jsp-api-2.1-6.1.14.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/junit-3.8.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/mina-core-2.0.0-M5.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/oro-2.0.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/servlet-api-2.5-20081211.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/servlet-api-2.5-6.1.14.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/slf4j-api-1.5.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/stax-api-1.0-2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/stax-api-1.0.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/xmlenc-0.52.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/ST4-4.0.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/antlr-3.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/antlr-runtime-3.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-mapred-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/bonecp-0.7.1.RELEASE.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-cli-1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-codec-1.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-compress-1.4.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-io-2.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-lang-2.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-logging-1.0.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-logging-api-1.0.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-pool-1.5.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-api-jdo-3.2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-core-3.2.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-rdbms-3.2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/derby-10.4.2.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/guava-11.0.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/guava-r08.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-common-0.12.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-serde-0.12.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-shims-0.12.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-core-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-mapper-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jdo-api-3.0.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libfb303-0.9.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libthrift-0.9.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/log4j-1.2.16.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/mockito-all-1.8.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/slf4j-api-1.6.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/slf4j-log4j12-1.6.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/velocity-1.5.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/xz-1.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/zookeeper-3.4.3.jar
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDatabase
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFieldSchema
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MType
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTable
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MOrder
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStringList
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartition
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MIndex
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRole
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRoleMap
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MMasterKey
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDelegationToken
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics
[datanucleusenhancer] DataNucleus Enhancer completed with success for 24 classes. Timings : input=659 ms, enhance=1144 ms, total=1803 ms. Consult the log for full details

compile:
     [echo] Project: metastore

jar:
     [echo] Project: metastore
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/hive-metastore-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-metastore;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 20:45:00 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-metastore
[ivy:publish] 	published hive-metastore to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.12.0-SNAPSHOT/jars/hive-metastore.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: ql

check-ivy:
     [echo] Project: ql

ivy-resolve:
     [echo] Project: ql
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-exec;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.12.0-SNAPSHOT/jars/hive-metastore.jar ...
[ivy:resolve] ..................................................... (3267kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-metastore;0.12.0-SNAPSHOT!hive-metastore.jar (54ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.4.1/protobuf-java-2.4.1.jar ...
[ivy:resolve] ........ (439kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.protobuf#protobuf-java;2.4.1!protobuf-java.jar (22ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/iq80/snappy/snappy/0.2/snappy-0.2.jar ...
[ivy:resolve] .. (47kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.iq80.snappy#snappy;0.2!snappy.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/json/json/20090211/json-20090211.jar ...
[ivy:resolve] .. (44kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.json#json;20090211!json.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar ...
[ivy:resolve] .. (16kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.googlecode.javaewah#JavaEWAH;0.3.2!JavaEWAH.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javolution/javolution/5.5.1/javolution-5.5.1.jar ...
[ivy:resolve] ........ (385kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javolution#javolution;5.5.1!javolution.jar(bundle) (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/jline/jline/0.9.94/jline-0.9.94.jar ...
[ivy:resolve] ... (85kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] jline#jline;0.9.94!jline.jar (24ms)
[ivy:resolve] :: resolution report :: resolve 10701ms :: artifacts dl 180ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   38  |   7   |   7   |   2   ||   36  |   7   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-exec-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-exec-default.html

make-pom:
     [echo] Project: ql
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: ql

init:
     [echo] Project: ql

ql-init:
     [echo] Project: ql
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/gen/antlr/gen-java/org/apache/hadoop/hive/ql/parse

ivy-retrieve:
     [echo] Project: ql
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-exec
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	10 artifacts copied, 26 already retrieved (5173kB/24ms)

build-grammar:
     [echo] Project: ql
     [echo] Building Grammar /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g  ....
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:866:5: 
     [java] Decision can match input such as &quot;Identifier KW_RENAME KW_TO&quot; using multiple alternatives: 1, 10
     [java] 
     [java] As a result, alternative(s) 10 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1167:5: 
     [java] Decision can match input such as &quot;KW_TEXTFILE&quot; using multiple alternatives: 2, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1167:5: 
     [java] Decision can match input such as &quot;KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1167:5: 
     [java] Decision can match input such as &quot;KW_ORCFILE&quot; using multiple alternatives: 4, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1167:5: 
     [java] Decision can match input such as &quot;KW_RCFILE&quot; using multiple alternatives: 3, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1180:23: 
     [java] Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1180:23: 
     [java] Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1180:23: 
     [java] Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:23: 
     [java] Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:23: 
     [java] Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:23: 
     [java] Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_PRETTY KW_PARTITION&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_PRETTY {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_PRETTY Identifier&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_FORMATTED {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_FORMATTED KW_PARTITION&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_FORMATTED Identifier&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1476:116: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_DIRECTORIES&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_INPUTFORMAT&quot; using multiple alternatives: 5, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_ORCFILE&quot; using multiple alternatives: 4, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_RCFILE&quot; using multiple alternatives: 3, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_TEXTFILE&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): SelectClauseParser.g:149:5: 
     [java] Decision can match input such as &quot;KW_NULL DOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): SelectClauseParser.g:149:5: 
     [java] Decision can match input such as &quot;KW_NULL DOT Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:127:2: 
     [java] Decision can match input such as &quot;KW_LATERAL KW_VIEW KW_OUTER&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:25: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral RPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:25: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral EQUAL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:25: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral COMMA&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL GREATERTHAN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL GREATERTHANOREQUALTO&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LESSTHAN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LESSTHANOREQUALTO&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL DOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL NOTEQUAL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL EQUAL_NS&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL {DIV..DIVIDE, MOD, STAR}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL BITWISEXOR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL EQUAL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL RPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_AND&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CAST LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL BITWISEOR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_BETWEEN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_IN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL AMPERSAND&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LSQUARE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL {KW_LIKE, KW_REGEXP, KW_RLIKE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL {MINUS, PLUS}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN CharSetName CharSetLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_WHEN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_IS&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_DATE StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_OR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:108:5: 
     [java] Decision can match input such as &quot;KW_ORDER KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:121:5: 
     [java] Decision can match input such as &quot;KW_CLUSTER KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:133:5: 
     [java] Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:144:5: 
     [java] Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:155:5: 
     [java] Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:172:7: 
     [java] Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:185:5: 
     [java] Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): IdentifiersParser.g:185:5: 
     [java] Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): IdentifiersParser.g:185:5: 
     [java] Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 8
     [java] 
     [java] As a result, alternative(s) 8 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_DATE StringLiteral&quot; using multiple alternatives: 2, 3
     [java] 
     [java] As a result, alternative(s) 3 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 3, 8
     [java] 
     [java] As a result, alternative(s) 8 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 3, 8
     [java] 
     [java] As a result, alternative(s) 8 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 6, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:514:5: 
     [java] Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3
     [java] 
     [java] As a result, alternative(s) 3 were disabled for that input

compile:
     [echo] Project: ql
    [javac] Compiling 918 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/exec/package-info.class
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/io/orc/package-info.class
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/udf/generic/package-info.class
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/exec/errors/package-info.class
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/lockmgr/package-info.class
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes

jar:
     [echo] Project: ql
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libthrift-0.9.0.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/thrift/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-lang-2.4.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/commons-lang/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/json-20090211.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/json/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/JavaEWAH-0.3.2.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/javaewah/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-1.7.1.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/avro/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-mapred-1.7.1.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/avro-mapred/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/javolution-5.5.1.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/javolution/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/protobuf-java-2.4.1.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/protobuf-java/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/guava-11.0.2.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/guava/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/snappy-0.2.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/snappy/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-core-asl-1.8.8.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/jackson-core-asl/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-mapper-asl-1.8.8.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/jackson-mapper-asl/classes
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/hive-exec-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-exec;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 20:45:56 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-exec
[ivy:publish] 	published hive-exec to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-exec/0.12.0-SNAPSHOT/jars/hive-exec.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-exec/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: contrib

check-ivy:
     [echo] Project: contrib

ivy-resolve:
     [echo] Project: contrib
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-contrib;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-exec;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-exec/0.12.0-SNAPSHOT/jars/hive-exec.jar ...
[ivy:resolve] ............................................................................................................................................ (8833kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-exec;0.12.0-SNAPSHOT!hive-exec.jar (115ms)
[ivy:resolve] :: resolution report :: resolve 6930ms :: artifacts dl 133ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   39  |   1   |   1   |   2   ||   37  |   1   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-contrib-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-contrib-default.html

make-pom:
     [echo] Project: contrib
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: contrib
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources does not exist.

init:
     [echo] Project: contrib

setup:
     [echo] Project: contrib

ivy-retrieve:
     [echo] Project: contrib
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-contrib
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	1 artifacts copied, 36 already retrieved (8833kB/49ms)

compile:
     [echo] Project: contrib
    [javac] Compiling 39 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/java/org/apache/hadoop/hive/contrib/udf/example/UDFExampleStructPrint.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/java/conf does not exist.

jar:
     [echo] Project: contrib
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/hive-contrib-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-contrib;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 20:46:04 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-contrib
[ivy:publish] 	published hive-contrib to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-contrib/0.12.0-SNAPSHOT/jars/hive-contrib.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-contrib/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: service

check-ivy:
     [echo] Project: service

ivy-resolve:
     [echo] Project: service
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-service;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-exec;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] :: resolution report :: resolve 6943ms :: artifacts dl 17ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   39  |   0   |   0   |   2   ||   37  |   0   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-service-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-service-default.html

make-pom:
     [echo] Project: service
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/service/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: service
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources does not exist.

init:
     [echo] Project: service

ivy-retrieve:
     [echo] Project: service
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-service
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	0 artifacts copied, 37 already retrieved (0kB/19ms)

compile:
     [echo] Project: service
    [javac] Compiling 151 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.

jar:
     [echo] Project: service
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/service/hive-service-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-service;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 20:46:15 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/service/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-service
[ivy:publish] 	published hive-service to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-service/0.12.0-SNAPSHOT/jars/hive-service.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-service/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: cli

check-ivy:
     [echo] Project: cli

ivy-resolve:
     [echo] Project: cli
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-cli;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-service;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-exec;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-service/0.12.0-SNAPSHOT/jars/hive-service.jar ...
[ivy:resolve] ........................ (1468kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-service;0.12.0-SNAPSHOT!hive-service.jar (40ms)
[ivy:resolve] :: resolution report :: resolve 6777ms :: artifacts dl 57ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   40  |   1   |   1   |   2   ||   38  |   1   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-cli-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-cli-default.html

make-pom:
     [echo] Project: cli
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/cli/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: cli
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/resources does not exist.

init:
     [echo] Project: cli

setup:
     [echo] Project: cli

ivy-retrieve:
     [echo] Project: cli
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-cli
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	1 artifacts copied, 37 already retrieved (1468kB/15ms)

compile:
     [echo] Project: cli
    [javac] Compiling 4 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:71: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac] import sun.misc.Signal;
    [javac]                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:72: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac] import sun.misc.SignalHandler;
    [javac]                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:362: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac]     SignalHandler oldSignal = null;
    [javac]     ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:363: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]     Signal interupSignal = null;
    [javac]     ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:368: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]       interupSignal = new Signal(&quot;INT&quot;);
    [javac]                           ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:369: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac]       oldSignal = Signal.handle(interupSignal, new SignalHandler() {
    [javac]                                                    ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:369: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac]       oldSignal = Signal.handle(interupSignal, new SignalHandler() {
    [javac]                                                    ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:374: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]         public void handle(Signal signal) {
    [javac]                            ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:369: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]       oldSignal = Signal.handle(interupSignal, new SignalHandler() {
    [javac]                   ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:430: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]         Signal.handle(interupSignal, oldSignal);
    [javac]         ^
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/RCFileCat.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] 10 warnings

jar:
     [echo] Project: cli
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/hive-cli-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-cli;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 20:46:23 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/cli/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-cli
[ivy:publish] 	published hive-cli to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-cli/0.12.0-SNAPSHOT/jars/hive-cli.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-cli/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: jdbc

check-ivy:
     [echo] Project: jdbc

ivy-resolve:
     [echo] Project: jdbc
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-jdbc;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-cli;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-service;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-exec;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-cli/0.12.0-SNAPSHOT/jars/hive-cli.jar ...
[ivy:resolve] .. (33kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-cli;0.12.0-SNAPSHOT!hive-cli.jar (6ms)
[ivy:resolve] :: resolution report :: resolve 7114ms :: artifacts dl 32ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   41  |   1   |   1   |   2   ||   39  |   1   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-jdbc-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-jdbc-default.html

make-pom:
     [echo] Project: jdbc
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: jdbc
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/test/resources does not exist.

init:
     [echo] Project: jdbc

ivy-retrieve:
     [echo] Project: jdbc
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-jdbc
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	1 artifacts copied, 38 already retrieved (33kB/23ms)

compile:
     [echo] Project: jdbc
    [javac] Compiling 28 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.

jar:
     [echo] Project: jdbc
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/hive-jdbc-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-jdbc;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 20:46:31 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-jdbc
[ivy:publish] 	published hive-jdbc to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-jdbc/0.12.0-SNAPSHOT/jars/hive-jdbc.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-jdbc/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: beeline

check-ivy:
     [echo] Project: beeline

ivy-resolve:
     [echo] Project: beeline
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-beeline;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-service;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-exec;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.4 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.4 in maven2
[ivy:resolve] 	found commons-logging#commons-logging-api;1.0.4 in maven2
[ivy:resolve] 	found org.apache.thrift#libthrift;0.9.0 in maven2
[ivy:resolve] :: resolution report :: resolve 7558ms :: artifacts dl 30ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   44  |   0   |   0   |   2   ||   42  |   0   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-beeline-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-beeline-default.html

make-pom:
     [echo] Project: beeline
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: beeline
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/test/resources does not exist.

init:
     [echo] Project: beeline

setup:
     [echo] Project: beeline

ivy-retrieve:
     [echo] Project: beeline
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-beeline
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	0 artifacts copied, 42 already retrieved (0kB/13ms)

compile:
     [echo] Project: beeline
    [javac] Compiling 29 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:28: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac] import sun.misc.Signal;
    [javac]                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:29: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac] import sun.misc.SignalHandler;
    [javac]                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:31: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac] public class SunSignalHandler implements BeeLineSignalHandler, SignalHandler {
    [javac]                                                                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:44: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]   public void handle (Signal signal) {
    [javac]                       ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:37: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]     Signal.handle (new Signal (&quot;INT&quot;), this);
    [javac]                        ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:37: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]     Signal.handle (new Signal (&quot;INT&quot;), this);
    [javac]     ^
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] 6 warnings
     [copy] Copying 2 files to /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes

jar:
     [echo] Project: beeline
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/hive-beeline-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-beeline;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 20:46:40 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-beeline
[ivy:publish] 	published hive-beeline to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-beeline/0.12.0-SNAPSHOT/jars/hive-beeline.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-beeline/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: hwi

check-ivy:
     [echo] Project: hwi

ivy-resolve:
     [echo] Project: hwi
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-hwi;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-cli;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-service;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-exec;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api;2.5-20081211 in maven2
[ivy:resolve] :: resolution report :: resolve 7506ms :: artifacts dl 19ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   44  |   0   |   0   |   2   ||   42  |   0   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-hwi-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-hwi-default.html

make-pom:
     [echo] Project: hwi
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: hwi
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources does not exist.

init:
     [echo] Project: hwi

setup:
     [echo] Project: hwi

ivy-retrieve:
     [echo] Project: hwi
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-hwi
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	3 artifacts copied, 39 already retrieved (831kB/15ms)

war:
     [echo] Project: hwi
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/hive-hwi-0.12.0-SNAPSHOT.war

compile:
     [echo] Project: hwi
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hwi/build.xml:67: warning: &apos;includeantruntime&apos; was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds
    [javac] Compiling 6 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes

jar:
     [echo] Project: hwi
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/hive-hwi-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-hwi;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 20:46:48 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-hwi
[ivy:publish] 	published hive-hwi to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-hwi/0.12.0-SNAPSHOT/jars/hive-hwi.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-hwi/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: hbase-handler

check-ivy:
     [echo] Project: hbase-handler

ivy-resolve:
     [echo] Project: hbase-handler
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-hbase-handler;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-exec;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] 	found org.apache.hbase#hbase;0.94.6.1 in maven2
[ivy:resolve] 	found com.github.stephenc.high-scale-lib#high-scale-lib;1.1.1 in maven2
[ivy:resolve] 	found com.yammer.metrics#metrics-core;2.1.2 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-jaxrs;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-xc;1.8.8 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hbase/hbase/0.94.6.1/hbase-0.94.6.1-tests.jar ...
[ivy:resolve] ......................................... (2360kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hbase#hbase;0.94.6.1!hbase.jar(test-jar) (48ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hbase/hbase/0.94.6.1/hbase-0.94.6.1.jar ...
[ivy:resolve] ......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................... (4952kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hbase#hbase;0.94.6.1!hbase.jar (403ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/github/stephenc/high-scale-lib/high-scale-lib/1.1.1/high-scale-lib-1.1.1.jar ...
[ivy:resolve] ... (93kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.github.stephenc.high-scale-lib#high-scale-lib;1.1.1!high-scale-lib.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/yammer/metrics/metrics-core/2.1.2/metrics-core-2.1.2.jar ...
[ivy:resolve] ... (80kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.yammer.metrics#metrics-core;2.1.2!metrics-core.jar (8ms)
[ivy:resolve] :: resolution report :: resolve 10878ms :: artifacts dl 492ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   46  |   3   |   3   |   2   ||   45  |   4   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-hbase-handler-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-hbase-handler-default.html

make-pom:
     [echo] Project: hbase-handler
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: hbase-handler
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources does not exist.

init:
     [echo] Project: hbase-handler

setup:
     [echo] Project: hbase-handler

ivy-retrieve:
     [echo] Project: hbase-handler
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-hbase-handler
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	6 artifacts copied, 39 already retrieved (7536kB/31ms)

compile:
     [echo] Project: hbase-handler
    [javac] Compiling 13 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes/org/apache/hadoop/hive/hbase/package-info.class
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/java/conf does not exist.

jar:
     [echo] Project: hbase-handler
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/hive-hbase-handler-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-hbase-handler;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 20:47:00 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-hbase-handler
[ivy:publish] 	published hive-hbase-handler to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-hbase-handler/0.12.0-SNAPSHOT/jars/hive-hbase-handler.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-hbase-handler/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: testutils

check-ivy:
     [echo] Project: testutils

ivy-resolve:
     [echo] Project: testutils
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-testutils;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found junit#junit;4.10 in maven2
[ivy:resolve] 	found org.hamcrest#hamcrest-core;1.1 in maven2
[ivy:resolve] 	found com.google.code.tempus-fugit#tempus-fugit;1.1 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/4.10/junit-4.10.jar ...
[ivy:resolve] ..... (247kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] junit#junit;4.10!junit.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/code/tempus-fugit/tempus-fugit/1.1/tempus-fugit-1.1.jar ...
[ivy:resolve] .. (54kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.code.tempus-fugit#tempus-fugit;1.1!tempus-fugit.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/hamcrest/hamcrest-core/1.1/hamcrest-core-1.1.jar ...
[ivy:resolve] ... (74kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.hamcrest#hamcrest-core;1.1!hamcrest-core.jar (6ms)
[ivy:resolve] :: resolution report :: resolve 2146ms :: artifacts dl 27ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	junit#junit;4.7 by [junit#junit;4.10] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   4   |   3   |   3   |   1   ||   3   |   3   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-testutils-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-testutils-default.html

make-pom:
     [echo] Project: testutils
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: testutils
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources does not exist.

init:
     [echo] Project: testutils

setup:
     [echo] Project: testutils

ivy-retrieve:
     [echo] Project: testutils
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-testutils
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	3 artifacts copied, 0 already retrieved (376kB/7ms)

compile:
     [echo] Project: testutils
    [javac] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/classes
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/java/conf does not exist.

jar:
     [echo] Project: testutils
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/hive-testutils-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-testutils;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 20:47:03 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-testutils
[ivy:publish] 	published hive-testutils to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-testutils/0.12.0-SNAPSHOT/jars/hive-testutils.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-testutils/0.12.0-SNAPSHOT/ivys/ivy.xml

init:

jar:

mvn-init:
     [echo] hcatalog-core
      [get] Getting: http://repo2.maven.org/maven2/org/apache/maven/maven-ant-tasks/2.1.3/maven-ant-tasks-2.1.3.jar
      [get] To: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build/maven-ant-tasks-2.1.3.jar

hive-mvn-publish:
     [echo] Installing local artifact for maven : shims
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.12.0-SNAPSHOT/hive-shims-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : common
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/common/hive-common-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-common/0.12.0-SNAPSHOT/hive-common-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : serde
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/serde/hive-serde-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-serde/0.12.0-SNAPSHOT/hive-serde-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : metastore
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/hive-metastore-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.12.0-SNAPSHOT/hive-metastore-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : ql
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/ql/hive-exec-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-exec/0.12.0-SNAPSHOT/hive-exec-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : contrib
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/hive-contrib-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-contrib/0.12.0-SNAPSHOT/hive-contrib-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : service
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/service/hive-service-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-service/0.12.0-SNAPSHOT/hive-service-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : cli
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/cli/hive-cli-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-cli/0.12.0-SNAPSHOT/hive-cli-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : jdbc
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/hive-jdbc-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-jdbc/0.12.0-SNAPSHOT/hive-jdbc-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : beeline
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/hive-beeline-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-beeline/0.12.0-SNAPSHOT/hive-beeline-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : hwi
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/hive-hwi-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hwi/0.12.0-SNAPSHOT/hive-hwi-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : hbase-handler
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/hive-hbase-handler-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hbase-handler/0.12.0-SNAPSHOT/hive-hbase-handler-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : testutils
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/hive-testutils-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-testutils/0.12.0-SNAPSHOT/hive-testutils-0.12.0-SNAPSHOT.jar

_check-mvn-dependencies:

mvn-dependencies:
     [echo] hcatalog-core
[artifact:dependencies] Downloading: com/google/guava/guava/11.0.2/guava-11.0.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google.guava:guava:pom:11.0.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/guava/guava/11.0.2/guava-11.0.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 5K from central
[artifact:dependencies] Downloading: com/google/guava/guava-parent/11.0.2/guava-parent-11.0.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google.guava:guava-parent:pom:11.0.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/guava/guava-parent/11.0.2/guava-parent-11.0.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/sonatype/oss/oss-parent/7/oss-parent-7.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.sonatype.oss:oss-parent:pom:7&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/sonatype/oss/oss-parent/7/oss-parent-7.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 5K from central
[artifact:dependencies] Downloading: com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google.code.findbugs:jsr305:pom:1.3.9&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-cli:0.12.0-SNAPSHOT: checking for updates from datanucleus
[artifact:dependencies] Downloading: jline/jline/0.9.94/jline-0.9.94.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;jline:jline:pom:0.9.94&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: jline/jline/0.9.94/jline-0.9.94.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 6K from central
[artifact:dependencies] Downloading: junit/junit/3.8.1/junit-3.8.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;junit:junit:pom:3.8.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: junit/junit/3.8.1/junit-3.8.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-service:0.12.0-SNAPSHOT: checking for updates from datanucleus
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-exec:0.12.0-SNAPSHOT: checking for updates from datanucleus
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-metastore:0.12.0-SNAPSHOT: checking for updates from datanucleus
[artifact:dependencies] Downloading: org/antlr/antlr/3.4/antlr-3.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:antlr:pom:3.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/antlr/3.4/antlr-3.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/antlr/antlr-master/3.4/antlr-master-3.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:antlr-master:pom:3.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/antlr-master/3.4/antlr-master-3.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:antlr-runtime:pom:3.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:stringtemplate:pom:3.2.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 7K from central
[artifact:dependencies] Downloading: antlr/antlr/2.7.7/antlr-2.7.7.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;antlr:antlr:pom:2.7.7&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: antlr/antlr/2.7.7/antlr-2.7.7.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/antlr/ST4/4.0.4/ST4-4.0.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:ST4:pom:4.0.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/ST4/4.0.4/ST4-4.0.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: org/antlr/antlr-runtime/3.3/antlr-runtime-3.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:antlr-runtime:pom:3.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/antlr-runtime/3.3/antlr-runtime-3.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/antlr/antlr-master/3.3/antlr-master-3.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:antlr-master:pom:3.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/antlr-master/3.3/antlr-master-3.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-serde:0.12.0-SNAPSHOT: checking for updates from datanucleus
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-common:0.12.0-SNAPSHOT: checking for updates from datanucleus
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-shims:0.12.0-SNAPSHOT: checking for updates from datanucleus
[artifact:dependencies] Downloading: org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.zookeeper:zookeeper:pom:3.4.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-api:pom:1.6.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.6.1/slf4j-parent-1.6.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-parent:pom:1.6.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.6.1/slf4j-parent-1.6.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-log4j12:pom:1.6.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: log4j/log4j/1.2.16/log4j-1.2.16.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;log4j:log4j:pom:1.2.16&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: log4j/log4j/1.2.16/log4j-1.2.16.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 20K from central
[artifact:dependencies] Downloading: log4j/log4j/1.2.15/log4j-1.2.15.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;log4j:log4j:pom:1.2.15&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: log4j/log4j/1.2.15/log4j-1.2.15.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 17K from central
[artifact:dependencies] Downloading: javax/mail/mail/1.4/mail-1.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;javax.mail:mail:pom:1.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: javax.mail/poms/mail-1.4.pom from repository java.net at https://maven-repository.dev.java.net/nonav/repository
[artifact:dependencies] Error transferring file: maven-repository.dev.java.net
[artifact:dependencies] [WARNING] Unable to get resource &apos;javax.mail:mail:pom:1.4&apos; from repository java.net (https://maven-repository.dev.java.net/nonav/repository): Error transferring file: maven-repository.dev.java.net
[artifact:dependencies] Downloading: javax/mail/mail/1.4/mail-1.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: javax/activation/activation/1.1/activation-1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;javax.activation:activation:pom:1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: javax.activation/poms/activation-1.1.pom from repository java.net at https://maven-repository.dev.java.net/nonav/repository
[artifact:dependencies] Error transferring file: maven-repository.dev.java.net
[artifact:dependencies] [WARNING] Unable to get resource &apos;javax.activation:activation:pom:1.1&apos; from repository java.net (https://maven-repository.dev.java.net/nonav/repository): Error transferring file: maven-repository.dev.java.net
[artifact:dependencies] Downloading: javax/activation/activation/1.1/activation-1.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: javax/jms/jms/1.1/jms-1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 1K from datanucleus
[artifact:dependencies] [WARNING] *** CHECKSUM FAILED - Error retrieving checksum file for javax/jms/jms/1.1/jms-1.1.pom - IGNORING
[artifact:dependencies] Downloading: com/sun/jdmk/jmxtools/1.2.1/jmxtools-1.2.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 0K from datanucleus
[artifact:dependencies] [WARNING] *** CHECKSUM FAILED - Error retrieving checksum file for com/sun/jdmk/jmxtools/1.2.1/jmxtools-1.2.1.pom - IGNORING
[artifact:dependencies] Downloading: com/sun/jmx/jmxri/1.2.1/jmxri-1.2.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 0K from datanucleus
[artifact:dependencies] [WARNING] *** CHECKSUM FAILED - Error retrieving checksum file for com/sun/jmx/jmxri/1.2.1/jmxri-1.2.1.pom - IGNORING
[artifact:dependencies] Downloading: org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.jboss.netty:netty:pom:3.2.2.Final&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 23K from central
[artifact:dependencies] Downloading: org/jboss/jboss-parent/5/jboss-parent-5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.jboss:jboss-parent:pom:5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/jboss/jboss-parent/5/jboss-parent-5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 18K from central
[artifact:dependencies] Downloading: org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.thrift:libthrift:pom:0.9.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.8/slf4j-api-1.5.8.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-api:pom:1.5.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.8/slf4j-api-1.5.8.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.8/slf4j-parent-1.5.8.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-parent:pom:1.5.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.8/slf4j-parent-1.5.8.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 8K from central
[artifact:dependencies] Downloading: commons-lang/commons-lang/2.5/commons-lang-2.5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-lang:commons-lang:pom:2.5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-lang/commons-lang/2.5/commons-lang-2.5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 17K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/12/commons-parent-12.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-parent:pom:12&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/12/commons-parent-12.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 26K from central
[artifact:dependencies] Downloading: org/apache/apache/4/apache-4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache:apache:pom:4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/apache/4/apache-4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:httpclient:pom:4.1.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 6K from central
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcomponents-client/4.1.3/httpcomponents-client-4.1.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:httpcomponents-client:pom:4.1.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcomponents-client/4.1.3/httpcomponents-client-4.1.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 12K from central
[artifact:dependencies] Downloading: org/apache/httpcomponents/project/5/project-5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:project:pom:5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/project/5/project-5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 23K from central
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcore/4.1.4/httpcore-4.1.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:httpcore:pom:4.1.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcore/4.1.4/httpcore-4.1.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 7K from central
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcomponents-core/4.1.4/httpcomponents-core-4.1.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:httpcomponents-core:pom:4.1.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcomponents-core/4.1.4/httpcomponents-core-4.1.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 10K from central
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-logging:commons-logging:pom:1.1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 18K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/5/commons-parent-5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-parent:pom:5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/5/commons-parent-5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 16K from central
[artifact:dependencies] Downloading: commons-codec/commons-codec/1.4/commons-codec-1.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-codec:commons-codec:pom:1.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-codec/commons-codec/1.4/commons-codec-1.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 10K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/11/commons-parent-11.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-parent:pom:11&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/11/commons-parent-11.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 24K from central
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:httpcore:pom:4.1.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 7K from central
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcomponents-core/4.1.3/httpcomponents-core-4.1.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:httpcomponents-core:pom:4.1.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcomponents-core/4.1.3/httpcomponents-core-4.1.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 10K from central
[artifact:dependencies] Downloading: org/apache/httpcomponents/project/4.1.1/project-4.1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:project:pom:4.1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/project/4.1.1/project-4.1.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 16K from central
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.0.4/commons-logging-1.0.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-logging:commons-logging:pom:1.0.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.0.4/commons-logging-1.0.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 5K from central
[artifact:dependencies] Downloading: commons-logging/commons-logging-api/1.0.4/commons-logging-api-1.0.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-logging:commons-logging-api:pom:1.0.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-logging/commons-logging-api/1.0.4/commons-logging-api-1.0.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 0K from central
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.codehaus.jackson:jackson-core-asl:pom:1.8.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.codehaus.jackson:jackson-mapper-asl:pom:1.8.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: commons-io/commons-io/2.4/commons-io-2.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-io:commons-io:pom:2.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-io/commons-io/2.4/commons-io-2.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 10K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/25/commons-parent-25.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-parent:pom:25&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/25/commons-parent-25.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 47K from central
[artifact:dependencies] Downloading: org/apache/apache/9/apache-9.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache:apache:pom:9&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/apache/9/apache-9.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 15K from central
[artifact:dependencies] Downloading: commons-cli/commons-cli/1.2/commons-cli-1.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-cli:commons-cli:pom:1.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-cli/commons-cli/1.2/commons-cli-1.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 8K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-compress:pom:1.4.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 11K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/24/commons-parent-24.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-parent:pom:24&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/24/commons-parent-24.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 46K from central
[artifact:dependencies] Downloading: org/tukaani/xz/1.0/xz-1.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.tukaani:xz:pom:1.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/tukaani/xz/1.0/xz-1.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: commons-lang/commons-lang/2.4/commons-lang-2.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-lang:commons-lang:pom:2.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-lang/commons-lang/2.4/commons-lang-2.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 14K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/9/commons-parent-9.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-parent:pom:9&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/9/commons-parent-9.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 21K from central
[artifact:dependencies] Downloading: org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mockito:mockito-all:pom:1.8.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.thrift:libfb303:pom:0.9.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/apache/avro/avro/1.7.1/avro-1.7.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.avro:avro:pom:1.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/avro/avro/1.7.1/avro-1.7.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/apache/avro/avro-parent/1.7.1/avro-parent-1.7.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.avro:avro-parent:pom:1.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/avro/avro-parent/1.7.1/avro-parent-1.7.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 15K from central
[artifact:dependencies] Downloading: org/apache/avro/avro-toplevel/1.7.1/avro-toplevel-1.7.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.avro:avro-toplevel:pom:1.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/avro/avro-toplevel/1.7.1/avro-toplevel-1.7.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: org/apache/apache/10/apache-10.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache:apache:pom:10&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/apache/10/apache-10.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 14K from central
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer:pom:2.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-parent/2.3/paranamer-parent-2.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer-parent:pom:2.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-parent/2.3/paranamer-parent-2.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 11K from central
[artifact:dependencies] Downloading: org/codehaus/codehaus-parent/1/codehaus-parent-1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.codehaus:codehaus-parent:pom:1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/codehaus/codehaus-parent/1/codehaus-parent-1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.xerial.snappy:snappy-java:pom:1.0.4.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.6.4/slf4j-api-1.6.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-api:pom:1.6.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.6.4/slf4j-api-1.6.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.6.4/slf4j-parent-1.6.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-parent:pom:1.6.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.6.4/slf4j-parent-1.6.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 12K from central
[artifact:dependencies] Downloading: org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.avro:avro-mapred:pom:1.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.avro:avro-ipc:pom:1.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jetty:pom:6.1.26&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 6K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/project/6.1.26/project-6.1.26.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:project:pom:6.1.26&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/project/6.1.26/project-6.1.26.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty-parent/10/jetty-parent-10.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jetty-parent:pom:10&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty-parent/10/jetty-parent-10.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/eclipse/jetty/jetty-parent/14/jetty-parent-14.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.eclipse.jetty:jetty-parent:pom:14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/eclipse/jetty/jetty-parent/14/jetty-parent-14.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 16K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jetty-util:pom:6.1.26&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:servlet-api:pom:2.5-20081211&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty-parent/7/jetty-parent-7.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jetty-parent:pom:7&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty-parent/7/jetty-parent-7.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 13K from central
[artifact:dependencies] Downloading: io/netty/netty/3.4.0.Final/netty-3.4.0.Final.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;io.netty:netty:pom:3.4.0.Final&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: io/netty/netty/3.4.0.Final/netty-3.4.0.Final.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 24K from central
[artifact:dependencies] Downloading: org/apache/velocity/velocity/1.7/velocity-1.7.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.velocity:velocity:pom:1.7&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/velocity/velocity/1.7/velocity-1.7.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 11K from central
[artifact:dependencies] Downloading: commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-collections:commons-collections:pom:3.2.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 12K from central
[artifact:dependencies] Downloading: com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.jolbox:bonecp:pom:0.7.1.RELEASE&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: com/jolbox/bonecp-parent/0.7.1.RELEASE/bonecp-parent-0.7.1.RELEASE.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.jolbox:bonecp-parent:pom:0.7.1.RELEASE&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/jolbox/bonecp-parent/0.7.1.RELEASE/bonecp-parent-0.7.1.RELEASE.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 24K from central
[artifact:dependencies] Downloading: com/google/guava/guava/r08/guava-r08.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google.guava:guava:pom:r08&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/guava/guava/r08/guava-r08.pom from repository jboss-public-repository-group at http://repository.jboss.org/nexus/content/groups/public
[artifact:dependencies] Transferring 3K from jboss-public-repository-group
[artifact:dependencies] [WARNING] *** CHECKSUM FAILED - Error retrieving checksum file for com/google/guava/guava/r08/guava-r08.pom - IGNORING
[artifact:dependencies] Downloading: com/google/google/5/google-5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google:google:pom:5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/google/5/google-5.pom from repository jboss-public-repository-group at http://repository.jboss.org/nexus/content/groups/public
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google:google:pom:5&apos; in repository jboss-public-repository-group (http://repository.jboss.org/nexus/content/groups/public)
[artifact:dependencies] Downloading: com/google/google/5/google-5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.10/slf4j-api-1.5.10.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-api:pom:1.5.10&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.10/slf4j-api-1.5.10.pom from repository jboss-public-repository-group at http://repository.jboss.org/nexus/content/groups/public
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-api:pom:1.5.10&apos; in repository jboss-public-repository-group (http://repository.jboss.org/nexus/content/groups/public)
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.10/slf4j-api-1.5.10.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.10/slf4j-parent-1.5.10.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-parent:pom:1.5.10&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.10/slf4j-parent-1.5.10.pom from repository jboss-public-repository-group at http://repository.jboss.org/nexus/content/groups/public
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-parent:pom:1.5.10&apos; in repository jboss-public-repository-group (http://repository.jboss.org/nexus/content/groups/public)
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.10/slf4j-parent-1.5.10.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-pool:commons-pool:pom:1.5.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 11K from central
[artifact:dependencies] Downloading: org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 9K from datanucleus
[artifact:dependencies] Downloading: org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 14K from datanucleus
[artifact:dependencies] Downloading: org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 12K from datanucleus
[artifact:dependencies] Downloading: javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;javax.jdo:jdo-api:pom:3.0.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 8K from central
[artifact:dependencies] Downloading: javax/transaction/jta/1.1/jta-1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;javax.transaction:jta:pom:1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: javax/transaction/jta/1.1/jta-1.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.derby:derby:pom:10.4.2.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: com/google/protobuf/protobuf-java/2.4.1/protobuf-java-2.4.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google.protobuf:protobuf-java:pom:2.4.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/protobuf/protobuf-java/2.4.1/protobuf-java-2.4.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 7K from central
[artifact:dependencies] Downloading: com/google/google/1/google-1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google:google:pom:1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/google/1/google-1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/iq80/snappy/snappy/0.2/snappy-0.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.iq80.snappy:snappy:pom:0.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/iq80/snappy/snappy/0.2/snappy-0.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 14K from central
[artifact:dependencies] Downloading: org/json/json/20090211/json-20090211.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.json:json:pom:20090211&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/json/json/20090211/json-20090211.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: commons-configuration/commons-configuration/1.6/commons-configuration-1.6.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-configuration:commons-configuration:pom:1.6&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-configuration/commons-configuration/1.6/commons-configuration-1.6.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 13K from central
[artifact:dependencies] Downloading: commons-digester/commons-digester/1.8/commons-digester-1.8.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-digester:commons-digester:pom:1.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-digester/commons-digester/1.8/commons-digester-1.8.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 7K from central
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-beanutils:commons-beanutils:pom:1.7.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 0K from central
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.0.3/commons-logging-1.0.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-logging:commons-logging:pom:1.0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.0.3/commons-logging-1.0.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.1/commons-logging-1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-logging:commons-logging:pom:1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.1/commons-logging-1.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 6K from central
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-beanutils:commons-beanutils-core:pom:1.8.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.googlecode.javaewah:JavaEWAH:pom:0.3.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/sonatype/oss/oss-parent/5/oss-parent-5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.sonatype.oss:oss-parent:pom:5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/sonatype/oss/oss-parent/5/oss-parent-5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: javolution/javolution/5.5.1/javolution-5.5.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;javolution:javolution:pom:5.5.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: javolution/javolution/5.5.1/javolution-5.5.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 13K from central
[artifact:dependencies] Downloading: junit/junit/4.10/junit-4.10.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;junit:junit:pom:4.10&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: junit/junit/4.10/junit-4.10.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/hamcrest/hamcrest-core/1.1/hamcrest-core-1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.hamcrest:hamcrest-core:pom:1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/hamcrest/hamcrest-core/1.1/hamcrest-core-1.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 0K from central
[artifact:dependencies] Downloading: org/hamcrest/hamcrest-parent/1.1/hamcrest-parent-1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.hamcrest:hamcrest-parent:pom:1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/hamcrest/hamcrest-parent/1.1/hamcrest-parent-1.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 6K from central
[artifact:dependencies] Downloading: com/puppycrawl/tools/checkstyle/5.5/checkstyle-5.5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.puppycrawl.tools:checkstyle:pom:5.5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/puppycrawl/tools/checkstyle/5.5/checkstyle-5.5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 19K from central
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils-core/1.8.3/commons-beanutils-core-1.8.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-beanutils:commons-beanutils-core:pom:1.8.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils-core/1.8.3/commons-beanutils-core-1.8.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-tools/1.0.3/hadoop-tools-1.0.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.hadoop:hadoop-tools:pom:1.0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-tools/1.0.3/hadoop-tools-1.0.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-core/1.0.3/hadoop-core-1.0.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.hadoop:hadoop-core:pom:1.0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-core/1.0.3/hadoop-core-1.0.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: xmlenc/xmlenc/0.52/xmlenc-0.52.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;xmlenc:xmlenc:pom:0.52&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: xmlenc/xmlenc/0.52/xmlenc-0.52.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-httpclient:commons-httpclient:pom:3.0.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 8K from central
[artifact:dependencies] Downloading: commons-codec/commons-codec/1.2/commons-codec-1.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-codec:commons-codec:pom:1.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-codec/commons-codec/1.2/commons-codec-1.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-math/2.1/commons-math-2.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-math:pom:2.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-math/2.1/commons-math-2.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 10K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/14/commons-parent-14.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-parent:pom:14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/14/commons-parent-14.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 31K from central
[artifact:dependencies] Downloading: org/apache/apache/7/apache-7.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache:apache:pom:7&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/apache/7/apache-7.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 14K from central
[artifact:dependencies] Downloading: commons-net/commons-net/1.4.1/commons-net-1.4.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-net:commons-net:pom:1.4.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-net/commons-net/1.4.1/commons-net-1.4.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 5K from central
[artifact:dependencies] Downloading: oro/oro/2.0.8/oro-2.0.8.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;oro:oro:pom:2.0.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: oro/oro/2.0.8/oro-2.0.8.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 0K from central
[artifact:dependencies] Downloading: tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;tomcat:jasper-runtime:pom:5.5.12&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 0K from central
[artifact:dependencies] Downloading: tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;tomcat:jasper-compiler:pom:5.5.12&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 0K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jsp-api-2.1:pom:6.1.14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/project/6.1.14/project-6.1.14.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:project:pom:6.1.14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/project/6.1.14/project-6.1.14.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:servlet-api-2.5:pom:6.1.14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.pom from repository java.net at http://download.java.net/maven/2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:servlet-api-2.5:pom:6.1.14&apos; in repository java.net (http://download.java.net/maven/2)
[artifact:dependencies] Downloading: org.mortbay.jetty/poms/servlet-api-2.5-6.1.14.pom from repository m1.java.net at http://download.java.net/maven/1
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:servlet-api-2.5:pom:6.1.14&apos; in repository m1.java.net (http://download.java.net/maven/1)
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jsp-2.1:pom:6.1.14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 6K from central
[artifact:dependencies] Downloading: org/eclipse/jdt/core/3.1.1/core-3.1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.eclipse.jdt:core:pom:3.1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/eclipse/jdt/core/3.1.1/core-3.1.1.pom from repository java.net at http://download.java.net/maven/2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.eclipse.jdt:core:pom:3.1.1&apos; in repository java.net (http://download.java.net/maven/2)
[artifact:dependencies] Downloading: org.eclipse.jdt/poms/core-3.1.1.pom from repository m1.java.net at http://download.java.net/maven/1
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.eclipse.jdt:core:pom:3.1.1&apos; in repository m1.java.net (http://download.java.net/maven/1)
[artifact:dependencies] Downloading: org/eclipse/jdt/core/3.1.1/core-3.1.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: ant/ant/1.6.5/ant-1.6.5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;ant:ant:pom:1.6.5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: ant/ant/1.6.5/ant-1.6.5.pom from repository java.net at http://download.java.net/maven/2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;ant:ant:pom:1.6.5&apos; in repository java.net (http://download.java.net/maven/2)
[artifact:dependencies] Downloading: ant/poms/ant-1.6.5.pom from repository m1.java.net at http://download.java.net/maven/1
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;ant:ant:pom:1.6.5&apos; in repository m1.java.net (http://download.java.net/maven/1)
[artifact:dependencies] Downloading: ant/ant/1.6.5/ant-1.6.5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: commons-el/commons-el/1.0/commons-el-1.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-el:commons-el:pom:1.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-el/commons-el/1.0/commons-el-1.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;net.java.dev.jets3t:jets3t:pom:0.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: commons-codec/commons-codec/1.3/commons-codec-1.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-codec:commons-codec:pom:1.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-codec/commons-codec/1.3/commons-codec-1.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 6K from central
[artifact:dependencies] Downloading: commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-httpclient:commons-httpclient:pom:3.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 8K from central
[artifact:dependencies] Downloading: net/sf/kosmosfs/kfs/0.3/kfs-0.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;net.sf.kosmosfs:kfs:pom:0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: net/sf/kosmosfs/kfs/0.3/kfs-0.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;hsqldb:hsqldb:pom:1.8.0.10&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-mapper-asl/1.0.1/jackson-mapper-asl-1.0.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.codehaus.jackson:jackson-mapper-asl:pom:1.0.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-mapper-asl/1.0.1/jackson-mapper-asl-1.0.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-test/1.0.3/hadoop-test-1.0.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.hadoop:hadoop-test:pom:1.0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-test/1.0.3/hadoop-test-1.0.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftplet-api/1.0.0/ftplet-api-1.0.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftplet-api:pom:1.0.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftplet-api/1.0.0/ftplet-api-1.0.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-parent/1.0.0/ftpserver-parent-1.0.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftpserver-parent:pom:1.0.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-parent/1.0.0/ftpserver-parent-1.0.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 13K from central
[artifact:dependencies] Downloading: org/apache/mina/mina-core/2.0.0-M5/mina-core-2.0.0-M5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.mina:mina-core:pom:2.0.0-M5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/mina/mina-core/2.0.0-M5/mina-core-2.0.0-M5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/apache/mina/mina-parent/2.0.0-M5/mina-parent-2.0.0-M5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.mina:mina-parent:pom:2.0.0-M5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/mina/mina-parent/2.0.0-M5/mina-parent-2.0.0-M5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 10K from central
[artifact:dependencies] Downloading: org/apache/mina/build/2.0.0-M5/build-2.0.0-M5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.mina:build:pom:2.0.0-M5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/mina/build/2.0.0-M5/build-2.0.0-M5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 8K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.2/slf4j-api-1.5.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-api:pom:1.5.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.2/slf4j-api-1.5.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.2/slf4j-parent-1.5.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-parent:pom:1.5.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.2/slf4j-parent-1.5.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 7K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-core/1.0.0/ftpserver-core-1.0.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftpserver-core:pom:1.0.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-core/1.0.0/ftpserver-core-1.0.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 6K from central
[artifact:dependencies] Downloading: org/apache/mina/mina-core/2.0.0-M4/mina-core-2.0.0-M4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.mina:mina-core:pom:2.0.0-M4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/mina/mina-core/2.0.0-M4/mina-core-2.0.0-M4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/apache/mina/build/2.0.0-M4/build-2.0.0-M4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.mina:build:pom:2.0.0-M4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/mina/build/2.0.0-M4/build-2.0.0-M4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 16K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-deprecated/1.0.0-M2/ftpserver-deprecated-1.0.0-M2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftpserver-deprecated:pom:1.0.0-M2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-deprecated/1.0.0-M2/ftpserver-deprecated-1.0.0-M2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-parent/1.0.0-M2/ftpserver-parent-1.0.0-M2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftpserver-parent:pom:1.0.0-M2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-parent/1.0.0-M2/ftpserver-parent-1.0.0-M2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 14K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftplet-api/1.0.0-M2/ftplet-api-1.0.0-M2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftplet-api:pom:1.0.0-M2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftplet-api/1.0.0-M2/ftplet-api-1.0.0-M2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-core/1.0.0-M2/ftpserver-core-1.0.0-M2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftpserver-core:pom:1.0.0-M2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-core/1.0.0-M2/ftpserver-core-1.0.0-M2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/apache/mina/mina-core/2.0.0-M2/mina-core-2.0.0-M2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.mina:mina-core:pom:2.0.0-M2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/mina/mina-core/2.0.0-M2/mina-core-2.0.0-M2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/apache/mina/build/2.0.0-M2/build-2.0.0-M2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.mina:build:pom:2.0.0-M2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/mina/build/2.0.0-M2/build-2.0.0-M2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 15K from central
[artifact:dependencies] Downloading: org/apache/pig/pig/0.10.1/pig-0.10.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.pig:pig:pom:0.10.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/pig/pig/0.10.1/pig-0.10.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: junit/junit/4.8.1/junit-4.8.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;junit:junit:pom:4.8.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: junit/junit/4.8.1/junit-4.8.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/apache/hadoop/avro/1.3.2/avro-1.3.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.hadoop:avro:pom:1.3.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/hadoop/avro/1.3.2/avro-1.3.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-mapper-asl/1.4.2/jackson-mapper-asl-1.4.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.codehaus.jackson:jackson-mapper-asl:pom:1.4.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-mapper-asl/1.4.2/jackson-mapper-asl-1.4.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.11/slf4j-api-1.5.11.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-api:pom:1.5.11&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.11/slf4j-api-1.5.11.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.11/slf4j-parent-1.5.11.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-parent:pom:1.5.11&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.11/slf4j-parent-1.5.11.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer/2.2/paranamer-2.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer:pom:2.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer/2.2/paranamer-2.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-parent/2.2/paranamer-parent-2.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer-parent:pom:2.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-parent/2.2/paranamer-parent-2.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 8K from central
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-ant/2.2/paranamer-ant-2.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer-ant:pom:2.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-ant/2.2/paranamer-ant-2.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-generator/2.2/paranamer-generator-2.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer-generator:pom:2.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-generator/2.2/paranamer-generator-2.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: com/thoughtworks/qdox/qdox/1.10.1/qdox-1.10.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.qdox:qdox:pom:1.10.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/qdox/qdox/1.10.1/qdox-1.10.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 17K from central
[artifact:dependencies] Downloading: asm/asm/3.2/asm-3.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;asm:asm:pom:3.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: asm/asm/3.2/asm-3.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 0K from central
[artifact:dependencies] Downloading: asm/asm-parent/3.2/asm-parent-3.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;asm:asm-parent:pom:3.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: asm/asm-parent/3.2/asm-parent-3.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer/2.2/paranamer-2.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/tukaani/xz/1.0/xz-1.0.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: commons-digester/commons-digester/1.8/commons-digester-1.8.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.derby:derby:jar:10.4.2.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2389K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-httpclient:commons-httpclient:jar:3.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-digester:commons-digester:jar:1.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-digester/commons-digester/1.8/commons-digester-1.8.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.tukaani:xz:jar:1.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/tukaani/xz/1.0/xz-1.0.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer:jar:2.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer/2.2/paranamer-2.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 298K from central
[artifact:dependencies] Transferring 140K from central
[artifact:dependencies] Transferring 92K from central
[artifact:dependencies] Transferring 29K from central
[artifact:dependencies] Downloading: jline/jline/0.9.94/jline-0.9.94.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.0.4/commons-logging-1.0.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/apache/pig/pig/0.10.1/pig-0.10.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;jline:jline:jar:0.9.94&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: jline/jline/0.9.94/jline-0.9.94.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 85K from central
[artifact:dependencies] Downloading: ant/ant/1.6.5/ant-1.6.5.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-logging:commons-logging:jar:1.0.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.0.4/commons-logging-1.0.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 37K from central
[artifact:dependencies] Downloading: javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;tomcat:jasper-runtime:jar:5.5.12&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:httpclient:jar:4.1.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 75K from central
[artifact:dependencies] Downloading: commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 344K from central
[artifact:dependencies] Downloading: antlr/antlr/2.7.7/antlr-2.7.7.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.pig:pig:jar:0.10.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/pig/pig/0.10.1/pig-0.10.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3010K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;ant:ant:jar:1.6.5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: ant/ant/1.6.5/ant-1.6.5.jar from repository java.net at http://download.java.net/maven/2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;javax.jdo:jdo-api:jar:3.0.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 196K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-collections:commons-collections:jar:3.2.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 562K from central
[artifact:dependencies] Downloading: org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;antlr:antlr:jar:2.7.7&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: antlr/antlr/2.7.7/antlr-2.7.7.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 435K from central
[artifact:dependencies] Downloading: javolution/javolution/5.5.1/javolution-5.5.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: xmlenc/xmlenc/0.52/xmlenc-0.52.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;ant:ant:jar:1.6.5&apos; in repository java.net (http://download.java.net/maven/2)
[artifact:dependencies] Downloading: ant/jars/ant-1.6.5.jar from repository m1.java.net at http://download.java.net/maven/1
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.xerial.snappy:snappy-java:jar:1.0.4.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 973K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;ant:ant:jar:1.6.5&apos; in repository m1.java.net (http://download.java.net/maven/1)
[artifact:dependencies] Downloading: ant/ant/1.6.5/ant-1.6.5.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1010K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;xmlenc:xmlenc:jar:0.52&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: xmlenc/xmlenc/0.52/xmlenc-0.52.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 15K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;javolution:javolution:jar:5.5.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: javolution/javolution/5.5.1/javolution-5.5.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Downloading: commons-cli/commons-cli/1.2/commons-cli-1.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 386K from central
[artifact:dependencies] Downloading: org/apache/avro/avro/1.7.1/avro-1.7.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.jolbox:bonecp:jar:0.7.1.RELEASE&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 113K from central
[artifact:dependencies] Downloading: org/apache/velocity/velocity/1.7/velocity-1.7.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: commons-codec/commons-codec/1.4/commons-codec-1.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-cli:commons-cli:jar:1.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-cli/commons-cli/1.2/commons-cli-1.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.avro:avro:jar:1.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/avro/avro/1.7.1/avro-1.7.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 291K from central
[artifact:dependencies] Transferring 40K from central
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.velocity:velocity:jar:1.7&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/velocity/velocity/1.7/velocity-1.7.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 439K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-codec:commons-codec:jar:1.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-codec/commons-codec/1.4/commons-codec-1.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;hsqldb:hsqldb:jar:1.8.0.10&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 690K from central
[artifact:dependencies] Transferring 57K from central
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: asm/asm/3.2/asm-3.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/iq80/snappy/snappy/0.2/snappy-0.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.codehaus.jackson:jackson-core-asl:jar:1.8.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 222K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google.code.findbugs:jsr305:jar:1.3.9&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 32K from central
[artifact:dependencies] Downloading: io/netty/netty/3.4.0.Final/netty-3.4.0.Final.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.iq80.snappy:snappy:jar:0.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/iq80/snappy/snappy/0.2/snappy-0.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 48K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;asm:asm:jar:3.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: asm/asm/3.2/asm-3.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-beanutils:commons-beanutils:jar:1.7.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 42K from central
[artifact:dependencies] Downloading: com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 184K from central
[artifact:dependencies] Downloading: oro/oro/2.0.8/oro-2.0.8.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;io.netty:netty:jar:3.4.0.Final&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: io/netty/netty/3.4.0.Final/netty-3.4.0.Final.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 935K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jetty:jar:6.1.26&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 527K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.googlecode.javaewah:JavaEWAH:jar:0.3.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 17K from central
[artifact:dependencies] Downloading: org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.jboss.netty:netty:jar:3.2.2.Final&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 767K from central
[artifact:dependencies] Downloading: com/thoughtworks/qdox/qdox/1.10.1/qdox-1.10.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;oro:oro:jar:2.0.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: oro/oro/2.0.8/oro-2.0.8.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 64K from central
[artifact:dependencies] Downloading: net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: commons-lang/commons-lang/2.4/commons-lang-2.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-compress:jar:1.4.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 236K from central
[artifact:dependencies] Downloading: commons-net/commons-net/1.4.1/commons-net-1.4.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.qdox:qdox:jar:1.10.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/qdox/qdox/1.10.1/qdox-1.10.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.thrift:libthrift:jar:0.9.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 339K from central
[artifact:dependencies] Transferring 169K from central
[artifact:dependencies] Downloading: net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-lang:commons-lang:jar:2.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-lang/commons-lang/2.4/commons-lang-2.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;net.java.dev.jets3t:jets3t:jar:0.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 369K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;net.sf.kosmosfs:kfs:jar:0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] Transferring 256K from central
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-net:commons-net:jar:1.4.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-net/commons-net/1.4.1/commons-net-1.4.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Downloading: net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 177K from central
[artifact:dependencies] Transferring 12K from central
[artifact:dependencies] Downloading: com/google/guava/guava/11.0.2/guava-11.0.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/antlr/antlr/3.4/antlr-3.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/json/json/20090211/json-20090211.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: com/google/protobuf/protobuf-java/2.4.1/protobuf-java-2.4.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.zookeeper:zookeeper:jar:3.4.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google.guava:guava:jar:11.0.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/guava/guava/11.0.2/guava-11.0.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 750K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.json:json:jar:20090211&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/json/json/20090211/json-20090211.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google.protobuf:protobuf-java:jar:2.4.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/protobuf/protobuf-java/2.4.1/protobuf-java-2.4.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1610K from central
[artifact:dependencies] Transferring 45K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:antlr:jar:3.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/antlr/3.4/antlr-3.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 440K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 1086K from central
[artifact:dependencies] Downloading: commons-io/commons-io/2.4/commons-io-2.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/eclipse/jdt/core/3.1.1/core-3.1.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: commons-el/commons-el/1.0/commons-el-1.0.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-api:jar:1.6.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 25K from central
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-tools/1.0.3/hadoop-tools-1.0.3.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-io:commons-io:jar:2.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-io/commons-io/2.4/commons-io-2.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 181K from central
[artifact:dependencies] Downloading: commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 329K from datanucleus
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.eclipse.jdt:core:jar:3.1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/eclipse/jdt/core/3.1.1/core-3.1.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-el:commons-el:jar:1.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-el/commons-el/1.0/commons-el-1.0.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.hadoop:hadoop-tools:jar:1.0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Transferring 110K from central
[artifact:dependencies] Transferring 3483K from central
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-tools/1.0.3/hadoop-tools-1.0.3.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-pool:commons-pool:jar:1.5.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 281K from central
[artifact:dependencies] Downloading: javax/transaction/jta/1.1/jta-1.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 94K from central
[artifact:dependencies] Downloading: org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: log4j/log4j/1.2.16/log4j-1.2.16.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-configuration:commons-configuration:jar:1.6&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;javax.transaction:jta:jar:1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: javax/transaction/jta/1.1/jta-1.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 292K from central
[artifact:dependencies] Transferring 15K from central
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-ant/2.2/paranamer-ant-2.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mockito:mockito-all:jar:1.8.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Downloading: commons-logging/commons-logging-api/1.0.4/commons-logging-api-1.0.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 1316K from central
[artifact:dependencies] Downloading: tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;log4j:log4j:jar:1.2.16&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: log4j/log4j/1.2.16/log4j-1.2.16.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 470K from central
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-logging:commons-logging-api:jar:1.0.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-logging/commons-logging-api/1.0.4/commons-logging-api-1.0.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 26K from central
[artifact:dependencies] Downloading: org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer-ant:jar:2.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-ant/2.2/paranamer-ant-2.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 5K from central
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;tomcat:jasper-compiler:jar:5.5.12&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 396K from central
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils-core/1.8.3/commons-beanutils-core-1.8.3.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:httpcore:jar:4.1.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 177K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.avro:avro-mapred:jar:1.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 165K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-math/2.1/commons-math-2.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.codehaus.jackson:jackson-mapper-asl:jar:1.8.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 653K from central
[artifact:dependencies] Downloading: org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-beanutils:commons-beanutils-core:jar:1.8.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils-core/1.8.3/commons-beanutils-core-1.8.3.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 202K from central
[artifact:dependencies] Downloading: org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jetty-util:jar:6.1.26&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 173K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-math:jar:2.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-math/2.1/commons-math-2.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 813K from central
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-core/1.0.3/hadoop-core-1.0.3.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.thrift:libfb303:jar:0.9.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 269K from central
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-generator/2.2/paranamer-generator-2.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:antlr-runtime:jar:3.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 161K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.hadoop:hadoop-core:jar:1.0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-core/1.0.3/hadoop-core-1.0.3.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3836K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-log4j12:jar:1.6.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 10K from central
[artifact:dependencies] Downloading: org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer-generator:jar:2.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-generator/2.2/paranamer-generator-2.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 7K from central
[artifact:dependencies] Downloading: org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.avro:avro-ipc:jar:1.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 181K from central
[artifact:dependencies] Downloading: org/apache/hadoop/avro/1.3.2/avro-1.3.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:servlet-api:jar:2.5-20081211&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 131K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 1760K from datanucleus
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:stringtemplate:jar:3.2.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 145K from central
[artifact:dependencies] Downloading: org/antlr/ST4/4.0.4/ST4-4.0.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.hadoop:avro:jar:1.3.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/hadoop/avro/1.3.2/avro-1.3.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 332K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jsp-api-2.1:jar:6.1.14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 132K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:ST4:jar:4.0.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/ST4/4.0.4/ST4-4.0.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 231K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:servlet-api-2.5:jar:6.1.14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 129K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jsp-2.1:jar:6.1.14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1001K from central
[artifact:dependencies] Downloading: org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 1728K from datanucleus
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/build/lib/compile
     [copy] Copying 87 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/build/lib/compile
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/build/lib/provided
[artifact:dependencies] Downloading: org/apache/mina/mina-core/2.0.0-M5/mina-core-2.0.0-M5.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/apache/ftpserver/ftplet-api/1.0.0/ftplet-api-1.0.0.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/hamcrest/hamcrest-core/1.1/hamcrest-core-1.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: com/puppycrawl/tools/checkstyle/5.5/checkstyle-5.5.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: junit/junit/4.10/junit-4.10.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.mina:mina-core:jar:2.0.0-M5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/mina/mina-core/2.0.0-M5/mina-core-2.0.0-M5.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 623K from central
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-test/1.0.3/hadoop-test-1.0.3.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftplet-api:jar:1.0.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftplet-api/1.0.0/ftplet-api-1.0.0.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.puppycrawl.tools:checkstyle:jar:5.5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/puppycrawl/tools/checkstyle/5.5/checkstyle-5.5.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.hamcrest:hamcrest-core:jar:1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/hamcrest/hamcrest-core/1.1/hamcrest-core-1.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;junit:junit:jar:4.10&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: junit/junit/4.10/junit-4.10.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 22K from central
[artifact:dependencies] Transferring 623K from central
[artifact:dependencies] Transferring 75K from central
[artifact:dependencies] Transferring 247K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-core/1.0.0/ftpserver-core-1.0.0.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.hadoop:hadoop-test:jar:1.0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-test/1.0.3/hadoop-test-1.0.3.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2594K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftpserver-core:jar:1.0.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-core/1.0.0/ftpserver-core-1.0.0.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 265K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-deprecated/1.0.0-M2/ftpserver-deprecated-1.0.0-M2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftpserver-deprecated:jar:1.0.0-M2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-deprecated/1.0.0-M2/ftpserver-deprecated-1.0.0-M2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 31K from central
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/build/lib/test
     [copy] Copying 95 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/build/lib/test
    [touch] Creating /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/build/lib/.mvn-dependencies.complete

compile:
     [echo] hcatalog-core
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/build/classes
    [javac] Compiling 74 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/build/classes
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java:53: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.DefaultOutputCommitterContainer
    [javac]         getBaseOutputCommitter().abortTask(HCatMapRedUtil.createTaskAttemptContext(context));
    [javac]                                            ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java:58: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.DefaultOutputCommitterContainer
    [javac]         getBaseOutputCommitter().commitTask(HCatMapRedUtil.createTaskAttemptContext(context));
    [javac]                                             ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java:63: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.DefaultOutputCommitterContainer
    [javac]         return getBaseOutputCommitter().needsTaskCommit(HCatMapRedUtil.createTaskAttemptContext(context));
    [javac]                                                         ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java:68: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.DefaultOutputCommitterContainer
    [javac]         getBaseOutputCommitter().setupJob(HCatMapRedUtil.createJobContext(context));
    [javac]                                           ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java:73: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.DefaultOutputCommitterContainer
    [javac]         getBaseOutputCommitter().setupTask(HCatMapRedUtil.createTaskAttemptContext(context));
    [javac]                                            ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java:78: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.DefaultOutputCommitterContainer
    [javac]         getBaseOutputCommitter().abortJob(HCatMapRedUtil.createJobContext(jobContext), state);
    [javac]                                           ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java:84: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.DefaultOutputCommitterContainer
    [javac]         getBaseOutputCommitter().commitJob(HCatMapRedUtil.createJobContext(jobContext));
    [javac]                                            ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java:90: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.DefaultOutputCommitterContainer
    [javac]         getBaseOutputCommitter().cleanupJob(HCatMapRedUtil.createJobContext(context));
    [javac]                                             ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:104: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]             getBaseOutputCommitter().abortTask(HCatMapRedUtil.createTaskAttemptContext(context));
    [javac]                                                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:113: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]             getBaseOutputCommitter().commitTask(HCatMapRedUtil.createTaskAttemptContext(context));
    [javac]                                                 ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:120: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]             return getBaseOutputCommitter().needsTaskCommit(HCatMapRedUtil.createTaskAttemptContext(context));
    [javac]                                                             ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:130: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]             getBaseOutputCommitter().setupJob(HCatMapRedUtil.createJobContext(context));
    [javac]                                               ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:138: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]             getBaseOutputCommitter().setupTask(HCatMapRedUtil.createTaskAttemptContext(context));
    [javac]                                                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:148: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]             org.apache.hadoop.mapred.JobContext mapRedJobContext = HCatMapRedUtil
    [javac]                                                                    ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:202: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]                         HCatMapRedUtil.createJobContext(jobContext));
    [javac]                         ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:579: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]                         InternalUtil.createReporter(HCatMapRedUtil.createTaskAttemptContext(jobConf,
    [javac]                                                     ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:576: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]                     JobContext currContext = HCatMapRedUtil.createJobContext(
    [javac]                                              ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileRecordWriterContainer.java:181: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileRecordWriterContainer
    [javac]                 org.apache.hadoop.mapred.TaskAttemptContext currTaskContext = HCatMapRedUtil.createTaskAttemptContext(context);
    [javac]                                                                               ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileRecordWriterContainer.java:206: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileRecordWriterContainer
    [javac]                 org.apache.hadoop.mapred.JobContext currJobContext = HCatMapRedUtil.createJobContext(currTaskContext);
    [javac]                                                                      ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileRecordWriterContainer.java:211: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileRecordWriterContainer
    [javac]                     HCatMapRedUtil.createTaskAttemptContext(currJobContext.getJobConf(),
    [javac]                     ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] 20 errors

BUILD FAILED
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:327: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:166: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:168: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build.xml:68: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build-support/ant/build-common.xml:85: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build-support/ant/build-common.xml:55: Compile failed; see the compiler error output for details.

Total time: 6 minutes 58 seconds
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13756294" author="ashutoshc" created="Tue, 3 Sep 2013 01:07:42 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13756303" author="yhuai" created="Tue, 3 Sep 2013 01:47:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt; broke the build?&lt;/p&gt;</comment>
                            <comment id="13756601" author="yhuai" created="Tue, 3 Sep 2013 13:19:37 +0000"  >&lt;p&gt;trigger the pre-commit build &lt;/p&gt;</comment>
                            <comment id="13756867" author="hiveqa" created="Tue, 3 Sep 2013 18:24:07 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12601170/HIVE-5149.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12601170/HIVE-5149.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 2905 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_groupby2
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/592/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/592/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/592/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/592/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13756966" author="ashutoshc" created="Tue, 3 Sep 2013 19:34:18 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Yin!&lt;/p&gt;

&lt;p&gt;groupby2.q failed because .q.out needs update, which I did. TestMTQueries didn&apos;t fail for me and looks flaky. That test seems inordinately long time (&amp;gt;30 mins) to execute and seems like spend all its time waiting to release locks in ZK. There is some threading issue going on there. Needs some investigation.&lt;/p&gt;</comment>
                            <comment id="13756969" author="yhuai" created="Tue, 3 Sep 2013 19:38:31 +0000"  >&lt;p&gt;groupby2.q is also used in TestMTQueries. Probably the failure of TestMTQueries was also caused groupby2.&lt;/p&gt;</comment>
                            <comment id="13756975" author="ashutoshc" created="Tue, 3 Sep 2013 19:43:36 +0000"  >&lt;p&gt;Right. Yeah, likely that was the reason for TestMTQueries failures.&lt;/p&gt;</comment>
                            <comment id="13757338" author="hudson" created="Wed, 4 Sep 2013 00:57:32 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2 #402 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/402/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/402/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5149&quot; title=&quot;ReduceSinkDeDuplication can pick the wrong partitioning columns&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5149&quot;&gt;&lt;del&gt;HIVE-5149&lt;/del&gt;&lt;/a&gt; : ReduceSinkDeDuplication can pick the wrong partitioning columns (Yin Huai via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519805&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519805&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/ReduceSinkDeDuplication.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby2_map_skew.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby_cube1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby_rollup1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/reduce_deduplicate_extended.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13757857" author="hudson" created="Wed, 4 Sep 2013 15:16:15 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #83 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/83/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/83/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5149&quot; title=&quot;ReduceSinkDeDuplication can pick the wrong partitioning columns&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5149&quot;&gt;&lt;del&gt;HIVE-5149&lt;/del&gt;&lt;/a&gt; : ReduceSinkDeDuplication can pick the wrong partitioning columns (Yin Huai via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519805&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519805&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/ReduceSinkDeDuplication.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby2_map_skew.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby_cube1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby_rollup1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/reduce_deduplicate_extended.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13757960" author="hudson" created="Wed, 4 Sep 2013 17:03:17 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #150 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/150/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/150/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5149&quot; title=&quot;ReduceSinkDeDuplication can pick the wrong partitioning columns&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5149&quot;&gt;&lt;del&gt;HIVE-5149&lt;/del&gt;&lt;/a&gt; : ReduceSinkDeDuplication can pick the wrong partitioning columns (Yin Huai via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519805&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519805&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/ReduceSinkDeDuplication.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby2_map_skew.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby_cube1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby_rollup1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/reduce_deduplicate_extended.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13758030" author="hudson" created="Wed, 4 Sep 2013 17:43:12 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hive-trunk-h0.21 #2309 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2309/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2309/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5149&quot; title=&quot;ReduceSinkDeDuplication can pick the wrong partitioning columns&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5149&quot;&gt;&lt;del&gt;HIVE-5149&lt;/del&gt;&lt;/a&gt; : ReduceSinkDeDuplication can pick the wrong partitioning columns (Yin Huai via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519805&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519805&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/ReduceSinkDeDuplication.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby2_map_skew.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby_cube1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby_rollup1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/reduce_deduplicate_extended.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13758256" author="yhuai" created="Wed, 4 Sep 2013 19:39:54 +0000"  >&lt;p&gt;&quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5149&quot; title=&quot;ReduceSinkDeDuplication can pick the wrong partitioning columns&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5149&quot;&gt;&lt;del&gt;HIVE-5149&lt;/del&gt;&lt;/a&gt;-branch-0.11.patch&quot; is a 0.11 port&lt;/p&gt;</comment>
                            <comment id="13795841" author="ashutoshc" created="Tue, 15 Oct 2013 23:29:00 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12667331">HIVE-5237</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12601446" name="HIVE-5149-branch-0.11.patch" size="7072" author="yhuai" created="Wed, 4 Sep 2013 19:39:54 +0000"/>
                            <attachment id="12600221" name="HIVE-5149.1.patch" size="5261" author="yhuai" created="Tue, 27 Aug 2013 18:43:55 +0000"/>
                            <attachment id="12600442" name="HIVE-5149.2.patch" size="6686" author="yhuai" created="Wed, 28 Aug 2013 19:03:38 +0000"/>
                            <attachment id="12601170" name="HIVE-5149.3.patch" size="7376" author="yhuai" created="Tue, 3 Sep 2013 14:29:54 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 26 Aug 2013 21:07:22 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345383</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nk5r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345684</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5150] UnsatisfiedLinkError when running hive unit tests on Windows</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5150</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;When running any hive unit tests against hadoop 2.0, it will fail with error like this:&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Exception in thread &quot;main&quot; java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:423)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:933)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.hadoop.util.DiskChecker.checkAccessByFileMethods(DiskChecker.java:177)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.hadoop.util.DiskChecker.checkDirAccess(DiskChecker.java:164)&lt;/p&gt;


&lt;p&gt;This is due to the test process failed to find hadoop.dll. This is related to &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-5451&quot; title=&quot;MR uses LD_LIBRARY_PATH which doesn&amp;#39;t mean anything in Windows&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-5451&quot;&gt;&lt;del&gt;YARN-729&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</description>
                <environment>&lt;p&gt;Windows&lt;/p&gt;</environment>
        <key id="12665574">HIVE-5150</key>
            <summary>UnsatisfiedLinkError when running hive unit tests on Windows</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="shanyu">shanyu zhao</assignee>
                                    <reporter username="shanyu">shanyu zhao</reporter>
                        <labels>
                    </labels>
                <created>Mon, 26 Aug 2013 18:49:52 +0000</created>
                <updated>Thu, 13 Nov 2014 06:34:47 +0000</updated>
                            <resolved>Thu, 13 Nov 2014 06:34:47 +0000</resolved>
                                    <version>0.12.0</version>
                                                    <component>Testing Infrastructure</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13750401" author="shanyu" created="Mon, 26 Aug 2013 18:52:37 +0000"  >&lt;p&gt;Patch attached.&lt;/p&gt;</comment>
                            <comment id="13770141" author="shanyu" created="Tue, 17 Sep 2013 23:12:09 +0000"  >&lt;p&gt;Fix the encoding of previous patch&lt;/p&gt;</comment>
                            <comment id="13950151" author="alangates" created="Thu, 27 Mar 2014 23:44:35 +0000"  >&lt;p&gt;Patch no longer applies.&lt;/p&gt;</comment>
                            <comment id="14209254" author="hiveqa" created="Thu, 13 Nov 2014 04:34:47 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12603708/HIVE-5150.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12603708/HIVE-5150.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1763/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1763/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1763/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1763/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1763/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1763/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-1763/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&apos;
Reverted &apos;metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&apos;
Reverted &apos;metastore/src/java/org/apache/hadoop/hive/metastore/StatObjectConverter.java&apos;
Reverted &apos;common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&apos;
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20/target shims/0.20S/target shims/0.23/target shims/aggregator/target shims/common/target shims/common-secure/target shims/scheduler/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit-hadoop2/target itests/hive-minikdc/target itests/hive-unit/target itests/custom-serde/target itests/util/target hcatalog/target hcatalog/core/target hcatalog/streaming/target hcatalog/server-extensions/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target hcatalog/hcatalog-pig-adapter/target accumulo-handler/target hwi/target common/target common/src/gen service/target contrib/target serde/target beeline/target odbc/target cli/target ql/dependency-reduced-pom.xml ql/target
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1639245.

At revision 1639245.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12603708 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14209359" author="ashutoshc" created="Thu, 13 Nov 2014 06:34:47 +0000"  >&lt;p&gt;After move to maven based system, cant repro this anymore.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12603708" name="HIVE-5150.patch" size="1163" author="shanyu" created="Tue, 17 Sep 2013 23:12:09 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 27 Mar 2014 23:44:35 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345514</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 10 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nkyv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345815</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5151] Going green: Container re-cycling in Tez</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5151</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Tez reuses containers to schedule tasks from same and different vertices in the same JVM. It also offers an API to reuse objects across vertices, dags and sessions.&lt;/p&gt;

&lt;p&gt;For hive we should reuse the operator plan as well as any hash tables (map join).&lt;/p&gt;

&lt;p&gt;NO PRECOMMIT TESTS (this is wip for the tez branch)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665586">HIVE-5151</key>
            <summary>Going green: Container re-cycling in Tez</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hagleitn">Gunther Hagleitner</assignee>
                                    <reporter username="hagleitn">Gunther Hagleitner</reporter>
                        <labels>
                    </labels>
                <created>Mon, 26 Aug 2013 20:27:50 +0000</created>
                <updated>Tue, 27 Aug 2013 00:25:07 +0000</updated>
                            <resolved>Tue, 27 Aug 2013 00:25:07 +0000</resolved>
                                                    <fixVersion>tez-branch</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                    <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12651047">HIVE-4660</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12600013" name="HIVE-5151.1.patch" size="14130" author="hagleitn" created="Mon, 26 Aug 2013 20:29:59 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345526</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 22 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nl1j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345827</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5152] Vector operators should inherit from non-vector operators for code re-use.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5152</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;In many cases vectorized operators could share code from non-vector operators by inheriting.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665593">HIVE-5152</key>
            <summary>Vector operators should inherit from non-vector operators for code re-use.</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jnp">Jitendra Nath Pandey</assignee>
                                    <reporter username="jnp">Jitendra Nath Pandey</reporter>
                        <labels>
                    </labels>
                <created>Mon, 26 Aug 2013 20:53:54 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:17 +0000</updated>
                            <resolved>Tue, 3 Sep 2013 19:04:53 +0000</resolved>
                                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13756920" author="ashutoshc" created="Tue, 3 Sep 2013 18:58:54 +0000"  >&lt;p&gt;For completeness, shall we make VectorFileSinkOp extend from FileSinkOp. Or is that not worthwhile?&lt;/p&gt;</comment>
                            <comment id="13756921" author="ashutoshc" created="Tue, 3 Sep 2013 19:00:37 +0000"  >&lt;p&gt;Oh sorry missed that one. VectorFS already extends from FS.&lt;/p&gt;</comment>
                            <comment id="13756930" author="ashutoshc" created="Tue, 3 Sep 2013 19:04:53 +0000"  >&lt;p&gt;Committed to branch. Thanks, Jitendra!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12600019" name="HIVE-5152.1.patch" size="14788" author="jnp" created="Mon, 26 Aug 2013 20:55:35 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 3 Sep 2013 18:58:54 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345533</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 20 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nl33:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345834</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5153] current database in hive prompt in cli remote mode is incorrect</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5153</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2233&quot; title=&quot;Show current database in hive prompt&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2233&quot;&gt;&lt;del&gt;HIVE-2233&lt;/del&gt;&lt;/a&gt; added a feature to show current database on hive cli prompt. &lt;br/&gt;
The current implementation will work only with local mode. It will not work if you try connecting to hive server (v1) from hive cli. &lt;/p&gt;

&lt;p&gt;This is because it relies on the Hive object in current thread to have the right current database information. But when remote mode is used, the client side Hive object does not get updated when database is changed.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665601">HIVE-5153</key>
            <summary>current database in hive prompt in cli remote mode is incorrect</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="thejas">Thejas M Nair</reporter>
                        <labels>
                    </labels>
                <created>Mon, 26 Aug 2013 21:46:28 +0000</created>
                <updated>Mon, 26 Aug 2013 21:47:44 +0000</updated>
                                            <version>0.8.0</version>
                    <version>0.8.1</version>
                    <version>0.9.0</version>
                    <version>0.10.0</version>
                    <version>0.11.0</version>
                                                    <component>CLI</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13750596" author="thejas" created="Mon, 26 Aug 2013 21:47:44 +0000"  >&lt;p&gt;Note that this is not an issue with beeline+hive-server2 which in my opinion is the recommended client and server to be used.&lt;/p&gt;
</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345541</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 22 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nl4v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345842</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-5154] Remove unnecessary array creation in ReduceSinkOperator</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5154</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Key array is created for each row, which seemed not necessary.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665644">HIVE-5154</key>
            <summary>Remove unnecessary array creation in ReduceSinkOperator</summary>
                <type id="3" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21148&amp;avatarType=issuetype">Task</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.svg">Trivial</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis</assignee>
                                    <reporter username="navis">Navis</reporter>
                        <labels>
                    </labels>
                <created>Tue, 27 Aug 2013 03:31:26 +0000</created>
                <updated>Sun, 22 Sep 2013 21:32:55 +0000</updated>
                            <resolved>Sun, 22 Sep 2013 15:52:00 +0000</resolved>
                                                    <fixVersion>0.13.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13750942" author="phabricator@reviews.facebook.net" created="Tue, 27 Aug 2013 04:00:52 +0000"  >&lt;p&gt;navis requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5154&quot; title=&quot;Remove unnecessary array creation in ReduceSinkOperator&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5154&quot;&gt;&lt;del&gt;HIVE-5154&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Remove unnecessary array creation in ReduceSinkOperator&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5154&quot; title=&quot;Remove unnecessary array creation in ReduceSinkOperator&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5154&quot;&gt;&lt;del&gt;HIVE-5154&lt;/del&gt;&lt;/a&gt; Remove unnecessary array creation in ReduceSinkOperator&lt;/p&gt;

&lt;p&gt;Key array is created for each row, which seemed not necessary.&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12549&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12549&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/30117/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/30117/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13773912" author="phabricator@reviews.facebook.net" created="Sat, 21 Sep 2013 21:51:52 +0000"  >&lt;p&gt;ashutoshc has accepted the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5154&quot; title=&quot;Remove unnecessary array creation in ReduceSinkOperator&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5154&quot;&gt;&lt;del&gt;HIVE-5154&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Remove unnecessary array creation in ReduceSinkOperator&quot;.&lt;/p&gt;

&lt;p&gt;  +1&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12549&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12549&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5154&quot; title=&quot;Remove unnecessary array creation in ReduceSinkOperator&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5154&quot;&gt;&lt;del&gt;HIVE-5154&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;/p&gt;</comment>
                            <comment id="13774014" author="ashutoshc" created="Sun, 22 Sep 2013 15:52:00 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Navis!&lt;/p&gt;</comment>
                            <comment id="13774095" author="hudson" created="Sun, 22 Sep 2013 21:32:55 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2 #451 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/451/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/451/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5154&quot; title=&quot;Remove unnecessary array creation in ReduceSinkOperator&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5154&quot;&gt;&lt;del&gt;HIVE-5154&lt;/del&gt;&lt;/a&gt; : Remove unnecessary array creation in ReduceSinkOperator (Navis via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1525381&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1525381&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12600089" name="HIVE-5154.D12549.1.patch" size="3292" author="phabricator@reviews.facebook.net" created="Tue, 27 Aug 2013 04:00:52 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 27 Aug 2013 04:00:52 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345584</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 18 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nlef:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345885</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5155] Support secure proxy user access to HiveServer2</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5155</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The HiveServer2 can authenticate a client using via Kerberos and impersonate the connecting user with underlying secure hadoop. This becomes a gateway for a remote client to access secure hadoop cluster. Now this works fine for when the client obtains Kerberos ticket and directly connects to HiveServer2. There&apos;s another big use case for middleware tools where the end user wants to access Hive via another server. For example Oozie action or Hue submitting queries or a BI tool server accessing to HiveServer2. In these cases, the third party server doesn&apos;t have end user&apos;s Kerberos credentials and hence it can&apos;t submit queries to HiveServer2 on behalf of the end user.&lt;/p&gt;

&lt;p&gt;This ticket is for enabling proxy access to HiveServer2 for third party tools on behalf of end users. There are two parts of the solution proposed in this ticket:&lt;br/&gt;
1) Delegation token based connection for Oozie (&lt;a href=&quot;https://issues.apache.org/jira/browse/OOZIE-1457&quot; title=&quot;Create a Hive Server 2 action&quot; class=&quot;issue-link&quot; data-issue-key=&quot;OOZIE-1457&quot;&gt;&lt;del&gt;OOZIE-1457&lt;/del&gt;&lt;/a&gt;)&lt;br/&gt;
This is the common mechanism for Hadoop ecosystem components. Hive Remote Metastore and HCatalog already support this. This is suitable for tool like Oozie that submits the MR jobs as actions on behalf of its client. Oozie already uses similar mechanism for Metastore/HCatalog access.&lt;/p&gt;

&lt;p&gt;2) Direct proxy access for privileged hadoop users&lt;br/&gt;
The delegation token implementation can be a challenge for non-hadoop (especially non-java) components. This second part enables a privileged user to directly specify an alternate session user during the connection. If the connecting user has hadoop level privilege to impersonate the requested userid, then HiveServer2 will run the session as that requested user. For example, user Hue is allowed to impersonate user Bob (via core-site.xml proxy user configuration). Then user Hue can connect to HiveServer2 and specify Bob as session user via a session property. HiveServer2 will verify Hue&apos;s proxy user privilege and then impersonate user Bob instead of Hue. This will enable any third party tool to impersonate alternate userid without having to implement delegation token connection.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665668">HIVE-5155</key>
            <summary>Support secure proxy user access to HiveServer2</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="prasadm">Prasad Mujumdar</assignee>
                                    <reporter username="prasadm">Prasad Mujumdar</reporter>
                        <labels>
                            <label>TODOC13</label>
                    </labels>
                <created>Tue, 27 Aug 2013 08:32:46 +0000</created>
                <updated>Fri, 4 Mar 2016 22:36:25 +0000</updated>
                            <resolved>Wed, 12 Mar 2014 11:06:43 +0000</resolved>
                                    <version>0.12.0</version>
                                    <fixVersion>0.13.0</fixVersion>
                                    <component>Authentication</component>
                    <component>HiveServer2</component>
                    <component>JDBC</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>19</watches>
                                                                <comments>
                            <comment id="13751082" author="prasadm" created="Tue, 27 Aug 2013 08:40:56 +0000"  >&lt;p&gt;Simple client application to test various direct and proxy connection to HiveServer2 &lt;/p&gt;</comment>
                            <comment id="13751084" author="prasadm" created="Tue, 27 Aug 2013 08:44:26 +0000"  >&lt;p&gt;Review request at &lt;a href=&quot;https://reviews.apache.org/r/13845/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/13845/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13762727" author="prasadm" created="Tue, 10 Sep 2013 04:52:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; Would you like to take a look at the patch ?&lt;/p&gt;</comment>
                            <comment id="13766860" author="prasadm" created="Fri, 13 Sep 2013 19:44:55 +0000"  >&lt;p&gt;Rebased with latest trunk&lt;/p&gt;</comment>
                            <comment id="13767558" author="hiveqa" created="Sat, 14 Sep 2013 19:51:47 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12603083/HIVE-5155.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12603083/HIVE-5155.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 3107 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hive.jdbc.TestJdbcDriver2.testBadURL
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/745/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/745/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/745/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/745/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13780139" author="tucu00" created="Fri, 27 Sep 2013 17:41:25 +0000"  >&lt;p&gt;We would like to include support for HiveServer2 in Oozie, &lt;a href=&quot;https://issues.apache.org/jira/browse/OOZIE-1457&quot; title=&quot;Create a Hive Server 2 action&quot; class=&quot;issue-link&quot; data-issue-key=&quot;OOZIE-1457&quot;&gt;&lt;del&gt;OOZIE-1457&lt;/del&gt;&lt;/a&gt;. Any ETA on this JIRA getting committed and in a Hive release?&lt;/p&gt;</comment>
                            <comment id="13780162" author="brocknoland" created="Fri, 27 Sep 2013 17:55:35 +0000"  >&lt;p&gt;I agree that oozie support would be great. 0.12 would be ideal. Prasad, can you upload the v3 patch without thrift?&lt;/p&gt;</comment>
                            <comment id="13780169" author="prasadm" created="Fri, 27 Sep 2013 18:01:31 +0000"  >&lt;p&gt;Sure, I will rebase again and upload attach the with-thrift patch for test run. Thanks!&lt;/p&gt;</comment>
                            <comment id="13781534" author="prasadm" created="Sun, 29 Sep 2013 23:49:36 +0000"  >&lt;p&gt;Rebased patch without thrift generated code.&lt;/p&gt;</comment>
                            <comment id="13781536" author="prasadm" created="Sun, 29 Sep 2013 23:51:34 +0000"  >&lt;p&gt;Test program to exercise proxy connection options with output.&lt;/p&gt;</comment>
                            <comment id="13781537" author="prasadm" created="Sun, 29 Sep 2013 23:52:25 +0000"  >&lt;p&gt;Rebased patch&lt;/p&gt;</comment>
                            <comment id="13786501" author="prasadm" created="Fri, 4 Oct 2013 18:59:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; Can we please consider this for 0.12. Its also blocking Oozie. Thanks!&lt;/p&gt;</comment>
                            <comment id="13786514" author="thejas" created="Fri, 4 Oct 2013 19:10:57 +0000"  >&lt;p&gt;Sorry about the delay in looking at the patch. I was hoping to get an RC out for 0.12 this weekend, and was planning to add only any blocker bug fixes to the branch until then. I will take a look at the patch tonight and see if I can get it into 0.12 .&lt;/p&gt;</comment>
                            <comment id="13786926" author="thejas" created="Sat, 5 Oct 2013 04:06:47 +0000"  >&lt;p&gt;This looks like a very valuable feature, but it is also a big one (new interfaces). I will not be able to finish reviewing it tonight. I will try to finish reviewing over the weekend. &lt;br/&gt;
I think it is too late to include this major feature in hive 0.12. I have been including only important bug fixes in last few days to stabilize the release (as I earlier mentioned in the email to dev list) . I am sorry, I should have reviewed it earlier so that we had enough time. &lt;/p&gt;</comment>
                            <comment id="13786933" author="prasadm" created="Sat, 5 Oct 2013 04:41:39 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; no problem. I agree that it would be a bit risky to add large feature just before the RC.&lt;br/&gt;
Let&apos;s try get this into 0.13. Please take a look when you get a chance. Thanks!&lt;/p&gt;</comment>
                            <comment id="13840506" author="prasadm" created="Thu, 5 Dec 2013 20:04:25 +0000"  >&lt;p&gt;Attached a Ad hoc integration test and results. It requires Kerberos and secure cluster setup.&lt;/p&gt;</comment>
                            <comment id="13859731" author="shivshi" created="Tue, 31 Dec 2013 21:58:35 +0000"  >&lt;p&gt;I am trying to accomplish the same task, i.e end user wants to access Hive via middleware server and the middleware server doesn&apos;t have access to the credentials. I looked at it from a different angle though using Subject.doAs and could get it working with a little hack on the client side(no changes to hive binaries). I Wanted to check if there are any issues with this approach.  Please see the attached file TestKERBEROS_Hive_JDBC.java. Obviously, the hack is not a good way to go, longer term it needs to be addressed in the Hive/Hadoop code, but wanted to point what is missing in the Hive code to accomplish support for multi-user kerberos support through middleware server. &lt;/p&gt;</comment>
                            <comment id="13859735" author="shivshi" created="Tue, 31 Dec 2013 22:03:54 +0000"  >&lt;p&gt;Test Script for Subject.doAs().&lt;/p&gt;</comment>
                            <comment id="13862038" author="shivshi" created="Fri, 3 Jan 2014 23:47:03 +0000"  >&lt;p&gt;It is important to note that the middle ware server does not have access to Principal&apos;s credentials. All it has is a javax.security.auth.Subject(&quot;Subject&quot;) from the end-user(Principal) and can do a Subject.doAS() to connect to HiveServer2. In Proposal 2, the middle ware server is expected to have access to Hadoop-level super-user&apos;s credentials(by doing &quot;kinit&quot;) or it has the Subject from a Hadoop-level super-user which has been passed on to it. In the code I have attached above, I am trying to show that any end-user&apos;s Subject can be effectively used to connect to HiveServer2 using Subject.doAs() in the middle ware server. This  will allow multi-user kerberos access through the middleware server without additional requirements of proxy access. I might have overlooked or be unaware of some limitations of such an approach, so I am soliciting feedback to check that.&lt;/p&gt;</comment>
                            <comment id="13865934" author="thejas" created="Wed, 8 Jan 2014 21:44:16 +0000"  >&lt;p&gt;Hi Prasad,&lt;br/&gt;
Sorry about the delay in reviewing this. I have added some comments to reviewboard.&lt;/p&gt;</comment>
                            <comment id="13865960" author="thejas" created="Wed, 8 Jan 2014 22:04:42 +0000"  >&lt;p&gt;Can you also please add the documentation for this change to the release note section, including example of the hive connection string to be used for proxy user. We can work on putting it in appropriate sections in wiki once this is committed.&lt;/p&gt;</comment>
                            <comment id="13878955" author="owen.omalley" created="Wed, 22 Jan 2014 18:22:00 +0000"  >&lt;p&gt;Since this patch is adding proxy users for HiveServer2, it really should include the same ability to limit the authority of the proxy users that the other Hadoop tools have. To make it consistent with Hadoop, the configuration would look like:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hive.server2.proxyuser.HS.hosts&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;host1,host2&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hive.server2.proxyuser.HS.groups&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;group1,group2&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;which configures HS as a hive server2 proxy user and limits it to working on a specified set of hosts (or * for all) and impersonating a specified group of users (or * for all).&lt;/p&gt;</comment>
                            <comment id="13900893" author="prasadm" created="Thu, 13 Feb 2014 23:33:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; Thanks! I will rebase the patch and add dock notes.&lt;/p&gt;</comment>
                            <comment id="13900906" author="thejas" created="Thu, 13 Feb 2014 23:48:06 +0000"  >&lt;p&gt;Prasad, I also have some comments in review board. One of them is on the lines of Owen&apos;s comment above.&lt;/p&gt;</comment>
                            <comment id="13908714" author="thejas" created="Fri, 21 Feb 2014 19:25:56 +0000"  >&lt;p&gt;Prasad, It would be great to get this patch in for 0.13 release.&lt;br/&gt;
I think just the issue of proxy user config parameter needs to be addressed. ie having a specific config for HS2 proxy privileges so that the user does not have to be made a hdfs/MR wide proxy user.&lt;/p&gt;</comment>
                            <comment id="13909729" author="lefty@hortonworks.com" created="Sun, 23 Feb 2014 09:53:45 +0000"  >&lt;p&gt;Just for the record:  patch noThrift.6 adds &lt;b&gt;hive.server2.allow.user.substitution&lt;/b&gt; to HiveConf.java and hive-default.xml.template.&lt;/p&gt;</comment>
                            <comment id="13910530" author="prasadm" created="Mon, 24 Feb 2014 17:25:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; My apologies for the delay. I was busy with a bunch of other things and didn&apos;t get a chance to revisit the patch. I will take a look at the review comments and update the patch soon. Thanks!&lt;/p&gt;</comment>
                            <comment id="13915198" author="thejas" created="Thu, 27 Feb 2014 23:27:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;Prasad Mujumdar&lt;/a&gt; Thanks Prasad. Please see if you can contribute this for 0.13 release.&lt;/p&gt;
</comment>
                            <comment id="13916642" author="vgumashta" created="Sat, 1 Mar 2014 00:38:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;Prasad Mujumdar&lt;/a&gt; I agree it will be very useful in 0.13. &lt;/p&gt;

&lt;p&gt;Prasad, let me know if you&apos;d like me to pitch in; I have some free cycles. Thanks! &lt;/p&gt;</comment>
                            <comment id="13918341" author="prasadm" created="Mon, 3 Mar 2014 18:13:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; I responded to your comments on the review board. Please let me your feedback.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;~vaibhavgumashta&amp;#93;&lt;/span&gt; Thanks for the offer. I am working on rebase and testing the updated patch.&lt;/p&gt;</comment>
                            <comment id="13918410" author="thejas" created="Mon, 3 Mar 2014 18:48:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;Prasad Mujumdar&lt;/a&gt; Yes, I think putting this in hive-site.xml is a reasonable way to restrict proxy user privileges to hs2.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;Owen O&apos;Malley&lt;/a&gt; Please refer to the conversation in reviewboard about the config settings. &lt;/p&gt;</comment>
                            <comment id="13918428" author="vgumashta" created="Mon, 3 Mar 2014 19:03:16 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;Prasad Mujumdar&lt;/a&gt; Thanks a lot for the heads up Prasad!&lt;/p&gt;</comment>
                            <comment id="13920152" author="prasadm" created="Tue, 4 Mar 2014 22:51:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; &amp;amp; &lt;span class=&quot;error&quot;&gt;&amp;#91;~vaibhavgumashta&amp;#93;&lt;/span&gt; The rebased patch is attached and review updated y&apos;day. I found a minor rebase conflict that I just fixed. Please take a look when you get a chance. Thanks!&lt;/p&gt;</comment>
                            <comment id="13923887" author="vgumashta" created="Fri, 7 Mar 2014 13:57:39 +0000"  >&lt;p&gt;+1 (non-binding). Latest patch looks good to me. Thanks for the patch &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;Prasad Mujumdar&lt;/a&gt;!&lt;/p&gt;</comment>
                            <comment id="13924104" author="thejas" created="Fri, 7 Mar 2014 17:48:48 +0000"  >&lt;p&gt;+1&lt;br/&gt;
I have a question - Should we cancel the token from HiveSession.close() ? (Even if it is a good thing, we can do it in a followup jira).&lt;/p&gt;</comment>
                            <comment id="13924140" author="thejas" created="Fri, 7 Mar 2014 18:13:59 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;Prasad Mujumdar&lt;/a&gt; Can you upload the patch with thrift generated files so that the tests can run on it ?&lt;/p&gt;</comment>
                            <comment id="13924220" author="prasadm" created="Fri, 7 Mar 2014 19:07:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; and &lt;span class=&quot;error&quot;&gt;&amp;#91;~vaibhavgumashta&amp;#93;&lt;/span&gt; Thanks for the review&lt;br/&gt;
I agree that it&apos;s good to cancel the token at the end of the session. There&apos;s a GC thread that removes the expired tokens, but the default interval is 1day. I will log a followup ticket and submit a patch.&lt;/p&gt;</comment>
                            <comment id="13924221" author="prasadm" created="Fri, 7 Mar 2014 19:08:56 +0000"  >&lt;p&gt;Full patch with thrift generated code. Rebased with trunk, had a conflict in hive-default.xml.template that&apos;s is resolved.&lt;/p&gt;</comment>
                            <comment id="13925185" author="hiveqa" created="Sun, 9 Mar 2014 11:42:09 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12633424/HIVE-5155.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12633424/HIVE-5155.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 5375 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hive.jdbc.TestSSL.testSSLConnectionWithProperty
org.apache.hive.jdbc.TestSSL.testSSLConnectionWithURL
org.apache.hive.jdbc.TestSSL.testSSLFetch
org.apache.hive.service.cli.session.TestSessionHooks.testProxyUser
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1673/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1673/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1673/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1673/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12633424&lt;/p&gt;</comment>
                            <comment id="13925532" author="thejas" created="Mon, 10 Mar 2014 07:58:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;Prasad Mujumdar&lt;/a&gt; Can you please check if the test failures are caused by the patch ?&lt;/p&gt;</comment>
                            <comment id="13925875" author="prasadm" created="Mon, 10 Mar 2014 16:42:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; will take a look shortly. Thanks!&lt;/p&gt;</comment>
                            <comment id="13926027" author="prasadm" created="Mon, 10 Mar 2014 18:41:52 +0000"  >&lt;p&gt;Address test ptest failures.&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Fixed TestSessionHooks test&lt;/li&gt;
	&lt;li&gt;Removed the extra transport getting layered in JDBC connection&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Diff without generated code is added to review request.&lt;/p&gt;</comment>
                            <comment id="13930276" author="thejas" created="Tue, 11 Mar 2014 12:15:36 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13931205" author="hiveqa" created="Wed, 12 Mar 2014 00:37:27 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12633746/HIVE-5155.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12633746/HIVE-5155.5.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 5378 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1705/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1705/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1705/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1705/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12633746&lt;/p&gt;</comment>
                            <comment id="13931470" author="vgumashta" created="Wed, 12 Mar 2014 07:11:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;Prasad Mujumdar&lt;/a&gt; Actually one thing I noticed we missed: bumping up the version number to V7 (since we changed the thrift interface)... Sorry for pointing out so late. But we can take that up in a follow up patch. &lt;/p&gt;</comment>
                            <comment id="13931545" author="prasadm" created="Wed, 12 Mar 2014 08:45:10 +0000"  >&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;~vaibhavgumashta&amp;#93;&lt;/span&gt; Good catch. Given that we are changing the version on every major interface change, this should cover that as well. It&apos;s a trivial change, I do have a patch ready.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; let me know if you want to review another update for this ticket or update that in a follow up patch. Thanks!&lt;/p&gt;

</comment>
                            <comment id="13931550" author="vgumashta" created="Wed, 12 Mar 2014 08:55:23 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;Prasad Mujumdar&lt;/a&gt; I agree. It would be awesome if you can post the new patch. &lt;/p&gt;

&lt;p&gt;I have one more comment (I&apos;ll add to rb), but we can definitely take that up in a follow up jira &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13931560" author="thejas" created="Wed, 12 Mar 2014 09:05:47 +0000"  >&lt;p&gt;I am planning to commit this soon, lets increment the version number in a followup jira.&lt;/p&gt;</comment>
                            <comment id="13931595" author="vgumashta" created="Wed, 12 Mar 2014 09:51:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;Prasad Mujumdar&lt;/a&gt; Left a comment on rb, but I think if &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6312&quot; title=&quot;doAs with plain sasl auth should be session aware&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6312&quot;&gt;&lt;del&gt;HIVE-6312&lt;/del&gt;&lt;/a&gt; (by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt;) gets in, it will address the issue. Thanks!&lt;/p&gt;</comment>
                            <comment id="13931640" author="thejas" created="Wed, 12 Mar 2014 11:06:43 +0000"  >&lt;p&gt;Patch committed to trunk and 0.13 branch (this is included in the list for 0.13 maintained by Harish).&lt;br/&gt;
Thanks for the contribution &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;Prasad Mujumdar&lt;/a&gt;. Thanks for reviews Vaibhav, Brock.&lt;/p&gt;</comment>
                            <comment id="13935616" author="vgumashta" created="Fri, 14 Mar 2014 20:47:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;Prasad Mujumdar&lt;/a&gt; I think we should add release / usage notes for this. &lt;/p&gt;</comment>
                            <comment id="13954617" author="lefty@hortonworks.com" created="Sun, 30 Mar 2014 08:28:57 +0000"  >&lt;p&gt;I agree with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vgumashta&quot; class=&quot;user-hover&quot; rel=&quot;vgumashta&quot;&gt;Vaibhav Gumashta&lt;/a&gt;, this needs release / usage notes.  Also documentation in the wiki.&lt;/p&gt;

&lt;p&gt;I can add &lt;b&gt;hive.server2.allow.user.substitution&lt;/b&gt; to the Configuration Properties doc, but someone else should document the concepts and usage.  &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;Prasad Mujumdar&lt;/a&gt;, would that be your task?&lt;/p&gt;</comment>
                            <comment id="13959722" author="vgumashta" created="Fri, 4 Apr 2014 07:45:21 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;Prasad Mujumdar&lt;/a&gt;, I had a question: &lt;a href=&quot;https://reviews.apache.org/r/13845/#comment71937&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/13845/#comment71937&lt;/a&gt;. Thanks!&lt;/p&gt;
</comment>
                            <comment id="13959723" author="vgumashta" created="Fri, 4 Apr 2014 07:46:59 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;Prasad Mujumdar&lt;/a&gt; The relevant question is regarding the intent of (hiveAuthFactory == null) in ThriftCLIService. Thanks!&lt;/p&gt;</comment>
                            <comment id="14038076" author="mrajah" created="Thu, 19 Jun 2014 23:10:24 +0000"  >&lt;p&gt;the bug is marked as fixed are there release notes or guide to using this feature?&lt;/p&gt;</comment>
                            <comment id="14068247" author="lefty@hortonworks.com" created="Mon, 21 Jul 2014 06:16:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;the bug is marked as fixed are there release notes or guide to using this feature?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not that I know of, but if we keep posting doc requests maybe someone will provide the information.&lt;/p&gt;</comment>
                            <comment id="14084408" author="lefty@hortonworks.com" created="Mon, 4 Aug 2014 07:51:04 +0000"  >&lt;p&gt;While documenting &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6486&quot; title=&quot;Support secure Subject.doAs() in HiveServer2 JDBC client.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6486&quot;&gt;&lt;del&gt;HIVE-6486&lt;/del&gt;&lt;/a&gt; &amp;#8211; secure Subject.doAs() &amp;#8211; I put some information from this jira&apos;s description in the wiki here:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Clients#HiveServer2Clients-Multi-UserScenariosandProgrammaticLogintoKerberosKDC&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HiveServer2 Clients &amp;#8211; JDBC Client Setup for a Secure Cluster &amp;#8211; Multi-User Scenarios and Programmatic Login to Kerberos KDC &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;It&apos;s a work in progress so reviews, suggestions, and revisions are encouraged.  In particular, the heading isn&apos;t optimal.  And a new subsection with guidance and examples for secure proxy users would be helpful.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12700917">HIVE-6625</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12658124">OOZIE-1457</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12696706">HIVE-6486</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12703365">HIVE-6738</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12944798">HIVE-13169</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12600116" name="HIVE-5155-1-nothrift.patch" size="46182" author="prasadm" created="Tue, 27 Aug 2013 08:37:49 +0000"/>
                            <attachment id="12602515" name="HIVE-5155-noThrift.2.patch" size="46180" author="prasadm" created="Wed, 11 Sep 2013 03:56:48 +0000"/>
                            <attachment id="12605841" name="HIVE-5155-noThrift.4.patch" size="43885" author="prasadm" created="Sun, 29 Sep 2013 23:52:25 +0000"/>
                            <attachment id="12617051" name="HIVE-5155-noThrift.5.patch" size="61290" author="prasadm" created="Wed, 4 Dec 2013 20:15:03 +0000"/>
                            <attachment id="12617229" name="HIVE-5155-noThrift.6.patch" size="63073" author="prasadm" created="Thu, 5 Dec 2013 20:10:12 +0000"/>
                            <attachment id="12632463" name="HIVE-5155-noThrift.7.patch" size="84394" author="prasadm" created="Tue, 4 Mar 2014 08:07:40 +0000"/>
                            <attachment id="12632692" name="HIVE-5155-noThrift.8.patch" size="84385" author="prasadm" created="Tue, 4 Mar 2014 22:47:58 +0000"/>
                            <attachment id="12600117" name="HIVE-5155.1.patch" size="357655" author="prasadm" created="Tue, 27 Aug 2013 08:37:49 +0000"/>
                            <attachment id="12602514" name="HIVE-5155.2.patch" size="357653" author="prasadm" created="Wed, 11 Sep 2013 03:56:48 +0000"/>
                            <attachment id="12603083" name="HIVE-5155.3.patch" size="357295" author="prasadm" created="Fri, 13 Sep 2013 19:44:55 +0000"/>
                            <attachment id="12633424" name="HIVE-5155.4.patch" size="398093" author="prasadm" created="Fri, 7 Mar 2014 19:08:56 +0000"/>
                            <attachment id="12633746" name="HIVE-5155.5.patch" size="397929" author="prasadm" created="Mon, 10 Mar 2014 18:41:52 +0000"/>
                            <attachment id="12617227" name="ProxyAuth.java" size="12105" author="prasadm" created="Thu, 5 Dec 2013 20:04:25 +0000"/>
                            <attachment id="12617228" name="ProxyAuth.out" size="13251" author="prasadm" created="Thu, 5 Dec 2013 20:04:25 +0000"/>
                            <attachment id="12620987" name="TestKERBEROS_Hive_JDBC.java" size="5068" author="shivshi" created="Tue, 31 Dec 2013 22:03:54 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>15.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 14 Sep 2013 19:51:47 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345608</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 25 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nljr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345909</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5156] HiveServer2 jdbc ResultSet.close should free up resources on server side</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5156</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;ResultSet.close does not free up any resources (tmp files etc) on hive server.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665674">HIVE-5156</key>
            <summary>HiveServer2 jdbc ResultSet.close should free up resources on server side</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vgumashta">Vaibhav Gumashta</assignee>
                                    <reporter username="vgumashta">Vaibhav Gumashta</reporter>
                        <labels>
                    </labels>
                <created>Tue, 27 Aug 2013 09:19:12 +0000</created>
                <updated>Tue, 15 Oct 2013 23:31:38 +0000</updated>
                            <resolved>Fri, 20 Sep 2013 01:41:57 +0000</resolved>
                                    <version>0.12.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                    <component>HiveServer2</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13762838" author="vgumashta" created="Tue, 10 Sep 2013 08:09:42 +0000"  >&lt;p&gt;WIP patch for review here: &lt;a href=&quot;https://reviews.facebook.net/D12837&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12837&lt;/a&gt; &lt;/p&gt;</comment>
                            <comment id="13770011" author="thejas" created="Tue, 17 Sep 2013 21:34:12 +0000"  >&lt;p&gt;+1 &lt;br/&gt;
Can you please open a new jira to address the issue that HiveStatement is not calling ResultSet.close when it should ?&lt;br/&gt;
&lt;a href=&quot;http://docs.oracle.com/javase/7/docs/api/java/sql/ResultSet.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://docs.oracle.com/javase/7/docs/api/java/sql/ResultSet.html&lt;/a&gt; - A ResultSet object is automatically closed when the Statement object that generated it is closed, re-executed, or used to retrieve the next result from a sequence of multiple results.&lt;/p&gt;</comment>
                            <comment id="13770023" author="vgumashta" created="Tue, 17 Sep 2013 21:44:02 +0000"  >&lt;p&gt;Thanks Thejas, created the new JIRA here: &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5305&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-5305&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13770231" author="hiveqa" created="Wed, 18 Sep 2013 00:37:59 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12603651/HIVE-5156.D12837.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12603651/HIVE-5156.D12837.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/789/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/789/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/789/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/789/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-789/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&apos;
Reverted &apos;ql/src/test/results/clientnegative/alter_table_add_partition.q.out&apos;
Reverted &apos;ql/src/test/results/clientnegative/alter_view_failure5.q.out&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ awk &apos;{print $2}&apos;
++ svn status --no-ignore
+ rm -rf build hcatalog/build hcatalog/core/build hcatalog/storage-handlers/hbase/build hcatalog/server-extensions/build hcatalog/webhcat/svr/build hcatalog/webhcat/java-client/build hcatalog/hcatalog-pig-adapter/build common/src/gen ql/src/test/results/clientnegative/illegal_partition_type.q.out ql/src/test/results/clientnegative/illegal_partition_type2.q.out ql/src/test/results/clientpositive/parititon_type_check.q.out ql/src/test/results/clientpositive/partition_type_check.q.out ql/src/test/queries/clientnegative/illegal_partition_type.q ql/src/test/queries/clientnegative/illegal_partition_type2.q ql/src/test/queries/clientpositive/partition_type_check.q
+ svn update
U    ql/src/test/queries/clientpositive/udaf_collect_set.q
U    ql/src/test/results/clientpositive/show_functions.q.out
U    ql/src/test/results/clientpositive/udaf_collect_set.q.out
U    ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCollectSet.java
U    hcatalog/webhcat/svr/src/main/bin/webhcat_config.sh
U    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/Server.java
U    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HiveDelegator.java
U    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/Main.java
A    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JobItemBean.java
U    hcatalog/src/test/e2e/templeton/tests/jobsubmission.conf

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
Updated external to revision 1524262.

Updated to revision 1524262.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java
patching file jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java
patching file jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java
Hunk #13 succeeded at 848 (offset 7 lines).
Hunk #14 succeeded at 892 (offset 7 lines).
Hunk #15 succeeded at 919 (offset 7 lines).
Hunk #16 succeeded at 980 (offset 19 lines).
Hunk #17 succeeded at 1000 (offset 19 lines).
Hunk #18 succeeded at 1023 (offset 19 lines).
Hunk #19 succeeded at 1076 (offset 19 lines).
Hunk #20 succeeded at 1119 (offset 19 lines).
Hunk #21 succeeded at 1343 (offset 19 lines).
+ [[ true == \t\r\u\e ]]
+ rm -rf /data/hive-ptest/working/ivy /data/hive-ptest/working/maven
+ mkdir /data/hive-ptest/working/ivy /data/hive-ptest/working/maven
+ ant -Dtest.continue.on.failure=true -Dtest.silent=false -Divy.default.ivy.user.dir=/data/hive-ptest/working/ivy -Dmvn.local.repo=/data/hive-ptest/working/maven clean package test -Dtestcase=nothing
Buildfile: /data/hive-ptest/working/apache-svn-trunk-source/build.xml

clean:
     [echo] Project: hive

clean:
     [echo] Project: anttasks

clean:
     [echo] Project: shims

clean:
     [echo] Project: common

clean:
     [echo] Project: serde

clean:
     [echo] Project: metastore

clean:
     [echo] Project: ql

clean:
     [echo] Project: contrib

clean:
     [echo] Project: service

clean:
     [echo] Project: cli

clean:
     [echo] Project: jdbc

clean:
     [echo] Project: beeline

clean:
     [echo] Project: hwi

clean:
     [echo] Project: hbase-handler

clean:
     [echo] Project: testutils

clean:
     [echo] hcatalog

clean:
     [echo] hcatalog-core

clean:
     [echo] hcatalog-pig-adapter

clean:
     [echo] hcatalog-server-extensions

clean:
     [echo] webhcat

clean:
     [echo] webhcat-java-client

clean:

clean:
     [echo] Project: odbc
     [exec] rm -rf /data/hive-ptest/working/apache-svn-trunk-source/build/odbc /data/hive-ptest/working/apache-svn-trunk-source/build/service/objs /data/hive-ptest/working/apache-svn-trunk-source/build/ql/objs /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/objs

clean-online:
     [echo] Project: hive

clean-offline:

ivy-init-dirs:
     [echo] Project: hive
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/maven

ivy-download:
     [echo] Project: hive
      [get] Getting: http://repo2.maven.org/maven2/org/apache/ivy/ivy/2.3.0/ivy-2.3.0.jar
      [get] To: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/ivy-2.3.0.jar

ivy-probe-antlib:
     [echo] Project: hive

ivy-init-antlib:
     [echo] Project: hive

compile-ant-tasks:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jexl/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

ivy-init-settings:
     [echo] Project: anttasks

ivy-resolve:
     [echo] Project: anttasks
[ivy:resolve] :: Apache Ivy 2.3.0 - 20130110142753 :: http://ant.apache.org/ivy/ ::
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-anttasks;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found velocity#velocity;1.5 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-lang/commons-lang/2.4/commons-lang-2.4.jar ...
[ivy:resolve] ..... (255kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-lang#commons-lang;2.4!commons-lang.jar (30ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/velocity/velocity/1.5/velocity-1.5.jar ...
[ivy:resolve] ....... (382kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] velocity#velocity;1.5!velocity.jar (24ms)
[ivy:resolve] :: resolution report :: resolve 5625ms :: artifacts dl 75ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-anttasks-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-anttasks-default.html

ivy-retrieve:
     [echo] Project: anttasks
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-anttasks
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	2 artifacts copied, 0 already retrieved (638kB/11ms)

compile:
     [echo] anttasks
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ant/build.xml:38: warning: &apos;includeantruntime&apos; was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds
    [javac] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.

deploy-ant-tasks:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

ivy-init-settings:
     [echo] Project: anttasks

ivy-resolve:
     [echo] Project: anttasks
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-anttasks;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found velocity#velocity;1.5 in maven2
[ivy:resolve] :: resolution report :: resolve 451ms :: artifacts dl 2ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-anttasks-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-anttasks-default.html

ivy-retrieve:
     [echo] Project: anttasks
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-anttasks
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	0 artifacts copied, 2 already retrieved (0kB/8ms)

compile:
     [echo] anttasks
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ant/build.xml:38: warning: &apos;includeantruntime&apos; was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds

jar:
     [echo] anttasks
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes/org/apache/hadoop/hive/ant
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/hive-anttasks-0.13.0-SNAPSHOT.jar

init:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

create-dirs:
     [echo] Project: shims
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/test/resources does not exist.

init:
     [echo] Project: shims

create-dirs:
     [echo] Project: common
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/resources
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/resources

init:
     [echo] Project: common

create-dirs:
     [echo] Project: serde
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources does not exist.

init:
     [echo] Project: serde

create-dirs:
     [echo] Project: metastore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources does not exist.

init:
     [echo] Project: metastore

create-dirs:
     [echo] Project: ql
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/resources
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/resources

init:
     [echo] Project: ql

create-dirs:
     [echo] Project: contrib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources does not exist.

init:
     [echo] Project: contrib

create-dirs:
     [echo] Project: service
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources does not exist.

init:
     [echo] Project: service

create-dirs:
     [echo] Project: cli
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/resources does not exist.

init:
     [echo] Project: cli

create-dirs:
     [echo] Project: jdbc
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/test/resources does not exist.

init:
     [echo] Project: jdbc

create-dirs:
     [echo] Project: beeline
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/test/resources does not exist.

init:
     [echo] Project: beeline

create-dirs:
     [echo] Project: hwi
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources does not exist.

init:
     [echo] Project: hwi

create-dirs:
     [echo] Project: hbase-handler
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources does not exist.

init:
     [echo] Project: hbase-handler

create-dirs:
     [echo] Project: testutils
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources does not exist.

init:
     [echo] Project: testutils

init:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build/hcatalog-0.13.0-SNAPSHOT

jar:
     [echo] Project: hive

ivy-init-settings:
     [echo] Project: shims

check-ivy:
     [echo] Project: shims

ivy-resolve:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.zookeeper#zookeeper;3.4.3 in maven2
[ivy:resolve] 	found org.apache.thrift#libthrift;0.9.0 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.4 in maven2
[ivy:resolve] 	found commons-logging#commons-logging-api;1.0.4 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.4 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar ...
[ivy:resolve] .............. (749kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.3!zookeeper.jar (50ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar ...
[ivy:resolve] ....... (339kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.thrift#libthrift;0.9.0!libthrift.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging/1.0.4/commons-logging-1.0.4.jar ...
[ivy:resolve] .. (37kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-logging#commons-logging;1.0.4!commons-logging.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging-api/1.0.4/commons-logging-api-1.0.4.jar ...
[ivy:resolve] .. (25kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-logging#commons-logging-api;1.0.4!commons-logging-api.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar ...
[ivy:resolve] ..... (222kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-core-asl;1.8.8!jackson-core-asl.jar (46ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar ...
[ivy:resolve] ............. (652kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-mapper-asl;1.8.8!jackson-mapper-asl.jar (18ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/log4j/log4j/1.2.16/log4j-1.2.16.jar ...
[ivy:resolve] ......... (470kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] log4j#log4j;1.2.16!log4j.jar(bundle) (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/guava/guava/11.0.2/guava-11.0.2.jar ...
[ivy:resolve] ........................... (1609kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.guava#guava;11.0.2!guava.jar (34ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-io/commons-io/2.4/commons-io-2.4.jar ...
[ivy:resolve] .... (180kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-io#commons-io;2.4!commons-io.jar (9ms)
[ivy:resolve] :: resolution report :: resolve 9037ms :: artifacts dl 227ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   9   |   9   |   0   ||   9   |   9   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-shims-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-shims-default.html

make-pom:
     [echo] Project: shims
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: shims
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/test/resources does not exist.

init:
     [echo] Project: shims

ivy-retrieve:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	9 artifacts copied, 0 already retrieved (4287kB/38ms)

compile:
     [echo] Project: shims
     [echo] Building shims 0.20

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20/java against hadoop 0.20.2 (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-0.20.2)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.20.shim]
[ivy:resolve] 	found org.apache.hadoop#hadoop-core;0.20.2 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.0.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.3 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.3 in maven2
[ivy:resolve] 	found commons-net#commons-net;1.4.1 in maven2
[ivy:resolve] 	found oro#oro;2.0.8 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api-2.5;6.1.14 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.12 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.12 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-api-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.eclipse.jdt#core;3.1.1 in maven2
[ivy:resolve] 	found ant#ant;1.6.5 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.7.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found net.sf.kosmosfs#kfs;0.3 in maven2
[ivy:resolve] 	found junit#junit;4.5 in maven2
[ivy:resolve] 	found hsqldb#hsqldb;1.8.0.10 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-tools;0.20.2 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-test;0.20.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftplet-api;1.0.0 in maven2
[ivy:resolve] 	found org.apache.mina#mina-core;2.0.0-M5 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.5.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-core;1.0.0 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-core/0.20.2/hadoop-core-0.20.2.jar ...
[ivy:resolve] ............................................ (2624kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-core;0.20.2!hadoop-core.jar (55ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-tools/0.20.2/hadoop-tools-0.20.2.jar ...
[ivy:resolve] ... (68kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-tools;0.20.2!hadoop-tools.jar (16ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-test/0.20.2/hadoop-test-0.20.2.jar ...
[ivy:resolve] .......................... (1527kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-test;0.20.2!hadoop-test.jar (32ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-cli/commons-cli/1.2/commons-cli-1.2.jar ...
[ivy:resolve] .. (40kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-cli#commons-cli;1.2!commons-cli.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/xmlenc/xmlenc/0.52/xmlenc-0.52.jar ...
[ivy:resolve] .. (14kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] xmlenc#xmlenc;0.52!xmlenc.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar ...
[ivy:resolve] ...... (273kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-httpclient#commons-httpclient;3.0.1!commons-httpclient.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-codec/commons-codec/1.3/commons-codec-1.3.jar ...
[ivy:resolve] .. (45kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-codec#commons-codec;1.3!commons-codec.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar ...
[ivy:resolve] .... (176kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-net#commons-net;1.4.1!commons-net.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty/6.1.14/jetty-6.1.14.jar ...
[ivy:resolve] ......... (504kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty;6.1.14!jetty.jar (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.14/jetty-util-6.1.14.jar ...
[ivy:resolve] .... (159kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty-util;6.1.14!jetty-util.jar (24ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar ...
[ivy:resolve] ... (74kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-runtime;5.5.12!jasper-runtime.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar ...
[ivy:resolve] ........ (395kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-compiler;5.5.12!jasper-compiler.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar ...
[ivy:resolve] .... (131kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jsp-api-2.1;6.1.14!jsp-api-2.1.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar ...
[ivy:resolve] ................. (1000kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jsp-2.1;6.1.14!jsp-2.1.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-el/commons-el/1.0/commons-el-1.0.jar ...
[ivy:resolve] ... (109kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-el#commons-el;1.0!commons-el.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar ...
[ivy:resolve] ....... (368kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.java.dev.jets3t#jets3t;0.7.1!jets3t.jar (42ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar ...
[ivy:resolve] .... (129kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#servlet-api-2.5;6.1.14!servlet-api-2.5.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar ...
[ivy:resolve] .. (11kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.sf.kosmosfs#kfs;0.3!kfs.jar (36ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/4.5/junit-4.5.jar ...
[ivy:resolve] ..... (194kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] junit#junit;4.5!junit.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar ...
[ivy:resolve] ............ (690kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] hsqldb#hsqldb;1.8.0.10!hsqldb.jar (22ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/oro/oro/2.0.8/oro-2.0.8.jar ...
[ivy:resolve] .. (63kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] oro#oro;2.0.8!oro.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar ...
[ivy:resolve] .......................................................................................... (3483kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.eclipse.jdt#core;3.1.1!core.jar (75ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/ant/ant/1.6.5/ant-1.6.5.jar ...
[ivy:resolve] ................. (1009kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] ant#ant;1.6.5!ant.jar (33ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar ...
[ivy:resolve] .. (59kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-logging#commons-logging;1.1.1!commons-logging.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftplet-api/1.0.0/ftplet-api-1.0.0.jar ...
[ivy:resolve] .. (22kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftplet-api;1.0.0!ftplet-api.jar(bundle) (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/mina/mina-core/2.0.0-M5/mina-core-2.0.0-M5.jar ...
[ivy:resolve] ........... (622kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.mina#mina-core;2.0.0-M5!mina-core.jar(bundle) (16ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftpserver-core/1.0.0/ftpserver-core-1.0.0.jar ...
[ivy:resolve] ...... (264kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftpserver-core;1.0.0!ftpserver-core.jar(bundle) (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftpserver-deprecated/1.0.0-M2/ftpserver-deprecated-1.0.0-M2.jar ...
[ivy:resolve] .. (31kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2!ftpserver-deprecated.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.5.2/slf4j-api-1.5.2.jar ...
[ivy:resolve] .. (16kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-api;1.5.2!slf4j-api.jar (36ms)
[ivy:resolve] :: resolution report :: resolve 32966ms :: artifacts dl 658ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	junit#junit;3.8.1 by [junit#junit;4.5] in [hadoop0.20.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.0.3 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20.shim]
[ivy:resolve] 	commons-codec#commons-codec;1.2 by [commons-codec#commons-codec;1.3] in [hadoop0.20.shim]
[ivy:resolve] 	commons-httpclient#commons-httpclient;3.1 by [commons-httpclient#commons-httpclient;3.0.1] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M4 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.ftpserver#ftplet-api;1.0.0-M2 by [org.apache.ftpserver#ftplet-api;1.0.0] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.ftpserver#ftpserver-core;1.0.0-M2 by [org.apache.ftpserver#ftpserver-core;1.0.0] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M2 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20.shim]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|  hadoop0.20.shim |   37  |   30  |   30  |   8   ||   29  |   29  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.20.shim]
[ivy:retrieve] 	29 artifacts copied, 0 already retrieved (14115kB/57ms)
    [javac] Compiling 17 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [echo] Building shims 0.20S

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/common-secure/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20S/java against hadoop 1.1.2 (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-1.1.2)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.20S.shim]
[ivy:resolve] 	found org.apache.hadoop#hadoop-core;1.1.2 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-core;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-json;1.8 in maven2
[ivy:resolve] 	found org.codehaus.jettison#jettison;1.1 in maven2
[ivy:resolve] 	found stax#stax-api;1.0.1 in maven2
[ivy:resolve] 	found com.sun.xml.bind#jaxb-impl;2.2.3-1 in maven2
[ivy:resolve] 	found javax.xml.bind#jaxb-api;2.2.2 in maven2
[ivy:resolve] 	found javax.xml.stream#stax-api;1.0-2 in maven2
[ivy:resolve] 	found javax.activation#activation;1.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-jaxrs;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-xc;1.7.1 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-server;1.8 in maven2
[ivy:resolve] 	found asm#asm;3.1 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.1 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.0.1 in maven2
[ivy:resolve] 	found junit#junit;3.8.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.3 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.commons#commons-math;2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found commons-digester#commons-digester;1.8 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils;1.7.0 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils-core;1.8.0 in maven2
[ivy:resolve] 	found commons-net#commons-net;1.4.1 in maven2
[ivy:resolve] 	found oro#oro;2.0.8 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api;2.5-20081211 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.12 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.12 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-api-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api-2.5;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.eclipse.jdt#core;3.1.1 in maven2
[ivy:resolve] 	found ant#ant;1.6.5 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.6.1 in maven2
[ivy:resolve] 	found hsqldb#hsqldb;1.8.0.10 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-tools;1.1.2 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-test;1.1.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftplet-api;1.0.0 in maven2
[ivy:resolve] 	found org.apache.mina#mina-core;2.0.0-M5 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.5.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-core;1.0.0 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-core/1.1.2/hadoop-core-1.1.2.jar ...
[ivy:resolve] ............................................................................................... (3941kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-core;1.1.2!hadoop-core.jar (82ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-tools/1.1.2/hadoop-tools-1.1.2.jar ...
[ivy:resolve] ...... (299kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-tools;1.1.2!hadoop-tools.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-test/1.1.2/hadoop-test-1.1.2.jar ...
[ivy:resolve] .............................................. (2712kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-test;1.1.2!hadoop-test.jar (53ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar ...
[ivy:resolve] ........ (447kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-core;1.8!jersey-core.jar(bundle) (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar ...
[ivy:resolve] .... (144kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-json;1.8!jersey-json.jar(bundle) (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar ...
[ivy:resolve] ............. (678kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-server;1.8!jersey-server.jar(bundle) (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-io/commons-io/2.1/commons-io-2.1.jar ...
[ivy:resolve] .... (159kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-io#commons-io;2.1!commons-io.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-codec/commons-codec/1.4/commons-codec-1.4.jar ...
[ivy:resolve] .. (56kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-codec#commons-codec;1.4!commons-codec.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-math/2.1/commons-math-2.1.jar ...
[ivy:resolve] ............... (812kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.commons#commons-math;2.1!commons-math.jar (20ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar ...
[ivy:resolve] ...... (291kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-configuration#commons-configuration;1.6!commons-configuration.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar ...
[ivy:resolve] .......... (527kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty;6.1.26!jetty.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar ...
[ivy:resolve] .... (172kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty-util;6.1.26!jetty-util.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar ...
[ivy:resolve] ...... (314kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.java.dev.jets3t#jets3t;0.6.1!jets3t.jar (25ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar ...
[ivy:resolve] ... (66kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jettison#jettison;1.1!jettison.jar(bundle) (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar ...
[ivy:resolve] ............... (869kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.xml.bind#jaxb-impl;2.2.3-1!jaxb-impl.jar (37ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.7.1/jackson-jaxrs-1.7.1.jar ...
[ivy:resolve] .. (17kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-jaxrs;1.7.1!jackson-jaxrs.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar ...
[ivy:resolve] .. (30kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-xc;1.7.1!jackson-xc.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/stax/stax-api/1.0.1/stax-api-1.0.1.jar ...
[ivy:resolve] .. (25kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] stax#stax-api;1.0.1!stax-api.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar ...
[ivy:resolve] ... (102kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.xml.bind#jaxb-api;2.2.2!jaxb-api.jar (21ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar ...
[ivy:resolve] .. (22kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.xml.stream#stax-api;1.0-2!stax-api.jar (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/activation/activation/1.1/activation-1.1.jar ...
[ivy:resolve] .. (61kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.activation#activation;1.1!activation.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/asm/asm/3.1/asm-3.1.jar ...
[ivy:resolve] .. (42kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] asm#asm;3.1!asm.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/3.8.1/junit-3.8.1.jar ...
[ivy:resolve] ... (118kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] junit#junit;3.8.1!junit.jar (21ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar ...
[ivy:resolve] .......... (561kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-collections#commons-collections;3.2.1!commons-collections.jar (35ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-digester/commons-digester/1.8/commons-digester-1.8.jar ...
[ivy:resolve] .... (140kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-digester#commons-digester;1.8!commons-digester.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar ...
[ivy:resolve] ..... (201kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-beanutils#commons-beanutils-core;1.8.0!commons-beanutils-core.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar ...
[ivy:resolve] .... (184kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-beanutils#commons-beanutils;1.7.0!commons-beanutils.jar (21ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar ...
[ivy:resolve] .... (130kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#servlet-api;2.5-20081211!servlet-api.jar (9ms)
[ivy:resolve] :: resolution report :: resolve 32216ms :: artifacts dl 713ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	org.codehaus.jackson#jackson-core-asl;1.7.1 by [org.codehaus.jackson#jackson-core-asl;1.8.8] in [hadoop0.20S.shim]
[ivy:resolve] 	org.codehaus.jackson#jackson-mapper-asl;1.7.1 by [org.codehaus.jackson#jackson-mapper-asl;1.8.8] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.0.3 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-codec#commons-codec;1.2 by [commons-codec#commons-codec;1.4] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.1 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-codec#commons-codec;1.3 by [commons-codec#commons-codec;1.4] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-httpclient#commons-httpclient;3.1 by [commons-httpclient#commons-httpclient;3.0.1] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M4 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.ftpserver#ftplet-api;1.0.0-M2 by [org.apache.ftpserver#ftplet-api;1.0.0] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.ftpserver#ftpserver-core;1.0.0-M2 by [org.apache.ftpserver#ftpserver-core;1.0.0] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M2 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20S.shim]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	| hadoop0.20S.shim |   62  |   30  |   30  |   11  ||   51  |   28  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.20S.shim]
[ivy:retrieve] 	51 artifacts copied, 0 already retrieved (22876kB/86ms)
    [javac] Compiling 15 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [echo] Building shims 0.23

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/common-secure/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.23/java against hadoop 2.1.0-beta (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-2.1.0-beta)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.23.shim]
[ivy:resolve] 	found org.apache.hadoop#hadoop-common;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-annotations;2.1.0-beta in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-math;2.1 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.1 in maven2
[ivy:resolve] 	found commons-net#commons-net;3.1 in maven2
[ivy:resolve] 	found javax.servlet#servlet-api;2.5 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.26 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-core;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-json;1.8 in maven2
[ivy:resolve] 	found org.codehaus.jettison#jettison;1.1 in maven2
[ivy:resolve] 	found stax#stax-api;1.0.1 in maven2
[ivy:resolve] 	found com.sun.xml.bind#jaxb-impl;2.2.3-1 in maven2
[ivy:resolve] 	found javax.xml.bind#jaxb-api;2.2.2 in maven2
[ivy:resolve] 	found javax.activation#activation;1.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-jaxrs;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-xc;1.8.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-server;1.8 in maven2
[ivy:resolve] 	found asm#asm;3.2 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.17 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.6.1 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.5 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-digester#commons-digester;1.8 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils;1.7.0 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils-core;1.8.0 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.5.3 in maven2
[ivy:resolve] 	found com.thoughtworks.paranamer#paranamer;2.3 in maven2
[ivy:resolve] 	found org.xerial.snappy#snappy-java;1.0.3.2 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.5.0 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-auth;2.1.0-beta in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found com.jcraft#jsch;0.1.42 in maven2
[ivy:resolve] 	found org.apache.zookeeper#zookeeper;3.4.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.23 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.23 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found javax.servlet.jsp#jsp-api;2.1 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-core;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-common;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-api;2.1.0-beta in maven2
[ivy:resolve] 	found com.google.inject.extensions#guice-servlet;3.0 in maven2
[ivy:resolve] 	found com.google.inject#guice;3.0 in maven2
[ivy:resolve] 	found javax.inject#javax.inject;1 in maven2
[ivy:resolve] 	found aopalliance#aopalliance;1.0 in maven2
[ivy:resolve] 	found org.sonatype.sisu.inject#cglib;2.2.1-v20090111 in maven2
[ivy:resolve] 	found io.netty#netty;3.5.11.Final in maven2
[ivy:resolve] 	found com.sun.jersey.jersey-test-framework#jersey-test-framework-grizzly2;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey.contribs#jersey-guice;1.8 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-archives;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-hdfs;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-common;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-client;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-common;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-tests;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-nodemanager;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-resourcemanager;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-web-proxy;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-app;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.1.0-beta in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-hs;2.1.0-beta in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.1.0-beta/hadoop-common-2.1.0-beta.jar ...
[ivy:resolve] ................................................. (2656kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-common;2.1.0-beta!hadoop-common.jar (91ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.1.0-beta/hadoop-common-2.1.0-beta-tests.jar ...
[ivy:resolve] ....................... (1321kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-common;2.1.0-beta!hadoop-common.jar(tests) (38ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-core/2.1.0-beta/hadoop-mapreduce-client-core-2.1.0-beta.jar ...
[ivy:resolve] ....................... (1340kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-core;2.1.0-beta!hadoop-mapreduce-client-core.jar (47ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-archives/2.1.0-beta/hadoop-archives-2.1.0-beta.jar ...
[ivy:resolve] .. (20kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-archives;2.1.0-beta!hadoop-archives.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.1.0-beta/hadoop-hdfs-2.1.0-beta.jar ...
[ivy:resolve] ................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. (5092kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs;2.1.0-beta!hadoop-hdfs.jar (404ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.1.0-beta/hadoop-hdfs-2.1.0-beta-tests.jar ...
[ivy:resolve] ................................ (1897kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs;2.1.0-beta!hadoop-hdfs.jar(tests) (50ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.1.0-beta/hadoop-mapreduce-client-jobclient-2.1.0-beta.jar ...
[ivy:resolve] .. (33kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.1.0-beta!hadoop-mapreduce-client-jobclient.jar (25ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.1.0-beta/hadoop-mapreduce-client-jobclient-2.1.0-beta-tests.jar ...
[ivy:resolve] ....................... (1395kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.1.0-beta!hadoop-mapreduce-client-jobclient.jar(tests) (47ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-common/2.1.0-beta/hadoop-mapreduce-client-common-2.1.0-beta.jar ...
[ivy:resolve] ............ (638kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-common;2.1.0-beta!hadoop-mapreduce-client-common.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-tests/2.1.0-beta/hadoop-yarn-server-tests-2.1.0-beta-tests.jar ...
[ivy:resolve] .. (33kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-tests;2.1.0-beta!hadoop-yarn-server-tests.jar(tests) (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-app/2.1.0-beta/hadoop-mapreduce-client-app-2.1.0-beta.jar ...
[ivy:resolve] ......... (461kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-app;2.1.0-beta!hadoop-mapreduce-client-app.jar (30ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-hs/2.1.0-beta/hadoop-mapreduce-client-hs-2.1.0-beta.jar ...
[ivy:resolve] ... (113kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-hs;2.1.0-beta!hadoop-mapreduce-client-hs.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-annotations/2.1.0-beta/hadoop-annotations-2.1.0-beta.jar ...
[ivy:resolve] .. (16kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-annotations;2.1.0-beta!hadoop-annotations.jar (44ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar ...
[ivy:resolve] ...... (297kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-httpclient#commons-httpclient;3.1!commons-httpclient.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-net/commons-net/3.1/commons-net-3.1.jar ...
[ivy:resolve] ...... (266kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-net#commons-net;3.1!commons-net.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar ...
[ivy:resolve] ... (102kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.servlet#servlet-api;2.5!servlet-api.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/log4j/log4j/1.2.17/log4j-1.2.17.jar ...
[ivy:resolve] ......... (478kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] log4j#log4j;1.2.17!log4j.jar(bundle) (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-lang/commons-lang/2.5/commons-lang-2.5.jar ...
[ivy:resolve] ...... (272kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-lang#commons-lang;2.5!commons-lang.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar ...
[ivy:resolve] .. (24kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-api;1.6.1!slf4j-api.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro/1.5.3/avro-1.5.3.jar ...
[ivy:resolve] ...... (257kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro;1.5.3!avro.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar ...
[ivy:resolve] .......... (520kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.protobuf#protobuf-java;2.5.0!protobuf-java.jar(bundle) (33ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-auth/2.1.0-beta/hadoop-auth-2.1.0-beta.jar ...
[ivy:resolve] .. (46kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-auth;2.1.0-beta!hadoop-auth.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar ...
[ivy:resolve] .... (181kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.jcraft#jsch;0.1.42!jsch.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.2/zookeeper-3.4.2.jar ...
[ivy:resolve] ............. (746kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.2!zookeeper.jar (25ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-compress/1.4/commons-compress-1.4.jar ...
[ivy:resolve] ..... (233kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.commons#commons-compress;1.4!commons-compress.jar (29ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar ...
[ivy:resolve] .. (32kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.code.findbugs#jsr305;1.3.9!jsr305.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.8.8/jackson-jaxrs-1.8.8.jar ...
[ivy:resolve] .. (17kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-jaxrs;1.8.8!jackson-jaxrs.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.8.8/jackson-xc-1.8.8.jar ...
[ivy:resolve] .. (31kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-xc;1.8.8!jackson-xc.jar (59ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/asm/asm/3.2/asm-3.2.jar ...
[ivy:resolve] .. (42kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] asm#asm;3.2!asm.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar ...
[ivy:resolve] .. (28kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.3!paranamer.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.0.3.2/snappy-java-1.0.3.2.jar ...
[ivy:resolve] ................. (972kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.0.3.2!snappy-java.jar(bundle) (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar ...
[ivy:resolve] .. (9kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-log4j12;1.6.1!slf4j-log4j12.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/tukaani/xz/1.0/xz-1.0.jar ...
[ivy:resolve] ... (92kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.tukaani#xz;1.0!xz.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar ...
[ivy:resolve] ........ (398kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-compiler;5.5.23!jasper-compiler.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar ...
[ivy:resolve] ... (75kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-runtime;5.5.23!jasper-runtime.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar ...
[ivy:resolve] ... (98kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.servlet.jsp#jsp-api;2.1!jsp-api.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-common/2.1.0-beta/hadoop-yarn-common-2.1.0-beta.jar ...
[ivy:resolve] ...................... (1263kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-common;2.1.0-beta!hadoop-yarn-common.jar (69ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar ...
[ivy:resolve] .. (63kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.inject.extensions#guice-servlet;3.0!guice-servlet.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/io/netty/netty/3.5.11.Final/netty-3.5.11.Final.jar ...
[ivy:resolve] ................... (1106kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] io.netty#netty;3.5.11.Final!netty.jar(bundle) (27ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-api/2.1.0-beta/hadoop-yarn-api-2.1.0-beta.jar ...
[ivy:resolve] .................... (1125kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-api;2.1.0-beta!hadoop-yarn-api.jar (30ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/inject/guice/3.0/guice-3.0.jar ...
[ivy:resolve] ............. (693kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.inject#guice;3.0!guice.jar (18ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-test-framework/jersey-test-framework-grizzly2/1.8/jersey-test-framework-grizzly2-1.8.jar ...
[ivy:resolve] .. (12kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey.jersey-test-framework#jersey-test-framework-grizzly2;1.8!jersey-test-framework-grizzly2.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/contribs/jersey-guice/1.8/jersey-guice-1.8.jar ...
[ivy:resolve] .. (14kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey.contribs#jersey-guice;1.8!jersey-guice.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/inject/javax.inject/1/javax.inject-1.jar ...
[ivy:resolve] .. (2kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.inject#javax.inject;1!javax.inject.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/aopalliance/aopalliance/1.0/aopalliance-1.0.jar ...
[ivy:resolve] .. (4kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] aopalliance#aopalliance;1.0!aopalliance.jar (27ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/sonatype/sisu/inject/cglib/2.2.1-v20090111/cglib-2.2.1-v20090111.jar ...
[ivy:resolve] ...... (272kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.sonatype.sisu.inject#cglib;2.2.1-v20090111!cglib.jar (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-client/2.1.0-beta/hadoop-yarn-client-2.1.0-beta.jar ...
[ivy:resolve] ... (84kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-client;2.1.0-beta!hadoop-yarn-client.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-common/2.1.0-beta/hadoop-yarn-server-common-2.1.0-beta.jar ...
[ivy:resolve] .... (171kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-common;2.1.0-beta!hadoop-yarn-server-common.jar (27ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.1.0-beta/hadoop-yarn-server-nodemanager-2.1.0-beta.jar ...
[ivy:resolve] ......... (451kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-nodemanager;2.1.0-beta!hadoop-yarn-server-nodemanager.jar (20ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.1.0-beta/hadoop-yarn-server-resourcemanager-2.1.0-beta.jar ...
[ivy:resolve] ............ (585kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-resourcemanager;2.1.0-beta!hadoop-yarn-server-resourcemanager.jar (24ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.1.0-beta/hadoop-yarn-server-web-proxy-2.1.0-beta.jar ...
[ivy:resolve] .. (24kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-web-proxy;2.1.0-beta!hadoop-yarn-server-web-proxy.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.1.0-beta/hadoop-mapreduce-client-shuffle-2.1.0-beta.jar ...
[ivy:resolve] .. (21kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.1.0-beta!hadoop-mapreduce-client-shuffle.jar (34ms)
[ivy:resolve] :: resolution report :: resolve 52812ms :: artifacts dl 1614ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|  hadoop0.23.shim |   75  |   49  |   49  |   0   ||   78  |   52  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.23.shim]
[ivy:retrieve] 	78 artifacts copied, 0 already retrieved (34675kB/154ms)
    [javac] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.23/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.

jar:
     [echo] Project: shims
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-shims;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Tue Sep 17 20:36:02 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-shims
[ivy:publish] 	published hive-shims to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.13.0-SNAPSHOT/jars/hive-shims.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: common

check-ivy:
     [echo] Project: common

ivy-resolve:
     [echo] Project: common
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-common;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.13.0-SNAPSHOT/jars/hive-shims.jar ...
[ivy:resolve] .... (145kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-shims;0.13.0-SNAPSHOT!hive-shims.jar (4ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar ...
[ivy:resolve] ..... (235kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.commons#commons-compress;1.4.1!commons-compress.jar (10ms)
[ivy:resolve] :: resolution report :: resolve 1402ms :: artifacts dl 19ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   6   |   2   |   2   |   0   ||   6   |   2   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-common-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-common-default.html

make-pom:
     [echo] Project: common
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/common/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: common

init:
     [echo] Project: common

setup:
     [echo] Project: common

ivy-retrieve:
     [echo] Project: common
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-common
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	4 artifacts copied, 2 already retrieved (513kB/9ms)

compile:
     [echo] Project: common
    [javac] Compiling 27 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/common/src/java/org/apache/hadoop/hive/common/ObjectPair.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes

jar:
     [echo] Project: common
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/common/hive-common-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-common;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Tue Sep 17 20:36:07 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/common/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-common
[ivy:publish] 	published hive-common to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.13.0-SNAPSHOT/jars/hive-common.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: serde

check-ivy:
     [echo] Project: serde

ivy-resolve:
     [echo] Project: serde
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-serde;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-common;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.13.0-SNAPSHOT/jars/hive-common.jar ...
[ivy:resolve] ... (97kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-common;0.13.0-SNAPSHOT!hive-common.jar (4ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar ...
[ivy:resolve] ...................... (1315kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mockito#mockito-all;1.8.2!mockito-all.jar (35ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar ...
[ivy:resolve] ...... (268kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.thrift#libfb303;0.9.0!libfb303.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro/1.7.1/avro-1.7.1.jar ...
[ivy:resolve] ...... (290kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro;1.7.1!avro.jar (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar ...
[ivy:resolve] .... (164kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro-mapred;1.7.1!avro-mapred.jar (10ms)
[ivy:resolve] :: resolution report :: resolve 6362ms :: artifacts dl 84ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   14  |   5   |   5   |   0   ||   14  |   5   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-serde-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-serde-default.html

make-pom:
     [echo] Project: serde
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: serde
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources does not exist.

init:
     [echo] Project: serde

ivy-retrieve:
     [echo] Project: serde
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-serde
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	8 artifacts copied, 6 already retrieved (2229kB/33ms)

dynamic-serde:

compile:
     [echo] Project: serde
    [javac] Compiling 338 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes/org/apache/hadoop/hive/serde2/typeinfo/package-info.class

jar:
     [echo] Project: serde
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/hive-serde-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-serde;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Tue Sep 17 20:36:25 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-serde
[ivy:publish] 	published hive-serde to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.13.0-SNAPSHOT/jars/hive-serde.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: metastore

check-ivy:
     [echo] Project: metastore

ivy-resolve:
     [echo] Project: metastore
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-metastore;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.13.0-SNAPSHOT/jars/hive-serde.jar ...
[ivy:resolve] ............ (693kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-serde;0.13.0-SNAPSHOT!hive-serde.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/antlr/3.4/antlr-3.4.jar ...
[ivy:resolve] .................. (1086kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.antlr#antlr;3.4!antlr.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar ...
[ivy:resolve] .... (160kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.antlr#antlr-runtime;3.4!antlr-runtime.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/ST4/4.0.4/ST4-4.0.4.jar ...
[ivy:resolve] ..... (231kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.antlr#ST4;4.0.4!ST4.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar ...
[ivy:resolve] ... (112kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.jolbox#bonecp;0.7.1.RELEASE!bonecp.jar(bundle) (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar ...
[ivy:resolve] ... (93kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-pool#commons-pool;1.5.4!commons-pool.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar ...
[ivy:resolve] ....... (329kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.datanucleus#datanucleus-api-jdo;3.2.1!datanucleus-api-jdo.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar ...
[ivy:resolve] .............................. (1759kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.datanucleus#datanucleus-core;3.2.2!datanucleus-core.jar (34ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar ...
[ivy:resolve] .............................. (1728kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.datanucleus#datanucleus-rdbms;3.2.1!datanucleus-rdbms.jar (42ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar ...
[ivy:resolve] ..... (196kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.jdo#jdo-api;3.0.1!jdo-api.jar (30ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar ...
[ivy:resolve] ......................................... (2389kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.derby#derby;10.4.2.0!derby.jar (51ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/guava/guava/r08/guava-r08.jar ...
[ivy:resolve] ................... (1088kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.guava#guava;r08!guava.jar (28ms)
[ivy:resolve] :: resolution report :: resolve 10147ms :: artifacts dl 286ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   27  |   12  |   12  |   1   ||   26  |   12  |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-metastore-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-metastore-default.html

make-pom:
     [echo] Project: metastore
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: metastore
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources does not exist.

init:
     [echo] Project: metastore

metastore-init:
     [echo] Project: metastore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/gen/antlr/gen-java/org/apache/hadoop/hive/metastore/parser

ivy-retrieve:
     [echo] Project: metastore
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-metastore
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	12 artifacts copied, 14 already retrieved (9868kB/32ms)

build-grammar:
     [echo] Project: metastore
     [echo] Building Grammar /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g  ....

model-compile:
     [echo] Project: metastore
    [javac] Compiling 24 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes

core-compile:
     [echo] Project: metastore
    [javac] Compiling 103 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes/org/apache/hadoop/hive/metastore/parser/package-info.class

model-enhance:
     [echo] Project: metastore
[datanucleusenhancer] log4j:WARN No appenders could be found for logger (DataNucleus.General).
[datanucleusenhancer] log4j:WARN Please initialize the log4j system properly.
[datanucleusenhancer] log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
[datanucleusenhancer] DataNucleus Enhancer (version 3.2.2) for API &quot;JDO&quot; using JRE &quot;1.6&quot;
[datanucleusenhancer] DataNucleus Enhancer : Classpath
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/hive-anttasks-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/common/hive-common-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/serde/hive-serde-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/activation-1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ant-1.6.5.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/asm-3.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-beanutils-1.7.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-beanutils-core-1.8.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-cli-1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-codec-1.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-collections-3.2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-configuration-1.6.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-digester-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-el-1.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-httpclient-3.0.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-io-2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-lang-2.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-logging-1.1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-math-2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-net-1.4.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/core-3.1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftplet-api-1.0.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftpserver-core-1.0.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftpserver-deprecated-1.0.0-M2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-core-1.1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-test-1.1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-tools-1.1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hsqldb-1.8.0.10.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-core-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-jaxrs-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-mapper-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-xc-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jasper-compiler-5.5.12.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jasper-runtime-5.5.12.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jaxb-api-2.2.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jaxb-impl-2.2.3-1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-core-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-json-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-server-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jets3t-0.6.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jettison-1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jetty-6.1.26.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jetty-util-6.1.26.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jsp-2.1-6.1.14.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jsp-api-2.1-6.1.14.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/junit-3.8.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/mina-core-2.0.0-M5.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/oro-2.0.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/servlet-api-2.5-20081211.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/servlet-api-2.5-6.1.14.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/slf4j-api-1.5.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/stax-api-1.0-2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/stax-api-1.0.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/xmlenc-0.52.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/ST4-4.0.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/antlr-3.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/antlr-runtime-3.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-mapred-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/bonecp-0.7.1.RELEASE.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-cli-1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-codec-1.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-compress-1.4.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-io-2.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-lang-2.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-logging-1.0.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-logging-api-1.0.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-pool-1.5.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-api-jdo-3.2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-core-3.2.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-rdbms-3.2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/derby-10.4.2.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/guava-11.0.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/guava-r08.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-common-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-serde-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-shims-0.13.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-core-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-mapper-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jdo-api-3.0.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libfb303-0.9.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libthrift-0.9.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/log4j-1.2.16.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/mockito-all-1.8.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/slf4j-api-1.6.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/slf4j-log4j12-1.6.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/velocity-1.5.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/xz-1.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/zookeeper-3.4.3.jar
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDatabase
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFieldSchema
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MType
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTable
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MOrder
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStringList
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartition
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MIndex
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRole
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRoleMap
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MMasterKey
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDelegationToken
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics
[datanucleusenhancer] DataNucleus Enhancer completed with success for 24 classes. Timings : input=738 ms, enhance=1164 ms, total=1902 ms. Consult the log for full details

compile:
     [echo] Project: metastore

jar:
     [echo] Project: metastore
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/hive-metastore-0.13.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-metastore;0.13.0-SNAPSHOT :: 0.13.0-SNAPSHOT :: integration :: Tue Sep 17 20:37:05 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/ivy-0.13.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-metastore
[ivy:publish] 	published hive-metastore to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.13.0-SNAPSHOT/jars/hive-metastore.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.13.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: ql

check-ivy:
     [echo] Project: ql

ivy-resolve:
     [echo] Project: ql
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-exec;0.13.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.13.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.5.0 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found com.esotericsoftware.kryo#kryo;2.22-SNAPSHOT in sonatype-snapshot
[ivy:resolve] 	found com.esotericsoftware.reflectasm#reflectasm;1.07 in maven2
[ivy:resolve] 	found org.ow2.asm#asm;4.0 in maven2
[ivy:resolve] 	found com.esotericsoftware.minlog#minlog;1.2 in maven2
[ivy:resolve] 	found org.objenesis#objenesis;1.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.13.0-SNAPSHOT/jars/hive-metastore.jar ...
[ivy:resolve] .................................................... (3257kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-metastore;0.13.0-SNAPSHOT!hive-metastore.jar (51ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/iq80/snappy/snappy/0.2/snappy-0.2.jar ...
[ivy:resolve] .. (47kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.iq80.snappy#snappy;0.2!snappy.jar (12ms)
[ivy:resolve] downloading https://oss.sonatype.org/content/repositories/snapshots/com/esotericsoftware/kryo/kryo/2.22-SNAPSHOT/kryo-2.22-20130903.084724-39.jar ...
[ivy:resolve] ............................................................................................ (420kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.esotericsoftware.kryo#kryo;2.22-SNAPSHOT!kryo.jar(bundle) (676ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/json/json/20090211/json-20090211.jar ...
[ivy:resolve] .. (44kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.json#json;20090211!json.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar ...
[ivy:resolve] .. (16kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.googlecode.javaewah#JavaEWAH;0.3.2!JavaEWAH.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javolution/javolution/5.5.1/javolution-5.5.1.jar ...
[ivy:resolve] ........ (385kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javolution#javolution;5.5.1!javolution.jar(bundle) (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/jline/jline/0.9.94/jline-0.9.94.jar ...
[ivy:resolve] ... (85kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] jline#jline;0.9.94!jline.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar ...
[ivy:resolve] ... (64kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.esotericsoftware.reflectasm#reflectasm;1.07!reflectasm.jar (40ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar ...
[ivy:resolve] .. (4kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.esotericsoftware.minlog#minlog;1.2!minlog.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/objenesis/objenesis/1.2/objenesis-1.2.jar ...
[ivy:resolve] .. (35kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.objenesis#objenesis;1.2!objenesis.jar (22ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/ow2/asm/asm/4.0/asm-4.0.jar ...
[ivy:resolve] .. (44kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.ow2.asm#asm;4.0!asm.jar (26ms)
[ivy:resolve] :: resolution report :: resolve 17137ms :: artifacts dl 922ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   43  |   11  |   11  |   2   ||   41  |   11  |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-exec-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-exec-default.html

make-pom:
     [echo] Project: ql
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: ql

init:
     [echo] Project: ql

ql-init:
     [echo] Project: ql
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/gen/antlr/gen-java/org/apache/hadoop/hive/ql/parse

ivy-retrieve:
     [echo] Project: ql
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-exec
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	15 artifacts copied, 26 already retrieved (5813kB/29ms)

build-grammar:
     [echo] Project: ql
     [echo] Building Grammar /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g  ....
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:867:5: 
     [java] Decision can match input such as &quot;Identifier KW_RENAME KW_TO&quot; using multiple alternatives: 1, 10
     [java] 
     [java] As a result, alternative(s) 10 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:5: 
     [java] Decision can match input such as &quot;KW_TEXTFILE&quot; using multiple alternatives: 2, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:5: 
     [java] Decision can match input such as &quot;KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:5: 
     [java] Decision can match input such as &quot;KW_ORCFILE&quot; using multiple alternatives: 4, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:5: 
     [java] Decision can match input such as &quot;KW_RCFILE&quot; using multiple alternatives: 3, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1181:23: 
     [java] Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1181:23: 
     [java] Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1181:23: 
     [java] Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1188:23: 
     [java] Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1188:23: 
     [java] Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1188:23: 
     [java] Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1206:29: 
     [java] Decision can match input such as &quot;KW_PRETTY KW_PARTITION&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1206:29: 
     [java] Decision can match input such as &quot;KW_PRETTY {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1206:29: 
     [java] Decision can match input such as &quot;KW_PRETTY Identifier&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1206:29: 
     [java] Decision can match input such as &quot;KW_FORMATTED {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1206:29: 
     [java] Decision can match input such as &quot;KW_FORMATTED KW_PARTITION&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1206:29: 
     [java] Decision can match input such as &quot;KW_FORMATTED Identifier&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:116: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_DIRECTORIES&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_TEXTFILE&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_INPUTFORMAT&quot; using multiple alternatives: 5, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_RCFILE&quot; using multiple alternatives: 3, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_ORCFILE&quot; using multiple alternatives: 4, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): SelectClauseParser.g:149:5: 
     [java] Decision can match input such as &quot;KW_NULL DOT Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): SelectClauseParser.g:149:5: 
     [java] Decision can match input such as &quot;KW_NULL DOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:127:2: 
     [java] Decision can match input such as &quot;KW_LATERAL KW_VIEW KW_OUTER&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:25: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral EQUAL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:25: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral COMMA&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:25: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral RPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL GREATERTHAN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL GREATERTHANOREQUALTO&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LESSTHAN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LESSTHANOREQUALTO&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL DOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL NOTEQUAL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL EQUAL_NS&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL {DIV..DIVIDE, MOD, STAR}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL BITWISEXOR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL EQUAL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL RPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_AND&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CAST LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL BITWISEOR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_BETWEEN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_IN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL AMPERSAND&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LSQUARE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL {KW_LIKE, KW_REGEXP, KW_RLIKE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL {MINUS, PLUS}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN CharSetName CharSetLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_WHEN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_IS&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_DATE StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_OR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:108:5: 
     [java] Decision can match input such as &quot;KW_ORDER KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:121:5: 
     [java] Decision can match input such as &quot;KW_CLUSTER KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:133:5: 
     [java] Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:144:5: 
     [java] Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:155:5: 
     [java] Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:172:7: 
     [java] Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:185:5: 
     [java] Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): IdentifiersParser.g:185:5: 
     [java] Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): IdentifiersParser.g:185:5: 
     [java] Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 8
     [java] 
     [java] As a result, alternative(s) 8 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_DATE StringLiteral&quot; using multiple alternatives: 2, 3
     [java] 
     [java] As a result, alternative(s) 3 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 3, 8
     [java] 
     [java] As a result, alternative(s) 8 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 3, 8
     [java] 
     [java] As a result, alternative(s) 8 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 6, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:514:5: 
     [java] Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3
     [java] 
     [java] As a result, alternative(s) 3 were disabled for that input

compile:
     [echo] Project: ql
    [javac] Compiling 922 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCollectSet.java:25: package org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMkCollectionEvaluator does not exist
    [javac] import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMkCollectionEvaluator.BufferType;
    [javac]                                                                              ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java:386: cannot find symbol
    [javac] symbol  : class GenericUDAFCollectList
    [javac] location: class org.apache.hadoop.hive.ql.exec.FunctionRegistry
    [javac]     registerGenericUDAF(&quot;collect_list&quot;, new GenericUDAFCollectList());
    [javac]                                             ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCollectSet.java:52: cannot find symbol
    [javac] symbol  : class GenericUDAFMkCollectionEvaluator
    [javac] location: class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCollectSet
    [javac]     return new GenericUDAFMkCollectionEvaluator(BufferType.SET);
    [javac]                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCollectSet.java:52: cannot find symbol
    [javac] symbol  : variable BufferType
    [javac] location: class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCollectSet
    [javac]     return new GenericUDAFMkCollectionEvaluator(BufferType.SET);
    [javac]                                                 ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] 4 errors

BUILD FAILED
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:327: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:166: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:168: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/ql/build.xml:198: Compile failed; see the compiler error output for details.

Total time: 4 minutes 32 seconds
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13772560" author="thejas" created="Fri, 20 Sep 2013 01:41:57 +0000"  >&lt;p&gt;I ran the jdbc tests as this is a jdbc only change. Patch committed to trunk and 0.12 branch.&lt;br/&gt;
Thanks Vaibhav for the contribution!&lt;/p&gt;</comment>
                            <comment id="13773014" author="hudson" created="Fri, 20 Sep 2013 13:54:04 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #107 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/107/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/107/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5156&quot; title=&quot;HiveServer2 jdbc ResultSet.close should free up resources on server side&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5156&quot;&gt;&lt;del&gt;HIVE-5156&lt;/del&gt;&lt;/a&gt;: HiveServer2 jdbc ResultSet.close should free up resources on server side (Vaibhav Gumashta via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524880&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524880&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13773073" author="hudson" created="Fri, 20 Sep 2013 15:25:22 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #174 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/174/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/174/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5156&quot; title=&quot;HiveServer2 jdbc ResultSet.close should free up resources on server side&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5156&quot;&gt;&lt;del&gt;HIVE-5156&lt;/del&gt;&lt;/a&gt;: HiveServer2 jdbc ResultSet.close should free up resources on server side (Vaibhav Gumashta via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524880&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524880&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13773082" author="hudson" created="Fri, 20 Sep 2013 15:32:52 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2 #444 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/444/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/444/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5156&quot; title=&quot;HiveServer2 jdbc ResultSet.close should free up resources on server side&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5156&quot;&gt;&lt;del&gt;HIVE-5156&lt;/del&gt;&lt;/a&gt;: HiveServer2 jdbc ResultSet.close should free up resources on server side (Vaibhav Gumashta via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524880&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524880&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13773083" author="hudson" created="Fri, 20 Sep 2013 15:32:52 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-h0.21 #2345 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2345/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2345/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5156&quot; title=&quot;HiveServer2 jdbc ResultSet.close should free up resources on server side&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5156&quot;&gt;&lt;del&gt;HIVE-5156&lt;/del&gt;&lt;/a&gt;: HiveServer2 jdbc ResultSet.close should free up resources on server side (Vaibhav Gumashta via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524880&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524880&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13796183" author="ashutoshc" created="Tue, 15 Oct 2013 23:31:38 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12603651" name="HIVE-5156.D12837.3.patch" size="14589" author="vgumashta" created="Tue, 17 Sep 2013 20:10:10 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 17 Sep 2013 21:34:12 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345614</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nll3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345915</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5157] ReduceSinkDeDuplication ignores hive.groupby.skewindata=true </title>
                <link>https://issues.apache.org/jira/browse/HIVE-5157</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;If hive.groupby.skewindata=true, we should generate two MR jobs. But, ReduceSinkDeDuplication will merge these two into a single MR job. Example: groupby2_map_skew.q and groupby2.q&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665728">HIVE-5157</key>
            <summary>ReduceSinkDeDuplication ignores hive.groupby.skewindata=true </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="yhuai">Yin Huai</assignee>
                                    <reporter username="yhuai">Yin Huai</reporter>
                        <labels>
                    </labels>
                <created>Tue, 27 Aug 2013 15:33:21 +0000</created>
                <updated>Tue, 3 Sep 2013 19:32:09 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345668</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 21 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nlx3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345969</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-5158] allow getting all partitions for table to also use direct SQL path</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5158</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;While testing some queries I noticed that getPartitions can be very slow (which happens e.g. in non-strict mode with no partition column filter); with a table with many partitions it can take 10-12s easily. SQL perf path can also be used for this path.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665752">HIVE-5158</key>
            <summary>allow getting all partitions for table to also use direct SQL path</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sershe">Sergey Shelukhin</assignee>
                                    <reporter username="sershe">Sergey Shelukhin</reporter>
                        <labels>
                    </labels>
                <created>Tue, 27 Aug 2013 17:53:02 +0000</created>
                <updated>Tue, 15 Oct 2013 23:31:25 +0000</updated>
                            <resolved>Fri, 6 Sep 2013 14:58:53 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13751994" author="phabricator@reviews.facebook.net" created="Wed, 28 Aug 2013 01:24:53 +0000"  >&lt;p&gt;sershe requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; allow getting all partitions for table to also use direct SQL path&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;initial patch. Tests are running.&lt;/p&gt;

&lt;p&gt;While testing some queries I noticed that getPartitions can be very slow (which happens e.g. in non-strict mode with no partition column filter); with a table with many partitions it can take 10-12s easily. SQL perf path can also be used for this path.&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/30189/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/30189/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, sershe&lt;/p&gt;</comment>
                            <comment id="13752496" author="phabricator@reviews.facebook.net" created="Wed, 28 Aug 2013 15:18:52 +0000"  >&lt;p&gt;ashutoshc has requested changes to the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; allow getting all partitions for table to also use direct SQL path&quot;.&lt;/p&gt;

&lt;p&gt;  Question on supporting max.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java:1387 Seems like its not hard to support max in this scenario. We can simply do  query.setRange(0, max) for it. Did you consider supporting it?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, sershe&lt;/p&gt;</comment>
                            <comment id="13752526" author="sershe" created="Wed, 28 Aug 2013 16:09:50 +0000"  >&lt;p&gt;Actually there&apos;s another path that needs to be changed...&lt;/p&gt;</comment>
                            <comment id="13752565" author="phabricator@reviews.facebook.net" created="Wed, 28 Aug 2013 16:52:54 +0000"  >&lt;p&gt;sershe has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; allow getting all partitions for table to also use direct SQL path&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java:1387 1) I am not sure this will work for SQL JDO; probably it will just get all of them and return limited number of rows.&lt;br/&gt;
  2) Due to absence of offset, it&apos;s really a semi-useless parameter; I don&apos;t see it used.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, sershe&lt;/p&gt;</comment>
                            <comment id="13752591" author="phabricator@reviews.facebook.net" created="Wed, 28 Aug 2013 17:14:53 +0000"  >&lt;p&gt;ashutoshc has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; allow getting all partitions for table to also use direct SQL path&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java:1387 1) That should still be as fast as orm path, if not faster.&lt;br/&gt;
  2) Metastore thrift api is public. There can be consumer of if apart from Hive.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, sershe&lt;/p&gt;</comment>
                            <comment id="13752696" author="sershe" created="Wed, 28 Aug 2013 18:36:34 +0000"  >&lt;p&gt;making blocked on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4914&quot; title=&quot;filtering via partition name should be done inside metastore server (implementation)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4914&quot;&gt;&lt;del&gt;HIVE-4914&lt;/del&gt;&lt;/a&gt;, it&apos;s not really blocked but &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4914&quot; title=&quot;filtering via partition name should be done inside metastore server (implementation)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4914&quot;&gt;&lt;del&gt;HIVE-4914&lt;/del&gt;&lt;/a&gt; is pain to rebase after all of these patches. I will submit a patch on top of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4914&quot; title=&quot;filtering via partition name should be done inside metastore server (implementation)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4914&quot;&gt;&lt;del&gt;HIVE-4914&lt;/del&gt;&lt;/a&gt; today.&lt;/p&gt;</comment>
                            <comment id="13752948" author="phabricator@reviews.facebook.net" created="Wed, 28 Aug 2013 22:20:53 +0000"  >&lt;p&gt;sershe updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; allow getting all partitions for table to also use direct SQL path&quot;.&lt;/p&gt;

&lt;p&gt;  Change the patch instead in such manner that PartitionPruner calls the method I already modified. It seems like it doesn&apos;t need auth (get-by-filter and get-by-name don&apos;t use it).&lt;/p&gt;

&lt;p&gt;Reviewers: ashutoshc, JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573?vs=39141&amp;amp;id=39201#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573?vs=39141&amp;amp;id=39201#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;MANIPHEST TASKS&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/T63&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/T63&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, sershe&lt;/p&gt;</comment>
                            <comment id="13753192" author="phabricator@reviews.facebook.net" created="Thu, 29 Aug 2013 02:18:51 +0000"  >&lt;p&gt;sershe updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; allow getting all partitions for table to also use direct SQL path&quot;.&lt;/p&gt;

&lt;p&gt;  Adding the limit support to this and other call... tests are running&lt;/p&gt;

&lt;p&gt;Reviewers: ashutoshc, JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573?vs=39201&amp;amp;id=39237#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573?vs=39201&amp;amp;id=39237#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;MANIPHEST TASKS&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/T63&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/T63&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, sershe&lt;/p&gt;</comment>
                            <comment id="13753248" author="phabricator@reviews.facebook.net" created="Thu, 29 Aug 2013 03:14:52 +0000"  >&lt;p&gt;ashutoshc has accepted the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; allow getting all partitions for table to also use direct SQL path&quot;.&lt;/p&gt;

&lt;p&gt;  +1&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, sershe&lt;/p&gt;</comment>
                            <comment id="13753811" author="ashutoshc" created="Thu, 29 Aug 2013 16:59:35 +0000"  >&lt;p&gt;~33 tests failed.&lt;/p&gt;</comment>
                            <comment id="13754341" author="phabricator@reviews.facebook.net" created="Fri, 30 Aug 2013 03:27:52 +0000"  >&lt;p&gt;sershe updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; allow getting all partitions for table to also use direct SQL path&quot;.&lt;/p&gt;

&lt;p&gt;  Fix the issue, looks like just cast (for tests that were failing for me).&lt;br/&gt;
  I am rerunning the tests.&lt;/p&gt;

&lt;p&gt;Reviewers: ashutoshc, JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573?vs=39237&amp;amp;id=39309#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573?vs=39237&amp;amp;id=39309#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;MANIPHEST TASKS&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/T63&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/T63&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, sershe&lt;/p&gt;</comment>
                            <comment id="13754963" author="appodictic" created="Fri, 30 Aug 2013 18:06:47 +0000"  >&lt;p&gt;A thing to keep in mind is that some tables with a huge number of partitions will OOM a client if you attempt to fetch them all at once. So some support for paging is required.&lt;/p&gt;</comment>
                            <comment id="13755009" author="sershe" created="Fri, 30 Aug 2013 18:50:35 +0000"  >&lt;p&gt;The existing logic to get all partitions doesn&apos;t actually appear to have any... it has max parameter but no offset. It does make sense to have it though. Let me take a look, probably in a separate jira. Might require API change&lt;/p&gt;</comment>
                            <comment id="13755025" author="appodictic" created="Fri, 30 Aug 2013 19:00:41 +0000"  >&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;The existing logic to get all partitions doesn&apos;t actually appear to have any.&lt;/p&gt;
{/quote}

&lt;p&gt;The partitions are ordered so you can start at an existing one and read N partitions. I am not sure it is related to your issue but I just wanted to remind everyone that if you doing two levels of partitions the number adds up very fast and can OOM the client, or the thrift server.&lt;/p&gt;</comment>
                            <comment id="13755144" author="hiveqa" created="Fri, 30 Aug 2013 21:08:34 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12600721/HIVE-5158.D12573.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12600721/HIVE-5158.D12573.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/575/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/575/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/575/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/575/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-575/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf build hcatalog/build hcatalog/core/build hcatalog/storage-handlers/hbase/build hcatalog/server-extensions/build hcatalog/webhcat/svr/build hcatalog/webhcat/java-client/build hcatalog/hcatalog-pig-adapter/build common/src/gen
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1519088.

At revision 1519088.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0 to p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13755371" author="ashutoshc" created="Sat, 31 Aug 2013 02:31:03 +0000"  >&lt;p&gt;AFAICS this patch is not altering memory footprint, hence doesn&apos;t make the situation better or worse. &lt;br/&gt;
In my run of full test suite all tests passed, except for TestPermsGrp and TestHCatClient in hcatalog dir, probably due to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5181&quot; title=&quot;RetryingRawStore should not retry on logical failures (e.g. from commit)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5181&quot;&gt;&lt;del&gt;HIVE-5181&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13755373" author="sershe" created="Sat, 31 Aug 2013 02:47:24 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5181&quot; title=&quot;RetryingRawStore should not retry on logical failures (e.g. from commit)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5181&quot;&gt;&lt;del&gt;HIVE-5181&lt;/del&gt;&lt;/a&gt; only happens in case if there&apos;s an actual failure underneath. Let me try to run these...&lt;/p&gt;</comment>
                            <comment id="13757104" author="phabricator@reviews.facebook.net" created="Tue, 3 Sep 2013 21:29:53 +0000"  >&lt;p&gt;sershe updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; allow getting all partitions for table to also use direct SQL path&quot;.&lt;/p&gt;

&lt;p&gt;  Update to fix test failures. It turns out rolling back TX for SQL failure is a bad idea - we might be inside of external tx which will then fail. We are just doing selects, so if they fail we might as well keep the tx.&lt;/p&gt;

&lt;p&gt;Reviewers: ashutoshc, JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573?vs=39309&amp;amp;id=39447#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573?vs=39309&amp;amp;id=39447#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;MANIPHEST TASKS&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/T63&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/T63&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;br/&gt;
  metastore/src/test/org/apache/hadoop/hive/metastore/VerifyingObjectStore.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, sershe&lt;/p&gt;</comment>
                            <comment id="13757154" author="ashutoshc" created="Tue, 3 Sep 2013 22:15:39 +0000"  >&lt;p&gt;Couple of questions:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Which one was the external txn in this case? It will help to understand the nesting of transactions.&lt;/li&gt;
	&lt;li&gt;Why did direct sql fail ? Seems like that shouldn&apos;t have happened anyway.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13757303" author="sershe" created="Wed, 4 Sep 2013 00:30:51 +0000"  >&lt;p&gt;In some test the database wasn&apos;t created, so SQL failed with PARTITION table not found. When it falls back to JDO presumably the db is getting created, judging by DN info logging.&lt;br/&gt;
External (to metastore) tx can be anywhere there code calls beginTransaction on metastore before doing stuff, for example in many drop-table cases.&lt;br/&gt;
External code calls begin, then we call begin, SQL fails and we intend to fall back and call rollback; this won&apos;t allow us to fall back though as the caller will now fail anyway.&lt;/p&gt;</comment>
                            <comment id="13757569" author="ashutoshc" created="Wed, 4 Sep 2013 08:50:45 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13758168" author="ashutoshc" created="Wed, 4 Sep 2013 18:52:05 +0000"  >&lt;p&gt;Latest patch is resulting in ton of failures in my test runs.&lt;/p&gt;</comment>
                            <comment id="13758418" author="sershe" created="Wed, 4 Sep 2013 22:13:46 +0000"  >&lt;p&gt;I cannot repro so far... I will try on different box, but let&apos;s try to have hiveqa run&lt;/p&gt;</comment>
                            <comment id="13758508" author="phabricator@reviews.facebook.net" created="Wed, 4 Sep 2013 23:17:53 +0000"  >&lt;p&gt;sershe updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; allow getting all partitions for table to also use direct SQL path&quot;.&lt;/p&gt;

&lt;p&gt;  Trying to update the patch to trigger HiveQA&lt;/p&gt;

&lt;p&gt;Reviewers: ashutoshc, JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573?vs=39447&amp;amp;id=39513#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573?vs=39447&amp;amp;id=39513#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;MANIPHEST TASKS&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/T63&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/T63&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;br/&gt;
  metastore/src/test/org/apache/hadoop/hive/metastore/VerifyingObjectStore.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, sershe&lt;/p&gt;</comment>
                            <comment id="13758559" author="sershe" created="Thu, 5 Sep 2013 00:18:38 +0000"  >&lt;p&gt;woops, I found the issue... pretty stupid actually&lt;/p&gt;</comment>
                            <comment id="13758690" author="phabricator@reviews.facebook.net" created="Thu, 5 Sep 2013 02:13:52 +0000"  >&lt;p&gt;sershe updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; allow getting all partitions for table to also use direct SQL path&quot;.&lt;/p&gt;

&lt;p&gt;  Fix bug, removed extra line&lt;/p&gt;

&lt;p&gt;Reviewers: ashutoshc, JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573?vs=39513&amp;amp;id=39525#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573?vs=39513&amp;amp;id=39525#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;MANIPHEST TASKS&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/T63&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/T63&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;br/&gt;
  metastore/src/test/org/apache/hadoop/hive/metastore/VerifyingObjectStore.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, sershe&lt;/p&gt;</comment>
                            <comment id="13758809" author="hiveqa" created="Thu, 5 Sep 2013 06:12:25 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12601544/HIVE-5158.D12573.7.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12601544/HIVE-5158.D12573.7.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 13 failed/errored test(s), 2909 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sort_merge_join_desc_6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_nonreserved_keywords_insert_into1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_shutdown
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_bigint
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_18
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppd_outer_join3
org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_parallel_orderby
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_transform2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_hex
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppd_constant_where
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppd_udf_col
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/622/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/622/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/622/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/622/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 13 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13759036" author="hiveqa" created="Thu, 5 Sep 2013 12:56:19 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12601544/HIVE-5158.D12573.7.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12601544/HIVE-5158.D12573.7.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 11 failed/errored test(s), 2909 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sort_merge_join_desc_6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_nonreserved_keywords_insert_into1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_shutdown
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_bigint
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_remove_18
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppd_outer_join3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_transform2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_hex
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppd_constant_where
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppd_udf_col
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/628/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/628/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/628/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/628/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 11 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13759482" author="phabricator@reviews.facebook.net" created="Thu, 5 Sep 2013 21:19:54 +0000"  >&lt;p&gt;sershe updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; allow getting all partitions for table to also use direct SQL path&quot;.&lt;/p&gt;

&lt;p&gt;  Fix issue with newly-added max support - different subsets are returned by SQL and ORM, due to lack of order when filtering. I verified some of these tests, will run all tests later today.&lt;/p&gt;

&lt;p&gt;Reviewers: ashutoshc, JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12573?vs=39525&amp;amp;id=39585#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12573?vs=39525&amp;amp;id=39585#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;MANIPHEST TASKS&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/T63&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/T63&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;br/&gt;
  metastore/src/test/org/apache/hadoop/hive/metastore/VerifyingObjectStore.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, sershe&lt;/p&gt;</comment>
                            <comment id="13759825" author="hiveqa" created="Fri, 6 Sep 2013 03:35:34 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12601684/HIVE-5158.D12573.8.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12601684/HIVE-5158.D12573.8.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 10 failed/errored test(s), 3084 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hive.hcatalog.fileformats.TestOrcDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask
org.apache.hive.hcatalog.pig.TestOrcHCatLoader.testReadDataBasic
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreMultiTables
org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatDynamicPartitionedTable
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoSchema
org.apache.hive.hcatalog.pig.TestOrcHCatLoader.testReadPartitionedBasic
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreInPartiitonedTbl
org.apache.hive.hcatalog.pig.TestHCatStorer.testMultiPartColsInData
org.apache.hive.hcatalog.pig.TestOrcHCatLoader.testProjectionsBasic
org.apache.hive.hcatalog.pig.TestHCatStorer.testPartColsInData
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/635/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/635/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/635/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/635/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 10 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13760245" author="ashutoshc" created="Fri, 6 Sep 2013 14:58:53 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Sergey!&lt;/p&gt;</comment>
                            <comment id="13760287" author="hudson" created="Fri, 6 Sep 2013 15:46:18 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2 #410 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/410/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/410/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt; : allow getting all partitions for table to also use direct SQL path (Sergey Shelukhin via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1520589&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1520589&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/test/org/apache/hadoop/hive/metastore/VerifyingObjectStore.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13760421" author="hudson" created="Fri, 6 Sep 2013 17:49:03 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-h0.21 #2314 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2314/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2314/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt; : allow getting all partitions for table to also use direct SQL path (Sergey Shelukhin via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1520589&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1520589&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/test/org/apache/hadoop/hive/metastore/VerifyingObjectStore.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13760771" author="hudson" created="Fri, 6 Sep 2013 23:49:52 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #153 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/153/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/153/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt; : allow getting all partitions for table to also use direct SQL path (Sergey Shelukhin via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1520589&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1520589&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/test/org/apache/hadoop/hive/metastore/VerifyingObjectStore.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13760884" author="hudson" created="Sat, 7 Sep 2013 02:43:11 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #85 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/85/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/85/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5158&quot; title=&quot;allow getting all partitions for table to also use direct SQL path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5158&quot;&gt;&lt;del&gt;HIVE-5158&lt;/del&gt;&lt;/a&gt; : allow getting all partitions for table to also use direct SQL path (Sergey Shelukhin via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1520589&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1520589&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/test/org/apache/hadoop/hive/metastore/VerifyingObjectStore.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13796157" author="ashutoshc" created="Tue, 15 Oct 2013 23:31:25 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12600311" name="HIVE-5158.D12573.1.patch" size="2741" author="phabricator@reviews.facebook.net" created="Wed, 28 Aug 2013 01:24:53 +0000"/>
                            <attachment id="12600484" name="HIVE-5158.D12573.2.patch" size="6337" author="phabricator@reviews.facebook.net" created="Wed, 28 Aug 2013 22:20:53 +0000"/>
                            <attachment id="12600528" name="HIVE-5158.D12573.3.patch" size="10856" author="phabricator@reviews.facebook.net" created="Thu, 29 Aug 2013 02:18:51 +0000"/>
                            <attachment id="12600721" name="HIVE-5158.D12573.4.patch" size="13406" author="phabricator@reviews.facebook.net" created="Fri, 30 Aug 2013 03:27:52 +0000"/>
                            <attachment id="12601246" name="HIVE-5158.D12573.5.patch" size="16038" author="phabricator@reviews.facebook.net" created="Tue, 3 Sep 2013 21:29:53 +0000"/>
                            <attachment id="12601504" name="HIVE-5158.D12573.6.patch" size="16038" author="phabricator@reviews.facebook.net" created="Wed, 4 Sep 2013 23:17:53 +0000"/>
                            <attachment id="12601544" name="HIVE-5158.D12573.7.patch" size="16068" author="phabricator@reviews.facebook.net" created="Thu, 5 Sep 2013 02:13:52 +0000"/>
                            <attachment id="12601684" name="HIVE-5158.D12573.8.patch" size="16705" author="phabricator@reviews.facebook.net" created="Thu, 5 Sep 2013 21:19:54 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 28 Aug 2013 01:24:53 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345691</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nm27:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345992</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5159] Change the kind fields in ORC&apos;s proto file to optional</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5159</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Java&apos;s protobuf generated code uses a null value to represent enum values that were added after the reader was compiled. To reflect that reality, the enum values should always be marked as optional.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665783">HIVE-5159</key>
            <summary>Change the kind fields in ORC&apos;s proto file to optional</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="jdere">Jason Dere</assignee>
                                    <reporter username="owen.omalley">Owen O&apos;Malley</reporter>
                        <labels>
                    </labels>
                <created>Tue, 27 Aug 2013 20:37:24 +0000</created>
                <updated>Fri, 30 Aug 2013 20:42:49 +0000</updated>
                                                                            <component>File Formats</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13755114" author="jdere" created="Fri, 30 Aug 2013 20:42:49 +0000"  >&lt;p&gt;Just want to get a bit of clarification on this issue, since it goes against the &quot;required is forever&quot; guideline described in &lt;a href=&quot;https://developers.google.com/protocol-buffers/docs/proto#simple&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://developers.google.com/protocol-buffers/docs/proto#simple&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If I understand correctly, the issue is when an older client receives newer Type value, containing a Kind enum that didn&apos;t exist at the time the older client was built. In this situation the Kind value is set as NULL.  Is the point of setting Kind as optional field of Type so that you would have the ability to call hasKind() on the Type and do appropriate error handling? Looking at OrcProto.java it appears that there is such a Type.hasKind() method already, so this use case is already covered. Or is there another use case that you are thinking of here?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 30 Aug 2013 20:42:49 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345722</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 21 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nm93:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>346023</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-5160] HS2 should support .hiverc</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5160</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;It would be useful to support the .hiverc functionality with hive server2 as well.&lt;br/&gt;
.hiverc is processed by CliDriver, so it works only with hive cli. It would be useful to be able to do things like register a standard set of jars and functions for all users. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12665802">HIVE-5160</key>
            <summary>HS2 should support .hiverc</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dongc">Dong Chen</assignee>
                                    <reporter username="thejas">Thejas M Nair</reporter>
                        <labels>
                    </labels>
                <created>Tue, 27 Aug 2013 21:58:38 +0000</created>
                <updated>Sun, 10 Jan 2016 02:04:10 +0000</updated>
                            <resolved>Thu, 24 Jul 2014 01:30:31 +0000</resolved>
                                                    <fixVersion>0.14.0</fixVersion>
                                    <component>HiveServer2</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>10</watches>
                                                                <comments>
                            <comment id="13751776" author="thejas" created="Tue, 27 Aug 2013 21:58:46 +0000"  >&lt;p&gt;I am not sure if a user specific .hiverc would be of value in case of hive server2.&lt;/p&gt;</comment>
                            <comment id="13751777" author="thejas" created="Tue, 27 Aug 2013 21:59:20 +0000"  >&lt;p&gt;I mean a global .hiverc file is going to be useful with hive server2.&lt;/p&gt;</comment>
                            <comment id="14068540" author="dongc" created="Mon, 21 Jul 2014 13:57:49 +0000"  >&lt;p&gt;A patch which supports global .hiverc file in HS2 is attached. In this patch, the global .hiverc file will be loaded and parsed when a session is created.&lt;/p&gt;

&lt;p&gt;RB entry: &lt;a href=&quot;https://reviews.apache.org/r/23738/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/23738/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14069546" author="szehon" created="Mon, 21 Jul 2014 23:57:24 +0000"  >&lt;p&gt;Hi Dong, thanks for looking at this, it is pretty useful.  I left comments on the review board.&lt;/p&gt;</comment>
                            <comment id="14070008" author="dongc" created="Tue, 22 Jul 2014 08:42:03 +0000"  >&lt;p&gt;Hi Szehon, Lefty, thanks very much for your comments. They are very helpful.&lt;br/&gt;
I have updated the code in the review board. The change lists are:&lt;/p&gt;

&lt;p&gt;1. clear typo. I should be more careful on spelling and grammar. &lt;sup&gt;_&lt;/sup&gt;&lt;br/&gt;
2. rebase my local trunk and use new HiveConf.java.&lt;br/&gt;
3. rework the initialization order so that we use proxy Session.&lt;/p&gt;</comment>
                            <comment id="14071020" author="szehon" created="Tue, 22 Jul 2014 22:15:26 +0000"  >&lt;p&gt;+1 pending tests, thanks for making these changes.  It seems Lefty also approved on the review-board.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt; can we add Dong Chen to contributor list so that he can get the credit?&lt;/p&gt;</comment>
                            <comment id="14071073" author="lefty@hortonworks.com" created="Tue, 22 Jul 2014 22:53:36 +0000"  >&lt;p&gt;Yes, +1 as far as docs go.  (I&apos;m not qualified to judge the code, but pushing the &quot;Ship It&quot; button was fun.)&lt;/p&gt;</comment>
                            <comment id="14071976" author="hiveqa" created="Wed, 23 Jul 2014 17:07:46 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12657092/HIVE-5160.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12657092/HIVE-5160.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 5754 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_optimization
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/21/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/21/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/21/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/21/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-21/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-21/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12657092&lt;/p&gt;</comment>
                            <comment id="14072680" author="szehon" created="Thu, 24 Jul 2014 01:30:31 +0000"  >&lt;p&gt;Committed to trunk.  Thanks Dong Chen for the contribution!&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt; , &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cwsteinbach&quot; class=&quot;user-hover&quot; rel=&quot;cwsteinbach&quot;&gt;Carl Steinbach&lt;/a&gt; Hi can one of you guys add Dong Chen to the contributor list so we can credit the JIRA to him?&lt;/p&gt;</comment>
                            <comment id="14072691" author="brocknoland" created="Thu, 24 Jul 2014 01:51:34 +0000"  >&lt;p&gt;Nice work Dong Chen! Thank you much for the contribution! I think we should change one &lt;b&gt;small&lt;/b&gt; item (in HiveConf related specifically to the Hive build) and thus I have filed &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7497&quot; title=&quot;Fix some default values in HiveConf&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7497&quot;&gt;&lt;del&gt;HIVE-7497&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14072779" author="lefty@hortonworks.com" created="Thu, 24 Jul 2014 04:32:56 +0000"  >&lt;p&gt;This adds &lt;b&gt;hive.global.init.file.location&lt;/b&gt; to HiveConf.java and the template file, so it needs to be included in two wikidocs:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-HiveServer2&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Configuration Properties &amp;#8211; HiveServer2 &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Setting+Up+HiveServer2#SettingUpHiveServer2-HowtoConfigure&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Setting Up HiveServer2 &amp;#8211; How to Configure &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Questions:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Does this parameter only apply to HiveServer2?&lt;/li&gt;
	&lt;li&gt;If so, why isn&apos;t it named hive.server2.* like the other HS2 parameters?  (Sorry for asking after the commit.)&lt;/li&gt;
	&lt;li&gt;Is any other doc needed, such as usage notes or examples?&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="14072884" author="szehon" created="Thu, 24 Jul 2014 06:26:47 +0000"  >&lt;p&gt;Brock&apos;s scenario of generating a wrong hive-default-template during build is possible (now the template is generated).  As of now it would show up during review, but it seems that the template is pending to be removed from source-control, so we probably should fix that.&lt;/p&gt;

&lt;p&gt;Also I think Lefty has a nice suggestion about renaming the property for consistency.  Dong Chen, what do you think?&lt;/p&gt;</comment>
                            <comment id="14072987" author="dongc" created="Thu, 24 Jul 2014 08:30:21 +0000"  >&lt;p&gt;Hi Brock, Lefty, Szehon, thanks for your comments and nice suggestion.&lt;/p&gt;

&lt;p&gt;1. The wrong generated hive-default-template during build (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7497&quot; title=&quot;Fix some default values in HiveConf&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7497&quot;&gt;&lt;del&gt;HIVE-7497&lt;/del&gt;&lt;/a&gt;) has been fixed. I also found we might need use ${env:xxx} for properties related to env variable. The details were commented in that Jira. Could you please help to take a look at it?&lt;/p&gt;

&lt;p&gt;2. Renaming the property to hive.server2.* is a nice suggestion. I did the change in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7497&quot; title=&quot;Fix some default values in HiveConf&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7497&quot;&gt;&lt;del&gt;HIVE-7497&lt;/del&gt;&lt;/a&gt;, instead of filing a new Jira or continuing in this Jira. In case that there might be conflict when merging code. Do you think putting this change in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7497&quot; title=&quot;Fix some default values in HiveConf&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7497&quot;&gt;&lt;del&gt;HIVE-7497&lt;/del&gt;&lt;/a&gt; is OK?&lt;/p&gt;</comment>
                            <comment id="14073353" author="lefty@hortonworks.com" created="Thu, 24 Jul 2014 16:30:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;2. Renaming the property to hive.server2.*  ...  putting this change in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7497&quot; title=&quot;Fix some default values in HiveConf&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7497&quot;&gt;&lt;del&gt;HIVE-7497&lt;/del&gt;&lt;/a&gt; is OK?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, that&apos;s the best place for it.  Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongc&quot; class=&quot;user-hover&quot; rel=&quot;dongc&quot;&gt;Dong Chen&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14144081" author="lefty@hortonworks.com" created="Tue, 23 Sep 2014 00:03:04 +0000"  >&lt;p&gt;Doc note:  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8138&quot; title=&quot;Global Init file should allow specifying file name  not only directory&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8138&quot;&gt;&lt;del&gt;HIVE-8138&lt;/del&gt;&lt;/a&gt; alters the behavior of &lt;b&gt;hive.server2.global.init.file.location&lt;/b&gt; (originally &lt;b&gt;hive.global.init.file.location&lt;/b&gt;), so use the description in that patch when documenting the parameter in these two wikidocs:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-HiveServer2&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Configuration Properties &amp;#8211; HiveServer2 &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Setting+Up+HiveServer2#SettingUpHiveServer2-HowtoConfigure&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Setting Up HiveServer2 &amp;#8211; How to Configure &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14207780" author="szehon" created="Wed, 12 Nov 2014 07:52:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=leftylev&quot; class=&quot;user-hover&quot; rel=&quot;leftylev&quot;&gt;Lefty Leverenz&lt;/a&gt; Added a section:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Setting+Up+HiveServer2#SettingUpHiveServer2-OptionalGlobalInitFile(.hiverc)&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/Setting+Up+HiveServer2#SettingUpHiveServer2-OptionalGlobalInitFile(.hiverc)&lt;/a&gt;&lt;br/&gt;
and&lt;br/&gt;
&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties&lt;/a&gt;&lt;br/&gt;
under hive.server2.global.init.file.location.&lt;/p&gt;

&lt;p&gt;Wiki beginner question, I wonder how do you generate a link to a specific configuration property in the second page, without typing it out?&lt;/p&gt;</comment>
                            <comment id="14207821" author="lefty@hortonworks.com" created="Wed, 12 Nov 2014 08:45:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;... how do you generate a link to a specific configuration property ...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Take the link to any heading in Configuration Properties and substitute the property name.  (This works because each property is a level-5 heading.)&lt;/p&gt;

&lt;p&gt;For example, for a link to hive.server2.global.init.file.location go to the Configuration Properties page, click the Tez link in the table of contents (Tez because it&apos;s nice and short, so easy to delete) and copy the URL at the top of the window:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-Tez&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-Tez&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Then replace &quot;-Tez&quot; with &quot;-hive.server2.global.init.file.location&quot;:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.server2.global.init.file.location&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.server2.global.init.file.location&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The process is a kludge but it&apos;s easier than remembering the link syntax for headings.  I should add a section about wiki links in &lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/AboutThisWiki&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;About This Wiki&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14210801" author="thejas" created="Thu, 13 Nov 2014 19:42:40 +0000"  >&lt;p&gt;This has been fixed in 0.14 release. Please open new jira if you see any issues.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12741863">HIVE-8138</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12921317">HIVE-12660</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12729324">HIVE-7497</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12699041">HIVE-6561</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12657092" name="HIVE-5160.1.patch" size="20730" author="dongc" created="Tue, 22 Jul 2014 08:49:59 +0000"/>
                            <attachment id="12656869" name="HIVE-5160.patch" size="20981" author="dongc" created="Mon, 21 Jul 2014 14:00:27 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 21 Jul 2014 13:57:49 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345741</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 10 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nmdb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>346042</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5161] Additional SerDe support for varchar type</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5161</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Breaking out support for varchar for the various SerDes as an additional task.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665803">HIVE-5161</key>
            <summary>Additional SerDe support for varchar type</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jdere">Jason Dere</assignee>
                                    <reporter username="jdere">Jason Dere</reporter>
                        <labels>
                            <label>TODOC12</label>
                    </labels>
                <created>Tue, 27 Aug 2013 22:01:19 +0000</created>
                <updated>Sun, 15 Jun 2014 04:50:38 +0000</updated>
                            <resolved>Mon, 16 Sep 2013 02:12:33 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Serializers/Deserializers</component>
                    <component>Types</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13754206" author="hiveqa" created="Thu, 29 Aug 2013 23:42:27 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12600626/HIVE-5161.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12600626/HIVE-5161.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/562/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/562/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/562/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/562/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-562/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;jdbc/src/test/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java&apos;
Reverted &apos;jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java&apos;
Reverted &apos;jdbc/src/java/org/apache/hadoop/hive/jdbc/JdbcColumn.java&apos;
Reverted &apos;jdbc/src/java/org/apache/hadoop/hive/jdbc/Utils.java&apos;
Reverted &apos;jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveBaseResultSet.java&apos;
Reverted &apos;jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveMetaDataResultSet.java&apos;
Reverted &apos;jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveResultSetMetaData.java&apos;
Reverted &apos;jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveQueryResultSet.java&apos;
Reverted &apos;jdbc/src/java/org/apache/hive/jdbc/Utils.java&apos;
Reverted &apos;jdbc/src/java/org/apache/hive/jdbc/HiveBaseResultSet.java&apos;
Reverted &apos;jdbc/src/java/org/apache/hive/jdbc/HiveResultSetMetaData.java&apos;
Reverted &apos;jdbc/src/java/org/apache/hive/jdbc/JdbcColumn.java&apos;
Reverted &apos;jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java&apos;
Reverted &apos;metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java&apos;
Reverted &apos;data/files/datatypes.txt&apos;
Reverted &apos;contrib/src/java/org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesRecordReader.java&apos;
Reverted &apos;service/src/java/org/apache/hive/service/cli/TypeDescriptor.java&apos;
Reverted &apos;service/src/java/org/apache/hive/service/cli/Type.java&apos;
Reverted &apos;service/src/java/org/apache/hive/service/cli/ColumnValue.java&apos;
Reverted &apos;service/src/java/org/apache/hive/service/cli/ColumnDescriptor.java&apos;
Reverted &apos;service/src/gen/thrift/gen-py/TCLIService/ttypes.py&apos;
Reverted &apos;service/src/gen/thrift/gen-py/TCLIService/constants.py&apos;
Reverted &apos;service/src/gen/thrift/gen-cpp/TCLIService_types.cpp&apos;
Reverted &apos;service/src/gen/thrift/gen-cpp/TCLIService_types.h&apos;
Reverted &apos;service/src/gen/thrift/gen-cpp/TCLIService_constants.cpp&apos;
Reverted &apos;service/src/gen/thrift/gen-cpp/TCLIService_constants.h&apos;
Reverted &apos;service/src/gen/thrift/gen-rb/t_c_l_i_service_constants.rb&apos;
Reverted &apos;service/src/gen/thrift/gen-rb/t_c_l_i_service_types.rb&apos;
Reverted &apos;service/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/service/ThriftHive.java&apos;
Reverted &apos;service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TTypeDesc.java&apos;
Reverted &apos;service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TRowSet.java&apos;
Reverted &apos;service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TCLIServiceConstants.java&apos;
Reverted &apos;service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TStructTypeEntry.java&apos;
Reverted &apos;service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TPrimitiveTypeEntry.java&apos;
Reverted &apos;service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TUnionTypeEntry.java&apos;
Reverted &apos;service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TOpenSessionReq.java&apos;
Reverted &apos;service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TStatus.java&apos;
Reverted &apos;service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TColumn.java&apos;
Reverted &apos;service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TExecuteStatementReq.java&apos;
Reverted &apos;service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TTableSchema.java&apos;
Reverted &apos;service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TGetTablesReq.java&apos;
Reverted &apos;service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TTypeId.java&apos;
Reverted &apos;service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TOpenSessionResp.java&apos;
Reverted &apos;service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TRow.java&apos;
Reverted &apos;service/if/TCLIService.thrift&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyPrimitiveObjectInspectorFactory.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/BinarySortableSerDe.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryUtils.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryFactory.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/dynamic_type/DynamicSerDe.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/PrimitiveTypeInfo.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfo.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoUtils.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorConverters.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/PrimitiveObjectInspector.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorUtils.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/AbstractPrimitiveObjectInspector.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/SerDeUtils.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/io/DoubleWritable.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroObjectInspectorGenerator.java&apos;
Reverted &apos;serde/src/gen/thrift/gen-py/org_apache_hadoop_hive_serde/constants.py&apos;
Reverted &apos;serde/src/gen/thrift/gen-cpp/serde_constants.cpp&apos;
Reverted &apos;serde/src/gen/thrift/gen-cpp/serde_constants.h&apos;
Reverted &apos;serde/src/gen/thrift/gen-rb/serde_constants.rb&apos;
Reverted &apos;serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/test/ThriftTestObj.java&apos;
Reverted &apos;serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/serdeConstants.java&apos;
Reverted &apos;serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/Complex.java&apos;
Reverted &apos;serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/MegaStruct.java&apos;
Reverted &apos;serde/src/gen/thrift/gen-php/org/apache/hadoop/hive/serde/Types.php&apos;
Reverted &apos;serde/if/serde.thrift&apos;
Reverted &apos;ql/src/test/results/compiler/plan/udf6.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/groupby2.q.xml&apos;
Reverted &apos;ql/src/test/org/apache/hadoop/hive/ql/exec/TestFunctionRegistry.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/metadata/VirtualColumn.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/GenericUDFEncode.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFStringToMap.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToDate.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFConcatWS.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBaseCompare.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFReflect2.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToString.java&apos;
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf build data/files/vc1.txt hcatalog/build hcatalog/core/build hcatalog/storage-handlers/hbase/build hcatalog/server-extensions/build hcatalog/webhcat/svr/build hcatalog/webhcat/java-client/build hcatalog/hcatalog-pig-adapter/build common/src/gen common/src/test/org/apache/hadoop/hive/common/type common/src/java/org/apache/hadoop/hive/common/type/HiveVarchar.java common/src/java/org/apache/hadoop/hive/common/type/HiveBaseChar.java service/src/java/org/apache/hive/service/cli/TypeQualifiers.java service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TTypeQualifierValue.java service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TTypeQualifiers.java serde/src/test/org/apache/hadoop/hive/serde2/typeinfo serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyHiveVarchar.java serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyHiveVarcharObjectInspector.java serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryHiveVarchar.java serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/BaseTypeParams.java serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/ParameterizedPrimitiveTypeInfo.java serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/ParameterizedPrimitiveTypeUtils.java serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/VarcharTypeParams.java serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/SettableHiveVarcharObjectInspector.java serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/HiveVarcharObjectInspector.java serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaHiveVarcharObjectInspector.java serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableHiveVarcharObjectInspector.java serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/ParameterizedObjectInspector.java serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveVarcharObjectInspector.java serde/src/java/org/apache/hadoop/hive/serde2/io/HiveVarcharWritable.java ql/src/test/results/clientpositive/varchar_union1.q.out ql/src/test/results/clientpositive/varchar_cast.q.out ql/src/test/results/clientpositive/alter_varchar1.q.out ql/src/test/results/clientpositive/varchar_udf1.q.out ql/src/test/results/clientpositive/varchar_2.q.out ql/src/test/results/clientpositive/partition_varchar1.q.out ql/src/test/results/clientpositive/varchar_nested_types.q.out ql/src/test/results/clientpositive/varchar_join1.q.out ql/src/test/results/clientpositive/varchar_comparison.q.out ql/src/test/results/clientpositive/ctas_varchar.q.out ql/src/test/results/clientpositive/varchar_1.q.out ql/src/test/queries/clientpositive/varchar_cast.q ql/src/test/queries/clientpositive/varchar_join1.q ql/src/test/queries/clientpositive/alter_varchar1.q ql/src/test/queries/clientpositive/varchar_1.q ql/src/test/queries/clientpositive/partition_varchar1.q ql/src/test/queries/clientpositive/varchar_comparison.q ql/src/test/queries/clientpositive/ctas_varchar.q ql/src/test/queries/clientpositive/varchar_2.q ql/src/test/queries/clientpositive/varchar_nested_types.q ql/src/test/queries/clientpositive/varchar_udf1.q ql/src/test/queries/clientpositive/varchar_union1.q ql/src/java/org/apache/hadoop/hive/ql/exec/SettableUDF.java ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFConcat.java ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLower.java ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUpper.java ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1518855.

At revision 1518855.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/ColumnStatisticsImpl.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcStruct.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java
Hunk #3 succeeded at 880 (offset 19 lines).
Hunk #4 succeeded at 1027 (offset 20 lines).
Hunk #5 succeeded at 1535 (offset 20 lines).
Hunk #6 succeeded at 1603 (offset 20 lines).
patching file ql/src/protobuf/org/apache/hadoop/hive/ql/io/orc/orc_proto.proto
patching file ql/src/test/queries/clientpositive/varchar_serde.q
patching file ql/src/test/results/clientpositive/varchar_serde.q.out
patching file serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java
+ [[ true == \t\r\u\e ]]
+ rm -rf /data/hive-ptest/working/ivy /data/hive-ptest/working/maven
+ mkdir /data/hive-ptest/working/ivy /data/hive-ptest/working/maven
+ ant -Dtest.continue.on.failure=true -Dtest.silent=false -Divy.default.ivy.user.dir=/data/hive-ptest/working/ivy -Dmvn.local.repo=/data/hive-ptest/working/maven clean package test -Dtestcase=nothing
Buildfile: /data/hive-ptest/working/apache-svn-trunk-source/build.xml

clean:
     [echo] Project: hive

clean:
     [echo] Project: anttasks

clean:
     [echo] Project: shims

clean:
     [echo] Project: common

clean:
     [echo] Project: serde

clean:
     [echo] Project: metastore

clean:
     [echo] Project: ql

clean:
     [echo] Project: contrib

clean:
     [echo] Project: service

clean:
     [echo] Project: cli

clean:
     [echo] Project: jdbc

clean:
     [echo] Project: beeline

clean:
     [echo] Project: hwi

clean:
     [echo] Project: hbase-handler

clean:
     [echo] Project: testutils

clean:
     [echo] hcatalog

clean:
     [echo] hcatalog-core

clean:
     [echo] hcatalog-pig-adapter

clean:
     [echo] hcatalog-server-extensions

clean:
     [echo] webhcat

clean:
     [echo] webhcat-java-client

clean:

clean:
     [echo] shims

clean:
     [echo] Project: odbc
     [exec] rm -rf /data/hive-ptest/working/apache-svn-trunk-source/build/odbc /data/hive-ptest/working/apache-svn-trunk-source/build/service/objs /data/hive-ptest/working/apache-svn-trunk-source/build/ql/objs /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/objs

clean-online:
     [echo] Project: hive

clean-offline:

ivy-init-dirs:
     [echo] Project: hive
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/maven

ivy-download:
     [echo] Project: hive
      [get] Getting: http://repo2.maven.org/maven2/org/apache/ivy/ivy/2.3.0/ivy-2.3.0.jar
      [get] To: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/ivy-2.3.0.jar

ivy-probe-antlib:
     [echo] Project: hive

ivy-init-antlib:
     [echo] Project: hive

compile-ant-tasks:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jexl/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

ivy-init-settings:
     [echo] Project: anttasks

ivy-resolve:
     [echo] Project: anttasks
[ivy:resolve] :: Apache Ivy 2.3.0 - 20130110142753 :: http://ant.apache.org/ivy/ ::
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-anttasks;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found velocity#velocity;1.5 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-lang/commons-lang/2.4/commons-lang-2.4.jar ...
[ivy:resolve] ..... (255kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-lang#commons-lang;2.4!commons-lang.jar (30ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/velocity/velocity/1.5/velocity-1.5.jar ...
[ivy:resolve] ....... (382kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] velocity#velocity;1.5!velocity.jar (32ms)
[ivy:resolve] :: resolution report :: resolve 4392ms :: artifacts dl 81ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-anttasks-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-anttasks-default.html

ivy-retrieve:
     [echo] Project: anttasks
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-anttasks
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	2 artifacts copied, 0 already retrieved (638kB/8ms)

compile:
     [echo] anttasks
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ant/build.xml:38: warning: &apos;includeantruntime&apos; was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds
    [javac] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.

deploy-ant-tasks:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

ivy-init-settings:
     [echo] Project: anttasks

ivy-resolve:
     [echo] Project: anttasks
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-anttasks;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found velocity#velocity;1.5 in maven2
[ivy:resolve] :: resolution report :: resolve 492ms :: artifacts dl 3ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-anttasks-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-anttasks-default.html

ivy-retrieve:
     [echo] Project: anttasks
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-anttasks
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	0 artifacts copied, 2 already retrieved (0kB/13ms)

compile:
     [echo] anttasks
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ant/build.xml:38: warning: &apos;includeantruntime&apos; was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds

jar:
     [echo] anttasks
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes/org/apache/hadoop/hive/ant
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/hive-anttasks-0.12.0-SNAPSHOT.jar

init:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

create-dirs:
     [echo] Project: shims
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/test/resources does not exist.

init:
     [echo] Project: shims

create-dirs:
     [echo] Project: common
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/resources
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/resources

init:
     [echo] Project: common

create-dirs:
     [echo] Project: serde
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources does not exist.

init:
     [echo] Project: serde

create-dirs:
     [echo] Project: metastore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources does not exist.

init:
     [echo] Project: metastore

create-dirs:
     [echo] Project: ql
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/resources
     [copy] Copying 3 files to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/resources

init:
     [echo] Project: ql

create-dirs:
     [echo] Project: contrib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources does not exist.

init:
     [echo] Project: contrib

create-dirs:
     [echo] Project: service
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources does not exist.

init:
     [echo] Project: service

create-dirs:
     [echo] Project: cli
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/resources does not exist.

init:
     [echo] Project: cli

create-dirs:
     [echo] Project: jdbc
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/test/resources does not exist.

init:
     [echo] Project: jdbc

create-dirs:
     [echo] Project: beeline
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/test/resources does not exist.

init:
     [echo] Project: beeline

create-dirs:
     [echo] Project: hwi
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources does not exist.

init:
     [echo] Project: hwi

create-dirs:
     [echo] Project: hbase-handler
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources does not exist.

init:
     [echo] Project: hbase-handler

create-dirs:
     [echo] Project: testutils
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources does not exist.

init:
     [echo] Project: testutils

init:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build/hcatalog-0.12.0-SNAPSHOT

jar:
     [echo] Project: hive

ivy-init-settings:
     [echo] Project: shims

check-ivy:
     [echo] Project: shims

ivy-resolve:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.zookeeper#zookeeper;3.4.3 in maven2
[ivy:resolve] 	found org.apache.thrift#libthrift;0.9.0 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.4 in maven2
[ivy:resolve] 	found commons-logging#commons-logging-api;1.0.4 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.4 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar ...
[ivy:resolve] .............. (749kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.3!zookeeper.jar (24ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar ...
[ivy:resolve] ....... (339kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.thrift#libthrift;0.9.0!libthrift.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging/1.0.4/commons-logging-1.0.4.jar ...
[ivy:resolve] .. (37kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-logging#commons-logging;1.0.4!commons-logging.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging-api/1.0.4/commons-logging-api-1.0.4.jar ...
[ivy:resolve] .. (25kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-logging#commons-logging-api;1.0.4!commons-logging-api.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar ...
[ivy:resolve] ..... (222kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-core-asl;1.8.8!jackson-core-asl.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar ...
[ivy:resolve] ............ (652kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-mapper-asl;1.8.8!jackson-mapper-asl.jar (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/log4j/log4j/1.2.16/log4j-1.2.16.jar ...
[ivy:resolve] ......... (470kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] log4j#log4j;1.2.16!log4j.jar(bundle) (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/guava/guava/11.0.2/guava-11.0.2.jar ...
[ivy:resolve] ............................ (1609kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.guava#guava;11.0.2!guava.jar (43ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-io/commons-io/2.4/commons-io-2.4.jar ...
[ivy:resolve] .... (180kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-io#commons-io;2.4!commons-io.jar (9ms)
[ivy:resolve] :: resolution report :: resolve 8054ms :: artifacts dl 175ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   9   |   9   |   0   ||   9   |   9   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-shims-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-shims-default.html

make-pom:
     [echo] Project: shims
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: shims
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/test/resources does not exist.

init:
     [echo] Project: shims

ivy-retrieve:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	9 artifacts copied, 0 already retrieved (4287kB/19ms)

compile:
     [echo] Project: shims
     [echo] Building shims 0.20

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20/java against hadoop 0.20.2 (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-0.20.2)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.20.shim]
[ivy:resolve] 	found org.apache.hadoop#hadoop-core;0.20.2 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.0.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.3 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.3 in maven2
[ivy:resolve] 	found commons-net#commons-net;1.4.1 in maven2
[ivy:resolve] 	found oro#oro;2.0.8 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api-2.5;6.1.14 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.12 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.12 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-api-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.eclipse.jdt#core;3.1.1 in maven2
[ivy:resolve] 	found ant#ant;1.6.5 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.7.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found net.sf.kosmosfs#kfs;0.3 in maven2
[ivy:resolve] 	found junit#junit;4.5 in maven2
[ivy:resolve] 	found hsqldb#hsqldb;1.8.0.10 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-tools;0.20.2 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-test;0.20.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftplet-api;1.0.0 in maven2
[ivy:resolve] 	found org.apache.mina#mina-core;2.0.0-M5 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.5.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-core;1.0.0 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-core/0.20.2/hadoop-core-0.20.2.jar ...
[ivy:resolve] ............................................ (2624kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-core;0.20.2!hadoop-core.jar (55ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-tools/0.20.2/hadoop-tools-0.20.2.jar ...
[ivy:resolve] ... (68kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-tools;0.20.2!hadoop-tools.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-test/0.20.2/hadoop-test-0.20.2.jar ...
[ivy:resolve] ........................... (1527kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-test;0.20.2!hadoop-test.jar (34ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-cli/commons-cli/1.2/commons-cli-1.2.jar ...
[ivy:resolve] .. (40kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-cli#commons-cli;1.2!commons-cli.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/xmlenc/xmlenc/0.52/xmlenc-0.52.jar ...
[ivy:resolve] .. (14kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] xmlenc#xmlenc;0.52!xmlenc.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar ...
[ivy:resolve] ...... (273kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-httpclient#commons-httpclient;3.0.1!commons-httpclient.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-codec/commons-codec/1.3/commons-codec-1.3.jar ...
[ivy:resolve] .. (45kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-codec#commons-codec;1.3!commons-codec.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar ...
[ivy:resolve] .... (176kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-net#commons-net;1.4.1!commons-net.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty/6.1.14/jetty-6.1.14.jar ...
[ivy:resolve] ......... (504kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty;6.1.14!jetty.jar (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.14/jetty-util-6.1.14.jar ...
[ivy:resolve] .... (159kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty-util;6.1.14!jetty-util.jar (18ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar ...
[ivy:resolve] ... (74kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-runtime;5.5.12!jasper-runtime.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar ...
[ivy:resolve] ........ (395kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-compiler;5.5.12!jasper-compiler.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar ...
[ivy:resolve] .... (131kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jsp-api-2.1;6.1.14!jsp-api-2.1.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar ...
[ivy:resolve] ................. (1000kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jsp-2.1;6.1.14!jsp-2.1.jar (27ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-el/commons-el/1.0/commons-el-1.0.jar ...
[ivy:resolve] ... (109kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-el#commons-el;1.0!commons-el.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar ...
[ivy:resolve] ....... (368kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.java.dev.jets3t#jets3t;0.7.1!jets3t.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar ...
[ivy:resolve] .... (129kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#servlet-api-2.5;6.1.14!servlet-api-2.5.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar ...
[ivy:resolve] .. (11kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.sf.kosmosfs#kfs;0.3!kfs.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/4.5/junit-4.5.jar ...
[ivy:resolve] ..... (194kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] junit#junit;4.5!junit.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar ...
[ivy:resolve] ............. (690kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] hsqldb#hsqldb;1.8.0.10!hsqldb.jar (18ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/oro/oro/2.0.8/oro-2.0.8.jar ...
[ivy:resolve] .. (63kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] oro#oro;2.0.8!oro.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar ...
[ivy:resolve] ......................................................................................................... (3483kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.eclipse.jdt#core;3.1.1!core.jar (74ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/ant/ant/1.6.5/ant-1.6.5.jar ...
[ivy:resolve] ................. (1009kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] ant#ant;1.6.5!ant.jar (24ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar ...
[ivy:resolve] .. (59kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-logging#commons-logging;1.1.1!commons-logging.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftplet-api/1.0.0/ftplet-api-1.0.0.jar ...
[ivy:resolve] .. (22kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftplet-api;1.0.0!ftplet-api.jar(bundle) (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/mina/mina-core/2.0.0-M5/mina-core-2.0.0-M5.jar ...
[ivy:resolve] ........... (622kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.mina#mina-core;2.0.0-M5!mina-core.jar(bundle) (37ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftpserver-core/1.0.0/ftpserver-core-1.0.0.jar ...
[ivy:resolve] ...... (264kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftpserver-core;1.0.0!ftpserver-core.jar(bundle) (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftpserver-deprecated/1.0.0-M2/ftpserver-deprecated-1.0.0-M2.jar ...
[ivy:resolve] .. (31kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2!ftpserver-deprecated.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.5.2/slf4j-api-1.5.2.jar ...
[ivy:resolve] .. (16kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-api;1.5.2!slf4j-api.jar (5ms)
[ivy:resolve] :: resolution report :: resolve 30224ms :: artifacts dl 569ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	junit#junit;3.8.1 by [junit#junit;4.5] in [hadoop0.20.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.0.3 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20.shim]
[ivy:resolve] 	commons-codec#commons-codec;1.2 by [commons-codec#commons-codec;1.3] in [hadoop0.20.shim]
[ivy:resolve] 	commons-httpclient#commons-httpclient;3.1 by [commons-httpclient#commons-httpclient;3.0.1] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M4 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.ftpserver#ftplet-api;1.0.0-M2 by [org.apache.ftpserver#ftplet-api;1.0.0] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.ftpserver#ftpserver-core;1.0.0-M2 by [org.apache.ftpserver#ftpserver-core;1.0.0] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M2 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20.shim]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|  hadoop0.20.shim |   37  |   30  |   30  |   8   ||   29  |   29  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.20.shim]
[ivy:retrieve] 	29 artifacts copied, 0 already retrieved (14115kB/98ms)
    [javac] Compiling 17 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [echo] Building shims 0.20S

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/common-secure/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20S/java against hadoop 1.1.2 (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-1.1.2)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.20S.shim]
[ivy:resolve] 	found org.apache.hadoop#hadoop-core;1.1.2 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-core;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-json;1.8 in maven2
[ivy:resolve] 	found org.codehaus.jettison#jettison;1.1 in maven2
[ivy:resolve] 	found stax#stax-api;1.0.1 in maven2
[ivy:resolve] 	found com.sun.xml.bind#jaxb-impl;2.2.3-1 in maven2
[ivy:resolve] 	found javax.xml.bind#jaxb-api;2.2.2 in maven2
[ivy:resolve] 	found javax.xml.stream#stax-api;1.0-2 in maven2
[ivy:resolve] 	found javax.activation#activation;1.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-jaxrs;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-xc;1.7.1 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-server;1.8 in maven2
[ivy:resolve] 	found asm#asm;3.1 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.1 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.0.1 in maven2
[ivy:resolve] 	found junit#junit;3.8.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.3 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.commons#commons-math;2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found commons-digester#commons-digester;1.8 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils;1.7.0 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils-core;1.8.0 in maven2
[ivy:resolve] 	found commons-net#commons-net;1.4.1 in maven2
[ivy:resolve] 	found oro#oro;2.0.8 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api;2.5-20081211 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.12 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.12 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-api-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api-2.5;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.eclipse.jdt#core;3.1.1 in maven2
[ivy:resolve] 	found ant#ant;1.6.5 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.6.1 in maven2
[ivy:resolve] 	found hsqldb#hsqldb;1.8.0.10 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-tools;1.1.2 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-test;1.1.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftplet-api;1.0.0 in maven2
[ivy:resolve] 	found org.apache.mina#mina-core;2.0.0-M5 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.5.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-core;1.0.0 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-core/1.1.2/hadoop-core-1.1.2.jar ...
[ivy:resolve] ........................................................................................................... (3941kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-core;1.1.2!hadoop-core.jar (77ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-tools/1.1.2/hadoop-tools-1.1.2.jar ...
[ivy:resolve] ...... (299kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-tools;1.1.2!hadoop-tools.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-test/1.1.2/hadoop-test-1.1.2.jar ...
[ivy:resolve] ............................................... (2712kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-test;1.1.2!hadoop-test.jar (53ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar ...
[ivy:resolve] ........ (447kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-core;1.8!jersey-core.jar(bundle) (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar ...
[ivy:resolve] .... (144kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-json;1.8!jersey-json.jar(bundle) (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar ...
[ivy:resolve] ............. (678kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-server;1.8!jersey-server.jar(bundle) (27ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-io/commons-io/2.1/commons-io-2.1.jar ...
[ivy:resolve] .... (159kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-io#commons-io;2.1!commons-io.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-codec/commons-codec/1.4/commons-codec-1.4.jar ...
[ivy:resolve] .. (56kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-codec#commons-codec;1.4!commons-codec.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-math/2.1/commons-math-2.1.jar ...
[ivy:resolve] ............... (812kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.commons#commons-math;2.1!commons-math.jar (20ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar ...
[ivy:resolve] ...... (291kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-configuration#commons-configuration;1.6!commons-configuration.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar ...
[ivy:resolve] .......... (527kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty;6.1.26!jetty.jar (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar ...
[ivy:resolve] .... (172kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty-util;6.1.26!jetty-util.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar ...
[ivy:resolve] ...... (314kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.java.dev.jets3t#jets3t;0.6.1!jets3t.jar (21ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar ...
[ivy:resolve] ... (66kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jettison#jettison;1.1!jettison.jar(bundle) (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar ...
[ivy:resolve] ................ (869kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.xml.bind#jaxb-impl;2.2.3-1!jaxb-impl.jar (21ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.7.1/jackson-jaxrs-1.7.1.jar ...
[ivy:resolve] .. (17kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-jaxrs;1.7.1!jackson-jaxrs.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar ...
[ivy:resolve] .. (30kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-xc;1.7.1!jackson-xc.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/stax/stax-api/1.0.1/stax-api-1.0.1.jar ...
[ivy:resolve] .. (25kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] stax#stax-api;1.0.1!stax-api.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar ...
[ivy:resolve] ... (102kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.xml.bind#jaxb-api;2.2.2!jaxb-api.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar ...
[ivy:resolve] .. (22kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.xml.stream#stax-api;1.0-2!stax-api.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/activation/activation/1.1/activation-1.1.jar ...
[ivy:resolve] .. (61kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.activation#activation;1.1!activation.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/asm/asm/3.1/asm-3.1.jar ...
[ivy:resolve] .. (42kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] asm#asm;3.1!asm.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/3.8.1/junit-3.8.1.jar ...
[ivy:resolve] ... (118kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] junit#junit;3.8.1!junit.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar ...
[ivy:resolve] .......... (561kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-collections#commons-collections;3.2.1!commons-collections.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-digester/commons-digester/1.8/commons-digester-1.8.jar ...
[ivy:resolve] .... (140kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-digester#commons-digester;1.8!commons-digester.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar ...
[ivy:resolve] ..... (201kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-beanutils#commons-beanutils-core;1.8.0!commons-beanutils-core.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar ...
[ivy:resolve] .... (184kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-beanutils#commons-beanutils;1.7.0!commons-beanutils.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar ...
[ivy:resolve] .... (130kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#servlet-api;2.5-20081211!servlet-api.jar (8ms)
[ivy:resolve] :: resolution report :: resolve 35568ms :: artifacts dl 509ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	org.codehaus.jackson#jackson-core-asl;1.7.1 by [org.codehaus.jackson#jackson-core-asl;1.8.8] in [hadoop0.20S.shim]
[ivy:resolve] 	org.codehaus.jackson#jackson-mapper-asl;1.7.1 by [org.codehaus.jackson#jackson-mapper-asl;1.8.8] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.0.3 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-codec#commons-codec;1.2 by [commons-codec#commons-codec;1.4] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.1 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-codec#commons-codec;1.3 by [commons-codec#commons-codec;1.4] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-httpclient#commons-httpclient;3.1 by [commons-httpclient#commons-httpclient;3.0.1] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M4 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.ftpserver#ftplet-api;1.0.0-M2 by [org.apache.ftpserver#ftplet-api;1.0.0] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.ftpserver#ftpserver-core;1.0.0-M2 by [org.apache.ftpserver#ftpserver-core;1.0.0] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M2 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20S.shim]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	| hadoop0.20S.shim |   62  |   30  |   30  |   11  ||   51  |   28  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.20S.shim]
[ivy:retrieve] 	51 artifacts copied, 0 already retrieved (22876kB/97ms)
    [javac] Compiling 14 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [echo] Building shims 0.23

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/common-secure/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.23/java against hadoop 2.0.5-alpha (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-2.0.5-alpha)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.23.shim]
[ivy:resolve] 	found org.apache.hadoop#hadoop-common;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-annotations;2.0.5-alpha in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-math;2.1 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.1 in maven2
[ivy:resolve] 	found commons-net#commons-net;3.1 in maven2
[ivy:resolve] 	found javax.servlet#servlet-api;2.5 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.26 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-core;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-json;1.8 in maven2
[ivy:resolve] 	found org.codehaus.jettison#jettison;1.1 in maven2
[ivy:resolve] 	found stax#stax-api;1.0.1 in maven2
[ivy:resolve] 	found com.sun.xml.bind#jaxb-impl;2.2.3-1 in maven2
[ivy:resolve] 	found javax.xml.bind#jaxb-api;2.2.2 in maven2
[ivy:resolve] 	found javax.activation#activation;1.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-jaxrs;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-xc;1.8.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-server;1.8 in maven2
[ivy:resolve] 	found asm#asm;3.2 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.17 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.6.1 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.5 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-digester#commons-digester;1.8 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils;1.7.0 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils-core;1.8.0 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.5.3 in maven2
[ivy:resolve] 	found com.thoughtworks.paranamer#paranamer;2.3 in maven2
[ivy:resolve] 	found org.xerial.snappy#snappy-java;1.0.3.2 in maven2
[ivy:resolve] 	found net.sf.kosmosfs#kfs;0.3 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.0a in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-auth;2.0.5-alpha in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found com.jcraft#jsch;0.1.42 in maven2
[ivy:resolve] 	found org.apache.zookeeper#zookeeper;3.4.2 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.23 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.23 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found javax.servlet.jsp#jsp-api;2.1 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-core;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-common;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-api;2.0.5-alpha in maven2
[ivy:resolve] 	found com.google.inject.extensions#guice-servlet;3.0 in maven2
[ivy:resolve] 	found com.google.inject#guice;3.0 in maven2
[ivy:resolve] 	found javax.inject#javax.inject;1 in maven2
[ivy:resolve] 	found aopalliance#aopalliance;1.0 in maven2
[ivy:resolve] 	found org.sonatype.sisu.inject#cglib;2.2.1-v20090111 in maven2
[ivy:resolve] 	found io.netty#netty;3.5.11.Final in maven2
[ivy:resolve] 	found com.sun.jersey.jersey-test-framework#jersey-test-framework-grizzly2;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey.contribs#jersey-guice;1.8 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-archives;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-hdfs;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-common;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-client;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-common;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-tests;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-nodemanager;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-resourcemanager;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-web-proxy;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-app;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-hs;2.0.5-alpha in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.0.5-alpha/hadoop-common-2.0.5-alpha.jar ...
[ivy:resolve] ...................................... (2295kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-common;2.0.5-alpha!hadoop-common.jar (50ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.0.5-alpha/hadoop-common-2.0.5-alpha-tests.jar ...
[ivy:resolve] .................... (1151kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-common;2.0.5-alpha!hadoop-common.jar(tests) (26ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-core/2.0.5-alpha/hadoop-mapreduce-client-core-2.0.5-alpha.jar ...
[ivy:resolve] ....................... (1325kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-core;2.0.5-alpha!hadoop-mapreduce-client-core.jar (28ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-archives/2.0.5-alpha/hadoop-archives-2.0.5-alpha.jar ...
[ivy:resolve] .. (20kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-archives;2.0.5-alpha!hadoop-archives.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.0.5-alpha/hadoop-hdfs-2.0.5-alpha.jar ...
[ivy:resolve] .............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. (4241kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs;2.0.5-alpha!hadoop-hdfs.jar (373ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.0.5-alpha/hadoop-hdfs-2.0.5-alpha-tests.jar ...
[ivy:resolve] ........................... (1631kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs;2.0.5-alpha!hadoop-hdfs.jar(tests) (34ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.0.5-alpha/hadoop-mapreduce-client-jobclient-2.0.5-alpha-tests.jar ...
[ivy:resolve] ....................... (1350kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.0.5-alpha!hadoop-mapreduce-client-jobclient.jar(tests) (29ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.0.5-alpha/hadoop-mapreduce-client-jobclient-2.0.5-alpha.jar ...
[ivy:resolve] .. (32kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.0.5-alpha!hadoop-mapreduce-client-jobclient.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-common/2.0.5-alpha/hadoop-mapreduce-client-common-2.0.5-alpha.jar ...
[ivy:resolve] ........... (579kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-common;2.0.5-alpha!hadoop-mapreduce-client-common.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-tests/2.0.5-alpha/hadoop-yarn-server-tests-2.0.5-alpha-tests.jar ...
[ivy:resolve] .. (39kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-tests;2.0.5-alpha!hadoop-yarn-server-tests.jar(tests) (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-app/2.0.5-alpha/hadoop-mapreduce-client-app-2.0.5-alpha.jar ...
[ivy:resolve] ......... (463kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-app;2.0.5-alpha!hadoop-mapreduce-client-app.jar (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-hs/2.0.5-alpha/hadoop-mapreduce-client-hs-2.0.5-alpha.jar ...
[ivy:resolve] ... (111kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-hs;2.0.5-alpha!hadoop-mapreduce-client-hs.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-annotations/2.0.5-alpha/hadoop-annotations-2.0.5-alpha.jar ...
[ivy:resolve] .. (16kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-annotations;2.0.5-alpha!hadoop-annotations.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar ...
[ivy:resolve] ...... (297kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-httpclient#commons-httpclient;3.1!commons-httpclient.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-net/commons-net/3.1/commons-net-3.1.jar ...
[ivy:resolve] ...... (266kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-net#commons-net;3.1!commons-net.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar ...
[ivy:resolve] ... (102kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.servlet#servlet-api;2.5!servlet-api.jar (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/log4j/log4j/1.2.17/log4j-1.2.17.jar ...
[ivy:resolve] ......... (478kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] log4j#log4j;1.2.17!log4j.jar(bundle) (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-lang/commons-lang/2.5/commons-lang-2.5.jar ...
[ivy:resolve] ...... (272kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-lang#commons-lang;2.5!commons-lang.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar ...
[ivy:resolve] .. (24kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-api;1.6.1!slf4j-api.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro/1.5.3/avro-1.5.3.jar ...
[ivy:resolve] ...... (257kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro;1.5.3!avro.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.4.0a/protobuf-java-2.4.0a.jar ...
[ivy:resolve] ........ (439kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.protobuf#protobuf-java;2.4.0a!protobuf-java.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-auth/2.0.5-alpha/hadoop-auth-2.0.5-alpha.jar ...
[ivy:resolve] .. (46kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-auth;2.0.5-alpha!hadoop-auth.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar ...
[ivy:resolve] .... (181kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.jcraft#jsch;0.1.42!jsch.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.2/zookeeper-3.4.2.jar ...
[ivy:resolve] .............. (746kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.2!zookeeper.jar (18ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar ...
[ivy:resolve] .. (32kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.code.findbugs#jsr305;1.3.9!jsr305.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.8.8/jackson-jaxrs-1.8.8.jar ...
[ivy:resolve] .. (17kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-jaxrs;1.8.8!jackson-jaxrs.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.8.8/jackson-xc-1.8.8.jar ...
[ivy:resolve] .. (31kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-xc;1.8.8!jackson-xc.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/asm/asm/3.2/asm-3.2.jar ...
[ivy:resolve] .. (42kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] asm#asm;3.2!asm.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar ...
[ivy:resolve] .. (28kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.3!paranamer.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.0.3.2/snappy-java-1.0.3.2.jar ...
[ivy:resolve] ................. (972kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.0.3.2!snappy-java.jar(bundle) (25ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar ...
[ivy:resolve] .. (9kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-log4j12;1.6.1!slf4j-log4j12.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar ...
[ivy:resolve] ........ (398kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-compiler;5.5.23!jasper-compiler.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar ...
[ivy:resolve] ... (75kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-runtime;5.5.23!jasper-runtime.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar ...
[ivy:resolve] ... (98kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.servlet.jsp#jsp-api;2.1!jsp-api.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-common/2.0.5-alpha/hadoop-yarn-common-2.0.5-alpha.jar ...
[ivy:resolve] .................. (1050kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-common;2.0.5-alpha!hadoop-yarn-common.jar (24ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar ...
[ivy:resolve] .. (63kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.inject.extensions#guice-servlet;3.0!guice-servlet.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/io/netty/netty/3.5.11.Final/netty-3.5.11.Final.jar ...
[ivy:resolve] .................... (1106kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] io.netty#netty;3.5.11.Final!netty.jar(bundle) (25ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-api/2.0.5-alpha/hadoop-yarn-api-2.0.5-alpha.jar ...
[ivy:resolve] ................... (1014kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-api;2.0.5-alpha!hadoop-yarn-api.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/inject/guice/3.0/guice-3.0.jar ...
[ivy:resolve] ............ (693kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.inject#guice;3.0!guice.jar (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-test-framework/jersey-test-framework-grizzly2/1.8/jersey-test-framework-grizzly2-1.8.jar ...
[ivy:resolve] .. (12kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey.jersey-test-framework#jersey-test-framework-grizzly2;1.8!jersey-test-framework-grizzly2.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/contribs/jersey-guice/1.8/jersey-guice-1.8.jar ...
[ivy:resolve] .. (14kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey.contribs#jersey-guice;1.8!jersey-guice.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/inject/javax.inject/1/javax.inject-1.jar ...
[ivy:resolve] .. (2kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.inject#javax.inject;1!javax.inject.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/aopalliance/aopalliance/1.0/aopalliance-1.0.jar ...
[ivy:resolve] .. (4kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] aopalliance#aopalliance;1.0!aopalliance.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/sonatype/sisu/inject/cglib/2.2.1-v20090111/cglib-2.2.1-v20090111.jar ...
[ivy:resolve] ...... (272kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.sonatype.sisu.inject#cglib;2.2.1-v20090111!cglib.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-client/2.0.5-alpha/hadoop-yarn-client-2.0.5-alpha.jar ...
[ivy:resolve] .. (28kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-client;2.0.5-alpha!hadoop-yarn-client.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-common/2.0.5-alpha/hadoop-yarn-server-common-2.0.5-alpha.jar ...
[ivy:resolve] .... (148kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-common;2.0.5-alpha!hadoop-yarn-server-common.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.0.5-alpha/hadoop-yarn-server-nodemanager-2.0.5-alpha.jar ...
[ivy:resolve] ........ (404kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-nodemanager;2.0.5-alpha!hadoop-yarn-server-nodemanager.jar (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.0.5-alpha/hadoop-yarn-server-resourcemanager-2.0.5-alpha.jar ...
[ivy:resolve] .......... (517kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-resourcemanager;2.0.5-alpha!hadoop-yarn-server-resourcemanager.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.0.5-alpha/hadoop-yarn-server-web-proxy-2.0.5-alpha.jar ...
[ivy:resolve] .. (24kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-web-proxy;2.0.5-alpha!hadoop-yarn-server-web-proxy.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.0.5-alpha/hadoop-mapreduce-client-shuffle-2.0.5-alpha.jar ...
[ivy:resolve] .. (20kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.0.5-alpha!hadoop-mapreduce-client-shuffle.jar (5ms)
[ivy:resolve] :: resolution report :: resolve 59564ms :: artifacts dl 1103ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|  hadoop0.23.shim |   74  |   47  |   47  |   0   ||   77  |   50  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.23.shim]
[ivy:retrieve] 	77 artifacts copied, 0 already retrieved (31997kB/115ms)
    [javac] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.23/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.

jar:
     [echo] Project: shims
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-shims;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Thu Aug 29 19:42:08 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-shims
[ivy:publish] 	published hive-shims to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.12.0-SNAPSHOT/jars/hive-shims.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: common

check-ivy:
     [echo] Project: common

ivy-resolve:
     [echo] Project: common
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-common;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.12.0-SNAPSHOT/jars/hive-shims.jar ...
[ivy:resolve] .... (129kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-shims;0.12.0-SNAPSHOT!hive-shims.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar ...
[ivy:resolve] ..... (235kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.commons#commons-compress;1.4.1!commons-compress.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/tukaani/xz/1.0/xz-1.0.jar ...
[ivy:resolve] ... (92kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.tukaani#xz;1.0!xz.jar (13ms)
[ivy:resolve] :: resolution report :: resolve 2137ms :: artifacts dl 33ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   6   |   3   |   3   |   0   ||   6   |   3   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-common-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-common-default.html

make-pom:
     [echo] Project: common
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/common/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: common

init:
     [echo] Project: common

setup:
     [echo] Project: common

ivy-retrieve:
     [echo] Project: common
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-common
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	4 artifacts copied, 2 already retrieved (497kB/6ms)

compile:
     [echo] Project: common
    [javac] Compiling 25 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/common/src/java/org/apache/hadoop/hive/common/ObjectPair.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes

jar:
     [echo] Project: common
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/common/hive-common-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-common;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Thu Aug 29 19:42:13 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/common/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-common
[ivy:publish] 	published hive-common to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.12.0-SNAPSHOT/jars/hive-common.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: serde

check-ivy:
     [echo] Project: serde

ivy-resolve:
     [echo] Project: serde
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-serde;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.12.0-SNAPSHOT/jars/hive-common.jar ...
[ivy:resolve] ... (95kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-common;0.12.0-SNAPSHOT!hive-common.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar ...
[ivy:resolve] ...................... (1315kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mockito#mockito-all;1.8.2!mockito-all.jar (27ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar ...
[ivy:resolve] ...... (268kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.thrift#libfb303;0.9.0!libfb303.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro/1.7.1/avro-1.7.1.jar ...
[ivy:resolve] ...... (290kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro;1.7.1!avro.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar ...
[ivy:resolve] .... (164kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro-mapred;1.7.1!avro-mapred.jar (8ms)
[ivy:resolve] :: resolution report :: resolve 5937ms :: artifacts dl 71ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   14  |   5   |   5   |   0   ||   14  |   5   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-serde-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-serde-default.html

make-pom:
     [echo] Project: serde
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: serde
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources does not exist.

init:
     [echo] Project: serde

ivy-retrieve:
     [echo] Project: serde
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-serde
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	8 artifacts copied, 6 already retrieved (2227kB/24ms)

dynamic-serde:

compile:
     [echo] Project: serde
    [javac] Compiling 325 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java:33: cannot find symbol
    [javac] symbol  : class HiveVarchar
    [javac] location: package org.apache.hadoop.hive.common.type
    [javac] import org.apache.hadoop.hive.common.type.HiveVarchar;
    [javac]                                          ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java:40: cannot find symbol
    [javac] symbol  : class ParameterizedPrimitiveTypeUtils
    [javac] location: package org.apache.hadoop.hive.serde2.typeinfo
    [javac] import org.apache.hadoop.hive.serde2.typeinfo.ParameterizedPrimitiveTypeUtils;
    [javac]                                              ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java:44: cannot find symbol
    [javac] symbol  : class VarcharTypeParams
    [javac] location: package org.apache.hadoop.hive.serde2.typeinfo
    [javac] import org.apache.hadoop.hive.serde2.typeinfo.VarcharTypeParams;
    [javac]                                              ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java:153: cannot find symbol
    [javac] symbol  : variable VARCHAR
    [javac] location: class org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector.PrimitiveCategory
    [javac]           ((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory() == PrimitiveCategory.VARCHAR) {
    [javac]                                                                                     ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java:154: cannot find symbol
    [javac] symbol  : class VarcharTypeParams
    [javac] location: class org.apache.hadoop.hive.serde2.RegexSerDe
    [javac]         VarcharTypeParams varcharParams = (VarcharTypeParams)
    [javac]         ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java:154: cannot find symbol
    [javac] symbol  : class VarcharTypeParams
    [javac] location: class org.apache.hadoop.hive.serde2.RegexSerDe
    [javac]         VarcharTypeParams varcharParams = (VarcharTypeParams)
    [javac]                                            ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java:155: cannot find symbol
    [javac] symbol  : variable ParameterizedPrimitiveTypeUtils
    [javac] location: class org.apache.hadoop.hive.serde2.RegexSerDe
    [javac]             ParameterizedPrimitiveTypeUtils.getTypeParamsFromTypeInfo(typeInfo);
    [javac]             ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java:157: cannot find symbol
    [javac] symbol  : variable VARCHAR
    [javac] location: class org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector.PrimitiveCategory
    [javac]             PrimitiveCategory.VARCHAR, varcharParams));
    [javac]                              ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java:266: cannot find symbol
    [javac] symbol  : variable VARCHAR
    [javac] location: class org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector.PrimitiveCategory
    [javac]             ((PrimitiveTypeInfo) typeInfo).getPrimitiveCategory() == PrimitiveCategory.VARCHAR) {
    [javac]                                                                                       ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java:267: cannot find symbol
    [javac] symbol  : class VarcharTypeParams
    [javac] location: class org.apache.hadoop.hive.serde2.RegexSerDe
    [javac]           VarcharTypeParams varcharParams = (VarcharTypeParams)
    [javac]           ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java:267: cannot find symbol
    [javac] symbol  : class VarcharTypeParams
    [javac] location: class org.apache.hadoop.hive.serde2.RegexSerDe
    [javac]           VarcharTypeParams varcharParams = (VarcharTypeParams)
    [javac]                                              ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java:268: cannot find symbol
    [javac] symbol  : variable ParameterizedPrimitiveTypeUtils
    [javac] location: class org.apache.hadoop.hive.serde2.RegexSerDe
    [javac]               ParameterizedPrimitiveTypeUtils.getTypeParamsFromTypeInfo(typeInfo);
    [javac]               ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java:269: cannot find symbol
    [javac] symbol  : class HiveVarchar
    [javac] location: class org.apache.hadoop.hive.serde2.RegexSerDe
    [javac]           HiveVarchar hv = new HiveVarchar(t, varcharParams != null ? varcharParams.length : -1);
    [javac]           ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java:269: cannot find symbol
    [javac] symbol  : class HiveVarchar
    [javac] location: class org.apache.hadoop.hive.serde2.RegexSerDe
    [javac]           HiveVarchar hv = new HiveVarchar(t, varcharParams != null ? varcharParams.length : -1);
    [javac]                                ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] 14 errors

BUILD FAILED
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:327: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:166: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:168: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/serde/build.xml:48: Compile failed; see the compiler error output for details.

Total time: 2 minutes 57 seconds
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13755030" author="jdere" created="Fri, 30 Aug 2013 19:04:17 +0000"  >&lt;p&gt;Attaching &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5161&quot; title=&quot;Additional SerDe support for varchar type&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5161&quot;&gt;&lt;del&gt;HIVE-5161&lt;/del&gt;&lt;/a&gt;.2.patch. This updates a few of the SerDe&apos;s to use the HiveVarcharWritable&apos;s Text member directly, rather than converting to a String before serializing. &lt;/p&gt;</comment>
                            <comment id="13766171" author="jdere" created="Fri, 13 Sep 2013 02:02:58 +0000"  >&lt;p&gt;uploading patch v3:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;rebase against trunk, dependent patches&lt;/li&gt;
	&lt;li&gt;regenerate OrcProto using protobuf-2.5&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13766172" author="jdere" created="Fri, 13 Sep 2013 02:03:21 +0000"  >&lt;p&gt;posted review at &lt;a href=&quot;https://reviews.facebook.net/D12897&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12897&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13766291" author="phabricator@reviews.facebook.net" created="Fri, 13 Sep 2013 07:06:53 +0000"  >&lt;p&gt;jdere requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5161&quot; title=&quot;Additional SerDe support for varchar type&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5161&quot;&gt;&lt;del&gt;HIVE-5161&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Additional SerDe support for varchar type&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5161&quot; title=&quot;Additional SerDe support for varchar type&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5161&quot;&gt;&lt;del&gt;HIVE-5161&lt;/del&gt;&lt;/a&gt;: Additional SerDe support for varchar type&lt;/p&gt;

&lt;p&gt;Breaking out support for varchar for the various SerDes as an additional task.&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12897&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12897&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/orc/ColumnStatisticsImpl.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcStruct.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java&lt;br/&gt;
  ql/src/protobuf/org/apache/hadoop/hive/ql/io/orc/orc_proto.proto&lt;br/&gt;
  ql/src/test/queries/clientpositive/varchar_serde.q&lt;br/&gt;
  ql/src/test/results/clientpositive/varchar_serde.q.out&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/BinarySortableSerDe.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/30867/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/30867/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, jdere&lt;/p&gt;</comment>
                            <comment id="13767235" author="phabricator@reviews.facebook.net" created="Sat, 14 Sep 2013 00:26:52 +0000"  >&lt;p&gt;hsubramaniyan has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5161&quot; title=&quot;Additional SerDe support for varchar type&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5161&quot;&gt;&lt;del&gt;HIVE-5161&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Additional SerDe support for varchar type&quot;.&lt;/p&gt;

&lt;p&gt;  Hi Jason&lt;br/&gt;
  Can you make sure that there are changes in ObjectInspectorConverters.java and related files as well. Otherwise, I am not sure if this will work well when varchar is inside a complex data type such as struct or list.&lt;/p&gt;

&lt;p&gt;  Thanks&lt;br/&gt;
  Hari&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12897&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12897&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, omalley, jdere&lt;br/&gt;
Cc: hsubramaniyan&lt;/p&gt;</comment>
                            <comment id="13767243" author="phabricator@reviews.facebook.net" created="Sat, 14 Sep 2013 00:36:51 +0000"  >&lt;p&gt;jdere has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5161&quot; title=&quot;Additional SerDe support for varchar type&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5161&quot;&gt;&lt;del&gt;HIVE-5161&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Additional SerDe support for varchar type&quot;.&lt;/p&gt;

&lt;p&gt;  Hi Hari, most of the ObjectInspector-related changes for varchar are in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4844&quot; title=&quot;Add varchar data type&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4844&quot;&gt;&lt;del&gt;HIVE-4844&lt;/del&gt;&lt;/a&gt; - the review is at &lt;a href=&quot;https://reviews.facebook.net/D12891&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12891&lt;/a&gt;, if you think there is something I have missed.  That patch does have some struct/list tests in varchar_nested_types.q&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D12897&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12897&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, omalley, jdere&lt;br/&gt;
Cc: hsubramaniyan&lt;/p&gt;</comment>
                            <comment id="13767877" author="ashutoshc" created="Sun, 15 Sep 2013 18:35:52 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13768005" author="ashutoshc" created="Mon, 16 Sep 2013 02:12:33 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Jason!&lt;/p&gt;</comment>
                            <comment id="13768023" author="hudson" created="Mon, 16 Sep 2013 03:09:44 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #166 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/166/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/166/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5161&quot; title=&quot;Additional SerDe support for varchar type&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5161&quot;&gt;&lt;del&gt;HIVE-5161&lt;/del&gt;&lt;/a&gt; : Additional SerDe support for varchar type (Jason Dere via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1523532&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1523532&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ColumnStatisticsImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcStruct.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/protobuf/org/apache/hadoop/hive/ql/io/orc/orc_proto.proto&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/varchar_serde.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/varchar_serde.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/BinarySortableSerDe.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13768048" author="hudson" created="Mon, 16 Sep 2013 04:10:34 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #100 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/100/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/100/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5161&quot; title=&quot;Additional SerDe support for varchar type&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5161&quot;&gt;&lt;del&gt;HIVE-5161&lt;/del&gt;&lt;/a&gt; : Additional SerDe support for varchar type (Jason Dere via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1523532&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1523532&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ColumnStatisticsImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcStruct.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/protobuf/org/apache/hadoop/hive/ql/io/orc/orc_proto.proto&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/varchar_serde.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/varchar_serde.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/BinarySortableSerDe.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13768545" author="hudson" created="Mon, 16 Sep 2013 17:50:54 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2 #433 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/433/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/433/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5161&quot; title=&quot;Additional SerDe support for varchar type&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5161&quot;&gt;&lt;del&gt;HIVE-5161&lt;/del&gt;&lt;/a&gt; : Additional SerDe support for varchar type (Jason Dere via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1523532&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1523532&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ColumnStatisticsImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcStruct.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/protobuf/org/apache/hadoop/hive/ql/io/orc/orc_proto.proto&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/varchar_serde.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/varchar_serde.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/BinarySortableSerDe.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13768875" author="jdere" created="Mon, 16 Sep 2013 22:26:49 +0000"  >&lt;p&gt;attaching &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5161&quot; title=&quot;Additional SerDe support for varchar type&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5161&quot;&gt;&lt;del&gt;HIVE-5161&lt;/del&gt;&lt;/a&gt;.v12.1.patch, for use in 0.12 branch. Code generated using protobuf-2.4&lt;/p&gt;</comment>
                            <comment id="13769090" author="hudson" created="Tue, 17 Sep 2013 02:06:30 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-h0.21 #2336 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2336/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2336/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5161&quot; title=&quot;Additional SerDe support for varchar type&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5161&quot;&gt;&lt;del&gt;HIVE-5161&lt;/del&gt;&lt;/a&gt; : Additional SerDe support for varchar type (Jason Dere via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1523532&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1523532&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/ColumnStatisticsImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcStruct.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/protobuf/org/apache/hadoop/hive/ql/io/orc/orc_proto.proto&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/varchar_serde.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/varchar_serde.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/BinarySortableSerDe.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13769894" author="thejas" created="Tue, 17 Sep 2013 20:26:46 +0000"  >&lt;p&gt;Patch committed to 0.12 branch.&lt;/p&gt;</comment>
                            <comment id="13796060" author="ashutoshc" created="Tue, 15 Oct 2013 23:30:42 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12657385">HIVE-4844</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12602972" name="D12897.1.patch" size="78701" author="phabricator@reviews.facebook.net" created="Fri, 13 Sep 2013 07:06:53 +0000"/>
                            <attachment id="12600626" name="HIVE-5161.1.patch" size="75946" author="jdere" created="Thu, 29 Aug 2013 18:11:57 +0000"/>
                            <attachment id="12600836" name="HIVE-5161.2.patch" size="80417" author="jdere" created="Fri, 30 Aug 2013 19:04:17 +0000"/>
                            <attachment id="12602943" name="HIVE-5161.3.patch" size="80681" author="jdere" created="Fri, 13 Sep 2013 02:02:58 +0000"/>
                            <attachment id="12603473" name="HIVE-5161.v12.1.patch" size="80532" author="jdere" created="Mon, 16 Sep 2013 22:26:49 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 29 Aug 2013 23:42:27 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345742</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nmdj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>346043</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-5162] Add mod(a, b) semantic for modular function</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5162</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently Hive is supporting &apos;a % b&apos; as modular function, not mod(a, b). Unlike MySQL which supports both.&lt;/p&gt;

&lt;p&gt;It would be a good idea to support both.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665809">HIVE-5162</key>
            <summary>Add mod(a, b) semantic for modular function</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png" description="A patch for this issue has been uploaded to JIRA by a contributor.">Patch Available</status>
                    <statusCategory id="4" key="indeterminate" colorName="yellow"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="apivovarov">Alexander Pivovarov</assignee>
                                    <reporter username="xguo27">Xiu (Joe) Guo</reporter>
                        <labels>
                    </labels>
                <created>Tue, 27 Aug 2013 22:16:56 +0000</created>
                <updated>Fri, 10 Apr 2015 01:24:00 +0000</updated>
                                            <version>0.11.0</version>
                                                    <component>UDF</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13800220" author="analog.sony" created="Sun, 20 Oct 2013 20:48:29 +0000"  >&lt;p&gt;It seems we already have pmod function available.&lt;/p&gt;

&lt;p&gt;select  44.22 %22,44.22%22.22,pmod(44.22,22),pmod(44.22,22.22)  from dual  limit 2;&lt;/p&gt;

&lt;p&gt;OK&lt;br/&gt;
0.21999999999999886	22.0	0.21999999999999886	22.0&lt;br/&gt;
0.21999999999999886	22.0	0.21999999999999886	22.0&lt;br/&gt;
Time taken: 20.954 seconds&lt;/p&gt;

&lt;p&gt;This will solve your requirement. Please let me know if we can close this ticket.&lt;/p&gt;</comment>
                            <comment id="13800222" author="xguo27" created="Sun, 20 Oct 2013 20:56:00 +0000"  >&lt;p&gt;I see, thanks for your help, Anandha!&lt;/p&gt;</comment>
                            <comment id="14485867" author="apivovarov" created="Wed, 8 Apr 2015 19:34:10 +0000"  >&lt;p&gt;pmod is not the same as mod&lt;br/&gt;
e.g.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;select mod(-35, 6), pmod(-35, 6)
-5    1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</comment>
                            <comment id="14486129" author="apivovarov" created="Wed, 8 Apr 2015 21:46:32 +0000"  >&lt;p&gt;patch #1&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;added GenericUDFMod which extends GenericUDFOPMod&lt;/li&gt;
	&lt;li&gt;fixed function name and signature&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14488714" author="hiveqa" created="Fri, 10 Apr 2015 01:24:00 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12724034/HIVE-5162.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12724034/HIVE-5162.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 16 failed/errored test(s), 8665 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestMinimrCliDriver-bucketmapjoin6.q-constprog_partitioner.q-infer_bucket_sort_dyn_part.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-external_table_with_space_in_location_path.q-infer_bucket_sort_merge.q-auto_sortmerge_join_16.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-groupby2.q-import_exported_table.q-bucketizedhiveinputformat.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-index_bitmap3.q-stats_counter_partitioned.q-temp_table_external.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_map_operators.q-join1.q-bucketmapjoin7.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_num_buckets.q-disable_merge_for_bucketing.q-uber_reduce.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_reducers_power_two.q-scriptfile1.q-scriptfile1_win.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-leftsemijoin_mr.q-load_hdfs_file_with_space_in_the_name.q-root_dir_external_table.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-list_bucket_dml_10.q-bucket_num_reducers.q-bucket6.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-load_fs2.q-file_with_header_footer.q-ql_rewrite_gbtoidx_cbo_1.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-parallel_orderby.q-reduce_deduplicate.q-ql_rewrite_gbtoidx_cbo_2.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-ql_rewrite_gbtoidx.q-smb_mapjoin_8.q - did not produce a TEST-*.xml file
TestMinimrCliDriver-schemeAuthority2.q-bucket4.q-input16_cc.q-and-1-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.thrift.TestHadoop20SAuthBridge.testMetastoreProxyUser
org.apache.hadoop.hive.thrift.TestHadoop20SAuthBridge.testSaslWithHiveMetaStore
org.apache.hive.minikdc.TestHiveAuthFactory.org.apache.hive.minikdc.TestHiveAuthFactory
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3352/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3352/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3352/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3352/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3352/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3352/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 16 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12724034 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12595727">HIVE-3194</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12724034" name="HIVE-5162.1.patch" size="12483" author="apivovarov" created="Wed, 8 Apr 2015 21:46:32 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 20 Oct 2013 20:48:29 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345748</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 41 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nmev:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>346049</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-5163] refactor org.apache.hadoop.mapred.HCatMapRedUtil</title>
                <link>https://issues.apache.org/jira/browse/HIVE-5163</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Everything that this class does is delegated to a Shim class.&lt;br/&gt;
To make &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4895&quot; title=&quot;Move all HCatalog classes to org.apache.hive.hcatalog&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4895&quot;&gt;&lt;del&gt;HIVE-4895&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4896&quot; title=&quot;create binary backwards compatibility layer hcatalog 0.12 and 0.11&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4896&quot;&gt;&lt;del&gt;HIVE-4896&lt;/del&gt;&lt;/a&gt; smoother, we need to get rid of HCatMapRedUtil and make the calls directly to the Shim layer.  It will make it easier because all org.apache.hcatalog classes will move to org.apache.hive.hcatalog classes thus making way to provide binary backwards compat.  This class won&apos;t change it&apos;s name so it&apos;s more difficult to provide backwards compat.  The org.apache.hadoop.mapred.TempletonJobTracker is not an issue since it goes away in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4460&quot; title=&quot;Publish HCatalog artifacts for Hadoop 2.x&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4460&quot;&gt;&lt;del&gt;HIVE-4460&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665818">HIVE-5163</key>
            <summary>refactor org.apache.hadoop.mapred.HCatMapRedUtil</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12658080">HIVE-4869</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ekoifman">Eugene Koifman</assignee>
                                    <reporter username="ekoifman">Eugene Koifman</reporter>
                        <labels>
                    </labels>
                <created>Tue, 27 Aug 2013 23:32:34 +0000</created>
                <updated>Tue, 15 Oct 2013 23:30:45 +0000</updated>
                            <resolved>Mon, 2 Sep 2013 23:25:48 +0000</resolved>
                                    <version>0.12.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                    <component>HCatalog</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13752684" author="ekoifman" created="Wed, 28 Aug 2013 18:29:46 +0000"  >&lt;p&gt;Moved HCatMapRedUtil to org.apache.hcatalog.mapreduce to make above mentioned bugs easier.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt;.patch - cummulative (for automated build)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt;.move - just the rename for SVN rename to preserve history&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt;.update - changed to apply after SVN move is done&lt;/p&gt;</comment>
                            <comment id="13752685" author="ekoifman" created="Wed, 28 Aug 2013 18:30:43 +0000"  >&lt;p&gt;This must be checked in after &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4460&quot; title=&quot;Publish HCatalog artifacts for Hadoop 2.x&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4460&quot;&gt;&lt;del&gt;HIVE-4460&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13752820" author="thejas" created="Wed, 28 Aug 2013 20:38:25 +0000"  >&lt;p&gt;Looks good +1.&lt;br/&gt;
This is hcat only change, so I will make sure it doesn&apos;t break hive build and run the hcat unit tests before committing.&lt;/p&gt;
</comment>
                            <comment id="13756264" author="thejas" created="Mon, 2 Sep 2013 23:25:48 +0000"  >&lt;p&gt;Committed to trunk. Thanks Eugene!&lt;/p&gt;</comment>
                            <comment id="13756269" author="hudson" created="Mon, 2 Sep 2013 23:44:37 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2 #397 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/397/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/397/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt; : refactor org.apache.hadoop.mapred.HCatMapRedUtil (Eugene Koifman via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519530&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519530&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hadoop/mapred/HCatMapRedUtil.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileRecordWriterContainer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/HCatMapRedUtil.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/storage-handlers/hbase/src/java/org/apache/hcatalog/hbase/HBaseInputFormat.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/storage-handlers/hbase/src/java/org/apache/hcatalog/hbase/ImportSequenceFile.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13756278" author="hudson" created="Tue, 3 Sep 2013 00:04:12 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-h0.21 #2305 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2305/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2305/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt; : refactor org.apache.hadoop.mapred.HCatMapRedUtil (Eugene Koifman via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519530&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519530&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hadoop/mapred/HCatMapRedUtil.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileRecordWriterContainer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/HCatMapRedUtil.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/storage-handlers/hbase/src/java/org/apache/hcatalog/hbase/HBaseInputFormat.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/storage-handlers/hbase/src/java/org/apache/hcatalog/hbase/ImportSequenceFile.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13756283" author="hudson" created="Tue, 3 Sep 2013 00:23:52 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #81 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/81/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/81/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt; : refactor org.apache.hadoop.mapred.HCatMapRedUtil (Eugene Koifman via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519530&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519530&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hadoop/mapred/HCatMapRedUtil.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileRecordWriterContainer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/HCatMapRedUtil.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/storage-handlers/hbase/src/java/org/apache/hcatalog/hbase/HBaseInputFormat.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/storage-handlers/hbase/src/java/org/apache/hcatalog/hbase/ImportSequenceFile.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13756288" author="hudson" created="Tue, 3 Sep 2013 00:40:14 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #148 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/148/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/148/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt; : refactor org.apache.hadoop.mapred.HCatMapRedUtil (Eugene Koifman via Thejas Nair) (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519530&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519530&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hadoop/mapred/HCatMapRedUtil.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileRecordWriterContainer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/HCatMapRedUtil.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/storage-handlers/hbase/src/java/org/apache/hcatalog/hbase/HBaseInputFormat.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/storage-handlers/hbase/src/java/org/apache/hcatalog/hbase/ImportSequenceFile.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13756305" author="thejas" created="Tue, 3 Sep 2013 01:51:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt;.update was missing a change in the moved file. Attaching &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt;.update.2 which is an additional change that had to be committed.&lt;/p&gt;</comment>
                            <comment id="13756310" author="hudson" created="Tue, 3 Sep 2013 02:00:43 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-h0.21 #2306 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2306/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2306/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt; : refactor org.apache.hadoop.mapred.HCatMapRedUtil - &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt;.update.2 (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519538&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519538&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/HCatMapRedUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13756398" author="hudson" created="Tue, 3 Sep 2013 06:57:45 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2 #398 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/398/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/398/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt; : refactor org.apache.hadoop.mapred.HCatMapRedUtil - &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt;.update.2 (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519538&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519538&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/HCatMapRedUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13756399" author="hudson" created="Tue, 3 Sep 2013 06:57:45 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #82 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/82/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/82/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt; : refactor org.apache.hadoop.mapred.HCatMapRedUtil - &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt;.update.2 (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519538&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519538&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/HCatMapRedUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13756464" author="hudson" created="Tue, 3 Sep 2013 08:56:34 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hive-trunk-hadoop1-ptest #149 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/149/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/149/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt; : refactor org.apache.hadoop.mapred.HCatMapRedUtil - &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5163&quot; title=&quot;refactor org.apache.hadoop.mapred.HCatMapRedUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5163&quot;&gt;&lt;del&gt;HIVE-5163&lt;/del&gt;&lt;/a&gt;.update.2 (thejas: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519538&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1519538&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/HCatMapRedUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13796069" author="ashutoshc" created="Tue, 15 Oct 2013 23:30:45 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12600429" name="HIVE-5163.move" size="5967" author="ekoifman" created="Wed, 28 Aug 2013 18:29:46 +0000"/>
                            <attachment id="12600430" name="HIVE-5163.patch" size="10568" author="ekoifman" created="Wed, 28 Aug 2013 18:29:46 +0000"/>
                            <attachment id="12600431" name="HIVE-5163.update" size="4601" author="ekoifman" created="Wed, 28 Aug 2013 18:29:46 +0000"/>
                            <attachment id="12601098" name="HIVE-5163.update.2" size="884" author="thejas" created="Tue, 3 Sep 2013 01:51:22 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 28 Aug 2013 20:38:25 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345757</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nmgv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>346058</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>
</channel>
</rss>
