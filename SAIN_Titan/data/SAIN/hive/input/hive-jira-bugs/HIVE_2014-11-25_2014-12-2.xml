<!--
RSS generated by JIRA (7.6.3#76005-sha1:8a4e38d34af948780dbf52044e7aafb13a7cae58) at Tue Jan 22 03:31:37 UTC 2019

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<!-- If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
    <channel>
        <title>ASF JIRA</title>
        <link>https://issues.apache.org/jira/issues/?jql=project+%3D+HIVE+AND+created+%3E%3D+2014-11-25+AND+created+%3C%3D+2014-12-2+ORDER+BY+key+ASC</link>
        <description>An XML representation of a search request</description>
                <language>en-uk</language>
                        <issue start="0" end="45" total="45"/>
                <build-info>
            <version>7.6.3</version>
            <build-number>76005</build-number>
            <build-date>09-01-2018</build-date>
        </build-info>

<item>
            <title>[HIVE-8956] Hive hangs while some error/exception happens beyond job execution [Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8956</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Remote spark client communicate with remote spark context asynchronously, if error/exception is throw out during job execution in remote spark context, it would be wrapped and send back to remote spark client, but if error/exception is throw out beyond job execution, such as job serialized failed, remote spark client would never know what&apos;s going on in remote spark context, and it would hangs there.&lt;br/&gt;
Set a timeout in remote spark client side may not a great idea, as we are not sure how long the query executed in spark cluster. we need find a way to check whether job has failed(whole life cycle) in remote spark context.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12757601">HIVE-8956</key>
            <summary>Hive hangs while some error/exception happens beyond job execution [Spark Branch]</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12749643">HIVE-8548</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lirui">Rui Li</assignee>
                                    <reporter username="chengxiang li">Chengxiang Li</reporter>
                        <labels>
                            <label>Spark-M3</label>
                    </labels>
                <created>Tue, 25 Nov 2014 03:03:08 +0000</created>
                <updated>Fri, 29 May 2015 02:31:39 +0000</updated>
                            <resolved>Wed, 26 Nov 2014 05:08:53 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="14224263" author="lirui" created="Tue, 25 Nov 2014 09:03:03 +0000"  >&lt;p&gt;Add timeout for waiting a spark job to be submitted.&lt;/p&gt;</comment>
                            <comment id="14224413" author="hiveqa" created="Tue, 25 Nov 2014 11:25:13 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12683506/HIVE-8956.1-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12683506/HIVE-8956.1-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 3 failed/errored test(s), 7181 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_transform_acid
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/425/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/425/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/425/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/425/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-425/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-425/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12683506 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14224513" author="xuefuz" created="Tue, 25 Nov 2014 13:13:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;Marcelo Vanzin&lt;/a&gt;, could you comment on the changes? Thanks.&lt;/p&gt;</comment>
                            <comment id="14225082" author="vanzin" created="Tue, 25 Nov 2014 19:28:01 +0000"  >&lt;p&gt;This is ok if it unblocks something right now. For the code, I&apos;d suggest using &lt;tt&gt;System.nanoTime()&lt;/tt&gt; to calculate durations, since it&apos;s monotonic. And use &lt;tt&gt;long&lt;/tt&gt; instead of &lt;tt&gt;int&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;But I think a better approach is needed here. Currently the &lt;tt&gt;JobSubmitted&lt;/tt&gt; message seems to only be sent when you use Spark&apos;s async APIs to submit a Spark job. A remote client job that does not use those APIs would never generate that message. Also, the backend uses a thread pool to execute jobs - so if you&apos;re queueing up multiple jobs, you may hit this timeout.&lt;/p&gt;

&lt;p&gt;I think we need more fine-grained remote client-level events for tracking job progress. e.g., adding &lt;tt&gt;JobReceived&lt;/tt&gt; and &lt;tt&gt;JobStarted&lt;/tt&gt; messages would be a good start (&lt;tt&gt;JobResult&lt;/tt&gt; already covers the &quot;job finished&quot; case). I think these two extra messages should be enough to cover the problems described in this bug.&lt;/p&gt;</comment>
                            <comment id="14225614" author="lirui" created="Wed, 26 Nov 2014 02:33:22 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;Marcelo Vanzin&lt;/a&gt; for your input!&lt;br/&gt;
Adding &lt;tt&gt;JobReceived&lt;/tt&gt; and &lt;tt&gt;JobStarted&lt;/tt&gt; is great. But even with that, we still need timeout for &lt;tt&gt;JobSubmitted&lt;/tt&gt;, because spark job monitor depends on it to get the job ID. Otherwise, it&apos;s still possible the monitor will hang forever.&lt;br/&gt;
Besides, do you think we have to set timeouts between all these events?&lt;/p&gt;</comment>
                            <comment id="14225734" author="brocknoland" created="Wed, 26 Nov 2014 04:44:37 +0000"  >&lt;p&gt;Based on what we are seeing in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8836&quot; title=&quot;Enable automatic tests with remote spark client [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8836&quot;&gt;&lt;del&gt;HIVE-8836&lt;/del&gt;&lt;/a&gt; I wonder if we won&apos;t need a retry?&lt;/p&gt;</comment>
                            <comment id="14225750" author="brocknoland" created="Wed, 26 Nov 2014 05:07:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;Rui Li&lt;/a&gt; can you create a follow-on ticket for &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;Marcelo Vanzin&lt;/a&gt;&apos;s improvements? I will commit this we can move forward on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8836&quot; title=&quot;Enable automatic tests with remote spark client [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8836&quot;&gt;&lt;del&gt;HIVE-8836&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14225763" author="lirui" created="Wed, 26 Nov 2014 05:18:01 +0000"  >&lt;p&gt;Yeah I created &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8972&quot; title=&quot;Implement more fine-grained remote client-level events [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8972&quot;&gt;&lt;del&gt;HIVE-8972&lt;/del&gt;&lt;/a&gt; as a follow up.&lt;br/&gt;
As for retry failed job, I think it&apos;d be better if we can get what caused the failure. E.g. in case of non-deserailizable failures, it doesn&apos;t make sense to retry it.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;Marcelo Vanzin&lt;/a&gt; do you know if there&apos;s any way we can catch such failures (beyond job execution) and send it back to client?&lt;/p&gt;</comment>
                            <comment id="14226504" author="vanzin" created="Wed, 26 Nov 2014 17:32:34 +0000"  >&lt;p&gt;I haven&apos;t looked at akka in that much detail to see if there is some API to catch those. You can enable akka logging (set &lt;tt&gt;spark.akka.logLifecycleEvents&lt;/tt&gt; to true) and that will print these errors to the logs. Spark tries to serialize data before sending it to akka, to try to catch serialization issues, but that adds overhead, and it also doesn&apos;t help in the deserialization path...&lt;/p&gt;</comment>
                            <comment id="14227107" author="lirui" created="Thu, 27 Nov 2014 01:32:26 +0000"  >&lt;p&gt;OK I see. Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;Marcelo Vanzin&lt;/a&gt; for the explanation.&lt;/p&gt;</comment>
                            <comment id="14260006" author="chiragaggarwal" created="Mon, 29 Dec 2014 10:28:48 +0000"  >&lt;p&gt;Does this take care of instances like:&lt;br/&gt;
ERROR util.Utils: Uncaught exception in thread Result resolver thread-1 &lt;br/&gt;
java.lang.OutOfMemoryError: Java heap space &lt;br/&gt;
        at java.nio.HeapByteBuffer.&amp;lt;init&amp;gt;(Unknown Source) &lt;br/&gt;
        at java.nio.ByteBuffer.allocate(Unknown Source) &lt;br/&gt;
        at org.apache.spark.storage.BlockMessage.set(BlockMessage.scala:94) &lt;br/&gt;
        at org.apache.spark.storage.BlockMessage$.fromByteBuffer(BlockMessage.scala:176) &lt;br/&gt;
        at org.apache.spark.storage.BlockMessageArray.set(BlockMessageArray.scala:63) &lt;br/&gt;
        at org.apache.spark.storage.BlockMessageArray$.fromBufferMessage(BlockMessageArray.scala:109) &lt;br/&gt;
        at org.apache.spark.storage.BlockManagerWorker$.syncGetBlock(BlockManagerWorker.scala:138) &lt;br/&gt;
        at org.apache.spark.storage.BlockManager$$anonfun$doGetRemote$2.apply(BlockManager.scala:530) &lt;br/&gt;
        at org.apache.spark.storage.BlockManager$$anonfun$doGetRemote$2.apply(BlockManager.scala:528) &lt;br/&gt;
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59) &lt;br/&gt;
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47) &lt;br/&gt;
        at org.apache.spark.storage.BlockManager.doGetRemote(BlockManager.scala:528) &lt;br/&gt;
        at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:522) &lt;br/&gt;
        at org.apache.spark.scheduler.TaskResultGetter$$anon$2$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:53) &lt;br/&gt;
        at org.apache.spark.scheduler.TaskResultGetter$$anon$2$$anonfun$run$1.apply(TaskResultGetter.scala:47) &lt;br/&gt;
        at org.apache.spark.scheduler.TaskResultGetter$$anon$2$$anonfun$run$1.apply(TaskResultGetter.scala:47) &lt;br/&gt;
        at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1311) &lt;br/&gt;
        at org.apache.spark.scheduler.TaskResultGetter$$anon$2.run(TaskResultGetter.scala:46) &lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) &lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) &lt;br/&gt;
        at java.lang.Thread.run(Unknown Source) &lt;/p&gt;</comment>
                            <comment id="14260017" author="chiragaggarwal" created="Mon, 29 Dec 2014 10:29:34 +0000"  >&lt;p&gt;I guess no. Is there any ticket which tracks this issue?&lt;/p&gt;</comment>
                            <comment id="14260139" author="brocknoland" created="Mon, 29 Dec 2014 14:57:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chirag.aggarwal&quot; class=&quot;user-hover&quot; rel=&quot;chirag.aggarwal&quot;&gt;Chirag Aggarwal&lt;/a&gt;, it looks to me like some memory setting is too low but it&apos;s be better to create a sub-task of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7292&quot; title=&quot;Hive on Spark&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7292&quot;&gt;&lt;del&gt;HIVE-7292&lt;/del&gt;&lt;/a&gt; and discuss this error there. Would you mind doing this?&lt;/p&gt;</comment>
                            <comment id="14260652" author="lirui" created="Tue, 30 Dec 2014 01:30:42 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chirag.aggarwal&quot; class=&quot;user-hover&quot; rel=&quot;chirag.aggarwal&quot;&gt;Chirag Aggarwal&lt;/a&gt;, which query triggered this error? And you may need to check if the configured memory is not enough. Some related properties are &lt;tt&gt;spark.executor.memory&lt;/tt&gt; and &lt;tt&gt;spark.storage.memoryFraction&lt;/tt&gt;.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12757902">HIVE-8972</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12683506" name="HIVE-8956.1-spark.patch" size="2255" author="lirui" created="Tue, 25 Nov 2014 09:03:03 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 25 Nov 2014 09:03:03 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22qxr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8957] Remote spark context needs to clean up itself in case of connection timeout [Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8957</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;In the current SparkClient implementation (class SparkClientImpl), the constructor does some initialization and in the end waits for the remote driver to connect. In case of timeout, it just throws an exception without cleaning itself. The cleanup is necessary to release system resources.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12757602">HIVE-8957</key>
            <summary>Remote spark context needs to clean up itself in case of connection timeout [Spark Branch]</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12749643">HIVE-8548</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="xuefuz">Xuefu Zhang</assignee>
                                    <reporter username="xuefuz">Xuefu Zhang</reporter>
                        <labels>
                    </labels>
                <created>Tue, 25 Nov 2014 03:14:53 +0000</created>
                <updated>Mon, 1 Dec 2014 21:34:30 +0000</updated>
                                                                            <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="14224728" author="hiveqa" created="Tue, 25 Nov 2014 16:00:05 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12683546/HIVE-8957.1-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12683546/HIVE-8957.1-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 5 failed/errored test(s), 7178 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_covar_samp
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin7
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_mapjoin
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/429/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/429/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/429/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/429/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-429/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-429/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12683546 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14225525" author="xuefuz" created="Wed, 26 Nov 2014 01:07:02 +0000"  >&lt;p&gt;&lt;del&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mvalleavila&quot; class=&quot;user-hover&quot; rel=&quot;mvalleavila&quot;&gt;Marcelo Valle Avila&lt;/a&gt;&lt;/del&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;Marcelo Vanzin&lt;/a&gt;, could you advise what is right thing to do here? Calling stop() actually makes Hive process hang. Thanks.&lt;/p&gt;</comment>
                            <comment id="14225580" author="szehon" created="Wed, 26 Nov 2014 01:46:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;Marcelo Vanzin&lt;/a&gt; tagged the wrong person?&lt;/p&gt;</comment>
                            <comment id="14226515" author="vanzin" created="Wed, 26 Nov 2014 17:39:55 +0000"  >&lt;p&gt;I think a fix here will be a little more complicated than that. Let me look at the code and think about it.&lt;/p&gt;</comment>
                            <comment id="14230473" author="xuefuz" created="Mon, 1 Dec 2014 21:15:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;Marcelo Vanzin&lt;/a&gt;, would you mind owning the JIRA for now until you figure out a solution? &lt;/p&gt;</comment>
                            <comment id="14230478" author="vanzin" created="Mon, 1 Dec 2014 21:17:10 +0000"  >&lt;p&gt;If you don&apos;t mind the bug remaining unattended for several days, sure. I have my hands full with all sorts of other things at the moment.&lt;/p&gt;</comment>
                            <comment id="14230502" author="xuefuz" created="Mon, 1 Dec 2014 21:34:30 +0000"  >&lt;p&gt;That&apos;s all right. I think I can bug you on this when you have cycles.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12757304">HIVE-8951</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12683546" name="HIVE-8957.1-spark.patch" size="557" author="xuefuz" created="Tue, 25 Nov 2014 13:33:30 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 25 Nov 2014 16:00:05 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22qxz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-8958] Make sure map join tasks created by runtime skew join can fit into memory [Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8958</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Runtime skew join creates map join tasks to join skewed data. We have to make sure (if not yet) that these tasks can fit into memory, and find backup solution if they don&apos;t.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12757625">HIVE-8958</key>
            <summary>Make sure map join tasks created by runtime skew join can fit into memory [Spark Branch]</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="lirui">Rui Li</reporter>
                        <labels>
                    </labels>
                <created>Tue, 25 Nov 2014 06:58:49 +0000</created>
                <updated>Tue, 25 Nov 2014 06:59:32 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                    <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12746817">HIVE-8406</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22r33:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-8959] SparkSession is not closed until JVM exit.[Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8959</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;During unit test, SparkSession is closed by Runtime shutdownHook, which means it&apos;s closed until JVM exist. During unit test suite, each qfile, as a single test case, would reset SessionState, which lead to a new Sparksession is created for each qfile. As we know that, RemoteSparkClient is SparkSession specified, so more and more executors is launched during unit test until blocked by no more resources.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12757643">HIVE-8959</key>
            <summary>SparkSession is not closed until JVM exit.[Spark Branch]</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12749643">HIVE-8548</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="chengxiang li">Chengxiang Li</assignee>
                                    <reporter username="chengxiang li">Chengxiang Li</reporter>
                        <labels>
                            <label>Spark-M3</label>
                    </labels>
                <created>Tue, 25 Nov 2014 08:35:13 +0000</created>
                <updated>Fri, 29 May 2015 02:29:22 +0000</updated>
                            <resolved>Tue, 25 Nov 2014 12:59:37 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="14224474" author="hiveqa" created="Tue, 25 Nov 2014 12:36:27 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12683509/HIVE-8959.1-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12683509/HIVE-8959.1-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 7181 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/426/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/426/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/426/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/426/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-426/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-426/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12683509 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14224497" author="xuefuz" created="Tue, 25 Nov 2014 12:58:11 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14224498" author="xuefuz" created="Tue, 25 Nov 2014 12:59:37 +0000"  >&lt;p&gt;Committed to Spark branch. Thanks, Chengxiang.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12754699">HIVE-8836</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12683509" name="HIVE-8959.1-spark.patch" size="3889" author="chengxiang li" created="Tue, 25 Nov 2014 09:36:14 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 25 Nov 2014 12:36:27 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22r6v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8960] ParsingException in the WHERE statement with a Sub Query</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8960</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Comparison with a Sub query in a WHERE statement does not work.&lt;br/&gt;
Given that id_chargement is an integer:&lt;/p&gt;

&lt;p&gt;USE db1;&lt;br/&gt;
SELECT * FROM tbl1 a WHERE a.id_chargement &amp;gt; (SELECT MAX(b.id_chargement) FROM tbl2 b);&lt;br/&gt;
or&lt;br/&gt;
SELECT * FROM tbl1 a WHERE a.id_chargement &amp;gt; (SELECT b.id_chargement FROM tbl2 b LIMIT 1);&lt;/p&gt;

&lt;p&gt;Both return the following parsing error:&lt;/p&gt;

&lt;p&gt;Error: Error while compiling statement: FAILED: ParseException line 1:88 cannot recognize input near &apos;SELECT&apos; &apos;b&apos; &apos;.&apos; in expression specification (state=42000,code=40000)&lt;br/&gt;
java.sql.SQLException: Error while compiling statement: FAILED: ParseException line 1:88 cannot recognize input near &apos;SELECT&apos; &apos;b&apos; &apos;.&apos; in expression specification&lt;br/&gt;
        at org.apache.hive.jdbc.Utils.verifySuccess(Utils.java:121)&lt;br/&gt;
        at org.apache.hive.jdbc.Utils.verifySuccessWithInfo(Utils.java:109)&lt;br/&gt;
        at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:231)&lt;br/&gt;
        at org.apache.hive.beeline.Commands.execute(Commands.java:736)&lt;br/&gt;
        at org.apache.hive.beeline.Commands.sql(Commands.java:657)&lt;br/&gt;
        at org.apache.hive.beeline.BeeLine.dispatch(BeeLine.java:804)&lt;br/&gt;
        at org.apache.hive.beeline.BeeLine.begin(BeeLine.java:659)&lt;br/&gt;
        at org.apache.hive.beeline.BeeLine.mainWithInputRedirection(BeeLine.java:368)&lt;br/&gt;
        at org.apache.hive.beeline.BeeLine.main(BeeLine.java:351)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:601)&lt;br/&gt;
        at org.apache.hadoop.util.RunJar.main(RunJar.java:212)&lt;/p&gt;</description>
                <environment>&lt;p&gt;Secured HDP 2.1.3 with Hive 0.13.0&lt;/p&gt;</environment>
        <key id="12757652">HIVE-8960</key>
            <summary>ParsingException in the WHERE statement with a Sub Query</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="r&#233;my">R&#233;my Saissy</reporter>
                        <labels>
                    </labels>
                <created>Tue, 25 Nov 2014 09:53:18 +0000</created>
                <updated>Sun, 21 Aug 2016 06:25:09 +0000</updated>
                                            <version>0.13.0</version>
                                                    <component>Parser</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="14252759" author="navis" created="Fri, 19 Dec 2014 01:46:43 +0000"  >&lt;p&gt;Simply, it&apos;s not supported.&lt;/p&gt;</comment>
                            <comment id="14253266" author="lefty@hortonworks.com" created="Fri, 19 Dec 2014 10:55:36 +0000"  >&lt;p&gt;Hive 0.13 supports a few types of subqueries in the WHERE clause, but only for IN, NOT IN, EXISTS, &amp;amp; NOT EXISTS.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+SubQueries#LanguageManualSubQueries-SubqueriesintheWHEREClause&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Subqueries in the WHERE Clause &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15429315" author="vpareek" created="Sat, 20 Aug 2016 10:12:00 +0000"  >&lt;p&gt;I am trying following query, it is working in Impala but not in Hive. &lt;/p&gt;

&lt;p&gt;SELECT t1.col1 FROM table1 t1 LEFT OUTER JOIN table2 t2 ON (t1.col2 = t2.col2 AND t1.col3 = t2.col3) &lt;br/&gt;
WHERE t2.col4 = (SELECT MAX(t22.col4) FROM table2 t22 WHERE t22.col4 &amp;lt;= t1.col4);&lt;/p&gt;

&lt;p&gt;Is there any alternative for this in Hive?&lt;/p&gt;</comment>
                            <comment id="15429608" author="lefty@hortonworks.com" created="Sun, 21 Aug 2016 06:25:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Vikash+Pareek&quot; class=&quot;user-hover&quot; rel=&quot;Vikash Pareek&quot;&gt;Vikash Pareek&lt;/a&gt;, perhaps you would get more replies if you posted this question on the user@hive.apache.org mailing list.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;http://hive.apache.org/mailing_lists.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Hive mailing lists &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 19 Dec 2014 01:46:43 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 22 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22r8v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-8961] Remove unnecessary dependency collection task [Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8961</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Seems some dependency collection task we add for move task is unnecessary.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12757664">HIVE-8961</key>
            <summary>Remove unnecessary dependency collection task [Spark Branch]</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12723734">HIVE-7292</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lirui">Rui Li</assignee>
                                    <reporter username="lirui">Rui Li</reporter>
                        <labels>
                    </labels>
                <created>Tue, 25 Nov 2014 11:15:49 +0000</created>
                <updated>Fri, 29 May 2015 02:30:25 +0000</updated>
                            <resolved>Wed, 26 Nov 2014 06:14:04 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="14224480" author="lirui" created="Tue, 25 Nov 2014 12:38:31 +0000"  >&lt;p&gt;Changes to golden files are all in query plan. No results changed.&lt;/p&gt;</comment>
                            <comment id="14224532" author="xuefuz" created="Tue, 25 Nov 2014 13:29:33 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14224733" author="hiveqa" created="Tue, 25 Nov 2014 16:01:02 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12683535/HIVE-8961.1-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12683535/HIVE-8961.1-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/430/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/430/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/430/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/430/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-430/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-430/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/lib64/qt-3.3/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/lib64/qt-3.3/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-SPARK-Build-430/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-spark-source ]]
+ [[ ! -d apache-svn-spark-source/.svn ]]
+ [[ ! -d apache-svn-spark-source ]]
+ cd apache-svn-spark-source
+ svn revert -R .
Reverted &apos;spark-client/src/main/java/org/apache/hive/spark/client/SparkClientImpl.java&apos;
++ svn status --no-ignore
++ egrep -v &apos;^X|^Performing status on external&apos;
++ awk &apos;{print $2}&apos;
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20/target shims/0.20S/target shims/0.23/target shims/aggregator/target shims/common/target shims/common-secure/target shims/scheduler/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit-hadoop2/target itests/hive-minikdc/target itests/hive-unit/target itests/custom-serde/target itests/util/target itests/qtest-spark/target hcatalog/target hcatalog/core/target hcatalog/streaming/target hcatalog/server-extensions/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target hcatalog/hcatalog-pig-adapter/target accumulo-handler/target hwi/target common/target common/src/gen spark-client/target spark-client/src/main/java/org/apache/hive/spark/client/SparkClientImpl.java.orig service/target contrib/target serde/target beeline/target cli/target odbc/target ql/dependency-reduced-pom.xml ql/target
+ svn update
A    ql/src/test/results/clientpositive/spark/limit_partition_metadataonly.q.out
U    ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SparkCompiler.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkTask.java

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
Updated external to revision 1641642.

Updated to revision 1641642.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12683535 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14225174" author="xuefuz" created="Tue, 25 Nov 2014 20:41:47 +0000"  >&lt;p&gt;Patch #2 rebased with trunk. Not sure If I messed up anything. In addition, I saw result for parallel_join0.q have diff, but the diff isn&apos;t included in patch #2 either. Also, my patch, generated by running &quot;mvn test -Dtestcase=TestSparkCliDriver -Dtest.output.overwrite=true -Phadoop-2&quot;, is much larger.&lt;/p&gt;</comment>
                            <comment id="14225277" author="hiveqa" created="Tue, 25 Nov 2014 21:57:22 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12683648/HIVE-8961.2-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12683648/HIVE-8961.2-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 6 failed/errored test(s), 7178 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join22
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin7
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parallel_join0
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/432/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/432/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/432/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/432/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-432/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-432/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12683648 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14225358" author="xuefuz" created="Tue, 25 Nov 2014 23:10:49 +0000"  >&lt;p&gt;Fix the failures. I noticed that the result is different in my local run for parallel_join0.q and auto_join22.q. However, patch #3 didn&apos;t include the diff.&lt;/p&gt;</comment>
                            <comment id="14225534" author="hiveqa" created="Wed, 26 Nov 2014 01:12:24 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12683687/HIVE-8961.3-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12683687/HIVE-8961.3-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/436/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/436/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/436/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/436/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-436/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-436/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: SSHExecutionException: SSHResult [command=pkill -f java, getExitCode()=1, getException()=null, getUser()=hiveptest, getHost()=54.176.195.138, getInstance()=0]: &apos;OpenSSH_5.3p1, OpenSSL 1.0.0-fips 29 Mar 2010
debug1: Reading configuration data /home/hiveptest/.ssh/config
debug1: Reading configuration data /etc/ssh/ssh_config
debug1: Applying options for *
debug1: Connecting to 54.176.195.138 [54.176.195.138] port 22.
debug1: fd 3 clearing O_NONBLOCK
debug1: Connection established.
debug1: identity file /home/hiveptest/.ssh/hive-ptest-user-key type -1
debug1: Remote protocol version 2.0, remote software version OpenSSH_5.3
debug1: match: OpenSSH_5.3 pat OpenSSH*
debug1: Enabling compatibility mode for protocol 2.0
debug1: Local version string SSH-2.0-OpenSSH_5.3
debug1: SSH2_MSG_KEXINIT sent
debug1: SSH2_MSG_KEXINIT received
debug1: kex: server-&amp;gt;client aes128-ctr hmac-md5 none
debug1: kex: client-&amp;gt;server aes128-ctr hmac-md5 none
debug1: SSH2_MSG_KEX_DH_GEX_REQUEST(1024&amp;lt;1024&amp;lt;8192) sent
debug1: expecting SSH2_MSG_KEX_DH_GEX_GROUP
debug1: SSH2_MSG_KEX_DH_GEX_INIT sent
debug1: expecting SSH2_MSG_KEX_DH_GEX_REPLY
debug1: Host &apos;54.176.195.138&apos; is known and matches the RSA host key.
debug1: Found key in /home/hiveptest/.ssh/known_hosts:1194
debug1: ssh_rsa_verify: signature correct
debug1: SSH2_MSG_NEWKEYS sent
debug1: expecting SSH2_MSG_NEWKEYS
debug1: SSH2_MSG_NEWKEYS received
debug1: SSH2_MSG_SERVICE_REQUEST sent
debug1: SSH2_MSG_SERVICE_ACCEPT received
debug1: Authentications that can continue: publickey,gssapi-keyex,gssapi-with-mic,password
debug1: Next authentication method: gssapi-keyex
debug1: No valid Key exchange context
debug1: Next authentication method: gssapi-with-mic
Address 54.176.195.138 maps to ec2-54-176-195-138.us-west-1.compute.amazonaws.com, but this does not map back to the address - POSSIBLE BREAK-IN ATTEMPT!
debug1: Unspecified GSS failure.  Minor code may provide more information
Credentials cache file &apos;/tmp/krb5cc_501&apos; not found

debug1: Unspecified GSS failure.  Minor code may provide more information
Credentials cache file &apos;/tmp/krb5cc_501&apos; not found

debug1: Unspecified GSS failure.  Minor code may provide more information


debug1: Unspecified GSS failure.  Minor code may provide more information
Credentials cache file &apos;/tmp/krb5cc_501&apos; not found

debug1: Next authentication method: publickey
debug1: Trying private key: /home/hiveptest/.ssh/hive-ptest-user-key
debug1: read PEM private key done: type RSA
debug1: Authentication succeeded (publickey).
debug1: channel 0: new [client-session]
debug1: Requesting no-more-sessions@openssh.com
debug1: Entering interactive session.
debug1: Sending environment.
debug1: Sending env LANG = en_US.UTF-8
debug1: Sending command: pkill -f java
debug1: client_input_channel_req: channel 0 rtype exit-status reply 0
debug1: client_input_channel_req: channel 0 rtype eow@openssh.com reply 0
debug1: channel 0: free: client-session, nchannels 1
debug1: fd 0 clearing O_NONBLOCK
debug1: fd 1 clearing O_NONBLOCK
Transferred: sent 1952, received 1976 bytes, in 0.0 seconds
Bytes per second: sent 59767.7, received 60502.6
debug1: Exit status 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12683687 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14225570" author="lirui" created="Wed, 26 Nov 2014 01:40:11 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;Xuefu Zhang&lt;/a&gt; for taking care of this. I&apos;ll rebase and run tests on my side.&lt;/p&gt;</comment>
                            <comment id="14225606" author="xuefuz" created="Wed, 26 Nov 2014 02:18:57 +0000"  >&lt;p&gt;Reattach the same patch to trigger test.&lt;/p&gt;</comment>
                            <comment id="14225619" author="xuefuz" created="Wed, 26 Nov 2014 02:38:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ruili&quot; class=&quot;user-hover&quot; rel=&quot;ruili&quot;&gt;Rui Li&lt;/a&gt;, no problem. I just wanted to get this in as soon as possible. The latest patch should be good.&lt;/p&gt;</comment>
                            <comment id="14225804" author="hiveqa" created="Wed, 26 Nov 2014 06:05:06 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12683739/HIVE-8961.3-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12683739/HIVE-8961.3-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 13 failed/errored test(s), 7178 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestAuthorizationApiAuthorizer - did not produce a TEST-*.xml file
TestGenericUDFOPNumeric - did not produce a TEST-*.xml file
TestHBaseKeyFactory - did not produce a TEST-*.xml file
TestHBaseKeyFactory2 - did not produce a TEST-*.xml file
TestHBaseKeyFactory3 - did not produce a TEST-*.xml file
TestHBasePredicateDecomposer - did not produce a TEST-*.xml file
TestTezSessionState - did not produce a TEST-*.xml file
TestURLHook - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_alter_partition_coltype
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_transform_acid
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin7
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/440/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/440/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/440/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/440/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-440/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-440/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 13 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12683739 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14225810" author="xuefuz" created="Wed, 26 Nov 2014 06:10:20 +0000"  >&lt;p&gt;alter_partition_coltype.q failure doesn&apos;t seem related. bucketmapjoin7.q failure is existing and tracked by other JIRA. So the patch looks good. I&apos;m going to commit it now.&lt;/p&gt;</comment>
                            <comment id="14225815" author="xuefuz" created="Wed, 26 Nov 2014 06:14:04 +0000"  >&lt;p&gt;Patch #3 is committed to Spark branch. Thanks to Rui for the contribution.&lt;/p&gt;</comment>
                            <comment id="14225826" author="lirui" created="Wed, 26 Nov 2014 06:28:40 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;Xuefu Zhang&lt;/a&gt; for the work.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12749435">HIVE-8536</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12683535" name="HIVE-8961.1-spark.patch" size="389790" author="lirui" created="Tue, 25 Nov 2014 12:38:31 +0000"/>
                            <attachment id="12683648" name="HIVE-8961.2-spark.patch" size="620935" author="xuefuz" created="Tue, 25 Nov 2014 20:41:47 +0000"/>
                            <attachment id="12683739" name="HIVE-8961.3-spark.patch" size="621489" author="xuefuz" created="Wed, 26 Nov 2014 02:18:57 +0000"/>
                            <attachment id="12683687" name="HIVE-8961.3-spark.patch" size="621489" author="xuefuz" created="Tue, 25 Nov 2014 23:10:49 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 25 Nov 2014 13:29:33 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22rbj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8962] Add SORT_QUERY_RESULTS for join tests that do not guarantee order #2</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8962</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Similar to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8936&quot; title=&quot;Add SORT_QUERY_RESULTS for join tests that do not guarantee order&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8936&quot;&gt;&lt;del&gt;HIVE-8936&lt;/del&gt;&lt;/a&gt;, we need to add &lt;tt&gt;SORT_QUERY_RESULTS&lt;/tt&gt; to the following q-files:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ppd_multi_insert.q
ptf_streaming.q
subquery_exists.q
subquery_multiinsert.q
vectorized_ptf.q
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12757726">HIVE-8962</key>
            <summary>Add SORT_QUERY_RESULTS for join tests that do not guarantee order #2</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12752296">HIVE-8699</parent>
                                    <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="csun">Chao Sun</assignee>
                                    <reporter username="csun">Chao Sun</reporter>
                        <labels>
                    </labels>
                <created>Tue, 25 Nov 2014 15:53:38 +0000</created>
                <updated>Thu, 12 Feb 2015 23:40:58 +0000</updated>
                            <resolved>Wed, 26 Nov 2014 15:12:42 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="14225123" author="csun" created="Tue, 25 Nov 2014 20:03:01 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chinnalalam&quot; class=&quot;user-hover&quot; rel=&quot;chinnalalam&quot;&gt;Chinna Rao Lalam&lt;/a&gt;, do you mind if I take this over? It&apos;s related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8946&quot; title=&quot;Enable Map Join [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8946&quot;&gt;&lt;del&gt;HIVE-8946&lt;/del&gt;&lt;/a&gt;, and I&apos;ve already have a patch for this.Thanks!&lt;/p&gt;</comment>
                            <comment id="14225182" author="xuefuz" created="Tue, 25 Nov 2014 20:49:21 +0000"  >&lt;p&gt;+1 pending on test.&lt;/p&gt;</comment>
                            <comment id="14226050" author="hiveqa" created="Wed, 26 Nov 2014 11:36:45 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12683651/HIVE-8962.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12683651/HIVE-8962.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 6683 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1907/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1907/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1907/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1907/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1907/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1907/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12683651 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14226287" author="xuefuz" created="Wed, 26 Nov 2014 15:12:42 +0000"  >&lt;p&gt;Patch committed to trunk. Thanks to Chao for the contribution.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12757088">HIVE-8946</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12683651" name="HIVE-8962.patch" size="32993" author="csun" created="Tue, 25 Nov 2014 20:46:03 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 25 Nov 2014 20:49:21 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22rov:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8963] Investigate test failure on bucketmapjoin7.q [Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8963</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;When running on jenkins, test result for this one is different (same as MR though) from the result generated on my local machine. The test is similar to bucketmapjoin10 and bucketmapjoin11, so it might be related. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12757730">HIVE-8963</key>
            <summary>Investigate test failure on bucketmapjoin7.q [Spark Branch]</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12752296">HIVE-8699</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jxiang">Jimmy Xiang</assignee>
                                    <reporter username="csun">Chao Sun</reporter>
                        <labels>
                    </labels>
                <created>Tue, 25 Nov 2014 16:07:09 +0000</created>
                <updated>Fri, 29 May 2015 02:28:55 +0000</updated>
                            <resolved>Sun, 30 Nov 2014 17:42:26 +0000</resolved>
                                    <version>spark-branch</version>
                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="14225455" author="jxiang" created="Wed, 26 Nov 2014 00:17:16 +0000"  >&lt;p&gt;Looked into it. Without limit 1, the output for spark is the same as that for mr. With order by, the output is always right. So it should be an order isue. Filed &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8967&quot; title=&quot;Fix bucketmapjoin7.q determinism&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8967&quot;&gt;&lt;del&gt;HIVE-8967&lt;/del&gt;&lt;/a&gt; for trunk.&lt;/p&gt;</comment>
                            <comment id="14229173" author="jxiang" created="Sun, 30 Nov 2014 17:43:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8967&quot; title=&quot;Fix bucketmapjoin7.q determinism&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8967&quot;&gt;&lt;del&gt;HIVE-8967&lt;/del&gt;&lt;/a&gt; was merged to spark banch. &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8994&quot; title=&quot;Merge from trunk Nov 28 2014&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8994&quot;&gt;&lt;del&gt;HIVE-8994&lt;/del&gt;&lt;/a&gt; fixed the spark qfile output.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12757088">HIVE-8946</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 26 Nov 2014 00:17:16 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22rpr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8964] Some TestMiniTezCliDriver tests taking two hours</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8964</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The test &lt;tt&gt;TestMiniTezCliDriver&lt;/tt&gt; with the following query files:&lt;/p&gt;

&lt;p&gt;vectorization_16.q,mapjoin_mapjoin.q,groupby2.q,lvj_mapjoin.q,vectorization_5.q,vectorization_pushdown.q,orc_merge_incompat1.q,cbo_gby.q,vectorization_4.q,auto_join0.q,cross_product_check_1.q,vectorization_not.q,update_where_no_match.q,ctas.q,cbo_udf_udaf.q&lt;/p&gt;

&lt;p&gt;is timing out after two hours severely delaying the Hive precommits&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1898/failed/TestMiniTezCliDriver-vectorization_16.q-mapjoin_mapjoin.q-groupby2.q-and-12-more/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1898/failed/TestMiniTezCliDriver-vectorization_16.q-mapjoin_mapjoin.q-groupby2.q-and-12-more/&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12757744">HIVE-8964</key>
            <summary>Some TestMiniTezCliDriver tests taking two hours</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hagleitn">Gunther Hagleitner</assignee>
                                    <reporter username="brocknoland">Brock Noland</reporter>
                        <labels>
                    </labels>
                <created>Tue, 25 Nov 2014 16:54:11 +0000</created>
                <updated>Thu, 12 Feb 2015 23:41:02 +0000</updated>
                            <resolved>Sun, 18 Jan 2015 20:26:32 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="14224819" author="brocknoland" created="Tue, 25 Nov 2014 16:58:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8965&quot; title=&quot;Enhance PTest to kill all processes between tests and to report when a TEST*.xml file is not generated&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8965&quot;&gt;&lt;del&gt;HIVE-8965&lt;/del&gt;&lt;/a&gt; should catch when these are introduced.&lt;/p&gt;</comment>
                            <comment id="14224821" author="brocknoland" created="Tue, 25 Nov 2014 17:00:24 +0000"  >&lt;p&gt;FYI &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hagleitn&quot; class=&quot;user-hover&quot; rel=&quot;hagleitn&quot;&gt;Gunther Hagleitner&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14224831" author="brocknoland" created="Tue, 25 Nov 2014 17:03:51 +0000"  >&lt;p&gt;The only thing I noted in the logs was two &quot;connection reset by peer&quot; errors and:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2014-11-25 01:15:37,975 DEBUG security.UserGroupInformation (UserGroupInformation.java:doAs(1618)) - PrivilegedActionException as:hiveptest (auth:SIMPLE) cause:org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException: No lease on /home/hiveptest/54.227.92.185-hiveptest-0/apache-svn-trunk-source/itests/qtest/target/tmp/scratchdir/hiveptest/_tez_session_dir/5c3bba9c-9090-46de-81bd-93367d97f2ce/.tez/application_1416906780994_0001/recovery/1/summary (inode 16430): File does not exist. Holder DFSClient_NONMAPREDUCE_248168316_1 does not have any open files.
2014-11-25 01:15:37,976 DEBUG security.UserGroupInformation (UserGroupInformation.java:logPrivilegedAction(1638)) - PrivilegedAction as:hiveptest (auth:SIMPLE) from:org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)
2014-11-25 01:15:37,976 INFO  ipc.Server (Server.java:run(2027)) - IPC Server handler 8 on 37902, call org.apache.hadoop.hdfs.protocol.ClientProtocol.complete from 127.0.0.1:41635 Call#467 Retry#0: org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException: No lease on /home/hiveptest/54.227.92.185-hiveptest-0/apache-svn-trunk-source/itests/qtest/target/tmp/scratchdir/hiveptest/_tez_session_dir/5c3bba9c-9090-46de-81bd-93367d97f2ce/.tez/application_1416906780994_0001/recovery/1/summary (inode 16430): File does not exist. Holder DFSClient_NONMAPREDUCE_248168316_1 does not have any open files.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14224908" author="hagleitn" created="Tue, 25 Nov 2014 17:52:59 +0000"  >&lt;p&gt;I&apos;ll take a look.&lt;/p&gt;</comment>
                            <comment id="14227040" author="brocknoland" created="Thu, 27 Nov 2014 00:18:50 +0000"  >&lt;p&gt;I am pretty sure this is &lt;tt&gt;lvj_mapjoin.q&lt;/tt&gt; which was added in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8888&quot; title=&quot;Mapjoin with LateralViewJoin generates wrong plan in Tez&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8888&quot;&gt;&lt;del&gt;HIVE-8888&lt;/del&gt;&lt;/a&gt;. I&apos;ve excluded that test on the PTest side. We&apos;ll see if that helps.&lt;/p&gt;</comment>
                            <comment id="14228019" author="hagleitn" created="Fri, 28 Nov 2014 01:09:59 +0000"  >&lt;p&gt;Yes, it&apos;s definitely lvj_mapjoin.q. I can repro the hang - no idea why yet.&lt;/p&gt;</comment>
                            <comment id="14228026" author="hagleitn" created="Fri, 28 Nov 2014 01:33:39 +0000"  >&lt;p&gt;Happens with tez 0.6.0 also. Same as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt; only Exception I see is:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /Users/ghagleitner/Projects/hive-trunk2/itests/qtest/target/tmp/scratchdir/ghagleitner/_tez_session_dir/dc4fca20-4a39-4452-9\
75a-467bda4947ca/.tez/application_1417137410462_0001/recovery/1/summary (inode 16430): File does not exist. Holder DFSClient_NONMAPREDUCE_1900574341_1 does not have any open files.                                                          
  at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3083)                                                                                                                                                   
  at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3170)                                                                                                                                         
  at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3140)                                                                                                                                                 
  at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:665)                                                                                                                                            
  at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:499)                                                                                           
  at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)                                                                                        
  at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)                                                                                                                                       
  at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)                                                                                                                                                                                      
  at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)                                                                                                                                                                             
  at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)                                                                                                                                                                             
  at java.security.AccessController.doPrivileged(Native Method)                                                                                                                                                                               
  at javax.security.auth.Subject.doAs(Subject.java:394)                                                                                                                                                                                       
  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)                                                                                                                                                     
  at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)                                                                                                                                                                               
                                                                                                                                                                                                                                              
  at org.apache.hadoop.ipc.Client.call(Client.java:1411)                                                                                                                                                                                      
  at org.apache.hadoop.ipc.Client.call(Client.java:1364)                                                                                                                                                                                      
  at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)                                                                                                                                                       
  at com.sun.proxy.$Proxy14.complete(Unknown Source)                                                                                                                                                                                          
  at sun.reflect.GeneratedMethodAccessor50.invoke(Unknown Source)                                                                                                                                                                             
  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)                                                                                                                                                    
  at java.lang.reflect.Method.invoke(Method.java:597)                                                                                                                                                                                         
  at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)                                                                                                                                          
  at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)                                                                                                                                                
  at com.sun.proxy.$Proxy14.complete(Unknown Source)                                                                                                                                                                                          
  at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:412)                                                                                                               
  at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2135)                                                                                                                                                           
  at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2119)                                                                                                                                                                  
  at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)                                                                                                                                                  
  at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)                                                                                                                                                               
  at org.apache.tez.dag.history.recovery.RecoveryService.serviceStop(RecoveryService.java:201)                                                                                                                                                
  at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)                                                                                                                                                                 
  at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)                                                                                                                                                              
  at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)                                                                                                                                                       
  at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157)                                                                                                                                                               
  at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)                                                                                                                                                        
  at org.apache.tez.dag.history.HistoryEventHandler.serviceStop(HistoryEventHandler.java:80)                                                                                                                                                  
  at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)                                                                                                                                                                 
  at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)                                                                                                                                                              
  at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)                                                                                                                                                       
  at org.apache.tez.dag.app.DAGAppMaster.stopServices(DAGAppMaster.java:1504)                                                                                                                                                                 
  at org.apache.tez.dag.app.DAGAppMaster.serviceStop(DAGAppMaster.java:1643)                                                                                                                                                                  
  at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)                                                                                                                                                                 
  at org.apache.tez.dag.app.DAGAppMaster$DAGAppMasterShutdownHandler$AMShutdownRunnable.run(DAGAppMaster.java:698)                                                                                                                            
  at java.lang.Thread.run(Thread.java:695)  
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Will open tez bug to see if they can help.&lt;/p&gt;</comment>
                            <comment id="14228139" author="hagleitn" created="Fri, 28 Nov 2014 08:07:09 +0000"  >&lt;p&gt;Alright with the Tez guys&apos; help figured out that the planner was producing a cyclic graph. I&apos;ve re-opened &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8888&quot; title=&quot;Mapjoin with LateralViewJoin generates wrong plan in Tez&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8888&quot;&gt;&lt;del&gt;HIVE-8888&lt;/del&gt;&lt;/a&gt; and added a new patch. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt; when the new patch in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8888&quot; title=&quot;Mapjoin with LateralViewJoin generates wrong plan in Tez&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8888&quot;&gt;&lt;del&gt;HIVE-8888&lt;/del&gt;&lt;/a&gt;, can you re-enable the test on the build machine? (or did you disable in the source somewhere?)&lt;/p&gt;</comment>
                            <comment id="14228459" author="brocknoland" created="Fri, 28 Nov 2014 18:28:50 +0000"  >&lt;p&gt;I disabled it in some properties files on the build host. Really need to get those in svn. I&apos;ll try that today.&lt;/p&gt;

&lt;p&gt;I will continue the discussion on how to test the patch in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8888&quot; title=&quot;Mapjoin with LateralViewJoin generates wrong plan in Tez&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8888&quot;&gt;&lt;del&gt;HIVE-8888&lt;/del&gt;&lt;/a&gt; over there.&lt;/p&gt;</comment>
                            <comment id="14281946" author="brocknoland" created="Sun, 18 Jan 2015 20:26:32 +0000"  >&lt;p&gt;We fixed this instance but this is happening again. I&apos;ll resolve this and open a new JIRA.&lt;/p&gt;</comment>
                            <comment id="14281948" author="brocknoland" created="Sun, 18 Jan 2015 20:28:10 +0000"  >&lt;p&gt;Jira tracking new issue is here: &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-9406&quot; title=&quot;Some TestMiniTezCliDriver tests not returning results after two hours&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-9406&quot;&gt;&lt;del&gt;HIVE-9406&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12768326">HIVE-9406</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12756855">HIVE-8931</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12757746">HIVE-8965</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12758296">TEZ-1805</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 25 Nov 2014 17:52:59 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 1 week, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22rsf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8965] Enhance PTest to kill all processes between tests and to report when a TEST*.xml file is not generated</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8965</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12757746">HIVE-8965</key>
            <summary>Enhance PTest to kill all processes between tests and to report when a TEST*.xml file is not generated</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="brocknoland">Brock Noland</assignee>
                                    <reporter username="brocknoland">Brock Noland</reporter>
                        <labels>
                    </labels>
                <created>Tue, 25 Nov 2014 16:58:27 +0000</created>
                <updated>Thu, 12 Feb 2015 23:41:04 +0000</updated>
                            <resolved>Wed, 26 Nov 2014 00:49:41 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="14225348" author="szehon" created="Tue, 25 Nov 2014 22:57:58 +0000"  >&lt;p&gt;Great, was hoping for this feature for awhile.  +1.  &lt;/p&gt;

&lt;p&gt;Just wondering why do we need to do &apos;pkill -9&apos; followed by regular &apos;pkill&apos;, ie why do we need to do it twice?&lt;/p&gt;</comment>
                            <comment id="14225351" author="brocknoland" created="Tue, 25 Nov 2014 23:03:32 +0000"  >&lt;p&gt;The code executes &lt;tt&gt;pkill -f java&lt;/tt&gt; then &lt;tt&gt;pkill -9 -f java&lt;/tt&gt;:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;    execHostsIgnoreErrors(&quot;pkill -f java&quot;);
    execHostsIgnoreErrors(&quot;pkill -9 -f java&quot;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;but it shows out the opposite in the output file since the commands are sorted:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  protected String getExecutedCommands() {
    List&amp;lt;String&amp;gt; result = Lists.newArrayList();
    result.addAll(returnNotNull(sshCommandExecutor.getCommands()));
    result.addAll(returnNotNull(localCommandFactory.getCommands()));
    result.addAll(returnNotNull(rsyncCommandExecutor.getCommands()));
    Collections.sort(result);
    return Joiner.on(&quot;\n&quot;).join(result);
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We do that because we first tell the processes to terminate normally and then if they do not we force kill them.&lt;/p&gt;</comment>
                            <comment id="14225368" author="szehon" created="Tue, 25 Nov 2014 23:17:02 +0000"  >&lt;p&gt;Got it, the reverse order confused me.&lt;/p&gt;</comment>
                            <comment id="14225501" author="brocknoland" created="Wed, 26 Nov 2014 00:48:43 +0000"  >&lt;p&gt;Since this is causing some issues I am going to commit this now and then test it on the spark branch.&lt;/p&gt;</comment>
                            <comment id="14225597" author="szehon" created="Wed, 26 Nov 2014 02:08:02 +0000"  >&lt;p&gt;+1 on latest patch&lt;/p&gt;</comment>
                            <comment id="14225753" author="brocknoland" created="Wed, 26 Nov 2014 05:09:16 +0000"  >&lt;p&gt;FYI this exposed &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8971&quot; title=&quot;HIVE-8965 exposed some classes which start with Test but are not tests&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8971&quot;&gt;&lt;del&gt;HIVE-8971&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12756855">HIVE-8931</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12757744">HIVE-8964</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12757899">HIVE-8971</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12683734" name="HIVE-8965.patch" size="1404" author="brocknoland" created="Wed, 26 Nov 2014 02:05:49 +0000"/>
                            <attachment id="12683682" name="HIVE-8965.patch" size="12623" author="brocknoland" created="Tue, 25 Nov 2014 22:46:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 25 Nov 2014 22:57:58 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22rsv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8966] Delta files created by hive hcatalog streaming cannot be compacted</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8966</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;hive hcatalog streaming will also create a file like bucket_n_flush_length in each delta directory. Where &quot;n&quot; is the bucket number. But the compactor.CompactorMR think this file also needs to compact. However this file of course cannot be compacted, so compactor.CompactorMR will not continue to do the compaction. &lt;/p&gt;

&lt;p&gt;Did a test, after removed the bucket_n_flush_length file, then the &quot;alter table partition compact&quot; finished successfully. If don&apos;t delete that file, nothing will be compacted. &lt;br/&gt;
This is probably a very severity bug. Both 0.13 and 0.14 have this issue&lt;/p&gt;</description>
                <environment>&lt;p&gt;hive&lt;/p&gt;</environment>
        <key id="12757795">HIVE-8966</key>
            <summary>Delta files created by hive hcatalog streaming cannot be compacted</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="alangates">Alan Gates</assignee>
                                    <reporter username="jihongliu">Jihong Liu</reporter>
                        <labels>
                    </labels>
                <created>Tue, 25 Nov 2014 20:32:53 +0000</created>
                <updated>Thu, 19 Feb 2015 18:22:01 +0000</updated>
                            <resolved>Tue, 27 Jan 2015 19:19:39 +0000</resolved>
                                    <version>0.14.0</version>
                                    <fixVersion>1.0.0</fixVersion>
                                    <component>HCatalog</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>10</watches>
                                                                <comments>
                            <comment id="14226794" author="alangates" created="Wed, 26 Nov 2014 20:48:20 +0000"  >&lt;p&gt;This flush length file should be removed when the batch is closed.  Are you closing the transaction batch on a regular basis?&lt;/p&gt;</comment>
                            <comment id="14226872" author="jihongliu" created="Wed, 26 Nov 2014 22:08:43 +0000"  >&lt;p&gt;Yes. Closed the transaction batch. Suggest to do either the following two updates, or do both:&lt;/p&gt;

&lt;p&gt;1. if a file is non-bucket file, don&apos;t try to compact it. So update the following code:&lt;br/&gt;
   in org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.java&lt;br/&gt;
  Change the following code:&lt;/p&gt;

&lt;p&gt;  private void addFileToMap(Matcher matcher, Path file, boolean sawBase,&lt;br/&gt;
                              Map&amp;lt;Integer, BucketTracker&amp;gt; splitToBucketMap) {&lt;br/&gt;
      if (!matcher.find()) &lt;/p&gt;
{
        LOG.warn(&quot;Found a non-bucket file that we thought matched the bucket pattern! &quot; +
            file.toString());
      }

&lt;p&gt;   .....&lt;br/&gt;
 to:&lt;br/&gt;
   private void addFileToMap(Matcher matcher, Path file, boolean sawBase,&lt;br/&gt;
                              Map&amp;lt;Integer, BucketTracker&amp;gt; splitToBucketMap) {&lt;br/&gt;
      if (!matcher.find()) &lt;/p&gt;
{
        LOG.warn(&quot;Found a non-bucket file that we thought matched the bucket pattern! &quot; +
            file.toString());
        return;
      }
&lt;p&gt;     ....&lt;/p&gt;

&lt;p&gt;2. don&apos;t use the bucket file pattern to name to &quot;flush_length&quot; file. So update the following code:&lt;br/&gt;
  in org.apache.hadoop.hive.ql.io.orc.OrcRecordUpdater.java&lt;br/&gt;
 change the following code:&lt;br/&gt;
   static Path getSideFile(org.apache.tools.ant.types.Path main) &lt;/p&gt;
{
     return new Path(main + &quot;_flush_length&quot;);
   }

&lt;p&gt;to:&lt;br/&gt;
 static Path getSideFile(org.apache.tools.ant.types.Path main) {&lt;br/&gt;
	if (main.toString().startsWith(&quot;bucket_&quot;)) &lt;/p&gt;
{
	     return new Path(&quot;bkt&quot;+main.toString().substring(6)+ &quot;_flush_length&quot;);
	}
&lt;p&gt;              else return new Path(main + &quot;_flush_length&quot;);&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;after did the above updates and re-compiled the hive-exec.jar, the compaction works fine now&lt;/p&gt;</comment>
                            <comment id="14226890" author="alangates" created="Wed, 26 Nov 2014 22:19:10 +0000"  >&lt;p&gt;1 might be the right thing to do.  2 breaks backward compatibility.  Before we do that though I&apos;d like to understand why you still see the flush length files hanging around.  In my tests I don&apos;t see this issue because the flush length file is properly cleaned up.  I want to make sure that its existence doesn&apos;t mean something else is wrong.&lt;/p&gt;

&lt;p&gt;Do you see the flush length files in all delta directories or only the most recent?  &lt;/p&gt;</comment>
                            <comment id="14226925" author="jihongliu" created="Wed, 26 Nov 2014 22:43:34 +0000"  >&lt;p&gt;That flush_length file is only in the most recent delta. By the way, for streaming loading, a transaction batch is probably always open since data keeps coming. Is it possible to do compaction in the streaming loading environment? Thanks &lt;/p&gt;</comment>
                            <comment id="14226943" author="alangates" created="Wed, 26 Nov 2014 22:54:56 +0000"  >&lt;p&gt;Ok, that makes sense.  You&apos;re current delta has the file because it&apos;s still open and being written to.  It also explains why my tests don&apos;t see it, as they don&apos;t run long enough.  The streaming is always done by the time the compactor kicks in.  Why don&apos;t you post a patch to this JIRA with the change for 1, and I can get that committed.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hagleitn&quot; class=&quot;user-hover&quot; rel=&quot;hagleitn&quot;&gt;Gunther Hagleitner&lt;/a&gt;, I&apos;d like to put this in 0.14.1 as well as trunk if you&apos;re ok with it, since it blocks compaction for users using the streaming interface.&lt;/p&gt;</comment>
                            <comment id="14227045" author="hagleitn" created="Thu, 27 Nov 2014 00:25:47 +0000"  >&lt;p&gt;+1 for 0.14.1&lt;/p&gt;</comment>
                            <comment id="14232306" author="jihongliu" created="Tue, 2 Dec 2014 23:41:12 +0000"  >&lt;p&gt;Thanks. So now the fix is in 0.14.1?&lt;/p&gt;</comment>
                            <comment id="14233768" author="jihongliu" created="Thu, 4 Dec 2014 01:27:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/i#browse/HIVE-8966&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/i#browse/HIVE-8966&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14233775" author="jihongliu" created="Thu, 4 Dec 2014 01:30:26 +0000"  >&lt;p&gt;Patch for HIVE08966&lt;/p&gt;</comment>
                            <comment id="14233790" author="jihongliu" created="Thu, 4 Dec 2014 01:40:05 +0000"  >&lt;p&gt;The patch is attached. Please review. Thanks&lt;/p&gt;</comment>
                            <comment id="14234769" author="jihongliu" created="Thu, 4 Dec 2014 23:11:34 +0000"  >&lt;p&gt;I think we may have to withdraw this patch for now. It looks like currently hive must not support doing compaction and loading in the same time for a partition. &lt;br/&gt;
Without this patch, if loading for a partition is not completely finished, compaction will always fail, so nothing happen. After apply this patch, compaction will go through and finish. However we may loss data! I did a test. Data could be lost if we do compaction meanwhile the loading is not finished yet. &lt;br/&gt;
But if keep the current version, it must be a limitation for hive. If streaming load to a partition for a long period, performance will be affected if cannot do compaction on it. &lt;/p&gt;

&lt;p&gt;For completely solve this issue, my initial thinking is that the delta files with open transaction should not be compacted. Currently they must be inlcuded, and it is probably the reason for data lost. But other closed delta files should be able to compact. So we can do compaction and loading in the same time.&lt;/p&gt;</comment>
                            <comment id="14235645" author="alangates" created="Fri, 5 Dec 2014 15:40:59 +0000"  >&lt;p&gt;Jihong, thanks for doing the testing on this.  &lt;/p&gt;

&lt;p&gt;We could change this to not compact the current delta file, or we could change the cleaner to not remove the delta file that was still open during compaction.  I&apos;ll try to look at this in the next couple of days.  We need to get this fixed for 0.14.1.&lt;/p&gt;</comment>
                            <comment id="14235923" author="jihongliu" created="Fri, 5 Dec 2014 19:07:24 +0000"  >&lt;p&gt;Great. I am working on that now. Will update you after finished the testing.&lt;/p&gt;</comment>
                            <comment id="14237046" author="jihongliu" created="Sun, 7 Dec 2014 04:41:34 +0000"  >&lt;p&gt;The scenario of data lost:&lt;br/&gt;
Assume when start compaction there are two deltas, delta_00011_00020 and delta_00021_00030, where the transaction batch in the first one is closed, and the second one still has transaction batch open. After compaction is finished, the status in compaction_ queue  will become &#8220;ready_for_clean&#8221;. Then clean process will be triggered. Cleaner will remove all deltas if its transaction id is less than the base which just created and if there is no lock on it. In the meantime, we still load data into the second delta. When finish loading and close the transaction batch, cleaner detects no lock on that, so delete it. So the new data added after compaction will be lost. &lt;/p&gt;</comment>
                            <comment id="14237047" author="jihongliu" created="Sun, 7 Dec 2014 04:42:48 +0000"  >&lt;p&gt;Solution: &lt;br/&gt;
if the last delta has any file which is in bucket file pattern, but actually is non bucket file, don&#8217;t compact this delta. When a transaction is not close, a delta will have a file like bucket_n_flash_length, which is non bucket file. Actually for any reason, if the last delta has a file with bucket file pattern but not compactable, we should ignore this delta. Since after compaction, the delta will be removed. So if the whole delta cannot be compacted, leave it as what it is. So in the above scenario, the second delta will not be compacted. And the cleaner will not remove it because it has higher transaction id than the new created compaction file(base or delta). &lt;br/&gt;
The reason we only do the above for the last delta is to consider the case that two or more transaction batches may be created and the last one is close first. Then if the last delta gets compacted, the transaction id in the base will be big, so all deltas will be removed by cleaner. So data could be lost. In this case, in the list of deltas for compaction, at least one delta has that bucket_n_flash_length file inside. Since we do not ignore it, the compaction will be auto-fail, so nothing happen, no data lost. In this case, the compaction can only be done after all transaction batches are closed. Although it is not so good, at least no data lost.&lt;br/&gt;
The patch is attached. It adds one method to test whether needs to remove the last delta from the delta list. And before process the delta list, run that method.  After applying this patch, no data is lost. We can do either major or minor compaction meanwhile keeping loading data in the same time.&lt;/p&gt;</comment>
                            <comment id="14237048" author="jihongliu" created="Sun, 7 Dec 2014 04:43:23 +0000"  >&lt;p&gt;By the way, hive may need another cleaning process which auto removes the bucket_n_flash_length file if the connection is actually closed.  A program may not be able to close a transaction batch, due to many reasons, for example, network disconnected, server shutdown, application killed, and etc. So if the connection which creates a batch has been closed, that bucket_n_flash_length file needs to be removed. Otherwise that delta and the deltas after it can never be compacted unless we remove that file manually.&lt;/p&gt;</comment>
                            <comment id="14237057" author="hiveqa" created="Sun, 7 Dec 2014 05:07:41 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12685584/HIVE-8966.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12685584/HIVE-8966.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1985/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1985/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1985/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1985/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1985/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1985/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-1985/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java&apos;
Reverted &apos;common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java&apos;
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20S/target shims/0.23/target shims/aggregator/target shims/common/target shims/scheduler/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit-hadoop2/target itests/hive-minikdc/target itests/hive-unit/target itests/custom-serde/target itests/util/target hcatalog/target hcatalog/core/target hcatalog/streaming/target hcatalog/server-extensions/target hcatalog/hcatalog-pig-adapter/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target accumulo-handler/target hwi/target common/target common/src/gen common/src/java/org/apache/hadoop/hive/conf/HiveConf.java.orig contrib/target service/target serde/target beeline/target odbc/target cli/target ql/dependency-reduced-pom.xml ql/target ql/src/test/results/clientpositive/parquet_array_of_multi_field_struct_gen_schema.q.out ql/src/test/results/clientpositive/parquet_decimal_gen_schema.q.out ql/src/test/results/clientpositive/parquet_array_of_unannotated_groups_gen_schema.q.out ql/src/test/results/clientpositive/parquet_array_of_single_field_struct_gen_schema.q.out ql/src/test/results/clientpositive/parquet_array_of_unannotated_primitives_gen_schema.q.out ql/src/test/results/clientpositive/parquet_array_of_structs_gen_schema.q.out ql/src/test/results/clientpositive/parquet_avro_array_of_primitives_gen_schema.q.out ql/src/test/results/clientpositive/parquet_thrift_array_of_single_field_struct_gen_schema.q.out ql/src/test/results/clientpositive/parquet_array_of_optional_elements_gen_schema.q.out ql/src/test/results/clientpositive/parquet_avro_array_of_single_field_struct_gen_schema.q.out ql/src/test/results/clientpositive/parquet_thrift_array_of_primitives_gen_schema.q.out ql/src/test/results/clientpositive/parquet_array_of_structs_gen_schema_ext.q.out ql/src/test/results/clientpositive/parquet_array_of_required_elements_gen_schema.q.out ql/src/test/queries/clientpositive/parquet_avro_array_of_single_field_struct_gen_schema.q ql/src/test/queries/clientpositive/parquet_array_of_single_field_struct_gen_schema.q ql/src/test/queries/clientpositive/parquet_array_of_structs_gen_schema.q ql/src/test/queries/clientpositive/parquet_array_of_multi_field_struct_gen_schema.q ql/src/test/queries/clientpositive/parquet_thrift_array_of_primitives_gen_schema.q ql/src/test/queries/clientpositive/parquet_thrift_array_of_single_field_struct_gen_schema.q ql/src/test/queries/clientpositive/parquet_array_of_required_elements_gen_schema.q ql/src/test/queries/clientpositive/parquet_array_of_unannotated_groups_gen_schema.q ql/src/test/queries/clientpositive/parquet_avro_array_of_primitives_gen_schema.q ql/src/test/queries/clientpositive/parquet_decimal_gen_schema.q ql/src/test/queries/clientpositive/parquet_array_of_structs_gen_schema_ext.q ql/src/test/queries/clientpositive/parquet_array_of_optional_elements_gen_schema.q ql/src/test/queries/clientpositive/parquet_array_of_unannotated_primitives_gen_schema.q ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java.orig ql/src/java/org/apache/hadoop/hive/ql/io/parquet/convert/ParquetSchemaReader.java ql/src/java/org/apache/hadoop/hive/ql/io/parquet/convert/ParquetToHiveSchemaConverter.java
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1643648.

At revision 1643648.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12685584 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14237062" author="jihongliu" created="Sun, 7 Dec 2014 05:34:41 +0000"  >&lt;p&gt;Hi Alan,I have created a new patch. It works fine. The patch is pasted in that jira, also added comment about the logic. Please have a look.&#160;Thanks and have a good dayJihong&lt;br/&gt;
      From: Alan Gates (JIRA) &amp;lt;jira@apache.org&amp;gt;&#160;&lt;br/&gt;
 To: jhliu08@yahoo.com &lt;br/&gt;
 Sent: Friday, December 5, 2014 7:41 AM&lt;br/&gt;
 Subject: &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Commented&amp;#93;&lt;/span&gt; (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8966&quot; title=&quot;Delta files created by hive hcatalog streaming cannot be compacted&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8966&quot;&gt;&lt;del&gt;HIVE-8966&lt;/del&gt;&lt;/a&gt;) Delta files created by hive hcatalog streaming cannot be compacted&lt;/p&gt;


&lt;p&gt;&#160; &#160; [ &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8966?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&amp;amp;focusedCommentId=14235645#comment-14235645&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-8966?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&amp;amp;focusedCommentId=14235645#comment-14235645&lt;/a&gt; ] &lt;/p&gt;

&lt;p&gt;Alan Gates commented on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8966&quot; title=&quot;Delta files created by hive hcatalog streaming cannot be compacted&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8966&quot;&gt;&lt;del&gt;HIVE-8966&lt;/del&gt;&lt;/a&gt;:&lt;br/&gt;
----------------------------------&lt;/p&gt;

&lt;p&gt;Jihong, thanks for doing the testing on this.&#160; &lt;/p&gt;

&lt;p&gt;We could change this to not compact the current delta file, or we could change the cleaner to not remove the delta file that was still open during compaction.&#160; I&apos;ll try to look at this in the next couple of days.&#160; We need to get this fixed for 0.14.1.&lt;/p&gt;




&lt;p&gt;&amp;#8211;&lt;br/&gt;
This message was sent by Atlassian JIRA&lt;br/&gt;
(v6.3.4#6332)&lt;/p&gt;

</comment>
                            <comment id="14237067" author="jihongliu" created="Sun, 7 Dec 2014 06:04:49 +0000"  >&lt;p&gt;Alan,&lt;br/&gt;
I created a wrong patch about 1 hour ago. Before I removed it. QA automatically did the above test. Please ignore and look the current attached patch. I think it really solves the issue.&lt;/p&gt;</comment>
                            <comment id="14237080" author="hiveqa" created="Sun, 7 Dec 2014 06:49:05 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12685590/HIVE-8966.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12685590/HIVE-8966.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 6696 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hive.hcatalog.streaming.TestStreaming.testEndpointConnection
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1986/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1986/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1986/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1986/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1986/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1986/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12685590 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14237257" author="jihongliu" created="Sun, 7 Dec 2014 20:00:54 +0000"  >&lt;p&gt;I am confused about the QA test. The error looks like not related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8966&quot; title=&quot;Delta files created by hive hcatalog streaming cannot be compacted&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8966&quot;&gt;&lt;del&gt;HIVE-8966&lt;/del&gt;&lt;/a&gt;.patch. First, was this patch really included in the build? Also this patch is for 0.14.1, not for trunk.&lt;/p&gt;</comment>
                            <comment id="14239636" author="alangates" created="Tue, 9 Dec 2014 16:45:29 +0000"  >&lt;p&gt;Don&apos;t worry about the results from testing, those tests are flaky.  I&apos;ll review the patch.&lt;/p&gt;</comment>
                            <comment id="14239750" author="alangates" created="Tue, 9 Dec 2014 17:59:50 +0000"  >&lt;p&gt;Rather than go remove these directories from the list of deltas I think it makes more sense to change Directory.getAcidState to not include these deltas.  We obviously can&apos;t do that in all cases, as readers need to see these deltas. But we can change it to see that this is the compactor and therefore those should be excluded.  I&apos;ll post a patch with this change.&lt;/p&gt;</comment>
                            <comment id="14240004" author="jihongliu" created="Tue, 9 Dec 2014 20:25:27 +0000"  >&lt;p&gt;I see. Basically there are two solutions. One is that when get the delta list, we don&apos;t include the current delta if it has open tranaction. So uptate the AcidUtil.getAcidState() directly. The other is what I posted here. We first get the delta list, then when do compaction, we don&apos;t compact the last one if there is open transaction. The first solution is better as long as changing getAcidState() doesn&apos;t affact other existing code, since it is a public static method. &lt;br/&gt;
By the way, we should only do that to the current delta (the delta with the largest transaction id), not to all deltas which have open transactions. If I am correct, the base file will be named based on the largest transaction id in the deltas. So if the latest delta is closed, but an early delta has an open transaction, we should not do anything. So simply let the compaction fail. Otherwise, the base will be named by the last transaction id, and all early deltas will be removed. That will cause data lost. This is my understanding, please correct me, it it is not correct. Thanks&lt;/p&gt;</comment>
                            <comment id="14240259" author="alangates" created="Tue, 9 Dec 2014 23:15:32 +0000"  >&lt;p&gt;A new version of the patch that moves Jihong&apos;s code into AcidUtils.getAcidState so that delta directories with flush length files are not put into the list of files to compact.  &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jihongliu&quot; class=&quot;user-hover&quot; rel=&quot;jihongliu&quot;&gt;Jihong Liu&lt;/a&gt;, could you test this on your end to make sure it addresses your issues.  I&apos;ll also do some long running tests to see that it allows compaction while streaming is ongoing.&lt;/p&gt;</comment>
                            <comment id="14240415" author="owen.omalley" created="Wed, 10 Dec 2014 00:43:23 +0000"  >&lt;p&gt;Alan, your patch looks good +1&lt;/p&gt;</comment>
                            <comment id="14240482" author="hiveqa" created="Wed, 10 Dec 2014 01:36:17 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12686124/HIVE-8966.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12686124/HIVE-8966.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 6704 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx_cbo_1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2013/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2013/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2013/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2013/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2013/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2013/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12686124 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14240701" author="jihongliu" created="Wed, 10 Dec 2014 06:00:07 +0000"  >&lt;p&gt;Alan,&lt;br/&gt;
Your idea is very good. But there is an issue here &amp;#8211; we should only do this &quot;compacting&quot; test for the most recent delta, not for all deltas. Following is an example for the reason:&lt;br/&gt;
Assume there are two deltas:&lt;br/&gt;
   1  delta_00011_00020    this delta has open transaction batch&lt;br/&gt;
   2  delta_00021_00030    this delta has no open transaction batch. All closed.&lt;/p&gt;

&lt;p&gt;In the above, the first delta has open transaction batch, the second has not. And the second delta is the most recent delta. This case is possible, especially when multiple threads write to the same partition. If we ignore the first one, then the compaction will success and create a base, like base_00030. Then cleaner will delete all the two deltas since their transaction id are less or equal to the base transaction id. Thus the data in delta 2 will be lost. This is why we should only test the most recent delta, all other deltas will be automatically in the list. Thus in this case, the compaction will be fail, since the &quot;flush_length&quot; file is there. And for this case, the compaction will be success only when all transaction batchs are closed. Although it is not perfect, at least no data lost. Since each delta file and transaction id for compaction is not saved anywhere, probably this is the only solution for now. &lt;br/&gt;
In my removeNotCompactableDeltas() method, we first sort the deltas, then only check the last one. But the name: &quot;removeNotCompactableDeltas&quot; is not good, easy makes confusion. It will be clear if named it as &quot;removeLastDeltaIfNotCompactable&quot;. &lt;br/&gt;
Thanks&lt;/p&gt;</comment>
                            <comment id="14241394" author="alangates" created="Wed, 10 Dec 2014 17:11:24 +0000"  >&lt;p&gt;Right, makes sense.  I need to think about whether it makes more sense to change AcidUtils.getAcidState to catch this as well or whether your approach of post processing it in the compactor makes more sense.&lt;/p&gt;</comment>
                            <comment id="14256032" author="alangates" created="Mon, 22 Dec 2014 18:43:59 +0000"  >&lt;p&gt;A new version of the patch which properly handles not putting any deltas in the list once we see a delta with a flush length file.  Unfortunately, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;Owen O&apos;Malley&lt;/a&gt; who needs to review this is out for a couple of weeks.  &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jihongliu&quot; class=&quot;user-hover&quot; rel=&quot;jihongliu&quot;&gt;Jihong Liu&lt;/a&gt;, please take a look at this and test it in your environment.&lt;/p&gt;</comment>
                            <comment id="14256700" author="hiveqa" created="Tue, 23 Dec 2014 07:28:53 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12688699/HIVE-8966.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12688699/HIVE-8966.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 6724 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_lvj_mapjoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2168/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2168/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2168/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2168/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2168/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2168/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12688699 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14264177" author="jihongliu" created="Mon, 5 Jan 2015 04:43:52 +0000"  >&lt;p&gt;Did a test. Generally the new version works as expected. But for the following case, the compaction will always fail:&lt;/p&gt;

&lt;p&gt;1. due to any reason, the writer exits without closing a batch. So the &quot;length&quot; file is still there. This could happen, for example the program is killed, hive/server restarts.&lt;br/&gt;
2. restart the program, so a new writer and a new batch is created and continute to write into the same partition. The data will go to a new delta.&lt;br/&gt;
3. Now we manually delete that &quot;length&quot; file in the previous delta. Then do compaction, but it fails. Even we totally exit the program so that no any open batch and no any &quot;length&quot; file, the compaction will never success for this partition. &lt;/p&gt;

&lt;p&gt;However the current hive 14.0 will work fine for the above case.&lt;/p&gt;</comment>
                            <comment id="14265257" author="alangates" created="Mon, 5 Jan 2015 22:41:03 +0000"  >&lt;p&gt;What error message does it give when it fails?  I would expect this to work.&lt;/p&gt;</comment>
                            <comment id="14266854" author="jihongliu" created="Tue, 6 Jan 2015 22:03:49 +0000"  >&lt;p&gt;The error occur when doing the mapreduce job. Following is log in hivemetastore.log&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:22,506 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: compactor.Worker (Worker.java:run(137)) - Starting MAJOR compaction for ds_infra.event_metrics.date=2014-12-24&lt;br/&gt;
2015-01-06 16:42:22,564 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: impl.TimelineClientImpl (TimelineClientImpl.java:serviceInit(285)) - Timeline service address: &lt;a href=&quot;http://sfdmgctmn003.gid.gap.com:8188/ws/v1/timeline/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://sfdmgctmn003.gid.gap.com:8188/ws/v1/timeline/&lt;/a&gt;&lt;br/&gt;
2015-01-06 16:42:22,622 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: impl.TimelineClientImpl (TimelineClientImpl.java:serviceInit(285)) - Timeline service address: &lt;a href=&quot;http://sfdmgctmn003.gid.gap.com:8188/ws/v1/timeline/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://sfdmgctmn003.gid.gap.com:8188/ws/v1/timeline/&lt;/a&gt;&lt;br/&gt;
2015-01-06 16:42:22,628 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.JobSubmitter (JobSubmitter.java:copyAndConfigureFiles(153)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.&lt;br/&gt;
2015-01-06 16:42:22,753 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: split.JobSplitWriter (JobSplitWriter.java:writeOldSplits(168)) - Max block location exceeded for split: CompactorInputSplit&lt;/p&gt;
{base: hdfs://sfdmgct/apps/hive/warehouse/ds_infra/event_metrics/date=2014-12-24/base_0035304, bucket: 1, length: 292280, deltas: [delta_0035311_0035313, delta_0035479_0035481, delta_0035491_0035493, delta_0035515_0035517, delta_0035533_0035535, delta_0035548_0035550, delta_0035563_0035565, delta_0035578_0035580, delta_0035593_0035595, delta_0035599_0035601, delta_0035656_0035658, delta_0035671_0035673, delta_0035686_0035688, delta_0035701_0035703, delta_0035716_0035718, delta_0035731_0035733, delta_0035746_0035748, delta_0035761_0035763, delta_0035776_0035778, delta_0035791_0035793, delta_0035806_0035808, delta_0035821_0035823, delta_0035830_0035832, delta_0035842_0035844, delta_0035854_0035856, delta_0035866_0035868, delta_0035878_0035880]}
&lt;p&gt; splitsize: 27 maxsize: 10&lt;br/&gt;
2015-01-06 16:42:22,753 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: split.JobSplitWriter (JobSplitWriter.java:writeOldSplits(168)) - Max block location exceeded for split: CompactorInputSplit&lt;/p&gt;
{base: null, bucket: 3, length: 199770, deltas: [delta_0035311_0035313, delta_0035479_0035481, delta_0035491_0035493, delta_0035515_0035517, delta_0035533_0035535, delta_0035548_0035550, delta_0035563_0035565, delta_0035578_0035580, delta_0035593_0035595, delta_0035599_0035601, delta_0035656_0035658, delta_0035671_0035673, delta_0035686_0035688, delta_0035701_0035703, delta_0035716_0035718, delta_0035731_0035733, delta_0035746_0035748, delta_0035761_0035763, delta_0035776_0035778, delta_0035791_0035793, delta_0035806_0035808, delta_0035821_0035823, delta_0035830_0035832, delta_0035842_0035844, delta_0035854_0035856, delta_0035866_0035868, delta_0035878_0035880]}
&lt;p&gt; splitsize: 21 maxsize: 10&lt;br/&gt;
2015-01-06 16:42:22,753 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: split.JobSplitWriter (JobSplitWriter.java:writeOldSplits(168)) - Max block location exceeded for split: CompactorInputSplit&lt;/p&gt;
{base: hdfs://sfdmgct/apps/hive/warehouse/ds_infra/event_metrics/date=2014-12-24/base_0035304, bucket: 0, length: 172391, deltas: [delta_0035311_0035313, delta_0035479_0035481, delta_0035491_0035493, delta_0035515_0035517, delta_0035533_0035535, delta_0035548_0035550, delta_0035563_0035565, delta_0035578_0035580, delta_0035593_0035595, delta_0035599_0035601, delta_0035656_0035658, delta_0035671_0035673, delta_0035686_0035688, delta_0035701_0035703, delta_0035716_0035718, delta_0035731_0035733, delta_0035746_0035748, delta_0035761_0035763, delta_0035776_0035778, delta_0035791_0035793, delta_0035806_0035808, delta_0035821_0035823, delta_0035830_0035832, delta_0035842_0035844, delta_0035854_0035856, delta_0035866_0035868, delta_0035878_0035880]}
&lt;p&gt; splitsize: 30 maxsize: 10&lt;br/&gt;
2015-01-06 16:42:22,777 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(494)) - number of splits:4&lt;br/&gt;
2015-01-06 16:42:22,793 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.JobSubmitter (JobSubmitter.java:printTokens(583)) - Submitting tokens for job: job_1419291043936_1639&lt;br/&gt;
2015-01-06 16:42:23,000 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: impl.YarnClientImpl (YarnClientImpl.java:submitApplication(251)) - Submitted application application_1419291043936_1639&lt;br/&gt;
2015-01-06 16:42:23,001 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:submit(1300)) - The url to track the job: &lt;a href=&quot;http://sfdmgctmn002.gid.gap.com:8088/proxy/application_1419291043936_1639/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://sfdmgctmn002.gid.gap.com:8088/proxy/application_1419291043936_1639/&lt;/a&gt;&lt;br/&gt;
2015-01-06 16:42:23,001 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:monitorAndPrintJob(1345)) - Running job: job_1419291043936_1639&lt;br/&gt;
2015-01-06 16:42:30,042 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:monitorAndPrintJob(1366)) - Job job_1419291043936_1639 running in uber mode : false&lt;br/&gt;
2015-01-06 16:42:30,043 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:monitorAndPrintJob(1373)) -  map 0% reduce 0%&lt;br/&gt;
2015-01-06 16:42:35,066 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:printTaskEvents(1452)) - Task Id : attempt_1419291043936_1639_m_000002_0, Status : FAILED&lt;br/&gt;
2015-01-06 16:42:37,078 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:monitorAndPrintJob(1373)) -  map 75% reduce 0%&lt;br/&gt;
2015-01-06 16:42:41,091 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:printTaskEvents(1452)) - Task Id : attempt_1419291043936_1639_m_000002_1, Status : FAILED&lt;br/&gt;
2015-01-06 16:42:45,105 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:printTaskEvents(1452)) - Task Id : attempt_1419291043936_1639_m_000002_2, Status : FAILED&lt;br/&gt;
2015-01-06 16:42:52,124 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:monitorAndPrintJob(1373)) -  map 100% reduce 0%&lt;br/&gt;
2015-01-06 16:42:52,130 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:monitorAndPrintJob(1386)) - Job job_1419291043936_1639 failed with state FAILED due to: Task failed task_1419291043936_1639_m_000002&lt;br/&gt;
Job failed as tasks failed. failedMaps:1 failedReduces:0&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:52,149 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:monitorAndPrintJob(1391)) - Counters: 32&lt;br/&gt;
        File System Counters&lt;br/&gt;
                FILE: Number of bytes read=0&lt;br/&gt;
                FILE: Number of bytes written=668781&lt;br/&gt;
                FILE: Number of read operations=0&lt;br/&gt;
                FILE: Number of large read operations=0&lt;br/&gt;
                FILE: Number of write operations=0&lt;br/&gt;
                HDFS: Number of bytes read=840325&lt;br/&gt;
                HDFS: Number of bytes written=405818&lt;br/&gt;
                HDFS: Number of read operations=243&lt;br/&gt;
                HDFS: Number of large read operations=0&lt;br/&gt;
                HDFS: Number of write operations=3&lt;br/&gt;
        Job Counters&lt;br/&gt;
                Failed map tasks=4&lt;br/&gt;
                Launched map tasks=7&lt;br/&gt;
                Other local map tasks=3&lt;br/&gt;
                Data-local map tasks=4&lt;br/&gt;
                Total time spent by all maps in occupied slots (ms)=32359&lt;br/&gt;
                Total time spent by all reduces in occupied slots (ms)=0&lt;br/&gt;
                Total time spent by all map tasks (ms)=32359&lt;br/&gt;
                Total vcore-seconds taken by all map tasks=32359&lt;br/&gt;
                Total megabyte-seconds taken by all map tasks=463898624&lt;br/&gt;
        Map-Reduce Framework&lt;br/&gt;
                Map input records=3&lt;br/&gt;
                Map output records=0&lt;br/&gt;
                Input split bytes=10663&lt;br/&gt;
                Spilled Records=0&lt;br/&gt;
                Failed Shuffles=0&lt;br/&gt;
                Merged Map outputs=0&lt;br/&gt;
                GC time elapsed (ms)=153&lt;br/&gt;
                CPU time spent (ms)=7680&lt;br/&gt;
                Physical memory (bytes) snapshot=1065402368&lt;br/&gt;
                Virtual memory (bytes) snapshot=39759937536&lt;br/&gt;
                Total committed heap usage (bytes)=6714032128&lt;br/&gt;
        File Input Format Counters&lt;br/&gt;
                Bytes Read=0&lt;br/&gt;
        File Output Format Counters&lt;br/&gt;
                Bytes Written=0&lt;br/&gt;
2015-01-06 16:42:52,150 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: compactor.Worker (Worker.java:run(159)) - Caught exception while trying to compact ds_infra.event_metrics.date=2014-12-24.  Marking clean to avoid repeated failures, java.io.IOException: Job failed!&lt;br/&gt;
        at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:836)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.run(CompactorMR.java:184)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.txn.compactor.Worker.run(Worker.java:145)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:52,150 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctmn003.gid.gap.com-32&amp;#93;&lt;/span&gt;: txn.CompactionTxnHandler (CompactionTxnHandler.java:markCleaned(327)) - Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!&lt;/p&gt;



&lt;p&gt;--------------------------------------------------------------------------------------------------------------------------------&lt;br/&gt;
following is mapreduce job log. Got the log from uri mentioned in the above log:  (&lt;a href=&quot;http://sfdmgctmn002.gid.gap.com:8088/proxy/application_1419291043936_1639/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://sfdmgctmn002.gid.gap.com:8088/proxy/application_1419291043936_1639/&lt;/a&gt;)&lt;/p&gt;


&lt;p&gt;2015-01-06 16:42:25,991 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Created MRAppMaster for application appattempt_1419291043936_1639_000001&lt;br/&gt;
2015-01-06 16:42:26,304 WARN &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable&lt;br/&gt;
2015-01-06 16:42:26,314 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Executing with tokens:&lt;br/&gt;
2015-01-06 16:42:26,314 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id &lt;/p&gt;
{ id: 1639 cluster_timestamp: 1419291043936 }
&lt;p&gt; attemptId: 1 } keyId: -950898635)&lt;br/&gt;
2015-01-06 16:42:26,842 WARN &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.&lt;br/&gt;
2015-01-06 16:42:26,919 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorOutputCommitter&lt;br/&gt;
2015-01-06 16:42:26,921 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorOutputCommitter&lt;br/&gt;
2015-01-06 16:42:26,951 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler&lt;br/&gt;
2015-01-06 16:42:26,951 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher&lt;br/&gt;
2015-01-06 16:42:26,952 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher&lt;br/&gt;
2015-01-06 16:42:26,952 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher&lt;br/&gt;
2015-01-06 16:42:26,952 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler&lt;br/&gt;
2015-01-06 16:42:26,956 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.speculate.Speculator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$SpeculatorEventDispatcher&lt;br/&gt;
2015-01-06 16:42:26,956 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter&lt;br/&gt;
2015-01-06 16:42:26,957 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerLauncherRouter&lt;br/&gt;
2015-01-06 16:42:26,975 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring&lt;br/&gt;
2015-01-06 16:42:26,987 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring&lt;br/&gt;
2015-01-06 16:42:26,999 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring&lt;br/&gt;
2015-01-06 16:42:27,023 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Emitting job history data to the timeline server is not enabled&lt;br/&gt;
2015-01-06 16:42:27,050 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobFinishEvent$Type for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler&lt;br/&gt;
2015-01-06 16:42:27,191 WARN &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.metrics2.impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-mrappmaster.properties,hadoop-metrics2.properties&lt;br/&gt;
2015-01-06 16:42:27,232 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).&lt;br/&gt;
2015-01-06 16:42:27,232 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MRAppMaster metrics system started&lt;br/&gt;
2015-01-06 16:42:27,239 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Adding job token for job_1419291043936_1639 to jobTokenSecretManager&lt;br/&gt;
2015-01-06 16:42:27,327 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Not uberizing job_1419291043936_1639 because: not enabled;&lt;br/&gt;
2015-01-06 16:42:27,340 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Input size for job job_1419291043936_1639 = 845156. Number of splits = 4&lt;br/&gt;
2015-01-06 16:42:27,341 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Number of reduces for job job_1419291043936_1639 = 0&lt;br/&gt;
2015-01-06 16:42:27,341 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1419291043936_1639Job Transitioned from NEW to INITED&lt;br/&gt;
2015-01-06 16:42:27,341 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: MRAppMaster launching normal, non-uberized, multi-container job job_1419291043936_1639.&lt;br/&gt;
2015-01-06 16:42:27,359 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue&lt;br/&gt;
2015-01-06 16:42:27,366 INFO &lt;a href=&quot;#1 for port 57524&quot;&gt;Socket Reader #1 for port 57524&lt;/a&gt; org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 57524&lt;br/&gt;
2015-01-06 16:42:27,379 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server&lt;br/&gt;
2015-01-06 16:42:27,380 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server Responder&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.Server: IPC Server Responder: starting&lt;br/&gt;
2015-01-06 16:42:27,381 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server listener on 57524&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.Server: IPC Server listener on 57524: starting&lt;br/&gt;
2015-01-06 16:42:27,381 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.client.MRClientService: Instantiated MRClientService at sfdmgctsn004.gid.gap.com/10.9.21.134:57524&lt;br/&gt;
2015-01-06 16:42:27,429 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog&lt;br/&gt;
2015-01-06 16:42:27,431 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.mapreduce is not defined&lt;br/&gt;
2015-01-06 16:42:27,439 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.http.HttpServer2: Added global filter &apos;safety&apos; (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)&lt;br/&gt;
2015-01-06 16:42:27,472 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce&lt;br/&gt;
2015-01-06 16:42:27,472 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static&lt;br/&gt;
2015-01-06 16:42:27,475 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.http.HttpServer2: adding path spec: /mapreduce/*&lt;br/&gt;
2015-01-06 16:42:27,475 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*&lt;br/&gt;
2015-01-06 16:42:27,482 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.http.HttpServer2: Jetty bound to port 45674&lt;br/&gt;
2015-01-06 16:42:27,482 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.mortbay.log: jetty-6.1.26.hwx&lt;br/&gt;
2015-01-06 16:42:27,505 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.mortbay.log: Extract jar:&lt;a href=&quot;file:/data/sfdmgct05/hadoop/yarn/local/filecache/12/mapreduce.tar.gz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.2.2.0.0-2041.jar!/webapps/mapreduce&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/data/sfdmgct05/hadoop/yarn/local/filecache/12/mapreduce.tar.gz/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.2.2.0.0-2041.jar!/webapps/mapreduce&lt;/a&gt; to /tmp/Jetty_0_0_0_0_45674_mapreduce____.ycambd/webapp&lt;br/&gt;
2015-01-06 16:42:27,805 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:45674&lt;br/&gt;
2015-01-06 16:42:27,806 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.webapp.WebApps: Web app /mapreduce started at 45674&lt;br/&gt;
2015-01-06 16:42:28,026 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules&lt;br/&gt;
2015-01-06 16:42:28,029 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: JOB_CREATE job_1419291043936_1639&lt;br/&gt;
2015-01-06 16:42:28,030 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue&lt;br/&gt;
2015-01-06 16:42:28,030 INFO &lt;a href=&quot;#1 for port 33406&quot;&gt;Socket Reader #1 for port 33406&lt;/a&gt; org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 33406&lt;br/&gt;
2015-01-06 16:42:28,034 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server Responder&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.Server: IPC Server Responder: starting&lt;br/&gt;
2015-01-06 16:42:28,034 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server listener on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.Server: IPC Server listener on 33406: starting&lt;br/&gt;
2015-01-06 16:42:28,074 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: nodeBlacklistingEnabled:true&lt;br/&gt;
2015-01-06 16:42:28,075 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: maxTaskFailuresPerNode is 3&lt;br/&gt;
2015-01-06 16:42:28,075 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: blacklistDisablePercent is 33&lt;br/&gt;
2015-01-06 16:42:28,158 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: maxContainerCapability: &amp;lt;memory:186368, vCores:32&amp;gt;&lt;br/&gt;
2015-01-06 16:42:28,158 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: queue: default&lt;br/&gt;
2015-01-06 16:42:28,160 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Upper limit on the thread pool size is 500&lt;br/&gt;
2015-01-06 16:42:28,161 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0&lt;br/&gt;
2015-01-06 16:42:28,165 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1419291043936_1639Job Transitioned from INITED to SETUP&lt;br/&gt;
2015-01-06 16:42:28,167 INFO &lt;a href=&quot;#0&quot;&gt;CommitterEvent Processor #0&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_SETUP&lt;br/&gt;
2015-01-06 16:42:28,168 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1419291043936_1639Job Transitioned from SETUP to RUNNING&lt;br/&gt;
2015-01-06 16:42:28,182 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,186 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn003.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,188 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn001.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,191 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn005.gid.gap.com to /default/rack_06&lt;br/&gt;
2015-01-06 16:42:28,194 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn002.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,198 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000000 Task Transitioned from NEW to SCHEDULED&lt;br/&gt;
2015-01-06 16:42:28,198 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,198 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn003.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,198 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn001.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,198 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn005.gid.gap.com to /default/rack_06&lt;br/&gt;
2015-01-06 16:42:28,198 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn002.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,198 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000001 Task Transitioned from NEW to SCHEDULED&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn003.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn001.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn005.gid.gap.com to /default/rack_06&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn002.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000002 Task Transitioned from NEW to SCHEDULED&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn001.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn005.gid.gap.com to /default/rack_06&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn002.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:28,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000003 Task Transitioned from NEW to SCHEDULED&lt;br/&gt;
2015-01-06 16:42:28,200 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000000_0 TaskAttempt Transitioned from NEW to UNASSIGNED&lt;br/&gt;
2015-01-06 16:42:28,200 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000001_0 TaskAttempt Transitioned from NEW to UNASSIGNED&lt;br/&gt;
2015-01-06 16:42:28,200 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_0 TaskAttempt Transitioned from NEW to UNASSIGNED&lt;br/&gt;
2015-01-06 16:42:28,200 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000003_0 TaskAttempt Transitioned from NEW to UNASSIGNED&lt;br/&gt;
2015-01-06 16:42:28,201 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-50&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: mapResourceRequest:&amp;lt;memory:14336, vCores:1&amp;gt;&lt;br/&gt;
2015-01-06 16:42:28,226 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;eventHandlingThread&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Event Writer setup for JobId: job_1419291043936_1639, File: hdfs://sfdmgct:8020/user/hive/.staging/job_1419291043936_1639/job_1419291043936_1639_1.jhist&lt;br/&gt;
2015-01-06 16:42:29,160 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:4 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:29,181 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1419291043936_1639: ask=8 release= 0 newContainers=0 finishedContainers=0 resourcelimit=&amp;lt;memory:458752, vCores:79&amp;gt; knownNMs=5&lt;br/&gt;
2015-01-06 16:42:30,189 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 4&lt;br/&gt;
2015-01-06 16:42:30,190 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1419291043936_1639_01_000002 to attempt_1419291043936_1639_m_000000_0&lt;br/&gt;
2015-01-06 16:42:30,191 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1419291043936_1639_01_000003 to attempt_1419291043936_1639_m_000001_0&lt;br/&gt;
2015-01-06 16:42:30,191 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1419291043936_1639_01_000004 to attempt_1419291043936_1639_m_000002_0&lt;br/&gt;
2015-01-06 16:42:30,191 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1419291043936_1639_01_000005 to attempt_1419291043936_1639_m_000003_0&lt;br/&gt;
2015-01-06 16:42:30,191 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:4 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:4 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:30,217 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:30,227 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-jar file on the remote FS is hdfs://sfdmgct/user/hive/.staging/job_1419291043936_1639/job.jar&lt;br/&gt;
2015-01-06 16:42:30,229 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-conf file on the remote FS is /user/hive/.staging/job_1419291043936_1639/job.xml&lt;br/&gt;
2015-01-06 16:42:30,231 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Adding #0 tokens and #1 secret keys for NM use for launching container&lt;br/&gt;
2015-01-06 16:42:30,231 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Size of containertokens_dob is 1&lt;br/&gt;
2015-01-06 16:42:30,231 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Putting shuffle token in serviceData&lt;br/&gt;
2015-01-06 16:42:30,247 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000000_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED&lt;br/&gt;
2015-01-06 16:42:30,248 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:30,248 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000001_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED&lt;br/&gt;
2015-01-06 16:42:30,249 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:30,249 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED&lt;br/&gt;
2015-01-06 16:42:30,249 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:30,250 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000003_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED&lt;br/&gt;
2015-01-06 16:42:30,251 INFO &lt;a href=&quot;#0&quot;&gt;ContainerLauncher #0&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1419291043936_1639_01_000002 taskAttempt attempt_1419291043936_1639_m_000000_0&lt;br/&gt;
2015-01-06 16:42:30,251 INFO &lt;a href=&quot;#1&quot;&gt;ContainerLauncher #1&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1419291043936_1639_01_000003 taskAttempt attempt_1419291043936_1639_m_000001_0&lt;br/&gt;
2015-01-06 16:42:30,251 INFO &lt;a href=&quot;#2&quot;&gt;ContainerLauncher #2&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1419291043936_1639_01_000004 taskAttempt attempt_1419291043936_1639_m_000002_0&lt;br/&gt;
2015-01-06 16:42:30,251 INFO &lt;a href=&quot;#3&quot;&gt;ContainerLauncher #3&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1419291043936_1639_01_000005 taskAttempt attempt_1419291043936_1639_m_000003_0&lt;br/&gt;
2015-01-06 16:42:30,252 INFO &lt;a href=&quot;#2&quot;&gt;ContainerLauncher #2&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1419291043936_1639_m_000002_0&lt;br/&gt;
2015-01-06 16:42:30,252 INFO &lt;a href=&quot;#1&quot;&gt;ContainerLauncher #1&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1419291043936_1639_m_000001_0&lt;br/&gt;
2015-01-06 16:42:30,252 INFO &lt;a href=&quot;#3&quot;&gt;ContainerLauncher #3&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1419291043936_1639_m_000003_0&lt;br/&gt;
2015-01-06 16:42:30,252 INFO &lt;a href=&quot;#0&quot;&gt;ContainerLauncher #0&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1419291043936_1639_m_000000_0&lt;br/&gt;
2015-01-06 16:42:30,253 INFO &lt;a href=&quot;#2&quot;&gt;ContainerLauncher #2&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn004.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:30,266 INFO &lt;a href=&quot;#0&quot;&gt;ContainerLauncher #0&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn004.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:30,267 INFO &lt;a href=&quot;#3&quot;&gt;ContainerLauncher #3&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn004.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:30,267 INFO &lt;a href=&quot;#1&quot;&gt;ContainerLauncher #1&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn004.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:30,294 INFO &lt;a href=&quot;#2&quot;&gt;ContainerLauncher #2&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1419291043936_1639_m_000002_0 : 13562&lt;br/&gt;
2015-01-06 16:42:30,294 INFO &lt;a href=&quot;#3&quot;&gt;ContainerLauncher #3&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1419291043936_1639_m_000003_0 : 13562&lt;br/&gt;
2015-01-06 16:42:30,294 INFO &lt;a href=&quot;#0&quot;&gt;ContainerLauncher #0&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1419291043936_1639_m_000000_0 : 13562&lt;br/&gt;
2015-01-06 16:42:30,294 INFO &lt;a href=&quot;#1&quot;&gt;ContainerLauncher #1&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1419291043936_1639_m_000001_0 : 13562&lt;br/&gt;
2015-01-06 16:42:30,295 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: &lt;span class=&quot;error&quot;&gt;&amp;#91;attempt_1419291043936_1639_m_000000_0&amp;#93;&lt;/span&gt; using containerId: [container_1419291043936_1639_01_000002 on NM: &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctsn004.gid.gap.com:45454&amp;#93;&lt;/span&gt;&lt;br/&gt;
2015-01-06 16:42:30,297 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000000_0 TaskAttempt Transitioned from ASSIGNED to RUNNING&lt;br/&gt;
2015-01-06 16:42:30,297 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: &lt;span class=&quot;error&quot;&gt;&amp;#91;attempt_1419291043936_1639_m_000003_0&amp;#93;&lt;/span&gt; using containerId: [container_1419291043936_1639_01_000005 on NM: &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctsn004.gid.gap.com:45454&amp;#93;&lt;/span&gt;&lt;br/&gt;
2015-01-06 16:42:30,297 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000003_0 TaskAttempt Transitioned from ASSIGNED to RUNNING&lt;br/&gt;
2015-01-06 16:42:30,297 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: &lt;span class=&quot;error&quot;&gt;&amp;#91;attempt_1419291043936_1639_m_000002_0&amp;#93;&lt;/span&gt; using containerId: [container_1419291043936_1639_01_000004 on NM: &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctsn004.gid.gap.com:45454&amp;#93;&lt;/span&gt;&lt;br/&gt;
2015-01-06 16:42:30,298 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_0 TaskAttempt Transitioned from ASSIGNED to RUNNING&lt;br/&gt;
2015-01-06 16:42:30,298 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: &lt;span class=&quot;error&quot;&gt;&amp;#91;attempt_1419291043936_1639_m_000001_0&amp;#93;&lt;/span&gt; using containerId: [container_1419291043936_1639_01_000003 on NM: &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctsn004.gid.gap.com:45454&amp;#93;&lt;/span&gt;&lt;br/&gt;
2015-01-06 16:42:30,298 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000001_0 TaskAttempt Transitioned from ASSIGNED to RUNNING&lt;br/&gt;
2015-01-06 16:42:30,298 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000000 Task Transitioned from SCHEDULED to RUNNING&lt;br/&gt;
2015-01-06 16:42:30,298 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000003 Task Transitioned from SCHEDULED to RUNNING&lt;br/&gt;
2015-01-06 16:42:30,299 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000002 Task Transitioned from SCHEDULED to RUNNING&lt;br/&gt;
2015-01-06 16:42:30,299 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000001 Task Transitioned from SCHEDULED to RUNNING&lt;br/&gt;
2015-01-06 16:42:31,194 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1419291043936_1639: ask=8 release= 0 newContainers=0 finishedContainers=0 resourcelimit=&amp;lt;memory:401408, vCores:75&amp;gt; knownNMs=5&lt;br/&gt;
2015-01-06 16:42:33,555 INFO &lt;a href=&quot;#1 for port 33406&quot;&gt;Socket Reader #1 for port 33406&lt;/a&gt; SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1419291043936_1639 (auth:SIMPLE)&lt;br/&gt;
2015-01-06 16:42:33,572 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 0 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1419291043936_1639_m_000002 asked for a task&lt;br/&gt;
2015-01-06 16:42:33,572 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 0 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1419291043936_1639_m_000002 given task: attempt_1419291043936_1639_m_000000_0&lt;br/&gt;
2015-01-06 16:42:33,587 INFO &lt;a href=&quot;#1 for port 33406&quot;&gt;Socket Reader #1 for port 33406&lt;/a&gt; SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1419291043936_1639 (auth:SIMPLE)&lt;br/&gt;
2015-01-06 16:42:33,596 INFO &lt;a href=&quot;#1 for port 33406&quot;&gt;Socket Reader #1 for port 33406&lt;/a&gt; SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1419291043936_1639 (auth:SIMPLE)&lt;br/&gt;
2015-01-06 16:42:33,601 INFO &lt;a href=&quot;#1 for port 33406&quot;&gt;Socket Reader #1 for port 33406&lt;/a&gt; SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1419291043936_1639 (auth:SIMPLE)&lt;br/&gt;
2015-01-06 16:42:33,602 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 1 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1419291043936_1639_m_000005 asked for a task&lt;br/&gt;
2015-01-06 16:42:33,602 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 1 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1419291043936_1639_m_000005 given task: attempt_1419291043936_1639_m_000003_0&lt;br/&gt;
2015-01-06 16:42:33,607 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 2 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1419291043936_1639_m_000003 asked for a task&lt;br/&gt;
2015-01-06 16:42:33,607 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 2 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1419291043936_1639_m_000003 given task: attempt_1419291043936_1639_m_000001_0&lt;br/&gt;
2015-01-06 16:42:33,612 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 3 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1419291043936_1639_m_000004 asked for a task&lt;br/&gt;
2015-01-06 16:42:33,612 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 3 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1419291043936_1639_m_000004 given task: attempt_1419291043936_1639_m_000002_0&lt;br/&gt;
2015-01-06 16:42:35,010 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 4 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000002_0 is : 0.0&lt;br/&gt;
2015-01-06 16:42:35,014 FATAL &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 5 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1419291043936_1639_m_000002_0 - exited : java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:35,014 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 5 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_0: Error: java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:35,016 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_0: Error: java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:35,016 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP&lt;br/&gt;
2015-01-06 16:42:35,017 INFO &lt;a href=&quot;#4&quot;&gt;ContainerLauncher #4&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1419291043936_1639_01_000004 taskAttempt attempt_1419291043936_1639_m_000002_0&lt;br/&gt;
2015-01-06 16:42:35,017 INFO &lt;a href=&quot;#4&quot;&gt;ContainerLauncher #4&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1419291043936_1639_m_000002_0&lt;br/&gt;
2015-01-06 16:42:35,017 INFO &lt;a href=&quot;#4&quot;&gt;ContainerLauncher #4&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn004.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:35,029 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP&lt;br/&gt;
2015-01-06 16:42:35,030 INFO &lt;a href=&quot;#1&quot;&gt;CommitterEvent Processor #1&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT&lt;br/&gt;
2015-01-06 16:42:35,031 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED&lt;br/&gt;
2015-01-06 16:42:35,035 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:35,035 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn003.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:35,035 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn001.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:35,035 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn005.gid.gap.com to /default/rack_06&lt;br/&gt;
2015-01-06 16:42:35,035 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn002.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:35,035 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-50&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 1 failures on node sfdmgctsn004.gid.gap.com&lt;br/&gt;
2015-01-06 16:42:35,036 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_1 TaskAttempt Transitioned from NEW to UNASSIGNED&lt;br/&gt;
2015-01-06 16:42:35,037 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-50&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1419291043936_1639_m_000002_1 to list of failed maps&lt;br/&gt;
2015-01-06 16:42:35,198 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:1 ScheduledReds:0 AssignedMaps:4 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:4 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:35,199 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1419291043936_1639: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=&amp;lt;memory:401408, vCores:75&amp;gt; knownNMs=5&lt;br/&gt;
2015-01-06 16:42:35,697 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 4 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000001_0 is : 0.0&lt;br/&gt;
2015-01-06 16:42:35,734 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 5 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000003_0 is : 0.0&lt;br/&gt;
2015-01-06 16:42:35,833 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 6 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000000_0 is : 0.0&lt;br/&gt;
2015-01-06 16:42:35,896 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 7 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000001_0 is : 1.0&lt;br/&gt;
2015-01-06 16:42:35,901 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 8 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1419291043936_1639_m_000001_0&lt;br/&gt;
2015-01-06 16:42:35,902 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000001_0 TaskAttempt Transitioned from RUNNING to SUCCESS_CONTAINER_CLEANUP&lt;br/&gt;
2015-01-06 16:42:35,903 INFO &lt;a href=&quot;#5&quot;&gt;ContainerLauncher #5&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1419291043936_1639_01_000003 taskAttempt attempt_1419291043936_1639_m_000001_0&lt;br/&gt;
2015-01-06 16:42:35,903 INFO &lt;a href=&quot;#5&quot;&gt;ContainerLauncher #5&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1419291043936_1639_m_000001_0&lt;br/&gt;
2015-01-06 16:42:35,903 INFO &lt;a href=&quot;#5&quot;&gt;ContainerLauncher #5&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn004.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:35,911 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000001_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED&lt;br/&gt;
2015-01-06 16:42:35,912 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1419291043936_1639_m_000001_0&lt;br/&gt;
2015-01-06 16:42:35,913 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000001 Task Transitioned from RUNNING to SUCCEEDED&lt;br/&gt;
2015-01-06 16:42:35,913 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 1&lt;br/&gt;
2015-01-06 16:42:35,925 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 9 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000003_0 is : 1.0&lt;br/&gt;
2015-01-06 16:42:35,927 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 10 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1419291043936_1639_m_000003_0&lt;br/&gt;
2015-01-06 16:42:35,928 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000003_0 TaskAttempt Transitioned from RUNNING to SUCCESS_CONTAINER_CLEANUP&lt;br/&gt;
2015-01-06 16:42:35,929 INFO &lt;a href=&quot;#6&quot;&gt;ContainerLauncher #6&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1419291043936_1639_01_000005 taskAttempt attempt_1419291043936_1639_m_000003_0&lt;br/&gt;
2015-01-06 16:42:35,929 INFO &lt;a href=&quot;#6&quot;&gt;ContainerLauncher #6&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1419291043936_1639_m_000003_0&lt;br/&gt;
2015-01-06 16:42:35,929 INFO &lt;a href=&quot;#6&quot;&gt;ContainerLauncher #6&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn004.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:35,936 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000003_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED&lt;br/&gt;
2015-01-06 16:42:35,936 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1419291043936_1639_m_000003_0&lt;br/&gt;
2015-01-06 16:42:35,936 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000003 Task Transitioned from RUNNING to SUCCEEDED&lt;br/&gt;
2015-01-06 16:42:35,937 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 2&lt;br/&gt;
2015-01-06 16:42:36,035 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 11 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000000_0 is : 1.0&lt;br/&gt;
2015-01-06 16:42:36,037 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 12 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1419291043936_1639_m_000000_0&lt;br/&gt;
2015-01-06 16:42:36,038 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000000_0 TaskAttempt Transitioned from RUNNING to SUCCESS_CONTAINER_CLEANUP&lt;br/&gt;
2015-01-06 16:42:36,039 INFO &lt;a href=&quot;#7&quot;&gt;ContainerLauncher #7&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1419291043936_1639_01_000002 taskAttempt attempt_1419291043936_1639_m_000000_0&lt;br/&gt;
2015-01-06 16:42:36,039 INFO &lt;a href=&quot;#7&quot;&gt;ContainerLauncher #7&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1419291043936_1639_m_000000_0&lt;br/&gt;
2015-01-06 16:42:36,039 INFO &lt;a href=&quot;#7&quot;&gt;ContainerLauncher #7&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn004.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:36,045 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000000_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED&lt;br/&gt;
2015-01-06 16:42:36,045 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1419291043936_1639_m_000000_0&lt;br/&gt;
2015-01-06 16:42:36,045 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000000 Task Transitioned from RUNNING to SUCCEEDED&lt;br/&gt;
2015-01-06 16:42:36,046 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 3&lt;br/&gt;
2015-01-06 16:42:36,200 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:1 ScheduledReds:0 AssignedMaps:4 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:4 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:36,207 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1419291043936_1639_01_000004&lt;br/&gt;
2015-01-06 16:42:36,207 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 1&lt;br/&gt;
2015-01-06 16:42:36,208 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_0: Container killed by the ApplicationMaster.&lt;br/&gt;
Container killed on request. Exit code is 143&lt;br/&gt;
Container exited with a non-zero exit code 143&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:36,208 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1419291043936_1639_01_000006, NodeId: sfdmgctsn003.gid.gap.com:45454, NodeHttpAddress: sfdmgctsn003.gid.gap.com:8042, Resource: &amp;lt;memory:14336, vCores:1&amp;gt;, Priority: 5, Token: Token &lt;/p&gt;
{ kind: ContainerToken, service: 10.9.21.133:45454 }
&lt;p&gt;, ] to fast fail map&lt;br/&gt;
2015-01-06 16:42:36,208 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps&lt;br/&gt;
2015-01-06 16:42:36,208 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1419291043936_1639_01_000006 to attempt_1419291043936_1639_m_000002_1&lt;br/&gt;
2015-01-06 16:42:36,208 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:4 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:5 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:36,209 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn003.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:36,209 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED&lt;br/&gt;
2015-01-06 16:42:36,210 INFO &lt;a href=&quot;#8&quot;&gt;ContainerLauncher #8&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1419291043936_1639_01_000006 taskAttempt attempt_1419291043936_1639_m_000002_1&lt;br/&gt;
2015-01-06 16:42:36,210 INFO &lt;a href=&quot;#8&quot;&gt;ContainerLauncher #8&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1419291043936_1639_m_000002_1&lt;br/&gt;
2015-01-06 16:42:36,210 INFO &lt;a href=&quot;#8&quot;&gt;ContainerLauncher #8&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn003.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:36,218 INFO &lt;a href=&quot;#8&quot;&gt;ContainerLauncher #8&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1419291043936_1639_m_000002_1 : 13562&lt;br/&gt;
2015-01-06 16:42:36,219 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: &lt;span class=&quot;error&quot;&gt;&amp;#91;attempt_1419291043936_1639_m_000002_1&amp;#93;&lt;/span&gt; using containerId: [container_1419291043936_1639_01_000006 on NM: &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctsn003.gid.gap.com:45454&amp;#93;&lt;/span&gt;&lt;br/&gt;
2015-01-06 16:42:36,219 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_1 TaskAttempt Transitioned from ASSIGNED to RUNNING&lt;br/&gt;
2015-01-06 16:42:37,210 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1419291043936_1639: ask=1 release= 0 newContainers=0 finishedContainers=3 resourcelimit=&amp;lt;memory:444416, vCores:78&amp;gt; knownNMs=5&lt;br/&gt;
2015-01-06 16:42:37,210 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1419291043936_1639_01_000002&lt;br/&gt;
2015-01-06 16:42:37,210 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1419291043936_1639_01_000003&lt;br/&gt;
2015-01-06 16:42:37,210 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1419291043936_1639_01_000005&lt;br/&gt;
2015-01-06 16:42:37,210 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000000_0: Container killed by the ApplicationMaster.&lt;br/&gt;
Container killed on request. Exit code is 143&lt;br/&gt;
Container exited with a non-zero exit code 143&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:37,210 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:5 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:37,210 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000001_0: Container killed by the ApplicationMaster.&lt;br/&gt;
Container killed on request. Exit code is 143&lt;br/&gt;
Container exited with a non-zero exit code 143&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:37,211 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000003_0: Container killed by the ApplicationMaster.&lt;br/&gt;
Container killed on request. Exit code is 143&lt;br/&gt;
Container exited with a non-zero exit code 143&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:39,096 INFO &lt;a href=&quot;#1 for port 33406&quot;&gt;Socket Reader #1 for port 33406&lt;/a&gt; SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1419291043936_1639 (auth:SIMPLE)&lt;br/&gt;
2015-01-06 16:42:39,106 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 0 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1419291043936_1639_m_000006 asked for a task&lt;br/&gt;
2015-01-06 16:42:39,106 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 0 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1419291043936_1639_m_000006 given task: attempt_1419291043936_1639_m_000002_1&lt;br/&gt;
2015-01-06 16:42:40,344 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 1 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000002_1 is : 0.0&lt;br/&gt;
2015-01-06 16:42:40,345 FATAL &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 2 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1419291043936_1639_m_000002_1 - exited : java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:40,345 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 2 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_1: Error: java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:40,346 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_1: Error: java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:40,346 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP&lt;br/&gt;
2015-01-06 16:42:40,347 INFO &lt;a href=&quot;#9&quot;&gt;ContainerLauncher #9&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1419291043936_1639_01_000006 taskAttempt attempt_1419291043936_1639_m_000002_1&lt;br/&gt;
2015-01-06 16:42:40,347 INFO &lt;a href=&quot;#9&quot;&gt;ContainerLauncher #9&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1419291043936_1639_m_000002_1&lt;br/&gt;
2015-01-06 16:42:40,347 INFO &lt;a href=&quot;#9&quot;&gt;ContainerLauncher #9&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn003.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:40,353 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP&lt;br/&gt;
2015-01-06 16:42:40,354 INFO &lt;a href=&quot;#2&quot;&gt;CommitterEvent Processor #2&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT&lt;br/&gt;
2015-01-06 16:42:40,354 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED&lt;br/&gt;
2015-01-06 16:42:40,354 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:40,354 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn003.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:40,354 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn001.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:40,355 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn005.gid.gap.com to /default/rack_06&lt;br/&gt;
2015-01-06 16:42:40,355 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn002.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:40,355 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-50&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 1 failures on node sfdmgctsn003.gid.gap.com&lt;br/&gt;
2015-01-06 16:42:40,355 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_2 TaskAttempt Transitioned from NEW to UNASSIGNED&lt;br/&gt;
2015-01-06 16:42:40,355 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-50&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1419291043936_1639_m_000002_2 to list of failed maps&lt;br/&gt;
2015-01-06 16:42:41,215 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:1 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:5 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:41,216 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1419291043936_1639: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=&amp;lt;memory:444416, vCores:78&amp;gt; knownNMs=5&lt;br/&gt;
2015-01-06 16:42:42,218 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1419291043936_1639_01_000006&lt;br/&gt;
2015-01-06 16:42:42,218 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 1&lt;br/&gt;
2015-01-06 16:42:42,218 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_1: Container killed by the ApplicationMaster.&lt;br/&gt;
Container killed on request. Exit code is 143&lt;br/&gt;
Container exited with a non-zero exit code 143&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:42,218 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1419291043936_1639_01_000007, NodeId: sfdmgctsn003.gid.gap.com:45454, NodeHttpAddress: sfdmgctsn003.gid.gap.com:8042, Resource: &amp;lt;memory:14336, vCores:1&amp;gt;, Priority: 5, Token: Token &lt;/p&gt;
{ kind: ContainerToken, service: 10.9.21.133:45454 }
&lt;p&gt;, ] to fast fail map&lt;br/&gt;
2015-01-06 16:42:42,218 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps&lt;br/&gt;
2015-01-06 16:42:42,218 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1419291043936_1639_01_000007 to attempt_1419291043936_1639_m_000002_2&lt;br/&gt;
2015-01-06 16:42:42,218 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:6 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:42,218 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn003.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:42,219 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED&lt;br/&gt;
2015-01-06 16:42:42,219 INFO &lt;a href=&quot;#3&quot;&gt;ContainerLauncher #3&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1419291043936_1639_01_000007 taskAttempt attempt_1419291043936_1639_m_000002_2&lt;br/&gt;
2015-01-06 16:42:42,219 INFO &lt;a href=&quot;#3&quot;&gt;ContainerLauncher #3&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1419291043936_1639_m_000002_2&lt;br/&gt;
2015-01-06 16:42:42,219 INFO &lt;a href=&quot;#3&quot;&gt;ContainerLauncher #3&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn003.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:42,226 INFO &lt;a href=&quot;#3&quot;&gt;ContainerLauncher #3&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1419291043936_1639_m_000002_2 : 13562&lt;br/&gt;
2015-01-06 16:42:42,226 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: &lt;span class=&quot;error&quot;&gt;&amp;#91;attempt_1419291043936_1639_m_000002_2&amp;#93;&lt;/span&gt; using containerId: [container_1419291043936_1639_01_000007 on NM: &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctsn003.gid.gap.com:45454&amp;#93;&lt;/span&gt;&lt;br/&gt;
2015-01-06 16:42:42,227 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_2 TaskAttempt Transitioned from ASSIGNED to RUNNING&lt;br/&gt;
2015-01-06 16:42:43,220 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1419291043936_1639: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=&amp;lt;memory:444416, vCores:78&amp;gt; knownNMs=5&lt;br/&gt;
2015-01-06 16:42:43,270 INFO &lt;a href=&quot;#1 for port 33406&quot;&gt;Socket Reader #1 for port 33406&lt;/a&gt; SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1419291043936_1639 (auth:SIMPLE)&lt;br/&gt;
2015-01-06 16:42:43,279 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 1 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1419291043936_1639_m_000007 asked for a task&lt;br/&gt;
2015-01-06 16:42:43,279 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 1 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1419291043936_1639_m_000007 given task: attempt_1419291043936_1639_m_000002_2&lt;br/&gt;
2015-01-06 16:42:44,498 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 3 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000002_2 is : 0.0&lt;br/&gt;
2015-01-06 16:42:44,500 FATAL &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 4 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1419291043936_1639_m_000002_2 - exited : java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:44,500 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 4 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_2: Error: java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:44,500 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_2: Error: java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:44,501 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_2 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP&lt;br/&gt;
2015-01-06 16:42:44,501 INFO &lt;a href=&quot;#1&quot;&gt;ContainerLauncher #1&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1419291043936_1639_01_000007 taskAttempt attempt_1419291043936_1639_m_000002_2&lt;br/&gt;
2015-01-06 16:42:44,501 INFO &lt;a href=&quot;#1&quot;&gt;ContainerLauncher #1&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1419291043936_1639_m_000002_2&lt;br/&gt;
2015-01-06 16:42:44,501 INFO &lt;a href=&quot;#1&quot;&gt;ContainerLauncher #1&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn003.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:44,507 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_2 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP&lt;br/&gt;
2015-01-06 16:42:44,508 INFO &lt;a href=&quot;#3&quot;&gt;CommitterEvent Processor #3&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT&lt;br/&gt;
2015-01-06 16:42:44,508 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_2 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED&lt;br/&gt;
2015-01-06 16:42:44,508 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn004.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:44,508 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn003.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:44,508 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn001.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:44,508 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn005.gid.gap.com to /default/rack_06&lt;br/&gt;
2015-01-06 16:42:44,508 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn002.gid.gap.com to /default/rack_05&lt;br/&gt;
2015-01-06 16:42:44,509 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-50&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 2 failures on node sfdmgctsn003.gid.gap.com&lt;br/&gt;
2015-01-06 16:42:44,509 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_3 TaskAttempt Transitioned from NEW to UNASSIGNED&lt;br/&gt;
2015-01-06 16:42:44,509 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-50&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1419291043936_1639_m_000002_3 to list of failed maps&lt;br/&gt;
2015-01-06 16:42:45,222 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:1 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:6 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:45,223 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1419291043936_1639: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=&amp;lt;memory:444416, vCores:78&amp;gt; knownNMs=5&lt;br/&gt;
2015-01-06 16:42:46,225 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1419291043936_1639_01_000007&lt;br/&gt;
2015-01-06 16:42:46,225 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 1&lt;br/&gt;
2015-01-06 16:42:46,226 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1419291043936_1639_01_000008, NodeId: sfdmgctsn005.gid.gap.com:45454, NodeHttpAddress: sfdmgctsn005.gid.gap.com:8042, Resource: &amp;lt;memory:14336, vCores:1&amp;gt;, Priority: 5, Token: Token &lt;/p&gt;
{ kind: ContainerToken, service: 10.9.21.135:45454 }
&lt;p&gt;, ] to fast fail map&lt;br/&gt;
2015-01-06 16:42:46,226 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_2: Container killed by the ApplicationMaster.&lt;br/&gt;
Container killed on request. Exit code is 143&lt;br/&gt;
Container exited with a non-zero exit code 143&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:46,226 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps&lt;br/&gt;
2015-01-06 16:42:46,226 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1419291043936_1639_01_000008 to attempt_1419291043936_1639_m_000002_3&lt;br/&gt;
2015-01-06 16:42:46,226 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:7 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:46,226 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.yarn.util.RackResolver: Resolved sfdmgctsn005.gid.gap.com to /default/rack_06&lt;br/&gt;
2015-01-06 16:42:46,227 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_3 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED&lt;br/&gt;
2015-01-06 16:42:46,227 INFO &lt;a href=&quot;#0&quot;&gt;ContainerLauncher #0&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1419291043936_1639_01_000008 taskAttempt attempt_1419291043936_1639_m_000002_3&lt;br/&gt;
2015-01-06 16:42:46,227 INFO &lt;a href=&quot;#0&quot;&gt;ContainerLauncher #0&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1419291043936_1639_m_000002_3&lt;br/&gt;
2015-01-06 16:42:46,227 INFO &lt;a href=&quot;#0&quot;&gt;ContainerLauncher #0&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn005.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:46,235 INFO &lt;a href=&quot;#0&quot;&gt;ContainerLauncher #0&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1419291043936_1639_m_000002_3 : 13562&lt;br/&gt;
2015-01-06 16:42:46,235 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: &lt;span class=&quot;error&quot;&gt;&amp;#91;attempt_1419291043936_1639_m_000002_3&amp;#93;&lt;/span&gt; using containerId: [container_1419291043936_1639_01_000008 on NM: &lt;span class=&quot;error&quot;&gt;&amp;#91;sfdmgctsn005.gid.gap.com:45454&amp;#93;&lt;/span&gt;&lt;br/&gt;
2015-01-06 16:42:46,235 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_3 TaskAttempt Transitioned from ASSIGNED to RUNNING&lt;br/&gt;
2015-01-06 16:42:47,227 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;RMCommunicator Allocator&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1419291043936_1639: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=&amp;lt;memory:444416, vCores:78&amp;gt; knownNMs=5&lt;br/&gt;
2015-01-06 16:42:49,199 INFO &lt;a href=&quot;#1 for port 33406&quot;&gt;Socket Reader #1 for port 33406&lt;/a&gt; SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1419291043936_1639 (auth:SIMPLE)&lt;br/&gt;
2015-01-06 16:42:49,209 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 1 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1419291043936_1639_m_000008 asked for a task&lt;br/&gt;
2015-01-06 16:42:49,209 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 1 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1419291043936_1639_m_000008 given task: attempt_1419291043936_1639_m_000002_3&lt;br/&gt;
2015-01-06 16:42:50,432 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 3 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1419291043936_1639_m_000002_3 is : 0.0&lt;br/&gt;
2015-01-06 16:42:50,434 FATAL &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 4 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1419291043936_1639_m_000002_3 - exited : java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:50,434 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server handler 4 on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_3: Error: java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:50,434 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1419291043936_1639_m_000002_3: Error: java.lang.IndexOutOfBoundsException&lt;br/&gt;
	at java.nio.Buffer.checkIndex(Buffer.java:532)&lt;br/&gt;
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:369)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&amp;lt;init&amp;gt;(ReaderImpl.java:311)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:228)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:464)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1232)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:510)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:489)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:50,435 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_3 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP&lt;br/&gt;
2015-01-06 16:42:50,435 INFO &lt;a href=&quot;#2&quot;&gt;ContainerLauncher #2&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1419291043936_1639_01_000008 taskAttempt attempt_1419291043936_1639_m_000002_3&lt;br/&gt;
2015-01-06 16:42:50,435 INFO &lt;a href=&quot;#2&quot;&gt;ContainerLauncher #2&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1419291043936_1639_m_000002_3&lt;br/&gt;
2015-01-06 16:42:50,435 INFO &lt;a href=&quot;#2&quot;&gt;ContainerLauncher #2&lt;/a&gt; org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : sfdmgctsn005.gid.gap.com:45454&lt;br/&gt;
2015-01-06 16:42:50,441 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_3 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP&lt;br/&gt;
2015-01-06 16:42:50,441 INFO &lt;a href=&quot;#4&quot;&gt;CommitterEvent Processor #4&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT&lt;br/&gt;
2015-01-06 16:42:50,442 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1419291043936_1639_m_000002_3 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED&lt;br/&gt;
2015-01-06 16:42:50,443 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1419291043936_1639_m_000002 Task Transitioned from RUNNING to FAILED&lt;br/&gt;
2015-01-06 16:42:50,443 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-50&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 1 failures on node sfdmgctsn005.gid.gap.com&lt;br/&gt;
2015-01-06 16:42:50,443 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 4&lt;br/&gt;
2015-01-06 16:42:50,443 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Job failed as tasks failed. failedMaps:1 failedReduces:0&lt;br/&gt;
2015-01-06 16:42:50,444 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1419291043936_1639Job Transitioned from RUNNING to FAIL_ABORT&lt;br/&gt;
2015-01-06 16:42:50,444 INFO &lt;a href=&quot;#0&quot;&gt;CommitterEvent Processor #0&lt;/a&gt; org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_ABORT&lt;br/&gt;
2015-01-06 16:42:50,455 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AsyncDispatcher event handler&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1419291043936_1639Job Transitioned from FAIL_ABORT to FAILED&lt;br/&gt;
2015-01-06 16:42:50,456 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: We are finishing cleanly so this is the last retry&lt;br/&gt;
2015-01-06 16:42:50,456 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify RMCommunicator isAMLastRetry: true&lt;br/&gt;
2015-01-06 16:42:50,456 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: RMCommunicator notified that shouldUnregistered is: true&lt;br/&gt;
2015-01-06 16:42:50,456 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify JHEH isAMLastRetry: true&lt;br/&gt;
2015-01-06 16:42:50,456 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: JobHistoryEventHandler notified that forceJobCompletion is true&lt;br/&gt;
2015-01-06 16:42:50,456 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Calling stop for all the services&lt;br/&gt;
2015-01-06 16:42:50,456 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0&lt;br/&gt;
2015-01-06 16:42:50,485 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;eventHandlingThread&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://sfdmgct:8020/user/hive/.staging/job_1419291043936_1639/job_1419291043936_1639_1.jhist to hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639-1420580542797-hive-sfdmgctmn003.gid.gap.com%2D32%2Dcompactor%2Dds_infra.eve-1420580570443-3-0-FAILED-default-1420580548162.jhist_tmp&lt;br/&gt;
2015-01-06 16:42:50,504 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;eventHandlingThread&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639-1420580542797-hive-sfdmgctmn003.gid.gap.com%2D32%2Dcompactor%2Dds_infra.eve-1420580570443-3-0-FAILED-default-1420580548162.jhist_tmp&lt;br/&gt;
2015-01-06 16:42:50,507 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;eventHandlingThread&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://sfdmgct:8020/user/hive/.staging/job_1419291043936_1639/job_1419291043936_1639_1_conf.xml to hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639_conf.xml_tmp&lt;br/&gt;
2015-01-06 16:42:50,524 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;eventHandlingThread&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639_conf.xml_tmp&lt;br/&gt;
2015-01-06 16:42:50,530 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;eventHandlingThread&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639.summary_tmp to hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639.summary&lt;br/&gt;
2015-01-06 16:42:50,531 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;eventHandlingThread&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639_conf.xml_tmp to hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639_conf.xml&lt;br/&gt;
2015-01-06 16:42:50,533 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;eventHandlingThread&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639-1420580542797-hive-sfdmgctmn003.gid.gap.com%2D32%2Dcompactor%2Dds_infra.eve-1420580570443-3-0-FAILED-default-1420580548162.jhist_tmp to hdfs://sfdmgct:8020/mr-history/tmp/hive/job_1419291043936_1639-1420580542797-hive-sfdmgctmn003.gid.gap.com%2D32%2Dcompactor%2Dds_infra.eve-1420580570443-3-0-FAILED-default-1420580548162.jhist&lt;br/&gt;
2015-01-06 16:42:50,533 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopped JobHistoryEventHandler. super.stop()&lt;br/&gt;
2015-01-06 16:42:50,535 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Setting job diagnostics to Task failed task_1419291043936_1639_m_000002&lt;br/&gt;
Job failed as tasks failed. failedMaps:1 failedReduces:0&lt;/p&gt;

&lt;p&gt;2015-01-06 16:42:50,536 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: History url is &lt;a href=&quot;http://sfdmgctmn004.gid.gap.com:19888/jobhistory/job/job_1419291043936_1639&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://sfdmgctmn004.gid.gap.com:19888/jobhistory/job/job_1419291043936_1639&lt;/a&gt;&lt;br/&gt;
2015-01-06 16:42:50,539 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Waiting for application to be successfully unregistered.&lt;br/&gt;
2015-01-06 16:42:51,540 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:7 ContRel:0 HostLocal:4 RackLocal:0&lt;br/&gt;
2015-01-06 16:42:51,541 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Deleting staging directory hdfs://sfdmgct /user/hive/.staging/job_1419291043936_1639&lt;br/&gt;
2015-01-06 16:42:51,543 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-79&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.Server: Stopping server on 33406&lt;br/&gt;
2015-01-06 16:42:51,544 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server listener on 33406&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 33406&lt;br/&gt;
2015-01-06 16:42:51,545 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;TaskHeartbeatHandler PingChecker&amp;#93;&lt;/span&gt; org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler: TaskHeartbeatHandler thread interrupted&lt;br/&gt;
2015-01-06 16:42:51,545 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;IPC Server Responder&amp;#93;&lt;/span&gt; org.apache.hadoop.ipc.Server: Stopping IPC Server Responder&lt;/p&gt;
</comment>
                            <comment id="14270282" author="alangates" created="Fri, 9 Jan 2015 00:32:38 +0000"  >&lt;p&gt;The issue is that since the writer died with an unclosed batch it left the orc file in a state where it cannot be read without the length file.  So removing the length file means any reader will fail when reading it.&lt;/p&gt;

&lt;p&gt;The proper solution is for the compactor to stop at that partition until it has determined all transactions in that file have committed or aborted.  Then it should compact it using the length file, but properly ignore the length file.  I&apos;ll work on the fix.&lt;/p&gt;</comment>
                            <comment id="14271601" author="jihongliu" created="Fri, 9 Jan 2015 17:54:01 +0000"  >&lt;p&gt;Make sense. It is so great if that solution can be implemented.Thanks&lt;/p&gt;</comment>
                            <comment id="14272112" author="alangates" created="Sat, 10 Jan 2015 00:03:04 +0000"  >&lt;p&gt;This patch takes a new approach.  Rather than changing AcidUtils.getAcidState (as previous 2 attempts) this patch gives a new implementation of ValidTxnList that only returns isTxnRangeValid ALL or NONE, and gives NONE if there are any open transactions &amp;lt;= the max transaction in the range (even if it&apos;s below the range).  This new implementation is used only by the compactor so that it&apos;s understanding of what files it should compact are different than what files a reader views as available for reading.&lt;/p&gt;

&lt;p&gt;I&apos;ve also added tests to TestCompactor to test compaction during streaming and compaction after a streamer has aborted and died without cleaning up.&lt;/p&gt;</comment>
                            <comment id="14272443" author="hiveqa" created="Sat, 10 Jan 2015 11:15:22 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12691437/HIVE-8966.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12691437/HIVE-8966.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 6764 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2322/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2322/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2322/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2322/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2322/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2322/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12691437 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14274433" author="alangates" created="Mon, 12 Jan 2015 23:56:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;Owen O&apos;Malley&lt;/a&gt; pointed out that I need to change the implementation of ValidCompactorTxnList.isTxnValid to return false for aborted transactions so that aborted records aren&apos;t carried forward in compacted files.  &lt;/p&gt;</comment>
                            <comment id="14275957" author="alangates" created="Tue, 13 Jan 2015 21:16:46 +0000"  >&lt;p&gt;Yet another version of this patch, this one fixes the issue introduced by the last one that adds aborted records to compacted files.&lt;/p&gt;</comment>
                            <comment id="14278515" author="hiveqa" created="Thu, 15 Jan 2015 10:14:37 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12692048/HIVE-8966.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12692048/HIVE-8966.5.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 7330 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2369/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2369/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2369/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2369/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2369/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2369/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12692048 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14284927" author="owen.omalley" created="Wed, 21 Jan 2015 00:47:42 +0000"  >&lt;p&gt;This looks good, Alan. +1&lt;/p&gt;

&lt;p&gt;One minor nit is that the class javadoc for ValidReadTxnList has &quot;And&quot; instead of the intended &quot;An&quot;.&lt;/p&gt;</comment>
                            <comment id="14284935" author="owen.omalley" created="Wed, 21 Jan 2015 00:53:37 +0000"  >&lt;p&gt;After a little more thought, I&apos;m worried that someone will accidentally create a ValidCompactorTxnList and get confused by the different behavior. I think it would make sense to move it into the compactor package to minimize the chance that someone accidentally uses it by mistake. &lt;/p&gt;</comment>
                            <comment id="14286267" author="vikram.dixit" created="Wed, 21 Jan 2015 21:04:30 +0000"  >&lt;p&gt;+1 for a branch 1.0.&lt;/p&gt;</comment>
                            <comment id="14290349" author="alangates" created="Sat, 24 Jan 2015 01:39:20 +0000"  >&lt;p&gt;Final version of the patch.  Moved ValidCompactorTxnList per Owen&apos;s request.  Also made small changes to StreamingIntegrationTester to make it work properly in cases where you want it to go slowly.&lt;/p&gt;</comment>
                            <comment id="14290583" author="hiveqa" created="Sat, 24 Jan 2015 12:54:10 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12694321/HIVE-8966.6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12694321/HIVE-8966.6.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 7370 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestSparkCliDriver-parallel_join1.q-avro_joins.q-groupby_ppr.q-and-12-more - did not produce a TEST-*.xml file
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2506/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2506/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2506/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2506/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2506/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2506/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12694321 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14292593" author="brocknoland" created="Mon, 26 Jan 2015 23:11:51 +0000"  >&lt;p&gt;Looks like this was committed but I am seeing:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-common: Compilation failure: Compilation failure:
[ERROR] /Users/noland/workspaces/hive-apache/hive/common/src/java/org/apache/hadoop/hive/common/ValidTxnListImpl.java:[23,8] org.apache.hadoop.hive.common.ValidTxnListImpl is not abstract and does not override abstract method getInvalidTransactions() in org.apache.hadoop.hive.common.ValidTxnList
[ERROR] /Users/noland/workspaces/hive-apache/hive/common/src/java/org/apache/hadoop/hive/common/ValidTxnListImpl.java:[46,3] method does not override or implement a method from a supertype
[ERROR] /Users/noland/workspaces/hive-apache/hive/common/src/java/org/apache/hadoop/hive/common/ValidTxnListImpl.java:[54,3] method does not override or implement a method from a supertype
[ERROR] /Users/noland/workspaces/hive-apache/hive/common/src/java/org/apache/hadoop/hive/common/ValidTxnListImpl.java:[121,3] method does not override or implement a method from a supertype
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-common
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14292601" author="alangates" created="Mon, 26 Jan 2015 23:19:30 +0000"  >&lt;p&gt;I did svn add instead of svn rm on a couple of files that moved.  I&apos;ll fix it.&lt;/p&gt;</comment>
                            <comment id="14292615" author="brocknoland" created="Mon, 26 Jan 2015 23:24:42 +0000"  >&lt;p&gt;thx&lt;/p&gt;</comment>
                            <comment id="14292622" author="alangates" created="Mon, 26 Jan 2015 23:31:58 +0000"  >&lt;p&gt;Fixed.&lt;/p&gt;</comment>
                            <comment id="14294010" author="alangates" created="Tue, 27 Jan 2015 19:19:39 +0000"  >&lt;p&gt;Patch 6 checked into trunk.  Patch marked for branch 1 checked into branch 1.&lt;/p&gt;</comment>
                            <comment id="14294911" author="lefty@hortonworks.com" created="Wed, 28 Jan 2015 09:17:18 +0000"  >&lt;p&gt;Any documentation needed?&lt;/p&gt;</comment>
                            <comment id="14295328" author="alangates" created="Wed, 28 Jan 2015 16:11:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=leftylev&quot; class=&quot;user-hover&quot; rel=&quot;leftylev&quot;&gt;Lefty Leverenz&lt;/a&gt; no, we just made what should have worked before work properly.&lt;/p&gt;</comment>
                            <comment id="14297958" author="jihongliu" created="Fri, 30 Jan 2015 00:31:57 +0000"  >&lt;p&gt;Thanks Alan.&lt;/p&gt;</comment>
                            <comment id="14297960" author="lefty@hortonworks.com" created="Fri, 30 Jan 2015 00:32:40 +0000"  >&lt;p&gt;Does this also need to be checked into branch-1.1 (formerly known as 0.15)?&lt;/p&gt;</comment>
                            <comment id="14298910" author="alangates" created="Fri, 30 Jan 2015 17:35:41 +0000"  >&lt;p&gt;I confirmed that it is already in 1.1, based on the git logs.&lt;/p&gt;</comment>
                            <comment id="14327567" author="thejas" created="Thu, 19 Feb 2015 14:45:03 +0000"  >&lt;p&gt;Updating release version for jiras resolved in 1.0.0 .&lt;/p&gt;</comment>
                            <comment id="14327880" author="thejas" created="Thu, 19 Feb 2015 18:22:01 +0000"  >&lt;p&gt;This issue has been fixed in Apache Hive 1.0.0. If there is any issue with the fix, please open a new jira to address it.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12694674" name="HIVE-8966-branch-1.patch" size="103575" author="alangates" created="Tue, 27 Jan 2015 00:57:28 +0000"/>
                            <attachment id="12686124" name="HIVE-8966.2.patch" size="16858" author="alangates" created="Tue, 9 Dec 2014 23:15:32 +0000"/>
                            <attachment id="12688699" name="HIVE-8966.3.patch" size="19232" author="alangates" created="Mon, 22 Dec 2014 18:43:59 +0000"/>
                            <attachment id="12691437" name="HIVE-8966.4.patch" size="84374" author="alangates" created="Sat, 10 Jan 2015 00:03:04 +0000"/>
                            <attachment id="12692048" name="HIVE-8966.5.patch" size="89403" author="alangates" created="Tue, 13 Jan 2015 21:16:46 +0000"/>
                            <attachment id="12694321" name="HIVE-8966.6.patch" size="91211" author="alangates" created="Sat, 24 Jan 2015 01:39:20 +0000"/>
                            <attachment id="12685590" name="HIVE-8966.patch" size="2125" author="jihongliu" created="Sun, 7 Dec 2014 05:23:59 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 26 Nov 2014 20:48:20 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 48 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22s3j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Don&amp;#39;t do compaction on the current delta if it has a file in bucket pattern but not compactable</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8967] Fix bucketmapjoin7.q determinism</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8967</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;In working on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8963&quot; title=&quot;Investigate test failure on bucketmapjoin7.q [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8963&quot;&gt;&lt;del&gt;HIVE-8963&lt;/del&gt;&lt;/a&gt;, we found the output is not determistic. We can add order by to make sure the output fixed.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12757851">HIVE-8967</key>
            <summary>Fix bucketmapjoin7.q determinism</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jxiang">Jimmy Xiang</assignee>
                                    <reporter username="jxiang">Jimmy Xiang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 26 Nov 2014 00:16:55 +0000</created>
                <updated>Thu, 12 Feb 2015 23:41:03 +0000</updated>
                            <resolved>Wed, 26 Nov 2014 18:18:52 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="14225498" author="xuefuz" created="Wed, 26 Nov 2014 00:40:04 +0000"  >&lt;p&gt;+1 pending on test.&lt;/p&gt;</comment>
                            <comment id="14226445" author="hiveqa" created="Wed, 26 Nov 2014 16:54:35 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12683703/HIVE-8967.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12683703/HIVE-8967.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 6683 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1909/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1909/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1909/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1909/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1909/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1909/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12683703 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14226564" author="xuefuz" created="Wed, 26 Nov 2014 18:18:52 +0000"  >&lt;p&gt;Patch committed to trunk and also merged to Spark branch. Thanks, Jimmy.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12683703" name="HIVE-8967.patch" size="7357" author="jxiang" created="Wed, 26 Nov 2014 00:19:09 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 26 Nov 2014 00:40:04 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22sfj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8969] getChildPrivileges should in one transaction with revoke</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8969</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12757869">HIVE-8969</key>
            <summary>getChildPrivileges should in one transaction with revoke</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="6">Invalid</resolution>
                                        <assignee username="Huang Xiaomeng">Xiaomeng Huang</assignee>
                                    <reporter username="Huang Xiaomeng">Xiaomeng Huang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 26 Nov 2014 01:39:11 +0000</created>
                <updated>Thu, 11 Dec 2014 01:43:45 +0000</updated>
                            <resolved>Thu, 11 Dec 2014 01:43:45 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="14241979" author="huang xiaomeng" created="Thu, 11 Dec 2014 01:43:45 +0000"  >&lt;p&gt;Sorry, I want to create this jira in Sentry project, but I made a mistake in Hive.&lt;br/&gt;
Close this jira as Invalid.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 6 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22sjb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8970] Enable map join optimization only when hive.auto.convert.join is true [Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8970</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Right now, in Spark branch we enable MJ without looking at this configuration. The related code in &lt;tt&gt;SparkMapJoinOptimizer&lt;/tt&gt; is commented out. We should only enable MJ when the flag is true.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12757889">HIVE-8970</key>
            <summary>Enable map join optimization only when hive.auto.convert.join is true [Spark Branch]</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12752296">HIVE-8699</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="csun">Chao Sun</assignee>
                                    <reporter username="csun">Chao Sun</reporter>
                        <labels>
                    </labels>
                <created>Wed, 26 Nov 2014 03:33:49 +0000</created>
                <updated>Fri, 29 May 2015 02:29:37 +0000</updated>
                            <resolved>Tue, 2 Dec 2014 19:57:09 +0000</resolved>
                                    <version>spark-branch</version>
                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="14226010" author="hiveqa" created="Wed, 26 Nov 2014 10:44:08 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12683781/HIVE-8970.1-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12683781/HIVE-8970.1-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/445/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/445/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/445/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/445/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-445/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-445/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/lib64/qt-3.3/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/lib64/qt-3.3/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-SPARK-Build-445/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-spark-source ]]
+ [[ ! -d apache-svn-spark-source/.svn ]]
+ [[ ! -d apache-svn-spark-source ]]
+ cd apache-svn-spark-source
+ svn revert -R .
Reverted &apos;itests/src/test/resources/testconfiguration.properties&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/SparkMapJoinResolver.java&apos;
++ svn status --no-ignore
++ egrep -v &apos;^X|^Performing status on external&apos;
++ awk &apos;{print $2}&apos;
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20/target shims/0.20S/target shims/0.23/target shims/aggregator/target shims/common/target shims/common-secure/target shims/scheduler/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit-hadoop2/target itests/hive-minikdc/target itests/hive-unit/target itests/custom-serde/target itests/util/target itests/qtest-spark/target hcatalog/target hcatalog/core/target hcatalog/streaming/target hcatalog/server-extensions/target hcatalog/hcatalog-pig-adapter/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target accumulo-handler/target hwi/target common/target common/src/gen spark-client/target service/target contrib/target serde/target beeline/target cli/target odbc/target ql/dependency-reduced-pom.xml ql/target
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1641793.

At revision 1641793.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12683781 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14226114" author="csun" created="Wed, 26 Nov 2014 12:23:42 +0000"  >&lt;p&gt;This patch applies cleanly on my machine, not sure why it failed.&lt;/p&gt;</comment>
                            <comment id="14226116" author="csun" created="Wed, 26 Nov 2014 12:25:08 +0000"  >&lt;p&gt;Re-attach the same patch to trigger test run.&lt;/p&gt;</comment>
                            <comment id="14226193" author="hiveqa" created="Wed, 26 Nov 2014 13:53:15 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12683831/HIVE-8970.2-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12683831/HIVE-8970.2-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/447/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/447/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/447/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/447/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-447/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-447/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/lib64/qt-3.3/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/lib64/qt-3.3/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-SPARK-Build-447/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-spark-source ]]
+ [[ ! -d apache-svn-spark-source/.svn ]]
+ [[ ! -d apache-svn-spark-source ]]
+ cd apache-svn-spark-source
+ svn revert -R .
Reverted &apos;itests/src/test/resources/testconfiguration.properties&apos;
Reverted &apos;ql/src/test/results/clientpositive/spark/bucketmapjoin10.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/spark/bucketmapjoin11.q.out&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinTableContainerSerDe.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinEagerRowContainer.java&apos;
++ svn status --no-ignore
++ egrep -v &apos;^X|^Performing status on external&apos;
++ awk &apos;{print $2}&apos;
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20/target shims/0.20S/target shims/0.23/target shims/aggregator/target shims/common/target shims/common-secure/target shims/scheduler/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit-hadoop2/target itests/hive-minikdc/target itests/hive-unit/target itests/custom-serde/target itests/util/target itests/qtest-spark/target hcatalog/target hcatalog/core/target hcatalog/streaming/target hcatalog/server-extensions/target hcatalog/hcatalog-pig-adapter/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target accumulo-handler/target hwi/target common/target common/src/gen spark-client/target service/target contrib/target serde/target beeline/target cli/target odbc/target ql/dependency-reduced-pom.xml ql/target
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1641818.

At revision 1641818.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12683831 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14230169" author="csun" created="Mon, 1 Dec 2014 18:15:09 +0000"  >&lt;p&gt;I just regenerated all qfile outputs, and noticed some result differences for join38.q, join_literals.q, join_nullsafe.q and subquery_in.q.&lt;br/&gt;
Look like they are not related to map-join work, since if I reset my branch to the &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8946&quot; title=&quot;Enable Map Join [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8946&quot;&gt;&lt;del&gt;HIVE-8946&lt;/del&gt;&lt;/a&gt; commit then the results are correct.&lt;br/&gt;
Maybe it&apos;s caused by the recent merge or RSC commits.&lt;/p&gt;</comment>
                            <comment id="14230272" author="csun" created="Mon, 1 Dec 2014 19:16:25 +0000"  >&lt;p&gt;Also, for join38.q I ran the query on CLI local mode with spark.master=local&lt;span class=&quot;error&quot;&gt;&amp;#91;4&amp;#93;&lt;/span&gt;, and the result was correct, but running unit test gave different result.&lt;/p&gt;</comment>
                            <comment id="14230315" author="csun" created="Mon, 1 Dec 2014 19:44:23 +0000"  >&lt;p&gt;Excluded the following tests from this patch:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;join38.q
join_literals.q
join_nullsafe.q
subquery_in.q
ppd_join4.q
ppd_multi_insert.q
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Their results are different from MR. I will create follow-up JIRA to address the issue.&lt;/p&gt;</comment>
                            <comment id="14230427" author="xuefuz" created="Mon, 1 Dec 2014 20:43:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;Chao Sun&lt;/a&gt;, just to clarify, w/o your patch here, do these tests give correct result? Do they give correct result when master=local&lt;span class=&quot;error&quot;&gt;&amp;#91;4&amp;#93;&lt;/span&gt;? Basically I&apos;m unclear if the current golden files are correct.&lt;/p&gt;</comment>
                            <comment id="14230470" author="csun" created="Mon, 1 Dec 2014 21:15:03 +0000"  >&lt;p&gt;Yes, I believe so. When I enable mapjoin, I compared the unit test results against the previous results in the spark branch, which was previously compared against the MR results. &lt;/p&gt;</comment>
                            <comment id="14230489" author="hiveqa" created="Mon, 1 Dec 2014 21:23:50 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684466/HIVE-8970.3-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684466/HIVE-8970.3-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 6 failed/errored test(s), 7223 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_custom_input_output_format
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parquet_join
org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationDrops.testDropPartition
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/469/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/469/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/469/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/469/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-469/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-469/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684466 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14231894" author="csun" created="Tue, 2 Dec 2014 18:42:44 +0000"  >&lt;p&gt;Created follow-up JIRA &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-9007&quot; title=&quot;Hive may generate wrong plan for map join queries due to IdentityProjectRemover [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-9007&quot;&gt;&lt;del&gt;HIVE-9007&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14232051" author="xuefuz" created="Tue, 2 Dec 2014 19:53:53 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14232055" author="xuefuz" created="Tue, 2 Dec 2014 19:57:09 +0000"  >&lt;p&gt;Committed to Spark branch. Thanks, Chao.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12758957">HIVE-9007</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12749435">HIVE-8536</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12683781" name="HIVE-8970.1-spark.patch" size="3091428" author="csun" created="Wed, 26 Nov 2014 06:44:14 +0000"/>
                            <attachment id="12683831" name="HIVE-8970.2-spark.patch" size="3091428" author="csun" created="Wed, 26 Nov 2014 12:25:08 +0000"/>
                            <attachment id="12684466" name="HIVE-8970.3-spark.patch" size="3180021" author="csun" created="Mon, 1 Dec 2014 19:44:23 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 26 Nov 2014 10:44:08 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 7 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22snr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8971] HIVE-8965 exposed some classes which start with Test but are not tests</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8971</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;From the output here: &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8836?focusedCommentId=14225742&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14225742&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-8836?focusedCommentId=14225742&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14225742&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&apos;ve looked at the TestHBase* classes and they are not tests. PTest cannot support classes which start with Test but are not tests.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestAuthorizationApiAuthorizer - did not produce a TEST-*.xml file
TestGenericUDFOPNumeric - did not produce a TEST-*.xml file
TestHBaseKeyFactory - did not produce a TEST-*.xml file
TestHBaseKeyFactory2 - did not produce a TEST-*.xml file
TestHBaseKeyFactory3 - did not produce a TEST-*.xml file
TestHBasePredicateDecomposer - did not produce a TEST-*.xml file
TestTezSessionState - did not produce a TEST-*.xml file
TestURLHook - did not produce a TEST-*.xml file
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12757899">HIVE-8971</key>
            <summary>HIVE-8965 exposed some classes which start with Test but are not tests</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="brocknoland">Brock Noland</assignee>
                                    <reporter username="brocknoland">Brock Noland</reporter>
                        <labels>
                    </labels>
                <created>Wed, 26 Nov 2014 05:05:02 +0000</created>
                <updated>Thu, 12 Feb 2015 23:40:22 +0000</updated>
                            <resolved>Wed, 26 Nov 2014 18:32:21 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="14225787" author="xuefuz" created="Wed, 26 Nov 2014 05:38:20 +0000"  >&lt;p&gt;Looks like the patch is about renaming. +1 pending on test.&lt;/p&gt;</comment>
                            <comment id="14226579" author="hiveqa" created="Wed, 26 Nov 2014 18:28:06 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12683767/HIVE-8971.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12683767/HIVE-8971.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 6683 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hive.hcatalog.streaming.TestStreaming.testEndpointConnection
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1910/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1910/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1910/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1910/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1910/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1910/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12683767 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14226588" author="brocknoland" created="Wed, 26 Nov 2014 18:32:21 +0000"  >&lt;p&gt;Committed this as I will be updating the trunk ptest server shortly to take advantage of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8965&quot; title=&quot;Enhance PTest to kill all processes between tests and to report when a TEST*.xml file is not generated&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8965&quot;&gt;&lt;del&gt;HIVE-8965&lt;/del&gt;&lt;/a&gt; in order to improve some of the delays we&apos;ve seen in testing lately.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12757746">HIVE-8965</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12683767" name="HIVE-8971.patch" size="85462" author="brocknoland" created="Wed, 26 Nov 2014 05:33:47 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 26 Nov 2014 05:38:20 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22spz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8972] Implement more fine-grained remote client-level events [Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8972</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Follow up task of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8956&quot; title=&quot;Hive hangs while some error/exception happens beyond job execution [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8956&quot;&gt;&lt;del&gt;HIVE-8956&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
Fine-grained events are useful for better job monitor and failure handling.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12757902">HIVE-8972</key>
            <summary>Implement more fine-grained remote client-level events [Spark Branch]</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12749643">HIVE-8548</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lirui">Rui Li</assignee>
                                    <reporter username="lirui">Rui Li</reporter>
                        <labels>
                    </labels>
                <created>Wed, 26 Nov 2014 05:12:47 +0000</created>
                <updated>Fri, 29 May 2015 02:28:40 +0000</updated>
                            <resolved>Wed, 17 Dec 2014 20:54:38 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="14231526" author="lirui" created="Tue, 2 Dec 2014 14:13:42 +0000"  >&lt;p&gt;Submit a patch to let the test run&lt;/p&gt;</comment>
                            <comment id="14231663" author="hiveqa" created="Tue, 2 Dec 2014 15:47:16 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684658/HIVE-8972.1-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684658/HIVE-8972.1-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 39 failed/errored test(s), 7229 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorized_timestamp_funcs
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_alter_merge_orc
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join10
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join14
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_column_access_stats
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_custom_input_output_format
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_decimal_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_escape_sortby1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_multi_insert_common_distinct
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_infer_bucket_sort_convert_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_innerjoin
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join10
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join15
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join17
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join21
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join34
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part12
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_distinct
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_hook
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_subquery
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_subquery2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert_gby
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parquet_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_join4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ptf_general_queries
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample5
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats5
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats_noscan_1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union11
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_data_types
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_13
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/471/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/471/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/471/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/471/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-471/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-471/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 39 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684658 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14232473" author="lirui" created="Wed, 3 Dec 2014 02:25:52 +0000"  >&lt;p&gt;Reload the same patch to run test again.&lt;/p&gt;</comment>
                            <comment id="14232530" author="hiveqa" created="Wed, 3 Dec 2014 03:46:09 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684781/HIVE-8972.1-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684781/HIVE-8972.1-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 35 failed/errored test(s), 7223 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join22
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join9
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join_nulls
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join_reordering_values
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_custom_input_output_format
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_infer_bucket_sort_convert_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_input13
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join15
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join21
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_star
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part13
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part15
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_hook
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mergejoins
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_metadata_only_queries
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert_move_tasks_share_dependencies
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_order2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_outer_join_ppr
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parquet_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_outer_join4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats0
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats_counter
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats_noscan_2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union19
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union25
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_count_distinct
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_decimal_mapjoin
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_distinct_2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_9
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_math_funcs
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/476/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/476/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/476/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/476/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-476/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-476/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 35 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684781 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14232702" author="lirui" created="Wed, 3 Dec 2014 07:14:11 +0000"  >&lt;p&gt;Fix some bugs and try again.&lt;/p&gt;</comment>
                            <comment id="14232843" author="hiveqa" created="Wed, 3 Dec 2014 10:10:04 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684834/HIVE-8972.2-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684834/HIVE-8972.2-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 7 failed/errored test(s), 7212 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestSparkCliDriver-ptf_general_queries.q-bucketmapjoin3.q-enforce_order.q-and-12-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_custom_input_output_format
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_multi_single_reducer
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parquet_join
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/479/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/479/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/479/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/479/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-479/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-479/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 7 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684834 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14233863" author="lirui" created="Thu, 4 Dec 2014 03:02:10 +0000"  >&lt;p&gt;Try again as I can&apos;t reproduce the failures on my side.&lt;/p&gt;</comment>
                            <comment id="14235340" author="hiveqa" created="Fri, 5 Dec 2014 10:29:37 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12685253/HIVE-8972.3-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12685253/HIVE-8972.3-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 8 failed/errored test(s), 7213 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestSparkCliDriver-vector_distinct_2.q-join15.q-union19.q-and-12-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join30
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parquet_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_decimal_aggregate
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/483/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/483/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/483/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/483/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-483/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-483/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 8 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12685253 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14249601" author="lirui" created="Wed, 17 Dec 2014 07:56:13 +0000"  >&lt;p&gt;The latest patch only consists of minor fix and clean up.&lt;br/&gt;
I talked about this with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chengxiang+li&quot; class=&quot;user-hover&quot; rel=&quot;chengxiang li&quot;&gt;Chengxiang Li&lt;/a&gt;. Here&apos;s our thought on this task:&lt;br/&gt;
Currently we set timeout for &lt;tt&gt;JobSubmitted&lt;/tt&gt; event and assume the job is always submitted via async API and will send back its spark job ID (i.e. by calling monitorJob). If we add, say, &lt;tt&gt;JobStarted&lt;/tt&gt; and set timeout for that, we assume all failures after that can be properly captured and sent back to client. So one way or another, we&apos;ll have to make assumptions. Since timeout for &lt;tt&gt;JobSubmitted&lt;/tt&gt; serves us well at the moment, maybe we should leave it as is.&lt;br/&gt;
A possible improvement may be to differentiate the two kinds of jobs we have: hive query job and other jobs (e.g. addFile, getJobInfo). The former should guarantee to send back a spark job ID for monitoring and we can set timeout for that, while the latter should finish within constant time so we can set timeout when calling Future.get.&lt;br/&gt;
cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;Xuefu Zhang&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;Marcelo Vanzin&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14249704" author="hiveqa" created="Wed, 17 Dec 2014 10:54:20 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12687696/HIVE-8972.4-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12687696/HIVE-8972.4-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 8 failed/errored test(s), 7236 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_authorization_admin_almighty1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join10
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_10
org.apache.hive.hcatalog.streaming.TestStreaming.testEndpointConnection
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyCommit
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/562/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/562/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/562/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/562/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-562/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-562/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 8 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12687696 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14249783" author="lirui" created="Wed, 17 Dec 2014 12:29:14 +0000"  >&lt;p&gt;Try again.&lt;br/&gt;
The failures &lt;tt&gt;union_remove_10&lt;/tt&gt; and &lt;tt&gt;join10&lt;/tt&gt; are all due to timeout getting cluster infos, which seems unrelated to the patch.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2014-12-17 02:24:30,458 ERROR [main]: ql.Driver (SessionState.java:printError(838)) - FAILED: SemanticException Failed to get spark memory/core info: java.util.concurrent.TimeoutException
org.apache.hadoop.hive.ql.parse.SemanticException: Failed to get spark memory/core info: java.util.concurrent.TimeoutException
	at org.apache.hadoop.hive.ql.optimizer.spark.SetSparkReducerParallelism.process(SetSparkReducerParallelism.java:120)
	at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)
	at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:94)
	at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:78)
	at org.apache.hadoop.hive.ql.lib.ForwardWalker.walk(ForwardWalker.java:79)
	at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:109)
	at org.apache.hadoop.hive.ql.parse.spark.SparkCompiler.optimizeOperatorPlan(SparkCompiler.java:134)
	at org.apache.hadoop.hive.ql.parse.TaskCompiler.compile(TaskCompiler.java:99)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10202)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:221)
	at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:74)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:221)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:420)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:306)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1108)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1170)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1045)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1035)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:199)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:151)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:362)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:297)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:837)
	at org.apache.hadoop.hive.cli.TestSparkCliDriver.runTest(TestSparkCliDriver.java:234)
	at org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_10(TestSparkCliDriver.java:210)
......
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14249959" author="hiveqa" created="Wed, 17 Dec 2014 15:12:14 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12687722/HIVE-8972.5-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12687722/HIVE-8972.5-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 7236 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_authorization_admin_almighty1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/563/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/563/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/563/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/563/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-563/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-563/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12687722 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14250353" author="vanzin" created="Wed, 17 Dec 2014 19:20:50 +0000"  >&lt;p&gt;The patch looks ok to me.&lt;/p&gt;

&lt;p&gt;I though about creating a separate API for these kinds of RPCs - these wouldn&apos;t be queued in the backend but executed right away. My only concern is that this could be abused (e.g. a caller using these calls to run a Spark job before the queue ones), but perhaps that&apos;s an app-level concern and the client shouldn&apos;t care if someone uses it that way.&lt;/p&gt;

&lt;p&gt;The netty framework we&apos;re using now could also make some things easier, like adding listeners to JobHandle and reporting job state changes to the client side when they happen (instead of the current poll-like approach?). We could also add client-level listeners so that interesting events are reported (e.g. &quot;spark context up&quot; and things like that). If there&apos;s interest in these things we could create a new task and I&apos;ll try to find some time to work on it.&lt;/p&gt;</comment>
                            <comment id="14250522" author="xuefuz" created="Wed, 17 Dec 2014 20:51:34 +0000"  >&lt;p&gt;+1 to the latest patch.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;Marcelo Vanzin&lt;/a&gt;, I think it makes sense to have a separate API for short-lived tasks as well as push-based notification for job monitoring. Please feel free to create new tasks for those. Thanks.&lt;/p&gt;</comment>
                            <comment id="14250527" author="xuefuz" created="Wed, 17 Dec 2014 20:54:38 +0000"  >&lt;p&gt;Committed to Spark branch. Thanks to Rui, Marcelo, and Chengxiang.&lt;/p&gt;</comment>
                            <comment id="14250960" author="lirui" created="Thu, 18 Dec 2014 01:30:53 +0000"  >&lt;p&gt;Thanks guys for the review.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12757601">HIVE-8956</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12763028">HIVE-9178</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12763030">HIVE-9179</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12684781" name="HIVE-8972.1-spark.patch" size="14061" author="lirui" created="Wed, 3 Dec 2014 02:25:52 +0000"/>
                            <attachment id="12684834" name="HIVE-8972.2-spark.patch" size="14817" author="lirui" created="Wed, 3 Dec 2014 07:14:11 +0000"/>
                            <attachment id="12685253" name="HIVE-8972.3-spark.patch" size="14566" author="xuefuz" created="Fri, 5 Dec 2014 06:08:15 +0000"/>
                            <attachment id="12685029" name="HIVE-8972.3-spark.patch" size="14566" author="lirui" created="Thu, 4 Dec 2014 03:02:10 +0000"/>
                            <attachment id="12687696" name="HIVE-8972.4-spark.patch" size="4896" author="lirui" created="Wed, 17 Dec 2014 07:56:13 +0000"/>
                            <attachment id="12687722" name="HIVE-8972.5-spark.patch" size="4989" author="lirui" created="Wed, 17 Dec 2014 12:29:14 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 2 Dec 2014 15:47:16 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 5 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22sqn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8973] Add support for pulling HBase columns with regex matching</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8973</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Hi, &lt;br/&gt;
we would like to create table that pulling HBase columns with regex matching. for example: &lt;br/&gt;
CREATE EXTERNAL TABLE XXX( &lt;br/&gt;
key string &lt;br/&gt;
, DATES MAP&amp;lt;STRING, BIGINT&amp;gt; &lt;br/&gt;
, FLOATS MAP&amp;lt;STRING, DOUBLE&amp;gt; &lt;br/&gt;
, STRINGS MAP&amp;lt;STRING, STRING&amp;gt; &lt;br/&gt;
) &lt;br/&gt;
STORED BY &apos;org.apache.hadoop.hive.hbase.HBaseStorageHandler&apos; WITH SERDEPROPERTIES ( &lt;br/&gt;
&quot;hbase.columns.mapping&quot; = &quot;:key, FECF&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/biggrin.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;em&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;0-9&amp;#93;&lt;/span&gt;&lt;b&gt;, FECF:F&lt;/em&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;0-9&amp;#93;&lt;/span&gt;&lt;/b&gt;, FECF:C&lt;span class=&quot;error&quot;&gt;&amp;#91;0-9&amp;#93;&lt;/span&gt;&lt;b&gt;_&lt;span class=&quot;error&quot;&gt;&amp;#91;0-9&amp;#93;&lt;/span&gt;&lt;/b&gt;&quot;) &lt;br/&gt;
TBLPROPERTIES (&quot;hbase.table.name&quot; = &quot;XXX&quot;, &quot;hbase.table.default.storage.type&quot; = &quot;binary&quot;); &lt;/p&gt;

&lt;p&gt;currently only prefix work (with hive 0.12.0): &lt;br/&gt;
CREATE EXTERNAL TABLE XXX( &lt;br/&gt;
key string &lt;br/&gt;
, DATES MAP&amp;lt;STRING, BIGINT&amp;gt; &lt;br/&gt;
, FLOATS MAP&amp;lt;STRING, DOUBLE&amp;gt; &lt;br/&gt;
, STRINGS MAP&amp;lt;STRING, STRING&amp;gt; &lt;br/&gt;
) &lt;br/&gt;
STORED BY &apos;org.apache.hadoop.hive.hbase.HBaseStorageHandler&apos; WITH SERDEPROPERTIES ( &lt;br/&gt;
&quot;hbase.columns.mapping&quot; = &quot;:key, FECF&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/biggrin.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;em&gt;.&lt;b&gt;, FECF:F&lt;/em&gt;.&lt;/b&gt;, FECF:C.*&quot;, &lt;br/&gt;
&quot;hbase.table.default.storage.type&quot; = &quot;binary&quot;) &lt;br/&gt;
TBLPROPERTIES (&quot;hbase.table.name&quot; = &quot;XXX&quot;);&lt;/p&gt;</description>
                <environment></environment>
        <key id="12757916">HIVE-8973</key>
            <summary>Add support for pulling HBase columns with regex matching</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.svg">Trivial</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="sucaz">Sucaz Moshe</reporter>
                        <labels>
                    </labels>
                <created>Wed, 26 Nov 2014 07:22:19 +0000</created>
                <updated>Thu, 13 Aug 2015 05:59:02 +0000</updated>
                                                                            <component>Clients</component>
                    <component>HBase Handler</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22str:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-8974] Upgrade to Calcite 1.0.0-SNAPSHOT (with lots of renames)</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8974</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;CLEAR LIBRARY CACHE&lt;/p&gt;

&lt;p&gt;Calcite recently (after 0.9.2, before 1.0.0) re-organized its package structure and renamed a lot of classes. &lt;a href=&quot;https://issues.apache.org/jira/browse/CALCITE-296&quot; title=&quot;Re-organize package structure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CALCITE-296&quot;&gt;&lt;del&gt;CALCITE-296&lt;/del&gt;&lt;/a&gt; has the details, including a description of the before:after mapping.&lt;/p&gt;

&lt;p&gt;This task is to upgrade to the version of Calcite that has the renamed packages. There is a 1.0.0-SNAPSHOT in Apache nexus.&lt;/p&gt;

&lt;p&gt;Calcite functionality has not changed significantly, so it should be straightforward to rename. This task should be completed ASAP, before Calcite moves on.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758035">HIVE-8974</key>
            <summary>Upgrade to Calcite 1.0.0-SNAPSHOT (with lots of renames)</summary>
                <type id="3" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21148&amp;avatarType=issuetype">Task</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jcamachorodriguez">Jesus Camacho Rodriguez</assignee>
                                    <reporter username="julianhyde">Julian Hyde</reporter>
                        <labels>
                    </labels>
                <created>Wed, 26 Nov 2014 18:42:13 +0000</created>
                <updated>Thu, 12 Feb 2015 23:40:56 +0000</updated>
                            <resolved>Tue, 9 Dec 2014 23:06:47 +0000</resolved>
                                    <version>0.15.0</version>
                                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="14227483" author="jcamachorodriguez" created="Thu, 27 Nov 2014 10:28:44 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jpullokkaran&quot; class=&quot;user-hover&quot; rel=&quot;jpullokkaran&quot;&gt;Laljo John Pullokkaran&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=julianhyde&quot; class=&quot;user-hover&quot; rel=&quot;julianhyde&quot;&gt;Julian Hyde&lt;/a&gt;, can you check?&lt;/p&gt;</comment>
                            <comment id="14227504" author="hiveqa" created="Thu, 27 Nov 2014 10:45:44 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684030/HIVE-8974.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684030/HIVE-8974.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1924/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1924/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1924/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1924/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1924/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1924/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:138:5: 
Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:149:5: 
Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:166:7: 
Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_UNION KW_ALL&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:526:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---
Downloading: http://conjars.org/repo/org/apache/calcite/calcite/1.0.0-incubating-SNAPSHOT/maven-metadata.xml
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1992 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/ql/plan/api/Query.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/ql/plan/api/Query.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveRel.java:[23,8] class HiveRelNode is public, should be declared in a file named HiveRelNode.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HivePartitionPrunerRule.java:[30,8] class HivePartitionPruneRule is public, should be declared in a file named HivePartitionPruneRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/PartitionPruner.java:[42,8] class PartitionPrune is public, should be declared in a file named PartitionPrune.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveFilterRel.java:[31,8] class HiveFilter is public, should be declared in a file named HiveFilter.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveTableScanRel.java:[43,8] class HiveTableScan is public, should be declared in a file named HiveTableScan.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveProjectRel.java:[47,8] class HiveProject is public, should be declared in a file named HiveProject.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveLimitRel.java:[32,8] class HiveLimit is public, should be declared in a file named HiveLimit.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveUnionRel.java:[31,8] class HiveUnion is public, should be declared in a file named HiveUnion.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HivePushFilterPastJoinRule.java:[39,17] class HiveFilterJoinRule is public, should be declared in a file named HiveFilterJoinRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/OptiqSemanticException.java:[28,8] class CalciteSemanticException is public, should be declared in a file named CalciteSemanticException.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveSortRel.java:[33,8] class HiveSort is public, should be declared in a file named HiveSort.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HiveMergeProjectRule.java:[24,8] class HiveProjectMergeRule is public, should be declared in a file named HiveProjectMergeRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveJoinRel.java:[40,8] class HiveJoin is public, should be declared in a file named HiveJoin.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/HiveOptiqUtil.java:[56,8] class HiveCalciteUtil is public, should be declared in a file named HiveCalciteUtil.java
[INFO] 14 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [11.110s]
[INFO] Hive Shims Common ................................. SUCCESS [9.287s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [3.178s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [2.769s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [8.059s]
[INFO] Hive Shims Scheduler .............................. SUCCESS [2.285s]
[INFO] Hive Shims ........................................ SUCCESS [2.488s]
[INFO] Hive Common ....................................... SUCCESS [25.804s]
[INFO] Hive Serde ........................................ SUCCESS [15.248s]
[INFO] Hive Metastore .................................... SUCCESS [35.187s]
[INFO] Hive Ant Utilities ................................ SUCCESS [1.836s]
[INFO] Hive Query Language ............................... FAILURE [59.957s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive Accumulo Handler ............................. SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 3:00.191s
[INFO] Finished at: Thu Nov 27 05:44:44 EST 2014
[INFO] Final Memory: 90M/546M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveRel.java:[23,8] class HiveRelNode is public, should be declared in a file named HiveRelNode.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HivePartitionPrunerRule.java:[30,8] class HivePartitionPruneRule is public, should be declared in a file named HivePartitionPruneRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/PartitionPruner.java:[42,8] class PartitionPrune is public, should be declared in a file named PartitionPrune.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveFilterRel.java:[31,8] class HiveFilter is public, should be declared in a file named HiveFilter.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveTableScanRel.java:[43,8] class HiveTableScan is public, should be declared in a file named HiveTableScan.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveProjectRel.java:[47,8] class HiveProject is public, should be declared in a file named HiveProject.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveLimitRel.java:[32,8] class HiveLimit is public, should be declared in a file named HiveLimit.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveUnionRel.java:[31,8] class HiveUnion is public, should be declared in a file named HiveUnion.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HivePushFilterPastJoinRule.java:[39,17] class HiveFilterJoinRule is public, should be declared in a file named HiveFilterJoinRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/OptiqSemanticException.java:[28,8] class CalciteSemanticException is public, should be declared in a file named CalciteSemanticException.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveSortRel.java:[33,8] class HiveSort is public, should be declared in a file named HiveSort.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HiveMergeProjectRule.java:[24,8] class HiveProjectMergeRule is public, should be declared in a file named HiveProjectMergeRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveJoinRel.java:[40,8] class HiveJoin is public, should be declared in a file named HiveJoin.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/HiveOptiqUtil.java:[56,8] class HiveCalciteUtil is public, should be declared in a file named HiveCalciteUtil.java
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684030 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14227625" author="jcamachorodriguez" created="Thu, 27 Nov 2014 13:01:24 +0000"  >&lt;p&gt;Any idea why this is failing? It compiles for me...&lt;/p&gt;</comment>
                            <comment id="14227707" author="jcamachorodriguez" created="Thu, 27 Nov 2014 14:38:59 +0000"  >&lt;p&gt;I have just uploaded a patch where I have renamed a couple of internal classes that I had not seen before, so they comply with Calcine new names.&lt;/p&gt;</comment>
                            <comment id="14227737" author="hiveqa" created="Thu, 27 Nov 2014 15:19:27 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684074/HIVE-8974.01.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684074/HIVE-8974.01.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1925/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1925/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1925/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1925/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1925/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1925/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
warning(200): IdentifiersParser.g:127:5: 
Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:138:5: 
Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:149:5: 
Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:166:7: 
Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_UNION KW_ALL&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:526:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1992 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/ql/plan/api/Query.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/ql/plan/api/Query.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveRel.java:[23,8] class HiveRelNode is public, should be declared in a file named HiveRelNode.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HivePartitionPrunerRule.java:[30,8] class HivePartitionPruneRule is public, should be declared in a file named HivePartitionPruneRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/PartitionPruner.java:[42,8] class PartitionPrune is public, should be declared in a file named PartitionPrune.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveFilterRel.java:[31,8] class HiveFilter is public, should be declared in a file named HiveFilter.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveTableScanRel.java:[43,8] class HiveTableScan is public, should be declared in a file named HiveTableScan.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveProjectRel.java:[47,8] class HiveProject is public, should be declared in a file named HiveProject.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveLimitRel.java:[32,8] class HiveLimit is public, should be declared in a file named HiveLimit.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveUnionRel.java:[31,8] class HiveUnion is public, should be declared in a file named HiveUnion.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HivePushFilterPastJoinRule.java:[39,17] class HiveFilterJoinRule is public, should be declared in a file named HiveFilterJoinRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/OptiqSemanticException.java:[28,8] class CalciteSemanticException is public, should be declared in a file named CalciteSemanticException.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveSortRel.java:[33,8] class HiveSort is public, should be declared in a file named HiveSort.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HiveMergeProjectRule.java:[24,8] class HiveProjectMergeRule is public, should be declared in a file named HiveProjectMergeRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveJoinRel.java:[40,8] class HiveJoin is public, should be declared in a file named HiveJoin.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/HiveOptiqUtil.java:[56,8] class HiveCalciteUtil is public, should be declared in a file named HiveCalciteUtil.java
[INFO] 14 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [11.535s]
[INFO] Hive Shims Common ................................. SUCCESS [8.959s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [3.353s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [2.632s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [8.663s]
[INFO] Hive Shims Scheduler .............................. SUCCESS [2.019s]
[INFO] Hive Shims ........................................ SUCCESS [2.435s]
[INFO] Hive Common ....................................... SUCCESS [10.988s]
[INFO] Hive Serde ........................................ SUCCESS [15.746s]
[INFO] Hive Metastore .................................... SUCCESS [34.556s]
[INFO] Hive Ant Utilities ................................ SUCCESS [2.803s]
[INFO] Hive Query Language ............................... FAILURE [59.835s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive Accumulo Handler ............................. SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 2:46.326s
[INFO] Finished at: Thu Nov 27 10:18:27 EST 2014
[INFO] Final Memory: 73M/746M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveRel.java:[23,8] class HiveRelNode is public, should be declared in a file named HiveRelNode.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HivePartitionPrunerRule.java:[30,8] class HivePartitionPruneRule is public, should be declared in a file named HivePartitionPruneRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/PartitionPruner.java:[42,8] class PartitionPrune is public, should be declared in a file named PartitionPrune.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveFilterRel.java:[31,8] class HiveFilter is public, should be declared in a file named HiveFilter.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveTableScanRel.java:[43,8] class HiveTableScan is public, should be declared in a file named HiveTableScan.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveProjectRel.java:[47,8] class HiveProject is public, should be declared in a file named HiveProject.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveLimitRel.java:[32,8] class HiveLimit is public, should be declared in a file named HiveLimit.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveUnionRel.java:[31,8] class HiveUnion is public, should be declared in a file named HiveUnion.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HivePushFilterPastJoinRule.java:[39,17] class HiveFilterJoinRule is public, should be declared in a file named HiveFilterJoinRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/OptiqSemanticException.java:[28,8] class CalciteSemanticException is public, should be declared in a file named CalciteSemanticException.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveSortRel.java:[33,8] class HiveSort is public, should be declared in a file named HiveSort.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HiveMergeProjectRule.java:[24,8] class HiveProjectMergeRule is public, should be declared in a file named HiveProjectMergeRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveJoinRel.java:[40,8] class HiveJoin is public, should be declared in a file named HiveJoin.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/HiveOptiqUtil.java:[56,8] class HiveCalciteUtil is public, should be declared in a file named HiveCalciteUtil.java
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684074 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14230718" author="jpullokkaran" created="Mon, 1 Dec 2014 23:55:54 +0000"  >&lt;p&gt;The failure may be due to QA not clearing the local mvn repo.&lt;br/&gt;
I have updated your bug description (which should prompt qa run to clear cache).&lt;/p&gt;</comment>
                            <comment id="14231498" author="hiveqa" created="Tue, 2 Dec 2014 14:00:33 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684615/HIVE-8974.01.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684615/HIVE-8974.01.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1949/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1949/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1949/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1949/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1949/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1949/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
warning(200): IdentifiersParser.g:127:5: 
Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:138:5: 
Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:149:5: 
Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:166:7: 
Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_UNION KW_ALL&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:526:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---
Downloading: http://conjars.org/repo/org/apache/calcite/calcite/1.0.0-incubating-SNAPSHOT/maven-metadata.xml
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1992 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/ql/plan/api/Query.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/ql/plan/api/Query.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveRel.java:[23,8] class HiveRelNode is public, should be declared in a file named HiveRelNode.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HivePartitionPrunerRule.java:[30,8] class HivePartitionPruneRule is public, should be declared in a file named HivePartitionPruneRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/PartitionPruner.java:[42,8] class PartitionPrune is public, should be declared in a file named PartitionPrune.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveFilterRel.java:[31,8] class HiveFilter is public, should be declared in a file named HiveFilter.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveTableScanRel.java:[43,8] class HiveTableScan is public, should be declared in a file named HiveTableScan.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveProjectRel.java:[47,8] class HiveProject is public, should be declared in a file named HiveProject.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveLimitRel.java:[32,8] class HiveLimit is public, should be declared in a file named HiveLimit.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveUnionRel.java:[31,8] class HiveUnion is public, should be declared in a file named HiveUnion.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HivePushFilterPastJoinRule.java:[39,17] class HiveFilterJoinRule is public, should be declared in a file named HiveFilterJoinRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/OptiqSemanticException.java:[28,8] class CalciteSemanticException is public, should be declared in a file named CalciteSemanticException.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveSortRel.java:[33,8] class HiveSort is public, should be declared in a file named HiveSort.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HiveMergeProjectRule.java:[24,8] class HiveProjectMergeRule is public, should be declared in a file named HiveProjectMergeRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveJoinRel.java:[40,8] class HiveJoin is public, should be declared in a file named HiveJoin.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/HiveOptiqUtil.java:[56,8] class HiveCalciteUtil is public, should be declared in a file named HiveCalciteUtil.java
[INFO] 14 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [15.528s]
[INFO] Hive Shims Common ................................. SUCCESS [26.911s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [6.962s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [26.749s]
[INFO] Hive Shims Scheduler .............................. SUCCESS [2.894s]
[INFO] Hive Shims ........................................ SUCCESS [2.332s]
[INFO] Hive Common ....................................... SUCCESS [29.837s]
[INFO] Hive Serde ........................................ SUCCESS [20.155s]
[INFO] Hive Metastore .................................... SUCCESS [40.607s]
[INFO] Hive Ant Utilities ................................ SUCCESS [2.005s]
[INFO] Hive Query Language ............................... FAILURE [1:00.659s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive Accumulo Handler ............................. SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 3:58.780s
[INFO] Finished at: Tue Dec 02 08:59:28 EST 2014
[INFO] Final Memory: 89M/765M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveRel.java:[23,8] class HiveRelNode is public, should be declared in a file named HiveRelNode.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HivePartitionPrunerRule.java:[30,8] class HivePartitionPruneRule is public, should be declared in a file named HivePartitionPruneRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/PartitionPruner.java:[42,8] class PartitionPrune is public, should be declared in a file named PartitionPrune.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveFilterRel.java:[31,8] class HiveFilter is public, should be declared in a file named HiveFilter.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveTableScanRel.java:[43,8] class HiveTableScan is public, should be declared in a file named HiveTableScan.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveProjectRel.java:[47,8] class HiveProject is public, should be declared in a file named HiveProject.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveLimitRel.java:[32,8] class HiveLimit is public, should be declared in a file named HiveLimit.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveUnionRel.java:[31,8] class HiveUnion is public, should be declared in a file named HiveUnion.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HivePushFilterPastJoinRule.java:[39,17] class HiveFilterJoinRule is public, should be declared in a file named HiveFilterJoinRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/OptiqSemanticException.java:[28,8] class CalciteSemanticException is public, should be declared in a file named CalciteSemanticException.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveSortRel.java:[33,8] class HiveSort is public, should be declared in a file named HiveSort.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HiveMergeProjectRule.java:[24,8] class HiveProjectMergeRule is public, should be declared in a file named HiveProjectMergeRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveJoinRel.java:[40,8] class HiveJoin is public, should be declared in a file named HiveJoin.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/HiveOptiqUtil.java:[56,8] class HiveCalciteUtil is public, should be declared in a file named HiveCalciteUtil.java
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684615 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14231869" author="jcamachorodriguez" created="Tue, 2 Dec 2014 18:19:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt;, can you help us with this? Do you know how to solve it?&lt;/p&gt;</comment>
                            <comment id="14231877" author="ashutoshc" created="Tue, 2 Dec 2014 18:32:52 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveRel.java:[23,8] &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;HiveRelNode is &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt;, should be declared in a file named HiveRelNode.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HivePartitionPrunerRule.java:[30,8] &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;HivePartitionPruneRule is &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt;, should be declared in a file named HivePartitionPruneRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/PartitionPruner.java:[42,8] &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;PartitionPrune is &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt;, should be declared in a file named PartitionPrune.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveFilterRel.java:[31,8] &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;HiveFilter is &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt;, should be declared in a file named HiveFilter.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveTableScanRel.java:[43,8] &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;HiveTableScan is &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt;, should be declared in a file named HiveTableScan.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveProjectRel.java:[47,8] &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;HiveProject is &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt;, should be declared in a file named HiveProject.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveLimitRel.java:[32,8] &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;HiveLimit is &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt;, should be declared in a file named HiveLimit.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveUnionRel.java:[31,8] &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;HiveUnion is &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt;, should be declared in a file named HiveUnion.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HivePushFilterPastJoinRule.java:[39,17] &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;HiveFilterJoinRule is &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt;, should be declared in a file named HiveFilterJoinRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/OptiqSemanticException.java:[28,8] &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;CalciteSemanticException is &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt;, should be declared in a file named CalciteSemanticException.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveSortRel.java:[33,8] &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;HiveSort is &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt;, should be declared in a file named HiveSort.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/rules/HiveMergeProjectRule.java:[24,8] &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;HiveProjectMergeRule is &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt;, should be declared in a file named HiveProjectMergeRule.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/reloperators/HiveJoinRel.java:[40,8] &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;HiveJoin is &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt;, should be declared in a file named HiveJoin.java
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/optiq/HiveOptiqUtil.java:[56,8] &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;HiveCalciteUtil is &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt;, should be declared in a file named HiveCalciteUtil.java
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It is the way diff file is generated. git diff is doing rename detection and thus is generating a patch file which can be applied using git apply, but not with &lt;tt&gt;patch&lt;/tt&gt; command. You need to turn off renames in git diff and then generate patch. To replicate Hive QA, do following :&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;$ svn co https:&lt;span class=&quot;code-comment&quot;&gt;//svn.apache.org/repos/asf/hive/trunk .
&lt;/span&gt;$ curl https:&lt;span class=&quot;code-comment&quot;&gt;//issues.apache.org/jira/secure/attachment/12684615/HIVE-8974.01.patch | patch -p1
&lt;/span&gt;$ mvn clean install -DskipTests -Phadoop-2
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;you will see same errors.&lt;br/&gt;
Essentially, you need to generate a patch which can be applied on svn repo with a &lt;tt&gt;patch&lt;/tt&gt; command preferably with option -p0&lt;/p&gt;</comment>
                            <comment id="14231892" author="jcamachorodriguez" created="Tue, 2 Dec 2014 18:40:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt;, OK, I&apos;ll upload a new patch, thanks!&lt;/p&gt;</comment>
                            <comment id="14232195" author="hiveqa" created="Tue, 2 Dec 2014 21:52:05 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684718/HIVE-8974.02.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684718/HIVE-8974.02.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 12 failed/errored test(s), 6695 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_join
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_semijoin
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_subq_exists
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_subq_in
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_views
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_cbo_join
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_cbo_semijoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_cbo_subq_exists
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_cbo_subq_in
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_cbo_views
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1950/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1950/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1950/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1950/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1950/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1950/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 12 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684718 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14232404" author="jcamachorodriguez" created="Wed, 3 Dec 2014 00:52:22 +0000"  >&lt;p&gt;The new patch fixes an issue on HiveFilterJoinRule.java (length of ImmutableBitSet).&lt;/p&gt;</comment>
                            <comment id="14232568" author="hiveqa" created="Wed, 3 Dec 2014 04:34:08 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684764/HIVE-8974.03.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684764/HIVE-8974.03.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 6695 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_views
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_cbo_views
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1955/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1955/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1955/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1955/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1955/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1955/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684764 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14232746" author="jcamachorodriguez" created="Wed, 3 Dec 2014 08:11:38 +0000"  >&lt;p&gt;For &lt;tt&gt;vector_decimal_aggregate&lt;/tt&gt;, statistics change. However, for &lt;tt&gt;cbo_views&lt;/tt&gt; we get an &lt;tt&gt;java.lang.NullPointerException&lt;/tt&gt;. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=julianhyde&quot; class=&quot;user-hover&quot; rel=&quot;julianhyde&quot;&gt;Julian Hyde&lt;/a&gt;, I attach the stacktrace, can you help me figuring out whether this is a problem on the Calcite side?&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2014-12-02 23:50:00,322 ERROR parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10100)) - CBO failed, skipping CBO. 
java.lang.NullPointerException
	at org.apache.calcite.util.ImmutableBitSet.countBits(ImmutableBitSet.java:280)
	at org.apache.calcite.util.ImmutableBitSet.access$600(ImmutableBitSet.java:36)
	at org.apache.calcite.util.ImmutableBitSet$Builder.cardinality(ImmutableBitSet.java:799)
	at org.apache.calcite.rel.metadata.RelMdColumnUniqueness.areColumnsUnique(RelMdColumnUniqueness.java:178)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ReflectiveRelMetadataProvider$2$1.invoke(ReflectiveRelMetadataProvider.java:147)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ChainedRelMetadataProvider$ChainedInvocationHandler.invoke(ChainedRelMetadataProvider.java:109)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.CachingRelMetadataProvider$CachingInvocationHandler.invoke(CachingRelMetadataProvider.java:131)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ChainedRelMetadataProvider$ChainedInvocationHandler.invoke(ChainedRelMetadataProvider.java:109)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.CachingRelMetadataProvider$CachingInvocationHandler.invoke(CachingRelMetadataProvider.java:131)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at org.apache.calcite.rel.metadata.RelMetadataQuery.areColumnsUnique(RelMetadataQuery.java:275)
	at org.apache.calcite.rel.metadata.RelMdColumnUniqueness.areColumnsUnique(RelMdColumnUniqueness.java:139)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ReflectiveRelMetadataProvider$2$1.invoke(ReflectiveRelMetadataProvider.java:147)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ChainedRelMetadataProvider$ChainedInvocationHandler.invoke(ChainedRelMetadataProvider.java:109)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.CachingRelMetadataProvider$CachingInvocationHandler.invoke(CachingRelMetadataProvider.java:131)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ChainedRelMetadataProvider$ChainedInvocationHandler.invoke(ChainedRelMetadataProvider.java:109)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.CachingRelMetadataProvider$CachingInvocationHandler.invoke(CachingRelMetadataProvider.java:131)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at org.apache.calcite.rel.metadata.RelMetadataQuery.areColumnsUnique(RelMetadataQuery.java:275)
	at org.apache.calcite.rel.metadata.RelMdColumnUniqueness.areColumnsUnique(RelMdColumnUniqueness.java:139)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ReflectiveRelMetadataProvider$2$1.invoke(ReflectiveRelMetadataProvider.java:147)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ChainedRelMetadataProvider$ChainedInvocationHandler.invoke(ChainedRelMetadataProvider.java:109)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.CachingRelMetadataProvider$CachingInvocationHandler.invoke(CachingRelMetadataProvider.java:131)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ChainedRelMetadataProvider$ChainedInvocationHandler.invoke(ChainedRelMetadataProvider.java:109)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.CachingRelMetadataProvider$CachingInvocationHandler.invoke(CachingRelMetadataProvider.java:131)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at org.apache.calcite.rel.metadata.RelMetadataQuery.areColumnsUnique(RelMetadataQuery.java:275)
	at org.apache.calcite.rel.metadata.RelMdUtil.areColumnsDefinitelyUniqueWhenNullsFiltered(RelMdUtil.java:257)
	at org.apache.calcite.rel.rules.LoptOptimizeJoinRule.areSelfJoinKeysUnique(LoptOptimizeJoinRule.java:2056)
	at org.apache.calcite.rel.rules.LoptOptimizeJoinRule.isSelfJoinFilterUnique(LoptOptimizeJoinRule.java:432)
	at org.apache.calcite.rel.rules.LoptOptimizeJoinRule.findRemovableSelfJoins(LoptOptimizeJoinRule.java:340)
	at org.apache.calcite.rel.rules.LoptOptimizeJoinRule.onMatch(LoptOptimizeJoinRule.java:126)
	at org.apache.calcite.plan.AbstractRelOptPlanner.fireRule(AbstractRelOptPlanner.java:326)
	at org.apache.calcite.plan.hep.HepPlanner.applyRule(HepPlanner.java:515)
	at org.apache.calcite.plan.hep.HepPlanner.applyRules(HepPlanner.java:392)
	at org.apache.calcite.plan.hep.HepPlanner.executeInstruction(HepPlanner.java:255)
	at org.apache.calcite.plan.hep.HepInstruction$RuleInstance.execute(HepInstruction.java:125)
	at org.apache.calcite.plan.hep.HepPlanner.executeProgram(HepPlanner.java:207)
	at org.apache.calcite.plan.hep.HepPlanner.findBestExp(HepPlanner.java:194)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$CalciteBasedPlanner.apply(SemanticAnalyzer.java:12649)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$CalciteBasedPlanner.apply(SemanticAnalyzer.java:12531)
	at org.apache.calcite.tools.Frameworks$1.apply(Frameworks.java:110)
	at org.apache.calcite.prepare.CalcitePrepareImpl.perform(CalcitePrepareImpl.java:682)
	at org.apache.calcite.tools.Frameworks.withPrepare(Frameworks.java:148)
	at org.apache.calcite.tools.Frameworks.withPlanner(Frameworks.java:106)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$CalciteBasedPlanner.getOptimizedAST(SemanticAnalyzer.java:12551)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$CalciteBasedPlanner.access$400(SemanticAnalyzer.java:12531)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10061)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:221)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:420)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:306)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1108)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1170)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1045)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1035)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:199)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:151)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:362)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:297)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:834)
	at org.apache.hadoop.hive.cli.TestCliDriver.runTest(TestCliDriver.java:136)
	at org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_views(TestCliDriver.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:176)
	at junit.framework.TestCase.runBare(TestCase.java:141)
	at junit.framework.TestResult$1.protect(TestResult.java:122)
	at junit.framework.TestResult.runProtected(TestResult.java:142)
	at junit.framework.TestResult.run(TestResult.java:125)
	at junit.framework.TestCase.run(TestCase.java:129)
	at junit.framework.TestSuite.runTest(TestSuite.java:255)
	at junit.framework.TestSuite.run(TestSuite.java:250)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:84)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:264)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:200)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:153)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)
2014-12-02 23:50:00,323 ERROR ql.Driver (SessionState.java:printError(834)) - FAILED: NullPointerException null
java.lang.NullPointerException
	at org.apache.calcite.util.ImmutableBitSet.countBits(ImmutableBitSet.java:280)
	at org.apache.calcite.util.ImmutableBitSet.access$600(ImmutableBitSet.java:36)
	at org.apache.calcite.util.ImmutableBitSet$Builder.cardinality(ImmutableBitSet.java:799)
	at org.apache.calcite.rel.metadata.RelMdColumnUniqueness.areColumnsUnique(RelMdColumnUniqueness.java:178)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ReflectiveRelMetadataProvider$2$1.invoke(ReflectiveRelMetadataProvider.java:147)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ChainedRelMetadataProvider$ChainedInvocationHandler.invoke(ChainedRelMetadataProvider.java:109)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.CachingRelMetadataProvider$CachingInvocationHandler.invoke(CachingRelMetadataProvider.java:131)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ChainedRelMetadataProvider$ChainedInvocationHandler.invoke(ChainedRelMetadataProvider.java:109)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.CachingRelMetadataProvider$CachingInvocationHandler.invoke(CachingRelMetadataProvider.java:131)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at org.apache.calcite.rel.metadata.RelMetadataQuery.areColumnsUnique(RelMetadataQuery.java:275)
	at org.apache.calcite.rel.metadata.RelMdColumnUniqueness.areColumnsUnique(RelMdColumnUniqueness.java:139)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ReflectiveRelMetadataProvider$2$1.invoke(ReflectiveRelMetadataProvider.java:147)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ChainedRelMetadataProvider$ChainedInvocationHandler.invoke(ChainedRelMetadataProvider.java:109)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.CachingRelMetadataProvider$CachingInvocationHandler.invoke(CachingRelMetadataProvider.java:131)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ChainedRelMetadataProvider$ChainedInvocationHandler.invoke(ChainedRelMetadataProvider.java:109)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.CachingRelMetadataProvider$CachingInvocationHandler.invoke(CachingRelMetadataProvider.java:131)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at org.apache.calcite.rel.metadata.RelMetadataQuery.areColumnsUnique(RelMetadataQuery.java:275)
	at org.apache.calcite.rel.metadata.RelMdColumnUniqueness.areColumnsUnique(RelMdColumnUniqueness.java:139)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ReflectiveRelMetadataProvider$2$1.invoke(ReflectiveRelMetadataProvider.java:147)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ChainedRelMetadataProvider$ChainedInvocationHandler.invoke(ChainedRelMetadataProvider.java:109)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.CachingRelMetadataProvider$CachingInvocationHandler.invoke(CachingRelMetadataProvider.java:131)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.ChainedRelMetadataProvider$ChainedInvocationHandler.invoke(ChainedRelMetadataProvider.java:109)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.calcite.rel.metadata.CachingRelMetadataProvider$CachingInvocationHandler.invoke(CachingRelMetadataProvider.java:131)
	at com.sun.proxy.$Proxy27.areColumnsUnique(Unknown Source)
	at org.apache.calcite.rel.metadata.RelMetadataQuery.areColumnsUnique(RelMetadataQuery.java:275)
	at org.apache.calcite.rel.metadata.RelMdUtil.areColumnsDefinitelyUniqueWhenNullsFiltered(RelMdUtil.java:257)
	at org.apache.calcite.rel.rules.LoptOptimizeJoinRule.areSelfJoinKeysUnique(LoptOptimizeJoinRule.java:2056)
	at org.apache.calcite.rel.rules.LoptOptimizeJoinRule.isSelfJoinFilterUnique(LoptOptimizeJoinRule.java:432)
	at org.apache.calcite.rel.rules.LoptOptimizeJoinRule.findRemovableSelfJoins(LoptOptimizeJoinRule.java:340)
	at org.apache.calcite.rel.rules.LoptOptimizeJoinRule.onMatch(LoptOptimizeJoinRule.java:126)
	at org.apache.calcite.plan.AbstractRelOptPlanner.fireRule(AbstractRelOptPlanner.java:326)
	at org.apache.calcite.plan.hep.HepPlanner.applyRule(HepPlanner.java:515)
	at org.apache.calcite.plan.hep.HepPlanner.applyRules(HepPlanner.java:392)
	at org.apache.calcite.plan.hep.HepPlanner.executeInstruction(HepPlanner.java:255)
	at org.apache.calcite.plan.hep.HepInstruction$RuleInstance.execute(HepInstruction.java:125)
	at org.apache.calcite.plan.hep.HepPlanner.executeProgram(HepPlanner.java:207)
	at org.apache.calcite.plan.hep.HepPlanner.findBestExp(HepPlanner.java:194)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$CalciteBasedPlanner.apply(SemanticAnalyzer.java:12649)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$CalciteBasedPlanner.apply(SemanticAnalyzer.java:12531)
	at org.apache.calcite.tools.Frameworks$1.apply(Frameworks.java:110)
	at org.apache.calcite.prepare.CalcitePrepareImpl.perform(CalcitePrepareImpl.java:682)
	at org.apache.calcite.tools.Frameworks.withPrepare(Frameworks.java:148)
	at org.apache.calcite.tools.Frameworks.withPlanner(Frameworks.java:106)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$CalciteBasedPlanner.getOptimizedAST(SemanticAnalyzer.java:12551)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$CalciteBasedPlanner.access$400(SemanticAnalyzer.java:12531)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10061)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:221)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:420)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:306)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1108)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1170)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1045)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1035)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:199)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:151)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:362)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:297)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:834)
	at org.apache.hadoop.hive.cli.TestCliDriver.runTest(TestCliDriver.java:136)
	at org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_views(TestCliDriver.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:176)
	at junit.framework.TestCase.runBare(TestCase.java:141)
	at junit.framework.TestResult$1.protect(TestResult.java:122)
	at junit.framework.TestResult.runProtected(TestResult.java:142)
	at junit.framework.TestResult.run(TestResult.java:125)
	at junit.framework.TestCase.run(TestCase.java:129)
	at junit.framework.TestSuite.runTest(TestSuite.java:255)
	at junit.framework.TestSuite.run(TestSuite.java:250)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:84)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:264)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:200)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:153)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14233334" author="julianhyde" created="Wed, 3 Dec 2014 18:51:49 +0000"  >&lt;p&gt;Yes, it&apos;s a calcite problem. I&apos;ve logged &lt;a href=&quot;https://issues.apache.org/jira/browse/CALCITE-509&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/CALCITE-509&lt;/a&gt; and will fix shortly.&lt;/p&gt;</comment>
                            <comment id="14233392" author="jcamachorodriguez" created="Wed, 3 Dec 2014 19:24:14 +0000"  >&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=julianhyde&quot; class=&quot;user-hover&quot; rel=&quot;julianhyde&quot;&gt;Julian Hyde&lt;/a&gt;!&lt;/p&gt;</comment>
                            <comment id="14233627" author="julianhyde" created="Wed, 3 Dec 2014 22:51:18 +0000"  >&lt;p&gt;I&apos;ve pushed a new Calcite 1.0.0-SNAPSHOT so this bug should just go away next build.&lt;/p&gt;</comment>
                            <comment id="14233667" author="jcamachorodriguez" created="Wed, 3 Dec 2014 23:28:30 +0000"  >&lt;p&gt;Re-uploading patch to trigger a new build.&lt;/p&gt;</comment>
                            <comment id="14235130" author="hiveqa" created="Fri, 5 Dec 2014 05:56:25 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12685191/HIVE-8974.04.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12685191/HIVE-8974.04.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 6695 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1960/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1960/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1960/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1960/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1960/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1960/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12685191 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14235312" author="jcamachorodriguez" created="Fri, 5 Dec 2014 09:38:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jpullokkaran&quot; class=&quot;user-hover&quot; rel=&quot;jpullokkaran&quot;&gt;Laljo John Pullokkaran&lt;/a&gt;, I think this is ready to ship, tests fails are not related to the upgrade of Calcite.&lt;/p&gt;</comment>
                            <comment id="14235799" author="jpullokkaran" created="Fri, 5 Dec 2014 17:54:41 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14238848" author="jpullokkaran" created="Tue, 9 Dec 2014 01:58:48 +0000"  >&lt;p&gt;Can you rebase your patch? it doesn&apos;t apply cleanly on the latest trunk.&lt;/p&gt;</comment>
                            <comment id="14239220" author="jcamachorodriguez" created="Tue, 9 Dec 2014 10:07:25 +0000"  >&lt;p&gt;Uploading rebased patch.&lt;/p&gt;</comment>
                            <comment id="14239547" author="hiveqa" created="Tue, 9 Dec 2014 15:35:08 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12685981/HIVE-8974.05.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12685981/HIVE-8974.05.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 6699 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx_cbo_1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2008/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2008/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2008/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2008/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2008/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2008/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12685981 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14240247" author="jpullokkaran" created="Tue, 9 Dec 2014 23:06:36 +0000"  >&lt;p&gt;Checked in to trunk.&lt;/p&gt;

&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jcamachorodriguez&quot; class=&quot;user-hover&quot; rel=&quot;jcamachorodriguez&quot;&gt;Jesus Camacho Rodriguez&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12684615" name="HIVE-8974.01.patch" size="254711" author="jcamachorodriguez" created="Tue, 2 Dec 2014 10:42:36 +0000"/>
                            <attachment id="12684718" name="HIVE-8974.02.patch" size="628272" author="jcamachorodriguez" created="Tue, 2 Dec 2014 19:49:08 +0000"/>
                            <attachment id="12685101" name="HIVE-8974.03.patch" size="628321" author="jcamachorodriguez" created="Thu, 4 Dec 2014 11:49:25 +0000"/>
                            <attachment id="12685191" name="HIVE-8974.04.patch" size="628322" author="jcamachorodriguez" created="Thu, 4 Dec 2014 23:12:57 +0000"/>
                            <attachment id="12685981" name="HIVE-8974.05.patch" size="627929" author="jcamachorodriguez" created="Tue, 9 Dec 2014 10:07:25 +0000"/>
                            <attachment id="12684030" name="HIVE-8974.patch" size="254717" author="jcamachorodriguez" created="Thu, 27 Nov 2014 10:28:44 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 27 Nov 2014 10:28:44 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 6 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22tjr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8975] Possible performance regression on bucket_map_join_tez2.q</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8975</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;After introducing the identity project removal optimization in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8435&quot; title=&quot;Add identity project remover optimization&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8435&quot;&gt;&lt;del&gt;HIVE-8435&lt;/del&gt;&lt;/a&gt;, plan in bucket_map_join_tez2.q that runs on Tez changed to be sub-optimal. In particular, earlier it was doing a map-join and after &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8435&quot; title=&quot;Add identity project remover optimization&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8435&quot;&gt;&lt;del&gt;HIVE-8435&lt;/del&gt;&lt;/a&gt; it changed to a reduce-join.&lt;/p&gt;

&lt;p&gt;The query is the following one:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;select a.key, b.key from (select distinct key from tab) a join tab b on b.key = a.key
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The plan before removing the projections is:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TS[0]-FIL[16]-SEL[1]-GBY[2]-RS[3]-GBY[4]-SEL[5]-RS[8]-JOIN[11]-SEL[12]-FS[13]
TS[6]-FIL[17]-RS[10]-JOIN[11]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And after removing identity projections:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TS[0]-FIL[16]-GBY[2]-RS[3]-GBY[4]-RS[8]-JOIN[11]-SEL[12]-FS[13]
TS[6]-FIL[17]-RS[10]-JOIN[11]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After digging a bit, I realized it is not converting the reduce-join into a map-join because stats for GBY[4] change if SEL[5] is removed; thus the optimization does not kick in. &lt;br/&gt;
The reason for the stats change in the GroupBy operator is in &lt;a href=&quot;https://github.com/apache/hive/blob/6f4365e8a21e7b480bf595d079a71303a50bf1b2/ql/src/java/org/apache/hadoop/hive/ql/optimizer/stats/annotation/StatsRulesProcFactory.java#L633&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;this line&lt;/a&gt;, where it is checked whether the GBY is immediately followed by a RS operator or not, and calculate stats differently depending on it.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758050">HIVE-8975</key>
            <summary>Possible performance regression on bucket_map_join_tez2.q</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="prasanth_j">Prasanth Jayachandran</assignee>
                                    <reporter username="jcamachorodriguez">Jesus Camacho Rodriguez</reporter>
                        <labels>
                    </labels>
                <created>Wed, 26 Nov 2014 19:32:35 +0000</created>
                <updated>Thu, 12 Feb 2015 23:40:31 +0000</updated>
                            <resolved>Mon, 8 Dec 2014 16:21:35 +0000</resolved>
                                    <version>0.15.0</version>
                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Logical Optimizer</component>
                    <component>Statistics</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="14226695" author="jcamachorodriguez" created="Wed, 26 Nov 2014 19:35:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasanth_j&quot; class=&quot;user-hover&quot; rel=&quot;prasanth_j&quot;&gt;Prasanth Jayachandran&lt;/a&gt;, what do you think?&lt;/p&gt;</comment>
                            <comment id="14226865" author="prasanth_j" created="Wed, 26 Nov 2014 22:03:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jcamachorodriguez&quot; class=&quot;user-hover&quot; rel=&quot;jcamachorodriguez&quot;&gt;Jesus Camacho Rodriguez&lt;/a&gt; I see what the issue here is. That check (RS after GBY) was used to determine map-reduce boundary. The map-side GBY has different stats logic as compared to reduce side GBY. &lt;br/&gt;
Now after the identity projection removal optimization&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;TS[0]-FIL[16]-GBY[2]-RS[3]-GBY[4]-RS[8]-JOIN[11]-SEL[12]-FS[13]
TS[6]-FIL[17]-RS[10]-JOIN[11]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;both GBY&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt; and GBY&lt;span class=&quot;error&quot;&gt;&amp;#91;4&amp;#93;&lt;/span&gt; are identified as map-side GBY. I think we need to improve that if condition to better differentiate map-side and reduce-side GBY. Somewhat better check would be if RS is contained in upstream operators of GBY then that GBY is reduce side. In the above case GBY&lt;span class=&quot;error&quot;&gt;&amp;#91;4&amp;#93;&lt;/span&gt; contains RS&lt;span class=&quot;error&quot;&gt;&amp;#91;3&amp;#93;&lt;/span&gt; in its upstreams operators. Any thoughts?&lt;/p&gt;</comment>
                            <comment id="14226955" author="ashutoshc" created="Wed, 26 Nov 2014 23:00:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasanth_j&quot; class=&quot;user-hover&quot; rel=&quot;prasanth_j&quot;&gt;Prasanth Jayachandran&lt;/a&gt; Instead of trying to determine whether its running in map or reduce, I think stats logic should really make different stats calculation based on mode GBY is running in. That mode can be determined via GBYDesc.Mode All we want is an estimate of # of rows coming out of GBY and that is dependent on whether it is a partial aggregation or full aggregation, not whether its in map or reduce. Thoughts ?&lt;/p&gt;</comment>
                            <comment id="14227005" author="prasanth_j" created="Wed, 26 Nov 2014 23:42:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt; What are all the possible modes for map-side and reduce-side? Stats calculation also has some logic for hash-aggregation enabled vs disabled. Is it safe to assume that if mode is HASH/PARTIAL it is map-side? And if the mode is FULL then reduce-side?&lt;br/&gt;
If so I can change the logic accordingly without depending on the child/parent checks in operator tree. &lt;/p&gt;</comment>
                            <comment id="14232447" author="prasanth_j" created="Wed, 3 Dec 2014 01:41:52 +0000"  >&lt;p&gt;I ran few different combinations of group by queries and found that GBY in reduce side always has mode MERGEPARTIAL. So I believe its safe to assume reduce side GBY will always has mergepartial mode. I don&apos;t really fully understand other GBY modes (like PARTIAL1, PARTIAL2, PARTIALS, COMPLETE, FULL)&lt;br/&gt;
 &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt; Can you correct me if my understanding is wrong? Also can you take a look at this minor patch?&lt;/p&gt;</comment>
                            <comment id="14232631" author="hiveqa" created="Wed, 3 Dec 2014 05:54:09 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684771/HIVE-8975.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684771/HIVE-8975.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 122 failed/errored test(s), 6695 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join18
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join18_multi_distinct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer14
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer15
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer9
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_count
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cross_product_check_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cross_product_check_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_dynpart_sort_optimization
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_explain_logical
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby11
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby12
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby1_map_skew
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby1_noskew
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby2_limit
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby2_map_skew
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby2_noskew
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby2_noskew_multi_distinct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby4_noskew
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby5_noskew
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby6_map_skew
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby6_noskew
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby7_map_multi_single_reducer
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby7_map_skew
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby7_noskew
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby7_noskew_multi_single_reducer
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby8
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby8_map
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby8_map_skew
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby8_noskew
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby9
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_grouping_sets2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_multi_insert_common_distinct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_multi_single_reducer
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_multi_single_reducer2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_multi_single_reducer3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_position
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_ppr
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_ppr_multi_distinct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_resolution
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_sort_10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_sort_1_23
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_sort_3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_sort_5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_sort_7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_sort_skew_1_23
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join18
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join18_multi_distinct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join29
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_limit_pushdown
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_limit_pushdown_negative
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_distinct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multiMapJoin2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multi_insert
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multi_insert_gby
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multi_insert_gby3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multi_insert_lateral_view
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multi_insert_move_tasks_share_dependencies
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_nullgroup2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parallel
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppd2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_reduce_deduplicate_extended
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_semijoin
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_exists_having
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_in
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_in_having
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_notexists_having
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_notin_having
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udtf_json_tuple
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union31
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union33
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_char_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_groupby_reduce
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_mapjoin_reduce
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_orderby_5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_reduce_groupby_decimal
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorization_limit
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_queries
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_auto_sortmerge_join_9
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_bucket_map_join_tez1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_bucket_map_join_tez2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_count
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_cross_product_check_1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_cross_product_check_2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynamic_partition_pruning_2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_optimization
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_groupby1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_groupby2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_limit_pushdown
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mrr
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_parallel
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_subquery_in
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_dml
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_groupby_reduce
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_mapjoin_reduce
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_orderby_5
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_reduce_groupby_decimal
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorization_limit
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorized_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_groupby2
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_infer_bucket_sort_map_operators
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx
org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1
org.apache.hive.hcatalog.listener.TestNotificationListener.testAMQListener
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1957/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1957/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1957/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1957/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1957/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1957/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 122 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684771 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14233398" author="ashutoshc" created="Wed, 3 Dec 2014 19:28:43 +0000"  >&lt;p&gt;In addition to &lt;tt&gt;MERGEPARTIAL&lt;/tt&gt;, &lt;tt&gt;COMPLETE&lt;/tt&gt; &amp;amp; &lt;tt&gt;FINAL&lt;/tt&gt; modes should also be considered as one resulting in reductions. Other than patch looks good. Need to update golden files.&lt;/p&gt;</comment>
                            <comment id="14233516" author="prasanth_j" created="Wed, 3 Dec 2014 21:06:19 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt;! I incorporated other modes as well. Also renamed some variables to make more sense. I will regenerate the golden files after the next QA test run (hoping for number of diffs to reduce).&lt;/p&gt;</comment>
                            <comment id="14233526" author="ashutoshc" created="Wed, 3 Dec 2014 21:14:49 +0000"  >&lt;p&gt;cool.. yeah.. hoping golden files update to go down&lt;/p&gt;</comment>
                            <comment id="14233687" author="ashutoshc" created="Wed, 3 Dec 2014 23:52:50 +0000"  >&lt;p&gt;Also, per test report its worth noting that tests &lt;tt&gt;bucket_map_join_tez2.q&lt;/tt&gt; &amp;amp; &lt;tt&gt;mrr.q&lt;/tt&gt; are back to their pre-8435 plan, which is good.&lt;/p&gt;</comment>
                            <comment id="14236289" author="prasanth_j" created="Fri, 5 Dec 2014 23:22:50 +0000"  >&lt;p&gt;Reploading patch again to trigger hive QA&lt;/p&gt;</comment>
                            <comment id="14236542" author="hiveqa" created="Sat, 6 Dec 2014 03:14:23 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12685456/HIVE-8975.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12685456/HIVE-8975.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 65 failed/errored test(s), 6696 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join18
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join18_multi_distinct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer14
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer15
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer9
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cross_product_check_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cross_product_check_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_dynpart_sort_optimization
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_explain_logical
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby2_limit
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_position
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_resolution
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_sort_1_23
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_sort_skew_1_23
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join18
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join18_multi_distinct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join29
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_limit_pushdown
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multiMapJoin2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multi_insert_move_tasks_share_dependencies
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parallel
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppd2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_semijoin
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_exists_having
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_in
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_in_having
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_notexists_having
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_notin_having
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udtf_json_tuple
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_char_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_mapjoin_reduce
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_orderby_5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_reduce_groupby_decimal
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorization_limit
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_queries
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_auto_sortmerge_join_9
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_bucket_map_join_tez1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_bucket_map_join_tez2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_cross_product_check_1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_cross_product_check_2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynamic_partition_pruning_2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_optimization
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_limit_pushdown
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mrr
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_parallel
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_subquery_in
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_dml
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_mapjoin_reduce
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_orderby_5
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_reduce_groupby_decimal
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorization_limit
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorized_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1976/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1976/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1976/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1976/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1976/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1976/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 65 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12685456 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14237287" author="prasanth_j" created="Sun, 7 Dec 2014 21:51:22 +0000"  >&lt;p&gt;Updated golden files for test failures.&lt;/p&gt;</comment>
                            <comment id="14237294" author="ashutoshc" created="Sun, 7 Dec 2014 22:06:38 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14237324" author="hiveqa" created="Mon, 8 Dec 2014 00:01:48 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12685635/HIVE-8975.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12685635/HIVE-8975.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 3 failed/errored test(s), 6696 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_queries
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1988/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1988/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1988/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1988/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1988/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1988/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12685635 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14238015" author="ashutoshc" created="Mon, 8 Dec 2014 16:21:35 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Prasanth !&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12759757">HIVE-9031</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12684771" name="HIVE-8975.1.patch" size="1337" author="prasanth_j" created="Wed, 3 Dec 2014 01:41:52 +0000"/>
                            <attachment id="12685456" name="HIVE-8975.2.patch" size="5042" author="prasanth_j" created="Fri, 5 Dec 2014 23:22:50 +0000"/>
                            <attachment id="12685635" name="HIVE-8975.3.patch" size="315638" author="prasanth_j" created="Sun, 7 Dec 2014 21:51:22 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 26 Nov 2014 22:03:55 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 7 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22tmv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8976] Make nine additional tests deterministic</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8976</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;auto_join_without_localtask.q
count.q
limit_pushdown.q
mapreduce2.q
multi_insert_gby3.q
multi_join_union.q
ppd_outer_join3.q
ptf_decimal.q
ptf_general_queries.q
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12758078">HIVE-8976</key>
            <summary>Make nine additional tests deterministic</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="brocknoland">Brock Noland</assignee>
                                    <reporter username="brocknoland">Brock Noland</reporter>
                        <labels>
                    </labels>
                <created>Wed, 26 Nov 2014 21:40:02 +0000</created>
                <updated>Thu, 12 Feb 2015 23:40:45 +0000</updated>
                            <resolved>Thu, 27 Nov 2014 13:33:47 +0000</resolved>
                                    <version>0.15.0</version>
                                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="14226902" author="brocknoland" created="Wed, 26 Nov 2014 22:26:43 +0000"  >&lt;p&gt;Including tez tests&lt;/p&gt;</comment>
                            <comment id="14227061" author="xuefuz" created="Thu, 27 Nov 2014 00:46:42 +0000"  >&lt;p&gt;LGTM. +1 pending on test.&lt;/p&gt;</comment>
                            <comment id="14227240" author="hiveqa" created="Thu, 27 Nov 2014 04:05:42 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12683935/HIVE-8976.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12683935/HIVE-8976.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 6694 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestParquetDirect - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mapjoin_mapjoin
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1918/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1918/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1918/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1918/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1918/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1918/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12683935 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14227657" author="xuefuz" created="Thu, 27 Nov 2014 13:33:47 +0000"  >&lt;p&gt;Patch committed to trunk and merged to Spark branch. Thanks, Brock.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12754699">HIVE-8836</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12683935" name="HIVE-8976.patch" size="58158" author="brocknoland" created="Wed, 26 Nov 2014 22:26:43 +0000"/>
                            <attachment id="12683930" name="HIVE-8976.patch" size="47607" author="brocknoland" created="Wed, 26 Nov 2014 22:09:21 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 27 Nov 2014 00:46:42 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22ts7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8977] TestParquetDirect should be abstract</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8977</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The class &lt;tt&gt;TestParquetDirect&lt;/tt&gt; does not contain any tests but starts with Test. Thus the build system runs it and expects an output file. We should rename the file to &lt;tt&gt;AbstractTestParquetDirect&lt;/tt&gt; and make the class abstract.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758084">HIVE-8977</key>
            <summary>TestParquetDirect should be abstract</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="brocknoland">Brock Noland</assignee>
                                    <reporter username="brocknoland">Brock Noland</reporter>
                        <labels>
                    </labels>
                <created>Wed, 26 Nov 2014 22:22:55 +0000</created>
                <updated>Thu, 12 Feb 2015 23:41:08 +0000</updated>
                            <resolved>Thu, 27 Nov 2014 16:34:18 +0000</resolved>
                                    <version>0.15.0</version>
                                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="14226977" author="szehon" created="Wed, 26 Nov 2014 23:09:53 +0000"  >&lt;p&gt;+1 pending tests&lt;/p&gt;</comment>
                            <comment id="14227276" author="hiveqa" created="Thu, 27 Nov 2014 05:25:11 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12683936/HIVE-8977.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12683936/HIVE-8977.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 6694 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mapjoin_mapjoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1919/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1919/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1919/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1919/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1919/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1919/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12683936 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14227819" author="brocknoland" created="Thu, 27 Nov 2014 16:34:18 +0000"  >&lt;p&gt;Committed to trunk! Thank you Szehon for the review!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12683936" name="HIVE-8977.patch" size="12435" author="brocknoland" created="Wed, 26 Nov 2014 22:31:13 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 26 Nov 2014 23:09:53 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22ttj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8978] Fix test determinism issue for qfile: smb_mapjoin_1.q etc</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8978</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;We see the order of output of some qfile tests could change. Here is a list of qfiles I was thinking to fix:&lt;/p&gt;

&lt;p&gt;smb_mapjoin_1.q,&lt;br/&gt;
smb_mapjoin_2.q,&lt;br/&gt;
smb_mapjoin_4.q,&lt;br/&gt;
smb_mapjoin_5.q,&lt;br/&gt;
smb_mapjoin_8.q,&lt;br/&gt;
uniquejoin.q,&lt;br/&gt;
vector_decimal_aggregate.q,&lt;br/&gt;
vectorization_13.q,&lt;br/&gt;
join_reorder.q,&lt;br/&gt;
outer_join_ppr.q&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758097">HIVE-8978</key>
            <summary>Fix test determinism issue for qfile: smb_mapjoin_1.q etc</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jxiang">Jimmy Xiang</assignee>
                                    <reporter username="jxiang">Jimmy Xiang</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Nov 2014 00:28:59 +0000</created>
                <updated>Thu, 12 Feb 2015 23:40:18 +0000</updated>
                            <resolved>Thu, 27 Nov 2014 12:42:04 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="14227188" author="brocknoland" created="Thu, 27 Nov 2014 02:55:09 +0000"  >&lt;p&gt;+1 pending tests&lt;/p&gt;</comment>
                            <comment id="14227425" author="hiveqa" created="Thu, 27 Nov 2014 09:22:44 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12683970/HIVE-8978.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12683970/HIVE-8978.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 6694 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestParquetDirect - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mapjoin_mapjoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1922/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1922/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1922/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1922/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1922/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1922/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12683970 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14227604" author="xuefuz" created="Thu, 27 Nov 2014 12:42:04 +0000"  >&lt;p&gt;Committed to trunk and merged to Spark branch. Thanks, Jimmy.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12683970" name="HIVE-8978.1.patch" size="79919" author="jxiang" created="Thu, 27 Nov 2014 01:26:00 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 27 Nov 2014 02:55:09 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22twf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8979] Merge shims/common-secure into shims/common</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8979</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;After &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8828&quot; title=&quot;Remove hadoop 20 shims&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8828&quot;&gt;&lt;del&gt;HIVE-8828&lt;/del&gt;&lt;/a&gt; there is no reason to keep both. &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8828&quot; title=&quot;Remove hadoop 20 shims&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8828&quot;&gt;&lt;del&gt;HIVE-8828&lt;/del&gt;&lt;/a&gt; already migrated many of classes from common-secure into common. We should move rest as well and delete common-secure.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758102">HIVE-8979</key>
            <summary>Merge shims/common-secure into shims/common</summary>
                <type id="3" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21148&amp;avatarType=issuetype">Task</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ashutoshc">Ashutosh Chauhan</assignee>
                                    <reporter username="ashutoshc">Ashutosh Chauhan</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Nov 2014 01:15:38 +0000</created>
                <updated>Fri, 10 Jul 2015 05:55:56 +0000</updated>
                            <resolved>Fri, 28 Nov 2014 08:09:39 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Shims</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="14227923" author="ashutoshc" created="Thu, 27 Nov 2014 19:33:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/28520/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/28520/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14227989" author="hiveqa" created="Thu, 27 Nov 2014 22:27:04 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684105/HIVE-8979.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684105/HIVE-8979.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 3 failed/errored test(s), 6694 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mapjoin_mapjoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1927/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1927/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1927/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1927/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1927/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1927/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684105 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14227994" author="ashutoshc" created="Thu, 27 Nov 2014 22:44:10 +0000"  >&lt;p&gt;Failures are unrelated. These have failed in previous Hive QA runs as well.&lt;/p&gt;</comment>
                            <comment id="14227995" author="ashutoshc" created="Thu, 27 Nov 2014 22:44:22 +0000"  >&lt;p&gt;Patch is ready for review.&lt;/p&gt;</comment>
                            <comment id="14228090" author="thejas" created="Fri, 28 Nov 2014 06:19:16 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14228140" author="ashutoshc" created="Fri, 28 Nov 2014 08:09:40 +0000"  >&lt;p&gt;Committed to trunk.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12754592">HIVE-8828</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12827612">PIG-4534</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12684105" name="HIVE-8979.patch" size="87397" author="ashutoshc" created="Thu, 27 Nov 2014 19:25:30 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 27 Nov 2014 22:27:04 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22txj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8980] Remove shimming of CombineHiveInputFormat</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8980</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;No longer needed post &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8828&quot; title=&quot;Remove hadoop 20 shims&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8828&quot;&gt;&lt;del&gt;HIVE-8828&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758103">HIVE-8980</key>
            <summary>Remove shimming of CombineHiveInputFormat</summary>
                <type id="3" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21148&amp;avatarType=issuetype">Task</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ashutoshc">Ashutosh Chauhan</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Nov 2014 01:16:28 +0000</created>
                <updated>Thu, 27 Nov 2014 01:19:45 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                    <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12754592">HIVE-8828</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22txr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-8981] Not a directory error in mapjoin_hook.q [Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8981</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Hits the following exception:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2014-11-26 15:17:11,728 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) - 14/11/26 15:17:11 WARN TaskSetManager: Lost task 0.0 in stage 8.0 (TID 18, 172.16.3.52): java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: Error while trying to create table container
2014-11-26 15:17:11,728 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.processRow(SparkMapRecordHandler.java:160)
2014-11-26 15:17:11,728 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.processNextRecord(HiveMapFunctionResultList.java:47)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.processNextRecord(HiveMapFunctionResultList.java:28)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.hasNext(HiveBaseFunctionResultList.java:96)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:41)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at scala.collection.Iterator$class.foreach(Iterator.scala:727)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$2.apply(AsyncRDDActions.scala:115)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$2.apply(AsyncRDDActions.scala:115)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.spark.SparkContext$$anonfun$30.apply(SparkContext.scala:1390)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.spark.SparkContext$$anonfun$30.apply(SparkContext.scala:1390)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.spark.scheduler.Task.run(Task.scala:56)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at java.lang.Thread.run(Thread.java:744)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) - Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: Error while trying to create table container
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.hadoop.hive.ql.exec.spark.HashTableLoader.load(HashTableLoader.java:100)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.hadoop.hive.ql.exec.MapJoinOperator.loadHashTable(MapJoinOperator.java:193)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.hadoop.hive.ql.exec.MapJoinOperator.cleanUpInputFileChangedOp(MapJoinOperator.java:219)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1051)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1055)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1055)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1055)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:486)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.processRow(SparkMapRecordHandler.java:149)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     ... 16 more
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) - Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Error while trying to create table container
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.hadoop.hive.ql.exec.persistence.MapJoinTableContainerSerDe.load(MapJoinTableContainerSerDe.java:154)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.hadoop.hive.ql.exec.spark.HashTableLoader.load(HashTableLoader.java:97)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     ... 24 more
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) - Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Error, not a directory: file:/home/szehon/repos/apache-hive-git/hive/itests/qtest-spark/target/tmp/scratchdir/szehon/34689ef1-da29-422f-9409-f358480e03b9/hive_2014-11-26_15-17-11_015_4372638719563218766-1/-mr-10002/HashTable-Stage-1/MapJoin-mapfile31--.hashtable
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     at org.apache.hadoop.hive.ql.exec.persistence.MapJoinTableContainerSerDe.load(MapJoinTableContainerSerDe.java:105)
2014-11-26 15:17:11,729 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(364)) -     ... 25 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment>&lt;p&gt;Using remote-spark context with spark-master=local-cluster &lt;span class=&quot;error&quot;&gt;&amp;#91;2,2,1024&amp;#93;&lt;/span&gt;&lt;/p&gt;</environment>
        <key id="12758110">HIVE-8981</key>
            <summary>Not a directory error in mapjoin_hook.q [Spark Branch]</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12752296">HIVE-8699</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="8">Not A Problem</resolution>
                                        <assignee username="csun">Chao Sun</assignee>
                                    <reporter username="szehon">Szehon Ho</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Nov 2014 02:03:54 +0000</created>
                <updated>Wed, 17 Feb 2016 14:49:14 +0000</updated>
                            <resolved>Wed, 3 Dec 2014 22:13:53 +0000</resolved>
                                    <version>spark-branch</version>
                                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="14227135" author="szehon" created="Thu, 27 Nov 2014 02:06:21 +0000"  >&lt;p&gt;FYI &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;Chao Sun&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14227295" author="csun" created="Thu, 27 Nov 2014 06:14:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=szehon&quot; class=&quot;user-hover&quot; rel=&quot;szehon&quot;&gt;Szehon Ho&lt;/a&gt; OK, I&apos;ll take a look. Thanks&lt;/p&gt;</comment>
                            <comment id="14230375" author="csun" created="Mon, 1 Dec 2014 20:14:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=szehon&quot; class=&quot;user-hover&quot; rel=&quot;szehon&quot;&gt;Szehon Ho&lt;/a&gt; I just ran unit test on this one and the result looks correct to me. Any idea on how to reproduce this issue? Thanks.&lt;/p&gt;</comment>
                            <comment id="14230465" author="szehon" created="Mon, 1 Dec 2014 21:13:12 +0000"  >&lt;p&gt;That&apos;s interesting, maybe it went away with some of the recent checkins..  I guess we&apos;ll keep an eye out if it happens again.&lt;/p&gt;</comment>
                            <comment id="14230486" author="xuefuz" created="Mon, 1 Dec 2014 21:21:50 +0000"  >&lt;p&gt;Yeah, the test seems passed in the latest test run: &lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8998?focusedCommentId=14229321&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14229321&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-8998?focusedCommentId=14229321&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14229321&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Closing this for now.&lt;/p&gt;</comment>
                            <comment id="14230600" author="csun" created="Mon, 1 Dec 2014 22:43:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=szehon&quot; class=&quot;user-hover&quot; rel=&quot;szehon&quot;&gt;Szehon Ho&lt;/a&gt; Is this issue also happening randomly? What is the failing test? Any suggestion on how to reproduce it?&lt;/p&gt;</comment>
                            <comment id="14231931" author="csun" created="Tue, 2 Dec 2014 19:04:47 +0000"  >&lt;p&gt;I think the root issue is this:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Caused by: org.apache.hadoop.hive.ql.exec.mapjoin.MapJoinMemoryExhaustionException: 2014-11-28 08:21:44	Processing rows:	4	Hashtable size:	3	Memory usage:	105163912	percentage:	0.204
	at org.apache.hadoop.hive.ql.exec.mapjoin.MapJoinMemoryExhaustionHandler.checkMemoryStatus(MapJoinMemoryExhaustionHandler.java:99)
	at org.apache.hadoop.hive.ql.exec.HashTableSinkOperator.processOp(HashTableSinkOperator.java:251)
	at org.apache.hadoop.hive.ql.exec.SparkHashTableSinkOperator.processOp(SparkHashTableSinkOperator.java:66)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:815)
	at org.apache.hadoop.hive.ql.exec.FilterOperator.processOp(FilterOperator.java:120)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:815)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:95)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:157)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:493)
	... 17 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Somehow it failed because of running out of memory. Since hash table sink failed to generate a directory (and file), hash table loader will complain &quot;Not a directory&quot;.&lt;/p&gt;</comment>
                            <comment id="14231934" author="csun" created="Tue, 2 Dec 2014 19:07:52 +0000"  >&lt;p&gt;Also note that the golden file for this test contains several &quot;Status: Failed&quot;. It&apos;s not related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-9007&quot; title=&quot;Hive may generate wrong plan for map join queries due to IdentityProjectRemover [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-9007&quot;&gt;&lt;del&gt;HIVE-9007&lt;/del&gt;&lt;/a&gt;, and I&apos;m not sure whether it&apos;s related to the issue in this JIRA.&lt;/p&gt;</comment>
                            <comment id="14231938" author="xuefuz" created="Tue, 2 Dec 2014 19:09:58 +0000"  >&lt;p&gt;Can we find out why we run out of memory (randomly)? Should we fail the task in such a case?&lt;/p&gt;</comment>
                            <comment id="14232446" author="csun" created="Wed, 3 Dec 2014 01:41:48 +0000"  >&lt;p&gt;Talked offline, and we&apos;ll create separate JIRA to skip the rest tasks if parent task failed. I&apos;ll try to dive deeper into the memory issue.&lt;/p&gt;</comment>
                            <comment id="14232457" author="csun" created="Wed, 3 Dec 2014 01:57:54 +0000"  >&lt;p&gt;I debugged the unit test, and interestingly, for some queries in mapjoin_hook.q, Hive will skip some tasks, which may contain HTS, therefore &quot;Not a directory&quot; error will happen. The plan looks correct to me, and everything looks normal until &lt;tt&gt;SparkTask#execute&lt;/tt&gt;. But after that, the execution never go into &lt;tt&gt;SparkMapRecordHandler&lt;/tt&gt;. The test even fail with spark.master=local&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;.&lt;/p&gt;</comment>
                            <comment id="14233359" author="csun" created="Wed, 3 Dec 2014 19:09:24 +0000"  >&lt;p&gt;Interesting, somehow in &lt;tt&gt;SparkReduceSinkMapJoinProc&lt;/tt&gt;, the value for &lt;tt&gt;hive.mapjoin.localtask.max.memory.usage&lt;/tt&gt;, which is read from HiveConf, is 0.00, which causes the hash table memory issue. The default value is set to 0.90, and I didn&apos;t see it get overwritten anywhere.&lt;/p&gt;</comment>
                            <comment id="14233535" author="csun" created="Wed, 3 Dec 2014 21:22:04 +0000"  >&lt;p&gt;Just worked with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=szehon&quot; class=&quot;user-hover&quot; rel=&quot;szehon&quot;&gt;Szehon Ho&lt;/a&gt; on this issue and he noticed instantly that this test explicitly set the memory usage to be 0.0001, which is why it&apos;s failing. The test intentionally makes the mapjoin to fail and test whether it can be recovered by the backup task.&lt;/p&gt;

&lt;p&gt;Since in spark branch we don&apos;t use conditional task for mapjoin as until now, I think the &quot;Status: Failed&quot; messages in output is OK.&lt;/p&gt;</comment>
                            <comment id="14233600" author="csun" created="Wed, 3 Dec 2014 22:13:53 +0000"  >&lt;p&gt;Closing it now, since the error message is expected.&lt;/p&gt;</comment>
                            <comment id="14238729" author="csun" created="Tue, 9 Dec 2014 00:17:27 +0000"  >&lt;p&gt;Created follow up JIRA &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-9046&quot; title=&quot;Skip child tasks if parent task failed [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-9046&quot;&gt;&lt;del&gt;HIVE-9046&lt;/del&gt;&lt;/a&gt; to track the issue that child tasks continue to run after parent task failed.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12754699">HIVE-8836</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12760310">HIVE-9046</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 27 Nov 2014 06:14:18 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 7 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22tzb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8982] IndexOutOfBounds exception in mapjoin [Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8982</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;There are sometimes random failures in spark mapjoin during unit tests like:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.IndexOutOfBoundsException: Index: 1, Size: 1
	at org.apache.hadoop.hive.ql.exec.SparkHashTableSinkOperator.closeOp(SparkHashTableSinkOperator.java:83)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:598)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:610)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:610)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:610)
	at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.close(SparkMapRecordHandler.java:185)
	at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.closeRecordProcessor(HiveMapFunctionResultList.java:57)
	at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.hasNext(HiveBaseFunctionResultList.java:108)
	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:41)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$2.apply(AsyncRDDActions.scala:115)
	at org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$2.apply(AsyncRDDActions.scala:115)
	at org.apache.spark.SparkContext$$anonfun$30.apply(SparkContext.scala:1365)
	at org.apache.spark.SparkContext$$anonfun$30.apply(SparkContext.scala:1365)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.IndexOutOfBoundsException: Index: 1, Size: 1
	at java.util.ArrayList.rangeCheck(ArrayList.java:635)
	at java.util.ArrayList.get(ArrayList.java:411)
	at org.apache.hadoop.hive.ql.exec.persistence.MapJoinEagerRowContainer.first(MapJoinEagerRowContainer.java:70)
	at org.apache.hadoop.hive.ql.exec.persistence.MapJoinEagerRowContainer.write(MapJoinEagerRowContainer.java:150)
	at org.apache.hadoop.hive.ql.exec.persistence.MapJoinTableContainerSerDe.persist(MapJoinTableContainerSerDe.java:167)
	at org.apache.hadoop.hive.ql.exec.SparkHashTableSinkOperator.flushToFile(SparkHashTableSinkOperator.java:128)
	at org.apache.hadoop.hive.ql.exec.SparkHashTableSinkOperator.closeOp(SparkHashTableSinkOperator.java:77)
	... 20 more
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.IndexOutOfBoundsException: Index: 1, Size: 1
	at org.apache.hadoop.hive.ql.exec.SparkHashTableSinkOperator.closeOp(SparkHashTableSinkOperator.java:83)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:598)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:610)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:610)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:610)
	at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.close(SparkMapRecordHandler.java:185)
	at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.closeRecordProcessor(HiveMapFunctionResultList.java:57)
	at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.hasNext(HiveBaseFunctionResultList.java:108)
	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:41)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$2.apply(AsyncRDDActions.scala:115)
	at org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$2.apply(AsyncRDDActions.scala:115)
	at org.apache.spark.SparkContext$$anonfun$30.apply(SparkContext.scala:1365)
	at org.apache.spark.SparkContext$$anonfun$30.apply(SparkContext.scala:1365)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.IndexOutOfBoundsException: Index: 1, Size: 1
	at java.util.ArrayList.rangeCheck(ArrayList.java:635)
	at java.util.ArrayList.get(ArrayList.java:411)
	at org.apache.hadoop.hive.ql.exec.persistence.MapJoinEagerRowContainer.first(MapJoinEagerRowContainer.java:70)
	at org.apache.hadoop.hive.ql.exec.persistence.MapJoinEagerRowContainer.write(MapJoinEagerRowContainer.java:150)
	at org.apache.hadoop.hive.ql.exec.persistence.MapJoinTableContainerSerDe.persist(MapJoinTableContainerSerDe.java:167)
	at org.apache.hadoop.hive.ql.exec.SparkHashTableSinkOperator.flushToFile(SparkHashTableSinkOperator.java:128)
	at org.apache.hadoop.hive.ql.exec.SparkHashTableSinkOperator.closeOp(SparkHashTableSinkOperator.java:77)
	... 20 more
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.IndexOutOfBoundsException: Index: 1, Size: 1
	at org.apache.hadoop.hive.ql.exec.SparkHashTableSinkOperator.closeOp(SparkHashTableSinkOperator.java:83)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:598)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:610)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:610)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:610)
	at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.close(SparkMapRecordHandler.java:185)
	at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.closeRecordProcessor(HiveMapFunctionResultList.java:57)
	at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.hasNext(HiveBaseFunctionResultList.java:108)
	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:41)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$2.apply(AsyncRDDActions.scala:115)
	at org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$2.apply(AsyncRDDActions.scala:115)
	at org.apache.spark.SparkContext$$anonfun$30.apply(SparkContext.scala:1365)
	at org.apache.spark.SparkContext$$anonfun$30.apply(SparkContext.scala:1365)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.IndexOutOfBoundsException: Index: 1, Size: 1
	at java.util.ArrayList.rangeCheck(ArrayList.java:635)
	at java.util.ArrayList.get(ArrayList.java:411)
	at org.apache.hadoop.hive.ql.exec.persistence.MapJoinEagerRowContainer.first(MapJoinEagerRowContainer.java:70)
	at org.apache.hadoop.hive.ql.exec.persistence.MapJoinEagerRowContainer.write(MapJoinEagerRowContainer.java:150)
	at org.apache.hadoop.hive.ql.exec.persistence.MapJoinTableContainerSerDe.persist(MapJoinTableContainerSerDe.java:167)
	at org.apache.hadoop.hive.ql.exec.SparkHashTableSinkOperator.flushToFile(SparkHashTableSinkOperator.java:128)
	at org.apache.hadoop.hive.ql.exec.SparkHashTableSinkOperator.closeOp(SparkHashTableSinkOperator.java:77)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12758112">HIVE-8982</key>
            <summary>IndexOutOfBounds exception in mapjoin [Spark Branch]</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12752296">HIVE-8699</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="csun">Chao Sun</assignee>
                                    <reporter username="szehon">Szehon Ho</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Nov 2014 02:11:36 +0000</created>
                <updated>Fri, 29 May 2015 02:32:08 +0000</updated>
                            <resolved>Sat, 13 Dec 2014 15:32:55 +0000</resolved>
                                    <version>spark-branch</version>
                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="14227139" author="szehon" created="Thu, 27 Nov 2014 02:12:05 +0000"  >&lt;p&gt;Also FYI if you&apos;ve seen the issue, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;Chao Sun&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14227234" author="xuefuz" created="Thu, 27 Nov 2014 03:55:26 +0000"  >&lt;p&gt;I assume the q test is mapjoin_mapjoin.q (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8985&quot; title=&quot;Investigate mapjoin_mapjoin.q failure [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8985&quot;&gt;&lt;del&gt;HIVE-8985&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;</comment>
                            <comment id="14227237" author="szehon" created="Thu, 27 Nov 2014 03:58:43 +0000"  >&lt;p&gt;Yea you&apos;re right but it also happens in other ones like:  &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/450/testReport/org.apache.hadoop.hive.cli/TestSparkCliDriver/testCliDriver_auto_join31/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/450/testReport/org.apache.hadoop.hive.cli/TestSparkCliDriver/testCliDriver_auto_join31&lt;/a&gt;  That&apos;s why I didnt think one specific test that has this, it seems to be somewhat random.&lt;/p&gt;</comment>
                            <comment id="14227790" author="csun" created="Thu, 27 Nov 2014 16:14:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=szehon&quot; class=&quot;user-hover&quot; rel=&quot;szehon&quot;&gt;Szehon Ho&lt;/a&gt; OK, I&apos;ll take a look.&lt;/p&gt;</comment>
                            <comment id="14230548" author="csun" created="Mon, 1 Dec 2014 22:09:59 +0000"  >&lt;p&gt;I ran mapjoin_mapjoin and auto_join31 each 10 times on the latest spark branch, but couldn&apos;t reproduce the issue. Is this still occuring on jenkins?&lt;/p&gt;</comment>
                            <comment id="14230567" author="szehon" created="Mon, 1 Dec 2014 22:23:28 +0000"  >&lt;p&gt;Yea.  I still see some random failures in mapjoin tests like:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/464/testReport/junit/org.apache.hadoop.hive.cli/TestSparkCliDriver/testCliDriver_mapjoin_hook/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/464/testReport/junit/org.apache.hadoop.hive.cli/TestSparkCliDriver/testCliDriver_mapjoin_hook/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Usually when I get those, I see this exception.  I didnt dig too deep into the latest random failure logs to confirm again though.&lt;/p&gt;</comment>
                            <comment id="14230568" author="xuefuz" created="Mon, 1 Dec 2014 22:23:47 +0000"  >&lt;p&gt;It doesn&apos;t seem they are happening any more. Feel free to close this.&lt;/p&gt;</comment>
                            <comment id="14230572" author="csun" created="Mon, 1 Dec 2014 22:26:14 +0000"  >&lt;p&gt;OK, closing for now.&lt;/p&gt;</comment>
                            <comment id="14230583" author="szehon" created="Mon, 1 Dec 2014 22:37:09 +0000"  >&lt;p&gt;I dug a little and found the exception again here as part of run 464.  See &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-464/failed/TestSparkCliDriver-groupby_complex_types.q-auto_join9.q-groupby_map_ppr.q-and-12-more/spark.log&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-464/failed/TestSparkCliDriver-groupby_complex_types.q-auto_join9.q-groupby_map_ppr.q-and-12-more/spark.log&lt;/a&gt;.  I think its still unresolved..&lt;/p&gt;</comment>
                            <comment id="14230588" author="szehon" created="Mon, 1 Dec 2014 22:39:18 +0000"  >&lt;p&gt;Sorry this is the &quot;Not a directory&quot; exception that was closed in the other JIRA..&lt;/p&gt;</comment>
                            <comment id="14233961" author="csun" created="Thu, 4 Dec 2014 06:56:01 +0000"  >&lt;p&gt;This issue is happening again, while running CLI.&lt;/p&gt;</comment>
                            <comment id="14242786" author="csun" created="Thu, 11 Dec 2014 16:57:19 +0000"  >&lt;p&gt;This one is quite interesting: in &lt;tt&gt;MapJoinEagerRowContainer#first&lt;/tt&gt;, &lt;tt&gt;index&lt;/tt&gt; is explicitly set to 0 before being used.&lt;br/&gt;
This row container maybe is shared between threads.&lt;/p&gt;</comment>
                            <comment id="14243363" author="csun" created="Thu, 11 Dec 2014 23:38:52 +0000"  >&lt;p&gt;The problem seems to be related to the static &lt;tt&gt;HashTableSinkOperator#EMPTY_ROW_CONTAINER&lt;/tt&gt;, which is shared between threads. &lt;/p&gt;</comment>
                            <comment id="14243389" author="csun" created="Thu, 11 Dec 2014 23:54:16 +0000"  >&lt;p&gt;Think more on this issue, imaging there are two threads (A and B) who share the same static container.&lt;br/&gt;
Now A is calling &lt;tt&gt;MapJoinEagerRowContainer#first()&lt;/tt&gt;, which first set &lt;tt&gt;index&lt;/tt&gt; to 0, and passed the if check. Then, thread B enters&lt;br/&gt;
&lt;tt&gt;MapJoinEagerRowContainer#next()&lt;/tt&gt;, which increment &lt;tt&gt;index&lt;/tt&gt; to 1. Last, A calls &lt;tt&gt;get&lt;/tt&gt; on the list - with &lt;tt&gt;index&lt;/tt&gt; being 1, which failed with exception.&lt;/p&gt;

&lt;p&gt;I&apos;m proposing to make the &lt;tt&gt;HashTableSinkOperator#EMPTY_ROW_CONTAINER&lt;/tt&gt; non-static. This should solve the issue.&lt;/p&gt;</comment>
                            <comment id="14243395" author="csun" created="Thu, 11 Dec 2014 23:57:41 +0000"  >&lt;p&gt;... or we could protect these two methods with locks.&lt;/p&gt;</comment>
                            <comment id="14244623" author="csun" created="Fri, 12 Dec 2014 19:04:36 +0000"  >&lt;p&gt;Making &lt;tt&gt;HashTableSinkOperator#EMPTY_ROW_CONTAINER&lt;/tt&gt; non-static.&lt;/p&gt;</comment>
                            <comment id="14245164" author="hiveqa" created="Sat, 13 Dec 2014 03:47:01 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12686916/HIVE-8982.1-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12686916/HIVE-8982.1-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 7 failed/errored test(s), 7261 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join25
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_join4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_25
org.apache.hive.hcatalog.streaming.TestStreaming.testEndpointConnection
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/532/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/532/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/532/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/532/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-532/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-532/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 7 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12686916 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14245169" author="csun" created="Sat, 13 Dec 2014 03:56:02 +0000"  >&lt;p&gt;Not sure why &lt;tt&gt;join25.q&lt;/tt&gt; failed - it runs OK on my machine.&lt;/p&gt;</comment>
                            <comment id="14245173" author="xuefuz" created="Sat, 13 Dec 2014 04:12:34 +0000"  >&lt;p&gt;join25.q failed because:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2014-12-12 19:14:50,084 ERROR [main]: ql.Driver (SessionState.java:printError(838)) - FAILED: SemanticException Failed to get spark memory/core info: java.util.concurrent.TimeoutException
org.apache.hadoop.hive.ql.parse.SemanticException: Failed to get spark memory/core info: java.util.concurrent.TimeoutException
        at org.apache.hadoop.hive.ql.optimizer.spark.SetSparkReducerParallelism.process(SetSparkReducerParallelism.java:120)
        at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)
        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:94)
        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:78)
        at org.apache.hadoop.hive.ql.lib.ForwardWalker.walk(ForwardWalker.java:79)
        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:109)
        at org.apache.hadoop.hive.ql.parse.spark.SparkCompiler.optimizeOperatorPlan(SparkCompiler.java:134)
        at org.apache.hadoop.hive.ql.parse.TaskCompiler.compile(TaskCompiler.java:99)
        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10202)
        at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:221)
        at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:74)
        at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:221)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:420)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:306)
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1108)
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1170)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1045)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1035)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:199)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:151)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:362)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:297)
        at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:837)
        at org.apache.hadoop.hive.cli.TestSparkCliDriver.runTest(TestSparkCliDriver.java:234)
        at org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join25(TestSparkCliDriver.java:162)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at junit.framework.TestCase.runTest(TestCase.java:176)
        at junit.framework.TestCase.runBare(TestCase.java:141)
        at junit.framework.TestResult$1.protect(TestResult.java:122)
        at junit.framework.TestResult.runProtected(TestResult.java:142)
        at junit.framework.TestResult.run(TestResult.java:125)
        at junit.framework.TestCase.run(TestCase.java:129)
        at junit.framework.TestSuite.runTest(TestSuite.java:255)
        at junit.framework.TestSuite.run(TestSuite.java:250)
        at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:84)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:264)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:124)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:200)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:153)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)
Caused by: java.util.concurrent.TimeoutException
        at io.netty.util.concurrent.AbstractFuture.get(AbstractFuture.java:49)
        at org.apache.hive.spark.client.JobHandleImpl.get(JobHandleImpl.java:74)
        at org.apache.hive.spark.client.JobHandleImpl.get(JobHandleImpl.java:35)
        at org.apache.hadoop.hive.ql.exec.spark.RemoteHiveSparkClient.getExecutorCount(RemoteHiveSparkClient.java:92)
        at org.apache.hadoop.hive.ql.exec.spark.session.SparkSessionImpl.getMemoryAndCores(SparkSessionImpl.java:77)
        at org.apache.hadoop.hive.ql.optimizer.spark.SetSparkReducerParallelism.process(SetSparkReducerParallelism.java:118)
        ... 43 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Chengxiang has a patch to fix this. On the other hand, I&apos;m not sure why ppd_join4.q and smb_mapjoin_25.q failed.&lt;/p&gt;</comment>
                            <comment id="14245177" author="xuefuz" created="Sat, 13 Dec 2014 04:18:46 +0000"  >&lt;p&gt;Actually Chengxiang&apos;s patch (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-9079&quot; title=&quot;Hive hangs while failed to get executorCount[Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-9079&quot;&gt;&lt;del&gt;HIVE-9079&lt;/del&gt;&lt;/a&gt;) is to timeout the request rather than letting the driver hang. This is a reliability issue with RSC.&lt;/p&gt;</comment>
                            <comment id="14245181" author="csun" created="Sat, 13 Dec 2014 04:23:16 +0000"  >&lt;p&gt;The &quot;Status: Failed&quot; messages for ppd_join4.q and smb_mapjoin_25.q are actually in the committed golden files. &lt;/p&gt;</comment>
                            <comment id="14245191" author="xuefuz" created="Sat, 13 Dec 2014 04:34:15 +0000"  >&lt;p&gt;That&apos;s good. +1&lt;/p&gt;</comment>
                            <comment id="14245216" author="xuefuz" created="Sat, 13 Dec 2014 05:24:24 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;Chao Sun&lt;/a&gt;, for some reason, I wasn&apos;t able to generate the right .out for ppd_join4.q and smb_mapjoin_25.q. Could you also try? Thanks.&lt;/p&gt;</comment>
                            <comment id="14245217" author="csun" created="Sat, 13 Dec 2014 05:40:46 +0000"  >&lt;p&gt;OK, let me try it.&lt;/p&gt;</comment>
                            <comment id="14245220" author="csun" created="Sat, 13 Dec 2014 05:53:25 +0000"  >&lt;p&gt;Regenerated some golden files.&lt;/p&gt;</comment>
                            <comment id="14245305" author="hiveqa" created="Sat, 13 Dec 2014 12:05:18 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12687022/HIVE-8982.2-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12687022/HIVE-8982.2-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 7261 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyCommit
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/536/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/536/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/536/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/536/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-536/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-536/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12687022 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14245384" author="xuefuz" created="Sat, 13 Dec 2014 15:32:55 +0000"  >&lt;p&gt;Committed to Spark branch. Thanks to Chao for this nice finding and fix.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12761536">HIVE-9094</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12686916" name="HIVE-8982.1-spark.patch" size="1509" author="csun" created="Fri, 12 Dec 2014 19:03:41 +0000"/>
                            <attachment id="12687022" name="HIVE-8982.2-spark.patch" size="3106" author="csun" created="Sat, 13 Dec 2014 05:53:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 27 Nov 2014 03:55:26 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 6 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22tzr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8983] PTest Backup spark.log in addition to hive.log</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8983</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12758119">HIVE-8983</key>
            <summary>PTest Backup spark.log in addition to hive.log</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="brocknoland">Brock Noland</assignee>
                                    <reporter username="brocknoland">Brock Noland</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Nov 2014 02:47:28 +0000</created>
                <updated>Tue, 8 Dec 2015 21:29:10 +0000</updated>
                            <resolved>Thu, 27 Nov 2014 16:13:40 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="14227185" author="szehon" created="Thu, 27 Nov 2014 02:51:48 +0000"  >&lt;p&gt;+1 looks ok to me&lt;/p&gt;</comment>
                            <comment id="14227494" author="hiveqa" created="Thu, 27 Nov 2014 10:41:01 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12683987/HIVE-8983.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12683987/HIVE-8983.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 6692 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestParquetDirect - did not produce a TEST-*.xml file
TestPrimitiveObjectInspectorFactory - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mapjoin_mapjoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1923/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1923/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1923/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1923/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1923/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1923/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12683987 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14227788" author="brocknoland" created="Thu, 27 Nov 2014 16:13:40 +0000"  >&lt;p&gt;Thank you! I have committed this to trunk!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12920196">HIVE-12621</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12683987" name="HIVE-8983.patch" size="672" author="brocknoland" created="Thu, 27 Nov 2014 02:47:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 27 Nov 2014 02:51:48 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22u1b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8984] Enable job metrics/statistics gathering for remote spark context [Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8984</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;stats_counter fails due to this issue&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758121">HIVE-8984</key>
            <summary>Enable job metrics/statistics gathering for remote spark context [Spark Branch]</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12749643">HIVE-8548</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lirui">Rui Li</assignee>
                                    <reporter username="lirui">Rui Li</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Nov 2014 03:10:13 +0000</created>
                <updated>Fri, 29 May 2015 02:28:39 +0000</updated>
                            <resolved>Fri, 28 Nov 2014 01:22:51 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="14227552" author="lirui" created="Thu, 27 Nov 2014 11:39:11 +0000"  >&lt;p&gt;The refactor in this patch is mainly moving spark counter related classes to spark-client so they can be accessed by RSC.&lt;/p&gt;</comment>
                            <comment id="14227593" author="xuefuz" created="Thu, 27 Nov 2014 12:22:52 +0000"  >&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;Rui Li&lt;/a&gt;. I only briefly went thru the patch, it seems fine. However, I think we can hold the patch until &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8836&quot; title=&quot;Enable automatic tests with remote spark client [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8836&quot;&gt;&lt;del&gt;HIVE-8836&lt;/del&gt;&lt;/a&gt; gets in so as not to further distablize the build.&lt;/p&gt;</comment>
                            <comment id="14227596" author="xuefuz" created="Thu, 27 Nov 2014 12:31:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ruili&quot; class=&quot;user-hover&quot; rel=&quot;ruili&quot;&gt;Rui Li&lt;/a&gt;, quick question: what&apos;s the symptom of not having this patch? Does it fixes any failed tests?&lt;/p&gt;</comment>
                            <comment id="14227631" author="hiveqa" created="Thu, 27 Nov 2014 13:08:23 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684047/HIVE-8984.1-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684047/HIVE-8984.1-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 3 failed/errored test(s), 7181 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/459/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/459/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/459/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/459/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-459/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-459/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684047 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14227708" author="lirui" created="Thu, 27 Nov 2014 14:46:23 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;Xuefu Zhang&lt;/a&gt; - sorry for the lack of descriptions. The patch should fix &lt;tt&gt;stats_counter&lt;/tt&gt; which is failing in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8836&quot; title=&quot;Enable automatic tests with remote spark client [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8836&quot;&gt;&lt;del&gt;HIVE-8836&lt;/del&gt;&lt;/a&gt; due to lack of job metrics. I tried on my machine and the patch can properly gather the metrics for the queries in that test.&lt;/p&gt;</comment>
                            <comment id="14227909" author="xuefuz" created="Thu, 27 Nov 2014 19:19:49 +0000"  >&lt;p&gt;+1. I left a question on RB, but patch can be committed and I can get answer later.&lt;/p&gt;</comment>
                            <comment id="14228020" author="xuefuz" created="Fri, 28 Nov 2014 01:22:51 +0000"  >&lt;p&gt;Patch committed to trunk. Thanks to Rui for the contribution.&lt;/p&gt;</comment>
                            <comment id="14228039" author="lirui" created="Fri, 28 Nov 2014 01:54:16 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;Xuefu Zhang&lt;/a&gt; for the review!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12684047" name="HIVE-8984.1-spark.patch" size="47243" author="lirui" created="Thu, 27 Nov 2014 11:39:11 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 27 Nov 2014 12:22:52 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22u1r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8985] Investigate mapjoin_mapjoin.q failure [Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8985</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The recent test run showed result diff:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/453/testReport/org.apache.hadoop.hive.cli/TestSparkCliDriver/testCliDriver_mapjoin_mapjoin/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/453/testReport/org.apache.hadoop.hive.cli/TestSparkCliDriver/testCliDriver_mapjoin_mapjoin/&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758125">HIVE-8985</key>
            <summary>Investigate mapjoin_mapjoin.q failure [Spark Branch]</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12752296">HIVE-8699</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="xuefuz">Xuefu Zhang</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Nov 2014 03:39:31 +0000</created>
                <updated>Thu, 27 Nov 2014 03:54:21 +0000</updated>
                            <resolved>Thu, 27 Nov 2014 03:54:21 +0000</resolved>
                                                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="14227232" author="xuefuz" created="Thu, 27 Nov 2014 03:54:21 +0000"  >&lt;p&gt;Duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8982&quot; title=&quot;IndexOutOfBounds exception in mapjoin [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8982&quot;&gt;&lt;del&gt;HIVE-8982&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22u2n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8986] Add limit_partition_metadataonly.q in testconfiguration.properties [Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8986</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Adding limit_partition_metadataonly.q in testconfiguration.properties is missed in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8788&quot; title=&quot;UT: fix partition test case [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8788&quot;&gt;&lt;del&gt;HIVE-8788&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758141">HIVE-8986</key>
            <summary>Add limit_partition_metadataonly.q in testconfiguration.properties [Spark Branch]</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.svg">Trivial</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="chinnalalam">Chinna Rao Lalam</assignee>
                                    <reporter username="chinnalalam">Chinna Rao Lalam</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Nov 2014 06:32:56 +0000</created>
                <updated>Fri, 29 May 2015 02:29:48 +0000</updated>
                            <resolved>Thu, 27 Nov 2014 12:54:29 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="14227359" author="hiveqa" created="Thu, 27 Nov 2014 07:52:31 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12683999/HIVE-8986-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12683999/HIVE-8986-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 7181 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestHS2ImpersonationWithRemoteMS - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/457/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/457/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/457/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/457/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-457/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-457/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12683999 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14227612" author="xuefuz" created="Thu, 27 Nov 2014 12:53:09 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14227615" author="xuefuz" created="Thu, 27 Nov 2014 12:54:29 +0000"  >&lt;p&gt;Committed to Spark branch. Thanks, Chinna.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12683999" name="HIVE-8986-spark.patch" size="502" author="chinnalalam" created="Thu, 27 Nov 2014 06:34:59 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 27 Nov 2014 07:52:31 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22u67:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8987] slf4j classpath collision when starting hive metastore</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8987</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The latest release introduced a collision on the classpath. When I start the metatstore, I see an slf4j error:&lt;/p&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;apache-hive-0.14.0-bin/bin/hive --service metastore 
Starting Hive Metastore Server
SLF4J: &lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt; path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/vagrant/apache-hive-0.14.0-bin/lib/hive-jdbc-0.14.0-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http:&lt;span class=&quot;code-comment&quot;&gt;//www.slf4j.org/codes.html#multiple_bindings &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; an explanation.
&lt;/span&gt;SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment>&lt;p&gt;Apache Hadoop 2.5.2 and Apache Hive 0.14&lt;/p&gt;</environment>
        <key id="12758202">HIVE-8987</key>
            <summary>slf4j classpath collision when starting hive metastore</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="fs111">Andr&#233; Kelpe</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Nov 2014 12:06:07 +0000</created>
                <updated>Thu, 27 Nov 2014 12:06:07 +0000</updated>
                                            <version>0.14.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22uj3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-8988] Support advanced aggregation in Hive to Calcite path </title>
                <link>https://issues.apache.org/jira/browse/HIVE-8988</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;CLEAR LIBRARY CACHE&lt;/p&gt;

&lt;p&gt;To close the gap between Hive and Calcite, we need to support the translation of GroupingSets into Calcite; currently this is not implemented.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758229">HIVE-8988</key>
            <summary>Support advanced aggregation in Hive to Calcite path </summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jcamachorodriguez">Jesus Camacho Rodriguez</assignee>
                                    <reporter username="jcamachorodriguez">Jesus Camacho Rodriguez</reporter>
                        <labels>
                            <label>grouping</label>
                            <label>logical</label>
                            <label>optiq</label>
                    </labels>
                <created>Thu, 27 Nov 2014 14:43:13 +0000</created>
                <updated>Thu, 16 Apr 2015 07:47:59 +0000</updated>
                            <resolved>Thu, 8 Jan 2015 22:19:04 +0000</resolved>
                                    <version>0.15.0</version>
                                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="14242569" author="jcamachorodriguez" created="Thu, 11 Dec 2014 14:30:34 +0000"  >&lt;p&gt;The patch implements the AST-&amp;gt;Calcite and Calcite-&amp;gt;AST paths for grouping sets.&lt;/p&gt;

&lt;p&gt;The grouping__id function of Hive is computed relying on the group_id function in Calcite. &lt;/p&gt;

&lt;p&gt;As grouping sets in Calcite are represented using a boolean for every grouping column, a projection is added on top of the Aggregate operator in Calcite. The projection removes these columns, so taking the plan back to Hive AST afterwards is straightforward (column indices are right).&lt;/p&gt;</comment>
                            <comment id="14242596" author="jcamachorodriguez" created="Thu, 11 Dec 2014 14:32:30 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jpullokkaran&quot; class=&quot;user-hover&quot; rel=&quot;jpullokkaran&quot;&gt;Laljo John Pullokkaran&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=julianhyde&quot; class=&quot;user-hover&quot; rel=&quot;julianhyde&quot;&gt;Julian Hyde&lt;/a&gt;, can you take a look?&lt;/p&gt;</comment>
                            <comment id="14243272" author="hiveqa" created="Thu, 11 Dec 2014 22:31:01 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12686661/HIVE-8988.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12686661/HIVE-8988.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2045/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2045/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2045/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2045/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2045/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2045/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:166:7: 
Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_UNION KW_ALL&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:526:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1992 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/ql/plan/api/Query.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/ql/plan/api/Query.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java:[32,39] package org.apache.calcite.avatica.util does not exist
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[24,39] package org.apache.calcite.avatica.util does not exist
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:[13746,71] cannot find symbol
  symbol:   variable GROUP_ID
  location: class org.apache.calcite.sql.fun.SqlStdOperatorTable
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java:[313,7] cannot find symbol
  symbol:   class ByteString
  location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.RexNodeConverter
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java:[313,27] cannot find symbol
  symbol:   class ByteString
  location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.RexNodeConverter
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTConverter.java:[185,47] cannot find symbol
  symbol:   variable GROUP_ID
  location: class org.apache.calcite.sql.fun.SqlStdOperatorTable
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[148,7] cannot find symbol
  symbol:   class ByteString
  location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[148,24] cannot find symbol
  symbol:   class ByteString
  location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder
[INFO] 8 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [8.269s]
[INFO] Hive Shims Common ................................. SUCCESS [13.245s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [5.098s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [8.894s]
[INFO] Hive Shims Scheduler .............................. SUCCESS [2.288s]
[INFO] Hive Shims ........................................ SUCCESS [2.655s]
[INFO] Hive Common ....................................... SUCCESS [27.156s]
[INFO] Hive Serde ........................................ SUCCESS [14.918s]
[INFO] Hive Metastore .................................... SUCCESS [35.124s]
[INFO] Hive Ant Utilities ................................ SUCCESS [2.580s]
[INFO] Hive Query Language ............................... FAILURE [59.473s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive Accumulo Handler ............................. SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 3:02.721s
[INFO] Finished at: Thu Dec 11 17:29:33 EST 2014
[INFO] Final Memory: 89M/481M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java:[32,39] package org.apache.calcite.avatica.util does not exist
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[24,39] package org.apache.calcite.avatica.util does not exist
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:[13746,71] cannot find symbol
[ERROR] symbol:   variable GROUP_ID
[ERROR] location: class org.apache.calcite.sql.fun.SqlStdOperatorTable
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java:[313,7] cannot find symbol
[ERROR] symbol:   class ByteString
[ERROR] location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.RexNodeConverter
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java:[313,27] cannot find symbol
[ERROR] symbol:   class ByteString
[ERROR] location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.RexNodeConverter
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTConverter.java:[185,47] cannot find symbol
[ERROR] symbol:   variable GROUP_ID
[ERROR] location: class org.apache.calcite.sql.fun.SqlStdOperatorTable
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[148,7] cannot find symbol
[ERROR] symbol:   class ByteString
[ERROR] location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[148,24] cannot find symbol
[ERROR] symbol:   class ByteString
[ERROR] location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12686661 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14243533" author="julianhyde" created="Fri, 12 Dec 2014 01:07:50 +0000"  >&lt;p&gt;I am a bit surprised that translating GROUPING__ID to Calcite&apos;s GROUP_ID function works. The logic to expand it is in SqlToRelConverter, which Hive does not call (IIRC). How does it work?&lt;/p&gt;

&lt;p&gt;You don&apos;t need to call BitSets.toIter anymore. ImmutableBitSet implements Iterable (BitSet, which we used to use for Aggregate.groupKeys, does not).&lt;/p&gt;

&lt;p&gt;For &lt;tt&gt;ImmutableBitSet convert(int value)&lt;/tt&gt;, I&apos;ll add ImmutableBitSet.valueOf(long...). valueOf&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/error.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; would be equivalent to convert&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/error.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. You can migrate to it in a future version of Calcite, if you like.&lt;/p&gt;</comment>
                            <comment id="14243933" author="jcamachorodriguez" created="Fri, 12 Dec 2014 10:07:02 +0000"  >&lt;p&gt;Changed the patch so it does not call &lt;tt&gt;toIter(...)&lt;/tt&gt; method.&lt;/p&gt;</comment>
                            <comment id="14243936" author="jcamachorodriguez" created="Fri, 12 Dec 2014 10:13:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=julianhyde&quot; class=&quot;user-hover&quot; rel=&quot;julianhyde&quot;&gt;Julian Hyde&lt;/a&gt;, thanks for the comments.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I am a bit surprised that translating GROUPING__ID to Calcite&apos;s GROUP_ID function works. The logic to expand it is in SqlToRelConverter, which Hive does not call (IIRC). How does it work?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It works because we never call the function. In fact, when we go back from Calcite to Hive, the GROUP_ID call in the Calcite project operator is replaced by a pointer to the column containing the GROUPING__ID that comes out of the Hive GroupBy operator.&lt;/p&gt;</comment>
                            <comment id="14244310" author="julianhyde" created="Fri, 12 Dec 2014 16:04:42 +0000"  >&lt;p&gt;You&apos;d better make sure that that function isn&apos;t pushed down.&lt;/p&gt;</comment>
                            <comment id="14244390" author="jcamachorodriguez" created="Fri, 12 Dec 2014 16:18:10 +0000"  >&lt;blockquote&gt;
&lt;p&gt;You&apos;d better make sure that that function isn&apos;t pushed down.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I thought it would not be pushed through the GroupBy clause. Then, do you think it is better to formulate it in the translation to Calcite as grouping_id(e1,...) instead of group_id()? Then, as it is dependent on the other columns, it will not go down for sure. &lt;/p&gt;</comment>
                            <comment id="14244400" author="julianhyde" created="Fri, 12 Dec 2014 16:25:28 +0000"  >&lt;p&gt;It looks just like a function with no arguments, so Calcite will treat accordingly. &lt;/p&gt;

&lt;p&gt;You can&apos;t translate to grouping_id because that&apos;s a pseudo function too. Safest might be to translate it to &lt;tt&gt;$Foo(i0, i1, i2, i3, ...)&lt;/tt&gt; where i&amp;lt;i&amp;gt;n&amp;lt;/i&amp;gt; are the indicator columns, and look for it afterwards. The column references will prevent it from being pushed down. Putatively $Foo would expand to &lt;tt&gt;i0 + 2 * i1 + 4 * i2 + ...&lt;/tt&gt; (in fact the same logic that SqlToRelConverter translates GROUP_ID to) but it will be substituted before that ever happens.&lt;/p&gt;</comment>
                            <comment id="14244528" author="jcamachorodriguez" created="Fri, 12 Dec 2014 17:59:09 +0000"  >&lt;blockquote&gt;
&lt;p&gt;You can&apos;t translate to grouping_id because that&apos;s a pseudo function too.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I am trying to understand why &lt;tt&gt;grouping_id&lt;/tt&gt; would not be the right choice. Since &lt;tt&gt;grouping_id&lt;/tt&gt; has as arguments the column references &lt;tt&gt;i0, i1, i2, i3, ...&lt;/tt&gt;, we are certain that it won&apos;t get pushed down, right? That should be enough.&lt;/p&gt;

&lt;p&gt;Sorry about insisting, I&apos;m just trying to avoid creating another pseudo function &lt;tt&gt;$Foo&lt;/tt&gt; on my side if it is not really necessary.&lt;/p&gt;</comment>
                            <comment id="14244535" author="julianhyde" created="Fri, 12 Dec 2014 18:05:51 +0000"  >&lt;p&gt;If I wrote &lt;tt&gt;select f(deptno, gender), count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; from emp group by deptno, gender having f(deptno, gender) &amp;gt; 100&lt;/tt&gt; and f was a &quot;regular&quot; function, then Calcite could push it down. And you&apos;d probably want it to.&lt;/p&gt;

&lt;p&gt;So we&apos;d have to flag that &quot;grouping_id&quot; is not a regular function.&lt;/p&gt;

&lt;p&gt;In my approach you apply the $Foo function to the indicator columns, which do not exist until the Aggregate creates them, hence the function cannot be pushed down. (The call to $Foo could still be pulled up.)&lt;/p&gt;</comment>
                            <comment id="14244550" author="jcamachorodriguez" created="Fri, 12 Dec 2014 18:20:15 +0000"  >&lt;p&gt;OK, I was confused with the &lt;tt&gt;grouping_id&lt;/tt&gt; function, as I thought the input were the &lt;em&gt;indicator&lt;/em&gt; columns instead of the &lt;em&gt;grouping&lt;/em&gt; columns themselves. Now I get your point.&lt;/p&gt;

&lt;p&gt;Would that &lt;tt&gt;$foo&lt;/tt&gt; function be something interesting to have in Calcite itself? Meaning, a function that given &lt;em&gt;n&lt;/em&gt; booleans, computes the integer value as &lt;tt&gt;i0 + 2 * i1 + 4 * i2 + ...&lt;/tt&gt;? Otherwise, I&apos;ll implement it and keep it in Hive.&lt;/p&gt;</comment>
                            <comment id="14244585" author="julianhyde" created="Fri, 12 Dec 2014 18:38:22 +0000"  >&lt;p&gt;$Foo is probably not interesting to end-users, so let&apos;s keep it in Hive.  You should sub-class SqlInternalOperator. In SqlStdOperatorTable, you&apos;ll see $SLICE, $ELEMENT_SLICE, $SCALAR_QUERY and EXTEND are all examples of it.&lt;/p&gt;</comment>
                            <comment id="14245157" author="hiveqa" created="Sat, 13 Dec 2014 03:31:55 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12686821/HIVE-8988.01.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12686821/HIVE-8988.01.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2065/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2065/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2065/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2065/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2065/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2065/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
warning(200): IdentifiersParser.g:127:5: 
Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:138:5: 
Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:149:5: 
Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:166:7: 
Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_UNION KW_ALL&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:526:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---
Downloading: http://conjars.org/repo/org/apache/calcite/calcite/1.0.0-incubating-SNAPSHOT/maven-metadata.xml
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1994 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/ql/plan/api/Query.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/ql/plan/api/Query.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java:[32,39] package org.apache.calcite.avatica.util does not exist
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[24,39] package org.apache.calcite.avatica.util does not exist
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:[13748,71] cannot find symbol
  symbol:   variable GROUP_ID
  location: class org.apache.calcite.sql.fun.SqlStdOperatorTable
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTConverter.java:[185,47] cannot find symbol
  symbol:   variable GROUP_ID
  location: class org.apache.calcite.sql.fun.SqlStdOperatorTable
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[148,7] cannot find symbol
  symbol:   class ByteString
  location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[148,24] cannot find symbol
  symbol:   class ByteString
  location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder
[INFO] 6 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [19.210s]
[INFO] Hive Shims Common ................................. SUCCESS [27.585s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [7.259s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [27.721s]
[INFO] Hive Shims Scheduler .............................. SUCCESS [2.558s]
[INFO] Hive Shims ........................................ SUCCESS [2.618s]
[INFO] Hive Common ....................................... SUCCESS [26.852s]
[INFO] Hive Serde ........................................ SUCCESS [17.845s]
[INFO] Hive Metastore .................................... SUCCESS [42.746s]
[INFO] Hive Ant Utilities ................................ SUCCESS [1.978s]
[INFO] Hive Query Language ............................... FAILURE [57.813s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive Accumulo Handler ............................. SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 3:58.855s
[INFO] Finished at: Fri Dec 12 22:30:41 EST 2014
[INFO] Final Memory: 86M/746M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java:[32,39] package org.apache.calcite.avatica.util does not exist
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[24,39] package org.apache.calcite.avatica.util does not exist
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:[13748,71] cannot find symbol
[ERROR] symbol:   variable GROUP_ID
[ERROR] location: class org.apache.calcite.sql.fun.SqlStdOperatorTable
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTConverter.java:[185,47] cannot find symbol
[ERROR] symbol:   variable GROUP_ID
[ERROR] location: class org.apache.calcite.sql.fun.SqlStdOperatorTable
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[148,7] cannot find symbol
[ERROR] symbol:   class ByteString
[ERROR] location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[148,24] cannot find symbol
[ERROR] symbol:   class ByteString
[ERROR] location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12686821 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14245395" author="jcamachorodriguez" created="Sat, 13 Dec 2014 16:09:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=julianhyde&quot; class=&quot;user-hover&quot; rel=&quot;julianhyde&quot;&gt;Julian Hyde&lt;/a&gt;, thanks for the feedback. I uploaded a new patch.&lt;/p&gt;</comment>
                            <comment id="14245408" author="hiveqa" created="Sat, 13 Dec 2014 16:47:21 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12687044/HIVE-8988.02.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12687044/HIVE-8988.02.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2074/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2074/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2074/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2074/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2074/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2074/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:115:5: 
Decision can match input such as &quot;KW_CLUSTER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:127:5: 
Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:138:5: 
Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:149:5: 
Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:166:7: 
Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_UNION KW_ALL&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:526:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---
Downloading: http://conjars.org/repo/org/apache/calcite/calcite/1.0.0-incubating-SNAPSHOT/maven-metadata.xml
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1995 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/ql/plan/api/Query.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/ql/plan/api/Query.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java:[32,39] package org.apache.calcite.avatica.util does not exist
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[24,39] package org.apache.calcite.avatica.util does not exist
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[148,7] cannot find symbol
  symbol:   class ByteString
  location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[148,24] cannot find symbol
  symbol:   class ByteString
  location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder
[INFO] 4 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [15.675s]
[INFO] Hive Shims Common ................................. SUCCESS [26.604s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [7.310s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [26.525s]
[INFO] Hive Shims Scheduler .............................. SUCCESS [2.443s]
[INFO] Hive Shims ........................................ SUCCESS [2.501s]
[INFO] Hive Common ....................................... SUCCESS [27.723s]
[INFO] Hive Serde ........................................ SUCCESS [19.131s]
[INFO] Hive Metastore .................................... SUCCESS [42.751s]
[INFO] Hive Ant Utilities ................................ SUCCESS [2.105s]
[INFO] Hive Query Language ............................... FAILURE [1:00.272s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive Accumulo Handler ............................. SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 3:56.850s
[INFO] Finished at: Sat Dec 13 11:46:07 EST 2014
[INFO] Final Memory: 93M/761M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java:[32,39] package org.apache.calcite.avatica.util does not exist
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[24,39] package org.apache.calcite.avatica.util does not exist
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[148,7] cannot find symbol
[ERROR] symbol:   class ByteString
[ERROR] location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[148,24] cannot find symbol
[ERROR] symbol:   class ByteString
[ERROR] location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12687044 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14246548" author="hiveqa" created="Mon, 15 Dec 2014 10:55:32 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12687218/HIVE-8988.02.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12687218/HIVE-8988.02.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2079/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2079/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2079/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2079/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2079/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2079/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:115:5: 
Decision can match input such as &quot;KW_CLUSTER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:127:5: 
Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:138:5: 
Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:149:5: 
Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:166:7: 
Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:179:5: 
Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:270:5: 
Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_UNION KW_ALL&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:401:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:526:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-exec ---
Downloading: http://conjars.org/repo/org/apache/calcite/calcite/1.0.0-incubating-SNAPSHOT/maven-metadata.xml
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-exec ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1995 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/ql/plan/api/Query.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/ql/plan/api/Query.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java:[32,39] package org.apache.calcite.avatica.util does not exist
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[24,39] package org.apache.calcite.avatica.util does not exist
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[148,7] cannot find symbol
  symbol:   class ByteString
  location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[148,24] cannot find symbol
  symbol:   class ByteString
  location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder
[INFO] 4 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [15.025s]
[INFO] Hive Shims Common ................................. SUCCESS [26.230s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [7.093s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [27.462s]
[INFO] Hive Shims Scheduler .............................. SUCCESS [2.583s]
[INFO] Hive Shims ........................................ SUCCESS [2.790s]
[INFO] Hive Common ....................................... SUCCESS [27.406s]
[INFO] Hive Serde ........................................ SUCCESS [17.275s]
[INFO] Hive Metastore .................................... SUCCESS [40.886s]
[INFO] Hive Ant Utilities ................................ SUCCESS [2.043s]
[INFO] Hive Query Language ............................... FAILURE [1:01.467s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive Accumulo Handler ............................. SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 3:54.415s
[INFO] Finished at: Mon Dec 15 05:54:17 EST 2014
[INFO] Final Memory: 95M/706M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java:[32,39] package org.apache.calcite.avatica.util does not exist
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[24,39] package org.apache.calcite.avatica.util does not exist
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[148,7] cannot find symbol
[ERROR] symbol:   class ByteString
[ERROR] location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java:[148,24] cannot find symbol
[ERROR] symbol:   class ByteString
[ERROR] location: class org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12687218 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14248652" author="jpullokkaran" created="Tue, 16 Dec 2014 18:43:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jcamachorodriguez&quot; class=&quot;user-hover&quot; rel=&quot;jcamachorodriguez&quot;&gt;Jesus Camacho Rodriguez&lt;/a&gt; could you replied the patch. Now after Sergeys patch CBO is on by default; we want to make sure all Cube/Rollup/GroupingSet tests succeed.&lt;/p&gt;</comment>
                            <comment id="14248706" author="jcamachorodriguez" created="Tue, 16 Dec 2014 19:06:28 +0000"  >&lt;p&gt;.03 is the new patch with CBO enabled.&lt;/p&gt;</comment>
                            <comment id="14249396" author="hiveqa" created="Wed, 17 Dec 2014 03:18:53 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12687542/HIVE-8988.03.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12687542/HIVE-8988.03.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2099/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2099/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2099/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2099/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2099/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2099/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-2099/source-prep.txt
+ [[ true == \t\r\u\e ]]
+ rm -rf ivy maven
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;shims/0.20S/pom.xml&apos;
Reverted &apos;shims/0.23/pom.xml&apos;
Reverted &apos;shims/scheduler/pom.xml&apos;
Reverted &apos;jdbc/pom.xml&apos;
Reverted &apos;ql/pom.xml&apos;
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20S/target shims/0.23/target shims/aggregator/target shims/common/target shims/scheduler/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit-hadoop2/target itests/hive-minikdc/target itests/hive-unit/target itests/custom-serde/target itests/util/target hcatalog/target hcatalog/core/target hcatalog/streaming/target hcatalog/server-extensions/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target hcatalog/hcatalog-pig-adapter/target accumulo-handler/target hwi/target common/target common/src/gen contrib/target service/target serde/target beeline/target odbc/target cli/target ql/dependency-reduced-pom.xml ql/target
+ svn update
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTBuilder.java

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
Updated external to revision 1646143.

Updated to revision 1646143.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12687542 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14249683" author="jcamachorodriguez" created="Wed, 17 Dec 2014 10:12:00 +0000"  >&lt;p&gt;Patch after &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-9129&quot; title=&quot;Migrate to newer Calcite snapshot, where ByteString is now in org.apache.calcite.avatica.util&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-9129&quot;&gt;&lt;del&gt;HIVE-9129&lt;/del&gt;&lt;/a&gt; has been applied to the trunk.&lt;/p&gt;</comment>
                            <comment id="14250226" author="hiveqa" created="Wed, 17 Dec 2014 18:06:10 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12687709/HIVE-8988.04.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12687709/HIVE-8988.04.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 10 failed/errored test(s), 6713 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_annotate_stats_groupby
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_annotate_stats_groupby2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_grouping_id2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_grouping_sets1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_grouping_sets2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_grouping_sets3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_grouping_sets5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_rollup1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_infer_bucket_sort_grouping_operators
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2111/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2111/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2111/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2111/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2111/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2111/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 10 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12687709 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14252516" author="jcamachorodriguez" created="Thu, 18 Dec 2014 23:13:31 +0000"  >&lt;p&gt;Patch with new golden files and new test to check that Filter is pushed through Aggregate with grouping sets by Calcite rule.&lt;/p&gt;</comment>
                            <comment id="14252895" author="hiveqa" created="Fri, 19 Dec 2014 04:10:36 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12688175/HIVE-8988.05.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12688175/HIVE-8988.05.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 6719 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_grouping_id2
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2136/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2136/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2136/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2136/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2136/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2136/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12688175 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14253269" author="jcamachorodriguez" created="Fri, 19 Dec 2014 10:57:54 +0000"  >&lt;p&gt;If the Calcite library is refreshed in Hive, that test passes; the problem has been fixed in &lt;a href=&quot;https://issues.apache.org/jira/browse/CALCITE-542&quot; title=&quot;Support for Aggregate with grouping sets in RelMdColumnOrigins&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CALCITE-542&quot;&gt;&lt;del&gt;CALCITE-542&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14253730" author="julianhyde" created="Fri, 19 Dec 2014 18:22:12 +0000"  >&lt;p&gt;I&apos;ve pushed a snapshot of Calcite that contains the fix to &lt;a href=&quot;https://issues.apache.org/jira/browse/CALCITE-542&quot; title=&quot;Support for Aggregate with grouping sets in RelMdColumnOrigins&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CALCITE-542&quot;&gt;&lt;del&gt;CALCITE-542&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14253732" author="jcamachorodriguez" created="Fri, 19 Dec 2014 18:22:52 +0000"  >&lt;p&gt;Reuploaded path to trigger a new build.&lt;/p&gt;</comment>
                            <comment id="14254222" author="hiveqa" created="Fri, 19 Dec 2014 23:24:38 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12688371/HIVE-8988.05.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12688371/HIVE-8988.05.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 6719 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_nonmr_fetch
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_virtual_column
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2145/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2145/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2145/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2145/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2145/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2145/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12688371 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14254547" author="jcamachorodriguez" created="Sat, 20 Dec 2014 06:25:34 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=julianhyde&quot; class=&quot;user-hover&quot; rel=&quot;julianhyde&quot;&gt;Julian Hyde&lt;/a&gt;. Tests fails are not related to the patch, I think it is ready to go. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jpullokkaran&quot; class=&quot;user-hover&quot; rel=&quot;jpullokkaran&quot;&gt;Laljo John Pullokkaran&lt;/a&gt; , what do you think?&lt;/p&gt;</comment>
                            <comment id="14264542" author="jcamachorodriguez" created="Mon, 5 Jan 2015 12:25:35 +0000"  >&lt;p&gt;Rebased patch. Added recognition of CUBE and ROLLUP in ASTConverter as suggested by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jpullokkaran&quot; class=&quot;user-hover&quot; rel=&quot;jpullokkaran&quot;&gt;Laljo John Pullokkaran&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14264671" author="hiveqa" created="Mon, 5 Jan 2015 15:22:32 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12690076/HIVE-8988.06.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12690076/HIVE-8988.06.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 6724 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_infer_bucket_sort_grouping_operators
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2252/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2252/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2252/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2252/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2252/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2252/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12690076 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14264707" author="jcamachorodriguez" created="Mon, 5 Jan 2015 15:48:47 +0000"  >&lt;p&gt;Updating golden file.&lt;/p&gt;</comment>
                            <comment id="14264833" author="hiveqa" created="Mon, 5 Jan 2015 18:06:44 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12690095/HIVE-8988.07.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12690095/HIVE-8988.07.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 6724 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2254/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2254/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2254/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2254/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2254/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2254/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12690095 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14264845" author="jcamachorodriguez" created="Mon, 5 Jan 2015 18:16:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jpullokkaran&quot; class=&quot;user-hover&quot; rel=&quot;jpullokkaran&quot;&gt;Laljo John Pullokkaran&lt;/a&gt;, test fail is not related to the patch. I think it is good to go, can you check it? Thanks!&lt;/p&gt;</comment>
                            <comment id="14267979" author="jpullokkaran" created="Wed, 7 Jan 2015 18:20:53 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14270133" author="jpullokkaran" created="Thu, 8 Jan 2015 22:18:46 +0000"  >&lt;p&gt;Committed to trunk, thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jcamachorodriguez&quot; class=&quot;user-hover&quot; rel=&quot;jcamachorodriguez&quot;&gt;Jesus Camacho Rodriguez&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12776287">HIVE-9727</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12686821" name="HIVE-8988.01.patch" size="21632" author="jcamachorodriguez" created="Fri, 12 Dec 2014 10:07:02 +0000"/>
                            <attachment id="12687536" name="HIVE-8988.02.patch" size="23334" author="jcamachorodriguez" created="Tue, 16 Dec 2014 18:52:06 +0000"/>
                            <attachment id="12687542" name="HIVE-8988.03.patch" size="25334" author="jcamachorodriguez" created="Tue, 16 Dec 2014 19:06:28 +0000"/>
                            <attachment id="12687709" name="HIVE-8988.04.patch" size="23924" author="jcamachorodriguez" created="Wed, 17 Dec 2014 10:12:00 +0000"/>
                            <attachment id="12688371" name="HIVE-8988.05.patch" size="64544" author="jcamachorodriguez" created="Fri, 19 Dec 2014 18:22:52 +0000"/>
                            <attachment id="12688175" name="HIVE-8988.05.patch" size="64544" author="jcamachorodriguez" created="Thu, 18 Dec 2014 23:13:31 +0000"/>
                            <attachment id="12690076" name="HIVE-8988.06.patch" size="67412" author="jcamachorodriguez" created="Mon, 5 Jan 2015 12:45:53 +0000"/>
                            <attachment id="12690095" name="HIVE-8988.07.patch" size="66935" author="jcamachorodriguez" created="Mon, 5 Jan 2015 15:48:47 +0000"/>
                            <attachment id="12686661" name="HIVE-8988.patch" size="21470" author="jcamachorodriguez" created="Thu, 11 Dec 2014 20:14:37 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 11 Dec 2014 22:31:01 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 2 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22up3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8989] Make groupby_multi_single_reducer.q and smb_mapjoin_3.q deterministic</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8989</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12758272">HIVE-8989</key>
            <summary>Make groupby_multi_single_reducer.q and smb_mapjoin_3.q deterministic</summary>
                <type id="3" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21148&amp;avatarType=issuetype">Task</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="brocknoland">Brock Noland</assignee>
                                    <reporter username="brocknoland">Brock Noland</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Nov 2014 18:28:53 +0000</created>
                <updated>Thu, 12 Feb 2015 23:40:22 +0000</updated>
                            <resolved>Fri, 28 Nov 2014 13:08:07 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="14227901" author="szehon" created="Thu, 27 Nov 2014 19:06:39 +0000"  >&lt;p&gt;+1, looks good to me&lt;/p&gt;</comment>
                            <comment id="14227968" author="hiveqa" created="Thu, 27 Nov 2014 21:07:42 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684102/HIVE-8989.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684102/HIVE-8989.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 3 failed/errored test(s), 6694 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mapjoin_mapjoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1926/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1926/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1926/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1926/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1926/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1926/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684102 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14228273" author="xuefuz" created="Fri, 28 Nov 2014 13:08:07 +0000"  >&lt;p&gt;Patch committed to trunk. Thanks, Brock.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12684102" name="HIVE-8989.patch" size="16823" author="brocknoland" created="Thu, 27 Nov 2014 18:56:20 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 27 Nov 2014 19:06:39 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22uyn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8990] mapjoin_mapjoin.q is failing on Tez (missed golden file update)</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8990</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;mapjoin_mapjoin.q was updated (SORT_BEFORE_DIFF). However, since the tez test were stuck the accompanying update to the golden file was missed.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758318">HIVE-8990</key>
            <summary>mapjoin_mapjoin.q is failing on Tez (missed golden file update)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hagleitn">Gunther Hagleitner</assignee>
                                    <reporter username="hagleitn">Gunther Hagleitner</reporter>
                        <labels>
                    </labels>
                <created>Fri, 28 Nov 2014 08:12:53 +0000</created>
                <updated>Thu, 12 Feb 2015 23:40:49 +0000</updated>
                            <resolved>Tue, 2 Dec 2014 19:09:35 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="14228403" author="hiveqa" created="Fri, 28 Nov 2014 17:17:42 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684145/HIVE-8990.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684145/HIVE-8990.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 3 failed/errored test(s), 6694 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_schemeAuthority
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyCommit
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1932/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1932/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1932/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1932/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1932/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1932/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684145 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14230825" author="szehon" created="Tue, 2 Dec 2014 01:48:22 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14231937" author="prasanth_j" created="Tue, 2 Dec 2014 19:09:35 +0000"  >&lt;p&gt;Committed to trunk.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12684145" name="HIVE-8990.1.patch" size="1777" author="hagleitn" created="Fri, 28 Nov 2014 08:13:58 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 28 Nov 2014 17:17:42 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 7 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22v8v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8991] Fix custom_input_output_format [Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8991</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;After &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8836&quot; title=&quot;Enable automatic tests with remote spark client [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8836&quot;&gt;&lt;del&gt;HIVE-8836&lt;/del&gt;&lt;/a&gt;, &lt;tt&gt;custom_input_output_format&lt;/tt&gt; fails because of missing hive-it-util in remote driver&apos;s class path.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758344">HIVE-8991</key>
            <summary>Fix custom_input_output_format [Spark Branch]</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12749643">HIVE-8548</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lirui">Rui Li</assignee>
                                    <reporter username="lirui">Rui Li</reporter>
                        <labels>
                    </labels>
                <created>Fri, 28 Nov 2014 12:15:39 +0000</created>
                <updated>Fri, 29 May 2015 02:30:41 +0000</updated>
                            <resolved>Fri, 5 Dec 2014 06:07:10 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="14228327" author="lirui" created="Fri, 28 Nov 2014 15:26:33 +0000"  >&lt;p&gt;This patch can fix the test on my machine.&lt;br/&gt;
Strange thing is that, if I add hive-it-util to &lt;tt&gt;spark.driver.extraClassPath&lt;/tt&gt;, I&apos;ll have to add hive-exec to it as well, which I suppose should be always added to driver&apos;s class path by default.&lt;br/&gt;
Looked a little bit into this. It seems spark will use &lt;tt&gt;SparkSubmitDriverBootstrapper&lt;/tt&gt; to launch &lt;tt&gt;SparkSubmit&lt;/tt&gt; if there&apos;re &lt;tt&gt;spark.driver.extra*&lt;/tt&gt; properties. So I suspect &lt;tt&gt;SparkSubmitDriverBootstrapper&lt;/tt&gt; somehow doesn&apos;t set CP properly for the driver.&lt;br/&gt;
Also tried setting &lt;tt&gt;--driver-class-path&lt;/tt&gt; in &lt;tt&gt;SparkClientImpl&lt;/tt&gt;, but it will override &lt;tt&gt;spark.driver.extraClassPath&lt;/tt&gt;.&lt;br/&gt;
Another thing is that &lt;tt&gt;SparkSubmitDriverBootstrapper&lt;/tt&gt; just hangs after client and driver have shut down. Others may help me verify this.&lt;/p&gt;</comment>
                            <comment id="14228335" author="lirui" created="Fri, 28 Nov 2014 15:36:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;Marcelo Vanzin&lt;/a&gt; could you help look at this? Thanks!&lt;/p&gt;</comment>
                            <comment id="14228395" author="hiveqa" created="Fri, 28 Nov 2014 16:57:36 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684187/HIVE-8991.1-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684187/HIVE-8991.1-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 6 failed/errored test(s), 7182 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join_without_localtask
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_infer_bucket_sort_convert_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_hook
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parquet_join
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/464/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/464/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/464/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/464/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-464/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-464/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684187 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14230227" author="vanzin" created="Mon, 1 Dec 2014 18:49:00 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;Rui Li&lt;/a&gt;, the patch looks good if it unblocks the unit tests. I have to think a bit about whether it would work in a real deployment scenario, since IIRC hive-exec shades a lot of dependencies and it might cause problems with Spark. But the main one (Guava) should be solved in Spark, so hopefully there won&apos;t be other cases like that.&lt;/p&gt;</comment>
                            <comment id="14230468" author="xuefuz" created="Mon, 1 Dec 2014 21:13:51 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;Marcelo Vanzin&lt;/a&gt;, this doesn&apos;t block anything, and so let&apos;s do it in the right way. In the meantime, does it make sense for you to take this JIRA while you&apos;re doing the research? Thanks.&lt;/p&gt;</comment>
                            <comment id="14230811" author="lirui" created="Tue, 2 Dec 2014 01:35:48 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;Marcelo Vanzin&lt;/a&gt;, just as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;Xuefu Zhang&lt;/a&gt; said, this JIRA is only meant to fix the test &lt;tt&gt;custom_input_output_format.q&lt;/tt&gt; after we enable unit tests with remote spark context. Please feel free to take it if you think of a better solution. Thanks!&lt;/p&gt;</comment>
                            <comment id="14231866" author="vanzin" created="Tue, 2 Dec 2014 18:18:30 +0000"  >&lt;p&gt;I didn&apos;t mean to stop you guys from checking in this patch. I just said that while this may fix the test, it&apos;s an indication of something that we need to understand better (i.e. how to properly add jars to the Spark job&apos;s classpath without causing conflicts).&lt;/p&gt;</comment>
                            <comment id="14233993" author="lirui" created="Thu, 4 Dec 2014 08:07:31 +0000"  >&lt;p&gt;I looked a little more into this. It seems hive-exec is properly added to class path (as user application jar in &lt;tt&gt;SparkSubmit&lt;/tt&gt;) and class loader can load &lt;tt&gt;HiveIgnoreKeyTextOutputFormat&lt;/tt&gt;:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2014-12-04 08:35:33,383 INFO  [stdout-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(384)) - [Loaded org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat from file:/home/hive/packaging/target/apache-hive-0.15.0-SNAPSHOT-bin/apache-hive-0.15.0-SNAPSHOT-bin/lib/hive-exec-0.15.0-SNAPSHOT.jar]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Nevertheless I still get the following error:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2014-12-04 08:32:26,681 INFO  [stderr-redir-1]: client.SparkClientImpl (SparkClientImpl.java:run(384)) - java.lang.NoClassDefFoundError: org/apache/hadoop/hive/ql/io/HiveIgnoreKeyTextOutputFormat
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Besides, the exception is thrown when we try to deserialize SparkWork in the job, which means &lt;tt&gt;org.apache.hadoop.hive.ql.exec.spark.KryoSerializer&lt;/tt&gt; has been loaded properly.&lt;br/&gt;
I&apos;ll do more debugging. Wondering if it&apos;s possible the error message is not accurate.&lt;/p&gt;

&lt;p&gt;As for &lt;tt&gt;SparkSubmitDriverBootstrapper&lt;/tt&gt; hanging issue, it&apos;s because it calls System.exit in a shutdown hook which causes deadlock. It&apos;s been fixed in latest branch.&lt;/p&gt;</comment>
                            <comment id="14234082" author="lirui" created="Thu, 4 Dec 2014 09:58:30 +0000"  >&lt;p&gt;Not sure if it&apos;s because how we add hive-exec:&lt;br/&gt;
If added dynamically (as application jar), spark loads it with &lt;tt&gt;ExecutorURLClassLoader&lt;/tt&gt; and set it as the thread&apos;s ContextClassLoader. Then we hit the NoClassDefFoundError.&lt;br/&gt;
If added to &lt;tt&gt;spark.driver.extraClassPath&lt;/tt&gt;, then it&apos;s loaded with the system class loader and the error is gone.&lt;/p&gt;</comment>
                            <comment id="14234275" author="xuefuz" created="Thu, 4 Dec 2014 15:34:42 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;Rui Li&lt;/a&gt;, many thanks for the new findings. I think the patch here is good to be checked in to fix the the test. However, if you and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;Marcelo Vanzin&lt;/a&gt; find additional improvement needed for library loading mechanism, please create a new JIRA and linked with this one. Thanks.&lt;/p&gt;</comment>
                            <comment id="14235143" author="xuefuz" created="Fri, 5 Dec 2014 06:07:10 +0000"  >&lt;p&gt;Committed to Spark branch. Thanks, Rui.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12754699">HIVE-8836</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12684187" name="HIVE-8991.1-spark.patch" size="3302" author="lirui" created="Fri, 28 Nov 2014 15:26:33 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 28 Nov 2014 16:57:36 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 7 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22ve7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8992] Fix bucket related test failure: parquet_join.q [Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8992</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Failures shown in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8836&quot; title=&quot;Enable automatic tests with remote spark client [Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8836&quot;&gt;&lt;del&gt;HIVE-8836&lt;/del&gt;&lt;/a&gt;. The seemed related to wrong reducer numbers in terms of bucket join.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758351">HIVE-8992</key>
            <summary>Fix bucket related test failure: parquet_join.q [Spark Branch]</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12752296">HIVE-8699</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jxiang">Jimmy Xiang</assignee>
                                    <reporter username="xuefuz">Xuefu Zhang</reporter>
                        <labels>
                    </labels>
                <created>Fri, 28 Nov 2014 13:26:37 +0000</created>
                <updated>Fri, 29 May 2015 02:30:02 +0000</updated>
                            <resolved>Fri, 5 Dec 2014 18:27:08 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>spark-branch</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="14232422" author="hiveqa" created="Wed, 3 Dec 2014 01:17:11 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684746/HIVE-8992.1-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684746/HIVE-8992.1-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 6 failed/errored test(s), 7223 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_custom_input_output_format
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parquet_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_decimal_aggregate
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/474/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/474/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/474/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/474/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-474/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-474/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684746 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14232433" author="jxiang" created="Wed, 3 Dec 2014 01:27:50 +0000"  >&lt;p&gt;Need to order the output of parquet_join.q.&lt;/p&gt;</comment>
                            <comment id="14235154" author="xuefuz" created="Fri, 5 Dec 2014 06:16:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;Jimmy Xiang&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-9011&quot; title=&quot;Fix parquet_join.q determinism&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-9011&quot;&gt;&lt;del&gt;HIVE-9011&lt;/del&gt;&lt;/a&gt; is merged to Spark branch. Is the patch here ready to be checked in?&lt;/p&gt;</comment>
                            <comment id="14235713" author="jxiang" created="Fri, 5 Dec 2014 16:49:20 +0000"  >&lt;p&gt;I uploaded v2 that has the new parquet_join.q.out, which should be fine now. Thanks.&lt;/p&gt;</comment>
                            <comment id="14235833" author="hiveqa" created="Fri, 5 Dec 2014 18:18:09 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12685342/HIVE-8992.2-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12685342/HIVE-8992.2-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 3 failed/errored test(s), 7229 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/486/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/486/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/486/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/486/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-486/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-486/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 3 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12685342 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14235847" author="xuefuz" created="Fri, 5 Dec 2014 18:25:45 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14235849" author="xuefuz" created="Fri, 5 Dec 2014 18:27:08 +0000"  >&lt;p&gt;Committed to Spark branch. Thanks, Jimmy.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12754699">HIVE-8836</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12684746" name="HIVE-8992.1-spark.patch" size="8846" author="jxiang" created="Tue, 2 Dec 2014 22:39:03 +0000"/>
                            <attachment id="12685342" name="HIVE-8992.2-spark.patch" size="8634" author="jxiang" created="Fri, 5 Dec 2014 16:48:02 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 3 Dec 2014 01:17:11 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 7 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22vfr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8993] Make sure Spark + HS2 work [Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8993</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;We haven&apos;t formally tested this combination yet.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758368">HIVE-8993</key>
            <summary>Make sure Spark + HS2 work [Spark Branch]</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12723734">HIVE-7292</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="chengxiang li">Chengxiang Li</assignee>
                                    <reporter username="xuefuz">Xuefu Zhang</reporter>
                        <labels>
                            <label>TODOC-SPARK</label>
                            <label>TODOC15</label>
                    </labels>
                <created>Fri, 28 Nov 2014 16:23:07 +0000</created>
                <updated>Fri, 29 May 2015 09:07:24 +0000</updated>
                            <resolved>Thu, 11 Dec 2014 04:20:20 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="14228476" author="brocknoland" created="Fri, 28 Nov 2014 19:09:21 +0000"  >&lt;p&gt;I think we should create a simple class &lt;tt&gt;TestSparkViaJdbcWithMiniHS2&lt;/tt&gt; based on &lt;tt&gt;TestJdbcWithMiniHS2&lt;/tt&gt;&lt;/p&gt;</comment>
                            <comment id="14240798" author="chengxiang li" created="Wed, 10 Dec 2014 08:11:22 +0000"  >&lt;p&gt;Run several queries on real environment, all work well.&lt;/p&gt;</comment>
                            <comment id="14240807" author="chengxiang li" created="Wed, 10 Dec 2014 08:21:20 +0000"  >&lt;p&gt;TestJdbcWithMiniHS2&apos;s tests does not touch execution layler actually, so i add TestJdbcWithLocalClusterSpark which is cloned from TestJdbcWithMiniMR, it test the logic go through JDBC-&amp;gt;HS2-&amp;gt;RSC-&amp;gt;Spark.&lt;/p&gt;</comment>
                            <comment id="14240834" author="chengxiang li" created="Wed, 10 Dec 2014 09:00:45 +0000"  >&lt;p&gt;share thirdparty folder between hive-unit and qtest-spark, so that hive only need to download spark installation once during unit test.&lt;/p&gt;</comment>
                            <comment id="14240942" author="hiveqa" created="Wed, 10 Dec 2014 11:09:23 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12686227/HIVE-8993.2-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12686227/HIVE-8993.2-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 7253 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_optimize_nullscan
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/510/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/510/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/510/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/510/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-510/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-510/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12686227 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14241863" author="xuefuz" created="Wed, 10 Dec 2014 22:30:57 +0000"  >&lt;p&gt;Patch looks good to me. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt;, could you take a look at the pom changes since they are similar to what you did previously.&lt;/p&gt;</comment>
                            <comment id="14241890" author="brocknoland" created="Wed, 10 Dec 2014 22:44:53 +0000"  >&lt;p&gt;I don&apos;t think we should have more than one antrun command attempting to download spark. If we need it in multiple places, let&apos;s put it in a central location. I think that &lt;tt&gt;spark-client&lt;/tt&gt; might be using it as well. Perhaps we put this in the spark client pom and then have the other places look there?&lt;/p&gt;</comment>
                            <comment id="14241977" author="chengxiang li" created="Thu, 11 Dec 2014 01:38:40 +0000"  >&lt;p&gt;Should we put download spark logic in itests pom, as we only need to download spark for unit test.&lt;/p&gt;</comment>
                            <comment id="14242011" author="brocknoland" created="Thu, 11 Dec 2014 02:11:27 +0000"  >&lt;p&gt;That sounds good!&lt;/p&gt;</comment>
                            <comment id="14242043" author="chengxiang li" created="Thu, 11 Dec 2014 02:48:47 +0000"  >&lt;p&gt;Move spark download script to itests/pom.xml, which would be used by both hive-unit and qtest-spark, so that we only need to maintain on script copy.&lt;/p&gt;</comment>
                            <comment id="14242050" author="brocknoland" created="Thu, 11 Dec 2014 02:56:54 +0000"  >&lt;p&gt;+1 pending tests&lt;/p&gt;</comment>
                            <comment id="14242108" author="hiveqa" created="Thu, 11 Dec 2014 04:07:56 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12686425/HIVE-8993.3-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12686425/HIVE-8993.3-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 7255 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join29
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_outer_join5
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/514/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/514/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/514/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/514/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-514/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-514/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12686425 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14242117" author="xuefuz" created="Thu, 11 Dec 2014 04:14:01 +0000"  >&lt;p&gt;The test failures are concerning, but I don&apos;t think they are related to this patch. Will commit this patch shortly.&lt;/p&gt;</comment>
                            <comment id="14242121" author="xuefuz" created="Thu, 11 Dec 2014 04:20:20 +0000"  >&lt;p&gt;Committed to Spark branch. Thanks, Chengxiang.&lt;/p&gt;</comment>
                            <comment id="14243929" author="chengxiang li" created="Fri, 12 Dec 2014 09:56:36 +0000"  >&lt;p&gt;During the test of multi beelines connect to HS2, the second beeline would hangs while execute query, due to can not launch executors.&lt;br/&gt;
In standalone mode, Spark Application(aka per SparkContext) apply its own executors from Spark Master, which schedule executors by allocating work resources to new executor, the resource contains memory and cpu cores. executor cores is set with &quot;spark.cores.max&quot;, with default value &quot;spark.deploy.defaultCores&quot; which is Integer.MaxValue in default. If Hive do not set &quot;spark.cores.max&quot;, Master would assign all worker cores to the first one who apply executors, which make later Spark Applications never have a chance to launch executors until first one quit. To enable multi users with HS2, user have to set &quot;spark.cores.max&quot; or &quot;spark.deploy.defaultCores&quot; properly.&lt;/p&gt;</comment>
                            <comment id="14246248" author="brocknoland" created="Mon, 15 Dec 2014 02:28:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chengxiang+li&quot; class=&quot;user-hover&quot; rel=&quot;chengxiang li&quot;&gt;Chengxiang Li&lt;/a&gt; - I am using the HS2 get log API, which is what beeline uses as well, and I am not seeing the progress of the query. Map1, Map2, etc and percent complete. Are you able to get that working through HS2?&lt;/p&gt;</comment>
                            <comment id="14246293" author="chengxiang li" created="Mon, 15 Dec 2014 03:51:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt;, the query progress info is printed to HS2 console, I use nohup to run HS2 as backgroud job, so i can find the progress info in HS2&apos;s nohup.output file. &lt;/p&gt;</comment>
                            <comment id="14247492" author="brocknoland" created="Tue, 16 Dec 2014 00:28:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chengxiang+li&quot; class=&quot;user-hover&quot; rel=&quot;chengxiang li&quot;&gt;Chengxiang Li&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;Thank you! The issue is that HS2 is used by many users and thus many queries may run in parallel. Additionally many users won&apos;t have access to the &quot;nohup.out&quot; of HS2. In &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4629&quot; title=&quot;HS2 should support an API to retrieve query logs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4629&quot;&gt;&lt;del&gt;HIVE-4629&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7615&quot; title=&quot;Beeline should have an option for user to see the query progress&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7615&quot;&gt;&lt;del&gt;HIVE-7615&lt;/del&gt;&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongc&quot; class=&quot;user-hover&quot; rel=&quot;dongc&quot;&gt;Dong Chen&lt;/a&gt; allowed beeline and JDBC users of HS2 to see the queries progress. I am not sure why it&apos;s not showing for spark?&lt;/p&gt;</comment>
                            <comment id="14247996" author="chengxiang li" created="Tue, 16 Dec 2014 09:53:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt;, I talked with Dong offline, we found the reasons why Beeline query progress does not work, and created &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-9120&quot; title=&quot;Hive Query log does not work when hive.exec.parallel is true&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-9120&quot;&gt;&lt;del&gt;HIVE-9120&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-9121&quot; title=&quot;Enable beeline query progress information for Spark job[Spark Branch]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-9121&quot;&gt;&lt;del&gt;HIVE-9121&lt;/del&gt;&lt;/a&gt; to track them.&lt;/p&gt;</comment>
                            <comment id="14564445" author="lefty@hortonworks.com" created="Fri, 29 May 2015 09:07:24 +0000"  >&lt;p&gt;Adding TODOC15 (which means TODOC1.1.0).&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12686220" name="HIVE-8993.1-spark.patch" size="15393" author="chengxiang li" created="Wed, 10 Dec 2014 08:21:20 +0000"/>
                            <attachment id="12686227" name="HIVE-8993.2-spark.patch" size="15882" author="chengxiang li" created="Wed, 10 Dec 2014 09:00:45 +0000"/>
                            <attachment id="12686425" name="HIVE-8993.3-spark.patch" size="17711" author="chengxiang li" created="Thu, 11 Dec 2014 02:48:47 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 28 Nov 2014 19:09:21 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 34 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22vjb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8994] Merge from trunk Nov 28 2014</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8994</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12758386">HIVE-8994</key>
            <summary>Merge from trunk Nov 28 2014</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12723734">HIVE-7292</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="brocknoland">Brock Noland</assignee>
                                    <reporter username="brocknoland">Brock Noland</reporter>
                        <labels>
                    </labels>
                <created>Fri, 28 Nov 2014 19:07:58 +0000</created>
                <updated>Fri, 29 May 2015 02:27:51 +0000</updated>
                            <resolved>Sat, 29 Nov 2014 03:44:52 +0000</resolved>
                                    <version>spark-branch</version>
                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="14228527" author="hiveqa" created="Fri, 28 Nov 2014 21:49:29 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684211/HIVE-8994.2-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684211/HIVE-8994.2-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 309 failed/errored test(s), 7215 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestAccumuloCliDriver - did not produce a TEST-*.xml file
TestMiniTezCliDriver-vectorization_13.q-auto_sortmerge_join_13.q-tez_bmj_schema_evolution.q-and-12-more - did not produce a TEST-*.xml file
TestParquetDirect - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_vc
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multi_insert_mixed
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parallel_join0
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parallel_join1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_array_of_multi_field_struct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_array_of_optional_elements
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_array_of_required_elements
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_array_of_single_field_struct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_array_of_structs
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_array_of_unannotated_groups
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_array_of_unannotated_primitives
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_avro_array_of_primitives
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_avro_array_of_single_field_struct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_map_of_maps
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_thrift_array_of_primitives
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_thrift_array_of_single_field_struct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_annotate_stats_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join0
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join10
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join11
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join12
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join13
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join14
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join15
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join16
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join17
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join18
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join18_multi_distinct
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join19
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join20
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join21
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join22
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join23
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join24
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join26
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join27
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join28
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join29
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join30
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join31
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join32
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join9
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join_reordering_values
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_join_without_localtask
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_smb_mapjoin_14
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_10
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_11
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_12
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_14
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_15
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_5
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_6
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_7
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_8
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_auto_sortmerge_join_9
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_tez1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucket_map_join_tez2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin10
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin11
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin12
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin13
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin5
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin7
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin8
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin9
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin_negative
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin_negative2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_bucketmapjoin_negative3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_column_access_stats
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_cross_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ctas
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_custom_input_output_format
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby7_noskew_multi_single_reducer
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_complex_types
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_complex_types_multi_single_reducer
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_multi_single_reducer2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_multi_single_reducer3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_position
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_sort_1_23
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_sort_skew_1_23
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_having
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_index_auto_self_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_infer_bucket_sort_convert_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_innerjoin
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_input12
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join0
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join11
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join12
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join13
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join14
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join15
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join17
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join18
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join18_multi_distinct
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join19
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join20
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join21
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join22
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join23
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join25
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join26
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join27
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join28
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join29
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join30
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join31
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join32
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join32_lessSize
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join33
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join35
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join36
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join37
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join38
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join39
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join40
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join41
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join9
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_alt_syntax
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_unqual1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_unqual2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_unqual3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_cond_pushdown_unqual4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_filters_overlap
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_hive_626
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_map_ppr
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_merge_multi_expressions
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_merging
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_nullsafe
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_rc
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_reorder
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_reorder2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_reorder3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_reorder4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_star
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_thrift
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_vc
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_view
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_limit_pushdown
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part13
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_load_dyn_part14
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_louter_join_ppr
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_decimal
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_distinct
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_filter_on_outerjoin
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_hook
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_mapjoin
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_memcheck
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_subquery
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_subquery2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mapjoin_test_outer
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mergejoins
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_mergejoins_mixed
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert_gby
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert_gby2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert_gby3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert_lateral_view
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert_mixed
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_insert_move_tasks_share_dependencies
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_multi_join_union
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_outer_join_ppr
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parallel
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parallel_join0
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parallel_join1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parquet_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_pcr
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_gby_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_join2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_join3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_join4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_join5
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_join_filter
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_multi_insert
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_outer_join1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_outer_join2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_outer_join3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_outer_join4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_outer_join5
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_ppd_transform
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_reduce_deduplicate_exclude_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_router_join_ppr
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample10
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sample8
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_script_pipe
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_semijoin
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoin
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoin_noskew
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoin_union_remove_1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoin_union_remove_2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt10
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt11
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt12
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt13
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt14
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt15
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt16
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt17
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt18
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt19
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt20
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt5
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt6
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt7
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt8
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_skewjoinopt9
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin9
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_10
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_13
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_14
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_15
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_16
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_17
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_25
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_5
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_6
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_smb_mapjoin_7
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sort_merge_join_desc_1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sort_merge_join_desc_2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sort_merge_join_desc_3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sort_merge_join_desc_4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sort_merge_join_desc_5
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sort_merge_join_desc_6
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sort_merge_join_desc_7
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_sort_merge_join_desc_8
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_subquery_in
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_subquery_multiinsert
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_table_access_keys_stats
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_temp_table
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_temp_table_join1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_tez_join_tests
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_tez_joins_explain
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union18
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union19
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union23
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union25
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union30
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union33
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union6
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_10
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_11
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_15
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_16
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_17
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_18
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_19
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_2
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_20
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_24
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_25
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_3
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_4
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_5
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_6
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_7
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_8
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_remove_9
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_decimal_mapjoin
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_left_outer_join
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_mapjoin_reduce
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_orderby_5
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_0
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_bucketmapjoin1
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_mapjoin
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_nested_mapjoin
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorized_shufflejoin
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/465/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/465/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/465/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/465/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-465/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-465/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 309 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684211 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14228606" author="hiveqa" created="Sat, 29 Nov 2014 02:46:57 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684219/HIVE-8994.3-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684219/HIVE-8994.3-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 17 failed/errored test(s), 7229 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_array_of_multi_field_struct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_array_of_optional_elements
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_array_of_required_elements
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_array_of_single_field_struct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_array_of_structs
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_array_of_unannotated_groups
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_array_of_unannotated_primitives
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_avro_array_of_primitives
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_avro_array_of_single_field_struct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_map_of_maps
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_thrift_array_of_primitives
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_thrift_array_of_single_field_struct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_custom_input_output_format
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parquet_join
org.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/466/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/466/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/466/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/466/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-466/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-466/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 17 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684219 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14228617" author="brocknoland" created="Sat, 29 Nov 2014 03:44:45 +0000"  >&lt;p&gt;The parquet tests fail because svn doesn&apos;t handle binary files. Committed merge to branch.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12684211" name="HIVE-8994.2-spark.patch" size="5897059" author="brocknoland" created="Fri, 28 Nov 2014 19:33:05 +0000"/>
                            <attachment id="12684219" name="HIVE-8994.3-spark.patch" size="8012131" author="brocknoland" created="Sat, 29 Nov 2014 01:12:09 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 28 Nov 2014 21:49:29 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22vnb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8995] Find thread leak in RSC Tests [Spark Branch]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8995</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;I was regenerating output as part of the merge:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;mvn test -Dtest=TestSparkCliDriver -Phadoop-2 -Dtest.output.overwrite=true -Dqfile=annotate_stats_join.q,auto_join0.q,auto_join1.q,auto_join10.q,auto_join11.q,auto_join12.q,auto_join13.q,auto_join14.q,auto_join15.q,auto_join16.q,auto_join17.q,auto_join18.q,auto_join18_multi_distinct.q,auto_join19.q,auto_join2.q,auto_join20.q,auto_join21.q,auto_join22.q,auto_join23.q,auto_join24.q,auto_join26.q,auto_join27.q,auto_join28.q,auto_join29.q,auto_join3.q,auto_join30.q,auto_join31.q,auto_join32.q,auto_join9.q,auto_join_reordering_values.q auto_join_without_localtask.q,auto_smb_mapjoin_14.q,auto_sortmerge_join_1.q,auto_sortmerge_join_10.q,auto_sortmerge_join_11.q,auto_sortmerge_join_12.q,auto_sortmerge_join_14.q,auto_sortmerge_join_15.q,auto_sortmerge_join_2.q,auto_sortmerge_join_3.q,auto_sortmerge_join_4.q,auto_sortmerge_join_5.q,auto_sortmerge_join_6.q,auto_sortmerge_join_7.q,auto_sortmerge_join_8.q,auto_sortmerge_join_9.q,bucket_map_join_1.q,bucket_map_join_2.q,bucket_map_join_tez1.q,bucket_map_join_tez2.q,bucketmapjoin1.q,bucketmapjoin10.q,bucketmapjoin11.q,bucketmapjoin12.q,bucketmapjoin13.q,bucketmapjoin2.q,bucketmapjoin3.q,bucketmapjoin4.q,bucketmapjoin5.q,bucketmapjoin7.q bucketmapjoin8.q,bucketmapjoin9.q,bucketmapjoin_negative.q,bucketmapjoin_negative2.q,bucketmapjoin_negative3.q,column_access_stats.q,cross_join.q,ctas.q,custom_input_output_format.q,groupby4.q,groupby7_noskew_multi_single_reducer.q,groupby_complex_types.q,groupby_complex_types_multi_single_reducer.q,groupby_multi_single_reducer2.q,groupby_multi_single_reducer3.q,groupby_position.q,groupby_sort_1_23.q,groupby_sort_skew_1_23.q,having.q,index_auto_self_join.q,infer_bucket_sort_convert_join.q,innerjoin.q,input12.q,join0.q,join1.q,join11.q,join12.q,join13.q,join14.q,join15.q join17.q,join18.q,join18_multi_distinct.q,join19.q,join2.q,join20.q,join21.q,join22.q,join23.q,join25.q,join26.q,join27.q,join28.q,join29.q,join3.q,join30.q,join31.q,join32.q,join32_lessSize.q,join33.q,join35.q,join36.q,join37.q,join38.q,join39.q,join40.q,join41.q,join9.q,join_alt_syntax.q,join_cond_pushdown_1.q join_cond_pushdown_2.q,join_cond_pushdown_3.q,join_cond_pushdown_4.q,join_cond_pushdown_unqual1.q,join_cond_pushdown_unqual2.q,join_cond_pushdown_unqual3.q,join_cond_pushdown_unqual4.q,join_filters_overlap.q,join_hive_626.q,join_map_ppr.q,join_merge_multi_expressions.q,join_merging.q,join_nullsafe.q,join_rc.q,join_reorder.q,join_reorder2.q,join_reorder3.q,join_reorder4.q,join_star.q,join_thrift.q,join_vc.q,join_view.q,limit_pushdown.q,load_dyn_part13.q,load_dyn_part14.q,louter_join_ppr.q,mapjoin1.q,mapjoin_decimal.q,mapjoin_distinct.q,mapjoin_filter_on_outerjoin.q mapjoin_hook.q,mapjoin_mapjoin.q,mapjoin_memcheck.q,mapjoin_subquery.q,mapjoin_subquery2.q,mapjoin_test_outer.q,mergejoins.q,mergejoins_mixed.q,multi_insert.q,multi_insert_gby.q,multi_insert_gby2.q,multi_insert_gby3.q,multi_insert_lateral_view.q,multi_insert_mixed.q,multi_insert_move_tasks_share_dependencies.q,multi_join_union.q,optimize_nullscan.q,outer_join_ppr.q,parallel.q,parallel_join0.q,parallel_join1.q,parquet_join.q,pcr.q,ppd_gby_join.q,ppd_join.q,ppd_join2.q,ppd_join3.q,ppd_join4.q,ppd_join5.q,ppd_join_filter.q ppd_multi_insert.q,ppd_outer_join1.q,ppd_outer_join2.q,ppd_outer_join3.q,ppd_outer_join4.q,ppd_outer_join5.q,ppd_transform.q,reduce_deduplicate_exclude_join.q,router_join_ppr.q,sample10.q,sample8.q,script_pipe.q,semijoin.q,skewjoin.q,skewjoin_noskew.q,skewjoin_union_remove_1.q,skewjoin_union_remove_2.q,skewjoinopt1.q,skewjoinopt10.q,skewjoinopt11.q,skewjoinopt12.q,skewjoinopt13.q,skewjoinopt14.q,skewjoinopt15.q,skewjoinopt16.q,skewjoinopt17.q,skewjoinopt18.q,skewjoinopt19.q,skewjoinopt2.q,skewjoinopt20.q skewjoinopt3.q,skewjoinopt4.q,skewjoinopt5.q,skewjoinopt6.q,skewjoinopt7.q,skewjoinopt8.q,skewjoinopt9.q,smb_mapjoin9.q,smb_mapjoin_1.q,smb_mapjoin_10.q,smb_mapjoin_13.q,smb_mapjoin_14.q,smb_mapjoin_15.q,smb_mapjoin_16.q,smb_mapjoin_17.q,smb_mapjoin_2.q,smb_mapjoin_25.q,smb_mapjoin_3.q,smb_mapjoin_4.q,smb_mapjoin_5.q,smb_mapjoin_6.q,smb_mapjoin_7.q,sort_merge_join_desc_1.q,sort_merge_join_desc_2.q,sort_merge_join_desc_3.q,sort_merge_join_desc_4.q,sort_merge_join_desc_5.q,sort_merge_join_desc_6.q,sort_merge_join_desc_7.q,sort_merge_join_desc_8.q stats1.q,subquery_in.q,subquery_multiinsert.q,table_access_keys_stats.q,temp_table.q,temp_table_join1.q,tez_join_tests.q,tez_joins_explain.q,union18.q,union19.q,union23.q,union25.q,union3.q,union30.q,union33.q,union6.q,union_remove_1.q,union_remove_10.q,union_remove_11.q,union_remove_15.q,union_remove_16.q,union_remove_17.q,union_remove_18.q,union_remove_19.q,union_remove_2.q,union_remove_20.q,union_remove_24.q,union_remove_25.q,union_remove_3.q,union_remove_4.q union_remove_5.q,union_remove_6.q,union_remove_7.q,union_remove_8.q,union_remove_9.q,vector_cast_constant.q,vector_decimal_mapjoin.q,vector_left_outer_join.q,vector_mapjoin_reduce.q,vector_orderby_5.q,vectorization_0.q,vectorized_bucketmapjoin1.q,vectorized_mapjoin.q,vectorized_nested_mapjoin.q,vectorized_ptf.q,vectorized_shufflejoin.q
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and the test JVM ran out of threads:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:713)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:521)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:702)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:791)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:774)
	at org.apache.hadoop.fs.FileUtil.execCommand(FileUtil.java:1097)
	at org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus.loadPermissionInfo(RawLocalFileSystem.java:572)
	at org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus.getPermission(RawLocalFileSystem.java:547)
	at org.apache.hadoop.fs.ProxyFileSystem.swizzleFileStatus(ProxyFileSystem.java:61)
	at org.apache.hadoop.fs.ProxyFileSystem.getFileStatus(ProxyFileSystem.java:265)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:397)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1398)
	at org.apache.hadoop.hive.ql.QTestUtil.clearTablesCreatedDuringTests(QTestUtil.java:578)
	at org.apache.hadoop.hive.ql.QTestUtil.clearTestSideEffects(QTestUtil.java:606)
	at org.apache.hadoop.hive.cli.TestSparkCliDriver.setUp(TestSparkCliDriver.java:66)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;thus there is a thread-leak somewhere in the test framework or in our RSC integration.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758409">HIVE-8995</key>
            <summary>Find thread leak in RSC Tests [Spark Branch]</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12723734">HIVE-7292</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lirui">Rui Li</assignee>
                                    <reporter username="brocknoland">Brock Noland</reporter>
                        <labels>
                    </labels>
                <created>Fri, 28 Nov 2014 23:55:28 +0000</created>
                <updated>Fri, 29 May 2015 02:29:24 +0000</updated>
                            <resolved>Tue, 2 Dec 2014 14:59:46 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="14228561" author="brocknoland" created="Sat, 29 Nov 2014 00:04:38 +0000"  >&lt;p&gt;I see three kinds of threads which appear to be leaked:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&quot;9b6aa26e-db45-424d-89d0-3763f04f4b6b-akka.actor.default-dispatcher-3&quot; daemon prio=5 tid=0x00007fd646195000 nid=0x11e07 waiting on condition [0x0000000120afc000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000078331caf8&amp;gt; (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool)
	at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&quot;9b6aa26e-db45-424d-89d0-3763f04f4b6b-scheduler-1&quot; daemon prio=5 tid=0x00007fd64609d800 nid=0x121e3 sleeping[0x000000011ee40000]
   java.lang.Thread.State: TIMED_WAITING (sleeping)
	at java.lang.Thread.sleep(Native Method)
	at akka.actor.LightArrayRevolverScheduler.waitNanos(Scheduler.scala:226)
	at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:405)
	at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375)
	at java.lang.Thread.run(Thread.java:744)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&quot;New I/O server boss #48&quot; daemon prio=5 tid=0x00007fd644886000 nid=0x11b03 runnable [0x0000000122956000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:200)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
	- locked &amp;lt;0x0000000782fe25d0&amp;gt; (a sun.nio.ch.Util$2)
	- locked &amp;lt;0x0000000782fe25e0&amp;gt; (a java.util.Collections$UnmodifiableSet)
	- locked &amp;lt;0x0000000782fe2580&amp;gt; (a sun.nio.ch.KQueueSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:102)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.select(NioServerBoss.java:163)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:206)
	at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14228636" author="brocknoland" created="Sat, 29 Nov 2014 05:15:52 +0000"  >&lt;p&gt;FYI &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;Marcelo Vanzin&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;Xuefu Zhang&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14230254" author="vanzin" created="Mon, 1 Dec 2014 19:02:27 +0000"  >&lt;p&gt;The three threads are from akka; I wonder if the test code is failing to properly shut down clients or the library itself (i.e. call &lt;tt&gt;SparkClientFactory.stop()&lt;/tt&gt;).&lt;/p&gt;</comment>
                            <comment id="14230264" author="brocknoland" created="Mon, 1 Dec 2014 19:09:25 +0000"  >&lt;p&gt;We are not. However that appears to be a JVM wide impact and we had dozens of instances of the &quot;three akka&quot; threads and we won&apos;t be able to call &lt;tt&gt;SparkClientFactory.stop()&lt;/tt&gt; after each session terminates when running inside HS2 since HS2 will have dozens of sessions concurrently and thousands of sessions over a few weeks.&lt;/p&gt;</comment>
                            <comment id="14230273" author="vanzin" created="Mon, 1 Dec 2014 19:16:26 +0000"  >&lt;p&gt;You don&apos;t need to call that method for every session. The pattern here is:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Call &lt;tt&gt;SparkClientFactory.initialize()&lt;/tt&gt; once&lt;/li&gt;
	&lt;li&gt;Create / use as many clients as you want&lt;/li&gt;
	&lt;li&gt;When app shuts down, call &lt;tt&gt;SparkClientFactory.stop()&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So this should work nicely for HS2 (call initialize during bring up, call stop during shut down).&lt;/p&gt;

&lt;p&gt;I see &lt;tt&gt;RemoteHiveSparkClient&lt;/tt&gt; calls initialize; that seems wrong, if my understanding of that class is correct (that it will be instantiated once for each session).&lt;/p&gt;

&lt;p&gt;Another option is to make &lt;tt&gt;initialize&lt;/tt&gt; idempotent; right now it will just leak the old akka actor system, which is bad. This should be a trivial change (just add a check for &lt;tt&gt;initialized&lt;/tt&gt;).&lt;/p&gt;</comment>
                            <comment id="14230291" author="brocknoland" created="Mon, 1 Dec 2014 19:30:28 +0000"  >&lt;blockquote&gt;&lt;p&gt;You don&apos;t need to call that method for every session&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes I was just saying that calling this might not be our problem.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I see &lt;tt&gt;RemoteHiveSparkClient&lt;/tt&gt; calls initialize;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This seems like it&apos;s the issue. We should change this and throw an exception if it&apos;s called twice.&lt;/p&gt;</comment>
                            <comment id="14230457" author="xuefuz" created="Mon, 1 Dec 2014 21:09:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ruili&quot; class=&quot;user-hover&quot; rel=&quot;ruili&quot;&gt;Rui Li&lt;/a&gt;, could you take a look at this? Thanks.&lt;/p&gt;</comment>
                            <comment id="14230812" author="lirui" created="Tue, 2 Dec 2014 01:36:25 +0000"  >&lt;p&gt;OK I&apos;ll have a look.&lt;/p&gt;</comment>
                            <comment id="14230872" author="lirui" created="Tue, 2 Dec 2014 02:40:21 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt;, I checked the code. It seems we initialize &lt;tt&gt;SparkClientFactory&lt;/tt&gt; each time we open a session, and we never stop it. Based on the discussion above, I think we should initialize &lt;tt&gt;SparkClientFactory&lt;/tt&gt; only once and stop it when app shuts down right? Maybe we can do that in &lt;tt&gt;SparkSessionManager&lt;/tt&gt;, what do you think?&lt;/p&gt;</comment>
                            <comment id="14230884" author="xuefuz" created="Tue, 2 Dec 2014 02:49:44 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;Rui Li&lt;/a&gt; SparkSessionManager, a singleton, seems to be a good place to initialize and destroy SparkClientFactory. We just need to do this lazily, which mean we initialize SparkClientFactory only if we instantiate SparkSessionManger instance. &lt;/p&gt;</comment>
                            <comment id="14230942" author="brocknoland" created="Tue, 2 Dec 2014 04:06:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;seems to be a good place to initialize and destroy SparkClientFactory.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14231065" author="lirui" created="Tue, 2 Dec 2014 06:35:04 +0000"  >&lt;p&gt;I tried the tests &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt; mentioned with this patch. All the tests passed except &lt;tt&gt;custom_input_output_format.q&lt;/tt&gt; and &lt;tt&gt;parquet_join.q&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="14231145" author="hiveqa" created="Tue, 2 Dec 2014 08:15:05 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684572/HIVE-8995.1-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684572/HIVE-8995.1-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 7229 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_custom_input_output_format
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parquet_join
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/470/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/470/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/470/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/470/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-470/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-470/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684572 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                            <comment id="14231528" author="lirui" created="Tue, 2 Dec 2014 14:18:16 +0000"  >&lt;p&gt;Further verified by monitoring the surefirebooter JVM. Seems it&apos;s working.&lt;/p&gt;</comment>
                            <comment id="14231561" author="xuefuz" created="Tue, 2 Dec 2014 14:51:33 +0000"  >&lt;p&gt;+1. Thanks for also fixing the synchronization issues.&lt;/p&gt;</comment>
                            <comment id="14231570" author="xuefuz" created="Tue, 2 Dec 2014 14:59:46 +0000"  >&lt;p&gt;Committed to Spark branch. Thanks, Rui.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12684572" name="HIVE-8995.1-spark.patch" size="5530" author="lirui" created="Tue, 2 Dec 2014 06:35:04 +0000"/>
                            <attachment id="12684660" name="with-patch.PNG" size="16482" author="lirui" created="Tue, 2 Dec 2014 14:16:41 +0000"/>
                            <attachment id="12684659" name="without-patch.PNG" size="14120" author="lirui" created="Tue, 2 Dec 2014 14:15:58 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 1 Dec 2014 19:02:27 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 7 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22vsf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8996] Rename getUGIForConf</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8996</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;getUGIForConf doesn&apos;t use the argument, let&apos;s rename it and remove the argument&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758418">HIVE-8996</key>
            <summary>Rename getUGIForConf</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="brocknoland">Brock Noland</assignee>
                                    <reporter username="brocknoland">Brock Noland</reporter>
                        <labels>
                    </labels>
                <created>Sat, 29 Nov 2014 04:29:22 +0000</created>
                <updated>Thu, 12 Feb 2015 23:40:29 +0000</updated>
                            <resolved>Sat, 29 Nov 2014 20:15:26 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="14228626" author="brocknoland" created="Sat, 29 Nov 2014 04:30:33 +0000"  >&lt;p&gt;FYI &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14228649" author="hiveqa" created="Sat, 29 Nov 2014 06:31:39 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684228/HIVE-8996.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684228/HIVE-8996.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 5 failed/errored test(s), 6694 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mapjoin_mapjoin
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_schemeAuthority
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1934/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1934/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1934/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1934/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1934/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1934/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684228 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14228651" author="ashutoshc" created="Sat, 29 Nov 2014 06:50:58 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14228924" author="brocknoland" created="Sat, 29 Nov 2014 20:15:26 +0000"  >&lt;p&gt;Thank you for the review! I have committed this to trunk.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12684228" name="HIVE-8996.patch" size="22093" author="brocknoland" created="Sat, 29 Nov 2014 04:29:51 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 29 Nov 2014 06:31:39 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22vuf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8997] Groupby index will fail if an indexed group by operator is followed by a non-indexed group by operator</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8997</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;following ql_rewrite_gbtoidx.q, if we run&lt;/p&gt;

&lt;p&gt;explain&lt;br/&gt;
select ckeysum, count(ckeysum)&lt;br/&gt;
from&lt;br/&gt;
(select l_shipdate, count(l_shipdate) as ckeysum&lt;br/&gt;
from lineitem_ix&lt;br/&gt;
group by l_shipdate) tabA&lt;br/&gt;
group by ckeysum&lt;/p&gt;

&lt;p&gt;We will get an error:&lt;/p&gt;

&lt;p&gt;junit.framework.AssertionFailedError: Client Execution failed with error code = 40000 running&lt;/p&gt;

&lt;p&gt;The trace is &lt;/p&gt;

&lt;p&gt;MismatchedTokenException(-1!=12)&lt;br/&gt;
at org.antlr.runtime.BaseRecognizer.recoverFromMismatchedToken(BaseRecognizer.java:617)&lt;br/&gt;
at org.antlr.runtime.BaseRecognizer.match(BaseRecognizer.java:115)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.charSetStringLiteral(HiveParser_IdentifiersParser.java:6099)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.constant(HiveParser_IdentifiersParser.java:5891)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6478)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6641)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:7026)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:7086)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7270)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7430)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7590)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7750)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7909)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8439)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9452)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9571)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9730)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6363)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.groupByExpression(HiveParser_IdentifiersParser.java:1386)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.groupByClause(HiveParser_IdentifiersParser.java:774)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser.groupByClause(HiveParser.java:44007)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser.singleSelectStatement(HiveParser.java:41504)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41135)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41072)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40125)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40001)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1519)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1057)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:199)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)&lt;br/&gt;
at org.apache.hadoop.hive.ql.optimizer.index.RewriteParseContextGenerator.generateOperatorTree(RewriteParseContextGenerator.java:67)&lt;br/&gt;
at org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndex$NewQueryGroupbySchemaProc.process(RewriteQueryUsingAggregateIndex.java:255)&lt;br/&gt;
at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)&lt;br/&gt;
at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:94)&lt;br/&gt;
at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:78)&lt;br/&gt;
at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.walk(DefaultGraphWalker.java:132)&lt;br/&gt;
at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:109)&lt;br/&gt;
at org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndexCtx.invokeRewriteQueryProc(RewriteQueryUsingAggregateIndexCtx.java:151)&lt;br/&gt;
at org.apache.hadoop.hive.ql.optimizer.index.RewriteGBUsingIndex.rewriteOriginalQuery(RewriteGBUsingIndex.java:382)&lt;br/&gt;
at org.apache.hadoop.hive.ql.optimizer.index.RewriteGBUsingIndex.transform(RewriteGBUsingIndex.java:135)&lt;br/&gt;
at org.apache.hadoop.hive.ql.optimizer.Optimizer.optimize(Optimizer.java:177)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10177)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:221)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:74)&lt;br/&gt;
at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:221)&lt;br/&gt;
at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:419)&lt;br/&gt;
at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:305)&lt;br/&gt;
at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1107)&lt;br/&gt;
at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1169)&lt;br/&gt;
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1044)&lt;br/&gt;
at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1034)&lt;br/&gt;
at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:199)&lt;br/&gt;
at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:151)&lt;br/&gt;
at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:362)&lt;br/&gt;
at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:297)&lt;br/&gt;
at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:849)&lt;br/&gt;
at org.apache.hadoop.hive.cli.TestCliDriver.runTest(TestCliDriver.java:136)&lt;br/&gt;
at org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ql_rewrite_gbtoidx_notwork(TestCliDriver.java:120)&lt;br/&gt;
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)&lt;br/&gt;
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
at java.lang.reflect.Method.invoke(Method.java:606)&lt;br/&gt;
at junit.framework.TestCase.runTest(TestCase.java:176)&lt;br/&gt;
at junit.framework.TestCase.runBare(TestCase.java:141)&lt;br/&gt;
at junit.framework.TestResult$1.protect(TestResult.java:122)&lt;br/&gt;
at junit.framework.TestResult.runProtected(TestResult.java:142)&lt;br/&gt;
at junit.framework.TestResult.run(TestResult.java:125)&lt;br/&gt;
at junit.framework.TestCase.run(TestCase.java:129)&lt;br/&gt;
at junit.framework.TestSuite.runTest(TestSuite.java:255)&lt;br/&gt;
at junit.framework.TestSuite.run(TestSuite.java:250)&lt;br/&gt;
at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:84)&lt;br/&gt;
at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:264)&lt;br/&gt;
at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)&lt;br/&gt;
at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:124)&lt;br/&gt;
at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:200)&lt;br/&gt;
at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:153)&lt;br/&gt;
at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)&lt;br/&gt;
Exception: Client Execution failed with error code = 40000 running&lt;/p&gt;

&lt;p&gt;The main reason is that&lt;br/&gt;
After Optimizer,org.apache.hadoop.hive.ql.optimizer.ColumnPruner, we should get the operator tree as&lt;br/&gt;
TS&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;-SEL&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;-GBY&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt;-RS&lt;span class=&quot;error&quot;&gt;&amp;#91;3&amp;#93;&lt;/span&gt;-GBY&lt;span class=&quot;error&quot;&gt;&amp;#91;4&amp;#93;&lt;/span&gt;-SEL&lt;span class=&quot;error&quot;&gt;&amp;#91;5&amp;#93;&lt;/span&gt;-SEL&lt;span class=&quot;error&quot;&gt;&amp;#91;6&amp;#93;&lt;/span&gt;-GBY&lt;span class=&quot;error&quot;&gt;&amp;#91;7&amp;#93;&lt;/span&gt;-RS&lt;span class=&quot;error&quot;&gt;&amp;#91;8&amp;#93;&lt;/span&gt;-GBY&lt;span class=&quot;error&quot;&gt;&amp;#91;9&amp;#93;&lt;/span&gt;-SEL&lt;span class=&quot;error&quot;&gt;&amp;#91;10&amp;#93;&lt;/span&gt;-FS&lt;span class=&quot;error&quot;&gt;&amp;#91;11&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Here, TS&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;, SEL&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;, GBY&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt;, GBY&lt;span class=&quot;error&quot;&gt;&amp;#91;4&amp;#93;&lt;/span&gt; should be rewritten. However, because the default graph walker is used in the code, GBY&lt;span class=&quot;error&quot;&gt;&amp;#91;9&amp;#93;&lt;/span&gt; and GBY&lt;span class=&quot;error&quot;&gt;&amp;#91;7&amp;#93;&lt;/span&gt; are going to be rewritten. This causes the error.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758422">HIVE-8997</key>
            <summary>Groupby index will fail if an indexed group by operator is followed by a non-indexed group by operator</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="pxiong">Pengcheng Xiong</assignee>
                                    <reporter username="pxiong">Pengcheng Xiong</reporter>
                        <labels>
                    </labels>
                <created>Sat, 29 Nov 2014 07:12:40 +0000</created>
                <updated>Mon, 8 Dec 2014 22:02:38 +0000</updated>
                            <resolved>Mon, 8 Dec 2014 22:02:38 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="14228660" author="pxiong" created="Sat, 29 Nov 2014 07:13:35 +0000"  >&lt;p&gt;This bug will be addressed by &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8774&quot; title=&quot;Fix groupBy index optimization&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8774&quot;&gt;&lt;del&gt;HIVE-8774&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14228661" author="pxiong" created="Sat, 29 Nov 2014 07:15:00 +0000"  >&lt;p&gt;according to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jpullokkaran&quot; class=&quot;user-hover&quot; rel=&quot;jpullokkaran&quot;&gt;Laljo John Pullokkaran&lt;/a&gt;&apos;s comments&lt;/p&gt;</comment>
                            <comment id="14238526" author="pxiong" created="Mon, 8 Dec 2014 22:02:38 +0000"  >&lt;p&gt;with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8774&quot; title=&quot;Fix groupBy index optimization&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8774&quot;&gt;&lt;del&gt;HIVE-8774&lt;/del&gt;&lt;/a&gt; patch&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12753572">HIVE-8774</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 7 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22vvb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8998] Logging is not configured in spark-submit sub-process</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8998</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12758546">HIVE-8998</key>
            <summary>Logging is not configured in spark-submit sub-process</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12723734">HIVE-7292</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="brocknoland">Brock Noland</assignee>
                                    <reporter username="brocknoland">Brock Noland</reporter>
                        <labels>
                    </labels>
                <created>Sun, 30 Nov 2014 23:45:55 +0000</created>
                <updated>Fri, 29 May 2015 02:29:57 +0000</updated>
                            <resolved>Mon, 1 Dec 2014 16:35:00 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="14229321" author="hiveqa" created="Mon, 1 Dec 2014 01:34:51 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684325/HIVE-8998.1-spark.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684325/HIVE-8998.1-spark.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 6 failed/errored test(s), 7229 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sample_islocalmode_hook
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_custom_input_output_format
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_join_nullsafe
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_parquet_join
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/467/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/467/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/467/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-SPARK-Build/467/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-467/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-50-18-27-0.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-SPARK-Build-467/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684325 - PreCommit-HIVE-SPARK-Build&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12759379">HIVE-9019</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12684325" name="HIVE-8998.1-spark.patch" size="3675" author="brocknoland" created="Sun, 30 Nov 2014 23:54:17 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 1 Dec 2014 01:34:51 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22wlz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-8999] hiveserver2 CUSTOM authentication Fails</title>
                <link>https://issues.apache.org/jira/browse/HIVE-8999</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Planned to secure the hiverserver2 Using Custom authentication Method. &lt;br/&gt;
But when the beeline starts and sets the server Ip and port using command. It hanges in the terminal after providing the username and Password.&lt;br/&gt;
*****************************&lt;b&gt;Procedure Followed&lt;/b&gt;***********************************&lt;br/&gt;
*Compiled Java File to create a jar&lt;br/&gt;
import java.util.Hashtable;&lt;br/&gt;
import javax.security.sasl.AuthenticationException;&lt;br/&gt;
import org.apache.hive.service.auth.PasswdAuthenticationProvider;&lt;/p&gt;

&lt;p&gt;public class SampleAuthenticator implements PasswdAuthenticationProvider {&lt;/p&gt;

&lt;p&gt;  Hashtable&amp;lt;String, String&amp;gt; store = null;&lt;/p&gt;

&lt;p&gt;  public SampleAuthenticator () &lt;/p&gt;
{
    store = new Hashtable&amp;lt;String, String&amp;gt;();
    store.put(&quot;user1&quot;, &quot;passwd1&quot;);
    store.put(&quot;user2&quot;, &quot;passwd2&quot;);
  }

&lt;p&gt;  @Override&lt;br/&gt;
  public void Authenticate(String user, String  password)&lt;br/&gt;
      throws AuthenticationException &lt;/p&gt;
{

    String storedPasswd = store.get(user);

    if (storedPasswd != null &amp;amp;&amp;amp; storedPasswd.equals(password))
      return;

    throw new AuthenticationException(&quot;SampleAuthenticator: Error validating user&quot;);
  }

&lt;p&gt;}&lt;br/&gt;
---------------------------------------------------------------------------------------------&lt;br/&gt;
*Properties Used in Hive-site.xml&lt;br/&gt;
&amp;lt;property&amp;gt;&lt;br/&gt;
  &amp;lt;name&amp;gt;hive.server2.authentication&amp;lt;/name&amp;gt;&lt;br/&gt;
  &amp;lt;value&amp;gt;CUSTOM&amp;lt;/value&amp;gt;&lt;br/&gt;
&amp;lt;/property&amp;gt;&lt;/p&gt;

&lt;p&gt;&amp;lt;property&amp;gt;&lt;br/&gt;
  &amp;lt;name&amp;gt;hive.server2.custom.authentication.class&amp;lt;/name&amp;gt;&lt;br/&gt;
  &amp;lt;value&amp;gt;org.apache.hive.service.auth.PasswdAuthenticationProvider.SampleAuth&amp;lt;/value&amp;gt;&lt;br/&gt;
&amp;lt;/property&amp;gt;&lt;br/&gt;
--------------------------------------------------------------------------&lt;br/&gt;
*Started Beeline &lt;br/&gt;
beeline&amp;gt; !connect jdbc:hive2://localhost:10000/default&lt;br/&gt;
scan complete in 13ms&lt;br/&gt;
Connecting to jdbc:hive2://localhost:10000/default&lt;br/&gt;
Enter username for jdbc:hive2://localhost:10000/default: user1&lt;br/&gt;
Enter password for jdbc:hive2://localhost:10000/default: *******&lt;br/&gt;
SLF4J: Class path contains multiple SLF4J bindings.&lt;br/&gt;
SLF4J: Found binding in &lt;span class=&quot;error&quot;&gt;&amp;#91;jar:file:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class&amp;#93;&lt;/span&gt;&lt;br/&gt;
SLF4J: Found binding in &lt;span class=&quot;error&quot;&gt;&amp;#91;jar:file:/opt/apache-hive/lib/hive-jdbc-0.14.0-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class&amp;#93;&lt;/span&gt;&lt;br/&gt;
SLF4J: See &lt;a href=&quot;http://www.slf4j.org/codes.html#multiple_bindings&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.slf4j.org/codes.html#multiple_bindings&lt;/a&gt; for an explanation.&lt;br/&gt;
SLF4J: Actual binding is of type &lt;span class=&quot;error&quot;&gt;&amp;#91;org.slf4j.impl.Log4jLoggerFactory&amp;#93;&lt;/span&gt;&lt;br/&gt;
------------------------------------------------------------------------------------------&lt;br/&gt;
Can Anyone help me by providing the correct Java file and Procedures to use Custom Authentication&lt;br/&gt;
Thank you&lt;br/&gt;
Amithsha.S&lt;/p&gt;</description>
                <environment>&lt;p&gt;Centos 6.5 Hadoop 2.4.1 Hive 0.14.0&lt;/p&gt;</environment>
        <key id="12758610">HIVE-8999</key>
            <summary>hiveserver2 CUSTOM authentication Fails</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="Amith">Amithsha</reporter>
                        <labels>
                    </labels>
                <created>Mon, 1 Dec 2014 10:33:33 +0000</created>
                <updated>Mon, 1 Dec 2014 10:33:33 +0000</updated>
                                            <version>0.14.0</version>
                                                    <component>Beeline</component>
                    <component>HiveServer2</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 8 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22x07:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-9000] LAST_VALUE Window function returns wrong results</title>
                <link>https://issues.apache.org/jira/browse/HIVE-9000</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;LAST_VALUE Windowing function has been returning bad results, as far as I can tell from day 1.&lt;/p&gt;

&lt;p&gt;And, it seems like the tests are also asserting that LAST_VALUE gives the wrong result.&lt;/p&gt;

&lt;p&gt;Here&apos;s the test output:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/hive/blob/branch-0.14/ql/src/test/results/clientpositive/windowing_navfn.q.out#L587&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hive/blob/branch-0.14/ql/src/test/results/clientpositive/windowing_navfn.q.out#L587&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The query is:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;select t, s, i, last_value(i) over (partition by t order by s) from over10k where (s = &lt;span class=&quot;code-quote&quot;&gt;&apos;oscar allen&apos;&lt;/span&gt; or s = &lt;span class=&quot;code-quote&quot;&gt;&apos;oscar carson&apos;&lt;/span&gt;) and t = 10
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The result is:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;t              s                    i          last_value(i)
-------------------------------------------------------
10	oscar allen	65662	65662
10	oscar carson	65549	65549
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;tt&gt;LAST_VALUE( i )&lt;/tt&gt; should have returned 65549 in both records, instead it simply ends up returning i.&lt;/p&gt;

&lt;p&gt;Another way you can make sure LAST_VALUE is bad is to verify it&apos;s result against LEAD(i,1) over (partition by t order by s). LAST_VALUE being last value should always be more (in terms of the specified &apos;order by s&apos;) than the lead by 1. While this doesn&apos;t directly apply to the above query, if the result set had more rows, you would clearly see records where lead is higher than last_value which is semantically incorrect.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758685">HIVE-9000</key>
            <summary>LAST_VALUE Window function returns wrong results</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="6">Invalid</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="mgrover">Mark Grover</reporter>
                        <labels>
                    </labels>
                <created>Mon, 1 Dec 2014 16:11:40 +0000</created>
                <updated>Sun, 25 Jan 2015 22:10:17 +0000</updated>
                            <resolved>Sun, 25 Jan 2015 22:10:17 +0000</resolved>
                                                                    <component>PTF-Windowing</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="14249520" author="navis" created="Wed, 17 Dec 2014 05:52:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mgrover&quot; class=&quot;user-hover&quot; rel=&quot;mgrover&quot;&gt;Mark Grover&lt;/a&gt; I think it&apos;s correct. You can acquire expected result by,&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;select t, s, i, last_value(i) over (partition by t order by s RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) 
from over10k where (s = &lt;span class=&quot;code-quote&quot;&gt;&apos;oscar allen&apos;&lt;/span&gt; or s = &lt;span class=&quot;code-quote&quot;&gt;&apos;oscar carson&apos;&lt;/span&gt;) and t = 10;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14291286" author="ashutoshc" created="Sun, 25 Jan 2015 21:56:26 +0000"  >&lt;p&gt;As Navis pointed out, result from Hive is indeed correct. I further verified on postgres. Mark, you can use alternative query suggested by Navis if you want your resultset to look like that.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 17 Dec 2014 05:52:03 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22xgv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-9001] Ship with log4j.properties file that has a reliable time based rolling policy</title>
                <link>https://issues.apache.org/jira/browse/HIVE-9001</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The hive log gets locked by the hive process and cannot be rolled in windows OS.&lt;br/&gt;
Install Hive in  Windows, start hive, try and rename hive log while Hive is running. &lt;br/&gt;
Wait for log4j tries to rename it and it will throw the same error as it is locked by the process.&lt;/p&gt;

&lt;p&gt;The changes in &lt;a href=&quot;https://issues.apache.org/bugzilla/show_bug.cgi?id=29726&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/bugzilla/show_bug.cgi?id=29726&lt;/a&gt; should be integrated to Hive for a reliable rollover.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12758767">HIVE-9001</key>
            <summary>Ship with log4j.properties file that has a reliable time based rolling policy</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hsubramaniyan">Hari Sankar Sivarama Subramaniyan</assignee>
                                    <reporter username="hsubramaniyan">Hari Sankar Sivarama Subramaniyan</reporter>
                        <labels>
                    </labels>
                <created>Mon, 1 Dec 2014 22:22:30 +0000</created>
                <updated>Thu, 12 Feb 2015 23:40:36 +0000</updated>
                            <resolved>Fri, 5 Dec 2014 23:46:45 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="14230569" author="hsubramaniyan" created="Mon, 1 Dec 2014 22:23:58 +0000"  >&lt;p&gt;cc-ing &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sushanth&quot; class=&quot;user-hover&quot; rel=&quot;sushanth&quot;&gt;Sushanth Sowmyan&lt;/a&gt; for reviewing this change.&lt;/p&gt;</comment>
                            <comment id="14230774" author="hiveqa" created="Tue, 2 Dec 2014 00:46:23 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12684492/HIVE-9001.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12684492/HIVE-9001.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 5 failed/errored test(s), 6695 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mapjoin_mapjoin
org.apache.hive.hcatalog.streaming.TestStreaming.testEndpointConnection
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyCommit
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1941/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1941/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1941/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1941/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1941/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1941/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12684492 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14230871" author="sushanth" created="Tue, 2 Dec 2014 02:40:02 +0000"  >&lt;p&gt;Looks good to me except for one minor fix - in the change to data/conf/hive-log4j.properties, you seem to have a comment section that is space-aligned to go to the next line rather than having newlines, which makes it one long comment line in the patch. I can fix this myself before committing if that&apos;s okay with you.&lt;/p&gt;
</comment>
                            <comment id="14234695" author="hsubramaniyan" created="Thu, 4 Dec 2014 22:03:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sushanth&quot; class=&quot;user-hover&quot; rel=&quot;sushanth&quot;&gt;Sushanth Sowmyan&lt;/a&gt; Made the space adjustments and overwrote the previous patch since this is a very minor change.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Hari&lt;/p&gt;</comment>
                            <comment id="14235378" author="hiveqa" created="Fri, 5 Dec 2014 11:08:10 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12685179/HIVE-9001.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12685179/HIVE-9001.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 6695 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_decimal_aggregate
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1964/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1964/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1964/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1964/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1964/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1964/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12685179 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14236318" author="sushanth" created="Fri, 5 Dec 2014 23:46:15 +0000"  >&lt;p&gt;+1, committing to trunk.&lt;/p&gt;</comment>
                            <comment id="14236319" author="sushanth" created="Fri, 5 Dec 2014 23:46:45 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Hari!&lt;/p&gt;</comment>
                            <comment id="14236580" author="lefty@hortonworks.com" created="Sat, 6 Dec 2014 04:15:23 +0000"  >&lt;p&gt;Does this need any documentation, or is it just a bug fix?&lt;/p&gt;</comment>
                            <comment id="14236639" author="sushanth" created="Sat, 6 Dec 2014 06:21:57 +0000"  >&lt;p&gt;I think this does need documentation in &lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-ErrorLogs&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-ErrorLogs&lt;/a&gt; - it adds an optional mode of logging. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hsubramaniyan&quot; class=&quot;user-hover&quot; rel=&quot;hsubramaniyan&quot;&gt;Hari Sankar Sivarama Subramaniyan&lt;/a&gt;, could you please add info to that wiki?&lt;/p&gt;</comment>
                            <comment id="14241747" author="hsubramaniyan" created="Wed, 10 Dec 2014 21:14:55 +0000"  >&lt;p&gt;Added the documentation in &lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-ErrorLogs&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-ErrorLogs&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Hari&lt;/p&gt;</comment>
                            <comment id="14241762" author="sushanth" created="Wed, 10 Dec 2014 21:21:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=leftylev&quot; class=&quot;user-hover&quot; rel=&quot;leftylev&quot;&gt;Lefty Leverenz&lt;/a&gt; : Just checking about procedure - is the process that we remove the TODOC15 flag now that Hari has added info for this on the wiki?&lt;/p&gt;</comment>
                            <comment id="14241995" author="lefty@hortonworks.com" created="Thu, 11 Dec 2014 01:56:34 +0000"  >&lt;p&gt;Yes, you can remove TODOC15 as soon as it&apos;s documented.  We don&apos;t use a DOC-DONE label, but comments show that the documentation was done.&lt;/p&gt;

&lt;p&gt;When I do the doc, sometimes I leave TODOC## pending review (unless I&apos;m sure of the information).  But there&apos;s no need for developers to wait for review once the information is in the doc.&lt;/p&gt;</comment>
                            <comment id="14244831" author="sushanth" created="Fri, 12 Dec 2014 21:43:29 +0000"  >&lt;p&gt;Thanks for the clarification! &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14281975" author="brocknoland" created="Sun, 18 Jan 2015 21:49:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sushanth&quot; class=&quot;user-hover&quot; rel=&quot;sushanth&quot;&gt;Sushanth Sowmyan&lt;/a&gt; can you please review &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-9407&quot; title=&quot;Fix spacing in pom&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-9407&quot;&gt;&lt;del&gt;HIVE-9407&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12768333">HIVE-9407</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12685179" name="HIVE-9001.1.patch" size="3681" author="hsubramaniyan" created="Thu, 4 Dec 2014 22:03:50 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 2 Dec 2014 00:46:23 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 1 week, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22xyv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>
</channel>
</rss>
