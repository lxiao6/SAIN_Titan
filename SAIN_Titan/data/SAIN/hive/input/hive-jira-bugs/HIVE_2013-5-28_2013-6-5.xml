<!--
RSS generated by JIRA (7.6.3#76005-sha1:8a4e38d34af948780dbf52044e7aafb13a7cae58) at Tue Jan 22 03:23:22 UTC 2019

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<!-- If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
    <channel>
        <title>ASF JIRA</title>
        <link>https://issues.apache.org/jira/issues/?jql=project+%3D+HIVE+AND+created+%3E%3D+2013-5-28+AND+created+%3C%3D+2013-6-5+ORDER+BY+key+ASC</link>
        <description>An XML representation of a search request</description>
                <language>en-uk</language>
                        <issue start="0" end="38" total="38"/>
                <build-info>
            <version>7.6.3</version>
            <build-number>76005</build-number>
            <build-date>09-01-2018</build-date>
        </build-info>

<item>
            <title>[HIVE-4619] Hive 0.11.0 is not working with pre-cdh3u6 and hadoop-0.23</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4619</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;path uris in input split are missing scheme (it&apos;s fixed on cdh3u6 and hadoop 1.0)&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2013-05-28 14:34:28,857 INFO org.apache.hadoop.hive.ql.exec.MapOperator: Adding alias data_type to work list for file hdfs://qa14:9000/user/hive/warehouse/data_type
2013-05-28 14:34:28,858 ERROR org.apache.hadoop.hive.ql.exec.MapOperator: Configuration does not have any alias for path: /user/hive/warehouse/data_type/000000_0
2013-05-28 14:34:28,875 INFO org.apache.hadoop.mapred.TaskLogsTruncater: Initializing logs&apos; truncater with mapRetainSize=-1 and reduceRetainSize=-1
2013-05-28 14:34:28,877 WARN org.apache.hadoop.mapred.Child: Error running child
java.lang.RuntimeException: Error in configuring object
        at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:93)
        at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:64)
        at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)
        at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:387)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:325)
        at org.apache.hadoop.mapred.Child$4.run(Child.java:266)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1278)
        at org.apache.hadoop.mapred.Child.main(Child.java:260)
Caused by: java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:88)
        ... 9 more
Caused by: java.lang.RuntimeException: Error in configuring object
        at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:93)
        at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:64)
        at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)
        at org.apache.hadoop.mapred.MapRunner.configure(MapRunner.java:34)
        ... 14 more
Caused by: java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:88)
        ... 17 more
Caused by: java.lang.RuntimeException: Map operator initialization failed
        at org.apache.hadoop.hive.ql.exec.ExecMapper.configure(ExecMapper.java:121)
        ... 22 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: Configuration and input path are inconsistent
        at org.apache.hadoop.hive.ql.exec.MapOperator.setChildren(MapOperator.java:522)
        at org.apache.hadoop.hive.ql.exec.ExecMapper.configure(ExecMapper.java:90)
        ... 22 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Configuration and input path are inconsistent
        at org.apache.hadoop.hive.ql.exec.MapOperator.setChildren(MapOperator.java:516)
        ... 23 more
2013-05-28 14:34:28,881 INFO org.apache.hadoop.mapred.Task: Runnning cleanup for the task
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12649639">HIVE-4619</key>
            <summary>Hive 0.11.0 is not working with pre-cdh3u6 and hadoop-0.23</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis</assignee>
                                    <reporter username="navis">Navis</reporter>
                        <labels>
                    </labels>
                <created>Tue, 28 May 2013 07:54:01 +0000</created>
                <updated>Tue, 15 Oct 2013 23:30:49 +0000</updated>
                            <resolved>Tue, 10 Sep 2013 19:23:27 +0000</resolved>
                                    <version>0.11.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>10</watches>
                                                                <comments>
                            <comment id="13668165" author="phabricator@reviews.facebook.net" created="Tue, 28 May 2013 08:00:29 +0000"  >&lt;p&gt;navis requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4619&quot; title=&quot;Hive 0.11.0 is not working with pre-cdh3u6 and hadoop-0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4619&quot;&gt;&lt;del&gt;HIVE-4619&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Hive 0.11.0 is not working with cdh3u5&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4619&quot; title=&quot;Hive 0.11.0 is not working with pre-cdh3u6 and hadoop-0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4619&quot;&gt;&lt;del&gt;HIVE-4619&lt;/del&gt;&lt;/a&gt; Hive 0.11.0 is not working with cdh3u5&lt;/p&gt;

&lt;p&gt;path uris in input split are missing scheme (it&apos;s fixed in cdh3u6)&lt;/p&gt;

&lt;p&gt;2013-05-28 14:34:28,857 INFO org.apache.hadoop.hive.ql.exec.MapOperator: Adding alias data_type to work list for file hdfs://qa14:9000/user/hive/warehouse/data_type&lt;br/&gt;
2013-05-28 14:34:28,858 ERROR org.apache.hadoop.hive.ql.exec.MapOperator: Configuration does not have any alias for path: /user/hive/warehouse/data_type/000000_0&lt;br/&gt;
2013-05-28 14:34:28,875 INFO org.apache.hadoop.mapred.TaskLogsTruncater: Initializing logs&apos; truncater with mapRetainSize=-1 and reduceRetainSize=-1&lt;br/&gt;
2013-05-28 14:34:28,877 WARN org.apache.hadoop.mapred.Child: Error running child&lt;br/&gt;
java.lang.RuntimeException: Error in configuring object&lt;br/&gt;
        at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:93)&lt;br/&gt;
        at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:64)&lt;br/&gt;
        at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)&lt;br/&gt;
        at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:387)&lt;br/&gt;
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:325)&lt;br/&gt;
        at org.apache.hadoop.mapred.Child$4.run(Child.java:266)&lt;br/&gt;
        at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
        at javax.security.auth.Subject.doAs(Subject.java:396)&lt;br/&gt;
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1278)&lt;br/&gt;
        at org.apache.hadoop.mapred.Child.main(Child.java:260)&lt;br/&gt;
Caused by: java.lang.reflect.InvocationTargetException&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:88)&lt;br/&gt;
        ... 9 more&lt;br/&gt;
Caused by: java.lang.RuntimeException: Error in configuring object&lt;br/&gt;
        at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:93)&lt;br/&gt;
        at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:64)&lt;br/&gt;
        at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)&lt;br/&gt;
        at org.apache.hadoop.mapred.MapRunner.configure(MapRunner.java:34)&lt;br/&gt;
        ... 14 more&lt;br/&gt;
Caused by: java.lang.reflect.InvocationTargetException&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:88)&lt;br/&gt;
        ... 17 more&lt;br/&gt;
Caused by: java.lang.RuntimeException: Map operator initialization failed&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.ExecMapper.configure(ExecMapper.java:121)&lt;br/&gt;
        ... 22 more&lt;br/&gt;
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: Configuration and input path are inconsistent&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.MapOperator.setChildren(MapOperator.java:522)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.ExecMapper.configure(ExecMapper.java:90)&lt;br/&gt;
        ... 22 more&lt;br/&gt;
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Configuration and input path are inconsistent&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.MapOperator.setChildren(MapOperator.java:516)&lt;br/&gt;
        ... 23 more&lt;br/&gt;
2013-05-28 14:34:28,881 INFO org.apache.hadoop.mapred.Task: Runnning cleanup for the task&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10971&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10971&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/26217/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/26217/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13761826" author="lars_francke" created="Mon, 9 Sep 2013 13:19:59 +0000"  >&lt;p&gt;Could we get this in for the 0.12 release?&lt;/p&gt;

&lt;p&gt;I&apos;ve been using this patch in production for weeks and it works at least for me.&lt;/p&gt;</comment>
                            <comment id="13761858" author="hiveqa" created="Mon, 9 Sep 2013 13:56:12 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12585003/HIVE-4619.D10971.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12585003/HIVE-4619.D10971.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/670/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/670/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/670/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/670/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-670/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf build hcatalog/build hcatalog/core/build hcatalog/storage-handlers/hbase/build hcatalog/server-extensions/build hcatalog/webhcat/svr/build hcatalog/webhcat/java-client/build hcatalog/hcatalog-pig-adapter/build common/src/gen
+ svn update
U    hcatalog/pom.xml
U    common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
U    ivy/ivysettings.xml
U    ivy/libraries.properties
U    ql/ivy.xml
U    ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java
U    ql/src/test/org/apache/hadoop/hive/ql/exec/TestPlan.java
U    ql/src/test/results/compiler/plan/input1.q.xml
U    ql/src/test/results/compiler/plan/input2.q.xml
U    ql/src/test/results/compiler/plan/input3.q.xml
U    ql/src/test/results/compiler/plan/input4.q.xml
U    ql/src/test/results/compiler/plan/input5.q.xml
U    ql/src/test/results/compiler/plan/input_testxpath2.q.xml
U    ql/src/test/results/compiler/plan/input6.q.xml
U    ql/src/test/results/compiler/plan/input7.q.xml
U    ql/src/test/results/compiler/plan/input_testsequencefile.q.xml
U    ql/src/test/results/compiler/plan/input8.q.xml
U    ql/src/test/results/compiler/plan/input9.q.xml
U    ql/src/test/results/compiler/plan/udf1.q.xml
U    ql/src/test/results/compiler/plan/input20.q.xml
U    ql/src/test/results/compiler/plan/udf4.q.xml
U    ql/src/test/results/compiler/plan/sample1.q.xml
U    ql/src/test/results/compiler/plan/sample2.q.xml
U    ql/src/test/results/compiler/plan/udf6.q.xml
U    ql/src/test/results/compiler/plan/sample3.q.xml
U    ql/src/test/results/compiler/plan/sample4.q.xml
U    ql/src/test/results/compiler/plan/sample5.q.xml
U    ql/src/test/results/compiler/plan/sample6.q.xml
U    ql/src/test/results/compiler/plan/sample7.q.xml
U    ql/src/test/results/compiler/plan/groupby1.q.xml
U    ql/src/test/results/compiler/plan/udf_case.q.xml
U    ql/src/test/results/compiler/plan/groupby2.q.xml
U    ql/src/test/results/compiler/plan/subq.q.xml
U    ql/src/test/results/compiler/plan/groupby3.q.xml
U    ql/src/test/results/compiler/plan/groupby4.q.xml
U    ql/src/test/results/compiler/plan/cast1.q.xml
U    ql/src/test/results/compiler/plan/groupby5.q.xml
U    ql/src/test/results/compiler/plan/groupby6.q.xml
U    ql/src/test/results/compiler/plan/join1.q.xml
U    ql/src/test/results/compiler/plan/join2.q.xml
U    ql/src/test/results/compiler/plan/join3.q.xml
U    ql/src/test/results/compiler/plan/join4.q.xml
U    ql/src/test/results/compiler/plan/join5.q.xml
U    ql/src/test/results/compiler/plan/join6.q.xml
U    ql/src/test/results/compiler/plan/case_sensitivity.q.xml
U    ql/src/test/results/compiler/plan/join7.q.xml
U    ql/src/test/results/compiler/plan/join8.q.xml
U    ql/src/test/results/compiler/plan/union.q.xml
U    ql/src/test/results/compiler/plan/udf_when.q.xml
U    ql/src/test/results/compiler/plan/input_testxpath.q.xml
U    ql/src/test/results/compiler/plan/input_part1.q.xml
U    ql/src/java/org/apache/hadoop/hive/ql/exec/ColumnInfo.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapRedTask.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/ExprNodeColumnEvaluator.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableDummyOperator.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/RowSchema.java
U    ql/src/java/org/apache/hadoop/hive/ql/Driver.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFParseUrlTuple.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFIndex.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFJSONTuple.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToUnixTimeStamp.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFStruct.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFNamedStruct.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFStack.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBridge.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFFormatNumber.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFExplode.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFArray.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFnGrams.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/SortMergeJoinTaskDispatcher.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/GenMRSkewJoinProcessor.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/LocalMapJoinProcFactory.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/BucketingSortingCtx.java
U    ql/src/java/org/apache/hadoop/hive/ql/plan/MapWork.java
U    ql/src/java/org/apache/hadoop/hive/ql/plan/PartitionDesc.java
U    ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeGenericFuncDesc.java
U    ql/src/java/org/apache/hadoop/hive/ql/plan/MapredWork.java
U    ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDesc.java
U    ql/src/java/org/apache/hadoop/hive/ql/parse/QBJoinTree.java
U    ql/build.xml
U    conf/hive-default.xml.template
U    contrib/src/java/org/apache/hadoop/hive/contrib/udtf/example/GenericUDTFCount2.java
U    contrib/src/java/org/apache/hadoop/hive/contrib/udtf/example/GenericUDTFExplode2.java

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
Updated external to revision 1521111.

Updated to revision 1521111.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0 to p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13761883" author="brocknoland" created="Mon, 9 Sep 2013 14:31:53 +0000"  >&lt;p&gt;I&apos;d be fine committing this if you submit a patch that applies.&lt;/p&gt;</comment>
                            <comment id="13762019" author="lars_francke" created="Mon, 9 Sep 2013 16:46:05 +0000"  >&lt;p&gt;This patch applies cleanly for me on current trunk.&lt;/p&gt;</comment>
                            <comment id="13762129" author="mikelikespie" created="Mon, 9 Sep 2013 18:28:08 +0000"  >&lt;p&gt;I just verified this patch fixes the issue with cdh4.3&lt;/p&gt;</comment>
                            <comment id="13762167" author="hiveqa" created="Mon, 9 Sep 2013 19:07:05 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12602163/HIVE-4619.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12602163/HIVE-4619.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 21 failed/errored test(s), 3088 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hcatalog.hbase.snapshot.lock.TestWriteLock.testRun
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSchema
org.apache.hive.hcatalog.fileformats.TestOrcDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_wise_fileformat17
org.apache.hive.hcatalog.api.TestHCatClient.testObjectNotFoundException
org.apache.hive.hcatalog.api.TestHCatClient.testTransportFailure
org.apache.hive.hcatalog.api.TestHCatClient.testDropTableException
org.apache.hive.hcatalog.api.TestHCatClient.testDropPartitionsWithPartialSpec
org.apache.hive.hcatalog.api.TestHCatClient.testCreateTableLike
org.apache.hive.hcatalog.api.TestHCatClient.testRenameTable
org.apache.hive.hcatalog.api.TestHCatClient.testOtherFailure
org.apache.hive.hcatalog.api.TestHCatClient.testBasicDDLCommands
org.apache.hive.hcatalog.pig.TestOrcHCatStorer.testStoreBasicTable
org.apache.hcatalog.api.TestHCatClient.testBasicDDLCommands
org.apache.hive.hcatalog.api.TestHCatClient.testGetPartitionsWithPartialSpec
org.apache.hive.hcatalog.api.TestHCatClient.testUpdateTableSchema
org.apache.hive.hcatalog.api.TestHCatClient.testDatabaseLocation
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStorePartitionedTable
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionsHCatClientImpl
org.apache.hcatalog.pig.TestHCatLoaderComplexSchema.testSyntheticComplexSchema
org.apache.hive.hcatalog.api.TestHCatClient.testGetMessageBusTopicName
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/673/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/673/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/673/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/673/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 21 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13762170" author="brocknoland" created="Mon, 9 Sep 2013 19:09:48 +0000"  >&lt;p&gt;Man those hcatalog tests are flaky. Let&apos;s run this one more time.&lt;/p&gt;</comment>
                            <comment id="13762448" author="hiveqa" created="Mon, 9 Sep 2013 23:23:43 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12602163/HIVE-4619.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12602163/HIVE-4619.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 3 failed/errored test(s), 3088 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_wise_fileformat17
org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned.testHCatPartitionedTable
org.apache.hcatalog.cli.TestPermsGrp.testCustomPerms
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/676/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/676/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/676/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/676/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 3 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13762615" author="navis" created="Tue, 10 Sep 2013 01:50:28 +0000"  >&lt;p&gt;Test for &quot;partition_wise_fileformat17&quot; seemed not flaky. I&apos;ll check that.&lt;/p&gt;</comment>
                            <comment id="13762637" author="navis" created="Tue, 10 Sep 2013 02:15:42 +0000"  >&lt;p&gt;partition_wise_fileformat17 was for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5249&quot; title=&quot;Missing test file for HIVE-5199 &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5249&quot;&gt;&lt;del&gt;HIVE-5249&lt;/del&gt;&lt;/a&gt; and others passed in local.&lt;/p&gt;</comment>
                            <comment id="13763147" author="brocknoland" created="Tue, 10 Sep 2013 16:01:13 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13763375" author="brocknoland" created="Tue, 10 Sep 2013 19:23:27 +0000"  >&lt;p&gt;I committed this to 0.12 and 0.13! Thank you for your contribution!&lt;/p&gt;</comment>
                            <comment id="13763875" author="hudson" created="Wed, 11 Sep 2013 02:29:13 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #93 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/93/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/93/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4619&quot; title=&quot;Hive 0.11.0 is not working with pre-cdh3u6 and hadoop-0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4619&quot;&gt;&lt;del&gt;HIVE-4619&lt;/del&gt;&lt;/a&gt; - Hive 0.11.0 is not working with pre-cdh3u6 and hadoop-0.23 (Navis via Brock Noland) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521593&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521593&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13764078" author="hudson" created="Wed, 11 Sep 2013 07:42:04 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #161 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/161/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/161/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4619&quot; title=&quot;Hive 0.11.0 is not working with pre-cdh3u6 and hadoop-0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4619&quot;&gt;&lt;del&gt;HIVE-4619&lt;/del&gt;&lt;/a&gt; - Hive 0.11.0 is not working with pre-cdh3u6 and hadoop-0.23 (Navis via Brock Noland) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521593&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521593&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13764234" author="hudson" created="Wed, 11 Sep 2013 11:50:23 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-h0.21 #2324 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2324/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2324/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4619&quot; title=&quot;Hive 0.11.0 is not working with pre-cdh3u6 and hadoop-0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4619&quot;&gt;&lt;del&gt;HIVE-4619&lt;/del&gt;&lt;/a&gt; - Hive 0.11.0 is not working with pre-cdh3u6 and hadoop-0.23 (Navis via Brock Noland) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521593&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521593&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13764876" author="hudson" created="Wed, 11 Sep 2013 22:25:32 +0000"  >&lt;p&gt;ABORTED: Integrated in Hive-trunk-hadoop2 #421 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/421/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/421/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4619&quot; title=&quot;Hive 0.11.0 is not working with pre-cdh3u6 and hadoop-0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4619&quot;&gt;&lt;del&gt;HIVE-4619&lt;/del&gt;&lt;/a&gt; - Hive 0.11.0 is not working with pre-cdh3u6 and hadoop-0.23 (Navis via Brock Noland) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521593&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521593&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13796079" author="ashutoshc" created="Tue, 15 Oct 2013 23:30:49 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12650141">HIVE-4633</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12602163" name="HIVE-4619.2.patch" size="1070" author="lars_francke" created="Mon, 9 Sep 2013 16:46:05 +0000"/>
                            <attachment id="12585003" name="HIVE-4619.D10971.1.patch" size="1374" author="phabricator@reviews.facebook.net" created="Tue, 28 May 2013 08:00:29 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 28 May 2013 08:00:29 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>329966</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kxe7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330301</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4620] MR temp directory conflicts in case of parallel execution mode</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4620</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;In parallel query execution mode, all the parallel running task ends up sharing the same temp/scratch directory. This could lead to file conflicts and temp files getting deleted before the job completion.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12649744">HIVE-4620</key>
            <summary>MR temp directory conflicts in case of parallel execution mode</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="prasadm">Prasad Mujumdar</assignee>
                                    <reporter username="prasadm">Prasad Mujumdar</reporter>
                        <labels>
                    </labels>
                <created>Tue, 28 May 2013 17:24:57 +0000</created>
                <updated>Tue, 15 Oct 2013 23:29:21 +0000</updated>
                            <resolved>Mon, 3 Jun 2013 23:42:44 +0000</resolved>
                                    <version>0.11.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13668471" author="prasadm" created="Tue, 28 May 2013 17:29:26 +0000"  >&lt;p&gt;Review request on &lt;a href=&quot;https://reviews.apache.org/r/11464/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11464/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13670160" author="navis" created="Thu, 30 May 2013 08:36:03 +0000"  >&lt;p&gt;Looks good to me. running test&lt;/p&gt;</comment>
                            <comment id="13671062" author="navis" created="Fri, 31 May 2013 02:00:34 +0000"  >&lt;p&gt;Failing one test but it seemed not related to this. I&apos;ll check on that first.&lt;/p&gt;</comment>
                            <comment id="13671105" author="navis" created="Fri, 31 May 2013 03:28:56 +0000"  >&lt;p&gt;Return value of TaskRunner#getTaskID() is not a task id but a task runner id, which can be a little confusing. Could you address that? Thanks.&lt;/p&gt;</comment>
                            <comment id="13671242" author="prasadm" created="Fri, 31 May 2013 07:58:23 +0000"  >&lt;p&gt;Updated patch per review comments.&lt;/p&gt;</comment>
                            <comment id="13672744" author="navis" created="Mon, 3 Jun 2013 00:54:36 +0000"  >&lt;p&gt;It would be good to make a phabricator or review-board entry. &lt;/p&gt;

&lt;p&gt;in TaskRunner.run()&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;taskRunnerID.set(taskCounter.incrementAndGet());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Is it necessary? If it is, is that should be called in runSequential() rather than run()?&lt;/p&gt;</comment>
                            <comment id="13672850" author="prasadm" created="Mon, 3 Jun 2013 06:20:10 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; Thanks for the comments. &lt;br/&gt;
The original review request on &lt;a href=&quot;https://reviews.apache.org/r/11464/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11464/&lt;/a&gt; is updated with the new patch.&lt;/p&gt;</comment>
                            <comment id="13673184" author="navis" created="Mon, 3 Jun 2013 14:58:44 +0000"  >&lt;p&gt;+1, running test.&lt;/p&gt;</comment>
                            <comment id="13673792" author="navis" created="Mon, 3 Jun 2013 23:42:44 +0000"  >&lt;p&gt;Committed to trunk, thanks Prasad!&lt;/p&gt;</comment>
                            <comment id="13673853" author="prasadm" created="Tue, 4 Jun 2013 00:24:57 +0000"  >&lt;p&gt;Thanks Navis!&lt;/p&gt;</comment>
                            <comment id="13674549" author="hudson" created="Tue, 4 Jun 2013 16:46:14 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2127 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2127/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2127/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4620&quot; title=&quot;MR temp directory conflicts in case of parallel execution mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4620&quot;&gt;&lt;del&gt;HIVE-4620&lt;/del&gt;&lt;/a&gt; MR temp directory conflicts in case of parallel execution mode (Prasad Mujumdar via Navis) (Revision 1489226)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
navis : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1489226&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1489226&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Context.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/TaskRunner.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13675547" author="hudson" created="Wed, 5 Jun 2013 03:02:12 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #225 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/225/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/225/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4620&quot; title=&quot;MR temp directory conflicts in case of parallel execution mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4620&quot;&gt;&lt;del&gt;HIVE-4620&lt;/del&gt;&lt;/a&gt; MR temp directory conflicts in case of parallel execution mode (Prasad Mujumdar via Navis) (Revision 1489226)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
navis : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1489226&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1489226&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Context.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/TaskRunner.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13795878" author="ashutoshc" created="Tue, 15 Oct 2013 23:29:21 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12585049" name="HIVE-4620-1.patch" size="3426" author="prasadm" created="Tue, 28 May 2013 17:29:10 +0000"/>
                            <attachment id="12585565" name="HIVE-4620-2.patch" size="3468" author="prasadm" created="Fri, 31 May 2013 07:58:23 +0000"/>
                            <attachment id="12585803" name="HIVE-4620-3.patch" size="3229" author="prasadm" created="Mon, 3 Jun 2013 06:20:10 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 30 May 2013 08:36:03 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330071</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ky1b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330405</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4621] &quot;describe formatted&quot; for table shows incorrect numRows data</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4621</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Created table (tab delimited), used &quot;load data local&quot; to get data into the table.&lt;br/&gt;
After creating the table, &quot;describe formatted&quot; showed numRow as 0.&lt;/p&gt;

&lt;p&gt;select count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; from... showed  43205 rows.&lt;/p&gt;

&lt;p&gt;Running &quot;describe formatted&quot; after &quot;select count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&quot; still shows numRows as 0.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12649760">HIVE-4621</key>
            <summary>&quot;describe formatted&quot; for table shows incorrect numRows data</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="6">Invalid</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="gwenshap">Gwen Shapira</reporter>
                        <labels>
                    </labels>
                <created>Tue, 28 May 2013 18:56:44 +0000</created>
                <updated>Wed, 13 Nov 2013 02:52:19 +0000</updated>
                            <resolved>Wed, 13 Nov 2013 02:31:53 +0000</resolved>
                                    <version>0.10.0</version>
                                                    <component>CLI</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13820849" author="ashutoshc" created="Wed, 13 Nov 2013 02:31:53 +0000"  >&lt;p&gt;Resolving it as invalid, since I can&apos;t repro this. Feel free to reopen if you can reproduce it. Also, provide steps to repro in case you are able to repro.&lt;/p&gt;</comment>
                            <comment id="13820857" author="ashutoshc" created="Wed, 13 Nov 2013 02:43:39 +0000"  >&lt;p&gt;Also, note &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4632&quot; title=&quot;Use hadoop counter as a stat publisher&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4632&quot;&gt;&lt;del&gt;HIVE-4632&lt;/del&gt;&lt;/a&gt; will simplify such that lot of requirements for stats collection will no longer be present.&lt;/p&gt;</comment>
                            <comment id="13820860" author="prasanth_j" created="Wed, 13 Nov 2013 02:46:41 +0000"  >&lt;p&gt;My understanding is that &quot;LOAD DATA LOCAL&quot; will never update statistics esp. numRows. This is an expected behavior. The description says load data local is used so describe formatted will always show numRows as 0. &lt;/p&gt;</comment>
                            <comment id="13820867" author="ashutoshc" created="Wed, 13 Nov 2013 02:52:19 +0000"  >&lt;p&gt;My bad. Prasanth is right. If you do insert queries than stats will be auto-gathered and displayed in describe formatted. Load statements don&apos;t gather stats. &lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12650087">HIVE-4632</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12600866">HIVE-3324</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 13 Nov 2013 02:31:53 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330087</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 10 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ky4v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330421</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4622] LOAD DATA LOCAL doesn&apos;t handle filenames with spaces</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4622</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;LOAD DATA LOCAL INPATH &apos;/mnt/hgfs/DATA/CA Locations.txt&apos; overwrite into table locations;&lt;/p&gt;

&lt;p&gt;Results in:&lt;br/&gt;
Copying data from &lt;a href=&quot;file:/mnt/hgfs/DATA/CA%20Locations.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/mnt/hgfs/DATA/CA%20Locations.txt&lt;/a&gt;&lt;br/&gt;
No files matching path: &lt;a href=&quot;file:/mnt/hgfs/DATA/CA%20Locations.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/mnt/hgfs/DATA/CA%20Locations.txt&lt;/a&gt;&lt;br/&gt;
FAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.CopyTask&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12649767">HIVE-4622</key>
            <summary>LOAD DATA LOCAL doesn&apos;t handle filenames with spaces</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="gwenshap">Gwen Shapira</reporter>
                        <labels>
                    </labels>
                <created>Tue, 28 May 2013 19:25:06 +0000</created>
                <updated>Tue, 28 May 2013 21:22:28 +0000</updated>
                            <resolved>Tue, 28 May 2013 21:22:28 +0000</resolved>
                                    <version>0.10.0</version>
                                                    <component>CLI</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13668623" author="xuefuz" created="Tue, 28 May 2013 20:10:42 +0000"  >&lt;p&gt;This might be a dupe of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4554&quot; title=&quot;Failed to create a table from existing file if file path has spaces&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4554&quot;&gt;&lt;del&gt;HIVE-4554&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13668694" author="gwenshap" created="Tue, 28 May 2013 21:22:16 +0000"  >&lt;p&gt;You are right, it is. I tried to search for existing bugs but missed that one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 28 May 2013 20:10:42 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330094</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 34 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ky6f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330428</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4623] LOAD DATA should support &quot;ignore 1 lines&quot; syntax</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4623</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;MySQL supports the following syntax to ignore lines while loading data:&lt;br/&gt;
LOAD DATA INFILE &apos;/tmp/test.txt&apos; INTO TABLE test IGNORE 1 LINES;&lt;/p&gt;

&lt;p&gt;Its a nice shortcut, especially for CSV files with column headers.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12649783">HIVE-4623</key>
            <summary>LOAD DATA should support &quot;ignore 1 lines&quot; syntax</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="gwenshap">Gwen Shapira</reporter>
                        <labels>
                    </labels>
                <created>Tue, 28 May 2013 20:30:28 +0000</created>
                <updated>Fri, 21 Jun 2013 06:54:21 +0000</updated>
                                            <version>0.10.0</version>
                                                    <component>Query Processor</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>3</watches>
                                                                    <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12654094">HIVE-4776</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330110</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 34 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ky9z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330444</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4624] Integrate Vectorized Substr into Vectorized QE</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4624</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Need to hook up the Vectorized Substr directly into Hive Vectorized QE so it can be leveraged.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12649825">HIVE-4624</key>
            <summary>Integrate Vectorized Substr into Vectorized QE</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ehans">Eric Hanson</assignee>
                                    <reporter username="tnachen">Timothy Chen</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 May 2013 00:23:10 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:13 +0000</updated>
                            <resolved>Sat, 21 Sep 2013 15:42:12 +0000</resolved>
                                    <version>vectorization-branch</version>
                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13698374" author="ehans" created="Tue, 2 Jul 2013 23:16:22 +0000"  >&lt;p&gt;Tim, please give a status update. Thanks.&lt;/p&gt;</comment>
                            <comment id="13717657" author="ehans" created="Tue, 23 Jul 2013 21:41:48 +0000"  >&lt;p&gt;Tim will try to get this done by Thurs or else explicitly give it to somebody else to finish.&lt;/p&gt;</comment>
                            <comment id="13721385" author="ehans" created="Fri, 26 Jul 2013 23:39:09 +0000"  >&lt;p&gt;Tim and I agreed I&apos;ll take this one.&lt;/p&gt;</comment>
                            <comment id="13724350" author="ehans" created="Tue, 30 Jul 2013 20:19:53 +0000"  >&lt;p&gt;This patch includes both changes to VectorizationContext to enable SUBSTR() to run end-to-end, but also bug fixes and unit test fixes related to StringSubstrColStart and StringSubstrColStartLen. I did ad hoc tests from the console to test a large number of variations of use of SUBSTR() in vectorized mode.&lt;/p&gt;</comment>
                            <comment id="13724595" author="hiveqa" created="Tue, 30 Jul 2013 23:21:03 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12595033/HIVE-4624.1-vectorization.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12595033/HIVE-4624.1-vectorization.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/249/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/249/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/249/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/249/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-249/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-vectorization-source ]]
+ [[ ! -d apache-svn-vectorization-source/.svn ]]
+ [[ ! -d apache-svn-vectorization-source ]]
+ cd apache-svn-vectorization-source
+ svn revert -R .
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf
+ svn update
U    metastore/build.xml
U    metastore/ivy.xml
A    metastore/scripts/upgrade/derby/hive-schema-0.12.0.derby.sql
A    metastore/scripts/upgrade/derby/013-HIVE-3255.derby.sql
A    metastore/scripts/upgrade/derby/upgrade-0.11.0-to-0.12.0.derby.sql
A    metastore/scripts/upgrade/mysql/013-HIVE-3255.mysql.sql
A    metastore/scripts/upgrade/mysql/upgrade-0.11.0-to-0.12.0.mysql.sql
A    metastore/scripts/upgrade/mysql/hive-schema-0.12.0.mysql.sql
A    metastore/scripts/upgrade/oracle/013-HIVE-3255.oracle.sql
A    metastore/scripts/upgrade/oracle/upgrade-0.11.0-to-0.12.0.oracle.sql
A    metastore/scripts/upgrade/oracle/hive-schema-0.12.0.oracle.sql
A    metastore/scripts/upgrade/postgres/hive-schema-0.12.0.postgres.sql
A    metastore/scripts/upgrade/postgres/013-HIVE-3255.postgres.sql
A    metastore/scripts/upgrade/postgres/upgrade-0.11.0-to-0.12.0.postgres.sql
U    metastore/src/test/org/apache/hadoop/hive/metastore/DummyRawStoreControlledCommit.java
U    metastore/src/test/org/apache/hadoop/hive/metastore/DummyRawStoreForJdoConnection.java
U    metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java
U    metastore/src/model/package.jdo
A    metastore/src/model/org/apache/hadoop/hive/metastore/model/MMasterKey.java
A    metastore/src/model/org/apache/hadoop/hive/metastore/model/MDelegationToken.java
U    metastore/src/java/org/apache/hadoop/hive/metastore/RawStore.java
U    metastore/src/java/org/apache/hadoop/hive/metastore/parser/ExpressionTree.java
U    metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g
U    metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
U    metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java
U    ivy/libraries.properties
A    data/files/v2.txt
A    data/files/flights_join.txt
A    data/files/v1.txt
A    data/files/flights_tiny.txt.1
U    data/files/datatypes.txt
U    data/files/csv.txt
U    hcatalog/storage-handlers/hbase/src/java/org/apache/hcatalog/hbase/snapshot/RevisionManagerFactory.java
U    hcatalog/build-support/ant/checkstyle.xml
U    hcatalog/webhcat/svr/src/main/java/org/apache/hcatalog/templeton/tool/TempletonControllerJob.java
A    hcatalog/hcatalog-pig-adapter/src/test/java/org/apache/hcatalog/pig/TestE2EScenarios.java
A    hcatalog/hcatalog-pig-adapter/src/test/java/org/apache/hcatalog/pig/TestOrcHCatLoaderComplexSchema.java
U    hcatalog/hcatalog-pig-adapter/src/test/java/org/apache/hcatalog/pig/TestHCatLoader.java
U    hcatalog/hcatalog-pig-adapter/src/test/java/org/apache/hcatalog/pig/TestHCatLoaderComplexSchema.java
U    hcatalog/hcatalog-pig-adapter/src/main/java/org/apache/hcatalog/pig/PigHCatUtil.java
U    hcatalog/src/test/e2e/templeton/build.xml
U    hcatalog/src/test/e2e/templeton/drivers/TestDriverCurl.pm
A    hcatalog/src/test/e2e/templeton/tests/jobsubmission2.conf
U    hcatalog/src/test/e2e/templeton/README.txt
U    hcatalog/core/src/main/java/org/apache/hcatalog/data/schema/HCatSchemaUtils.java
U    hcatalog/core/src/main/java/org/apache/hcatalog/data/HCatRecordSerDe.java
U    common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
U    service/src/gen/thrift/gen-cpp/TCLIService_constants.cpp
U    service/src/gen/thrift/gen-cpp/TCLIService_types.cpp
U    service/src/gen/thrift/gen-cpp/TCLIService_types.h
U    service/src/gen/thrift/gen-rb/t_c_l_i_service_constants.rb
U    service/src/gen/thrift/gen-rb/t_c_l_i_service_types.rb
U    service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TTypeId.java
U    service/src/gen/thrift/gen-javabean/org/apache/hive/service/cli/thrift/TCLIServiceConstants.java
U    service/src/gen/thrift/gen-py/TCLIService/ttypes.py
U    service/src/gen/thrift/gen-py/TCLIService/constants.py
U    service/src/java/org/apache/hive/service/cli/Type.java
U    service/src/java/org/apache/hive/service/cli/ColumnValue.java
A    service/README.txt
U    service/if/TCLIService.thrift
U    contrib/src/test/results/clientpositive/dboutput.q.out
U    contrib/src/test/results/clientpositive/serde_typedbytes4.q.out
U    serde/src/test/org/apache/hadoop/hive/serde2/lazybinary/TestLazyBinarySerDe.java
U    serde/src/test/org/apache/hadoop/hive/serde2/lazybinary/MyTestClassBigger.java
U    serde/src/test/org/apache/hadoop/hive/serde2/lazybinary/MyTestClassSmaller.java
U    serde/src/test/org/apache/hadoop/hive/serde2/avro/TestAvroObjectInspectorGenerator.java
U    serde/src/test/org/apache/hadoop/hive/serde2/avro/TestAvroDeserializer.java
A    serde/src/test/org/apache/hadoop/hive/serde2/io
A    serde/src/test/org/apache/hadoop/hive/serde2/io/TestTimestampWritable.java
U    serde/src/test/org/apache/hadoop/hive/serde2/binarysortable/MyTestClass.java
U    serde/src/test/org/apache/hadoop/hive/serde2/binarysortable/TestBinarySortableSerDe.java
U    serde/src/test/org/apache/hadoop/hive/serde2/TestStatsSerde.java
U    serde/src/java/org/apache/hadoop/hive/serde2/SerDeUtils.java
U    serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroDeserializer.java
U    serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroSerializer.java
U    serde/src/java/org/apache/hadoop/hive/serde2/avro/SchemaToTypeInfo.java
A    serde/src/java/org/apache/hadoop/hive/serde2/io/DateWritable.java
U    serde/src/java/org/apache/hadoop/hive/serde2/io/TimestampWritable.java
U    serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java
U    serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java
U    serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java
U    serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyPrimitiveObjectInspectorFactory.java
A    serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyDateObjectInspector.java
A    serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyDate.java
U    serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/BinarySortableSerDe.java
U    serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryFactory.java
A    serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryDate.java
U    serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryUtils.java
U    serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java
U    serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/PrimitiveObjectInspector.java
U    serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorConverters.java
U    serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorUtils.java
A    serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableDateObjectInspector.java
A    serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/SettableDateObjectInspector.java
A    serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/DateObjectInspector.java
U    serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java
U    serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory.java
U    serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java
A    serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaDateObjectInspector.java
A    serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantDateObjectInspector.java
U    serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory.java
U    ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java
D    ql/src/test/queries/clientnegative/invalid_t_create1.q
U    ql/src/test/queries/clientnegative/invalid_t_alter1.q
U    ql/src/test/queries/clientnegative/invalid_t_alter2.q
U    ql/src/test/queries/clientnegative/serde_regex.q
U    ql/src/test/queries/clientnegative/invalid_t_transform.q
A    ql/src/test/queries/clientnegative/date_literal1.q
A    ql/src/test/queries/clientnegative/date_literal2.q
A    ql/src/test/queries/clientnegative/date_literal3.q
A    ql/src/test/queries/clientpositive/date_1.q
A    ql/src/test/queries/clientpositive/date_3.q
A    ql/src/test/queries/clientpositive/partition_date2.q
A    ql/src/test/queries/clientpositive/date_serde.q
A    ql/src/test/queries/clientpositive/serde_user_properties.q
A    ql/src/test/queries/clientpositive/partition_date.q
A    ql/src/test/queries/clientpositive/date_udf.q
A    ql/src/test/queries/clientpositive/date_2.q
A    ql/src/test/queries/clientpositive/date_4.q
A    ql/src/test/queries/clientpositive/date_comparison.q
A    ql/src/test/queries/clientpositive/dynamic_partition_skip_default.q
A    ql/src/test/queries/clientpositive/describe_comment_nonascii.q
A    ql/src/test/queries/clientpositive/union_date.q
A    ql/src/test/queries/clientpositive/ctas_date.q
A    ql/src/test/queries/clientpositive/ptf_reuse_memstore.q
U    ql/src/test/queries/clientpositive/avro_nullable_fields.q
A    ql/src/test/queries/clientpositive/date_join1.q
U    ql/src/test/results/compiler/errors/missing_overwrite.q.out
U    ql/src/test/results/compiler/plan/input5.q.xml
U    ql/src/test/results/compiler/plan/input_testxpath2.q.xml
U    ql/src/test/results/compiler/plan/input6.q.xml
U    ql/src/test/results/compiler/plan/input7.q.xml
U    ql/src/test/results/compiler/plan/input_testsequencefile.q.xml
U    ql/src/test/results/compiler/plan/input8.q.xml
U    ql/src/test/results/compiler/plan/input9.q.xml
U    ql/src/test/results/compiler/plan/udf1.q.xml
U    ql/src/test/results/compiler/plan/input20.q.xml
U    ql/src/test/results/compiler/plan/sample1.q.xml
U    ql/src/test/results/compiler/plan/udf4.q.xml
U    ql/src/test/results/compiler/plan/sample2.q.xml
U    ql/src/test/results/compiler/plan/sample3.q.xml
U    ql/src/test/results/compiler/plan/udf6.q.xml
U    ql/src/test/results/compiler/plan/sample4.q.xml
U    ql/src/test/results/compiler/plan/sample5.q.xml
U    ql/src/test/results/compiler/plan/sample6.q.xml
U    ql/src/test/results/compiler/plan/sample7.q.xml
U    ql/src/test/results/compiler/plan/groupby1.q.xml
U    ql/src/test/results/compiler/plan/groupby2.q.xml
U    ql/src/test/results/compiler/plan/udf_case.q.xml
U    ql/src/test/results/compiler/plan/groupby3.q.xml
U    ql/src/test/results/compiler/plan/subq.q.xml
U    ql/src/test/results/compiler/plan/cast1.q.xml
U    ql/src/test/results/compiler/plan/groupby4.q.xml
U    ql/src/test/results/compiler/plan/groupby5.q.xml
U    ql/src/test/results/compiler/plan/groupby6.q.xml
U    ql/src/test/results/compiler/plan/join1.q.xml
U    ql/src/test/results/compiler/plan/join2.q.xml
U    ql/src/test/results/compiler/plan/join3.q.xml
U    ql/src/test/results/compiler/plan/join4.q.xml
U    ql/src/test/results/compiler/plan/join5.q.xml
U    ql/src/test/results/compiler/plan/case_sensitivity.q.xml
U    ql/src/test/results/compiler/plan/join6.q.xml
U    ql/src/test/results/compiler/plan/join7.q.xml
U    ql/src/test/results/compiler/plan/join8.q.xml
U    ql/src/test/results/compiler/plan/union.q.xml
U    ql/src/test/results/compiler/plan/udf_when.q.xml
U    ql/src/test/results/compiler/plan/input_testxpath.q.xml
U    ql/src/test/results/compiler/plan/input_part1.q.xml
U    ql/src/test/results/compiler/plan/input1.q.xml
U    ql/src/test/results/compiler/plan/input2.q.xml
U    ql/src/test/results/compiler/plan/input3.q.xml
U    ql/src/test/results/compiler/plan/input4.q.xml
D    ql/src/test/results/clientnegative/invalid_t_create1.q.out
U    ql/src/test/results/clientnegative/ptf_negative_PartitionBySortBy.q.out
A    ql/src/test/results/clientnegative/date_literal2.q.out
U    ql/src/test/results/clientnegative/invalid_t_alter1.q.out
U    ql/src/test/results/clientnegative/invalid_t_transform.q.out
A    ql/src/test/results/clientnegative/date_literal3.q.out
U    ql/src/test/results/clientnegative/invalid_t_alter2.q.out
U    ql/src/test/results/clientnegative/ptf_negative_DistributeByOrderBy.q.out
U    ql/src/test/results/clientnegative/invalid_t_create2.q.out
U    ql/src/test/results/clientnegative/serde_regex.q.out
A    ql/src/test/results/clientnegative/date_literal1.q.out
U    ql/src/test/results/clientnegative/invalid_create_tbl1.q.out
U    ql/src/test/results/clientpositive/bucket2.q.out
U    ql/src/test/results/clientpositive/auto_sortmerge_join_5.q.out
U    ql/src/test/results/clientpositive/input14_limit.q.out
U    ql/src/test/results/clientpositive/join23.q.out
U    ql/src/test/results/clientpositive/udf_second.q.out
U    ql/src/test/results/clientpositive/list_bucket_query_multiskew_3.q.out
U    ql/src/test/results/clientpositive/ctas_colname.q.out
U    ql/src/test/results/clientpositive/multi_insert_move_tasks_share_dependencies.q.out
U    ql/src/test/results/clientpositive/smb_mapjoin_13.q.out
U    ql/src/test/results/clientpositive/join32.q.out
U    ql/src/test/results/clientpositive/input_part9.q.out
U    ql/src/test/results/clientpositive/auto_join8.q.out
U    ql/src/test/results/clientpositive/bucketmapjoin11.q.out
U    ql/src/test/results/clientpositive/join41.q.out
A    ql/src/test/results/clientpositive/date_2.q.out
U    ql/src/test/results/clientpositive/list_bucket_dml_11.q.out
U    ql/src/test/results/clientpositive/udf9.q.out
U    ql/src/test/results/clientpositive/ppd_join_filter.q.out
U    ql/src/test/results/clientpositive/input_part4.q.out
U    ql/src/test/results/clientpositive/union20.q.out
U    ql/src/test/results/clientpositive/column_access_stats.q.out
U    ql/src/test/results/clientpositive/transform_ppr2.q.out
U    ql/src/test/results/clientpositive/rand_partitionpruner2.q.out
U    ql/src/test/results/clientpositive/index_stale_partitioned.q.out
A    ql/src/test/results/clientpositive/ptf_reuse_memstore.q.out
U    ql/src/test/results/clientpositive/avro_nullable_fields.q.out
U    ql/src/test/results/clientpositive/input12_hadoop20.q.out
A    ql/src/test/results/clientpositive/dynamic_partition_skip_default.q.out
U    ql/src/test/results/clientpositive/subq2.q.out
U    ql/src/test/results/clientpositive/sample6.q.out
U    ql/src/test/results/clientpositive/infer_const_type.q.out
U    ql/src/test/results/clientpositive/input18.q.out
U    ql/src/test/results/clientpositive/input2_limit.q.out
U    ql/src/test/results/clientpositive/multi_join_union.q.out
A    ql/src/test/results/clientpositive/union_date.q.out
U    ql/src/test/results/clientpositive/udf_minute.q.out
U    ql/src/test/results/clientpositive/sample1.q.out
U    ql/src/test/results/clientpositive/cast1.q.out
U    ql/src/test/results/clientpositive/having.q.out
U    ql/src/test/results/clientpositive/quote1.q.out
U    ql/src/test/results/clientpositive/notable_alias2.q.out
U    ql/src/test/results/clientpositive/list_bucket_dml_7.q.out
U    ql/src/test/results/clientpositive/metadataonly1.q.out
U    ql/src/test/results/clientpositive/input13.q.out
U    ql/src/test/results/clientpositive/bucketcontext_4.q.out
U    ql/src/test/results/clientpositive/sort_merge_join_desc_4.q.out
A    ql/src/test/results/clientpositive/partition_date.q.out
U    ql/src/test/results/clientpositive/join16.q.out
U    ql/src/test/results/clientpositive/nullgroup2.q.out
U    ql/src/test/results/clientpositive/join39.q.out
U    ql/src/test/results/clientpositive/multiMapJoin1.q.out
U    ql/src/test/results/clientpositive/index_auto.q.out
U    ql/src/test/results/clientpositive/bucket4.q.out
U    ql/src/test/results/clientpositive/auto_sortmerge_join_7.q.out
U    ql/src/test/results/clientpositive/udf_like.q.out
U    ql/src/test/results/clientpositive/join5.q.out
U    ql/src/test/results/clientpositive/list_bucket_dml_2.q.out
U    ql/src/test/results/clientpositive/columnstats_tbllvl.q.out
U    ql/src/test/results/clientpositive/join11.q.out
U    ql/src/test/results/clientpositive/smb_mapjoin_15.q.out
U    ql/src/test/results/clientpositive/join34.q.out
U    ql/src/test/results/clientpositive/udf_hour.q.out
U    ql/src/test/results/clientpositive/bucketmapjoin1.q.out
U    ql/src/test/results/clientpositive/ppd_udf_col.q.out
U    ql/src/test/results/clientpositive/auto_join12.q.out
U    ql/src/test/results/clientpositive/index_bitmap_auto.q.out
U    ql/src/test/results/clientpositive/auto_sortmerge_join_2.q.out
U    ql/src/test/results/clientpositive/bucketmapjoin13.q.out
U    ql/src/test/results/clientpositive/ppd_outer_join1.q.out
U    ql/src/test/results/clientpositive/join20.q.out
U    ql/src/test/results/clientpositive/udf_reflect2.q.out
U    ql/src/test/results/clientpositive/join0.q.out
U    ql/src/test/results/clientpositive/auto_join21.q.out
A    ql/src/test/results/clientpositive/date_serde.q.out
A    ql/src/test/results/clientpositive/date_4.q.out
U    ql/src/test/results/clientpositive/list_bucket_dml_13.q.out
U    ql/src/test/results/clientpositive/bucket_map_join_2.q.out
U    ql/src/test/results/clientpositive/auto_join5.q.out
U    ql/src/test/results/clientpositive/union22.q.out
U    ql/src/test/results/clientpositive/avro_schema_literal.q.out
U    ql/src/test/results/clientpositive/index_auto_multiple.q.out
U    ql/src/test/results/clientpositive/parallel_orderby.q.out
U    ql/src/test/results/clientpositive/allcolref_in_udf.q.out
U    ql/src/test/results/clientpositive/input_part1.q.out
U    ql/src/test/results/clientpositive/groupby_sort_skew_1.q.out
U    ql/src/test/results/clientpositive/auto_join0.q.out
A    ql/src/test/results/clientpositive/describe_comment_nonascii.q.out
U    ql/src/test/results/clientpositive/udf1.q.out
U    ql/src/test/results/clientpositive/ppd_clusterby.q.out
U    ql/src/test/results/clientpositive/columnstats_partlvl.q.out
U    ql/src/test/results/clientpositive/smb_mapjoin9.q.out
U    ql/src/test/results/clientpositive/groupby_multi_single_reducer2.q.out
U    ql/src/test/results/clientpositive/bucketmapjoin_negative3.q.out
U    ql/src/test/results/clientpositive/index_auto_update.q.out
U    ql/src/test/results/clientpositive/list_bucket_query_oneskew_1.q.out
U    ql/src/test/results/clientpositive/sample8.q.out
U    ql/src/test/results/clientpositive/join_map_ppr.q.out
U    ql/src/test/results/clientpositive/auto_sortmerge_join_12.q.out
U    ql/src/test/results/clientpositive/ppd_multi_insert.q.out
U    ql/src/test/results/clientpositive/udf_union.q.out
U    ql/src/test/results/clientpositive/ppr_allchildsarenull.q.out
U    ql/src/test/results/clientpositive/macro.q.out
U    ql/src/test/results/clientpositive/groupby_ppr_multi_distinct.q.out
U    ql/src/test/results/clientpositive/list_bucket_dml_9.q.out
U    ql/src/test/results/clientpositive/bucketcontext_6.q.out
U    ql/src/test/results/clientpositive/sort_merge_join_desc_6.q.out
U    ql/src/test/results/clientpositive/nullgroup4.q.out
U    ql/src/test/results/clientpositive/ppd_transform.q.out
U    ql/src/test/results/clientpositive/bucketmapjoin8.q.out
U    ql/src/test/results/clientpositive/index_bitmap_compression.q.out
U    ql/src/test/results/clientpositive/stats12.q.out
U    ql/src/test/results/clientpositive/nonmr_fetch.q.out
U    ql/src/test/results/clientpositive/correlationoptimizer8.q.out
U    ql/src/test/results/clientpositive/join_filters_overlap.q.out
U    ql/src/test/results/clientpositive/router_join_ppr.q.out
U    ql/src/test/results/clientpositive/input4.q.out
U    ql/src/test/results/clientpositive/join7.q.out
U    ql/src/test/results/clientpositive/list_bucket_dml_4.q.out
U    ql/src/test/results/clientpositive/mapjoin_subquery.q.out
U    ql/src/test/results/clientpositive/auto_join28.q.out
U    ql/src/test/results/clientpositive/bucketcontext_1.q.out
U    ql/src/test/results/clientpositive/join13.q.out
U    ql/src/test/results/clientpositive/sort_merge_join_desc_1.q.out
U    ql/src/test/results/clientpositive/bucketmapjoin3.q.out
U    ql/src/test/results/clientpositive/multi_insert_gby.q.out
U    ql/src/test/results/clientpositive/bucket1.q.out
U    ql/src/test/results/clientpositive/auto_sortmerge_join_4.q.out
U    ql/src/test/results/clientpositive/input42.q.out
U    ql/src/test/results/clientpositive/groupby_multi_single_reducer.q.out
U    ql/src/test/results/clientpositive/list_bucket_query_multiskew_2.q.out
U    ql/src/test/results/clientpositive/auto_join23.q.out
U    ql/src/test/results/clientpositive/smb_mapjoin_12.q.out
U    ql/src/test/results/clientpositive/auto_join7.q.out
U    ql/src/test/results/clientpositive/bucketmapjoin10.q.out
U    ql/src/test/results/clientpositive/union24.q.out
U    ql/src/test/results/clientpositive/input11_limit.q.out
U    ql/src/test/results/clientpositive/join40.q.out
U    ql/src/test/results/clientpositive/udtf_explode.q.out
A    ql/src/test/results/clientpositive/date_1.q.out
U    ql/src/test/results/clientpositive/outer_join_ppr.q.out
U    ql/src/test/results/clientpositive/union33.q.out
U    ql/src/test/results/clientpositive/list_bucket_dml_10.q.out
U    ql/src/test/results/clientpositive/auto_join2.q.out
U    ql/src/test/results/clientpositive/binary_output_format.q.out
U    ql/src/test/results/clientpositive/multi_insert.q.out
U    ql/src/test/results/clientpositive/ppd2.q.out
U    ql/src/test/results/clientpositive/ppr_pushdown3.q.out
U    ql/src/test/results/clientpositive/transform_ppr1.q.out
U    ql/src/test/results/clientpositive/index_auto_empty.q.out
U    ql/src/test/results/clientpositive/regexp_extract.q.out
U    ql/src/test/results/clientpositive/rand_partitionpruner1.q.out
U    ql/src/test/results/clientpositive/combine2_hadoop20.q.out
U    ql/src/test/results/clientpositive/noalias_subq1.q.out
A    ql/src/test/results/clientpositive/partition_date2.q.out
U    ql/src/test/results/clientpositive/regex_col.q.out
U    ql/src/test/results/clientpositive/louter_join_ppr.q.out
U    ql/src/test/results/clientpositive/list_bucket_query_oneskew_3.q.out
U    ql/src/test/results/clientpositive/udf_java_method.q.out
U    ql/src/test/results/clientpositive/ppd_union_view.q.out
U    ql/src/test/results/clientpositive/filter_join_breaktask.q.out
U    ql/src/test/results/clientpositive/udf_10_trims.q.out
U    ql/src/test/results/clientpositive/combine2.q.out
U    ql/src/test/results/clientpositive/mergejoins.q.out
A    ql/src/test/results/clientpositive/date_udf.q.out
U    ql/src/test/results/clientpositive/sample5.q.out
U    ql/src/test/results/clientpositive/no_hooks.q.out
U    ql/src/test/results/clientpositive/bucketcontext_8.q.out
U    ql/src/test/results/clientpositive/mapjoin_subquery2.q.out
U    ql/src/test/results/clientpositive/udf_explode.q.out
U    ql/src/test/results/clientpositive/groupby_position.q.out
U    ql/src/test/results/clientpositive/notable_alias1.q.out
U    ql/src/test/results/clientpositive/join9.q.out
U    ql/src/test/results/clientpositive/set_processor_namespaces.q.out
U    ql/src/test/results/clientpositive/list_bucket_dml_6.q.out
U    ql/src/test/results/clientpositive/bucketcontext_3.q.out
U    ql/src/test/results/clientpositive/sort_merge_join_desc_3.q.out
U    ql/src/test/results/clientpositive/join38.q.out
U    ql/src/test/results/clientpositive/bucketmapjoin5.q.out
U    ql/src/test/results/clientpositive/groupby_grouping_sets4.q.out
U    ql/src/test/results/clientpositive/udf_lower.q.out
U    ql/src/test/results/clientpositive/nullgroup.q.out
U    ql/src/test/results/clientpositive/auto_join14_hadoop20.q.out
U    ql/src/test/results/clientpositive/auto_join16.q.out
U    ql/src/test/results/clientpositive/bucket3.q.out
U    ql/src/test/results/clientpositive/index_auto_partitioned.q.out
U    ql/src/test/results/clientpositive/join4.q.out
U    ql/src/test/results/clientpositive/list_bucket_dml_1.q.out
U    ql/src/test/results/clientpositive/nullgroup4_multi_distinct.q.out
U    ql/src/test/results/clientpositive/join33.q.out
U    ql/src/test/results/clientpositive/index_auto_file_format.q.out
U    ql/src/test/results/clientpositive/auto_join11.q.out
U    ql/src/test/results/clientpositive/bucketmapjoin12.q.out
U    ql/src/test/results/clientpositive/auto_sortmerge_join_1.q.out
U    ql/src/test/results/clientpositive/auto_join20.q.out
A    ql/src/test/results/clientpositive/date_3.q.out
U    ql/src/test/results/clientpositive/list_bucket_dml_12.q.out
U    ql/src/test/results/clientpositive/bucket_map_join_1.q.out
U    ql/src/test/results/clientpositive/input_part5.q.out
U    ql/src/test/results/clientpositive/auto_join4.q.out
U    ql/src/test/results/clientpositive/load_dyn_part8.q.out
U    ql/src/test/results/clientpositive/truncate_column_list_bucket.q.out
U    ql/src/test/results/clientpositive/rand_partitionpruner3.q.out
U    ql/src/test/results/clientpositive/index_stale.q.out
U    ql/src/test/results/clientpositive/groupby_sort_6.q.out
U    ql/src/test/results/clientpositive/join32_lessSize.q.out
U    ql/src/test/results/clientpositive/groupby_sort_1.q.out
U    ql/src/test/results/clientpositive/udf_reflect.q.out
U    ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out
U    ql/src/test/results/clientpositive/sample7.q.out
U    ql/src/test/results/clientpositive/auto_sortmerge_join_11.q.out
U    ql/src/test/results/clientpositive/sample10.q.out
U    ql/src/test/results/clientpositive/subq.q.out
U    ql/src/test/results/clientpositive/plan_json.q.out
U    ql/src/test/results/clientpositive/index_auto_mult_tables_compact.q.out
U    ql/src/test/results/clientpositive/sample2.q.out
U    ql/src/test/results/clientpositive/groupby_map_ppr_multi_distinct.q.out
U    ql/src/test/results/clientpositive/disable_merge_for_bucketing.q.out
U    ql/src/test/results/clientpositive/union.q.out
U    ql/src/test/results/clientpositive/list_bucket_dml_8.q.out
U    ql/src/test/results/clientpositive/input14.q.out
U    ql/src/test/results/clientpositive/bucketcontext_5.q.out
U    ql/src/test/results/clientpositive/sort_merge_join_desc_5.q.out
U    ql/src/test/results/clientpositive/join17.q.out
U    ql/src/test/results/clientpositive/bucketmapjoin7.q.out
U    ql/src/test/results/clientpositive/index_compression.q.out
U    ql/src/test/results/clientpositive/join_star.q.out
U    ql/src/test/results/clientpositive/udf_parse_url.q.out
U    ql/src/test/results/clientpositive/stats11.q.out
U    ql/src/test/results/clientpositive/bucket5.q.out
U    ql/src/test/results/clientpositive/input23.q.out
U    ql/src/test/results/clientpositive/auto_sortmerge_join_8.q.out
U    ql/src/test/results/clientpositive/join26.q.out
U    ql/src/test/results/clientpositive/multi_insert_lateral_view.q.out
U    ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out
U    ql/src/test/results/clientpositive/join6.q.out
U    ql/src/test/results/clientpositive/list_bucket_dml_3.q.out
U    ql/src/test/results/clientpositive/skewjoin.q.out
U    ql/src/test/results/clientpositive/auto_join27.q.out
U    ql/src/test/results/clientpositive/join14_hadoop20.q.out
U    ql/src/test/results/clientpositive/join12.q.out
U    ql/src/test/results/clientpositive/join35.q.out
A    ql/src/test/results/clientpositive/date_join1.q.out
U    ql/src/test/results/clientpositive/bucketmapjoin2.q.out
U    ql/src/test/results/clientpositive/index_bitmap3.q.out
U    ql/src/test/results/clientpositive/auto_join13.q.out
U    ql/src/test/results/clientpositive/auto_sortmerge_join_3.q.out
U    ql/src/test/results/clientpositive/join21.q.out
U    ql/src/test/results/clientpositive/groupby_ppr.q.out
U    ql/src/test/results/clientpositive/stats0.q.out
U    ql/src/test/results/clientpositive/list_bucket_query_multiskew_1.q.out
U    ql/src/test/results/clientpositive/load_dyn_part13.q.out
U    ql/src/test/results/clientpositive/auto_join22.q.out
U    ql/src/test/results/clientpositive/smb_mapjoin_11.q.out
U    ql/src/test/results/clientpositive/union_ppr.q.out
A    ql/src/test/results/clientpositive/serde_user_properties.q.out
U    ql/src/test/results/clientpositive/input_part7.q.out
U    ql/src/test/results/clientpositive/auto_join6.q.out
U    ql/src/test/results/clientpositive/pcr.q.out
U    ql/src/test/results/clientpositive/correlationoptimizer10.q.out
U    ql/src/test/results/clientpositive/ctas_hadoop20.q.out
U    ql/src/test/results/clientpositive/index_auto_self_join.q.out
U    ql/src/test/results/clientpositive/mapjoin_filter_on_outerjoin.q.out
U    ql/src/test/results/clientpositive/cluster.q.out
U    ql/src/test/results/clientpositive/input_part2.q.out
U    ql/src/test/results/clientpositive/mapjoin_mapjoin.q.out
U    ql/src/test/results/clientpositive/create_view.q.out
U    ql/src/test/results/clientpositive/index_bitmap_auto_partitioned.q.out
U    ql/src/test/results/clientpositive/alter_partition_coltype.q.out
A    ql/src/test/results/clientpositive/date_comparison.q.out
U    ql/src/test/results/clientpositive/groupby_multi_single_reducer3.q.out
U    ql/src/test/results/clientpositive/list_bucket_query_oneskew_2.q.out
U    ql/src/test/results/clientpositive/reduce_deduplicate.q.out
U    ql/src/test/results/clientpositive/sample9.q.out
U    ql/src/test/results/clientpositive/index_auto_unused.q.out
U    ql/src/test/results/clientpositive/index_auto_mult_tables.q.out
U    ql/src/test/results/clientpositive/groupby_map_ppr.q.out
U    ql/src/test/results/clientpositive/ctas.q.out
U    ql/src/test/results/clientpositive/order2.q.out
U    ql/src/test/results/clientpositive/sample4.q.out
U    ql/src/test/results/clientpositive/merge3.q.out
U    ql/src/test/results/clientpositive/rcfile_null_value.q.out
U    ql/src/test/results/clientpositive/bucketcontext_7.q.out
U    ql/src/test/results/clientpositive/sort_merge_join_desc_7.q.out
U    ql/src/test/results/clientpositive/input1_limit.q.out
U    ql/src/test/results/clientpositive/bucketmapjoin9.q.out
U    ql/src/test/results/clientpositive/stats13.q.out
U    ql/src/test/results/clientpositive/join28.q.out
A    ql/src/test/results/clientpositive/ctas_date.q.out
U    ql/src/test/results/clientpositive/join8.q.out
U    ql/src/test/results/clientpositive/list_bucket_dml_5.q.out
U    ql/src/test/results/clientpositive/input11.q.out
U    ql/src/test/results/clientpositive/auto_join29.q.out
U    ql/src/test/results/clientpositive/bucketcontext_2.q.out
U    ql/src/test/results/clientpositive/sort_merge_join_desc_2.q.out
U    ql/src/test/results/clientpositive/bucketmapjoin4.q.out
U    ql/src/test/results/beelinepositive/auto_join4.q.out
U    ql/src/test/results/beelinepositive/auto_join16.q.out
U    ql/src/test/results/beelinepositive/auto_join5.q.out
U    ql/src/test/results/beelinepositive/auto_join20.q.out
U    ql/src/test/results/beelinepositive/auto_join0.q.out
U    ql/src/test/results/beelinepositive/auto_join6.q.out
U    ql/src/test/results/beelinepositive/auto_join12.q.out
U    ql/src/test/results/beelinepositive/auto_join21.q.out
U    ql/src/test/results/beelinepositive/auto_join27.q.out
U    ql/src/test/results/beelinepositive/auto_join7.q.out
U    ql/src/test/results/beelinepositive/auto_join13.q.out
U    ql/src/test/results/beelinepositive/create_view.q.out
U    ql/src/test/results/beelinepositive/auto_join28.q.out
U    ql/src/test/results/beelinepositive/auto_join8.q.out
U    ql/src/test/results/beelinepositive/auto_join23.q.out
U    ql/src/test/results/beelinepositive/auto_join29.q.out
U    ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java
U    ql/src/test/org/apache/hadoop/hive/ql/hooks/VerifyHiveSortedInputFormatUsedHook.java
U    ql/src/test/org/apache/hadoop/hive/ql/exec/TestUtilities.java
U    ql/src/test/org/apache/hadoop/hive/ql/exec/TestFunctionRegistry.java
U    ql/src/test/org/apache/hadoop/hive/ql/exec/TestOperators.java
U    ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java
U    ql/src/test/org/apache/hadoop/hive/ql/exec/vector/expressions/TestVectorStringExpressions.java
U    ql/src/test/org/apache/hadoop/hive/ql/exec/TestPlan.java
U    ql/src/test/org/apache/hadoop/hive/ql/io/TestSymlinkTextInputFormat.java
U    ql/src/protobuf/org/apache/hadoop/hive/ql/io/orc/orc_proto.proto
U    ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java
U    ql/src/java/org/apache/hadoop/hive/ql/metadata/formatting/TextMetaDataFormatter.java
U    ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/ExplainTask.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/PTFPersistence.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorizedRowBatchCtx.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/templates/CodeGen.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/templates/VectorUDAFVar.txt
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/templates/VectorUDAFMinMax.txt
A    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/templates/FilterStringScalarCompareColumn.txt
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/templates/VectorUDAFSum.txt
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/templates/VectorUDAFAvg.txt
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen/VectorUDAFVarPopDouble.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen/VectorUDAFMinLong.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen/VectorUDAFVarSampDouble.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen/VectorUDAFStdPopDouble.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen/VectorUDAFMaxLong.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen/VectorUDAFStdSampDouble.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen/VectorUDAFAvgDouble.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen/VectorUDAFMinDouble.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen/VectorUDAFMaxDouble.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen/VectorUDAFSumLong.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen/VectorUDAFVarPopLong.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen/VectorUDAFVarSampLong.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen/VectorUDAFStdPopLong.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen/VectorUDAFStdSampLong.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen/VectorUDAFAvgLong.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen/VectorUDAFSumDouble.java
A    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen/FilterStringScalarGreaterStringColumn.java
A    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen/FilterStringScalarNotEqualStringColumn.java
A    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen/FilterStringScalarLessEqualStringColumn.java
A    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen/FilterStringScalarGreaterEqualStringColumn.java
A    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen/FilterStringScalarLessStringColumn.java
A    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen/FilterStringScalarEqualStringColumn.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorMapOperator.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorExecMapper.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecMapper.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapRedTask.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecReducer.java
U    ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
U    ql/src/java/org/apache/hadoop/hive/ql/index/compact/CompactIndexHandler.java
U    ql/src/java/org/apache/hadoop/hive/ql/io/avro/AvroGenericRecordReader.java
U    ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java
U    ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcStruct.java
U    ql/src/java/org/apache/hadoop/hive/ql/io/orc/ColumnStatisticsImpl.java
U    ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java
A    ql/src/java/org/apache/hadoop/hive/ql/io/orc/DateColumnStatistics.java
U    ql/src/java/org/apache/hadoop/hive/ql/io/SymbolicInputFormat.java
U    ql/src/java/org/apache/hadoop/hive/ql/io/CombineHiveInputFormat.java
U    ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/merge/BlockMergeTask.java
U    ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/merge/MergeWork.java
U    ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/truncate/ColumnTruncateTask.java
U    ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/truncate/ColumnTruncateWork.java
U    ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/truncate/ColumnTruncateMapper.java
U    ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/stats/PartialScanTask.java
U    ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/stats/PartialScanWork.java
U    ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java
U    ql/src/java/org/apache/hadoop/hive/ql/Driver.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/UDFDateDiff.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/UDFUnixTimeStamp.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/UDFMonth.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/UDFWeekOfYear.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToLong.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToByte.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/UDFDateSub.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFVariance.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFStdSample.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFSum.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCovarianceSample.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBaseCompare.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFHistogramNumeric.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFStd.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCovariance.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFnGrams.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToUnixTimeStamp.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFAverage.java
A    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToDate.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCorrelation.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFVarianceSample.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFContextNGrams.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFPercentileApprox.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToInteger.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToShort.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToFloat.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToString.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/UDFDateAdd.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/UDFYear.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/UDFDayOfMonth.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/UDFDate.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToDouble.java
U    ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToBoolean.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRRedSink1.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRRedSink3.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/MapJoinResolver.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/SortMergeJoinTaskDispatcher.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/GenMRSkewJoinProcessor.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/MetadataOnlyOptimizer.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/index/IndexWhereTaskDispatcher.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/index/IndexWhereProcessor.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/BucketingSortingInferenceOptimizer.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/SkewJoinResolver.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/SamplingOptimizer.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/AbstractJoinTaskDispatcher.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRTableScan1.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java
U    ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinFactory.java
U    ql/src/java/org/apache/hadoop/hive/ql/plan/PartitionDesc.java
A    ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceWork.java
U    ql/src/java/org/apache/hadoop/hive/ql/plan/MapredWork.java
A    ql/src/java/org/apache/hadoop/hive/ql/plan/MapWork.java
U    ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverMergeFiles.java
A    ql/src/java/org/apache/hadoop/hive/ql/plan/BaseWork.java
U    ql/src/java/org/apache/hadoop/hive/ql/plan/Explain.java
U    ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java
U    ql/src/java/org/apache/hadoop/hive/ql/QueryPlan.java
U    ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g
U    ql/src/java/org/apache/hadoop/hive/ql/parse/IdentifiersParser.g
U    ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java
U    ql/src/java/org/apache/hadoop/hive/ql/parse/QB.java
U    ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
U    ql/src/java/org/apache/hadoop/hive/ql/parse/ParseContext.java
U    ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
U    ql/src/java/org/apache/hadoop/hive/ql/parse/FromClauseParser.g
U    ql/src/java/org/apache/hadoop/hive/ql/parse/MapReduceCompiler.java
U    eclipse-templates/.classpath._hbase
U    eclipse-templates/.classpath
U    shims/src/common/java/org/apache/hadoop/hive/thrift/HadoopThriftAuthBridge.java
A    shims/src/common-secure/test/org/apache/hadoop/hive/thrift/TestDBTokenStore.java
A    shims/src/common-secure/java/org/apache/hadoop/hive/thrift/DBTokenStore.java
U    shims/src/common-secure/java/org/apache/hadoop/hive/thrift/MemoryTokenStore.java
U    shims/src/common-secure/java/org/apache/hadoop/hive/thrift/DelegationTokenStore.java
U    shims/src/common-secure/java/org/apache/hadoop/hive/thrift/HadoopThriftAuthBridge20S.java
U    shims/src/common-secure/java/org/apache/hadoop/hive/thrift/ZooKeeperTokenStore.java
U    conf/hive-default.xml.template
U    testutils/ptest2/src/main/resources/batch-exec.vm
U    testutils/ptest2/src/main/resources/source-prep.vm
U    testutils/ptest2/src/main/java/org/apache/hive/ptest/api/client/PTestClient.java
U    testutils/ptest2/src/main/java/org/apache/hive/ptest/api/server/TestExecutor.java
U    testutils/ptest2/src/main/java/org/apache/hive/ptest/api/request/TestStartRequest.java
U    testutils/ptest2/src/main/java/org/apache/hive/ptest/execution/ExecutionPhase.java
U    testutils/ptest2/src/main/java/org/apache/hive/ptest/execution/ReportingPhase.java
U    testutils/ptest2/src/main/java/org/apache/hive/ptest/execution/HostExecutor.java
U    testutils/ptest2/src/main/java/org/apache/hive/ptest/execution/PTest.java
U    testutils/ptest2/src/main/java/org/apache/hive/ptest/execution/JUnitReportParser.java
U    testutils/ptest2/src/main/java/org/apache/hive/ptest/execution/conf/UnitTestBatch.java
U    testutils/ptest2/src/main/java/org/apache/hive/ptest/execution/conf/QFileTestBatch.java
U    testutils/ptest2/src/main/java/org/apache/hive/ptest/execution/conf/TestConfiguration.java
U    testutils/ptest2/src/main/java/org/apache/hive/ptest/execution/JIRAService.java
D    testutils/ptest2/src/test/resources/TEST-SomeTest-failure.xml
D    testutils/ptest2/src/test/resources/test-outputs/TEST-skewjoin.q-ab8536a7-1b5c-45ed-ba29-14450f27db8b-TEST-org.apache.hadoop.hive.cli.TestCliDriver.xml
D    testutils/ptest2/src/test/resources/test-outputs/TEST-index_auth.q-bucketcontex-ba31fb54-1d7f-4c70-a89d-477b7d155191-TEST-org.apache.hadoop.hive.cli.TestCliDriver.xml
D    testutils/ptest2/src/test/resources/test-outputs/TEST-skewjoin_union_remove_1.q-6fa31776-d2b0-4e13-9761-11f750627ad1-TEST-org.apache.hadoop.hive.cli.TestCliDriver.xml
D    testutils/ptest2/src/test/resources/test-outputs/TEST-SomeTest-truncated.xml
D    testutils/ptest2/src/test/resources/test-outputs/TEST-union_remove_9.q-acb9de8f-1b9c-4874-924c-b2107ca7b07c-TEST-org.apache.hadoop.hive.cli.TestCliDriver.xml
U    testutils/ptest2/src/test/resources/test-outputs/index_auth.q-bucketcontex-ba31fb54-1d7f-4c70-a89d-477b7d155191-hive.log
A    testutils/ptest2/src/test/resources/test-outputs/index_auth.q-hive.log
U    testutils/ptest2/src/test/resources/test-outputs/skewjoin.q-ab8536a7-1b5c-45ed-ba29-14450f27db8b-TestCliDriver.txt
U    testutils/ptest2/src/test/resources/test-outputs/skewjoin_union_remove_1.q-6fa31776-d2b0-4e13-9761-11f750627ad1-hive.log
A    testutils/ptest2/src/test/resources/test-outputs/index_auth.q-TEST-org.apache.hadoop.hive.cli.TestCliDriver.xml
A    testutils/ptest2/src/test/resources/test-outputs/skewjoin.q-TEST-org.apache.hadoop.hive.cli.TestCliDriver.xml
U    testutils/ptest2/src/test/resources/test-outputs/skewjoin_union_remove_1.q-6fa31776-d2b0-4e13-9761-11f750627ad1-TestCliDriver.txt
U    testutils/ptest2/src/test/resources/test-outputs/union_remove_9.q-acb9de8f-1b9c-4874-924c-b2107ca7b07c-hive.log
A    testutils/ptest2/src/test/resources/test-outputs/union_remove_9.q-TEST-org.apache.hadoop.hive.cli.TestCliDriver.xml
A    testutils/ptest2/src/test/resources/test-outputs/SomeTest-truncated.xml
A    testutils/ptest2/src/test/resources/test-outputs/skewjoin_union_remove_1.q-TEST-org.apache.hadoop.hive.cli.TestCliDriver.xml
U    testutils/ptest2/src/test/resources/test-outputs/skewjoin.q-ab8536a7-1b5c-45ed-ba29-14450f27db8b-hive.log
A    testutils/ptest2/src/test/resources/test-outputs/skewjoin_union_remove_1.q-TestCliDriver.txt
U    testutils/ptest2/src/test/resources/test-outputs/union_remove_9.q-acb9de8f-1b9c-4874-924c-b2107ca7b07c-TestCliDriver.txt
A    testutils/ptest2/src/test/resources/SomeTest-failure.xml
A    testutils/ptest2/src/test/resources/SomeTest-success.xml
U    testutils/ptest2/src/test/java/org/apache/hive/ptest/execution/TestScripts.testBatch.approved.txt
U    testutils/ptest2/src/test/java/org/apache/hive/ptest/execution/TestExecutionPhase.java
U    testutils/ptest2/src/test/java/org/apache/hive/ptest/execution/TestReportParser.java
U    testutils/ptest2/src/test/java/org/apache/hive/ptest/execution/TestHostExecutor.java
U    testutils/ptest2/src/test/java/org/apache/hive/ptest/execution/TestReportingPhase.testExecute.approved.txt
U    testutils/ptest2/src/test/java/org/apache/hive/ptest/execution/TestScripts.testPrepGit.approved.txt
U    testutils/ptest2/src/test/java/org/apache/hive/ptest/execution/TestScripts.java
U    testutils/ptest2/src/test/java/org/apache/hive/ptest/execution/TestScripts.testPrepNone.approved.txt
U    testutils/ptest2/src/test/java/org/apache/hive/ptest/execution/TestScripts.testPrepSvn.approved.txt
U    testutils/ptest2/README.md
U    jdbc/src/test/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java
U    jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java
U    jdbc/src/java/org/apache/hadoop/hive/jdbc/JdbcColumn.java
U    jdbc/src/java/org/apache/hadoop/hive/jdbc/Utils.java
U    jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveBaseResultSet.java
U    jdbc/src/java/org/apache/hadoop/hive/jdbc/HivePreparedStatement.java
U    jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveResultSetMetaData.java
U    jdbc/src/java/org/apache/hive/jdbc/HiveResultSetMetaData.java
U    jdbc/src/java/org/apache/hive/jdbc/JdbcColumn.java
U    jdbc/src/java/org/apache/hive/jdbc/Utils.java
U    jdbc/src/java/org/apache/hive/jdbc/HiveBaseResultSet.java
U    jdbc/src/java/org/apache/hive/jdbc/HivePreparedStatement.java
 U   .

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
Updated external to revision 1508681.

Updated to revision 1508679.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0 to p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13771010" author="ehans" created="Wed, 18 Sep 2013 17:53:06 +0000"  >&lt;p&gt;After the patch for CONCAT goes in (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4512&quot; title=&quot;The vectorized plan is not picking right expression class for string concatenation.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4512&quot;&gt;&lt;del&gt;HIVE-4512&lt;/del&gt;&lt;/a&gt;), this patch needs to be re-based and updated.&lt;/p&gt;</comment>
                            <comment id="13773491" author="ehans" created="Fri, 20 Sep 2013 22:04:24 +0000"  >&lt;p&gt;Re-based patch on latest version of vectorization branch. Verified that string function tests passed. Did ad hoc end-to-end testing of SUBSTR() function in vectorized mode.&lt;/p&gt;</comment>
                            <comment id="13773734" author="hiveqa" created="Sat, 21 Sep 2013 05:38:49 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12604321/HIVE-4624.2-vectorization.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12604321/HIVE-4624.2-vectorization.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 6 failed/errored test(s), 3991 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_plan_json
org.apache.hcatalog.mapreduce.TestHCatHiveThriftCompatibility.testDynamicCols
org.apache.hive.hcatalog.fileformats.TestOrcDynamicPartitioned.testHCatDynamicPartitionedTable
org.apache.hive.hcatalog.fileformats.TestOrcDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask
org.apache.hive.hcatalog.mapreduce.TestHCatHiveCompatibility.testUnpartedReadWrite
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/850/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/850/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/850/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/850/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 6 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13773840" author="ashutoshc" created="Sat, 21 Sep 2013 15:42:12 +0000"  >&lt;p&gt;Committed to branch. Thanks, Eric!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12595033" name="HIVE-4624.1-vectorization.patch" size="21205" author="ehans" created="Tue, 30 Jul 2013 20:17:28 +0000"/>
                            <attachment id="12604321" name="HIVE-4624.2-vectorization.patch" size="23082" author="ehans" created="Fri, 20 Sep 2013 22:04:24 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 2 Jul 2013 23:16:22 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330152</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 18 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kyjb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330486</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4625] HS2 should not attempt to get delegation token from metastore if using embedded metastore</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4625</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;colored textIn kerberos secure mode, with doas enabled, Hive server2 tries to get delegation token from metastore even if the metastore is being used in embedded mode. &lt;br/&gt;
To avoid failure in that case, it uses catch block for UnsupportedOperationException thrown that does nothing. But this leads to an error being logged  by lower levels and can mislead users into thinking that there is a problem.&lt;/p&gt;

&lt;p&gt;It should check if delegation token mode is supported with current configuration before calling the function.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12649838">HIVE-4625</key>
            <summary>HS2 should not attempt to get delegation token from metastore if using embedded metastore</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hsubramaniyan">Hari Sankar Sivarama Subramaniyan</assignee>
                                    <reporter username="thejas">Thejas M Nair</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 May 2013 02:59:54 +0000</created>
                <updated>Tue, 4 Jul 2017 12:18:55 +0000</updated>
                            <resolved>Mon, 27 Apr 2015 20:04:31 +0000</resolved>
                                    <version>0.11.0</version>
                                    <fixVersion>1.2.0</fixVersion>
                                    <component>HiveServer2</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13668950" author="thejas" created="Wed, 29 May 2013 03:01:22 +0000"  >&lt;p&gt;Exception like following is thrown with metastore embedded mode - &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; ERROR metadata.Hive (Hive.java:getDelegationToken(2415)) - java.lang.UnsupportedOperationException: getDelegationToken() can be called only in thrift (non local) mode
        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getDelegationToken(HiveMetaStoreClient.java:1302)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:74)
        at $Proxy8.getDelegationToken(Unknown Source)
        at org.apache.hadoop.hive.ql.metadata.Hive.getDelegationToken(Hive.java:2413)
        at org.apache.hive.service.cli.CLIService.getDelegationTokenFromMetaStore(CLIService.java:319)
        at org.apache.hive.service.cli.thrift.ThriftCLIService.getSessionHandle(ThriftCLIService.java:153)
        at org.apache.hive.service.cli.thrift.ThriftCLIService.OpenSession(ThriftCLIService.java:116)
        at org.apache.hive.service.cli.thrift.TCLIService$Processor$OpenSession.getResult(TCLIService.java:1073)
        at org.apache.hive.service.cli.thrift.TCLIService$Processor$OpenSession.getResult(TCLIService.java:1058)
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
        at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge20S.java:569)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:662)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14488337" author="hsubramaniyan" created="Thu, 9 Apr 2015 21:40:29 +0000"  >&lt;p&gt;cc-ing &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; to see if this fix is good enough or not.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Hari&lt;/p&gt;</comment>
                            <comment id="14490140" author="thejas" created="Fri, 10 Apr 2015 19:02:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hsubramaniyan&quot; class=&quot;user-hover&quot; rel=&quot;hsubramaniyan&quot;&gt;Hari Sankar Sivarama Subramaniyan&lt;/a&gt; I think it would be simpler for rest of the code to just make the delegation token functions in HiveMetaStoreClient a no-op and return null/0 as appropriate, and also update the javadoc in IMetaStoreClient to talk about that (including the return value). Outside of HS2, i expect everything to use remote metastore, so I think its OK to return null from getDelegationToken. Also since the local mode will not use the obtained token, the null value should just work fine (in fact we are already converting it to null at the higher level).&lt;/p&gt;</comment>
                            <comment id="14490858" author="hiveqa" created="Sat, 11 Apr 2015 08:07:36 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12724349/HIVE-4625.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12724349/HIVE-4625.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 14 failed/errored test(s), 8672 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestMinimrCliDriver-bucketmapjoin6.q-constprog_partitioner.q-infer_bucket_sort_dyn_part.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-external_table_with_space_in_location_path.q-infer_bucket_sort_merge.q-auto_sortmerge_join_16.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-groupby2.q-import_exported_table.q-bucketizedhiveinputformat.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-index_bitmap3.q-stats_counter_partitioned.q-temp_table_external.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_map_operators.q-join1.q-bucketmapjoin7.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_num_buckets.q-disable_merge_for_bucketing.q-uber_reduce.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_reducers_power_two.q-scriptfile1.q-scriptfile1_win.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-leftsemijoin_mr.q-load_hdfs_file_with_space_in_the_name.q-root_dir_external_table.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-list_bucket_dml_10.q-bucket_num_reducers.q-bucket6.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-load_fs2.q-file_with_header_footer.q-ql_rewrite_gbtoidx_cbo_1.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-parallel_orderby.q-reduce_deduplicate.q-ql_rewrite_gbtoidx_cbo_2.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-ql_rewrite_gbtoidx.q-smb_mapjoin_8.q - did not produce a TEST-*.xml file
TestMinimrCliDriver-schemeAuthority2.q-bucket4.q-input16_cc.q-and-1-more - did not produce a TEST-*.xml file
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testNewConnectionConfiguration
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3372/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3372/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3372/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3372/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3372/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3372/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 14 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12724349 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14499358" author="hiveqa" created="Fri, 17 Apr 2015 06:51:28 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12725948/HIVE-4625.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12725948/HIVE-4625.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 16 failed/errored test(s), 8711 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestMinimrCliDriver-bucketmapjoin6.q-constprog_partitioner.q-infer_bucket_sort_dyn_part.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-external_table_with_space_in_location_path.q-infer_bucket_sort_merge.q-auto_sortmerge_join_16.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-groupby2.q-import_exported_table.q-bucketizedhiveinputformat.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-index_bitmap3.q-stats_counter_partitioned.q-temp_table_external.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_map_operators.q-join1.q-bucketmapjoin7.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_num_buckets.q-disable_merge_for_bucketing.q-uber_reduce.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_reducers_power_two.q-scriptfile1.q-scriptfile1_win.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-leftsemijoin_mr.q-load_hdfs_file_with_space_in_the_name.q-root_dir_external_table.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-list_bucket_dml_10.q-bucket_num_reducers.q-bucket6.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-load_fs2.q-file_with_header_footer.q-ql_rewrite_gbtoidx_cbo_1.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-parallel_orderby.q-reduce_deduplicate.q-ql_rewrite_gbtoidx_cbo_2.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-ql_rewrite_gbtoidx.q-smb_mapjoin_8.q - did not produce a TEST-*.xml file
TestMinimrCliDriver-schemeAuthority2.q-bucket4.q-input16_cc.q-and-1-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_view
org.apache.hadoop.hive.thrift.TestHadoop20SAuthBridge.testMetastoreProxyUser
org.apache.hadoop.hive.thrift.TestHadoop20SAuthBridge.testSaslWithHiveMetaStore
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3470/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3470/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3470/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3470/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3470/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3470/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 16 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12725948 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14499510" author="hsubramaniyan" created="Fri, 17 Apr 2015 09:07:32 +0000"  >&lt;p&gt;Test failures with TestHadoop20SAuthBridge look like &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-10353&quot; title=&quot;Investigate test failure on TestHadoop20SAuthBridge.testMetastoreProxyUser&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-10353&quot;&gt;&lt;del&gt;HIVE-10353&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-10354&quot; title=&quot;Investigate the test failure of TestHadoop20SAuthBridge.testSaslWithHiveMetaStore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-10354&quot;&gt;&lt;del&gt;HIVE-10354&lt;/del&gt;&lt;/a&gt;. Made sure TestHadoop20SAuthBridge works with patch 3 locally. cc-ing &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; for reviewing patch 3.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Hari&lt;/p&gt;</comment>
                            <comment id="14500095" author="thejas" created="Fri, 17 Apr 2015 16:06:40 +0000"  >&lt;p&gt;Hari, what I meant is that the HiveMetaStoreClient should return null/0 instead of exception in case of localmetastore mode. If remote metastore is used, it should still make the right calls.&lt;/p&gt;

&lt;p&gt;The TestHadoop20SAuthBridge  tests seem to pass - &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3475/testReport/org.apache.hadoop.hive.thrift/TestHadoop20SAuthBridge/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3475/testReport/org.apache.hadoop.hive.thrift/TestHadoop20SAuthBridge/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14500371" author="hsubramaniyan" created="Fri, 17 Apr 2015 18:29:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; Thanks for the clarification. Overwrote patch #3. &lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Hari&lt;/p&gt;</comment>
                            <comment id="14506241" author="thejas" created="Wed, 22 Apr 2015 01:59:11 +0000"  >&lt;p&gt;There are 2 other functions as well there &quot;only in thrift (non local) mode&quot; exception is thrown, similar change should be made there as well for consistency.&lt;/p&gt;</comment>
                            <comment id="14506442" author="hiveqa" created="Wed, 22 Apr 2015 05:17:18 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12727018/HIVE-4625.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12727018/HIVE-4625.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 15 failed/errored test(s), 8728 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestMinimrCliDriver-bucketmapjoin6.q-constprog_partitioner.q-infer_bucket_sort_dyn_part.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-external_table_with_space_in_location_path.q-infer_bucket_sort_merge.q-auto_sortmerge_join_16.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-groupby2.q-import_exported_table.q-bucketizedhiveinputformat.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-index_bitmap3.q-stats_counter_partitioned.q-temp_table_external.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_map_operators.q-join1.q-bucketmapjoin7.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_num_buckets.q-disable_merge_for_bucketing.q-uber_reduce.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_reducers_power_two.q-scriptfile1.q-scriptfile1_win.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-leftsemijoin_mr.q-load_hdfs_file_with_space_in_the_name.q-root_dir_external_table.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-list_bucket_dml_10.q-bucket_num_reducers.q-bucket6.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-load_fs2.q-file_with_header_footer.q-ql_rewrite_gbtoidx_cbo_1.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-parallel_orderby.q-reduce_deduplicate.q-ql_rewrite_gbtoidx_cbo_2.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-ql_rewrite_gbtoidx.q-smb_mapjoin_8.q - did not produce a TEST-*.xml file
TestMinimrCliDriver-schemeAuthority2.q-bucket4.q-input16_cc.q-and-1-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.thrift.TestHadoop20SAuthBridge.testSaslWithHiveMetaStore
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyCommit
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3522/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3522/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3522/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3522/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3522/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3522/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 15 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12727018 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14508150" author="hiveqa" created="Wed, 22 Apr 2015 23:29:09 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12727315/HIVE-4625.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12727315/HIVE-4625.5.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 14 failed/errored test(s), 8728 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestMinimrCliDriver-bucketmapjoin6.q-constprog_partitioner.q-infer_bucket_sort_dyn_part.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-external_table_with_space_in_location_path.q-infer_bucket_sort_merge.q-auto_sortmerge_join_16.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-groupby2.q-import_exported_table.q-bucketizedhiveinputformat.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-index_bitmap3.q-stats_counter_partitioned.q-temp_table_external.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_map_operators.q-join1.q-bucketmapjoin7.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_num_buckets.q-disable_merge_for_bucketing.q-uber_reduce.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-infer_bucket_sort_reducers_power_two.q-scriptfile1.q-scriptfile1_win.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-leftsemijoin_mr.q-load_hdfs_file_with_space_in_the_name.q-root_dir_external_table.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-list_bucket_dml_10.q-bucket_num_reducers.q-bucket6.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-load_fs2.q-file_with_header_footer.q-ql_rewrite_gbtoidx_cbo_1.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-parallel_orderby.q-reduce_deduplicate.q-ql_rewrite_gbtoidx_cbo_2.q-and-1-more - did not produce a TEST-*.xml file
TestMinimrCliDriver-ql_rewrite_gbtoidx.q-smb_mapjoin_8.q - did not produce a TEST-*.xml file
TestMinimrCliDriver-schemeAuthority2.q-bucket4.q-input16_cc.q-and-1-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_histogram_numeric
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3531/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3531/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3531/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/3531/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3531/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-3531/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 14 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12727315 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14508168" author="thejas" created="Wed, 22 Apr 2015 23:43:35 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14509746" author="hsubramaniyan" created="Thu, 23 Apr 2015 20:40:38 +0000"  >&lt;p&gt;The test failures are unrelated to the change.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Hari&lt;/p&gt;</comment>
                            <comment id="14514867" author="thejas" created="Mon, 27 Apr 2015 20:04:31 +0000"  >&lt;p&gt;Patch committed to 1.2 branch and trunk. Thanks Hari!&lt;/p&gt;</comment>
                            <comment id="14548802" author="sushanth" created="Mon, 18 May 2015 19:51:41 +0000"  >&lt;p&gt;This issue has been fixed and released as part of the 1.2.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12724349" name="HIVE-4625.1.patch" size="2004" author="hsubramaniyan" created="Thu, 9 Apr 2015 21:40:29 +0000"/>
                            <attachment id="12725948" name="HIVE-4625.2.patch" size="2143" author="hsubramaniyan" created="Thu, 16 Apr 2015 18:44:38 +0000"/>
                            <attachment id="12726219" name="HIVE-4625.3.patch" size="2752" author="hsubramaniyan" created="Fri, 17 Apr 2015 18:17:07 +0000"/>
                            <attachment id="12727018" name="HIVE-4625.4.patch" size="2752" author="hsubramaniyan" created="Tue, 21 Apr 2015 22:53:00 +0000"/>
                            <attachment id="12727315" name="HIVE-4625.5.patch" size="2596" author="hsubramaniyan" created="Wed, 22 Apr 2015 19:45:59 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 9 Apr 2015 21:40:29 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330165</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 36 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kym7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330499</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4626] join_vc.q is not deterministic</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4626</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The test is selecting three columns but order by last column only, which make test fail in hadoop2.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12649857">HIVE-4626</key>
            <summary>join_vc.q is not deterministic</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12629407">HIVE-3949</parent>
                                    <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.svg">Trivial</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis</assignee>
                                    <reporter username="navis">Navis</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 May 2013 08:17:38 +0000</created>
                <updated>Tue, 15 Oct 2013 23:29:27 +0000</updated>
                            <resolved>Sun, 2 Jun 2013 23:54:34 +0000</resolved>
                                    <version>0.12.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Tests</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13669089" author="phabricator@reviews.facebook.net" created="Wed, 29 May 2013 08:20:22 +0000"  >&lt;p&gt;navis requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4626&quot; title=&quot;join_vc.q is not deterministic&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4626&quot;&gt;&lt;del&gt;HIVE-4626&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; join_vc.q is not deterministic&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4626&quot; title=&quot;join_vc.q is not deterministic&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4626&quot;&gt;&lt;del&gt;HIVE-4626&lt;/del&gt;&lt;/a&gt; join_vc.q is not deterministic&lt;/p&gt;

&lt;p&gt;The test is selecting three columns but order by last column only, which make test fail in hadoop2.&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10989&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10989&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/test/queries/clientpositive/join_vc.q&lt;br/&gt;
  ql/src/test/results/clientpositive/join_vc.q.out&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/26241/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/26241/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13672717" author="ashutoshc" created="Sun, 2 Jun 2013 23:31:57 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13672727" author="ashutoshc" created="Sun, 2 Jun 2013 23:54:34 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Navis!&lt;/p&gt;</comment>
                            <comment id="13673606" author="hudson" created="Mon, 3 Jun 2013 21:32:37 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #223 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/223/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/223/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4626&quot; title=&quot;join_vc.q is not deterministic&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4626&quot;&gt;&lt;del&gt;HIVE-4626&lt;/del&gt;&lt;/a&gt; : join_vc.q is not deterministic (Navis via Ashutosh Chauhan) (Revision 1488812)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1488812&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1488812&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/join_vc.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join_vc.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13674009" author="hudson" created="Tue, 4 Jun 2013 04:08:08 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2126 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2126/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2126/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4626&quot; title=&quot;join_vc.q is not deterministic&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4626&quot;&gt;&lt;del&gt;HIVE-4626&lt;/del&gt;&lt;/a&gt; : join_vc.q is not deterministic (Navis via Ashutosh Chauhan) (Revision 1488812)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1488812&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1488812&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/join_vc.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join_vc.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13795894" author="ashutoshc" created="Tue, 15 Oct 2013 23:29:27 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12585172" name="HIVE-4626.D10989.1.patch" size="5835" author="phabricator@reviews.facebook.net" created="Wed, 29 May 2013 08:20:22 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 29 May 2013 08:20:22 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330184</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kyqf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330518</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4627] Total ordering of Hive output</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4627</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;I&apos;d like to use Hive to generate HFiles for HBase. I started off by following the instructions on the &lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/HBaseBulkLoad&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;wiki&lt;/a&gt;, but that took me only so far. TotalOrderPartitioning didn&apos;t work. That took me to this &lt;a href=&quot;http://stackoverflow.com/questions/13715044/hive-cluster-by-vs-order-by-vs-sort-by&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;post&lt;/a&gt; which points out that Hive partitions on value instead of key. A patched TOP brings me to this error:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2013-05-17 21:00:47,781 WARN org.apache.hadoop.mapred.Child: Error running child
java.lang.RuntimeException: Hive Runtime Error while closing operators: java.io.IOException: No files found in hdfs://ip-10-191-3-134.ec2.internal:8020/tmp/hive-hrt_qa/hive_2013-05-17_20-58-58_357_6896546413926013201/_task_tmp.-ext-10000/_tmp.000000_0
	at org.apache.hadoop.hive.ql.exec.ExecReducer.close(ExecReducer.java:317)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:532)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:421)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:255)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)
	at org.apache.hadoop.mapred.Child.main(Child.java:249)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: No files found in hdfs://ip-10-191-3-134.ec2.internal:8020/tmp/hive-hrt_qa/hive_2013-05-17_20-58-58_357_6896546413926013201/_task_tmp.-ext-10000/_tmp.000000_0
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths.closeWriters(FileSinkOperator.java:183)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.closeOp(FileSinkOperator.java:865)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:588)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597)
	at org.apache.hadoop.hive.ql.exec.ExecReducer.close(ExecReducer.java:309)
	... 7 more
Caused by: java.io.IOException: No files found in hdfs://ip-10-191-3-134.ec2.internal:8020/tmp/hive-hrt_qa/hive_2013-05-17_20-58-58_357_6896546413926013201/_task_tmp.-ext-10000/_tmp.000000_0
	at org.apache.hadoop.hive.hbase.HiveHFileOutputFormat$1.close(HiveHFileOutputFormat.java:142)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths.closeWriters(FileSinkOperator.java:180)
	... 11 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12649960">HIVE-4627</key>
            <summary>Total ordering of Hive output</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="6">Invalid</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ndimiduk">Nick Dimiduk</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 May 2013 16:58:27 +0000</created>
                <updated>Tue, 4 Feb 2014 01:35:55 +0000</updated>
                            <resolved>Tue, 4 Feb 2014 01:35:55 +0000</resolved>
                                    <version>0.11.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13669442" author="ndimiduk" created="Wed, 29 May 2013 17:02:58 +0000"  >&lt;p&gt;These are my steps to reproduce:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;## load the input data
$ wget http://dumps.wikimedia.org/other/pagecounts-raw/2008/2008-10/pagecounts-20081001-000000.gz
$ hadoop fs -mkdir /tmp/wikistats
$ hadoop fs -put pagecounts-20081001-000000.gz /tmp/wikistats/

## create the necessary tables.
$ hcat -f /tmp/00_tables.ddl
OK
Time taken: 1.886 seconds
OK
Time taken: 0.654 seconds
OK
Time taken: 0.047 seconds
OK
Time taken: 0.115 seconds

## verify
$ hive -e &quot;select * from pagecounts limit 10;&quot;
...
OK
aa      Main_Page       4       41431
aa      Special:ListUsers       1       5555
aa      Special:Listusers       1       1052
...
$ hive -e &quot;select * from pgc limit 10;&quot;
...
OK
aa/Main_Page/20081001-000000    4       41431
aa/Special:ListUsers/20081001-000000    1       5555
aa/Special:Listusers/20081001-000000    1       1052
...

## produce the hfile splits file
$ hive -f /tmp/01_sample.hql
...
OK
Time taken: 54.681 seconds
[hrt_qa] $ hadoop fs -ls /tmp/hbase_splits
Found 1 items
-rwx------   3 hrt_qa hdfs        270 2013-05-17 19:05 /tmp/hbase_splits

## verify
$ hadoop jar /usr/lib/hadoop/contrib/streaming/hadoop-streaming-1.2.0.1.3.0.0-104.jar -libjars /usr/lib/hive/lib/hive-exec-0.11.0.1.3.0.0-104.jar -input /tmp/hbase_splits -output /tmp/hbase_splits_txt -inputformat SequenceFileAsTextInputFormat
...
13/05/17 19:08:38 INFO streaming.StreamJob: Output: /tmp/hbase_splits_txt
$ hadoop fs -cat /tmp/hbase_splits_txt/*
01 61 66 2e 71 2f 4d 61 69 6e 5f 50 61 67 65 2f 32 30 30 38 31 30 30 31 2d 30 30 30 30 30 30 00 (null)
01 61 66 2f 31 35 35 30 2f 32 30 30 38 31 30 30 31 2d 30 30 30 30 30 30 00      (null)
01 61 66 2f 32 38 5f 4d 61 61 72 74 2f 32 30 30 38 31 30 30 31 2d 30 30 30 30 30 30 00  (null)
01 61 66 2f 42 65 65 6c 64 3a 31 30 30 5f 31 38 33 30 2e 4a 50 47 2f 32 30 30 38 31 30 30 31 2d 30 30 30 30 30 30 00    (null)

## decoding the first line from utf8 bytes to String yields &quot;af.q/Main_Page/20081001-000000,&quot; which is correct

## generate the hfiles
$ HADOOP_CLASSPATH=/usr/lib/hbase/hbase-0.94.6.1.3.0.0-104-security.jar hive -f /tmp/02_hfiles.hql
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13669444" author="ndimiduk" created="Wed, 29 May 2013 17:04:07 +0000"  >&lt;p&gt;This is the patch to TOP to support Hive.&lt;/p&gt;</comment>
                            <comment id="13684572" author="navis" created="Sun, 16 Jun 2013 04:41:13 +0000"  >&lt;p&gt;Can I ask the hadoop version you&apos;ve used?&lt;/p&gt;</comment>
                            <comment id="13685939" author="ndimiduk" created="Mon, 17 Jun 2013 20:30:55 +0000"  >&lt;p&gt;hadoop-1.2.0&lt;/p&gt;</comment>
                            <comment id="13728259" author="ndimiduk" created="Fri, 2 Aug 2013 23:28:40 +0000"  >&lt;p&gt;bump. updating wiki link.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12585243" name="00_tables.ddl" size="1465" author="ndimiduk" created="Wed, 29 May 2013 17:02:58 +0000"/>
                            <attachment id="12585244" name="01_sample.hql" size="639" author="ndimiduk" created="Wed, 29 May 2013 17:02:58 +0000"/>
                            <attachment id="12585245" name="02_hfiles.hql" size="408" author="ndimiduk" created="Wed, 29 May 2013 17:02:58 +0000"/>
                            <attachment id="12585246" name="hive-partitioner.patch" size="723" author="ndimiduk" created="Wed, 29 May 2013 17:04:07 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 16 Jun 2013 04:41:13 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330287</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 25 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kzdb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330621</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>I&amp;#39;m not able to reproduce this behavior. I now suspect the input data set was empty, causing this runtime exception.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4628] HS2 sessionmanager should synchronize the call to insert/remove session objects from session hash map</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4628</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;HS2 SessionManager maintains a hashmap of active HS2 sessions. However, insert and deletes to this hashmap is not synchronized. A consequence of this is a racing thread could overwrite a valid session object in the hashmap and we could end up losing a session!&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650029">HIVE-4628</key>
            <summary>HS2 sessionmanager should synchronize the call to insert/remove session objects from session hash map</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="8">Not A Problem</resolution>
                                        <assignee username="shreepadma">Shreepadma Venugopalan</assignee>
                                    <reporter username="shreepadma">Shreepadma Venugopalan</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 May 2013 22:04:27 +0000</created>
                <updated>Thu, 30 May 2013 17:30:06 +0000</updated>
                            <resolved>Thu, 30 May 2013 17:29:37 +0000</resolved>
                                    <version>0.11.0</version>
                                                    <component>HiveServer2</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13670468" author="thejas" created="Thu, 30 May 2013 16:27:46 +0000"  >&lt;p&gt;Are you talking about handleToSession in SessionManager ? There is a &quot;synchronized(sessionMapLock) &quot; block around access to it.&lt;/p&gt;</comment>
                            <comment id="13670516" author="shreepadma" created="Thu, 30 May 2013 17:30:06 +0000"  >&lt;p&gt;Good catch Tejas. Looks like this is not an issue any more. I&apos;ve set the appropriate status.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 30 May 2013 16:27:46 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330356</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 34 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kzsn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330690</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4629] HS2 should support an API to retrieve query logs</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4629</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;HiveServer2 should support an API to retrieve query logs. This is particularly relevant because HiveServer2 supports async execution but doesn&apos;t provide a way to report progress. Providing an API to retrieve query logs will help report progress to the client.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650031">HIVE-4629</key>
            <summary>HS2 should support an API to retrieve query logs</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12550255">HIVE-2935</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dongc">Dong Chen</assignee>
                                    <reporter username="shreepadma">Shreepadma Venugopalan</reporter>
                        <labels>
                            <label>TODOC14</label>
                    </labels>
                <created>Wed, 29 May 2013 22:14:11 +0000</created>
                <updated>Tue, 1 Mar 2016 12:56:59 +0000</updated>
                            <resolved>Wed, 27 Aug 2014 20:45:59 +0000</resolved>
                                                    <fixVersion>0.14.0</fixVersion>
                                    <component>HiveServer2</component>
                        <due></due>
                            <votes>5</votes>
                                    <watches>27</watches>
                                                                <comments>
                            <comment id="13670559" author="cwsteinbach" created="Thu, 30 May 2013 18:18:18 +0000"  >&lt;p&gt;@Shreepadma: before making any code changes I think it would be a good idea to get feedback on the changes you plan to make to TCLIService and CLIService.&lt;/p&gt;</comment>
                            <comment id="13670583" author="shreepadma" created="Thu, 30 May 2013 18:40:26 +0000"  >&lt;p&gt;@Carl: The proposed addition to TCLIService.thrift is the following new API and structs,&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;// GetLog()
// Fetch operation log from the server corresponding to
// a particular OperationHandle.

struct TGetLogReq {
  // Operation whose log is requested
  1: required TOperationHandle operationHandle
}

struct TGetLogResp {
  1: required TStatus status
  2: required string log
}

service TCLIService {
...
...
TGetLogResp GetLog(1:TGetLogReq req);
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13673508" author="shreepadma" created="Mon, 3 Jun 2013 20:17:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cwsteinbach&quot; class=&quot;user-hover&quot; rel=&quot;cwsteinbach&quot;&gt;Carl Steinbach&lt;/a&gt;: Can you look at this? Thanks!&lt;/p&gt;</comment>
                            <comment id="13674097" author="cwsteinbach" created="Tue, 4 Jun 2013 05:56:51 +0000"  >&lt;p&gt;Here are some questions I had while looking at the API:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;When am I allowed to call GetLog()? For example, what happens if I call it after calling CloseOperation or CancelOperation? If it&apos;s ok to call after CloseOperation()/CancelOperation(), what does it return, and what does it return if I first call a function that also returns an operationhandle?&lt;/li&gt;
	&lt;li&gt;What happens if I call GetLog() twice during the same operation? Will it always return the entire log collected up to that point or just a piece of it?&lt;/li&gt;
	&lt;li&gt;Do you think we log (or should log) anything of interest between the OpenSession() call and creation of the first OperationHandle, or between CloseSession() and the previous call to CancelOperation()/CloseOperation()?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I also thought of a possible alternate approach and wanted to get your opinion on it:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Provide access to logs on a per-session basis instead of per-operation.&lt;/li&gt;
	&lt;li&gt;Provide a LogHandle (either hanging off of the SessionHandle or provided via GetLogHandle()) and make it fetchable with FetchResults()&lt;/li&gt;
	&lt;li&gt;We can provide per-operation log retrieval by supporting scrollable log cursors, e.g. scrolling to FETCH_LAST between operations will advance the log stream to the start of the next operation&apos;s log.&lt;/li&gt;
&lt;/ul&gt;

</comment>
                            <comment id="13776724" author="shreepadma" created="Tue, 24 Sep 2013 20:41:37 +0000"  >&lt;p&gt;This API gets the operation log aka the per query log. Clients are mostly interested in the operation/per query log rather than the session log. Furthermore, session log will contain log output for a given query interspersed with the log output of other queries that may be executing concurrently in the same session. Note that executing multiple queries in a session is possible with async execution. The main purpose of this JIRA is to support an API to retrieve per query log. If there&apos;s enough interest, adding an API to support retrieving session log can be done in a follow on JIRA.&lt;/p&gt;
</comment>
                            <comment id="13776747" author="shreepadma" created="Tue, 24 Sep 2013 21:06:58 +0000"  >&lt;ul&gt;
	&lt;li&gt;Operation logs don&apos;t persist beyond the life of an operation. If getLog(opHandle) is called after a CloseOperation() or CancelOperation(), an exception is raised.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;If getLog() is called on the same operationHandle twice, the log up to the point will be returned. Note that the log is maintained as a circular buffer and loops back. The default size is 128 KB, but is configurable. We have not come across a case where 128 KB was insufficient.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13776969" author="shreepadma" created="Wed, 25 Sep 2013 00:08:40 +0000"  >&lt;p&gt;Review board: &lt;a href=&quot;https://reviews.apache.org/r/14326/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/14326/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13777270" author="hiveqa" created="Wed, 25 Sep 2013 08:28:43 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12604928/HIVE-4629.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12604928/HIVE-4629.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/886/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/886/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/886/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/886/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-886/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToInteger.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToLong.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToByte.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToShort.java&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ awk &apos;{print $2}&apos;
++ svn status --no-ignore
+ rm -rf build hcatalog/build hcatalog/core/build hcatalog/storage-handlers/hbase/build hcatalog/server-extensions/build hcatalog/webhcat/svr/build hcatalog/webhcat/java-client/build hcatalog/hcatalog-pig-adapter/build common/src/gen ql/src/test/results/clientpositive/cast_to_int.q.out ql/src/test/queries/clientpositive/cast_to_int.q
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1526135.

At revision 1526135.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0 to p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13778224" author="shreepadma" created="Wed, 25 Sep 2013 23:27:47 +0000"  >&lt;p&gt;I&apos;m able to apply the patch with -p0 to the tip of trunk. I&apos;ve re-attached the patch to trigger a run.&lt;/p&gt;</comment>
                            <comment id="13778547" author="hiveqa" created="Thu, 26 Sep 2013 07:23:56 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12605136/HIVE-4629.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12605136/HIVE-4629.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/907/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/907/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/907/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/907/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-907/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;build-common.xml&apos;
Reverted &apos;ql/src/test/queries/clientnegative/invalid_columns.q&apos;
Reverted &apos;ql/src/test/queries/clientnegative/deletejar.q&apos;
Reverted &apos;ql/src/test/queries/clientpositive/input16_cc.q&apos;
Reverted &apos;ql/src/test/queries/clientpositive/alter1.q&apos;
Reverted &apos;ql/src/test/queries/clientpositive/input16.q&apos;
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf build hcatalog/build hcatalog/core/build hcatalog/storage-handlers/hbase/build hcatalog/server-extensions/build hcatalog/webhcat/svr/build hcatalog/webhcat/java-client/build hcatalog/hcatalog-pig-adapter/build common/src/gen
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1526404.

At revision 1526404.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0 to p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13799455" author="brocknoland" created="Fri, 18 Oct 2013 19:54:42 +0000"  >&lt;p&gt;I think it makes sense to do a scrollable log in a future jira. Carl do you have any more concerns?&lt;/p&gt;</comment>
                            <comment id="13799672" author="cwsteinbach" created="Sat, 19 Oct 2013 00:03:30 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt; Making the logs scrollable wasn&apos;t the point of my suggestion. I&apos;m more concerned about leveraging the existing fetch functions and patterns to satisfy a use case which fundamentally looks very similar to fetching a query result set. CLIService is a public interface. We&apos;re permanently stuck with any changes that are made to it. I&apos;d like to avoid cluttering it with a mishmash of logging RPCs if it&apos;s possible to reduce all of these use cases to a single pattern.&lt;/p&gt;

&lt;p&gt;In the future I hope we can finish discussing changes like this before the first patch is posted.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shreepadma&quot; class=&quot;user-hover&quot; rel=&quot;shreepadma&quot;&gt;Shreepadma Venugopalan&lt;/a&gt; I left some comments on reviewboard. Thanks.&lt;/p&gt;</comment>
                            <comment id="13800765" author="brocknoland" created="Mon, 21 Oct 2013 16:10:52 +0000"  >&lt;p&gt;Carl, I see, as you know I took your comments as a suggestion for a scrollable log. I apologize for mis-understanding your comments.&lt;/p&gt;</comment>
                            <comment id="13924290" author="prasadm" created="Fri, 7 Mar 2014 20:22:51 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shreepadma&quot; class=&quot;user-hover&quot; rel=&quot;shreepadma&quot;&gt;Shreepadma Venugopalan&lt;/a&gt; I guess the patch is out of sync and won&apos;t apply. There are a bunch of changes to HS2 interface, the build framework changed from ant to maven etc. Would you mind rebasing it to the latest and update the review.&lt;/p&gt;

&lt;p&gt;If you want I can take care of the rebase.&lt;/p&gt;</comment>
                            <comment id="13925394" author="wangg23" created="Mon, 10 Mar 2014 02:01:03 +0000"  >&lt;p&gt;What about the status of this jira?&lt;br/&gt;
Does anyone try to rebase it to the latest trunk?&lt;br/&gt;
I think it is a useful feature especially when doing some testing about hql.&lt;/p&gt;</comment>
                            <comment id="13925491" author="cwsteinbach" created="Mon, 10 Mar 2014 06:41:34 +0000"  >&lt;p&gt;Does the new version of the patch address any of the API design issues I mentioned earlier?&lt;/p&gt;</comment>
                            <comment id="13926260" author="suhassatish" created="Mon, 10 Mar 2014 21:36:57 +0000"  >&lt;p&gt;It would be great to have this jira accepted into hive trunk, even I am waiting on this from a long time. &lt;/p&gt;</comment>
                            <comment id="13963416" author="thecreationist" created="Tue, 8 Apr 2014 20:43:05 +0000"  >&lt;p&gt;Any estimate on when this will be accepted into trunk?&lt;/p&gt;</comment>
                            <comment id="14011967" author="raviprak" created="Thu, 29 May 2014 01:54:54 +0000"  >&lt;p&gt;This patch no longer applies on HIVE trunk. Is there a plan to upmerge it? And incorporate Carl&apos;s comments?&lt;/p&gt;</comment>
                            <comment id="14012079" author="navis" created="Thu, 29 May 2014 05:20:57 +0000"  >&lt;p&gt;Just rebased to trunk. Let this get in.&lt;/p&gt;</comment>
                            <comment id="14012353" author="brocknoland" created="Thu, 29 May 2014 13:28:07 +0000"  >&lt;p&gt;Agreed, let&apos;s get this in.&lt;/p&gt;</comment>
                            <comment id="14013058" author="raviprak" created="Thu, 29 May 2014 22:53:46 +0000"  >&lt;p&gt;Thanks a lot Navis for the updated patch!&lt;/p&gt;

&lt;p&gt;@Brock ++ Are there any plans to incorporate Carl&apos;s comments and provide an updated patch? &lt;/p&gt;

&lt;p&gt;@Carl: We need this functionality in Hive to continue providing Hue to our users. Hue is a pretty useful application, so we would like to continue providing it. Would you please consider accepting the patch?&lt;/p&gt;</comment>
                            <comment id="14013096" author="brocknoland" created="Thu, 29 May 2014 23:22:05 +0000"  >&lt;p&gt;Hi Ravi and Carl,&lt;/p&gt;

&lt;p&gt;The current patch does not implement the changes requested by Carl. I do think the changes described by Carl would make the API more flexible. However, the current design does work well and thus I feel we should move forward with the current design.&lt;/p&gt;

&lt;p&gt;Brock&lt;/p&gt;</comment>
                            <comment id="14013107" author="thejas" created="Thu, 29 May 2014 23:40:09 +0000"  >&lt;p&gt;Please give me a day to review this patch.&lt;br/&gt;
I had an initial pass on this, one concern I have is the 1 MB of log being returned on every call to getLog. I believe this is for use cases such as Hue. In such use cases there is only one consumer for the log, and giving out incremental logs would be better. ie , after a call to getLog, clear the buffer and the next getLog call returns only the new log lines. This will reduce the memory footprint in HiveServer2 and the load that getLog call puts on it. It will also make applications like Hue more responsive, and be able to refresh the log more frequently.&lt;/p&gt;</comment>
                            <comment id="14014172" author="cwsteinbach" created="Fri, 30 May 2014 20:19:03 +0000"  >&lt;p&gt;Does anyone think this is the right way to implement this feature?&lt;/p&gt;
</comment>
                            <comment id="14014559" author="hiveqa" created="Sat, 31 May 2014 07:29:07 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12647299/HIVE-4629.3.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12647299/HIVE-4629.3.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 7 failed/errored test(s), 5468 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_bucketmapjoin6
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_root_dir_external_table
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_ctas
org.apache.hadoop.hive.ql.exec.tez.TestTezTask.testSubmit
org.apache.hive.hcatalog.pig.TestOrcHCatPigStorer.testWriteDecimal
org.apache.hive.hcatalog.pig.TestOrcHCatPigStorer.testWriteDecimalX
org.apache.hive.hcatalog.pig.TestOrcHCatPigStorer.testWriteDecimalXY
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/343/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/343/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/343/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-Build/343/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-Build-343/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-Build-343/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 7 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12647299&lt;/p&gt;</comment>
                            <comment id="14015713" author="thejas" created="Mon, 2 Jun 2014 18:36:50 +0000"  >&lt;p&gt;I have added some comments on review board .&lt;/p&gt;

&lt;p&gt;I think this feature is very useful. A lot of other people have asked for it in the jira as well.&lt;br/&gt;
But I think we should address the review board comments and comments in this jira first.&lt;/p&gt;

&lt;p&gt;We should first agree on the public api before committing the patch. The suggestion from Carl about using the FetchResults api for this makes sense. As the use cases for this evolves, I think it the getLog api is likely to start looking more like the FetchResults api.&lt;br/&gt;
The TFetchResultsReq can have an additional resulttype parameter (OUTPUT vs LOG). &lt;/p&gt;

&lt;p&gt;Also, the circular in-memory buffer does not gurantee that you get the whole log, it also puts burden on the HS2 memory requirements. I think we should explore using the approach in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5924&quot; title=&quot;Save operation logs in per operation directories in HiveServer2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5924&quot;&gt;HIVE-5924&lt;/a&gt; for this instead of an inmemory pool. But I am OK with having such changes as part of follow up jiras, as long as we don&apos;t have the in-memory logging enabled by default in this patch.&lt;/p&gt;</comment>
                            <comment id="14016248" author="navis" created="Tue, 3 Jun 2014 06:04:28 +0000"  >&lt;p&gt;I&apos;m not intended to take this job(I&apos;m not good at interface design) but just rebased the patch. Will be really appreciated if anyone take this work, which will be huge contribution to hive community. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cwsteinbach&quot; class=&quot;user-hover&quot; rel=&quot;cwsteinbach&quot;&gt;Carl Steinbach&lt;/a&gt; Any idea on how to retrieve operation logs via currently existing APIs in ICliService? Should we extend select statement for that? (select _hive_operation_log from operation-handler, for example)&lt;/p&gt;</comment>
                            <comment id="14031304" author="raviprak" created="Fri, 13 Jun 2014 22:58:50 +0000"  >&lt;p&gt;Is this something complicated? Can a hive beginner take up this task?&lt;/p&gt;</comment>
                            <comment id="14031646" author="vgumashta" created="Sat, 14 Jun 2014 18:24:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=raviprak&quot; class=&quot;user-hover&quot; rel=&quot;raviprak&quot;&gt;Ravi Prakash&lt;/a&gt; This can definitely be taken up. There is some good feedback on the jira too regarding the modifications. Let me know if you plan to take it up and need more help while you work on it. Thanks a lot!&lt;/p&gt;</comment>
                            <comment id="14045634" author="raviprak" created="Fri, 27 Jun 2014 07:00:18 +0000"  >&lt;p&gt;Hi Vaibhav! Sorry for the delay. I wish I had enough cycles to take this up, but that&apos;s just not happening.&lt;/p&gt;</comment>
                            <comment id="14085772" author="dongc" created="Tue, 5 Aug 2014 04:18:13 +0000"  >&lt;p&gt;A patch &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4629&quot; title=&quot;HS2 should support an API to retrieve query logs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4629&quot;&gt;&lt;del&gt;HIVE-4629&lt;/del&gt;&lt;/a&gt;.4.patch is attached, which trying to address the comments in this jira and review board, to support an API to retrieve query logs.&lt;/p&gt;

&lt;p&gt;This patch is developed based on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4629&quot; title=&quot;HS2 should support an API to retrieve query logs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4629&quot;&gt;&lt;del&gt;HIVE-4629&lt;/del&gt;&lt;/a&gt;.3.patch code in this jira and refer to the method of saving operation log to files in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5924&quot; title=&quot;Save operation logs in per operation directories in HiveServer2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5924&quot;&gt;HIVE-5924&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;RB entry: &lt;a href=&quot;https://reviews.apache.org/r/24293/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/24293/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The design and changes are as follows:&lt;br/&gt;
1. Reuse FetchResults() API and add a TFetchType in the param. The type could be QUERY_OUTPUT and LOG.&lt;br/&gt;
2. Original LogManager code is modified and moved in OperationManager. Now OM is responsible for dispatching log updating and fetching request.&lt;br/&gt;
3. OperatinLog class wraps the actual operation log files. Each Operation create, register, and unregister the OperationLog around its run() method.&lt;br/&gt;
4. Make OperationLog to ThreadLocal, so that we don&apos;t have to bind and maintain them with threads in some Maps.&lt;br/&gt;
5. The actual operation log files are maintained in the hierarchy like:&lt;br/&gt;
rootDir/sessionDir/operationLogFiles&lt;br/&gt;
The rootDir is configurable, created when SessionManager init, deleted when stop.&lt;br/&gt;
The sessionDir is created when session is opened, and deleted during closing.&lt;br/&gt;
The operationLogFiles is create before operation runs, and deleted when it is closed. &lt;/p&gt;</comment>
                            <comment id="14086933" author="hiveqa" created="Tue, 5 Aug 2014 22:49:19 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12659815/HIVE-4629.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12659815/HIVE-4629.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 5 failed/errored test(s), 5854 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_mixed_case
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx
org.apache.hadoop.hive.ql.TestDDLWithRemoteMetastoreSecondNamenode.testCreateTableWithIndexAndPartitionsNonDefaultNameNode
org.apache.hive.hcatalog.pig.TestOrcHCatLoader.testReadDataPrimitiveTypes
org.apache.hive.service.cli.TestEmbeddedThriftBinaryCLIService.testExecuteStatementAsync
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/178/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/178/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/178/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/178/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-178/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-178/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12659815&lt;/p&gt;</comment>
                            <comment id="14089514" author="dongc" created="Thu, 7 Aug 2014 17:46:04 +0000"  >&lt;p&gt;Update the patch (v6) to trigger test. It addresses review comments and fixes one failed case related with this patch in HIVE QA.&lt;/p&gt;</comment>
                            <comment id="14090499" author="hiveqa" created="Fri, 8 Aug 2014 09:02:33 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12660420/HIVE-4629.6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12660420/HIVE-4629.6.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 6 failed/errored test(s), 5875 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_join_hash
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_load_hdfs_file_with_space_in_the_name
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx
org.apache.hadoop.hive.ql.TestDDLWithRemoteMetastoreSecondNamenode.testCreateTableWithIndexAndPartitionsNonDefaultNameNode
org.apache.hive.jdbc.miniHS2.TestHiveServer2.testConnection
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/221/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/221/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/221/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/221/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-221/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-221/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12660420&lt;/p&gt;</comment>
                            <comment id="14092876" author="brocknoland" created="Mon, 11 Aug 2014 15:21:03 +0000"  >&lt;p&gt;Nice work &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongc&quot; class=&quot;user-hover&quot; rel=&quot;dongc&quot;&gt;Dong Chen&lt;/a&gt;!!&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cwsteinbach&quot; class=&quot;user-hover&quot; rel=&quot;cwsteinbach&quot;&gt;Carl Steinbach&lt;/a&gt; you two had some good feedback on the earlier design. Can you take a look at the latest patch? &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=romainr&quot; class=&quot;user-hover&quot; rel=&quot;romainr&quot;&gt;Romain Rigaux&lt;/a&gt;, I know Hue uses this API, do you want to take a look?&lt;/p&gt;</comment>
                            <comment id="14095190" author="romainr" created="Wed, 13 Aug 2014 06:02:28 +0000"  >&lt;p&gt;I mostly looked at the TCLIService.thrift. The new API looks good. &lt;/p&gt;

&lt;p&gt;Is FETCH_FIRST also implemented for the TFetchOrientation? (would still be useful in case a user refresh the page or wants all the logs again)&lt;/p&gt;</comment>
                            <comment id="14097063" author="dongc" created="Thu, 14 Aug 2014 15:20:57 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=romainr&quot; class=&quot;user-hover&quot; rel=&quot;romainr&quot;&gt;Romain Rigaux&lt;/a&gt;, thanks for your review. Yes, the FETCH_FIRST is implemented.&lt;/p&gt;</comment>
                            <comment id="14097333" author="thejas" created="Thu, 14 Aug 2014 18:25:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongc&quot; class=&quot;user-hover&quot; rel=&quot;dongc&quot;&gt;Dong Chen&lt;/a&gt; Thanks for the patch! I will review it in a few days.&lt;/p&gt;</comment>
                            <comment id="14102460" author="brocknoland" created="Tue, 19 Aug 2014 16:58:17 +0000"  >&lt;p&gt;Hi Dong,&lt;/p&gt;

&lt;p&gt;I tried posting this on RB but it went down. Thank you very much for removing the thrift enum compatibility problem! I had another comment with regards to the method signature which I think I did not explain well. I think the new method should be:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;FetchResultsResponse fetchResults(FetchResultsRequest) throws ...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The problem with how we&apos;ve defined RPC methods to date has led to an explosion of RPC methods which is problematic. This is described in &lt;a href=&quot;http://mail-archives.apache.org/mod_mbox/hive-dev/201403.mbox/%3CCAFukC=6XsS1KjgAD7HV2V4wWoiGjzctm1RuJCCzSOCDJ8X31eg@mail.gmail.com%3E&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;more detail in this thread&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let me know what you think!!&lt;/p&gt;

&lt;p&gt;Cheers,&lt;br/&gt;
Brock&lt;/p&gt;</comment>
                            <comment id="14103336" author="thejas" created="Wed, 20 Aug 2014 03:51:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongc&quot; class=&quot;user-hover&quot; rel=&quot;dongc&quot;&gt;Dong Chen&lt;/a&gt; Thanks for the clean and well documented code! I have added some minor comments in review board.&lt;/p&gt;</comment>
                            <comment id="14103519" author="thejas" created="Wed, 20 Aug 2014 06:56:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongc&quot; class=&quot;user-hover&quot; rel=&quot;dongc&quot;&gt;Dong Chen&lt;/a&gt; Earlier patch also had a method in HiveStatement to get the log. I think that will be convenient for many users, though we need to be careful and specify that is the only non jdbc function that is part of a public API in it. But this can also be done as follow up work in separate jira.&lt;/p&gt;</comment>
                            <comment id="14105890" author="thejas" created="Thu, 21 Aug 2014 20:21:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4629&quot; title=&quot;HS2 should support an API to retrieve query logs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4629&quot;&gt;&lt;del&gt;HIVE-4629&lt;/del&gt;&lt;/a&gt;.7.patch - Dong&apos;s patch from reviewboard, just to know how it is doing wrt tests.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongc&quot; class=&quot;user-hover&quot; rel=&quot;dongc&quot;&gt;Dong Chen&lt;/a&gt; Looking forward to updated patch from you!&lt;/p&gt;</comment>
                            <comment id="14106098" author="cwsteinbach" created="Thu, 21 Aug 2014 22:50:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;I tried posting this on RB but it went down. Thank you very much for removing the thrift enum compatibility problem! I had another comment with regards to the method signature which I think I did not explain well. I think the new method should be...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt;, I totally agree with this, but I didn&apos;t see this in the patch. Are you referring to something in the Thrift IDL file or something else?&lt;/p&gt;</comment>
                            <comment id="14106168" author="brocknoland" created="Thu, 21 Aug 2014 23:41:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;I didn&apos;t see this in the patch. Are you referring to something in the Thrift IDL file or something else?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You are right...I was confused between ICLIService and TCLIService. The patch only adds a new option member to TFetchResultsReq which is exactly what I wanted.&lt;/p&gt;

&lt;p&gt;Nevermind me &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14106482" author="dongc" created="Fri, 22 Aug 2014 05:23:49 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cwsteinbach&quot; class=&quot;user-hover&quot; rel=&quot;cwsteinbach&quot;&gt;Carl Steinbach&lt;/a&gt;, thanks for your precious comments. I am working on the updated patch to address these comments, and will let you know when the updated patch is uploaded.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Earlier patch also had a method in HiveStatement to get the log. I think that will be convenient for many users, though we need to be careful and specify that is the only non jdbc function that is part of a public API in it. But this can also be done as follow up work in separate jira.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt;, you are right, adding a method in HiveStatement to get the log is convenient for users. I filed a Jira &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7615&quot; title=&quot;Beeline should have an option for user to see the query progress&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7615&quot;&gt;&lt;del&gt;HIVE-7615&lt;/del&gt;&lt;/a&gt; and planed to add the getting log API in jdbc level there.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I didn&apos;t see this in the patch. Are you referring to something in the Thrift IDL file or something else?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cwsteinbach&quot; class=&quot;user-hover&quot; rel=&quot;cwsteinbach&quot;&gt;Carl Steinbach&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt;, the latest patch still does not fulfill the comments about backward compatibility. I will update the patch soon and let you know. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
The Thrift level interface TCLIService is OK. &lt;br/&gt;
For client and service layer interface ICLIService, although it is not RPC and is not a public API of Hive, I think making it follow the single request/response struct mode is also good. Will make the new fetchResults method follow the single request/response struct model. Then remove those old fetchResults methods.&lt;/p&gt;</comment>
                            <comment id="14106691" author="hiveqa" created="Fri, 22 Aug 2014 10:25:11 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12663483/HIVE-4629.7.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12663483/HIVE-4629.7.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/455/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/455/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/455/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/455/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-455/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-455/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.6.0_34/bin:/usr/local/apache-maven-3.0.5/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.6.0_34/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.6.0_34/bin:/usr/local/apache-maven-3.0.5/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.6.0_34/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-455/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/io/orc/RunLengthIntegerWriterV2.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/io/orc/SerializationUtils.java&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ awk &apos;{print $2}&apos;
++ svn status --no-ignore
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20/target shims/0.20S/target shims/0.23/target shims/aggregator/target shims/common/target shims/common-secure/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit-hadoop2/target itests/hive-minikdc/target itests/hive-unit/target itests/custom-serde/target itests/util/target hcatalog/target hcatalog/core/target hcatalog/streaming/target hcatalog/server-extensions/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target hcatalog/hcatalog-pig-adapter/target accumulo-handler/target hwi/target common/target common/src/gen contrib/target service/target serde/target beeline/target odbc/target cli/target ql/dependency-reduced-pom.xml ql/target
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1619731.

At revision 1619731.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12663483&lt;/p&gt;</comment>
                            <comment id="14107206" author="brocknoland" created="Fri, 22 Aug 2014 18:03:29 +0000"  >&lt;p&gt;Hi Dong,&lt;/p&gt;

&lt;p&gt;The latest patch fails to apply to HEAD and will need to be rebased.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;the latest patch still does not fulfill the comments about backward compatibility.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I am very sorry for the confusion, I believe the patch &lt;b&gt;does&lt;/b&gt; meet the backward compatibility requirement.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;For client and service layer interface ICLIService, although it is not RPC and is not a public API of Hive, I think making it follow the single request/response struct mode is also good. Will make the new fetchResults method follow the single request/response struct model. Then remove those old fetchResults methods.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I do not feel this is required. The current patch works exactly as we requested!&lt;/p&gt;

&lt;p&gt;Thank you very much Dong!!&lt;/p&gt;</comment>
                            <comment id="14110510" author="dongc" created="Tue, 26 Aug 2014 08:54:03 +0000"  >&lt;p&gt;Update patch V8 to address the precious comments from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cwsteinbach&quot; class=&quot;user-hover&quot; rel=&quot;cwsteinbach&quot;&gt;Carl Steinbach&lt;/a&gt;, and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt;. Thanks very much for your review to make this patch better.&lt;/p&gt;

&lt;p&gt;And rebase it from latest trunk.&lt;/p&gt;</comment>
                            <comment id="14110892" author="brocknoland" created="Tue, 26 Aug 2014 16:19:06 +0000"  >&lt;p&gt;Nice work Dong! From my side this looks great and I think we should commit.&lt;/p&gt;

&lt;p&gt;+1 pending tests&lt;/p&gt;

&lt;p&gt;Thejas or Carl, please let me know if you&apos;d like to see additional work before commit.&lt;/p&gt;</comment>
                            <comment id="14111071" author="hiveqa" created="Tue, 26 Aug 2014 18:12:42 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12664360/HIVE-4629.8.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12664360/HIVE-4629.8.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 6119 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/505/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/505/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/505/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/505/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-505/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-505/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12664360&lt;/p&gt;</comment>
                            <comment id="14111122" author="thejas" created="Tue, 26 Aug 2014 18:43:37 +0000"  >&lt;p&gt;+1 . &lt;br/&gt;
Thanks Dong, great work!&lt;br/&gt;
Looking forward to your contributions in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7615&quot; title=&quot;Beeline should have an option for user to see the query progress&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7615&quot;&gt;&lt;del&gt;HIVE-7615&lt;/del&gt;&lt;/a&gt;, it would be great to have that in hive 0.14 release !&lt;/p&gt;</comment>
                            <comment id="14112807" author="brocknoland" created="Wed, 27 Aug 2014 20:45:50 +0000"  >&lt;p&gt;I have committed this to trunk! Thank you Dong! This is truly a long awaited contribution!&lt;/p&gt;

&lt;p&gt;FYI - I had to do one trivial rebase in SessionManager when committing so I&apos;ve uploaded that patch as v9. I verified it does not break the build.&lt;/p&gt;</comment>
                            <comment id="14113540" author="lefty@hortonworks.com" created="Thu, 28 Aug 2014 08:29:30 +0000"  >&lt;p&gt;Does this need to be documented in the wiki?&lt;/p&gt;

&lt;p&gt;Of course, two new parameters need to go in Configuration Properties (&lt;b&gt;hive.server2.logging.operation.enabled&lt;/b&gt;, &lt;b&gt;hive.server2.logging.operation.log.location&lt;/b&gt;), but should general guidance be given in one of the HS2 wikidocs?  The logging section in Getting Started could also mention this.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Clients&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HiveServer2 Clients &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Setting+Up+HiveServer2&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Setting Up HiveServer2 &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-ErrorLogs&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Getting Started &amp;#8211; Error Logs &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-HiveServer2&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Configuration Properties &amp;#8211; HiveServer2 &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</comment>
                            <comment id="14117171" author="dongc" created="Mon, 1 Sep 2014 08:20:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=leftylev&quot; class=&quot;user-hover&quot; rel=&quot;leftylev&quot;&gt;Lefty Leverenz&lt;/a&gt;, Thanks for your comments. For the document, I think adding the two new parameters in Configuration Properties might be enough now. &lt;br/&gt;
Since this patch only impact the Thrift interface, maybe the general guidance is not needed for users. The getting log API of JDBC layer, which is an upper level of Thrift layer, will be added in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7615&quot; title=&quot;Beeline should have an option for user to see the query progress&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7615&quot;&gt;&lt;del&gt;HIVE-7615&lt;/del&gt;&lt;/a&gt;. I think after that Jira is done, a general guidance about how to use the query logs api could be introduced then.&lt;/p&gt;</comment>
                            <comment id="14203666" author="lefty@hortonworks.com" created="Sat, 8 Nov 2014 22:45:07 +0000"  >&lt;p&gt;Doc note:  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8785&quot; title=&quot;HiveServer2 LogDivertAppender should be more selective for beeline getLogs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8785&quot;&gt;&lt;del&gt;HIVE-8785&lt;/del&gt;&lt;/a&gt; extends the description of &lt;b&gt;hive.server2.logging.operation.enabled&lt;/b&gt; to &quot;When true, HS2 will save operation logs &lt;em&gt;and make them available for clients&lt;/em&gt;&quot; (emphasis added).&lt;/p&gt;</comment>
                            <comment id="14210703" author="thejas" created="Thu, 13 Nov 2014 19:42:08 +0000"  >&lt;p&gt;This has been fixed in 0.14 release. Please open new jira if you see any issues.&lt;/p&gt;</comment>
                            <comment id="14245883" author="lefty@hortonworks.com" created="Sun, 14 Dec 2014 10:54:54 +0000"  >&lt;p&gt;Doc note:  &lt;b&gt;hive.server2.logging.operation.enabled&lt;/b&gt; and &lt;b&gt;hive.server2.logging.operation.log.location&lt;/b&gt; are now documented in the wiki, but I need help with the location&apos;s default value.  (I tried to generate a template file for 0.14.0, but failed because my new laptop didn&apos;t have Maven or JDK and I hit an installation snag.)&lt;/p&gt;

&lt;p&gt;In the patch, the default location is &lt;tt&gt;&quot;$system:java.io.tmpdir&quot; + File.separator + &quot;$system:user.name&quot; + File.separator + &quot;operation_logs&quot;&lt;/tt&gt; &amp;#8211; braces omitted &amp;#8211; but surely that can be simplified for the doc.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.server2.logging.operation.enabled&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;hive.server2.logging.operation.enabled &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.server2.logging.operation.log.location&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;hive.server2.logging.operation.log.location &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Also, now that &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-7615&quot; title=&quot;Beeline should have an option for user to see the query progress&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-7615&quot;&gt;&lt;del&gt;HIVE-7615&lt;/del&gt;&lt;/a&gt; has been committed we need some guidance about how to use the query logs API.&lt;/p&gt;</comment>
                            <comment id="14246219" author="dongc" created="Mon, 15 Dec 2014 01:35:25 +0000"  >&lt;p&gt;The location&apos;s value in template is &lt;tt&gt;${system:java.io.tmpdir}/${system:user.name}/operation_logs&lt;/tt&gt;. And for doc, I think it can be more simplified as &lt;tt&gt;${java.io.tmpdir}/${user.name}/operation_logs&lt;/tt&gt;&lt;/p&gt;</comment>
                            <comment id="14246500" author="lefty@hortonworks.com" created="Mon, 15 Dec 2014 09:32:28 +0000"  >&lt;p&gt;Done, thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongc&quot; class=&quot;user-hover&quot; rel=&quot;dongc&quot;&gt;Dong Chen&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Guidance about configuring and using the query logs could be added to one of the HiveServer2 docs (probably Setting Up HS2), with links to &amp;amp; from the logging section in Getting Started.  Also see &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8785&quot; title=&quot;HiveServer2 LogDivertAppender should be more selective for beeline getLogs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8785&quot;&gt;&lt;del&gt;HIVE-8785&lt;/del&gt;&lt;/a&gt; for &lt;b&gt;hive.server2.logging.operation.verbose&lt;/b&gt;.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Setting+Up+HiveServer2&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Setting Up HiveServer2 &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Clients&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HiveServer2 Clients &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-ErrorLogs&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Getting Started &amp;#8211; Error Logs &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15173707" author="prongs" created="Tue, 1 Mar 2016 12:56:59 +0000"  >&lt;p&gt;As far as I understand, the logs are removed once the operation completes. So if my operation finished with an error and I want to see the logs after it fails, how do I proceed?&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12753831">HIVE-8785</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12682313">HIVE-5924</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12731966">HIVE-7615</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12765461">HIVE-9297</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12604916" name="HIVE-4629-no_thrift.1.patch" size="42116" author="shreepadma" created="Tue, 24 Sep 2013 23:40:49 +0000"/>
                            <attachment id="12604928" name="HIVE-4629.1.patch" size="218838" author="shreepadma" created="Wed, 25 Sep 2013 00:13:08 +0000"/>
                            <attachment id="12605136" name="HIVE-4629.2.patch" size="218838" author="shreepadma" created="Wed, 25 Sep 2013 23:28:14 +0000"/>
                            <attachment id="12647299" name="HIVE-4629.3.patch.txt" size="139857" author="navis" created="Thu, 29 May 2014 05:20:39 +0000"/>
                            <attachment id="12659815" name="HIVE-4629.4.patch" size="85117" author="dongc" created="Tue, 5 Aug 2014 04:18:13 +0000"/>
                            <attachment id="12660406" name="HIVE-4629.5.patch" size="91029" author="dongc" created="Thu, 7 Aug 2014 17:14:12 +0000"/>
                            <attachment id="12660420" name="HIVE-4629.6.patch" size="91041" author="dongc" created="Thu, 7 Aug 2014 17:46:04 +0000"/>
                            <attachment id="12663483" name="HIVE-4629.7.patch" size="86880" author="thejas" created="Thu, 21 Aug 2014 20:21:15 +0000"/>
                            <attachment id="12664360" name="HIVE-4629.8.patch" size="87682" author="dongc" created="Tue, 26 Aug 2014 08:54:03 +0000"/>
                            <attachment id="12664737" name="HIVE-4629.9.patch" size="84106" author="brocknoland" created="Wed, 27 Aug 2014 20:45:50 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>10.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 30 May 2013 18:18:18 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330358</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 46 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kzt3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330692</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4630] bin/hive fails if the user has CDPATH environment variable set</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4630</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;If a user invokes bin/hive and he has CDPATH set in his environment the bin/hive script will fail.  The reason for this is the following line:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;bin=`cd &lt;span class=&quot;code-quote&quot;&gt;&quot;$bin&quot;&lt;/span&gt;; pwd`
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If CDPATH is set then &quot;cd $bin&quot; will echo the path just cd&apos;d to.  This causes the variable bin to have two lines, one from cd and one from pwd.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650048">HIVE-4630</key>
            <summary>bin/hive fails if the user has CDPATH environment variable set</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="alangates">Alan Gates</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 May 2013 22:54:23 +0000</created>
                <updated>Wed, 29 May 2013 22:54:23 +0000</updated>
                                            <version>0.11.0</version>
                                                    <component>CLI</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330375</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 34 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kzwn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330709</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4631] Hive doesn&apos;t flush errors of multi-stage queries to STDERR until end of query</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4631</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;When running a multi-stage query from the CLI for example &lt;br/&gt;
say the query is:&lt;br/&gt;
SELECT  COUNT&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; FROM ( &lt;br/&gt;
SELECT user from users&lt;br/&gt;
where datetime = 05-10-2013&lt;br/&gt;
UNION ALL&lt;br/&gt;
SELECT user from users&lt;br/&gt;
where datetime = 05-10-2013 &lt;br/&gt;
) a&lt;/p&gt;

&lt;p&gt;and the command to execute it:&lt;br/&gt;
hive -e &quot;&amp;lt;query&amp;gt;&quot; &lt;/p&gt;

&lt;p&gt;If one of the jobs fails for example the 1st of 3, it should immediately write that to the standard error and flush it. Therefore if you are scripting a hive query you can catch the exception and terminate the other jobs rather then having to wait for them to run to handle the exception from the first job.&lt;/p&gt;

&lt;p&gt;See here for more details:&lt;br/&gt;
&lt;a href=&quot;http://stackoverflow.com/questions/16825066/hive-flush-errors-of-multi-stage-jobs-to-stderr-in-python&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://stackoverflow.com/questions/16825066/hive-flush-errors-of-multi-stage-jobs-to-stderr-in-python&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650067">HIVE-4631</key>
            <summary>Hive doesn&apos;t flush errors of multi-stage queries to STDERR until end of query</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="bradruderman">Brad Ruderman</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 May 2013 00:26:22 +0000</created>
                <updated>Thu, 30 May 2013 15:47:37 +0000</updated>
                                            <version>0.9.0</version>
                                                    <component>CLI</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330394</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 34 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l00v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330728</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>CLI </customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4632] Use hadoop counter as a stat publisher</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4632</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently stats are all long/aggregation type and can be safely acquired by hadoop counter without other db or hbase.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650087">HIVE-4632</key>
            <summary>Use hadoop counter as a stat publisher</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis</assignee>
                                    <reporter username="navis">Navis</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 May 2013 05:00:00 +0000</created>
                <updated>Sun, 23 Mar 2014 09:27:26 +0000</updated>
                            <resolved>Tue, 19 Nov 2013 19:58:47 +0000</resolved>
                                    <version>0.12.0</version>
                                    <fixVersion>0.13.0</fixVersion>
                                    <component>Statistics</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13670079" author="phabricator@reviews.facebook.net" created="Thu, 30 May 2013 05:51:20 +0000"  >&lt;p&gt;navis requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4632&quot; title=&quot;Use hadoop counter as a stat publisher&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4632&quot;&gt;&lt;del&gt;HIVE-4632&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Use hadoop counter as a stat publisher&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4632&quot; title=&quot;Use hadoop counter as a stat publisher&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4632&quot;&gt;&lt;del&gt;HIVE-4632&lt;/del&gt;&lt;/a&gt; Use hadoop counter as a stat publisher&lt;/p&gt;

&lt;p&gt;Currently stats are all long/aggregation type and can be safely acquired by hadoop counter without other db or hbase.&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11001&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11001&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsAggregator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/MapredContext.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/StatsWork.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/CounterStatsAggregator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/CounterStatsPublisher.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/StatsAggregator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/StatsFactory.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/StatsSetupConst.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsAggregator.java&lt;br/&gt;
  ql/src/test/org/apache/hadoop/hive/ql/exec/TestStatsPublisherEnhanced.java&lt;br/&gt;
  ql/src/test/org/apache/hadoop/hive/ql/stats/DummyStatsAggregator.java&lt;br/&gt;
  ql/src/test/org/apache/hadoop/hive/ql/stats/KeyVerifyingStatsAggregator.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/26265/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/26265/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13820850" author="ashutoshc" created="Wed, 13 Nov 2013 02:36:08 +0000"  >&lt;p&gt;This looks useful, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; would you like to rebase this on latest trunk ?&lt;/p&gt;</comment>
                            <comment id="13820852" author="ashutoshc" created="Wed, 13 Nov 2013 02:37:23 +0000"  >&lt;p&gt;Also, I think counter should be default mechanism to gather stats instead of current defaults which never gather stats correctly.&lt;/p&gt;</comment>
                            <comment id="13822140" author="phabricator@reviews.facebook.net" created="Thu, 14 Nov 2013 03:49:17 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4632&quot; title=&quot;Use hadoop counter as a stat publisher&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4632&quot;&gt;&lt;del&gt;HIVE-4632&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Use hadoop counter as a stat publisher&quot;.&lt;/p&gt;

&lt;p&gt;  Rebased to trunk &amp;amp; added a test case&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11001&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11001&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11001?vs=34113&amp;amp;id=43617#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11001?vs=34113&amp;amp;id=43617#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/common/StatsSetupConst.java&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsAggregator.java&lt;br/&gt;
  itests/qtest/pom.xml&lt;br/&gt;
  itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/KeyVerifyingStatsAggregator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/StatsWork.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/CounterStatsAggregator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/CounterStatsPublisher.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/StatsAggregator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/StatsFactory.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/StatsSetupConst.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsAggregator.java&lt;br/&gt;
  ql/src/test/org/apache/hadoop/hive/ql/exec/TestStatsPublisherEnhanced.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/stats_counter.q&lt;br/&gt;
  ql/src/test/results/clientpositive/stats_counter.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13822200" author="ashutoshc" created="Thu, 14 Nov 2013 06:18:06 +0000"  >&lt;p&gt;Patch looks good. I think we should also change default (in HiveConf.java and also in data/conf/hive-site.xml for tests) to use counter mechanism, instead of current jdbc one. With the current default configs, stats cannot be collected, so its useless anyway. Even after you configure it with custom settings, I have found client takes forever to aggregate and publish stats once job ends, so using counter will give us something which works out of box as well as performing better.&lt;/p&gt;</comment>
                            <comment id="13823236" author="hiveqa" created="Fri, 15 Nov 2013 02:47:24 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12613778/D11001.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12613778/D11001.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/293/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/293/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/293/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/293/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-293/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&apos;
Reverted &apos;ql/src/test/results/clientpositive/groupby_ppr.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/input_part7.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketmapjoin5.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/pcr.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/macro.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/join33.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/input_part2.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/alter_partition_coltype.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/auto_sortmerge_join_4.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/load_dyn_part8.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/sample9.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/groupby_map_ppr.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/groupby_sort_6.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/sample4.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/push_or.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketcontext_7.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/groupby_sort_1.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/stats13.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/udf_reflect2.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/auto_sortmerge_join_11.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/rand_partitionpruner1.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/combine2_hadoop20.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketcontext_2.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/auto_join_reordering_values.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucket2.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/groupby_map_ppr_multi_distinct.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/filter_join_breaktask.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/join17.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/input_part9.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketmapjoin11.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/join26.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/ppd_join_filter.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/join35.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketmapjoin2.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/smb_mapjoin9.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/join_map_ppr.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/stats0.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/join9.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/smb_mapjoin_11.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/ppr_allchildsarenull.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/auto_sortmerge_join_1.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/sample6.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/join_filters_overlap.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucket_map_join_1.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/sample1.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/rand_partitionpruner3.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketcontext_4.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/udtf_explode.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/merge3.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/sort_merge_join_desc_7.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/binary_output_format.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketmapjoin9.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketmapjoin13.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketmapjoin4.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/union22.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/smb_mapjoin_13.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/join32.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/input_part1.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/groupby_sort_skew_1.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/auto_sortmerge_join_8.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/auto_sortmerge_join_3.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketmapjoin_negative3.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/sample8.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/transform_ppr2.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/union_ppr.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/serde_user_properties.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/ctas_hadoop20.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/ppd_vc.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/dynamic_partition_skip_default.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketcontext_6.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/stats12.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/router_join_ppr.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketcontext_1.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucket1.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/input42.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketmapjoin10.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/union24.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/smb_mapjoin_15.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/join34.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketmapjoin1.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/sample10.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/auto_sortmerge_join_5.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/louter_join_ppr.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/udf_java_method.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/sample5.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketcontext_8.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/udf_explode.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/auto_sortmerge_join_12.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/rand_partitionpruner2.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketcontext_3.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucket3.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/groupby_ppr_multi_distinct.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/sort_merge_join_desc_6.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketmapjoin8.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketmapjoin12.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketmapjoin3.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/smb_mapjoin_12.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/metadataonly1.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/join32_lessSize.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/auto_sortmerge_join_7.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/outer_join_ppr.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/udf_reflect.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/auto_sortmerge_join_2.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/sample7.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/transform_ppr1.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/regexp_extract.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucket_map_join_2.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/sample2.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/ppd_union_view.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketcontext_5.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/stats11.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/input23.q.out&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/plan/AbstractOperatorDesc.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/plan/OperatorDesc.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/util/JavaDataModel.java&apos;
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20/target shims/assembly/target shims/0.20S/target shims/0.23/target shims/common/target shims/common-secure/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target data/files/alltypes.txt data/files/dept.txt data/files/loc.txt data/files/emp.txt itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit/target itests/custom-serde/target itests/util/target hcatalog/target hcatalog/storage-handlers/hbase/target hcatalog/server-extensions/target hcatalog/core/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target hcatalog/hcatalog-pig-adapter/target hwi/target common/target common/src/gen contrib/target service/target serde/target beeline/target odbc/target cli/target ql/dependency-reduced-pom.xml ql/target ql/src/test/results/clientpositive/annotate_stats_select.q.out ql/src/test/results/clientpositive/annotate_stats_union.q.out ql/src/test/results/clientpositive/annotate_stats_groupby.q.out ql/src/test/results/clientpositive/annotate_stats_table.q.out ql/src/test/results/clientpositive/annotate_stats_join.q.out ql/src/test/results/clientpositive/annotate_stats_filter.q.out ql/src/test/results/clientpositive/annotate_stats_part.q.out ql/src/test/results/clientpositive/annotate_stats_limit.q.out ql/src/test/queries/clientpositive/annotate_stats_union.q ql/src/test/queries/clientpositive/annotate_stats_join.q ql/src/test/queries/clientpositive/annotate_stats_groupby.q ql/src/test/queries/clientpositive/annotate_stats_limit.q ql/src/test/queries/clientpositive/annotate_stats_select.q ql/src/test/queries/clientpositive/annotate_stats_table.q ql/src/test/queries/clientpositive/annotate_stats_part.q ql/src/test/queries/clientpositive/annotate_stats_filter.q ql/src/java/org/apache/hadoop/hive/ql/optimizer/stats ql/src/java/org/apache/hadoop/hive/ql/plan/ColStatistics.java ql/src/java/org/apache/hadoop/hive/ql/plan/Statistics.java ql/src/java/org/apache/hadoop/hive/ql/stats/StatsUtils.java
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1542159.

At revision 1542159.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12613778&lt;/p&gt;</comment>
                            <comment id="13824206" author="phabricator@reviews.facebook.net" created="Fri, 15 Nov 2013 22:51:19 +0000"  >&lt;p&gt;ashutoshc has requested changes to the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4632&quot; title=&quot;Use hadoop counter as a stat publisher&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4632&quot;&gt;&lt;del&gt;HIVE-4632&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Use hadoop counter as a stat publisher&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/CounterStatsAggregator.java:43 Instead of new JobConf(hconf, ExecDriver.class), doing (JobConf) hconf is better, ie instead of creating new JobConf object, cast hconf to JobConf.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/CounterStatsPublisher.java:48 I don&apos;t think we need to do this check isDecimals(). Counters by definition are countable, so they must be of numeric type. If they are not, than its bug, which we shouldn&apos;t hide.&lt;br/&gt;
  Thing is this method will be called on every row, so its lots of wasted compute here.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/CounterStatsAggregator.java:69 Good to do LOG.error(e) here.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11001&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11001&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4632&quot; title=&quot;Use hadoop counter as a stat publisher&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4632&quot;&gt;&lt;del&gt;HIVE-4632&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;br/&gt;
Cc: ashutoshc&lt;/p&gt;</comment>
                            <comment id="13824209" author="ashutoshc" created="Fri, 15 Nov 2013 22:54:33 +0000"  >&lt;p&gt;Left some minor comments on Phabricator.  &lt;br/&gt;
Seems like counters don&apos;t work for local job runner. So, I guess we can skip changing data/conf/hive-site.xml for test cases. Still good to change default in HiveConf.java. &lt;br/&gt;
Also, patch uploaded by phabricator seems to not apply cleanly on trunk and thats why Hive QA failed to run. Next time you update patch via phabricator you may want to make sure it applies cleanly on fresh svn checkout.&lt;/p&gt;</comment>
                            <comment id="13825094" author="phabricator@reviews.facebook.net" created="Mon, 18 Nov 2013 04:13:19 +0000"  >&lt;p&gt;navis has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4632&quot; title=&quot;Use hadoop counter as a stat publisher&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4632&quot;&gt;&lt;del&gt;HIVE-4632&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Use hadoop counter as a stat publisher&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/CounterStatsAggregator.java:43 I was not sure it&apos;s always a JobConf. I&apos;ll check the type of conf and make new JobConf only if needed.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/CounterStatsAggregator.java:69 done.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/CounterStatsPublisher.java:48 I always wondered why there is no string or double type counters, which might be useful for complex MR jobs if exists. I&apos;ll remove this part.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11001&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11001&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4632&quot; title=&quot;Use hadoop counter as a stat publisher&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4632&quot;&gt;&lt;del&gt;HIVE-4632&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;br/&gt;
Cc: ashutoshc&lt;/p&gt;</comment>
                            <comment id="13825096" author="navis" created="Mon, 18 Nov 2013 04:17:57 +0000"  >&lt;p&gt;Phabricator seemed to have low threshold for acknowledging new files as copied one(P mark on phabricator review), which makes the patch not applied cleanly. And I&apos;ve seen that It&apos;s not configurable one (it should be recompiled). I&apos;ll update the patch in manual.&lt;/p&gt;</comment>
                            <comment id="13825103" author="phabricator@reviews.facebook.net" created="Mon, 18 Nov 2013 04:29:17 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4632&quot; title=&quot;Use hadoop counter as a stat publisher&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4632&quot;&gt;&lt;del&gt;HIVE-4632&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Use hadoop counter as a stat publisher&quot;.&lt;/p&gt;

&lt;p&gt;  Addressed comments&lt;/p&gt;

&lt;p&gt;Reviewers: ashutoshc, JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11001&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11001&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11001?vs=43617&amp;amp;id=43839#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11001?vs=43617&amp;amp;id=43839#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/common/StatsSetupConst.java&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;br/&gt;
  conf/hive-default.xml.template&lt;br/&gt;
  data/conf/hive-site.xml&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsAggregator.java&lt;br/&gt;
  itests/qtest/pom.xml&lt;br/&gt;
  itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/KeyVerifyingStatsAggregator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/StatsWork.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/CounterStatsAggregator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/CounterStatsPublisher.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/StatsAggregator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/StatsFactory.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/StatsSetupConst.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsAggregator.java&lt;br/&gt;
  ql/src/test/org/apache/hadoop/hive/ql/exec/TestStatsPublisherEnhanced.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/stats_counter.q&lt;br/&gt;
  ql/src/test/results/clientpositive/stats_counter.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;br/&gt;
Cc: ashutoshc&lt;/p&gt;</comment>
                            <comment id="13825161" author="hiveqa" created="Mon, 18 Nov 2013 08:03:04 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12614333/HIVE-4632.4.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12614333/HIVE-4632.4.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/337/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/337/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/337/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/337/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-337/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;ql/src/test/results/clientnegative/notable_alias3.q.out&apos;
Reverted &apos;ql/src/test/results/compiler/plan/groupby1.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/groupby5.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/errors/nonkey_groupby.q.out&apos;
Reverted &apos;ql/src/test/queries/clientnegative/notable_alias3.q&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/PTFTranslator.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/RowResolver.java&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ awk &apos;{print $2}&apos;
++ svn status --no-ignore
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20/target shims/assembly/target shims/0.20S/target shims/0.23/target shims/common/target shims/common-secure/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit/target itests/custom-serde/target itests/util/target hcatalog/target hcatalog/storage-handlers/hbase/target hcatalog/server-extensions/target hcatalog/core/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target hcatalog/hcatalog-pig-adapter/target hwi/target common/target common/src/gen contrib/target service/target serde/target beeline/target odbc/target cli/target ql/dependency-reduced-pom.xml ql/target ql/src/test/results/clientpositive/notable_alias3.q.out ql/src/test/results/clientpositive/groupby_resolution.q.out ql/src/test/queries/clientpositive/notable_alias3.q ql/src/test/queries/clientpositive/groupby_resolution.q
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1542945.

At revision 1542945.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file common/src/java/org/apache/hadoop/hive/common/StatsSetupConst.java
patching file common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
patching file conf/hive-default.xml.template
patching file data/conf/hive-site.xml
patching file hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsAggregator.java
patching file itests/qtest/pom.xml
patching file itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/KeyVerifyingStatsAggregator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/StatsWork.java
patching file ql/src/java/org/apache/hadoop/hive/ql/stats/CounterStatsAggregator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/stats/CounterStatsPublisher.java
patching file ql/src/java/org/apache/hadoop/hive/ql/stats/StatsAggregator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/stats/StatsFactory.java
patching file ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsAggregator.java
patching file ql/src/test/org/apache/hadoop/hive/ql/exec/TestStatsPublisherEnhanced.java
patching file ql/src/test/queries/clientpositive/stats_counter.q
patching file ql/src/test/results/clientpositive/stats_counter.q.out
+ [[ maven == \m\a\v\e\n ]]
+ rm -rf /data/hive-ptest/working/maven/org/apache/hive
+ mvn -B clean install -DskipTests -Dmaven.repo.local=/data/hive-ptest/working/maven
[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Hive
[INFO] Hive Ant Utilities
[INFO] Hive Shims Common
[INFO] Hive Shims 0.20
[INFO] Hive Shims Secure Common
[INFO] Hive Shims 0.20S
[INFO] Hive Shims 0.23
[INFO] Hive Shims
[INFO] Hive Common
[INFO] Hive Serde
[INFO] Hive Metastore
[INFO] Hive Query Language
[INFO] Hive Service
[INFO] Hive JDBC
[INFO] Hive Beeline
[INFO] Hive CLI
[INFO] Hive Contrib
[INFO] Hive HBase Handler
[INFO] Hive HCatalog
[INFO] Hive HCatalog Core
[INFO] Hive HCatalog Pig Adapter
[INFO] Hive HCatalog Server Extensions
[INFO] Hive HCatalog Webhcat Java Client
[INFO] Hive HCatalog Webhcat
[INFO] Hive HCatalog HBase Storage Handler
[INFO] Hive HWI
[INFO] Hive ODBC
[INFO] Hive Shims Aggregator
[INFO] Hive TestUtils
[INFO] Hive Packaging
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive/0.13.0-SNAPSHOT/hive-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Ant Utilities 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-ant ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/ant (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-ant ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-ant ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-ant ---
[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-svn-trunk-source/ant/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-ant ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-ant ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-ant ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-ant ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-ant ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/hive-ant-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-ant ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ant/target/hive-ant-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-ant/0.13.0-SNAPSHOT/hive-ant-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ant/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-ant/0.13.0-SNAPSHOT/hive-ant-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-common ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/common (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common ---
[INFO] Compiling 15 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-common ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-common ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common/0.13.0-SNAPSHOT/hive-shims-common-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common/0.13.0-SNAPSHOT/hive-shims-common-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.20 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.20 ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20 (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20 ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20 ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20 ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.20 ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.20 ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20/0.13.0-SNAPSHOT/hive-shims-0.20-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20/0.13.0-SNAPSHOT/hive-shims-0.20-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Secure Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-common-secure ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common-secure ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common-secure ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common-secure ---
[INFO] Compiling 12 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/main/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common-secure ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common-secure ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common-secure ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common-secure ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-common-secure ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-common-secure ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common-secure/0.13.0-SNAPSHOT/hive-shims-common-secure-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common-secure/0.13.0-SNAPSHOT/hive-shims-common-secure-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.20S 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.20S ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20S ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20S ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20S ---
[INFO] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/main/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20S ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20S ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20S ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20S ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.20S ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.20S ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20S/0.13.0-SNAPSHOT/hive-shims-0.20S-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20S/0.13.0-SNAPSHOT/hive-shims-0.20S-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.23 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.23 ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23 (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.23 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.23 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.23 ---
[INFO] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/main/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.23 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.23 ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.23 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.23 ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.23 ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.23 ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.23/0.13.0-SNAPSHOT/hive-shims-0.23-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.23/0.13.0-SNAPSHOT/hive-shims-0.23-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims ---
[WARNING] JAR will be empty - no content was marked for inclusion!
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-assembly-plugin:2.3:single (uberjar) @ hive-shims ---
[INFO] Reading assembly descriptor: src/assemble/uberjar.xml
[WARNING] Artifact: org.apache.hive:hive-shims:jar:0.13.0-SNAPSHOT references the same file as the assembly destination file. Moving it to a temporary location for inclusion.
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[WARNING] Configuration options: &apos;appendAssemblyId&apos; is set to false, and &apos;classifier&apos; is missing.
Instead of attaching the assembly file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar, it will become the file for main project artifact.
NOTE: If multiple descriptors or descriptor-formats are provided for this project, the value of this file will be non-deterministic!
[WARNING] Replacing pre-existing project main-artifact file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/archive-tmp/hive-shims-0.13.0-SNAPSHOT.jar
with assembly file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.13.0-SNAPSHOT/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.13.0-SNAPSHOT/hive-shims-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-common ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/common (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-version-annotation) @ hive-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-common ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/common/src/gen added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-common ---
[INFO] Compiling 31 source files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/common/src/java/org/apache/hadoop/hive/common/ObjectPair.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-common ---
[INFO] Compiling 8 source files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-common ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-common ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-common ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-common/0.13.0-SNAPSHOT/hive-common-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/common/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-common/0.13.0-SNAPSHOT/hive-common-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Serde 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-serde ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/serde (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-serde ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/protobuf/gen-java added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-serde ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-serde ---
[INFO] Compiling 351 source files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-serde ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-serde ---
[INFO] Compiling 41 source files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-serde ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-serde ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-serde ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-serde/0.13.0-SNAPSHOT/hive-serde-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/serde/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-serde/0.13.0-SNAPSHOT/hive-serde-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Metastore 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-metastore ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/metastore (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-metastore ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/model added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-metastore ---
[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java
ANTLR Parser Generator  Version 3.4
org/apache/hadoop/hive/metastore/parser/Filter.g
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-metastore ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-metastore ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-metastore ---
[INFO] Compiling 132 source files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- datanucleus-maven-plugin:3.3.0-release:enhance (default) @ hive-metastore ---
[INFO] DataNucleus Enhancer (version 3.2.2) for API &quot;JDO&quot; using JRE &quot;1.6&quot;
DataNucleus Enhancer : Classpath
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-maven-plugin/3.3.0-release/datanucleus-maven-plugin-3.3.0-release.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-utils/3.0.8/plexus-utils-3.0.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-component-annotations/1.5.5/plexus-component-annotations-1.5.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-inject-bean/2.3.0/sisu-inject-bean-2.3.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guice/3.1.0/sisu-guice-3.1.0-no_aop.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guava/0.9.9/sisu-guava-0.9.9.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/xbean/xbean-reflect/3.4/xbean-reflect-3.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/log4j/log4j/1.2.12/log4j-1.2.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-logging/commons-logging-api/1.1/commons-logging-api-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/collections/google-collections/1.0/google-collections-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/junit/junit/3.8.2/junit-3.8.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/tukaani/xz/1.0/xz-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-codec/commons-codec/1.4/commons-codec-1.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/avro/avro/1.7.1/avro-1.7.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/jline/jline/0.9.94/jline-0.9.94.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/guava/guava/11.0.2/guava-11.0.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-lang/commons-lang/2.4/commons-lang-2.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/transaction/jta/1.1/jta-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/antlr/antlr/2.7.7/antlr-2.7.7.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/hadoop/hadoop-core/1.2.1/hadoop-core-1.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/xmlenc/xmlenc/0.52/xmlenc-0.52.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/stax/stax-api/1.0.1/stax-api-1.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/activation/activation/1.1/activation-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-jaxrs/1.7.1/jackson-jaxrs-1.7.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/asm/asm/3.1/asm-3.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-io/commons-io/2.1/commons-io-2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/commons/commons-math/2.1/commons-math-2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-digester/commons-digester/1.8/commons-digester-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/ant/ant/1.6.5/ant-1.6.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-el/commons-el/1.0/commons-el-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/oro/oro/2.0.8/oro-2.0.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/log4j/log4j/1.2.16/log4j-1.2.16.jar
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDatabase
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFieldSchema
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MType
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTable
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MOrder
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStringList
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartition
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MIndex
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRole
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRoleMap
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MMasterKey
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDelegationToken
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MVersionTable
DataNucleus Enhancer completed with success for 25 classes. Timings : input=598 ms, enhance=924 ms, total=1522 ms. Consult the log for full details

[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-metastore ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-metastore ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-metastore ---
[INFO] Compiling 10 source files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-metastore ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-metastore ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-metastore ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-metastore ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Query Language 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-exec ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/ql (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-sources) @ hive-exec ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-test-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
Generating vector expression code
Generating vector expression test code
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-exec ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/protobuf/gen-java added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-sources/java added.
[INFO] 
[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-exec ---
[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java
ANTLR Parser Generator  Version 3.4
org/apache/hadoop/hive/ql/parse/HiveLexer.g
org/apache/hadoop/hive/ql/parse/HiveParser.g
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:872:5: 
Decision can match input such as &quot;Identifier KW_RENAME KW_TO&quot; using multiple alternatives: 1, 10

As a result, alternative(s) 10 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:5: 
Decision can match input such as &quot;KW_TEXTFILE&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:5: 
Decision can match input such as &quot;KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:5: 
Decision can match input such as &quot;KW_ORCFILE&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:5: 
Decision can match input such as &quot;KW_RCFILE&quot; using multiple alternatives: 3, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1190:23: 
Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1190:23: 
Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1190:23: 
Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1197:23: 
Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1197:23: 
Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1197:23: 
Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_PRETTY {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_FORMATTED {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_PRETTY Identifier&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_FORMATTED Identifier&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_PRETTY KW_PARTITION&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_FORMATTED KW_PARTITION&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1486:116: 
Decision can match input such as &quot;KW_STORED KW_AS KW_DIRECTORIES&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_RCFILE&quot; using multiple alternatives: 3, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_ORCFILE&quot; using multiple alternatives: 4, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_TEXTFILE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_INPUTFORMAT&quot; using multiple alternatives: 5, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): SelectClauseParser.g:149:5: 
Decision can match input such as &quot;KW_NULL DOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): SelectClauseParser.g:149:5: 
Decision can match input such as &quot;KW_NULL DOT Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:127:2: 
Decision can match input such as &quot;KW_LATERAL KW_VIEW KW_OUTER&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:25: 
Decision can match input such as &quot;LPAREN StringLiteral EQUAL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:25: 
Decision can match input such as &quot;LPAREN StringLiteral COMMA&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:25: 
Decision can match input such as &quot;LPAREN StringLiteral RPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL {KW_LIKE, KW_REGEXP, KW_RLIKE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL AMPERSAND&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_IS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL RPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN StringLiteral StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL BITWISEOR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL DOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL {DIV..DIVIDE, MOD, STAR}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL NOTEQUAL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL EQUAL_NS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_EXISTS LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LESSTHAN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LESSTHANOREQUALTO&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_OR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_DATE StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL EQUAL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CAST LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL GREATERTHAN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL GREATERTHANOREQUALTO&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_BETWEEN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL {MINUS, PLUS}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LSQUARE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL BITWISEXOR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN CharSetName CharSetLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_AND&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_IN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_WHEN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:108:5: 
Decision can match input such as &quot;KW_ORDER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:121:5: 
Decision can match input such as &quot;KW_CLUSTER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:133:5: 
Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:144:5: 
Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:155:5: 
Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:172:7: 
Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_DATE StringLiteral&quot; using multiple alternatives: 2, 3

As a result, alternative(s) 3 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:524:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-exec ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1389 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-test-source (add-test-sources) @ hive-exec ---
[INFO] Test Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-test-sources/java added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-exec ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-exec ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-exec ---
[INFO] Compiling 135 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-exec ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-exec ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-exec ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-shade-plugin:2.1:shade (build-exec-bundle) @ hive-exec ---
[INFO] Excluding org.apache.hive:hive-ant:jar:0.13.0-SNAPSHOT from the shaded jar.
[INFO] Excluding org.apache.velocity:velocity:jar:1.5 from the shaded jar.
[INFO] Excluding commons-collections:commons-collections:jar:3.1 from the shaded jar.
[INFO] Including org.apache.hive:hive-common:jar:0.13.0-SNAPSHOT in the shaded jar.
[INFO] Excluding commons-cli:commons-cli:jar:1.2 from the shaded jar.
[INFO] Excluding org.apache.hive:hive-metastore:jar:0.13.0-SNAPSHOT from the shaded jar.
[INFO] Excluding com.jolbox:bonecp:jar:0.7.1.RELEASE from the shaded jar.
[INFO] Excluding org.apache.derby:derby:jar:10.4.2.0 from the shaded jar.
[INFO] Excluding org.datanucleus:datanucleus-api-jdo:jar:3.2.1 from the shaded jar.
[INFO] Excluding org.datanucleus:datanucleus-rdbms:jar:3.2.1 from the shaded jar.
[INFO] Excluding javax.jdo:jdo-api:jar:3.0.1 from the shaded jar.
[INFO] Excluding javax.transaction:jta:jar:1.1 from the shaded jar.
[INFO] Including org.apache.hive:hive-serde:jar:0.13.0-SNAPSHOT in the shaded jar.
[INFO] Including org.apache.hive:hive-shims:jar:0.13.0-SNAPSHOT in the shaded jar.
[INFO] Excluding org.apache.hive.shims:hive-shims-common:jar:0.13.0-SNAPSHOT from the shaded jar.
[INFO] Excluding org.apache.hive.shims:hive-shims-0.20:jar:0.13.0-SNAPSHOT from the shaded jar.
[INFO] Excluding org.apache.hive.shims:hive-shims-common-secure:jar:0.13.0-SNAPSHOT from the shaded jar.
[INFO] Excluding org.apache.hive.shims:hive-shims-0.20S:jar:0.13.0-SNAPSHOT from the shaded jar.
[INFO] Excluding org.apache.hive.shims:hive-shims-0.23:jar:0.13.0-SNAPSHOT from the shaded jar.
[INFO] Including com.esotericsoftware.kryo:kryo:jar:2.22 in the shaded jar.
[INFO] Excluding commons-codec:commons-codec:jar:1.4 from the shaded jar.
[INFO] Excluding commons-httpclient:commons-httpclient:jar:3.0.1 from the shaded jar.
[INFO] Excluding commons-io:commons-io:jar:2.4 from the shaded jar.
[INFO] Including commons-lang:commons-lang:jar:2.4 in the shaded jar.
[INFO] Excluding commons-logging:commons-logging:jar:1.1.3 from the shaded jar.
[INFO] Including javolution:javolution:jar:5.5.1 in the shaded jar.
[INFO] Excluding log4j:log4j:jar:1.2.16 from the shaded jar.
[INFO] Excluding org.antlr:antlr-runtime:jar:3.4 from the shaded jar.
[INFO] Excluding org.antlr:stringtemplate:jar:3.2.1 from the shaded jar.
[INFO] Excluding antlr:antlr:jar:2.7.7 from the shaded jar.
[INFO] Excluding org.antlr:ST4:jar:4.0.4 from the shaded jar.
[INFO] Excluding org.apache.avro:avro:jar:1.7.1 from the shaded jar.
[INFO] Excluding com.thoughtworks.paranamer:paranamer:jar:2.3 from the shaded jar.
[INFO] Excluding org.xerial.snappy:snappy-java:jar:1.0.4.1 from the shaded jar.
[INFO] Excluding org.apache.avro:avro-mapred:jar:1.7.1 from the shaded jar.
[INFO] Excluding org.apache.avro:avro-ipc:jar:1.7.1 from the shaded jar.
[INFO] Excluding io.netty:netty:jar:3.4.0.Final from the shaded jar.
[INFO] Excluding org.mortbay.jetty:servlet-api:jar:2.5-20081211 from the shaded jar.
[INFO] Excluding org.apache.ant:ant:jar:1.9.1 from the shaded jar.
[INFO] Excluding org.apache.ant:ant-launcher:jar:1.9.1 from the shaded jar.
[INFO] Excluding org.apache.commons:commons-compress:jar:1.4.1 from the shaded jar.
[INFO] Excluding org.tukaani:xz:jar:1.0 from the shaded jar.
[INFO] Excluding org.apache.thrift:libfb303:jar:0.9.0 from the shaded jar.
[INFO] Including org.apache.thrift:libthrift:jar:0.9.0 in the shaded jar.
[INFO] Excluding org.apache.httpcomponents:httpclient:jar:4.1.3 from the shaded jar.
[INFO] Excluding org.apache.httpcomponents:httpcore:jar:4.1.3 from the shaded jar.
[INFO] Excluding org.apache.zookeeper:zookeeper:jar:3.4.3 from the shaded jar.
[INFO] Excluding jline:jline:jar:0.9.94 from the shaded jar.
[INFO] Excluding org.jboss.netty:netty:jar:3.2.2.Final from the shaded jar.
[INFO] Excluding org.codehaus.groovy:groovy-all:jar:2.1.6 from the shaded jar.
[INFO] Including org.codehaus.jackson:jackson-core-asl:jar:1.9.2 in the shaded jar.
[INFO] Including org.codehaus.jackson:jackson-mapper-asl:jar:1.9.2 in the shaded jar.
[INFO] Excluding org.datanucleus:datanucleus-core:jar:3.2.2 from the shaded jar.
[INFO] Including com.google.guava:guava:jar:11.0.2 in the shaded jar.
[INFO] Excluding com.google.code.findbugs:jsr305:jar:1.3.9 from the shaded jar.
[INFO] Including com.google.protobuf:protobuf-java:jar:2.5.0 in the shaded jar.
[INFO] Including com.googlecode.javaewah:JavaEWAH:jar:0.3.2 in the shaded jar.
[INFO] Including org.iq80.snappy:snappy:jar:0.2 in the shaded jar.
[INFO] Including org.json:json:jar:20090211 in the shaded jar.
[INFO] Excluding stax:stax-api:jar:1.0.1 from the shaded jar.
[INFO] Excluding org.apache.hadoop:hadoop-core:jar:1.2.1 from the shaded jar.
[INFO] Excluding xmlenc:xmlenc:jar:0.52 from the shaded jar.
[INFO] Excluding com.sun.jersey:jersey-core:jar:1.8 from the shaded jar.
[INFO] Excluding com.sun.jersey:jersey-json:jar:1.8 from the shaded jar.
[INFO] Excluding org.codehaus.jettison:jettison:jar:1.1 from the shaded jar.
[INFO] Excluding com.sun.xml.bind:jaxb-impl:jar:2.2.3-1 from the shaded jar.
[INFO] Excluding javax.xml.bind:jaxb-api:jar:2.2.2 from the shaded jar.
[INFO] Excluding javax.xml.stream:stax-api:jar:1.0-2 from the shaded jar.
[INFO] Excluding javax.activation:activation:jar:1.1 from the shaded jar.
[INFO] Excluding org.codehaus.jackson:jackson-jaxrs:jar:1.7.1 from the shaded jar.
[INFO] Excluding org.codehaus.jackson:jackson-xc:jar:1.7.1 from the shaded jar.
[INFO] Excluding com.sun.jersey:jersey-server:jar:1.8 from the shaded jar.
[INFO] Excluding asm:asm:jar:3.1 from the shaded jar.
[INFO] Excluding org.apache.commons:commons-math:jar:2.1 from the shaded jar.
[INFO] Excluding commons-configuration:commons-configuration:jar:1.6 from the shaded jar.
[INFO] Excluding commons-digester:commons-digester:jar:1.8 from the shaded jar.
[INFO] Excluding commons-beanutils:commons-beanutils:jar:1.7.0 from the shaded jar.
[INFO] Excluding commons-beanutils:commons-beanutils-core:jar:1.8.0 from the shaded jar.
[INFO] Excluding commons-net:commons-net:jar:1.4.1 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jetty:jar:6.1.26 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jetty-util:jar:6.1.26 from the shaded jar.
[INFO] Excluding tomcat:jasper-runtime:jar:5.5.12 from the shaded jar.
[INFO] Excluding tomcat:jasper-compiler:jar:5.5.12 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jsp-api-2.1:jar:6.1.14 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:servlet-api-2.5:jar:6.1.14 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jsp-2.1:jar:6.1.14 from the shaded jar.
[INFO] Excluding ant:ant:jar:1.6.5 from the shaded jar.
[INFO] Excluding commons-el:commons-el:jar:1.0 from the shaded jar.
[INFO] Excluding net.java.dev.jets3t:jets3t:jar:0.6.1 from the shaded jar.
[INFO] Excluding hsqldb:hsqldb:jar:1.8.0.10 from the shaded jar.
[INFO] Excluding oro:oro:jar:2.0.8 from the shaded jar.
[INFO] Excluding org.eclipse.jdt:core:jar:3.1.1 from the shaded jar.
[INFO] Excluding org.slf4j:slf4j-api:jar:1.6.1 from the shaded jar.
[INFO] Excluding org.slf4j:slf4j-log4j12:jar:1.6.1 from the shaded jar.
[INFO] Replacing original artifact with shaded artifact.
[INFO] Replacing /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT.jar with /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT-shaded.jar
[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-svn-trunk-source/ql/dependency-reduced-pom.xml
[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-svn-trunk-source/ql/dependency-reduced-pom.xml
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-exec ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-exec/0.13.0-SNAPSHOT/hive-exec-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ql/dependency-reduced-pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-exec/0.13.0-SNAPSHOT/hive-exec-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-exec/0.13.0-SNAPSHOT/hive-exec-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Service 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-service ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/service (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-service ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/service/src/model added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/service/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-service ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/service/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-service ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-service ---
[INFO] Compiling 153 source files to /data/hive-ptest/working/apache-svn-trunk-source/service/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-service ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-service ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-service ---
[INFO] Compiling 7 source files to /data/hive-ptest/working/apache-svn-trunk-source/service/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-service ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-service ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-service ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-service ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-service/0.13.0-SNAPSHOT/hive-service-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/service/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-service/0.13.0-SNAPSHOT/hive-service-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-service/0.13.0-SNAPSHOT/hive-service-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive JDBC 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-jdbc ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/jdbc (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-jdbc ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-jdbc ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-jdbc ---
[INFO] Compiling 30 source files to /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-jdbc ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-jdbc ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-jdbc ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-jdbc ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-jdbc ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/hive-jdbc-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-jdbc ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/hive-jdbc-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-jdbc/0.13.0-SNAPSHOT/hive-jdbc-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/jdbc/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-jdbc/0.13.0-SNAPSHOT/hive-jdbc-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Beeline 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-beeline ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/beeline (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-beeline ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-beeline ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-beeline ---
[INFO] Compiling 31 source files to /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/classes
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:[28,16] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:[29,16] warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:[31,64] warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:[44,23] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:[37,24] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:[37,5] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-beeline ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-beeline ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-beeline ---
[INFO] Compiling 1 source file to /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-beeline ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-beeline ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/hive-beeline-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-beeline ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/hive-beeline-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-beeline/0.13.0-SNAPSHOT/hive-beeline-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/beeline/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-beeline/0.13.0-SNAPSHOT/hive-beeline-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive CLI 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-cli ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/cli (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-cli ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/cli/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-cli ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-cli ---
[INFO] Compiling 4 source files to /data/hive-ptest/working/apache-svn-trunk-source/cli/target/classes
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[74,16] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[75,16] warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[371,5] warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[372,5] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[377,27] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[378,52] warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[378,52] warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[383,28] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[378,19] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[439,9] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/RCFileCat.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-cli ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-cli ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/cli/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-cli ---
[INFO] Compiling 4 source files to /data/hive-ptest/working/apache-svn-trunk-source/cli/target/test-classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/org/apache/hadoop/hive/cli/TestCliDriverMethods.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-cli ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-cli ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/hive-cli-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-cli ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/cli/target/hive-cli-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-cli/0.13.0-SNAPSHOT/hive-cli-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/cli/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-cli/0.13.0-SNAPSHOT/hive-cli-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Contrib 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-contrib ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/contrib (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-contrib ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-contrib ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-contrib ---
[INFO] Compiling 39 source files to /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/java/org/apache/hadoop/hive/contrib/udf/example/UDFExampleStructPrint.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-contrib ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-contrib ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-contrib ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/test-classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/org/apache/hadoop/hive/contrib/serde2/TestRegexSerDe.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-contrib ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-contrib ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/hive-contrib-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-contrib ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/hive-contrib-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-contrib/0.13.0-SNAPSHOT/hive-contrib-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/contrib/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-contrib/0.13.0-SNAPSHOT/hive-contrib-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HBase Handler 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hbase-handler ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hbase-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hbase-handler ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hbase-handler ---
[INFO] Compiling 17 source files to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hbase-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hbase-handler ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hbase-handler ---
[INFO] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hbase-handler ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hbase-handler ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/hive-hbase-handler-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hbase-handler ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/hive-hbase-handler-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hbase-handler/0.13.0-SNAPSHOT/hive-hbase-handler-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-hbase-handler/0.13.0-SNAPSHOT/hive-hbase-handler-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hcatalog ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hcatalog ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog/0.13.0-SNAPSHOT/hive-hcatalog-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Core 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hcatalog-core ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hcatalog-core ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-core ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-core ---
[INFO] Compiling 144 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hcatalog-core ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog-core ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hcatalog-core ---
[INFO] Compiling 67 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hcatalog-core ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hcatalog-core ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/hive-hcatalog-core-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-hcatalog-core ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/hive-hcatalog-core-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hcatalog-core ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/hive-hcatalog-core-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog-core/0.13.0-SNAPSHOT/hive-hcatalog-core-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog-core/0.13.0-SNAPSHOT/hive-hcatalog-core-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/hive-hcatalog-core-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog-core/0.13.0-SNAPSHOT/hive-hcatalog-core-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Pig Adapter 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hcatalog-pig-adapter ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hcatalog-pig-adapter ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-pig-adapter ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-pig-adapter ---
[INFO] Compiling 10 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hcatalog-pig-adapter ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog-pig-adapter ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hcatalog-pig-adapter ---
[INFO] Compiling 26 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hcatalog-pig-adapter ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hcatalog-pig-adapter ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/hive-hcatalog-pig-adapter-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hcatalog-pig-adapter ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/hive-hcatalog-pig-adapter-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog-pig-adapter/0.13.0-SNAPSHOT/hive-hcatalog-pig-adapter-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog-pig-adapter/0.13.0-SNAPSHOT/hive-hcatalog-pig-adapter-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Server Extensions 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hcatalog-server-extensions ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hcatalog-server-extensions ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-server-extensions ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-server-extensions ---
[INFO] Compiling 38 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hcatalog-server-extensions ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog-server-extensions ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hcatalog-server-extensions ---
[INFO] Compiling 4 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hcatalog-server-extensions ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hcatalog-server-extensions ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/hive-hcatalog-server-extensions-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hcatalog-server-extensions ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/hive-hcatalog-server-extensions-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog-server-extensions/0.13.0-SNAPSHOT/hive-hcatalog-server-extensions-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog-server-extensions/0.13.0-SNAPSHOT/hive-hcatalog-server-extensions-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Webhcat Java Client 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-webhcat-java-client ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-webhcat-java-client ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-webhcat-java-client ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-webhcat-java-client ---
[INFO] Compiling 20 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-webhcat-java-client ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-webhcat-java-client ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-webhcat-java-client ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-webhcat-java-client ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-webhcat-java-client ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/hive-webhcat-java-client-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-webhcat-java-client ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/hive-webhcat-java-client-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-webhcat-java-client/0.13.0-SNAPSHOT/hive-webhcat-java-client-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-webhcat-java-client/0.13.0-SNAPSHOT/hive-webhcat-java-client-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Webhcat 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-webhcat ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-webhcat ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-webhcat ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-webhcat ---
[INFO] Compiling 65 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-javadoc-plugin:2.4:javadoc (resourcesdoc.xml) @ hive-webhcat ---
[INFO] Setting property: classpath.resource.loader.class =&amp;gt; &apos;org.codehaus.plexus.velocity.ContextClassLoaderResourceLoader&apos;.
[INFO] Setting property: velocimacro.messages.on =&amp;gt; &apos;false&apos;.
[INFO] Setting property: resource.loader =&amp;gt; &apos;classpath&apos;.
[INFO] Setting property: resource.manager.logwhenfound =&amp;gt; &apos;false&apos;.
[INFO] ************************************************************** 
[INFO] Starting Jakarta Velocity v1.4
[INFO] RuntimeInstance initializing.
[INFO] Default Properties File: org/apache/velocity/runtime/defaults/velocity.properties
[INFO] Default ResourceManager initializing. (class org.apache.velocity.runtime.resource.ResourceManagerImpl)
[INFO] Resource Loader Instantiated: org.codehaus.plexus.velocity.ContextClassLoaderResourceLoader
[INFO] ClasspathResourceLoader : initialization starting.
[INFO] ClasspathResourceLoader : initialization complete.
[INFO] ResourceCache : initialized. (class org.apache.velocity.runtime.resource.ResourceCacheImpl)
[INFO] Default ResourceManager initialization complete.
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Literal
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Macro
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Parse
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Include
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Foreach
[INFO] Created: 20 parsers.
[INFO] Velocimacro : initialization starting.
[INFO] Velocimacro : adding VMs from VM library template : VM_global_library.vm
[ERROR] ResourceManager : unable to find resource &apos;VM_global_library.vm&apos; in any resource loader.
[INFO] Velocimacro : error using  VM library template VM_global_library.vm : org.apache.velocity.exception.ResourceNotFoundException: Unable to find resource &apos;VM_global_library.vm&apos;
[INFO] Velocimacro :  VM library template macro registration complete.
[INFO] Velocimacro : allowInline = true : VMs can be defined inline in templates
[INFO] Velocimacro : allowInlineToOverride = false : VMs defined inline may NOT replace previous VM definitions
[INFO] Velocimacro : allowInlineLocal = false : VMs defined inline will be  global in scope if allowed.
[INFO] Velocimacro : initialization complete.
[INFO] Velocity successfully started.
Loading source files for package org.apache.hive.hcatalog.templeton...
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/SimpleExceptionMapper.java]
[parsing completed 31ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JsonBuilder.java]
[parsing completed 8ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JobItemBean.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JarDelegator.java]
[parsing completed 11ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/LauncherDelegator.java]
[parsing completed 20ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ExecServiceImpl.java]
[parsing completed 22ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/DeleteDelegator.java]
[parsing completed 7ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ExecBean.java]
[parsing completed 6ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/PigDelegator.java]
[parsing completed 13ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/TempletonDelegator.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/StreamingDelegator.java]
[parsing completed 12ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/DatabaseDesc.java]
[parsing completed 5ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CompleteBean.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HiveDelegator.java]
[parsing completed 17ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/Server.java]
[parsing completed 128ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/BadParam.java]
[parsing completed 4ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ColumnDesc.java]
[parsing completed 2ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/PartitionDesc.java]
[parsing completed 4ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CatchallExceptionMapper.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HcatDelegator.java]
[parsing completed 49ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/StatusDelegator.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/QueueStatusBean.java]
[parsing completed 2ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CompleteDelegator.java]
[parsing completed 6ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/GroupPermissionsDesc.java]
[parsing completed 4ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/AppConfig.java]
[parsing completed 5ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HcatException.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/QueueException.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/TableLikeDesc.java]
[parsing completed 4ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/TableDesc.java]
[parsing completed 7ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/WadlConfig.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/BusyException.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ExecService.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/NotAuthorizedException.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/EnqueueBean.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/SimpleWebException.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ListDelegator.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/Main.java]
[parsing completed 12ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/SecureProxySupport.java]
[parsing completed 11ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/MaxByteArrayOutputStream.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ProxyUserSupport.java]
[parsing completed 5ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/UgiFactory.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CallbackFailedException.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/TablePropertyDesc.java]
[parsing completed 1ms]
Loading source files for package org.apache.hive.hcatalog.templeton.tool...
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/ZooKeeperStorage.java]
[parsing completed 13ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/NullRecordReader.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/PigJobIDParser.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonStorage.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JobIDParser.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JobState.java]
[parsing completed 10ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonUtils.java]
[parsing completed 12ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/HDFSStorage.java]
[parsing completed 16ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/DelegationTokenCache.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JarJobIDParser.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JobSubmissionConstants.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/ZooKeeperCleanup.java]
[parsing completed 2ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JobStateTracker.java]
[parsing completed 3ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/NotFoundException.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/SingleInputFormat.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/LogRetriever.java]
[parsing completed 7ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/NullSplit.java]
[parsing completed 2ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/HDFSCleanup.java]
[parsing completed 7ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java]
[parsing completed 5ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/HiveJobIDParser.java]
[parsing completed 4ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/LaunchMapper.java]
[parsing completed 12ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java]
[parsing completed 1ms]
Constructing Javadoc information...
[search path for source files: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java]
[search path for class files: /usr/java/jdk1.6.0_34/jre/lib/resources.jar,/usr/java/jdk1.6.0_34/jre/lib/rt.jar,/usr/java/jdk1.6.0_34/jre/lib/sunrsasign.jar,/usr/java/jdk1.6.0_34/jre/lib/jsse.jar,/usr/java/jdk1.6.0_34/jre/lib/jce.jar,/usr/java/jdk1.6.0_34/jre/lib/charsets.jar,/usr/java/jdk1.6.0_34/jre/lib/modules/jdk.boot.jar,/usr/java/jdk1.6.0_34/jre/classes,/usr/java/jdk1.6.0_34/jre/lib/ext/localedata.jar,/usr/java/jdk1.6.0_34/jre/lib/ext/sunpkcs11.jar,/usr/java/jdk1.6.0_34/jre/lib/ext/sunjce_provider.jar,/usr/java/jdk1.6.0_34/jre/lib/ext/dnsns.jar,/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes,/data/hive-ptest/working/maven/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar,/data/hive-ptest/working/maven/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar,/data/hive-ptest/working/maven/com/sun/jersey/jersey-json/1.14/jersey-json-1.14.jar,/data/hive-ptest/working/maven/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar,/data/hive-ptest/working/maven/javax/mail/mail/1.4.1/mail-1.4.1.jar,/data/hive-ptest/working/maven/javax/mail/mail/1.4.1/activation.jar,/data/hive-ptest/working/maven/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar,/data/hive-ptest/working/maven/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar,/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/hive-hcatalog-core-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/org/codehaus/jackson/jackson-core-asl/1.9.2/jackson-core-asl-1.9.2.jar,/data/hive-ptest/working/maven/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar,/data/hive-ptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar,/data/hive-ptest/working/maven/xerces/xercesImpl/2.6.1/xercesImpl-2.6.1.jar,/data/hive-ptest/working/maven/antlr/antlr/2.7.7/antlr-2.7.7.jar,/data/hive-ptest/working/maven/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.jar,/data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar,/data/hive-ptest/working/maven/com/sun/jdmk/jmxtools/1.2.1/jmxtools-1.2.1.jar,/data/hive-ptest/working/maven/org/apache/velocity/velocity/1.5/velocity-1.5.jar,/data/hive-ptest/working/maven/com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar,/data/hive-ptest/working/maven/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar,/data/hive-ptest/working/maven/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar,/data/hive-ptest/working/maven/javax/jms/jms/1.1/jms-1.1.jar,/data/hive-ptest/working/maven/commons-lang/commons-lang/2.4/commons-lang-2.4.jar,/data/hive-ptest/working/maven/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar,/data/hive-ptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar,/data/hive-ptest/working/maven/org/apache/commons/commons-math/2.1/commons-math-2.1.jar,/data/hive-ptest/working/maven/org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.jar,/data/hive-ptest/working/maven/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar,/data/hive-ptest/working/maven/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar,/data/hive-ptest/working/maven/org/antlr/ST4/4.0.4/ST4-4.0.4.jar,/data/hive-ptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar,/data/hive-ptest/working/maven/com/google/guava/guava/11.0.2/guava-11.0.2.jar,/data/hive-ptest/working/maven/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar,/data/hive-ptest/working/maven/org/apache/hadoop/hadoop-core/1.2.1/hadoop-core-1.2.1.jar,/data/hive-ptest/working/maven/org/tukaani/xz/1.0/xz-1.0.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar,/data/hive-ptest/working/maven/javax/activation/activation/1.1/activation-1.1.jar,/data/hive-ptest/working/maven/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar,/data/hive-ptest/working/maven/stax/stax-api/1.0.1/stax-api-1.0.1.jar,/data/hive-ptest/working/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar,/data/hive-ptest/working/maven/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar,/data/hive-ptest/working/maven/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar,/data/hive-ptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar,/usr/java/jdk1.6.0_34/jre/../lib/tools.jar,/data/hive-ptest/working/maven/org/apache/ant/ant/1.9.1/ant-1.9.1.jar,/data/hive-ptest/working/maven/io/netty/netty/3.4.0.Final/netty-3.4.0.Final.jar,/data/hive-ptest/working/maven/org/slf4j/jul-to-slf4j/1.6.1/jul-to-slf4j-1.6.1.jar,/data/hive-ptest/working/maven/com/sun/jersey/contribs/wadl-resourcedoc-doclet/1.4/wadl-resourcedoc-doclet-1.4.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar,/data/hive-ptest/working/maven/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar,/data/hive-ptest/working/maven/oro/oro/2.0.8/oro-2.0.8.jar,/data/hive-ptest/working/maven/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar,/data/hive-ptest/working/maven/javax/transaction/jta/1.1/jta-1.1.jar,/data/hive-ptest/working/maven/log4j/log4j/1.2.15/log4j-1.2.15.jar,/data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/org/apache/geronimo/specs/geronimo-annotation_1.0_spec/1.1.1/geronimo-annotation_1.0_spec-1.1.1.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar,/data/hive-ptest/working/maven/org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.jar,/data/hive-ptest/working/maven/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar,/data/hive-ptest/working/maven/com/sun/jersey/jersey-servlet/1.14/jersey-servlet-1.14.jar,/data/hive-ptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar,/data/hive-ptest/working/maven/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar,/data/hive-ptest/working/maven/xmlenc/xmlenc/0.52/xmlenc-0.52.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar,/data/hive-ptest/working/maven/commons-el/commons-el/1.0/commons-el-1.0.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/jline/jline/0.9.94/jline-0.9.94.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar,/data/hive-ptest/working/maven/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar,/data/hive-ptest/working/maven/org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.jar,/data/hive-ptest/working/maven/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar,/data/hive-ptest/working/maven/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar,/data/hive-ptest/working/maven/ant/ant/1.6.5/ant-1.6.5.jar,/data/hive-ptest/working/apache-svn-trunk-source/cli/target/hive-cli-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar,/data/hive-ptest/working/maven/org/codehaus/groovy/groovy-all/2.1.6/groovy-all-2.1.6.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_cs.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_de_DE.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_es.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_fr.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_hu.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_it.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_ja_JP.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_ko_KR.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_pl.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_pt_BR.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_ru.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_zh_CN.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_zh_TW.jar,/data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/asm/asm-commons/3.1/asm-commons-3.1.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-api.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/activation.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jsr173_1.0_api.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb1-impl.jar,/data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar,/data/hive-ptest/working/maven/org/apache/hadoop/hadoop-tools/1.2.1/hadoop-tools-1.2.1.jar,/data/hive-ptest/working/maven/asm/asm-tree/3.1/asm-tree-3.1.jar,/data/hive-ptest/working/maven/com/thoughtworks/paranamer/paranamer/2.2/paranamer-2.2.jar,/data/hive-ptest/working/maven/commons-io/commons-io/2.1/commons-io-2.1.jar,/data/hive-ptest/working/maven/org/codehaus/jackson/jackson-mapper-asl/1.9.2/jackson-mapper-asl-1.9.2.jar,/data/hive-ptest/working/maven/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar,/data/hive-ptest/working/maven/org/apache/avro/avro/1.7.1/avro-1.7.1.jar,/data/hive-ptest/working/maven/commons-digester/commons-digester/1.8/commons-digester-1.8.jar,/data/hive-ptest/working/maven/org/apache/geronimo/specs/geronimo-jaspic_1.0_spec/1.0/geronimo-jaspic_1.0_spec-1.0.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar,/data/hive-ptest/working/maven/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/org/apache/geronimo/specs/geronimo-jta_1.1_spec/1.1.1/geronimo-jta_1.1_spec-1.1.1.jar,/data/hive-ptest/working/maven/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar,/data/hive-ptest/working/maven/com/sun/jmx/jmxri/1.2.1/jmxri-1.2.1.jar,/data/hive-ptest/working/maven/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar,/data/hive-ptest/working/apache-svn-trunk-source/ant/target/hive-ant-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/asm/asm/3.1/asm-3.1.jar,/data/hive-ptest/working/maven/commons-codec/commons-codec/1.4/commons-codec-1.4.jar]
[loading javax/ws/rs/core/Response.class(javax/ws/rs/core:Response.class)]
[loading javax/ws/rs/ext/ExceptionMapper.class(javax/ws/rs/ext:ExceptionMapper.class)]
[loading javax/ws/rs/ext/Provider.class(javax/ws/rs/ext:Provider.class)]
[loading java/io/IOException.class(java/io:IOException.class)]
[loading java/util/Map.class(java/util:Map.class)]
[loading java/util/HashMap.class(java/util:HashMap.class)]
[loading javax/ws/rs/core/MediaType.class(javax/ws/rs/core:MediaType.class)]
[loading org/codehaus/jackson/map/ObjectMapper.class(org/codehaus/jackson/map:ObjectMapper.class)]
[loading java/lang/Throwable.class(java/lang:Throwable.class)]
[loading java/io/Serializable.class(java/io:Serializable.class)]
[loading java/lang/Object.class(java/lang:Object.class)]
[loading java/lang/String.class(java/lang:String.class)]
[loading java/io/ByteArrayOutputStream.class(java/io:ByteArrayOutputStream.class)]
[loading org/apache/hadoop/hive/ql/ErrorMsg.class(org/apache/hadoop/hive/ql:ErrorMsg.class)]
[loading org/eclipse/jetty/http/HttpStatus.class(org/eclipse/jetty/http:HttpStatus.class)]
[loading java/lang/Integer.class(java/lang:Integer.class)]
[loading org/apache/hadoop/mapred/JobStatus.class(org/apache/hadoop/mapred:JobStatus.class)]
[loading org/apache/hadoop/mapred/JobProfile.class(org/apache/hadoop/mapred:JobProfile.class)]
[loading java/lang/Long.class(java/lang:Long.class)]
[loading java/util/ArrayList.class(java/util:ArrayList.class)]
[loading java/util/List.class(java/util:List.class)]
[loading org/apache/commons/logging/Log.class(org/apache/commons/logging:Log.class)]
[loading org/apache/commons/logging/LogFactory.class(org/apache/commons/logging:LogFactory.class)]
[loading org/apache/hadoop/conf/Configuration.class(org/apache/hadoop/conf:Configuration.class)]
[loading java/lang/Enum.class(java/lang:Enum.class)]
[loading java/lang/Comparable.class(java/lang:Comparable.class)]
[loading java/lang/Exception.class(java/lang:Exception.class)]
[loading java/io/FileNotFoundException.class(java/io:FileNotFoundException.class)]
[loading java/net/URISyntaxException.class(java/net:URISyntaxException.class)]
[loading org/apache/commons/exec/ExecuteException.class(org/apache/commons/exec:ExecuteException.class)]
[loading java/security/PrivilegedExceptionAction.class(java/security:PrivilegedExceptionAction.class)]
[loading org/apache/hadoop/fs/Path.class(org/apache/hadoop/fs:Path.class)]
[loading org/apache/hadoop/hive/conf/HiveConf.class(org/apache/hadoop/hive/conf:HiveConf.class)]
[loading org/apache/hadoop/security/UserGroupInformation.class(org/apache/hadoop/security:UserGroupInformation.class)]
[loading org/apache/hadoop/util/StringUtils.class(org/apache/hadoop/util:StringUtils.class)]
[loading org/apache/hadoop/util/ToolRunner.class(org/apache/hadoop/util:ToolRunner.class)]
[loading java/io/File.class(java/io:File.class)]
[loading java/net/URL.class(java/net:URL.class)]
[loading org/apache/hadoop/util/VersionInfo.class(org/apache/hadoop/util:VersionInfo.class)]
[loading java/lang/Iterable.class(java/lang:Iterable.class)]
[loading org/apache/hadoop/io/Writable.class(org/apache/hadoop/io:Writable.class)]
[loading java/lang/InterruptedException.class(java/lang:InterruptedException.class)]
[loading java/io/BufferedReader.class(java/io:BufferedReader.class)]
[loading java/io/InputStream.class(java/io:InputStream.class)]
[loading java/io/InputStreamReader.class(java/io:InputStreamReader.class)]
[loading java/io/OutputStream.class(java/io:OutputStream.class)]
[loading java/io/PrintWriter.class(java/io:PrintWriter.class)]
[loading java/util/Map$Entry.class(java/util:Map$Entry.class)]
[loading java/util/concurrent/Semaphore.class(java/util/concurrent:Semaphore.class)]
[loading org/apache/commons/exec/CommandLine.class(org/apache/commons/exec:CommandLine.class)]
[loading org/apache/commons/exec/DefaultExecutor.class(org/apache/commons/exec:DefaultExecutor.class)]
[loading org/apache/commons/exec/ExecuteWatchdog.class(org/apache/commons/exec:ExecuteWatchdog.class)]
[loading org/apache/commons/exec/PumpStreamHandler.class(org/apache/commons/exec:PumpStreamHandler.class)]
[loading org/apache/hadoop/util/Shell.class(org/apache/hadoop/util:Shell.class)]
[loading java/lang/Thread.class(java/lang:Thread.class)]
[loading java/lang/Runnable.class(java/lang:Runnable.class)]
[loading org/apache/hadoop/hive/shims/HadoopShims.class(org/apache/hadoop/hive/shims:HadoopShims.class)]
[loading org/apache/hadoop/hive/shims/HadoopShims$WebHCatJTShim.class(org/apache/hadoop/hive/shims:HadoopShims$WebHCatJTShim.class)]
[loading org/apache/hadoop/hive/shims/ShimLoader.class(org/apache/hadoop/hive/shims:ShimLoader.class)]
[loading org/apache/hadoop/mapred/JobID.class(org/apache/hadoop/mapred:JobID.class)]
[loading java/util/Arrays.class(java/util:Arrays.class)]
[loading javax/xml/bind/annotation/XmlRootElement.class(javax/xml/bind/annotation:XmlRootElement.class)]
[loading java/net/InetAddress.class(java/net:InetAddress.class)]
[loading java/net/UnknownHostException.class(java/net:UnknownHostException.class)]
[loading java/text/MessageFormat.class(java/text:MessageFormat.class)]
[loading java/util/Collections.class(java/util:Collections.class)]
[loading java/util/regex/Matcher.class(java/util/regex:Matcher.class)]
[loading java/util/regex/Pattern.class(java/util/regex:Pattern.class)]
[loading javax/servlet/http/HttpServletRequest.class(javax/servlet/http:HttpServletRequest.class)]
[loading javax/ws/rs/DELETE.class(javax/ws/rs:DELETE.class)]
[loading javax/ws/rs/FormParam.class(javax/ws/rs:FormParam.class)]
[loading javax/ws/rs/GET.class(javax/ws/rs:GET.class)]
[loading javax/ws/rs/POST.class(javax/ws/rs:POST.class)]
[loading javax/ws/rs/PUT.class(javax/ws/rs:PUT.class)]
[loading javax/ws/rs/Path.class(javax/ws/rs:Path.class)]
[loading javax/ws/rs/PathParam.class(javax/ws/rs:PathParam.class)]
[loading javax/ws/rs/Produces.class(javax/ws/rs:Produces.class)]
[loading javax/ws/rs/QueryParam.class(javax/ws/rs:QueryParam.class)]
[loading javax/ws/rs/core/Context.class(javax/ws/rs/core:Context.class)]
[loading javax/ws/rs/core/SecurityContext.class(javax/ws/rs/core:SecurityContext.class)]
[loading javax/ws/rs/core/UriInfo.class(javax/ws/rs/core:UriInfo.class)]
[loading org/apache/hadoop/security/authentication/client/PseudoAuthenticator.class(org/apache/hadoop/security/authentication/client:PseudoAuthenticator.class)]
[loading com/sun/jersey/api/NotFoundException.class(com/sun/jersey/api:NotFoundException.class)]
[loading java/net/URI.class(java/net:URI.class)]
[loading org/apache/commons/lang/StringUtils.class(org/apache/commons/lang:StringUtils.class)]
[loading org/apache/hadoop/fs/FileStatus.class(org/apache/hadoop/fs:FileStatus.class)]
[loading org/apache/hadoop/fs/FileSystem.class(org/apache/hadoop/fs:FileSystem.class)]
[loading java/util/Date.class(java/util:Date.class)]
[loading org/apache/hadoop/hive/common/classification/InterfaceAudience.class(org/apache/hadoop/hive/common/classification:InterfaceAudience.class)]
[loading org/apache/hadoop/hive/metastore/HiveMetaStoreClient.class(org/apache/hadoop/hive/metastore:HiveMetaStoreClient.class)]
[loading org/apache/hive/hcatalog/common/HCatUtil.class(org/apache/hive/hcatalog/common:HCatUtil.class)]
[loading org/apache/hadoop/hive/common/classification/InterfaceAudience$Private.class(org/apache/hadoop/hive/common/classification:InterfaceAudience$Private.class)]
[loading com/sun/jersey/api/wadl/config/WadlGeneratorConfig.class(com/sun/jersey/api/wadl/config:WadlGeneratorConfig.class)]
[loading com/sun/jersey/api/wadl/config/WadlGeneratorDescription.class(com/sun/jersey/api/wadl/config:WadlGeneratorDescription.class)]
[loading com/sun/jersey/server/wadl/generators/resourcedoc/WadlGeneratorResourceDocSupport.class(com/sun/jersey/server/wadl/generators/resourcedoc:WadlGeneratorResourceDocSupport.class)]
[loading com/sun/jersey/api/core/PackagesResourceConfig.class(com/sun/jersey/api/core:PackagesResourceConfig.class)]
[loading com/sun/jersey/spi/container/servlet/ServletContainer.class(com/sun/jersey/spi/container/servlet:ServletContainer.class)]
[loading org/apache/hadoop/hive/common/classification/InterfaceStability.class(org/apache/hadoop/hive/common/classification:InterfaceStability.class)]
[loading org/apache/hadoop/hdfs/web/AuthFilter.class(org/apache/hadoop/hdfs/web:AuthFilter.class)]
[loading org/apache/hadoop/util/GenericOptionsParser.class(org/apache/hadoop/util:GenericOptionsParser.class)]
[loading org/eclipse/jetty/rewrite/handler/RedirectPatternRule.class(org/eclipse/jetty/rewrite/handler:RedirectPatternRule.class)]
[loading org/eclipse/jetty/rewrite/handler/RewriteHandler.class(org/eclipse/jetty/rewrite/handler:RewriteHandler.class)]
[loading org/eclipse/jetty/server/Handler.class(org/eclipse/jetty/server:Handler.class)]
[loading org/eclipse/jetty/server/Server.class(org/eclipse/jetty/server:Server.class)]
[loading org/eclipse/jetty/server/handler/HandlerList.class(org/eclipse/jetty/server/handler:HandlerList.class)]
[loading org/eclipse/jetty/servlet/FilterHolder.class(org/eclipse/jetty/servlet:FilterHolder.class)]
[loading org/eclipse/jetty/servlet/FilterMapping.class(org/eclipse/jetty/servlet:FilterMapping.class)]
[loading org/eclipse/jetty/servlet/ServletContextHandler.class(org/eclipse/jetty/servlet:ServletContextHandler.class)]
[loading org/eclipse/jetty/servlet/ServletHolder.class(org/eclipse/jetty/servlet:ServletHolder.class)]
[loading org/slf4j/bridge/SLF4JBridgeHandler.class(org/slf4j/bridge:SLF4JBridgeHandler.class)]
[loading org/apache/hadoop/hive/common/classification/InterfaceAudience$LimitedPrivate.class(org/apache/hadoop/hive/common/classification:InterfaceAudience$LimitedPrivate.class)]
[loading org/apache/hadoop/hive/common/classification/InterfaceStability$Unstable.class(org/apache/hadoop/hive/common/classification:InterfaceStability$Unstable.class)]
[loading org/apache/hadoop/hive/metastore/api/MetaException.class(org/apache/hadoop/hive/metastore/api:MetaException.class)]
[loading org/apache/hadoop/io/Text.class(org/apache/hadoop/io:Text.class)]
[loading org/apache/hadoop/security/Credentials.class(org/apache/hadoop/security:Credentials.class)]
[loading org/apache/hadoop/security/token/Token.class(org/apache/hadoop/security/token:Token.class)]
[loading org/apache/thrift/TException.class(org/apache/thrift:TException.class)]
[loading java/io/Closeable.class(java/io:Closeable.class)]
[loading java/io/Flushable.class(java/io:Flushable.class)]
[loading org/apache/hadoop/security/Groups.class(org/apache/hadoop/security:Groups.class)]
[loading java/util/HashSet.class(java/util:HashSet.class)]
[loading java/util/Set.class(java/util:Set.class)]
[loading java/util/concurrent/ConcurrentHashMap.class(java/util/concurrent:ConcurrentHashMap.class)]
[loading java/io/UnsupportedEncodingException.class(java/io:UnsupportedEncodingException.class)]
[loading org/apache/zookeeper/CreateMode.class(org/apache/zookeeper:CreateMode.class)]
[loading org/apache/zookeeper/KeeperException.class(org/apache/zookeeper:KeeperException.class)]
[loading org/apache/zookeeper/WatchedEvent.class(org/apache/zookeeper:WatchedEvent.class)]
[loading org/apache/zookeeper/Watcher.class(org/apache/zookeeper:Watcher.class)]
[loading org/apache/zookeeper/ZooDefs.class(org/apache/zookeeper:ZooDefs.class)]
[loading org/apache/zookeeper/ZooDefs$Ids.class(org/apache/zookeeper:ZooDefs$Ids.class)]
[loading org/apache/zookeeper/ZooKeeper.class(org/apache/zookeeper:ZooKeeper.class)]
[loading org/apache/hadoop/io/NullWritable.class(org/apache/hadoop/io:NullWritable.class)]
[loading org/apache/hadoop/mapreduce/InputSplit.class(org/apache/hadoop/mapreduce:InputSplit.class)]
[loading org/apache/hadoop/mapreduce/RecordReader.class(org/apache/hadoop/mapreduce:RecordReader.class)]
[loading org/apache/hadoop/mapreduce/TaskAttemptContext.class(org/apache/hadoop/mapreduce:TaskAttemptContext.class)]
[loading java/net/URLConnection.class(java/net:URLConnection.class)]
[loading java/util/Collection.class(java/util:Collection.class)]
[loading javax/ws/rs/core/UriBuilder.class(javax/ws/rs/core:UriBuilder.class)]
[loading java/io/OutputStreamWriter.class(java/io:OutputStreamWriter.class)]
[loading org/apache/hadoop/hive/common/classification/InterfaceStability$Evolving.class(org/apache/hadoop/hive/common/classification:InterfaceStability$Evolving.class)]
[loading org/apache/zookeeper/data/Stat.class(org/apache/zookeeper/data:Stat.class)]
[loading org/apache/hadoop/mapreduce/InputFormat.class(org/apache/hadoop/mapreduce:InputFormat.class)]
[loading org/apache/hadoop/mapreduce/JobContext.class(org/apache/hadoop/mapreduce:JobContext.class)]
[loading org/apache/hadoop/mapred/JobClient.class(org/apache/hadoop/mapred:JobClient.class)]
[loading org/apache/hadoop/mapred/JobConf.class(org/apache/hadoop/mapred:JobConf.class)]
[loading org/apache/hadoop/mapred/RunningJob.class(org/apache/hadoop/mapred:RunningJob.class)]
[loading java/io/DataInput.class(java/io:DataInput.class)]
[loading java/io/DataOutput.class(java/io:DataOutput.class)]
[loading org/apache/hadoop/conf/Configured.class(org/apache/hadoop/conf:Configured.class)]
[loading org/apache/hadoop/fs/permission/FsPermission.class(org/apache/hadoop/fs/permission:FsPermission.class)]
[loading org/apache/hadoop/mapreduce/Job.class(org/apache/hadoop/mapreduce:Job.class)]
[loading org/apache/hadoop/mapreduce/JobID.class(org/apache/hadoop/mapreduce:JobID.class)]
[loading org/apache/hadoop/mapreduce/lib/output/NullOutputFormat.class(org/apache/hadoop/mapreduce/lib/output:NullOutputFormat.class)]
[loading org/apache/hadoop/mapreduce/security/token/delegation/DelegationTokenIdentifier.class(org/apache/hadoop/mapreduce/security/token/delegation:DelegationTokenIdentifier.class)]
[loading org/apache/hadoop/util/Tool.class(org/apache/hadoop/util:Tool.class)]
[loading org/apache/hadoop/conf/Configurable.class(org/apache/hadoop/conf:Configurable.class)]
[loading java/lang/ClassNotFoundException.class(java/lang:ClassNotFoundException.class)]
[loading org/apache/hadoop/mapreduce/Mapper.class(org/apache/hadoop/mapreduce:Mapper.class)]
[loading java/util/Iterator.class(java/util:Iterator.class)]
[loading java/util/LinkedList.class(java/util:LinkedList.class)]
[loading java/util/concurrent/ExecutorService.class(java/util/concurrent:ExecutorService.class)]
[loading java/util/concurrent/Executors.class(java/util/concurrent:Executors.class)]
[loading java/util/concurrent/TimeUnit.class(java/util/concurrent:TimeUnit.class)]
[loading org/apache/hadoop/mapreduce/Mapper$Context.class(org/apache/hadoop/mapreduce:Mapper$Context.class)]
[loading java/lang/Process.class(java/lang:Process.class)]
[loading java/lang/StringBuilder.class(java/lang:StringBuilder.class)]
[loading java/lang/ProcessBuilder.class(java/lang:ProcessBuilder.class)]
[loading java/lang/annotation/Target.class(java/lang/annotation:Target.class)]
[loading java/lang/annotation/ElementType.class(java/lang/annotation:ElementType.class)]
[loading java/lang/annotation/Retention.class(java/lang/annotation:Retention.class)]
[loading java/lang/annotation/RetentionPolicy.class(java/lang/annotation:RetentionPolicy.class)]
[loading java/lang/annotation/Annotation.class(java/lang/annotation:Annotation.class)]
[loading java/lang/SuppressWarnings.class(java/lang:SuppressWarnings.class)]
[loading java/lang/Override.class(java/lang:Override.class)]
[loading javax/ws/rs/HttpMethod.class(javax/ws/rs:HttpMethod.class)]
[loading java/lang/Deprecated.class(java/lang:Deprecated.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$3.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/HcatDelegator$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/LauncherDelegator$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$2.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/HcatException$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$2.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$2$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/ZooKeeperStorage$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/LogRetriever$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/ZooKeeperStorage$2.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonUtils$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/HDFSStorage$1.class]
[done in 6705 ms]
[WARNING] Javadoc Warnings
[WARNING] Nov 18, 2013 3:01:34 AM com.sun.jersey.wadl.resourcedoc.ResourceDoclet start
[WARNING] INFO: Wrote /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/resourcedoc.xml
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-webhcat ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-webhcat ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-webhcat ---
[INFO] Compiling 9 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/test-classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/test/java/org/apache/hive/hcatalog/templeton/TestDesc.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-webhcat ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-webhcat ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/hive-webhcat-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-webhcat ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/hive-webhcat-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-webhcat/0.13.0-SNAPSHOT/hive-webhcat-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-webhcat/0.13.0-SNAPSHOT/hive-webhcat-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog HBase Storage Handler 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hbase-storage-handler ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-hbase-storage-handler ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/src/gen-java added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hbase-storage-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hbase-storage-handler ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hbase-storage-handler ---
[INFO] Compiling 36 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hbase-storage-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hbase-storage-handler ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hbase-storage-handler ---
[INFO] Compiling 21 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hbase-storage-handler ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hbase-storage-handler ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/hive-hbase-storage-handler-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-hbase-storage-handler ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/hive-hbase-storage-handler-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hbase-storage-handler ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/hive-hbase-storage-handler-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hbase-storage-handler/0.13.0-SNAPSHOT/hive-hbase-storage-handler-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hbase-storage-handler/0.13.0-SNAPSHOT/hive-hbase-storage-handler-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/hive-hbase-storage-handler-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hbase-storage-handler/0.13.0-SNAPSHOT/hive-hbase-storage-handler-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HWI 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hwi ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hwi (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hwi ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hwi ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hwi ---
[INFO] Compiling 6 source files to /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hwi ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hwi ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hwi ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hwi ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hwi ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/hive-hwi-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hwi ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/hive-hwi-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hwi/0.13.0-SNAPSHOT/hive-hwi-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hwi/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-hwi/0.13.0-SNAPSHOT/hive-hwi-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive ODBC 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-odbc ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/odbc (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-odbc ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-odbc ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-odbc ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/odbc/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-odbc/0.13.0-SNAPSHOT/hive-odbc-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Aggregator 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-aggregator ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-aggregator ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-aggregator ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-aggregator ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-shims-aggregator/0.13.0-SNAPSHOT/hive-shims-aggregator-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive TestUtils 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-testutils ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/testutils (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-testutils ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-testutils ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-testutils ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-testutils ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-testutils ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-testutils ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-testutils ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-testutils ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/hive-testutils-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-testutils ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/hive-testutils-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-testutils/0.13.0-SNAPSHOT/hive-testutils-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/testutils/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-testutils/0.13.0-SNAPSHOT/hive-testutils-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Packaging 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-packaging ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/packaging (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-packaging ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-packaging ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-packaging ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/packaging/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-packaging/0.13.0-SNAPSHOT/hive-packaging-0.13.0-SNAPSHOT.pom
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [2.507s]
[INFO] Hive Ant Utilities ................................ SUCCESS [7.010s]
[INFO] Hive Shims Common ................................. SUCCESS [2.950s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [2.169s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [3.515s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [1.541s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [3.335s]
[INFO] Hive Shims ........................................ SUCCESS [3.584s]
[INFO] Hive Common ....................................... SUCCESS [13.932s]
[INFO] Hive Serde ........................................ SUCCESS [12.259s]
[INFO] Hive Metastore .................................... SUCCESS [26.351s]
[INFO] Hive Query Language ............................... SUCCESS [51.469s]
[INFO] Hive Service ...................................... SUCCESS [4.777s]
[INFO] Hive JDBC ......................................... SUCCESS [1.072s]
[INFO] Hive Beeline ...................................... SUCCESS [1.854s]
[INFO] Hive CLI .......................................... SUCCESS [1.744s]
[INFO] Hive Contrib ...................................... SUCCESS [1.383s]
[INFO] Hive HBase Handler ................................ SUCCESS [2.037s]
[INFO] Hive HCatalog ..................................... SUCCESS [0.327s]
[INFO] Hive HCatalog Core ................................ SUCCESS [2.879s]
[INFO] Hive HCatalog Pig Adapter ......................... SUCCESS [1.108s]
[INFO] Hive HCatalog Server Extensions ................... SUCCESS [1.448s]
[INFO] Hive HCatalog Webhcat Java Client ................. SUCCESS [1.025s]
[INFO] Hive HCatalog Webhcat ............................. SUCCESS [9.868s]
[INFO] Hive HCatalog HBase Storage Handler ............... SUCCESS [3.237s]
[INFO] Hive HWI .......................................... SUCCESS [0.837s]
[INFO] Hive ODBC ......................................... SUCCESS [0.379s]
[INFO] Hive Shims Aggregator ............................. SUCCESS [0.307s]
[INFO] Hive TestUtils .................................... SUCCESS [0.361s]
[INFO] Hive Packaging .................................... SUCCESS [0.430s]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 2:48.009s
[INFO] Finished at: Mon Nov 18 03:01:40 EST 2013
[INFO] Final Memory: 61M/483M
[INFO] ------------------------------------------------------------------------
+ mvn -B test -Dmaven.repo.local=/data/hive-ptest/working/maven -Dtest=TestDummy
[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Hive
[INFO] Hive Ant Utilities
[INFO] Hive Shims Common
[INFO] Hive Shims 0.20
[INFO] Hive Shims Secure Common
[INFO] Hive Shims 0.20S
[INFO] Hive Shims 0.23
[INFO] Hive Shims
[INFO] Hive Common
[INFO] Hive Serde
[INFO] Hive Metastore
[INFO] Hive Query Language
[INFO] Hive Service
[INFO] Hive JDBC
[INFO] Hive Beeline
[INFO] Hive CLI
[INFO] Hive Contrib
[INFO] Hive HBase Handler
[INFO] Hive HCatalog
[INFO] Hive HCatalog Core
[INFO] Hive HCatalog Pig Adapter
[INFO] Hive HCatalog Server Extensions
[INFO] Hive HCatalog Webhcat Java Client
[INFO] Hive HCatalog Webhcat
[INFO] Hive HCatalog HBase Storage Handler
[INFO] Hive HWI
[INFO] Hive ODBC
[INFO] Hive Shims Aggregator
[INFO] Hive TestUtils
[INFO] Hive Packaging
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf
[INFO] Executed tasks
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Ant Utilities 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-ant ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-ant ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-ant ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-ant ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-ant ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/ant/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-ant ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-ant ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.20 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20 ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20 ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20 ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Secure Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common-secure ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common-secure ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common-secure ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common-secure ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common-secure ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common-secure ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common-secure ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.20S 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20S ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20S ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20S ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20S ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20S ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20S ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20S ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.23 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.23 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.23 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.23 ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.23 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.23 ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.23 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.23 ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-version-annotation) @ hive-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-common ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/common/src/gen added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-common ---
[INFO] Compiling 1 source file to /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-common ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-common ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-common ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Serde 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-serde ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/protobuf/gen-java added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-serde ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-serde ---
[INFO] Compiling 1 source file to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-serde ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/serde/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-serde ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-serde ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Metastore 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-metastore ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/model added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-metastore ---
[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java
ANTLR Parser Generator  Version 3.4
Grammar /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g is up to date - build skipped
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-metastore ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-metastore ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-metastore ---
[INFO] Compiling 1 source file to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes
[INFO] 
[INFO] --- datanucleus-maven-plugin:3.3.0-release:enhance (default) @ hive-metastore ---
[INFO] DataNucleus Enhancer (version 3.2.2) for API &quot;JDO&quot; using JRE &quot;1.6&quot;
DataNucleus Enhancer : Classpath
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-maven-plugin/3.3.0-release/datanucleus-maven-plugin-3.3.0-release.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-utils/3.0.8/plexus-utils-3.0.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-component-annotations/1.5.5/plexus-component-annotations-1.5.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-inject-bean/2.3.0/sisu-inject-bean-2.3.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guice/3.1.0/sisu-guice-3.1.0-no_aop.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guava/0.9.9/sisu-guava-0.9.9.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/xbean/xbean-reflect/3.4/xbean-reflect-3.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/log4j/log4j/1.2.12/log4j-1.2.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-logging/commons-logging-api/1.1/commons-logging-api-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/collections/google-collections/1.0/google-collections-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/junit/junit/3.8.2/junit-3.8.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/serde/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/tukaani/xz/1.0/xz-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-codec/commons-codec/1.4/commons-codec-1.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/avro/avro/1.7.1/avro-1.7.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/jline/jline/0.9.94/jline-0.9.94.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/guava/guava/11.0.2/guava-11.0.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-lang/commons-lang/2.4/commons-lang-2.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/transaction/jta/1.1/jta-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/antlr/antlr/2.7.7/antlr-2.7.7.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/hadoop/hadoop-core/1.2.1/hadoop-core-1.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/xmlenc/xmlenc/0.52/xmlenc-0.52.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/stax/stax-api/1.0.1/stax-api-1.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/activation/activation/1.1/activation-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-jaxrs/1.7.1/jackson-jaxrs-1.7.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/asm/asm/3.1/asm-3.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-io/commons-io/2.1/commons-io-2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/commons/commons-math/2.1/commons-math-2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-digester/commons-digester/1.8/commons-digester-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/ant/ant/1.6.5/ant-1.6.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-el/commons-el/1.0/commons-el-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/oro/oro/2.0.8/oro-2.0.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/log4j/log4j/1.2.16/log4j-1.2.16.jar
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDatabase
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFieldSchema
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MType
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTable
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MOrder
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStringList
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartition
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MIndex
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRole
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRoleMap
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MMasterKey
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDelegationToken
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MVersionTable
DataNucleus Enhancer completed with success for 25 classes. Timings : input=700 ms, enhance=314 ms, total=1014 ms. Consult the log for full details

[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-metastore ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-metastore ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-metastore ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-metastore ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Query Language 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-sources) @ hive-exec ---
[INFO] Executing tasks

main:
Generating vector expression code
Generating vector expression test code
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-exec ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/protobuf/gen-java added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-sources/java added.
[INFO] 
[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-exec ---
[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java
ANTLR Parser Generator  Version 3.4
Grammar /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g is up to date - build skipped
Grammar /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g is up to date - build skipped
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-exec ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 6 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-test-source (add-test-sources) @ hive-exec ---
[INFO] Test Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-test-sources/java added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-exec ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-exec ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/ql/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/ql/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-exec ---
[INFO] Compiling 4 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-exec ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Service 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-service ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/service/src/model added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/service/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-service ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/service/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-service ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-service ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-service ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-service ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/service/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-service ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-service ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive JDBC 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-jdbc ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-jdbc ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-jdbc ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-jdbc ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-jdbc ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-jdbc ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-jdbc ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Beeline 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-beeline ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-beeline ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-beeline ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-beeline ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-beeline ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-beeline ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-beeline ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive CLI 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-cli ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/cli/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-cli ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-cli ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-cli ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-cli ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/cli/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/cli/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/cli/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-cli ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-cli ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Contrib 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-contrib ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-contrib ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-contrib ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-contrib ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-contrib ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-contrib ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-contrib ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HBase Handler 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hbase-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hbase-handler ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hbase-handler ---
[INFO] Compiling 1 source file to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hbase-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hbase-handler ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hbase-handler ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hbase-handler ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp/conf
[INFO] Executed tasks
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Core 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hcatalog-core ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-core ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-core ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hcatalog-core ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog-core ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hcatalog-core ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hcatalog-core ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Pig Adapter 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hcatalog-pig-adapter ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-pig-adapter ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-pig-adapter ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hcatalog-pig-adapter ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog-pig-adapter ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hcatalog-pig-adapter ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hcatalog-pig-adapter ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Server Extensions 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hcatalog-server-extensions ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-server-extensions ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-server-extensions ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hcatalog-server-extensions ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog-server-extensions ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hcatalog-server-extensions ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hcatalog-server-extensions ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Webhcat Java Client 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-webhcat-java-client ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-webhcat-java-client ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-webhcat-java-client ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-webhcat-java-client ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-webhcat-java-client ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-webhcat-java-client ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-webhcat-java-client ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Webhcat 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-webhcat ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-webhcat ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-webhcat ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-javadoc-plugin:2.4:javadoc (resourcesdoc.xml) @ hive-webhcat ---
[INFO] Setting property: classpath.resource.loader.class =&amp;gt; &apos;org.codehaus.plexus.velocity.ContextClassLoaderResourceLoader&apos;.
[INFO] Setting property: velocimacro.messages.on =&amp;gt; &apos;false&apos;.
[INFO] Setting property: resource.loader =&amp;gt; &apos;classpath&apos;.
[INFO] Setting property: resource.manager.logwhenfound =&amp;gt; &apos;false&apos;.
[INFO] ************************************************************** 
[INFO] Starting Jakarta Velocity v1.4
[INFO] RuntimeInstance initializing.
[INFO] Default Properties File: org/apache/velocity/runtime/defaults/velocity.properties
[INFO] Default ResourceManager initializing. (class org.apache.velocity.runtime.resource.ResourceManagerImpl)
[INFO] Resource Loader Instantiated: org.codehaus.plexus.velocity.ContextClassLoaderResourceLoader
[INFO] ClasspathResourceLoader : initialization starting.
[INFO] ClasspathResourceLoader : initialization complete.
[INFO] ResourceCache : initialized. (class org.apache.velocity.runtime.resource.ResourceCacheImpl)
[INFO] Default ResourceManager initialization complete.
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Literal
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Macro
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Parse
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Include
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Foreach
[INFO] Created: 20 parsers.
[INFO] Velocimacro : initialization starting.
[INFO] Velocimacro : adding VMs from VM library template : VM_global_library.vm
[ERROR] ResourceManager : unable to find resource &apos;VM_global_library.vm&apos; in any resource loader.
[INFO] Velocimacro : error using  VM library template VM_global_library.vm : org.apache.velocity.exception.ResourceNotFoundException: Unable to find resource &apos;VM_global_library.vm&apos;
[INFO] Velocimacro :  VM library template macro registration complete.
[INFO] Velocimacro : allowInline = true : VMs can be defined inline in templates
[INFO] Velocimacro : allowInlineToOverride = false : VMs defined inline may NOT replace previous VM definitions
[INFO] Velocimacro : allowInlineLocal = false : VMs defined inline will be  global in scope if allowed.
[INFO] Velocimacro : initialization complete.
[INFO] Velocity successfully started.
Loading source files for package org.apache.hive.hcatalog.templeton...
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/SimpleExceptionMapper.java]
[parsing completed 30ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JsonBuilder.java]
[parsing completed 8ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JobItemBean.java]
[parsing completed 2ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JarDelegator.java]
[parsing completed 11ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/LauncherDelegator.java]
[parsing completed 22ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ExecServiceImpl.java]
[parsing completed 20ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/DeleteDelegator.java]
[parsing completed 7ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ExecBean.java]
[parsing completed 7ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/PigDelegator.java]
[parsing completed 15ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/TempletonDelegator.java]
[parsing completed 5ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/StreamingDelegator.java]
[parsing completed 13ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/DatabaseDesc.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CompleteBean.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HiveDelegator.java]
[parsing completed 19ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/Server.java]
[parsing completed 126ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/BadParam.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ColumnDesc.java]
[parsing completed 2ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/PartitionDesc.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CatchallExceptionMapper.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HcatDelegator.java]
[parsing completed 43ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/StatusDelegator.java]
[parsing completed 15ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/QueueStatusBean.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CompleteDelegator.java]
[parsing completed 11ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/GroupPermissionsDesc.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/AppConfig.java]
[parsing completed 12ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HcatException.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/QueueException.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/TableLikeDesc.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/TableDesc.java]
[parsing completed 12ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/WadlConfig.java]
[parsing completed 4ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/BusyException.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ExecService.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/NotAuthorizedException.java]
[parsing completed 5ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/EnqueueBean.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/SimpleWebException.java]
[parsing completed 6ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ListDelegator.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/Main.java]
[parsing completed 16ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/SecureProxySupport.java]
[parsing completed 12ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/MaxByteArrayOutputStream.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ProxyUserSupport.java]
[parsing completed 12ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/UgiFactory.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CallbackFailedException.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/TablePropertyDesc.java]
[parsing completed 0ms]
Loading source files for package org.apache.hive.hcatalog.templeton.tool...
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/ZooKeeperStorage.java]
[parsing completed 19ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/NullRecordReader.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/PigJobIDParser.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonStorage.java]
[parsing completed 4ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JobIDParser.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JobState.java]
[parsing completed 14ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonUtils.java]
[parsing completed 18ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/HDFSStorage.java]
[parsing completed 11ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/DelegationTokenCache.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JarJobIDParser.java]
[parsing completed 10ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JobSubmissionConstants.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/ZooKeeperCleanup.java]
[parsing completed 5ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JobStateTracker.java]
[parsing completed 3ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/NotFoundException.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/SingleInputFormat.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/LogRetriever.java]
[parsing completed 11ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/NullSplit.java]
[parsing completed 2ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/HDFSCleanup.java]
[parsing completed 7ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java]
[parsing completed 7ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/HiveJobIDParser.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/LaunchMapper.java]
[parsing completed 12ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java]
[parsing completed 1ms]
Constructing Javadoc information...
[search path for source files: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java]
[search path for class files: /usr/java/jdk1.6.0_34/jre/lib/resources.jar,/usr/java/jdk1.6.0_34/jre/lib/rt.jar,/usr/java/jdk1.6.0_34/jre/lib/sunrsasign.jar,/usr/java/jdk1.6.0_34/jre/lib/jsse.jar,/usr/java/jdk1.6.0_34/jre/lib/jce.jar,/usr/java/jdk1.6.0_34/jre/lib/charsets.jar,/usr/java/jdk1.6.0_34/jre/lib/modules/jdk.boot.jar,/usr/java/jdk1.6.0_34/jre/classes,/usr/java/jdk1.6.0_34/jre/lib/ext/localedata.jar,/usr/java/jdk1.6.0_34/jre/lib/ext/sunpkcs11.jar,/usr/java/jdk1.6.0_34/jre/lib/ext/sunjce_provider.jar,/usr/java/jdk1.6.0_34/jre/lib/ext/dnsns.jar,/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes,/data/hive-ptest/working/maven/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar,/data/hive-ptest/working/maven/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar,/data/hive-ptest/working/maven/com/sun/jersey/jersey-json/1.14/jersey-json-1.14.jar,/data/hive-ptest/working/maven/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar,/data/hive-ptest/working/maven/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/classes,/data/hive-ptest/working/maven/javax/mail/mail/1.4.1/mail-1.4.1.jar,/data/hive-ptest/working/maven/javax/mail/mail/1.4.1/activation.jar,/data/hive-ptest/working/maven/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar,/data/hive-ptest/working/maven/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar,/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/classes,/data/hive-ptest/working/maven/org/codehaus/jackson/jackson-core-asl/1.9.2/jackson-core-asl-1.9.2.jar,/data/hive-ptest/working/maven/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar,/data/hive-ptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar,/data/hive-ptest/working/maven/xerces/xercesImpl/2.6.1/xercesImpl-2.6.1.jar,/data/hive-ptest/working/maven/antlr/antlr/2.7.7/antlr-2.7.7.jar,/data/hive-ptest/working/maven/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar,/data/hive-ptest/working/maven/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/classes,/data/hive-ptest/working/maven/org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.jar,/data/hive-ptest/working/apache-svn-trunk-source/serde/target/classes,/data/hive-ptest/working/maven/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar,/data/hive-ptest/working/maven/com/sun/jdmk/jmxtools/1.2.1/jmxtools-1.2.1.jar,/data/hive-ptest/working/maven/org/apache/velocity/velocity/1.5/velocity-1.5.jar,/data/hive-ptest/working/maven/com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar,/data/hive-ptest/working/maven/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar,/data/hive-ptest/working/maven/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar,/data/hive-ptest/working/maven/javax/jms/jms/1.1/jms-1.1.jar,/data/hive-ptest/working/maven/commons-lang/commons-lang/2.4/commons-lang-2.4.jar,/data/hive-ptest/working/maven/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar,/data/hive-ptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar,/data/hive-ptest/working/maven/org/apache/commons/commons-math/2.1/commons-math-2.1.jar,/data/hive-ptest/working/maven/org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.jar,/data/hive-ptest/working/maven/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar,/data/hive-ptest/working/maven/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar,/data/hive-ptest/working/maven/org/antlr/ST4/4.0.4/ST4-4.0.4.jar,/data/hive-ptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar,/data/hive-ptest/working/maven/com/google/guava/guava/11.0.2/guava-11.0.2.jar,/data/hive-ptest/working/maven/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar,/data/hive-ptest/working/maven/org/apache/hadoop/hadoop-core/1.2.1/hadoop-core-1.2.1.jar,/data/hive-ptest/working/maven/org/tukaani/xz/1.0/xz-1.0.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar,/data/hive-ptest/working/maven/javax/activation/activation/1.1/activation-1.1.jar,/data/hive-ptest/working/maven/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar,/data/hive-ptest/working/maven/stax/stax-api/1.0.1/stax-api-1.0.1.jar,/data/hive-ptest/working/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar,/data/hive-ptest/working/maven/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar,/data/hive-ptest/working/maven/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar,/data/hive-ptest/working/maven/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar,/data/hive-ptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar,/usr/java/jdk1.6.0_34/jre/../lib/tools.jar,/data/hive-ptest/working/maven/org/apache/ant/ant/1.9.1/ant-1.9.1.jar,/data/hive-ptest/working/maven/io/netty/netty/3.4.0.Final/netty-3.4.0.Final.jar,/data/hive-ptest/working/maven/org/slf4j/jul-to-slf4j/1.6.1/jul-to-slf4j-1.6.1.jar,/data/hive-ptest/working/maven/com/sun/jersey/contribs/wadl-resourcedoc-doclet/1.4/wadl-resourcedoc-doclet-1.4.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar,/data/hive-ptest/working/maven/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar,/data/hive-ptest/working/maven/oro/oro/2.0.8/oro-2.0.8.jar,/data/hive-ptest/working/maven/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/classes,/data/hive-ptest/working/maven/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar,/data/hive-ptest/working/maven/javax/transaction/jta/1.1/jta-1.1.jar,/data/hive-ptest/working/maven/log4j/log4j/1.2.15/log4j-1.2.15.jar,/data/hive-ptest/working/apache-svn-trunk-source/common/target/classes,/data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes,/data/hive-ptest/working/maven/org/apache/geronimo/specs/geronimo-annotation_1.0_spec/1.1.1/geronimo-annotation_1.0_spec-1.1.1.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar,/data/hive-ptest/working/maven/org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.jar,/data/hive-ptest/working/maven/javolution/javolution/5.5.1/javolution-5.5.1.jar,/data/hive-ptest/working/maven/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar,/data/hive-ptest/working/maven/com/sun/jersey/jersey-servlet/1.14/jersey-servlet-1.14.jar,/data/hive-ptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar,/data/hive-ptest/working/maven/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar,/data/hive-ptest/working/maven/xmlenc/xmlenc/0.52/xmlenc-0.52.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar,/data/hive-ptest/working/maven/commons-el/commons-el/1.0/commons-el-1.0.jar,/data/hive-ptest/working/maven/com/esotericsoftware/kryo/kryo/2.22/kryo-2.22.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/classes,/data/hive-ptest/working/maven/jline/jline/0.9.94/jline-0.9.94.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar,/data/hive-ptest/working/maven/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar,/data/hive-ptest/working/maven/org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.jar,/data/hive-ptest/working/maven/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar,/data/hive-ptest/working/maven/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar,/data/hive-ptest/working/maven/ant/ant/1.6.5/ant-1.6.5.jar,/data/hive-ptest/working/apache-svn-trunk-source/cli/target/classes,/data/hive-ptest/working/maven/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar,/data/hive-ptest/working/maven/org/codehaus/groovy/groovy-all/2.1.6/groovy-all-2.1.6.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_cs.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_de_DE.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_es.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_fr.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_hu.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_it.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_ja_JP.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_ko_KR.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_pl.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_pt_BR.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_ru.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_zh_CN.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_zh_TW.jar,/data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes,/data/hive-ptest/working/maven/asm/asm-commons/3.1/asm-commons-3.1.jar,/data/hive-ptest/working/maven/org/iq80/snappy/snappy/0.2/snappy-0.2.jar,/data/hive-ptest/working/apache-svn-trunk-source/service/target/classes,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-api.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/activation.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jsr173_1.0_api.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb1-impl.jar,/data/hive-ptest/working/maven/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar,/data/hive-ptest/working/maven/org/apache/hadoop/hadoop-tools/1.2.1/hadoop-tools-1.2.1.jar,/data/hive-ptest/working/maven/asm/asm-tree/3.1/asm-tree-3.1.jar,/data/hive-ptest/working/maven/com/thoughtworks/paranamer/paranamer/2.2/paranamer-2.2.jar,/data/hive-ptest/working/maven/commons-io/commons-io/2.1/commons-io-2.1.jar,/data/hive-ptest/working/maven/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar,/data/hive-ptest/working/maven/org/codehaus/jackson/jackson-mapper-asl/1.9.2/jackson-mapper-asl-1.9.2.jar,/data/hive-ptest/working/maven/org/apache/avro/avro/1.7.1/avro-1.7.1.jar,/data/hive-ptest/working/maven/commons-digester/commons-digester/1.8/commons-digester-1.8.jar,/data/hive-ptest/working/maven/org/apache/geronimo/specs/geronimo-jaspic_1.0_spec/1.0/geronimo-jaspic_1.0_spec-1.0.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar,/data/hive-ptest/working/maven/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/classes,/data/hive-ptest/working/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/classes,/data/hive-ptest/working/maven/org/apache/geronimo/specs/geronimo-jta_1.1_spec/1.1.1/geronimo-jta_1.1_spec-1.1.1.jar,/data/hive-ptest/working/maven/org/json/json/20090211/json-20090211.jar,/data/hive-ptest/working/maven/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar,/data/hive-ptest/working/maven/com/sun/jmx/jmxri/1.2.1/jmxri-1.2.1.jar,/data/hive-ptest/working/maven/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar,/data/hive-ptest/working/apache-svn-trunk-source/ant/target/classes,/data/hive-ptest/working/maven/asm/asm/3.1/asm-3.1.jar,/data/hive-ptest/working/maven/commons-codec/commons-codec/1.4/commons-codec-1.4.jar]
[loading javax/ws/rs/core/Response.class(javax/ws/rs/core:Response.class)]
[loading javax/ws/rs/ext/ExceptionMapper.class(javax/ws/rs/ext:ExceptionMapper.class)]
[loading javax/ws/rs/ext/Provider.class(javax/ws/rs/ext:Provider.class)]
[loading java/io/IOException.class(java/io:IOException.class)]
[loading java/util/Map.class(java/util:Map.class)]
[loading java/util/HashMap.class(java/util:HashMap.class)]
[loading javax/ws/rs/core/MediaType.class(javax/ws/rs/core:MediaType.class)]
[loading org/codehaus/jackson/map/ObjectMapper.class(org/codehaus/jackson/map:ObjectMapper.class)]
[loading java/lang/Throwable.class(java/lang:Throwable.class)]
[loading java/io/Serializable.class(java/io:Serializable.class)]
[loading java/lang/Object.class(java/lang:Object.class)]
[loading java/lang/String.class(java/lang:String.class)]
[loading java/io/ByteArrayOutputStream.class(java/io:ByteArrayOutputStream.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes/org/apache/hadoop/hive/ql/ErrorMsg.class]
[loading org/eclipse/jetty/http/HttpStatus.class(org/eclipse/jetty/http:HttpStatus.class)]
[loading java/lang/Integer.class(java/lang:Integer.class)]
[loading org/apache/hadoop/mapred/JobStatus.class(org/apache/hadoop/mapred:JobStatus.class)]
[loading org/apache/hadoop/mapred/JobProfile.class(org/apache/hadoop/mapred:JobProfile.class)]
[loading java/lang/Long.class(java/lang:Long.class)]
[loading java/util/ArrayList.class(java/util:ArrayList.class)]
[loading java/util/List.class(java/util:List.class)]
[loading org/apache/commons/logging/Log.class(org/apache/commons/logging:Log.class)]
[loading org/apache/commons/logging/LogFactory.class(org/apache/commons/logging:LogFactory.class)]
[loading org/apache/hadoop/conf/Configuration.class(org/apache/hadoop/conf:Configuration.class)]
[loading java/lang/Enum.class(java/lang:Enum.class)]
[loading java/lang/Comparable.class(java/lang:Comparable.class)]
[loading java/lang/Exception.class(java/lang:Exception.class)]
[loading java/io/FileNotFoundException.class(java/io:FileNotFoundException.class)]
[loading java/net/URISyntaxException.class(java/net:URISyntaxException.class)]
[loading org/apache/commons/exec/ExecuteException.class(org/apache/commons/exec:ExecuteException.class)]
[loading java/security/PrivilegedExceptionAction.class(java/security:PrivilegedExceptionAction.class)]
[loading org/apache/hadoop/fs/Path.class(org/apache/hadoop/fs:Path.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes/org/apache/hadoop/hive/conf/HiveConf.class]
[loading org/apache/hadoop/security/UserGroupInformation.class(org/apache/hadoop/security:UserGroupInformation.class)]
[loading org/apache/hadoop/util/StringUtils.class(org/apache/hadoop/util:StringUtils.class)]
[loading org/apache/hadoop/util/ToolRunner.class(org/apache/hadoop/util:ToolRunner.class)]
[loading java/io/File.class(java/io:File.class)]
[loading java/net/URL.class(java/net:URL.class)]
[loading org/apache/hadoop/util/VersionInfo.class(org/apache/hadoop/util:VersionInfo.class)]
[loading java/lang/Iterable.class(java/lang:Iterable.class)]
[loading org/apache/hadoop/io/Writable.class(org/apache/hadoop/io:Writable.class)]
[loading java/lang/InterruptedException.class(java/lang:InterruptedException.class)]
[loading java/io/BufferedReader.class(java/io:BufferedReader.class)]
[loading java/io/InputStream.class(java/io:InputStream.class)]
[loading java/io/InputStreamReader.class(java/io:InputStreamReader.class)]
[loading java/io/OutputStream.class(java/io:OutputStream.class)]
[loading java/io/PrintWriter.class(java/io:PrintWriter.class)]
[loading java/util/Map$Entry.class(java/util:Map$Entry.class)]
[loading java/util/concurrent/Semaphore.class(java/util/concurrent:Semaphore.class)]
[loading org/apache/commons/exec/CommandLine.class(org/apache/commons/exec:CommandLine.class)]
[loading org/apache/commons/exec/DefaultExecutor.class(org/apache/commons/exec:DefaultExecutor.class)]
[loading org/apache/commons/exec/ExecuteWatchdog.class(org/apache/commons/exec:ExecuteWatchdog.class)]
[loading org/apache/commons/exec/PumpStreamHandler.class(org/apache/commons/exec:PumpStreamHandler.class)]
[loading org/apache/hadoop/util/Shell.class(org/apache/hadoop/util:Shell.class)]
[loading java/lang/Thread.class(java/lang:Thread.class)]
[loading java/lang/Runnable.class(java/lang:Runnable.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/classes/org/apache/hadoop/hive/shims/HadoopShims.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/classes/org/apache/hadoop/hive/shims/HadoopShims$WebHCatJTShim.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/classes/org/apache/hadoop/hive/shims/ShimLoader.class]
[loading org/apache/hadoop/mapred/JobID.class(org/apache/hadoop/mapred:JobID.class)]
[loading java/util/Arrays.class(java/util:Arrays.class)]
[loading javax/xml/bind/annotation/XmlRootElement.class(javax/xml/bind/annotation:XmlRootElement.class)]
[loading java/net/InetAddress.class(java/net:InetAddress.class)]
[loading java/net/UnknownHostException.class(java/net:UnknownHostException.class)]
[loading java/text/MessageFormat.class(java/text:MessageFormat.class)]
[loading java/util/Collections.class(java/util:Collections.class)]
[loading java/util/regex/Matcher.class(java/util/regex:Matcher.class)]
[loading java/util/regex/Pattern.class(java/util/regex:Pattern.class)]
[loading javax/servlet/http/HttpServletRequest.class(javax/servlet/http:HttpServletRequest.class)]
[loading javax/ws/rs/DELETE.class(javax/ws/rs:DELETE.class)]
[loading javax/ws/rs/FormParam.class(javax/ws/rs:FormParam.class)]
[loading javax/ws/rs/GET.class(javax/ws/rs:GET.class)]
[loading javax/ws/rs/POST.class(javax/ws/rs:POST.class)]
[loading javax/ws/rs/PUT.class(javax/ws/rs:PUT.class)]
[loading javax/ws/rs/Path.class(javax/ws/rs:Path.class)]
[loading javax/ws/rs/PathParam.class(javax/ws/rs:PathParam.class)]
[loading javax/ws/rs/Produces.class(javax/ws/rs:Produces.class)]
[loading javax/ws/rs/QueryParam.class(javax/ws/rs:QueryParam.class)]
[loading javax/ws/rs/core/Context.class(javax/ws/rs/core:Context.class)]
[loading javax/ws/rs/core/SecurityContext.class(javax/ws/rs/core:SecurityContext.class)]
[loading javax/ws/rs/core/UriInfo.class(javax/ws/rs/core:UriInfo.class)]
[loading org/apache/hadoop/security/authentication/client/PseudoAuthenticator.class(org/apache/hadoop/security/authentication/client:PseudoAuthenticator.class)]
[loading com/sun/jersey/api/NotFoundException.class(com/sun/jersey/api:NotFoundException.class)]
[loading java/net/URI.class(java/net:URI.class)]
[loading org/apache/commons/lang/StringUtils.class(org/apache/commons/lang:StringUtils.class)]
[loading org/apache/hadoop/fs/FileStatus.class(org/apache/hadoop/fs:FileStatus.class)]
[loading org/apache/hadoop/fs/FileSystem.class(org/apache/hadoop/fs:FileSystem.class)]
[loading java/util/Date.class(java/util:Date.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes/org/apache/hadoop/hive/common/classification/InterfaceAudience.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/classes/org/apache/hive/hcatalog/common/HCatUtil.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes/org/apache/hadoop/hive/common/classification/InterfaceAudience$Private.class]
[loading com/sun/jersey/api/wadl/config/WadlGeneratorConfig.class(com/sun/jersey/api/wadl/config:WadlGeneratorConfig.class)]
[loading com/sun/jersey/api/wadl/config/WadlGeneratorDescription.class(com/sun/jersey/api/wadl/config:WadlGeneratorDescription.class)]
[loading com/sun/jersey/server/wadl/generators/resourcedoc/WadlGeneratorResourceDocSupport.class(com/sun/jersey/server/wadl/generators/resourcedoc:WadlGeneratorResourceDocSupport.class)]
[loading com/sun/jersey/api/core/PackagesResourceConfig.class(com/sun/jersey/api/core:PackagesResourceConfig.class)]
[loading com/sun/jersey/spi/container/servlet/ServletContainer.class(com/sun/jersey/spi/container/servlet:ServletContainer.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes/org/apache/hadoop/hive/common/classification/InterfaceStability.class]
[loading org/apache/hadoop/hdfs/web/AuthFilter.class(org/apache/hadoop/hdfs/web:AuthFilter.class)]
[loading org/apache/hadoop/util/GenericOptionsParser.class(org/apache/hadoop/util:GenericOptionsParser.class)]
[loading org/eclipse/jetty/rewrite/handler/RedirectPatternRule.class(org/eclipse/jetty/rewrite/handler:RedirectPatternRule.class)]
[loading org/eclipse/jetty/rewrite/handler/RewriteHandler.class(org/eclipse/jetty/rewrite/handler:RewriteHandler.class)]
[loading org/eclipse/jetty/server/Handler.class(org/eclipse/jetty/server:Handler.class)]
[loading org/eclipse/jetty/server/Server.class(org/eclipse/jetty/server:Server.class)]
[loading org/eclipse/jetty/server/handler/HandlerList.class(org/eclipse/jetty/server/handler:HandlerList.class)]
[loading org/eclipse/jetty/servlet/FilterHolder.class(org/eclipse/jetty/servlet:FilterHolder.class)]
[loading org/eclipse/jetty/servlet/FilterMapping.class(org/eclipse/jetty/servlet:FilterMapping.class)]
[loading org/eclipse/jetty/servlet/ServletContextHandler.class(org/eclipse/jetty/servlet:ServletContextHandler.class)]
[loading org/eclipse/jetty/servlet/ServletHolder.class(org/eclipse/jetty/servlet:ServletHolder.class)]
[loading org/slf4j/bridge/SLF4JBridgeHandler.class(org/slf4j/bridge:SLF4JBridgeHandler.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes/org/apache/hadoop/hive/common/classification/InterfaceAudience$LimitedPrivate.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes/org/apache/hadoop/hive/common/classification/InterfaceStability$Unstable.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes/org/apache/hadoop/hive/metastore/api/MetaException.class]
[loading org/apache/hadoop/io/Text.class(org/apache/hadoop/io:Text.class)]
[loading org/apache/hadoop/security/Credentials.class(org/apache/hadoop/security:Credentials.class)]
[loading org/apache/hadoop/security/token/Token.class(org/apache/hadoop/security/token:Token.class)]
[loading org/apache/thrift/TException.class(org/apache/thrift:TException.class)]
[loading java/io/Closeable.class(java/io:Closeable.class)]
[loading java/io/Flushable.class(java/io:Flushable.class)]
[loading org/apache/hadoop/security/Groups.class(org/apache/hadoop/security:Groups.class)]
[loading java/util/HashSet.class(java/util:HashSet.class)]
[loading java/util/Set.class(java/util:Set.class)]
[loading java/util/concurrent/ConcurrentHashMap.class(java/util/concurrent:ConcurrentHashMap.class)]
[loading java/io/UnsupportedEncodingException.class(java/io:UnsupportedEncodingException.class)]
[loading org/apache/zookeeper/CreateMode.class(org/apache/zookeeper:CreateMode.class)]
[loading org/apache/zookeeper/KeeperException.class(org/apache/zookeeper:KeeperException.class)]
[loading org/apache/zookeeper/WatchedEvent.class(org/apache/zookeeper:WatchedEvent.class)]
[loading org/apache/zookeeper/Watcher.class(org/apache/zookeeper:Watcher.class)]
[loading org/apache/zookeeper/ZooDefs.class(org/apache/zookeeper:ZooDefs.class)]
[loading org/apache/zookeeper/ZooDefs$Ids.class(org/apache/zookeeper:ZooDefs$Ids.class)]
[loading org/apache/zookeeper/ZooKeeper.class(org/apache/zookeeper:ZooKeeper.class)]
[loading org/apache/hadoop/io/NullWritable.class(org/apache/hadoop/io:NullWritable.class)]
[loading org/apache/hadoop/mapreduce/InputSplit.class(org/apache/hadoop/mapreduce:InputSplit.class)]
[loading org/apache/hadoop/mapreduce/RecordReader.class(org/apache/hadoop/mapreduce:RecordReader.class)]
[loading org/apache/hadoop/mapreduce/TaskAttemptContext.class(org/apache/hadoop/mapreduce:TaskAttemptContext.class)]
[loading java/net/URLConnection.class(java/net:URLConnection.class)]
[loading java/util/Collection.class(java/util:Collection.class)]
[loading javax/ws/rs/core/UriBuilder.class(javax/ws/rs/core:UriBuilder.class)]
[loading java/io/OutputStreamWriter.class(java/io:OutputStreamWriter.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes/org/apache/hadoop/hive/common/classification/InterfaceStability$Evolving.class]
[loading org/apache/zookeeper/data/Stat.class(org/apache/zookeeper/data:Stat.class)]
[loading org/apache/hadoop/mapreduce/InputFormat.class(org/apache/hadoop/mapreduce:InputFormat.class)]
[loading org/apache/hadoop/mapreduce/JobContext.class(org/apache/hadoop/mapreduce:JobContext.class)]
[loading org/apache/hadoop/mapred/JobClient.class(org/apache/hadoop/mapred:JobClient.class)]
[loading org/apache/hadoop/mapred/JobConf.class(org/apache/hadoop/mapred:JobConf.class)]
[loading org/apache/hadoop/mapred/RunningJob.class(org/apache/hadoop/mapred:RunningJob.class)]
[loading java/io/DataInput.class(java/io:DataInput.class)]
[loading java/io/DataOutput.class(java/io:DataOutput.class)]
[loading org/apache/hadoop/conf/Configured.class(org/apache/hadoop/conf:Configured.class)]
[loading org/apache/hadoop/fs/permission/FsPermission.class(org/apache/hadoop/fs/permission:FsPermission.class)]
[loading org/apache/hadoop/mapreduce/Job.class(org/apache/hadoop/mapreduce:Job.class)]
[loading org/apache/hadoop/mapreduce/JobID.class(org/apache/hadoop/mapreduce:JobID.class)]
[loading org/apache/hadoop/mapreduce/lib/output/NullOutputFormat.class(org/apache/hadoop/mapreduce/lib/output:NullOutputFormat.class)]
[loading org/apache/hadoop/mapreduce/security/token/delegation/DelegationTokenIdentifier.class(org/apache/hadoop/mapreduce/security/token/delegation:DelegationTokenIdentifier.class)]
[loading org/apache/hadoop/util/Tool.class(org/apache/hadoop/util:Tool.class)]
[loading org/apache/hadoop/conf/Configurable.class(org/apache/hadoop/conf:Configurable.class)]
[loading java/lang/ClassNotFoundException.class(java/lang:ClassNotFoundException.class)]
[loading org/apache/hadoop/mapreduce/Mapper.class(org/apache/hadoop/mapreduce:Mapper.class)]
[loading java/util/Iterator.class(java/util:Iterator.class)]
[loading java/util/LinkedList.class(java/util:LinkedList.class)]
[loading java/util/concurrent/ExecutorService.class(java/util/concurrent:ExecutorService.class)]
[loading java/util/concurrent/Executors.class(java/util/concurrent:Executors.class)]
[loading java/util/concurrent/TimeUnit.class(java/util/concurrent:TimeUnit.class)]
[loading org/apache/hadoop/mapreduce/Mapper$Context.class(org/apache/hadoop/mapreduce:Mapper$Context.class)]
[loading java/lang/Process.class(java/lang:Process.class)]
[loading java/lang/StringBuilder.class(java/lang:StringBuilder.class)]
[loading java/lang/ProcessBuilder.class(java/lang:ProcessBuilder.class)]
[loading java/lang/annotation/Target.class(java/lang/annotation:Target.class)]
[loading java/lang/annotation/ElementType.class(java/lang/annotation:ElementType.class)]
[loading java/lang/annotation/Retention.class(java/lang/annotation:Retention.class)]
[loading java/lang/annotation/RetentionPolicy.class(java/lang/annotation:RetentionPolicy.class)]
[loading java/lang/annotation/Annotation.class(java/lang/annotation:Annotation.class)]
[loading java/lang/SuppressWarnings.class(java/lang:SuppressWarnings.class)]
[loading java/lang/Override.class(java/lang:Override.class)]
[loading javax/ws/rs/HttpMethod.class(javax/ws/rs:HttpMethod.class)]
[loading java/lang/Deprecated.class(java/lang:Deprecated.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$3.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/HcatDelegator$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/LauncherDelegator$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$2.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/HcatException$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$2.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$2$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/ZooKeeperStorage$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/LogRetriever$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/ZooKeeperStorage$2.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonUtils$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/HDFSStorage$1.class]
[done in 7478 ms]
[WARNING] Javadoc Warnings
[WARNING] Nov 18, 2013 3:02:33 AM com.sun.jersey.wadl.resourcedoc.ResourceDoclet start
[WARNING] INFO: Wrote /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/resourcedoc.xml
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-webhcat ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-webhcat ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-webhcat ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-webhcat ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog HBase Storage Handler 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-hbase-storage-handler ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/src/gen-java added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hbase-storage-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hbase-storage-handler ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hbase-storage-handler ---
[INFO] Compiling 1 source file to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hbase-storage-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hbase-storage-handler ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hbase-storage-handler ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hbase-storage-handler ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HWI 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hwi ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hwi ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hwi ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hwi ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hwi ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hwi ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hwi ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive ODBC 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-odbc ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-odbc ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp/conf
[INFO] Executed tasks
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Aggregator 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-aggregator ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-aggregator ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp/conf
[INFO] Executed tasks
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive TestUtils 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-testutils ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-testutils ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-testutils ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-testutils ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-testutils ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-testutils ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-testutils ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Packaging 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-packaging ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-packaging ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/tmp/conf
[INFO] Executed tasks
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [1.953s]
[INFO] Hive Ant Utilities ................................ SUCCESS [3.474s]
[INFO] Hive Shims Common ................................. SUCCESS [1.045s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [0.561s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [0.918s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [0.359s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [1.321s]
[INFO] Hive Shims ........................................ SUCCESS [0.230s]
[INFO] Hive Common ....................................... SUCCESS [3.603s]
[INFO] Hive Serde ........................................ SUCCESS [0.628s]
[INFO] Hive Metastore .................................... SUCCESS [5.970s]
[INFO] Hive Query Language ............................... SUCCESS [11.260s]
[INFO] Hive Service ...................................... SUCCESS [0.447s]
[INFO] Hive JDBC ......................................... SUCCESS [0.428s]
[INFO] Hive Beeline ...................................... SUCCESS [0.708s]
[INFO] Hive CLI .......................................... SUCCESS [0.780s]
[INFO] Hive Contrib ...................................... SUCCESS [0.815s]
[INFO] Hive HBase Handler ................................ SUCCESS [1.381s]
[INFO] Hive HCatalog ..................................... SUCCESS [0.453s]
[INFO] Hive HCatalog Core ................................ SUCCESS [0.881s]
[INFO] Hive HCatalog Pig Adapter ......................... SUCCESS [0.666s]
[INFO] Hive HCatalog Server Extensions ................... SUCCESS [0.380s]
[INFO] Hive HCatalog Webhcat Java Client ................. SUCCESS [0.441s]
[INFO] Hive HCatalog Webhcat ............................. SUCCESS [9.370s]
[INFO] Hive HCatalog HBase Storage Handler ............... SUCCESS [0.584s]
[INFO] Hive HWI .......................................... SUCCESS [0.245s]
[INFO] Hive ODBC ......................................... SUCCESS [0.341s]
[INFO] Hive Shims Aggregator ............................. SUCCESS [0.095s]
[INFO] Hive TestUtils .................................... SUCCESS [0.128s]
[INFO] Hive Packaging .................................... SUCCESS [0.221s]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 52.003s
[INFO] Finished at: Mon Nov 18 03:02:35 EST 2013
[INFO] Final Memory: 38M/115M
[INFO] ------------------------------------------------------------------------
+ cd itests
+ mvn -B clean install -DskipTests -Dmaven.repo.local=/data/hive-ptest/working/maven
[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Hive Integration - Parent
[INFO] Hive Integration - Custom Serde
[INFO] Hive Integration - Testing Utilities
[INFO] Hive Integration - Unit Tests
[INFO] Hive Integration - HCatalog Unit Tests
[INFO] Hive Integration - Test Serde
[INFO] Hive Integration - QFile Tests
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Parent 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/itests (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-it/0.13.0-SNAPSHOT/hive-it-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Custom Serde 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-custom-serde ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-it-custom-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-custom-serde ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-custom-serde ---
[INFO] Compiling 8 source files to /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-it-custom-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-custom-serde ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-custom-serde ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-it-custom-serde ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-it-custom-serde ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/hive-it-custom-serde-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it-custom-serde ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/hive-it-custom-serde-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-it-custom-serde/0.13.0-SNAPSHOT/hive-it-custom-serde-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-it-custom-serde/0.13.0-SNAPSHOT/hive-it-custom-serde-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Testing Utilities 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-util ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/itests/util (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-it-util ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-util ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-util ---
[INFO] Compiling 42 source files to /data/hive-ptest/working/apache-svn-trunk-source/itests/util/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 2 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/DummyStatsAggregator.java:[30,8] org.apache.hadoop.hive.ql.stats.DummyStatsAggregator is not abstract and does not override abstract method connect(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.ql.exec.mr.MapRedTask) in org.apache.hadoop.hive.ql.stats.StatsAggregator
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive Integration - Parent ......................... SUCCESS [3.821s]
[INFO] Hive Integration - Custom Serde ................... SUCCESS [9.079s]
[INFO] Hive Integration - Testing Utilities .............. FAILURE [5.435s]
[INFO] Hive Integration - Unit Tests ..................... SKIPPED
[INFO] Hive Integration - HCatalog Unit Tests ............ SKIPPED
[INFO] Hive Integration - Test Serde ..................... SKIPPED
[INFO] Hive Integration - QFile Tests .................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 19.512s
[INFO] Finished at: Mon Nov 18 03:02:57 EST 2013
[INFO] Final Memory: 26M/62M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-it-util: Compilation failure
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/DummyStatsAggregator.java:[30,8] org.apache.hadoop.hive.ql.stats.DummyStatsAggregator is not abstract and does not override abstract method connect(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.ql.exec.mr.MapRedTask) in org.apache.hadoop.hive.ql.stats.StatsAggregator
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-it-util
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12614333&lt;/p&gt;</comment>
                            <comment id="13825170" author="navis" created="Mon, 18 Nov 2013 08:17:59 +0000"  >&lt;p&gt;missed DummyStatsAggregator&lt;/p&gt;</comment>
                            <comment id="13825175" author="phabricator@reviews.facebook.net" created="Mon, 18 Nov 2013 08:27:20 +0000"  >&lt;p&gt;ashutoshc has requested changes to the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4632&quot; title=&quot;Use hadoop counter as a stat publisher&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4632&quot;&gt;&lt;del&gt;HIVE-4632&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Use hadoop counter as a stat publisher&quot;.&lt;/p&gt;

&lt;p&gt;  Thanks for making changes. Lets also have counter as default in HiveConf.java&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java:606 As I said on jira, lets have counter as default.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11001&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11001&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4632&quot; title=&quot;Use hadoop counter as a stat publisher&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4632&quot;&gt;&lt;del&gt;HIVE-4632&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;br/&gt;
Cc: ashutoshc&lt;/p&gt;</comment>
                            <comment id="13825189" author="navis" created="Mon, 18 Nov 2013 08:47:05 +0000"  >&lt;p&gt;Changed default value. Ubuntu makes me dizzy after upgrading to 12.04.&lt;/p&gt;</comment>
                            <comment id="13825416" author="hiveqa" created="Mon, 18 Nov 2013 15:58:06 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12614357/HIVE-4632.6.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12614357/HIVE-4632.6.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 27 failed/errored test(s), 4609 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats19
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_aggregator_error_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_publisher_error_1
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_stats_aggregator_error_1
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_stats_aggregator_error_2
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_stats_publisher_error_1
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_stats_publisher_error_2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_case_sensitivity
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input7
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input9
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testsequencefile
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample7
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/339/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/339/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/339/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/339/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 27 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12614357&lt;/p&gt;</comment>
                            <comment id="13825479" author="ashutoshc" created="Mon, 18 Nov 2013 17:03:22 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13826232" author="phabricator@reviews.facebook.net" created="Tue, 19 Nov 2013 06:01:20 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4632&quot; title=&quot;Use hadoop counter as a stat publisher&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4632&quot;&gt;&lt;del&gt;HIVE-4632&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Use hadoop counter as a stat publisher&quot;.&lt;/p&gt;

&lt;p&gt;  1. Fixed tests&lt;br/&gt;
  2. Made StatsFactory thread-safe&lt;/p&gt;

&lt;p&gt;Reviewers: ashutoshc, JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11001&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11001&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11001?vs=43839&amp;amp;id=43989#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11001?vs=43839&amp;amp;id=43989#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/common/StatsSetupConst.java&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;br/&gt;
  conf/hive-default.xml.template&lt;br/&gt;
  data/conf/hive-site.xml&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsAggregator.java&lt;br/&gt;
  itests/qtest/pom.xml&lt;br/&gt;
  itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/DummyStatsAggregator.java&lt;br/&gt;
  itests/util/src/main/java/org/apache/hadoop/hive/ql/stats/KeyVerifyingStatsAggregator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/stats/PartialScanTask.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/StatsWork.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/CounterStatsAggregator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/CounterStatsPublisher.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/StatsAggregator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/StatsFactory.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/StatsSetupConst.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsAggregator.java&lt;br/&gt;
  ql/src/test/org/apache/hadoop/hive/ql/exec/TestStatsPublisherEnhanced.java&lt;br/&gt;
  ql/src/test/queries/clientnegative/stats_aggregator_error_1.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/stats_aggregator_error_2.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/stats_publisher_error_1.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/stats_publisher_error_2.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/stats19.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/stats_aggregator_error_1.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/stats_counter.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/stats_publisher_error_1.q&lt;br/&gt;
  ql/src/test/results/clientpositive/stats_aggregator_error_1.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/stats_counter.q.out&lt;br/&gt;
  ql/src/test/results/compiler/plan/case_sensitivity.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/groupby1.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/input1.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/input2.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/input3.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/input4.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/input5.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/input6.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/input7.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/input9.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/input_testsequencefile.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/join1.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/join2.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/join3.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/sample2.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/sample3.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/sample4.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/sample5.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/sample6.q.xml&lt;br/&gt;
  ql/src/test/results/compiler/plan/sample7.q.xml&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;br/&gt;
Cc: ashutoshc&lt;/p&gt;</comment>
                            <comment id="13826234" author="navis" created="Tue, 19 Nov 2013 06:05:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt; Except fixing test results, I&apos;ve changed StatsFactory to be thread-safe, which can be reverted if it&apos;s not good. Could you check that?&lt;/p&gt;</comment>
                            <comment id="13826343" author="ashutoshc" created="Tue, 19 Nov 2013 09:38:29 +0000"  >&lt;p&gt;Looks good to me. +1&lt;/p&gt;</comment>
                            <comment id="13826862" author="hiveqa" created="Tue, 19 Nov 2013 19:40:40 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12614557/HIVE-4632.7.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12614557/HIVE-4632.7.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4617 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/363/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/363/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/363/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/363/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12614557&lt;/p&gt;</comment>
                            <comment id="13826878" author="ashutoshc" created="Tue, 19 Nov 2013 19:58:47 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Navis!&lt;/p&gt;</comment>
                            <comment id="13936390" author="lefty@hortonworks.com" created="Sun, 16 Mar 2014 03:07:40 +0000"  >&lt;p&gt;Updated the wiki for &lt;b&gt;hive.stats.dbclass&lt;/b&gt; and two related parameters (&lt;b&gt;hive.stats.default.publisher&lt;/b&gt; and &lt;b&gt;hive.stats.default.aggregator&lt;/b&gt;):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;hive.stats.dbclass&lt;br/&gt;
Default Value: jdbc:derby (Hive 0.7 to 0.12) or counter (Hive 0.13 and later)&lt;br/&gt;
Added In: Hive 0.7&lt;/p&gt;

&lt;p&gt;Hive 0.7 to 0.12:  The default database that stores temporary Hive statistics.  Other options are jdbc:mysql and hbase as defined in StatsSetupConst.java&lt;br/&gt;
Hive 0.13 and later:  The storage that stores temporary Hive statistics. Supported values are jdbc, hbase, counter and custom (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4632&quot; title=&quot;Use hadoop counter as a stat publisher&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4632&quot;&gt;&lt;del&gt;HIVE-4632&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;hive.stats.default.publisher&lt;br/&gt;
Default Value: (empty)&lt;br/&gt;
Added In: Hive 0.7&lt;/p&gt;

&lt;p&gt;The Java class (implementing the StatsPublisher interface) that is used by default if hive.stats.dbclass is not JDBC or HBase (Hive 0.12.0 and earlier), or if hive.stats.dbclass is a custom type (Hive 0.13.0 and later:  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4632&quot; title=&quot;Use hadoop counter as a stat publisher&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4632&quot;&gt;&lt;del&gt;HIVE-4632&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;hive.stats.default.aggregator&lt;br/&gt;
Default Value: (empty)&lt;br/&gt;
Added In: Hive 0.7&lt;/p&gt;

&lt;p&gt;The Java class (implementing the StatsAggregator interface) that is used by default if hive.stats.dbclass is not JDBC or HBase (Hive 0.12.0 and earlier), or if hive.stats.dbclass is a custom type (Hive 0.13.0 and later:  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4632&quot; title=&quot;Use hadoop counter as a stat publisher&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4632&quot;&gt;&lt;del&gt;HIVE-4632&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Question:  Should the jdbc value for 0.13+ say jdbc:&amp;lt;db_type&amp;gt; or some such?&lt;/p&gt;

&lt;p&gt;Quick ref:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.stats.dbclass&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Configuration Properties:  hive.stats.dbclass  &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.stats.default.publisher&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Configuration Properties:  hive.stats.default.publisher  &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.stats.default.aggregator&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Configuration Properties:  hive.stats.default.aggregator  &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12600866">HIVE-3324</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12649760">HIVE-4621</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12697088">HIVE-6500</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12614333" name="HIVE-4632.4.patch.txt" size="33516" author="navis" created="Mon, 18 Nov 2013 04:32:57 +0000"/>
                            <attachment id="12614353" name="HIVE-4632.5.patch.txt" size="34533" author="navis" created="Mon, 18 Nov 2013 08:18:25 +0000"/>
                            <attachment id="12614357" name="HIVE-4632.6.patch.txt" size="34530" author="navis" created="Mon, 18 Nov 2013 08:47:05 +0000"/>
                            <attachment id="12614557" name="HIVE-4632.7.patch.txt" size="64453" author="navis" created="Tue, 19 Nov 2013 06:02:44 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 30 May 2013 05:51:20 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330414</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 45 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l05b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330748</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4633] MR Jobs execution failed.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4633</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;I am running Hive-0.11.0 + Hadoop-0.23 version. All queries that spawn MR jobs got failed. When I look into logs, below exception is thrown in hive.log&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: Configuration and input path are inconsistent
	at org.apache.hadoop.hive.ql.exec.MapOperator.setChildren(MapOperator.java:522)
	at org.apache.hadoop.hive.ql.exec.ExecMapper.configure(ExecMapper.java:90)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

</description>
                <environment>&lt;p&gt;Hive-0.11.0 + Hadoop-0.23 &lt;/p&gt;</environment>
        <key id="12650141">HIVE-4633</key>
            <summary>MR Jobs execution failed.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="rohithsharma">Rohith Sharma K S</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 May 2013 13:35:25 +0000</created>
                <updated>Fri, 31 May 2013 03:50:23 +0000</updated>
                            <resolved>Fri, 31 May 2013 03:31:19 +0000</resolved>
                                    <version>0.11.0</version>
                                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13670338" author="rohithsharma" created="Thu, 30 May 2013 13:36:55 +0000"  >&lt;p&gt;Complete exception trace is as below&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Diagnostic Messages for this Task:
Error: java.lang.RuntimeException: Error in configuring object
	at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:106)
	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:72)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:130)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:402)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:335)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:154)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:149)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:103)
	... 9 more
Caused by: java.lang.RuntimeException: Error in configuring object
	at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:106)
	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:72)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:130)
	at org.apache.hadoop.mapred.MapRunner.configure(MapRunner.java:38)
	... 14 more
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:103)
	... 17 more
Caused by: java.lang.RuntimeException: Map operator initialization failed
	at org.apache.hadoop.hive.ql.exec.ExecMapper.configure(ExecMapper.java:121)
	... 22 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: Configuration and input path are inconsistent
	at org.apache.hadoop.hive.ql.exec.MapOperator.setChildren(MapOperator.java:522)
	at org.apache.hadoop.hive.ql.exec.ExecMapper.configure(ExecMapper.java:90)
	... 22 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Configuration and input path are inconsistent
	at org.apache.hadoop.hive.q
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13671072" author="navis" created="Fri, 31 May 2013 02:31:14 +0000"  >&lt;p&gt;Could you try patch in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4619&quot; title=&quot;Hive 0.11.0 is not working with pre-cdh3u6 and hadoop-0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4619&quot;&gt;&lt;del&gt;HIVE-4619&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="13671101" author="rohithsharma" created="Fri, 31 May 2013 03:26:47 +0000"  >&lt;p&gt;It is working fine with patch &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I duplicate this defect. &lt;/p&gt;</comment>
                            <comment id="13671106" author="navis" created="Fri, 31 May 2013 03:32:46 +0000"  >&lt;p&gt;I&apos;ve thought this is happening only on pre CDH-u6 version of hadoop. I should update issue description on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4619&quot; title=&quot;Hive 0.11.0 is not working with pre-cdh3u6 and hadoop-0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4619&quot;&gt;&lt;del&gt;HIVE-4619&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13671114" author="rohithsharma" created="Fri, 31 May 2013 03:43:56 +0000"  >&lt;p&gt;Is this fix is from hadoop? The current patch in hive makes continue . I feel handling in hadoop is better.&lt;/p&gt;</comment>
                            <comment id="13671117" author="navis" created="Fri, 31 May 2013 03:50:23 +0000"  >&lt;p&gt;No it&apos;s not. it&apos;s on MapOperator in hive. Some hadoop versions remove scheme from path while making splits. &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4619&quot; title=&quot;Hive 0.11.0 is not working with pre-cdh3u6 and hadoop-0.23&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4619&quot;&gt;&lt;del&gt;HIVE-4619&lt;/del&gt;&lt;/a&gt; is mend for that.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12649639">HIVE-4619</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 31 May 2013 02:31:14 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330468</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 34 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l0hb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330802</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4634] Add hasNull flag to ORC index</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4634</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;It would help the predicate pushdown, if the index recorded whether each 10k rows had null values in that column.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650168">HIVE-4634</key>
            <summary>Add hasNull flag to ORC index</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="owen.omalley">Owen O&apos;Malley</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 May 2013 16:16:09 +0000</created>
                <updated>Tue, 4 Jun 2013 22:01:17 +0000</updated>
                            <resolved>Tue, 4 Jun 2013 22:01:17 +0000</resolved>
                                                                    <component>File Formats</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13675321" author="prasanth_j" created="Tue, 4 Jun 2013 22:01:17 +0000"  >&lt;p&gt;Duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4639&quot; title=&quot;Add has null flag to ORC internal index&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4639&quot;&gt;&lt;del&gt;HIVE-4639&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 4 Jun 2013 22:01:17 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330495</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 33 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l0nb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330829</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4635] Invalid query parsing when handling order by on an aliased column</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4635</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Assuming simple table src1, src2:&lt;/p&gt;

&lt;p&gt;create table src1 (key int, value string);&lt;br/&gt;
create table src2 (key int, value string);&lt;/p&gt;

&lt;p&gt;Ordering by s2.key gives an error:&lt;/p&gt;

&lt;p&gt;hive&amp;gt;SELECT s2.key, count(distinct s2.value) as cnt FROM src1 s1 join src2 s2 on (s1.key = s2.key) GROUP BY s2.key ORDER BY s2.key;&lt;br/&gt;
FAILED: SemanticException &lt;span class=&quot;error&quot;&gt;&amp;#91;Error 10004&amp;#93;&lt;/span&gt;: Line 1:117 Invalid table alias or column reference &apos;s2&apos;: (possible column names are: key, cnt)&lt;/p&gt;

&lt;p&gt;Ordering by key allows the hive query to run. &lt;/p&gt;

&lt;p&gt;However, if I select both s1.key and s2.key:&lt;/p&gt;

&lt;p&gt;hive&amp;gt; SELECT s1.key, s2.key, count(distinct s2.value) as cnt FROM src1 s1 join src2 s2 on (s1.key = s2.key) GROUP BY s2.key, s1.key ORDER BY s2.key; &lt;br/&gt;
FAILED: SemanticException &lt;span class=&quot;error&quot;&gt;&amp;#91;Error 10004&amp;#93;&lt;/span&gt;: Line 1:133 Invalid table alias or column reference &apos;s2&apos;: (possible column names are: key, cnt)&lt;/p&gt;

&lt;p&gt;Ordering by key in the above scenario allows the job to run but there is no indication which column is actually being used to order the results. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12650246">HIVE-4635</key>
            <summary>Invalid query parsing when handling order by on an aliased column</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="hitesh">Hitesh Shah</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 May 2013 23:22:03 +0000</created>
                <updated>Thu, 30 May 2013 23:22:03 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330573</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 34 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l14n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330907</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4636] Failing on TestSemanticAnalysis.testAddReplaceCols in trunk</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4636</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Seemed regression from &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4475&quot; title=&quot;Switch RCFile default to LazyBinaryColumnarSerDe&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4475&quot;&gt;&lt;del&gt;HIVE-4475&lt;/del&gt;&lt;/a&gt;. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12650267">HIVE-4636</key>
            <summary>Failing on TestSemanticAnalysis.testAddReplaceCols in trunk</summary>
                <type id="6" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/requirement.png">Test</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.svg">Trivial</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis</assignee>
                                    <reporter username="navis">Navis</reporter>
                        <labels>
                    </labels>
                <created>Fri, 31 May 2013 03:19:57 +0000</created>
                <updated>Tue, 15 Oct 2013 23:29:17 +0000</updated>
                            <resolved>Mon, 3 Jun 2013 01:37:54 +0000</resolved>
                                    <version>0.12.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Tests</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13671100" author="phabricator@reviews.facebook.net" created="Fri, 31 May 2013 03:23:21 +0000"  >&lt;p&gt;navis requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4636&quot; title=&quot;Failing on TestSemanticAnalysis.testAddReplaceCols in trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4636&quot;&gt;&lt;del&gt;HIVE-4636&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Failing on TestSemanticAnalysis.testAddReplaceCols in trunk&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4636&quot; title=&quot;Failing on TestSemanticAnalysis.testAddReplaceCols in trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4636&quot;&gt;&lt;del&gt;HIVE-4636&lt;/del&gt;&lt;/a&gt; Failing on TestSemanticAnalysis.testAddReplaceCols in trunk&lt;/p&gt;

&lt;p&gt;Seemed regression from &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4475&quot; title=&quot;Switch RCFile default to LazyBinaryColumnarSerDe&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4475&quot;&gt;&lt;del&gt;HIVE-4475&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11013&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11013&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  hcatalog/core/src/test/java/org/apache/hcatalog/cli/TestSemanticAnalysis.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/26289/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/26289/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13672752" author="ashutoshc" created="Mon, 3 Jun 2013 01:37:54 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Navis!&lt;/p&gt;</comment>
                            <comment id="13672753" author="phabricator@reviews.facebook.net" created="Mon, 3 Jun 2013 01:38:21 +0000"  >&lt;p&gt;ashutoshc has accepted the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4636&quot; title=&quot;Failing on TestSemanticAnalysis.testAddReplaceCols in trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4636&quot;&gt;&lt;del&gt;HIVE-4636&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Failing on TestSemanticAnalysis.testAddReplaceCols in trunk&quot;.&lt;/p&gt;

&lt;p&gt;  +1&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11013&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11013&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4636&quot; title=&quot;Failing on TestSemanticAnalysis.testAddReplaceCols in trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4636&quot;&gt;&lt;del&gt;HIVE-4636&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;/p&gt;</comment>
                            <comment id="13673607" author="hudson" created="Mon, 3 Jun 2013 21:32:37 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #223 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/223/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/223/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4636&quot; title=&quot;Failing on TestSemanticAnalysis.testAddReplaceCols in trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4636&quot;&gt;&lt;del&gt;HIVE-4636&lt;/del&gt;&lt;/a&gt; : Failing on TestSemanticAnalysis.testAddReplaceCols in trunk (Navis via Ashutosh Chauhan) (Revision 1488824)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1488824&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1488824&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/test/java/org/apache/hcatalog/cli/TestSemanticAnalysis.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13674010" author="hudson" created="Tue, 4 Jun 2013 04:08:09 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2126 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2126/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2126/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4636&quot; title=&quot;Failing on TestSemanticAnalysis.testAddReplaceCols in trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4636&quot;&gt;&lt;del&gt;HIVE-4636&lt;/del&gt;&lt;/a&gt; : Failing on TestSemanticAnalysis.testAddReplaceCols in trunk (Navis via Ashutosh Chauhan) (Revision 1488824)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1488824&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1488824&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/core/src/test/java/org/apache/hcatalog/cli/TestSemanticAnalysis.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13795865" author="ashutoshc" created="Tue, 15 Oct 2013 23:29:17 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12585542" name="HIVE-4636.D11013.1.patch" size="821" author="phabricator@reviews.facebook.net" created="Fri, 31 May 2013 03:23:21 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 31 May 2013 03:23:21 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330594</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l19b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330928</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4637] Fix VectorUDAFSum.txt to honor the expected vector column type</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4637</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;&quot;I think, its a bug in code generation for VectorUDAFSumDouble.&lt;br/&gt;
The template VectorUDAFSum.txt, assumes LongColumnVector for input rather than having it  replaced by code generation.&quot;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650280">HIVE-4637</key>
            <summary>Fix VectorUDAFSum.txt to honor the expected vector column type</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rusanu">Remus Rusanu</assignee>
                                    <reporter username="rusanu">Remus Rusanu</reporter>
                        <labels>
                    </labels>
                <created>Fri, 31 May 2013 06:38:43 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:24 +0000</updated>
                            <resolved>Tue, 4 Jun 2013 18:43:43 +0000</resolved>
                                    <version>vectorization-branch</version>
                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13671525" author="rusanu" created="Fri, 31 May 2013 14:40:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/11579/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11579/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13674692" author="ashutoshc" created="Tue, 4 Jun 2013 18:43:43 +0000"  >&lt;p&gt;Committed to branch. Thanks, Remus!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12585620" name="HIVE-4637.0.patch.txt" size="17386" author="rusanu" created="Fri, 31 May 2013 14:40:49 +0000"/>
                            <attachment id="12586080" name="HIVE-4637.1.patch.txt" size="38811" author="rusanu" created="Tue, 4 Jun 2013 09:31:08 +0000"/>
                            <attachment id="12586083" name="HIVE-4637.2.patch.txt" size="41250" author="rusanu" created="Tue, 4 Jun 2013 09:49:40 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 4 Jun 2013 18:43:43 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330607</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 33 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l1c7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330941</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4638] Thread local PerfLog can get shared by multiple hiveserver2 sessions</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4638</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The PerfLog is accessed as thread local which can be shared by multiple hiveserver2 session, overwriting query runtime information.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650285">HIVE-4638</key>
            <summary>Thread local PerfLog can get shared by multiple hiveserver2 sessions</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="prasadm">Prasad Mujumdar</assignee>
                                    <reporter username="prasadm">Prasad Mujumdar</reporter>
                        <labels>
                    </labels>
                <created>Fri, 31 May 2013 07:45:14 +0000</created>
                <updated>Tue, 15 Oct 2013 23:30:00 +0000</updated>
                            <resolved>Fri, 2 Aug 2013 04:58:54 +0000</resolved>
                                    <version>0.11.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                    <component>HiveServer2</component>
                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13671237" author="prasadm" created="Fri, 31 May 2013 07:51:05 +0000"  >&lt;p&gt;Review request on &lt;a href=&quot;https://reviews.facebook.net/D11019&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11019&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13691021" author="ashutoshc" created="Sat, 22 Jun 2013 02:33:13 +0000"  >&lt;p&gt;I will assume its bit hard to write junit test case for testing concurrency. But was wondering if you thought about writing test case for it. Else, can you provide info on what manual testing you did to verify the fix?&lt;/p&gt;</comment>
                            <comment id="13696202" author="ashutoshc" created="Sat, 29 Jun 2013 21:49:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;Prasad Mujumdar&lt;/a&gt; It will be good to get this in. I just want to make sure you have tested this fix.&lt;/p&gt;</comment>
                            <comment id="13723510" author="prasadm" created="Tue, 30 Jul 2013 07:25:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt; my apologies for missing the comment earlier.&lt;/p&gt;

&lt;p&gt;We found the issue in one of our internal integration tests with Cloudera Manager. The exec hook retrieves the query start time hookContext.getQueryPlan().getQueryStartTime()which sometimes used to return bogus timestamp values. The problem didn&apos;t reproduce with the patch.&lt;/p&gt;</comment>
                            <comment id="13723516" author="ashutoshc" created="Tue, 30 Jul 2013 07:32:44 +0000"  >&lt;p&gt;I see. Can you rebase the patch? Lets get it in.&lt;/p&gt;</comment>
                            <comment id="13723522" author="prasadm" created="Tue, 30 Jul 2013 07:41:01 +0000"  >&lt;p&gt;Rebased patch&lt;/p&gt;</comment>
                            <comment id="13726567" author="ashutoshc" created="Thu, 1 Aug 2013 16:21:23 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13727328" author="ashutoshc" created="Fri, 2 Aug 2013 04:58:54 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Prasad!&lt;/p&gt;</comment>
                            <comment id="13727500" author="hudson" created="Fri, 2 Aug 2013 09:25:14 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #41 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/41/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/41/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4638&quot; title=&quot;Thread local PerfLog can get shared by multiple hiveserver2 sessions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4638&quot;&gt;&lt;del&gt;HIVE-4638&lt;/del&gt;&lt;/a&gt; : Thread local PerfLog can get shared by multiple hiveserver2 sessions (Prasad Mujumdar via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1509544&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1509544&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/log/PerfLogger.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13727539" author="hudson" created="Fri, 2 Aug 2013 10:23:00 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hive-trunk-hadoop1-ptest #113 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/113/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/113/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4638&quot; title=&quot;Thread local PerfLog can get shared by multiple hiveserver2 sessions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4638&quot;&gt;&lt;del&gt;HIVE-4638&lt;/del&gt;&lt;/a&gt; : Thread local PerfLog can get shared by multiple hiveserver2 sessions (Prasad Mujumdar via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1509544&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1509544&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/log/PerfLogger.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13728040" author="hudson" created="Fri, 2 Aug 2013 20:16:14 +0000"  >&lt;p&gt;ABORTED: Integrated in Hive-trunk-hadoop2 #322 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/322/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/322/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4638&quot; title=&quot;Thread local PerfLog can get shared by multiple hiveserver2 sessions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4638&quot;&gt;&lt;del&gt;HIVE-4638&lt;/del&gt;&lt;/a&gt; : Thread local PerfLog can get shared by multiple hiveserver2 sessions (Prasad Mujumdar via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1509544&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1509544&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/log/PerfLogger.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13728423" author="hudson" created="Sat, 3 Aug 2013 03:24:27 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hive-trunk-h0.21 #2240 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2240/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2240/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4638&quot; title=&quot;Thread local PerfLog can get shared by multiple hiveserver2 sessions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4638&quot;&gt;&lt;del&gt;HIVE-4638&lt;/del&gt;&lt;/a&gt; : Thread local PerfLog can get shared by multiple hiveserver2 sessions (Prasad Mujumdar via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1509544&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1509544&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/log/PerfLogger.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13795953" author="ashutoshc" created="Tue, 15 Oct 2013 23:30:00 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12585562" name="HIVE-4638-1.patch" size="4500" author="prasadm" created="Fri, 31 May 2013 07:50:37 +0000"/>
                            <attachment id="12594892" name="HIVE-4638-2.patch" size="4500" author="prasadm" created="Tue, 30 Jul 2013 07:41:01 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 22 Jun 2013 02:33:13 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330612</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l1db:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330946</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4639] Add has null flag to ORC internal index</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4639</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;It would enable more predicate pushdown if we added a flag to the index entry recording if there were any null values in the column for the 10k rows.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650357">HIVE-4639</key>
            <summary>Add has null flag to ORC internal index</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="prasanth_j">Prasanth Jayachandran</assignee>
                                    <reporter username="owen.omalley">Owen O&apos;Malley</reporter>
                        <labels>
                    </labels>
                <created>Fri, 31 May 2013 15:47:39 +0000</created>
                <updated>Thu, 12 Feb 2015 23:40:27 +0000</updated>
                            <resolved>Sat, 10 Jan 2015 00:10:43 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>File Formats</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13675338" author="prasanth_j" created="Tue, 4 Jun 2013 22:12:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;Owen O&apos;Malley&lt;/a&gt;are you working on this issue? If not I can take over this issue.&lt;/p&gt;</comment>
                            <comment id="14267182" author="hiveqa" created="Wed, 7 Jan 2015 02:14:18 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12690444/HIVE-4639.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12690444/HIVE-4639.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 32 failed/errored test(s), 6731 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_alter_merge_orc
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_alter_merge_stats_orc
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_annotate_stats_part
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_annotate_stats_table
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_dynpart_sort_optimization2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_extrapolate_part_stats_full
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_extrapolate_part_stats_partial
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_orc_analyze
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_orc_predicate_pushdown
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_alter_merge_orc
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_alter_merge_stats_orc
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_opt_vectorization
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynpart_sort_optimization2
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_orc_analyze
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorized_ptf
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testCombinationInputFormatWithAcid
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.test1[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.test1[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testReadFormat_0_11[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testReadFormat_0_11[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testStringAndBinaryStatistics[0]
org.apache.hadoop.hive.ql.io.orc.TestOrcFile.testStringAndBinaryStatistics[1]
org.apache.hadoop.hive.ql.io.orc.TestOrcNullOptimization.testColumnsWithNullAndCompression
org.apache.hadoop.hive.ql.io.orc.TestOrcNullOptimization.testMultiStripeWithNull
org.apache.hadoop.hive.ql.io.orc.TestOrcNullOptimization.testMultiStripeWithoutNull
org.apache.hadoop.hive.ql.io.orc.TestOrcSerDeStats.testOrcSerDeStatsComplex
org.apache.hadoop.hive.ql.io.orc.TestOrcSerDeStats.testOrcSerDeStatsComplexOldFormat
org.apache.hadoop.hive.ql.io.orc.TestOrcSerDeStats.testSerdeStatsOldFormat
org.apache.hadoop.hive.ql.io.orc.TestOrcSerDeStats.testStringAndBinaryStatistics
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2274/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2274/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2274/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2274/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2274/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2274/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 32 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12690444 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14268053" author="owen.omalley" created="Wed, 7 Jan 2015 19:20:17 +0000"  >&lt;p&gt;You should encode four values:&lt;br/&gt;
  no_values, all_nulls, some_nulls, no_nulls&lt;/p&gt;

&lt;p&gt;This will allow you to support a richer set of sargs.&lt;/p&gt;</comment>
                            <comment id="14268071" author="gopalv" created="Wed, 7 Jan 2015 19:29:20 +0000"  >&lt;p&gt;Yes, we have that granularity locked up in two states (as a tri-state, now - all_nulls, some_nulls, no_nulls).&lt;/p&gt;

&lt;p&gt;We actually have all_nulls/no_values encoded as &quot;min=null/max=null&quot;. This patch is the &quot;some_nulls/no_nulls&quot; boolean on top of that - though, that information is in somewhat non-obvious detail.&lt;/p&gt;

&lt;p&gt;Another thought occurs, that since we have a whole long stream of IS_PRESENT already, I suspect storing the actual NULL count would be somewhat helpful, if we need to have a heuristic for IS_NULL row-level predicate evaluation for wide de-normalized tables (i.e read filter col first and then avoid creating large vector batches for the rest).&lt;/p&gt;</comment>
                            <comment id="14268099" author="prasanth_j" created="Wed, 7 Jan 2015 19:44:59 +0000"  >&lt;p&gt;As Gopal mentioned, we can infer the other stats from the existing information&lt;br/&gt;
all_nulls -&amp;gt; min = null&lt;br/&gt;
no_nulls -&amp;gt; hasNull = false&lt;br/&gt;
some_nulls -&amp;gt; hasNull = true, min != null&lt;/p&gt;</comment>
                            <comment id="14268678" author="prasanth_j" created="Thu, 8 Jan 2015 01:43:06 +0000"  >&lt;p&gt;Fixes test failures. All of them are file size diffs.&lt;/p&gt;</comment>
                            <comment id="14268884" author="gopalv" created="Thu, 8 Jan 2015 06:27:28 +0000"  >&lt;p&gt;Added this patch to my daily TPC-H 1Tb ETL &amp;amp; reloaded lineitem with the new format.&lt;/p&gt;

&lt;p&gt;Testing &lt;tt&gt;select * from lineitem where l_shipdate is null;&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Before: 66.728 seconds (208774320430 bytes read)&lt;br/&gt;
After: 7.87 seconds  (539046900 bytes read)&lt;/p&gt;

&lt;p&gt;LGTM - +1.&lt;/p&gt;</comment>
                            <comment id="14270348" author="hiveqa" created="Fri, 9 Jan 2015 01:22:17 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12690690/HIVE-4639.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12690690/HIVE-4639.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 8 failed/errored test(s), 6747 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.ql.io.orc.TestOrcNullOptimization.testColumnsWithNullAndCompression
org.apache.hadoop.hive.ql.io.orc.TestOrcNullOptimization.testMultiStripeWithNull
org.apache.hadoop.hive.ql.io.orc.TestOrcNullOptimization.testMultiStripeWithoutNull
org.apache.hadoop.hive.ql.io.orc.TestOrcSerDeStats.testOrcSerDeStatsComplex
org.apache.hadoop.hive.ql.io.orc.TestOrcSerDeStats.testOrcSerDeStatsComplexOldFormat
org.apache.hadoop.hive.ql.io.orc.TestOrcSerDeStats.testSerdeStatsOldFormat
org.apache.hadoop.hive.ql.io.orc.TestOrcSerDeStats.testStringAndBinaryStatistics
org.apache.hive.hcatalog.streaming.TestStreaming.testEndpointConnection
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2296/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2296/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2296/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2296/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2296/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2296/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 8 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12690690 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14270448" author="prasanth_j" created="Fri, 9 Jan 2015 02:40:30 +0000"  >&lt;p&gt;I missed out few test failure diffs in previous patch. Added them in this patch.&lt;/p&gt;</comment>
                            <comment id="14272090" author="hiveqa" created="Fri, 9 Jan 2015 23:45:54 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12691023/HIVE-4639.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12691023/HIVE-4639.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 6747 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_joins
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_optimize_nullscan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2311/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2311/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2311/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2311/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2311/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2311/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12691023 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14272120" author="prasanth_j" created="Sat, 10 Jan 2015 00:10:43 +0000"  >&lt;p&gt;Committed to trunk. Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gopalv&quot; class=&quot;user-hover&quot; rel=&quot;gopalv&quot;&gt;Gopal V&lt;/a&gt; for the review and test run!&lt;/p&gt;</comment>
                            <comment id="14272122" author="gopalv" created="Sat, 10 Jan 2015 00:13:41 +0000"  >&lt;p&gt;for the sake of documentation this does not change the ORC format version (i.e ORC files with hasNull flags can be read by hive-14).&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=leftylev&quot; class=&quot;user-hover&quot; rel=&quot;leftylev&quot;&gt;Lefty Leverenz&lt;/a&gt;: FYI.&lt;/p&gt;</comment>
                            <comment id="14272141" author="lefty@hortonworks.com" created="Sat, 10 Jan 2015 00:25:11 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gopalv&quot; class=&quot;user-hover&quot; rel=&quot;gopalv&quot;&gt;Gopal V&lt;/a&gt;.  I assume that means no documentation is needed, since this is internal and backward-compatible.&lt;/p&gt;</comment>
                            <comment id="14311024" author="lefty@hortonworks.com" created="Sat, 7 Feb 2015 23:57:32 +0000"  >&lt;p&gt;Doc note:  &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasanth_j&quot; class=&quot;user-hover&quot; rel=&quot;prasanth_j&quot;&gt;Prasanth Jayachandran&lt;/a&gt; documented this in the ORC wiki.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ORC#LanguageManualORC-ColumnStatistics&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;ORC &amp;#8211; Column Statistics &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;But it says the hasNull flag is added in 1.2.0 &amp;#8211; shouldn&apos;t that be 1.1.0, since this jira&apos;s fix version is 0.15?&lt;/p&gt;</comment>
                            <comment id="14311026" author="prasanth_j" created="Sun, 8 Feb 2015 00:00:40 +0000"  >&lt;p&gt;Good catch! &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=leftylev&quot; class=&quot;user-hover&quot; rel=&quot;leftylev&quot;&gt;Lefty Leverenz&lt;/a&gt;. Updated the docs!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12763154">HIVE-9188</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12720585">HIVE-7215</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12769229">HIVE-9443</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12690444" name="HIVE-4639.1.patch" size="150823" author="prasanth_j" created="Wed, 7 Jan 2015 00:02:40 +0000"/>
                            <attachment id="12690690" name="HIVE-4639.2.patch" size="279465" author="prasanth_j" created="Thu, 8 Jan 2015 01:43:06 +0000"/>
                            <attachment id="12691023" name="HIVE-4639.3.patch" size="290796" author="prasanth_j" created="Fri, 9 Jan 2015 02:40:30 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 4 Jun 2013 22:12:27 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330684</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 50 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l1tb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331018</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Support for hasNull flag in ORC row group index.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4640] CommonOrcInputFormat should be the default input format for Orc tables.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4640</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;CommonOrcInputFormat should be the default input format for Orc files, so that default orc format tables work with both vectorized and non-vectorized path.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650358">HIVE-4640</key>
            <summary>CommonOrcInputFormat should be the default input format for Orc tables.</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sarvesh.sn">Sarvesh Sakalanaga</assignee>
                                    <reporter username="jnp">Jitendra Nath Pandey</reporter>
                        <labels>
                    </labels>
                <created>Fri, 31 May 2013 15:54:59 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:23 +0000</updated>
                            <resolved>Fri, 7 Jun 2013 19:08:45 +0000</resolved>
                                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13675373" author="sarvesh.sn" created="Tue, 4 Jun 2013 22:49:38 +0000"  >&lt;p&gt;Patch available.&lt;/p&gt;</comment>
                            <comment id="13678323" author="ashutoshc" created="Fri, 7 Jun 2013 19:08:45 +0000"  >&lt;p&gt;Committed to branch. Thanks, Sarvesh!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12586212" name="Hive-4640.0.patch" size="1207" author="sarvesh.sn" created="Tue, 4 Jun 2013 22:49:38 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 4 Jun 2013 22:49:38 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330685</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 33 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l1tj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331019</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4641] Support post execution/fetch hook for HiveServer2</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4641</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Support post execution/fetch hook that is invoked prior to returning results to the client. This can be used to filter results before returning the result set to the client.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650379">HIVE-4641</key>
            <summary>Support post execution/fetch hook for HiveServer2</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="3" iconUrl="https://issues.apache.org/jira/images/icons/statuses/inprogress.png" description="This issue is being actively worked on at the moment by the assignee.">In Progress</status>
                    <statusCategory id="4" key="indeterminate" colorName="yellow"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="shreepadma">Shreepadma Venugopalan</assignee>
                                    <reporter username="shreepadma">Shreepadma Venugopalan</reporter>
                        <labels>
                    </labels>
                <created>Fri, 31 May 2013 18:25:09 +0000</created>
                <updated>Tue, 19 Nov 2013 14:48:58 +0000</updated>
                                                                            <component>HiveServer2</component>
                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13671767" author="cwsteinbach" created="Fri, 31 May 2013 19:38:47 +0000"  >&lt;p&gt;Are row-level ACL&apos;s the motivation for this change?&lt;/p&gt;</comment>
                            <comment id="13676367" author="shreepadma" created="Wed, 5 Jun 2013 21:24:41 +0000"  >&lt;p&gt;Enforcing security on a per row basis could be one use of such a hook. The hook can be used in other ways to apply custom transformations to the result set before returning to the client.&lt;/p&gt;</comment>
                            <comment id="13676402" author="cwsteinbach" created="Wed, 5 Jun 2013 21:57:42 +0000"  >&lt;p&gt;If the main use case is row-level security, then I think we&apos;re better off adding this functionality in a way that makes the additional work visible to the optimizer, e.g. with views.&lt;/p&gt;

&lt;p&gt;I think it would help to provide some more details about the motivation for this patch, possibly including a concrete use-case as well. Thanks.&lt;/p&gt;</comment>
                            <comment id="13676521" author="shreepadma" created="Thu, 6 Jun 2013 00:02:54 +0000"  >&lt;p&gt;This is a general purpose hook and is not specific to any feature. Hive has hooks at various stages of compilation and execution - pre semantic analysis, post semantic analysis, pre execution etc, but misses a post execution/post fetch hook. This JIRA just adds that.&lt;/p&gt;</comment>
                            <comment id="13676588" author="cwsteinbach" created="Thu, 6 Jun 2013 01:36:29 +0000"  >&lt;p&gt;Ok, but can you give me an actual example of something that requires this functionality?&lt;/p&gt;

&lt;p&gt;What kind of information do you plan to make available to the hook?&lt;/p&gt;

&lt;p&gt;I also think we need to be really careful about providing a way for people to mutate the resultset after it has been generated since this work will be done on the server node in a non-distributed fashion.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12679959">SENTRY-67</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 31 May 2013 19:38:47 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330706</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 33 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l1y7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331040</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4642] Implement vectorized RLIKE and REGEXP filter expressions</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4642</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;See title. I will add more details next week. The goal is (a) make this work correctly and (b) optimize it as well as possible, at least for the common cases.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650409">HIVE-4642</key>
            <summary>Implement vectorized RLIKE and REGEXP filter expressions</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="teddy.choi">Teddy Choi</assignee>
                                    <reporter username="ehans">Eric Hanson</reporter>
                        <labels>
                    </labels>
                <created>Fri, 31 May 2013 22:31:10 +0000</created>
                <updated>Fri, 4 Oct 2013 02:17:51 +0000</updated>
                            <resolved>Thu, 3 Oct 2013 16:10:56 +0000</resolved>
                                                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13671867" author="ehans" created="Fri, 31 May 2013 22:32:14 +0000"  >&lt;p&gt;This is for a later milestone, not the first milestone we are stabilizing in June. But we can start now.&lt;/p&gt;</comment>
                            <comment id="13674426" author="teddy.choi" created="Tue, 4 Jun 2013 14:11:22 +0000"  >&lt;p&gt;Here is my draft spec. Please leave a comment.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;The base version can be easily implemented with the basic template and the UDFRegExp class. It will be expensive, and it needs to be optimized more.&lt;/p&gt;

&lt;p&gt;Problem: Regular expression matcher is about 10+ times slower than prefix/suffix matcher(as shown in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4548&quot; title=&quot;Speed up vectorized LIKE filter for special cases abc%, %abc and %abc%&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4548&quot;&gt;&lt;del&gt;HIVE-4548&lt;/del&gt;&lt;/a&gt;). Because the Pattern is already compiled, it&apos;s hard to optimize the Pattern more. Matchers don&apos;t depend on each other, so they are distributable over threads. Also the base version will create new objects per call. These can be implemented more efficiently.&lt;/p&gt;

&lt;p&gt;Goal: Reduce object creations per call, and distribute matching loads over multiple threads.&lt;/p&gt;

&lt;p&gt;Cache and reuse a compiled pattern, a byte buffer, a char buffer, and a UTF-8 decoder as &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4548&quot; title=&quot;Speed up vectorized LIKE filter for special cases abc%, %abc and %abc%&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4548&quot;&gt;&lt;del&gt;HIVE-4548&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Divide matching tasks into groups, and run each group on different thread. Or apply the producer-consumer pattern. If there are enough idle CPU cores, total execution time will be reduced significantly.&lt;/p&gt;

&lt;p&gt;If it is feasible, implement prefix/suffix matchers for further optimization. People may use LIKE filter more for simpler filtering. So these matchers may not be used frequently but will run faster.&lt;/p&gt;</comment>
                            <comment id="13674690" author="ehans" created="Tue, 4 Jun 2013 18:43:08 +0000"  >&lt;p&gt;I think this sounds good except that using multi-threaded parallelism is not a good idea here. We should rely on getting parallelism for large data sets by having multiple splits processed in parallel in different processes. Using file-grain multi-threaded parallelism within a process only for purposes of speeding up RLIKE/REGEXP does not see appropriate. I&apos;d recommend focusing on the fastest operation you can get within a single thread, at least for common patterns, or maybe even all possible patterns.&lt;/p&gt;</comment>
                            <comment id="13675467" author="teddy.choi" created="Wed, 5 Jun 2013 00:26:29 +0000"  >&lt;p&gt;I see. I was not sure about parallelization. I&apos;ll focus in single thread. Thank you for feedback.&lt;/p&gt;</comment>
                            <comment id="13678996" author="teddy.choi" created="Sun, 9 Jun 2013 10:20:49 +0000"  >&lt;p&gt;I found that most methods FilterStringColRegExpStringScalar class are same with FilterStringColLikeStringScalar class of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4548&quot; title=&quot;Speed up vectorized LIKE filter for special cases abc%, %abc and %abc%&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4548&quot;&gt;&lt;del&gt;HIVE-4548&lt;/del&gt;&lt;/a&gt;. So I revised my spec again.&lt;/p&gt;

&lt;div class=&quot;panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;panelContent&quot;&gt;
&lt;p&gt;Create AbstractFilterStringColLikeStringScalar class and move up all methods of FilterStringColLikeStringScalar class except parseSimplePattern() method. Make FilterStringColLikeStringScalar class and FilterStringColRegExpStringScalar class extend AbstractFilterStringColLikeStringScalar class. Implement constructers and parseSimplePattern() method on each class differently.&lt;/p&gt;

&lt;p&gt;The class hierarchy will be;&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;AbstractFilterStringColLikeStringScalar
+ FilterStringColRegExpStringScalar
+ FilterStringColLikeStringScalar
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Evaluate a REGEXP pattern &quot;.&amp;#42;abc&quot; as a LIKE pattern &quot;%abc&quot; where abc contains literal characters only. Also evaluate &quot;abc.&amp;#42;&quot; as &quot;abc%&quot;, &quot;.&amp;#42;abc.&amp;#42;&quot; as &quot;%abc%&quot;, &quot;abc&quot; as &quot;abc&quot;, and others as others.&lt;/p&gt;

&lt;p&gt;Cache a Matcher member instance on AbstractFilterStringColLikeStringScalar class and call Matcher#reset(CharSequence).&lt;/p&gt;

&lt;p&gt;Optimize patterns containing &quot;_&quot;(or &quot;.&quot;) and literal characters only.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13679690" author="ehans" created="Mon, 10 Jun 2013 17:55:35 +0000"  >&lt;p&gt;This sounds good. &lt;/p&gt;

&lt;p&gt;Think about additional common cases for matching such as seeing if a text string is a phone number, email address, or URL. If you can broaden the use cases you accelerate to cover those, that would be a plus. If these are too complicated, you can defer them until later, maybe in a different JIRA.&lt;/p&gt;</comment>
                            <comment id="13682299" author="teddy.choi" created="Thu, 13 Jun 2013 14:46:23 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ehans&quot; class=&quot;user-hover&quot; rel=&quot;ehans&quot;&gt;Eric Hanson&lt;/a&gt;, I read some books and papers about regular expressions. According to &lt;a href=&quot;http://en.wikipedia.org/wiki/Regular_expression#Implementations_and_running_times&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Regular_expression#Implementations_and_running_times&lt;/a&gt; , DFA construction time and backtracking NFA running time are exponential, so they are not good solutions.&lt;/p&gt;

&lt;p&gt;According to &lt;a href=&quot;http://swtch.com/~rsc/regexp/regexp1.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://swtch.com/~rsc/regexp/regexp1.html&lt;/a&gt; and &lt;a href=&quot;http://www.cs.ucdavis.edu/~green/papers/techrept02.pdf&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.cs.ucdavis.edu/~green/papers/techrept02.pdf&lt;/a&gt; , lazy DFA could be a good choice. It&apos;s construction time is O(n ), and its running time is O(m^2*n) at most. If there are enough target strings and they share a similar pattern, then the average running time will become O(n ). So it looks promising.&lt;/p&gt;

&lt;p&gt;It&apos;s hard to find a Java lazy DFA regular expression engine. java.util.regex is traditional NFA, and JRegex is DFA. Jarkta Regex is retired, so is Jarkarta ORO. And others are not updated for years. I&apos;m surprised that it&apos;s hard to find one. So I think it will be good to implement one by myself. Fortunately, it doesn&apos;t seem hard to implement.&lt;/p&gt;

&lt;p&gt;If you know an alternative solution, please let me know it.&lt;/p&gt;</comment>
                            <comment id="13683558" author="ehans" created="Fri, 14 Jun 2013 17:30:30 +0000"  >
&lt;p&gt;This is great that you are learning about regular expression implementation algorithms. If you can come up with an approach that allows you to compile the regular expression once into a good internal format when you build the vectorized FilterStringColRegExpStringScalar class instance, that will be good. Then you can re-use the internal format (say some kind of FA) for each batch. &lt;/p&gt;

&lt;p&gt;Be careful to make sure the common cases are fast. Don&apos;t make the project too big. I am not sure how much time it will take to implement a fully general regexp matcher. If you think you can do it in the next month or two, fine. If it takes longer, maybe you should think of a different approach.&lt;/p&gt;

&lt;p&gt;If it looks like the project will become too big, consider focusing just on common special cases (like matching phone numbers, URLS, email addresses, various number formats, etc.), then use an existing RegExp matcher when the pattern is not one of the limited class of expressions your new code can handle.&lt;/p&gt;</comment>
                            <comment id="13696462" author="teddy.choi" created="Mon, 1 Jul 2013 04:15:47 +0000"  >&lt;p&gt;I wrote draft code. It needs more comments, tests, and refactoring.&lt;/p&gt;

&lt;p&gt;I agree that FA generation will be a heavy job, so I didn&apos;t implemented it. Common phone number patterns are covered with a simple fixed automaton. I will add more simple automata.&lt;/p&gt;

&lt;p&gt;There are already hard coded decisions, and more will come. So I introduced an interface that generalizes decisions. It may reduce performance little bit.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Class hierarchy:&lt;/p&gt;

&lt;p&gt;AbstractFilterStringColLikeStringScalar&lt;br/&gt;
+ FilterStringColLikeStringScalar&lt;br/&gt;
+ FilterStringColRegExpStringScalar&lt;/p&gt;

&lt;p&gt;AbstractFilter...#Checker&lt;br/&gt;
+ AbstractFilter...#BeginChecker&lt;br/&gt;
+ AbstractFilter...#EndChecker&lt;br/&gt;
+ AbstractFilter...#MiddleChecker&lt;br/&gt;
+ AbstractFilter...#NoneChecker&lt;br/&gt;
+ AbstractFilter...#AnyCharChecker&lt;br/&gt;
+ AbstractFilter...#ComplexChecker&lt;br/&gt;
+ FilterStringColRegExpStringScalar#PhoneNumberChecker&lt;/p&gt;

&lt;p&gt;AbstractFilter...#CheckerFactory&lt;br/&gt;
+ Filter...Like...#LikeBeginCheckerFactory&lt;br/&gt;
+ Filter...Like...#LikeEndCheckerFactory&lt;br/&gt;
+ Filter...Like...#LikeMiddleCheckerFactory&lt;br/&gt;
+ Filter...Like...#LikeNoneCheckerFactory&lt;br/&gt;
+ Filter...Like...#LikeAnyCharCheckerFactory&lt;br/&gt;
+ Filter...Like...#LikeComplexCheckerFactory&lt;br/&gt;
+ Filter...RegExp...#RegExpBeginCheckerFactory&lt;br/&gt;
+ Filter...RegExp...#RegExpEndCheckerFactory&lt;br/&gt;
+ Filter...RegExp...#RegExpMiddleCheckerFactory&lt;br/&gt;
+ Filter...RegExp...#RegExpNoneCheckerFactory&lt;br/&gt;
+ Filter...RegExp...#RegExpAnyCharCheckerFactory&lt;br/&gt;
+ Filter...RegExp...#RegExpComplexCheckerFactory&lt;br/&gt;
+ Filter...RegExp...#RegExpPhoneNumberCheckerFactory&lt;/p&gt;</comment>
                            <comment id="13698023" author="teddy.choi" created="Tue, 2 Jul 2013 17:37:14 +0000"  >&lt;p&gt;After applying &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4548&quot; title=&quot;Speed up vectorized LIKE filter for special cases abc%, %abc and %abc%&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4548&quot;&gt;&lt;del&gt;HIVE-4548&lt;/del&gt;&lt;/a&gt;, the previous patch became not available to apply on the vectorization branch. Because both of them change FilterStringColLikeStringScalar.&lt;/p&gt;

&lt;p&gt;This patch is available to apply on the vectorization branch.&lt;/p&gt;</comment>
                            <comment id="13698047" author="teddy.choi" created="Tue, 2 Jul 2013 18:02:16 +0000"  >&lt;p&gt;Review request on &lt;a href=&quot;https://reviews.apache.org/r/12235/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/12235/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13702148" author="ehans" created="Mon, 8 Jul 2013 17:24:42 +0000"  >&lt;p&gt;I will look at this today.&lt;/p&gt;</comment>
                            <comment id="13702302" author="ehans" created="Mon, 8 Jul 2013 19:17:41 +0000"  >&lt;p&gt;Teddy, please see my comments in the code review.&lt;/p&gt;

&lt;p&gt;Also, please either write either a long comment explaining the design in the code, or write a 1 page or so design specification as a Microsoft Word document. We could include that in the design spec attached to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4160&quot; title=&quot;Vectorized Query Execution in Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4160&quot;&gt;&lt;del&gt;HIVE-4160&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13716573" author="ehans" created="Tue, 23 Jul 2013 16:43:14 +0000"  >&lt;p&gt;Hi Teddy, how&apos;s it going with this? When do you think you can finish this up?&lt;/p&gt;</comment>
                            <comment id="13717829" author="teddy.choi" created="Wed, 24 Jul 2013 00:39:24 +0000"  >&lt;p&gt;Hello Eric. I uploaded a patch and I will upload its design specification on today night. It has more detailed comments and tests. It also applies your review. I&apos;m sorry for being late.&lt;/p&gt;</comment>
                            <comment id="13717981" author="hiveqa" created="Wed, 24 Jul 2013 04:59:13 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12593818/HIVE-4642.3.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12593818/HIVE-4642.3.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/160/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/160/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/160/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/160/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.CleanupPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-160/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;hcatalog/src/test/e2e/templeton/README.txt&apos;
Reverted &apos;hcatalog/src/test/e2e/templeton/drivers/TestDriverCurl.pm&apos;
Reverted &apos;hcatalog/src/test/e2e/templeton/build.xml&apos;
Reverted &apos;hcatalog/webhcat/svr/src/main/java/org/apache/hcatalog/templeton/tool/TempletonControllerJob.java&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ awk &apos;{print $2}&apos;
++ svn status --no-ignore
+ rm -rf build hcatalog/build hcatalog/src/test/e2e/templeton/tests/jobsubmission2.conf hcatalog/core/build hcatalog/storage-handlers/hbase/build hcatalog/server-extensions/build hcatalog/webhcat/svr/build hcatalog/webhcat/java-client/build hcatalog/hcatalog-pig-adapter/build common/src/gen
+ svn update
A    ql/src/test/queries/clientpositive/create_view_translate.q
A    ql/src/test/queries/clientpositive/view_cast.q
A    ql/src/test/results/clientpositive/create_view_translate.q.out
A    ql/src/test/results/clientpositive/view_cast.q.out
U    ql/src/java/org/apache/hadoop/hive/ql/parse/UnparseTranslator.java

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
Updated external to revision 1506396.

Updated to revision 1506396.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0 to p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13718319" author="hiveqa" created="Wed, 24 Jul 2013 12:39:17 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12593818/HIVE-4642.3.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12593818/HIVE-4642.3.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/163/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/163/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/163/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/163/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.CleanupPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-163/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;jdbc/src/test/org/apache/hive/jdbc/TestJdbcDriver2.java&apos;
Reverted &apos;jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java&apos;
Reverted &apos;service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/TaskRunner.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistory.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/Driver.java&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ awk &apos;{print $2}&apos;
++ svn status --no-ignore
+ rm -rf build hcatalog/build hcatalog/core/build hcatalog/storage-handlers/hbase/build hcatalog/server-extensions/build hcatalog/webhcat/svr/build hcatalog/webhcat/java-client/build hcatalog/hcatalog-pig-adapter/build common/src/gen
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1506523.

At revision 1506523.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0 to p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13718467" author="teddy.choi" created="Wed, 24 Jul 2013 15:15:48 +0000"  >&lt;p&gt;I wrote &quot;LIKE and REGEXP expressions:&quot; section in &quot;Filter operator&quot;. Following is the added text.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Filter condition expressions&lt;/p&gt;

&lt;p&gt;LIKE and REGEXP expressions:&lt;/p&gt;

&lt;p&gt;LIKE and REGEXP expressions find any strings fitting a pattern. They compile a pattern on creation, and find strings on evaluation.&lt;br/&gt;
Both kinds of expression use the Java regular expression package. REGEXP expressions use the package as it is. But LIKE expressions have different grammar, so they need conversion. &#8220;%&#8221; is converted to &#8220;.*&#8221; and &#8220;_&#8221; is converted to &#8220;.&#8221;. AbstractFilterStringColLikeStringScalar class defines common behaviors. FilterStringColLikeStringScalar class and FilterStringColRegExpStringScalar class implement differences.&lt;br/&gt;
There are simple and frequently used patterns; such as prefix match, suffix match, middle match, exact match, and phone numbers. There are optimized implementations for them. They evaluate using byte arrays directly to avoid UTF-8 decoding load.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This file is edited on Word for Mac 2011, so it may have incompatibilities.&lt;/p&gt;</comment>
                            <comment id="13718539" author="ehans" created="Wed, 24 Jul 2013 16:23:48 +0000"  >&lt;p&gt;Thanks Teddy!&lt;/p&gt;</comment>
                            <comment id="13720059" author="ehans" created="Thu, 25 Jul 2013 21:05:04 +0000"  >&lt;p&gt;+1 &lt;/p&gt;

&lt;p&gt;Looks good. Thanks again, Teddy.&lt;/p&gt;</comment>
                            <comment id="13721516" author="teddy.choi" created="Sat, 27 Jul 2013 04:05:59 +0000"  >&lt;p&gt;My pleasure. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13730354" author="teddy.choi" created="Tue, 6 Aug 2013 05:04:09 +0000"  >&lt;p&gt;4th patch contains the following changes.&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Added code on AbstractFilterStringColLikeStringScalar.java to evaluate child expressions.&lt;/li&gt;
	&lt;li&gt;Removed misleading comments.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13730498" author="hiveqa" created="Tue, 6 Aug 2013 08:07:55 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12596277/HIVE-4642.4.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12596277/HIVE-4642.4.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/322/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/322/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/322/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/322/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-322/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/processors/DfsProcessor.java&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ awk &apos;{print $2}&apos;
++ svn status --no-ignore
+ rm -rf build hcatalog/build hcatalog/core/build hcatalog/storage-handlers/hbase/build hcatalog/server-extensions/build hcatalog/webhcat/svr/build hcatalog/webhcat/java-client/build hcatalog/hcatalog-pig-adapter/build common/src/gen ql/src/test/results/clientpositive/dfscmd.q.out ql/src/test/queries/clientpositive/dfscmd.q
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1510878.

At revision 1510878.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0 to p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13736309" author="teddy.choi" created="Sun, 11 Aug 2013 15:26:32 +0000"  >&lt;p&gt;I uploaded 4th patch with an incorrect contents. This 5th patch corrects it.&lt;/p&gt;</comment>
                            <comment id="13736359" author="hiveqa" created="Sun, 11 Aug 2013 17:52:00 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12597351/HIVE-4642.5.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12597351/HIVE-4642.5.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/391/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/391/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/391/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/391/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-391/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ awk &apos;{print $2}&apos;
++ svn status --no-ignore
+ rm -rf build hcatalog/build hcatalog/core/build hcatalog/storage-handlers/hbase/build hcatalog/server-extensions/build hcatalog/webhcat/svr/build hcatalog/webhcat/java-client/build hcatalog/hcatalog-pig-adapter/build common/src/gen ql/src/test/results/clientpositive/auto_join_reordering_values.q.out ql/src/test/queries/clientpositive/auto_join_reordering_values.q
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1512979.

At revision 1512979.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0 to p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13754249" author="jnp" created="Fri, 30 Aug 2013 00:33:58 +0000"  >&lt;p&gt;Please make these new expressions serializable. &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4959&quot; title=&quot;Vectorized plan generation should be added as an optimization transform.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4959&quot;&gt;&lt;del&gt;HIVE-4959&lt;/del&gt;&lt;/a&gt; changes will mandate that all vectorized expressions are serializable. The VectorExpression class already implements Serializable interface.&lt;/p&gt;</comment>
                            <comment id="13754309" author="teddy.choi" created="Fri, 30 Aug 2013 01:56:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jnp&quot; class=&quot;user-hover&quot; rel=&quot;jnp&quot;&gt;Jitendra Nath Pandey&lt;/a&gt; Okay, I&apos;ll do it soon. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13761243" author="teddy.choi" created="Sun, 8 Sep 2013 09:56:17 +0000"  >&lt;p&gt;Added supports for serialization&lt;/p&gt;</comment>
                            <comment id="13761859" author="hiveqa" created="Mon, 9 Sep 2013 13:56:43 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12602047/HIVE-4642.6.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12602047/HIVE-4642.6.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/671/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/671/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/671/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/671/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-671/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1521111.

At revision 1521111.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0 to p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13770480" author="jnp" created="Wed, 18 Sep 2013 06:10:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=teddy.choi&quot; class=&quot;user-hover&quot; rel=&quot;teddy.choi&quot;&gt;Teddy Choi&lt;/a&gt; Thanks for taking care of the serialization part. I think the patch doesn&apos;t apply because of the recent changes to the branch. Please rebase the patch again.&lt;/p&gt;</comment>
                            <comment id="13778615" author="teddy.choi" created="Thu, 26 Sep 2013 09:56:02 +0000"  >&lt;p&gt;I attach a rebased version of the last patch.&lt;/p&gt;

&lt;p&gt;The problem was that plan serialization does not use setter/getter methods so the checker member variable never gets assigned after deserialization. Now it is assigned on evaluate() method. It passes tests without any misleading errors.&lt;/p&gt;

&lt;p&gt;I wish that this would be the last patch. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/tongue.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13779413" author="hiveqa" created="Thu, 26 Sep 2013 22:56:47 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12605231/HIVE-4642.7.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12605231/HIVE-4642.7.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/920/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/920/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/920/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/920/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-920/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1526730.

At revision 1526730.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0 to p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13780027" author="ehans" created="Fri, 27 Sep 2013 15:46:12 +0000"  >&lt;p&gt;The cleanest way I&apos;ve found is to pull hive, git checkout the &apos;vectorization&apos; branch, create a new branch locally for the patch, say teddy/hive-4642, then create the patch. When it is done and tested, pull vectorization to make it up to date, then merge vectorization into your work branch. Finally, diff the head of the two branches. E.g.&lt;/p&gt;

&lt;p&gt;git checkout vectorization&lt;br/&gt;
git checkout -b teddy/hive-4642&lt;br/&gt;
... work ...&lt;br/&gt;
git commit -m &quot;...&quot;&lt;br/&gt;
git checkout vectorization&lt;br/&gt;
git pull vectorization&lt;br/&gt;
git checkout teddy/hive-4642&lt;br/&gt;
git merge vectorization&lt;br/&gt;
git diff vectorization teddy/hive-4642 &amp;gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4642&quot; title=&quot;Implement vectorized RLIKE and REGEXP filter expressions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4642&quot;&gt;&lt;del&gt;HIVE-4642&lt;/del&gt;&lt;/a&gt;.n-vectorization.patch &lt;br/&gt;
  (where n is a serial number for the patch like 1, 2. 3 ...)&lt;/p&gt;

&lt;p&gt;Then upload the patch to the JIRA. The naming convention using n-branch_name in the patch name allows the automated tester to try to apply your patch to the correct branch. The workflow above makes it likely the patch will apply correctly to the vectorization branch.&lt;/p&gt;</comment>
                            <comment id="13780030" author="ehans" created="Fri, 27 Sep 2013 15:48:32 +0000"  >&lt;p&gt;Correction, need to pull vectorization first  before creating your work branch.&lt;/p&gt;

&lt;p&gt; git checkout vectorization&lt;br/&gt;
 git pull&lt;br/&gt;
 git checkout -b teddy/hive-4642&lt;br/&gt;
 ... work ...&lt;br/&gt;
 git commit -m &quot;...&quot;&lt;br/&gt;
 git checkout vectorization&lt;br/&gt;
 git pull vectorization&lt;br/&gt;
 git checkout teddy/hive-4642&lt;br/&gt;
 git merge vectorization&lt;br/&gt;
 git diff vectorization teddy/hive-4642 &amp;gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4642&quot; title=&quot;Implement vectorized RLIKE and REGEXP filter expressions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4642&quot;&gt;&lt;del&gt;HIVE-4642&lt;/del&gt;&lt;/a&gt;.n-vectorization.patch &lt;/p&gt;</comment>
                            <comment id="13780153" author="teddy.choi" created="Fri, 27 Sep 2013 17:51:44 +0000"  >&lt;p&gt;Sorry. My branch was not clean, it was merged. I should be more careful.&lt;/p&gt;

&lt;p&gt;My new patch is from a clean branch, so it must not have any problems.&lt;/p&gt;</comment>
                            <comment id="13780522" author="hiveqa" created="Fri, 27 Sep 2013 22:39:32 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12605494/HIVE-4642.8-vectorization.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12605494/HIVE-4642.8-vectorization.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 6 failed/errored test(s), 4053 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hcatalog.api.TestHCatClient.testBasicDDLCommands
org.apache.hive.hcatalog.fileformats.TestOrcDynamicPartitioned.testHCatDynamicPartitionedTable
org.apache.hive.hcatalog.fileformats.TestOrcDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask
org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask
org.apache.hive.hcatalog.mapreduce.TestHCatHiveCompatibility.testUnpartedReadWrite
org.apache.hive.hcatalog.pig.TestOrcHCatLoaderComplexSchema.testTupleInBagInTupleInBag
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/938/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/938/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/938/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/938/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 6 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13780600" author="hiveqa" created="Sat, 28 Sep 2013 00:08:56 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12605494/HIVE-4642.8-vectorization.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12605494/HIVE-4642.8-vectorization.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 4053 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_bucket_num_reducers
org.apache.hive.hcatalog.fileformats.TestOrcDynamicPartitioned.testHCatDynamicPartitionedTable
org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask
org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/939/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/939/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/939/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/939/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13780640" author="teddy.choi" created="Sat, 28 Sep 2013 01:35:03 +0000"  >&lt;p&gt;I&apos;m suspicious of that those errors are from this patch. Because they don&apos;t use LIKE/REGEXP functions.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5380&quot; title=&quot;Non-default OI constructors should be supported for backwards compatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5380&quot;&gt;&lt;del&gt;HIVE-5380&lt;/del&gt;&lt;/a&gt; fails org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_bucket_num_reducers&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5199&quot; title=&quot;Custom SerDe containing a nonSettable complex data type row object inspector throws cast exception with HIVE 0.11&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5199&quot;&gt;&lt;del&gt;HIVE-5199&lt;/del&gt;&lt;/a&gt; fails org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;If I missed something, please tell me.&lt;/p&gt;</comment>
                            <comment id="13781992" author="ehans" created="Mon, 30 Sep 2013 16:38:53 +0000"  >&lt;p&gt;I agree, it looks like the tests that failed are not related to your patch.&lt;/p&gt;</comment>
                            <comment id="13783648" author="jnp" created="Wed, 2 Oct 2013 04:57:08 +0000"  >&lt;p&gt;+1 for the patch.&lt;br/&gt;
However, the vectorization work is now committed to trunk. Please rebase the patch against trunk. All vectorization work is now happening directly on trunk.&lt;/p&gt;</comment>
                            <comment id="13784588" author="ashutoshc" created="Wed, 2 Oct 2013 22:53:52 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13785307" author="ashutoshc" created="Thu, 3 Oct 2013 16:10:56 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Teddy!&lt;/p&gt;</comment>
                            <comment id="13785647" author="hudson" created="Thu, 3 Oct 2013 23:08:35 +0000"  >&lt;p&gt;ABORTED: Integrated in Hive-trunk-h0.21 #2377 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2377/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2377/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4642&quot; title=&quot;Implement vectorized RLIKE and REGEXP filter expressions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4642&quot;&gt;&lt;del&gt;HIVE-4642&lt;/del&gt;&lt;/a&gt; : Implement vectorized RLIKE and REGEXP filter expressions (Teddy Choi via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1528917&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1528917&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/AbstractFilterStringColLikeStringScalar.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/FilterStringColLikeStringScalar.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/FilterStringColRegExpStringScalar.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/expressions/TestVectorStringExpressions.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13785648" author="hudson" created="Thu, 3 Oct 2013 23:08:35 +0000"  >&lt;p&gt;ABORTED: Integrated in Hive-trunk-hadoop2 #473 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/473/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/473/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4642&quot; title=&quot;Implement vectorized RLIKE and REGEXP filter expressions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4642&quot;&gt;&lt;del&gt;HIVE-4642&lt;/del&gt;&lt;/a&gt; : Implement vectorized RLIKE and REGEXP filter expressions (Teddy Choi via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1528917&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1528917&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/AbstractFilterStringColLikeStringScalar.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/FilterStringColLikeStringScalar.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/FilterStringColRegExpStringScalar.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/expressions/TestVectorStringExpressions.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13785659" author="hudson" created="Thu, 3 Oct 2013 23:08:39 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #123 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/123/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/123/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4642&quot; title=&quot;Implement vectorized RLIKE and REGEXP filter expressions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4642&quot;&gt;&lt;del&gt;HIVE-4642&lt;/del&gt;&lt;/a&gt; : Implement vectorized RLIKE and REGEXP filter expressions (Teddy Choi via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1528917&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1528917&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/AbstractFilterStringColLikeStringScalar.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/FilterStringColLikeStringScalar.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/FilterStringColRegExpStringScalar.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/expressions/TestVectorStringExpressions.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13785839" author="hudson" created="Fri, 4 Oct 2013 02:17:51 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hive-trunk-hadoop1-ptest #189 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/189/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/189/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4642&quot; title=&quot;Implement vectorized RLIKE and REGEXP filter expressions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4642&quot;&gt;&lt;del&gt;HIVE-4642&lt;/del&gt;&lt;/a&gt; : Implement vectorized RLIKE and REGEXP filter expressions (Teddy Choi via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1528917&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1528917&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/AbstractFilterStringColLikeStringScalar.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/FilterStringColLikeStringScalar.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/FilterStringColRegExpStringScalar.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/expressions/TestVectorStringExpressions.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12660154">HIVE-4945</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12590223" name="HIVE-4642-1.patch" size="35940" author="teddy.choi" created="Mon, 1 Jul 2013 04:15:47 +0000"/>
                            <attachment id="12590470" name="HIVE-4642.2.patch" size="48623" author="teddy.choi" created="Tue, 2 Jul 2013 17:37:14 +0000"/>
                            <attachment id="12593818" name="HIVE-4642.3.patch.txt" size="48073" author="teddy.choi" created="Wed, 24 Jul 2013 00:36:39 +0000"/>
                            <attachment id="12596277" name="HIVE-4642.4.patch.txt" size="29672" author="teddy.choi" created="Tue, 6 Aug 2013 05:04:09 +0000"/>
                            <attachment id="12597351" name="HIVE-4642.5.patch.txt" size="48017" author="teddy.choi" created="Sun, 11 Aug 2013 15:26:32 +0000"/>
                            <attachment id="12602047" name="HIVE-4642.6.patch.txt" size="45301" author="teddy.choi" created="Sun, 8 Sep 2013 09:56:17 +0000"/>
                            <attachment id="12605231" name="HIVE-4642.7.patch.txt" size="49987" author="teddy.choi" created="Thu, 26 Sep 2013 09:56:02 +0000"/>
                            <attachment id="12605494" name="HIVE-4642.8-vectorization.patch" size="40595" author="teddy.choi" created="Fri, 27 Sep 2013 17:52:44 +0000"/>
                            <attachment id="12605486" name="HIVE-4642.8.patch.txt" size="40595" author="teddy.choi" created="Fri, 27 Sep 2013 17:43:44 +0000"/>
                            <attachment id="12593958" name="Hive-Vectorized-Query-Execution-Design-rev10.docx" size="50759" author="teddy.choi" created="Wed, 24 Jul 2013 15:15:48 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>10.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 4 Jun 2013 14:11:22 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330736</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 16 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l24n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331069</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4643] HCatalog test TestSemanticAnalysis is failing on trunk</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4643</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Also reported in hudson builds: &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2124/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2124/console&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650518">HIVE-4643</key>
            <summary>HCatalog test TestSemanticAnalysis is failing on trunk</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ashutoshc">Ashutosh Chauhan</reporter>
                        <labels>
                    </labels>
                <created>Sun, 2 Jun 2013 17:03:36 +0000</created>
                <updated>Sun, 2 Jun 2013 23:58:00 +0000</updated>
                            <resolved>Sun, 2 Jun 2013 23:58:00 +0000</resolved>
                                    <version>0.12.0</version>
                                                    <component>HCatalog</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13672728" author="ashutoshc" created="Sun, 2 Jun 2013 23:58:00 +0000"  >&lt;p&gt;Dupe of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4636&quot; title=&quot;Failing on TestSemanticAnalysis.testAddReplaceCols in trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4636&quot;&gt;&lt;del&gt;HIVE-4636&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330845</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 34 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l2sv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331178</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4644] Access Multiple HBase clusters&apos; tables simultaneously</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4644</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Right now it doesn&apos;t seem possible to simultaneously access multiple HBase clusters in Hive. The best workaround I&apos;ve been able to come up with in Hive and BeeLine is:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;set hbase.zookeeper.quorum=cluster2-zookeeper-host;
select count(*) from hbase2_test;

set hbase.zookeeper.quorum=cluster1-zookeeper-host;
select count(*) from hbase1_test;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But I&apos;m not sure I can use the hbase.zookeeper.quorum override in JDBC in HiveServer2, at least I haven&apos;t seen any example code for config overrides.&lt;/p&gt;

&lt;p&gt;This workaround is also non-ideal and doesn&apos;t allow for simultaneous access to different HBase clusters. So I&apos;ve tried fiddling with SerDe, Table and Schema level properties to set hbase.zookeeper.quorum overrides on a per table or per schema basis but that didn&apos;t work.&lt;/p&gt;

&lt;p&gt;I think if the code can be made to respect those properties it would represent the best way of handling this in future, eg:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;create database cluster2 WITH DBPROPERTIES (&lt;span class=&quot;code-quote&quot;&gt;&quot;hbase.zookeeper.quorum&quot;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&quot;cluster2-zookeeper-host&quot;&lt;/span&gt;);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;would allow creation of tables in cluster2 database referencing the second HBase cluster.&lt;/p&gt;

&lt;p&gt;I&apos;ve over-simplified here with one zookeeper host in the quorum just for brevity.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650525">HIVE-4644</key>
            <summary>Access Multiple HBase clusters&apos; tables simultaneously</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="harisekhon">Hari Sekhon</reporter>
                        <labels>
                    </labels>
                <created>Sun, 2 Jun 2013 18:25:12 +0000</created>
                <updated>Sun, 2 Jun 2013 18:28:48 +0000</updated>
                                            <version>0.10.0</version>
                                                    <component>Database/Schema</component>
                    <component>HiveServer2</component>
                    <component>Metastore</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330852</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 34 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l2uf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331185</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4645] Stat information like numFiles and totalSize is not correct when sub-directory is exists</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4645</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The test &quot;infer_bucket_sort_list_bucket.q&quot; returns 4096 as totalSize but it&apos;s size of parent directory, not sum of file size.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650563">HIVE-4645</key>
            <summary>Stat information like numFiles and totalSize is not correct when sub-directory is exists</summary>
                <type id="6" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/requirement.png">Test</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.svg">Trivial</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis</assignee>
                                    <reporter username="navis">Navis</reporter>
                        <labels>
                    </labels>
                <created>Mon, 3 Jun 2013 05:51:00 +0000</created>
                <updated>Tue, 15 Oct 2013 23:29:59 +0000</updated>
                            <resolved>Tue, 20 Aug 2013 16:45:26 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Statistics</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13672845" author="phabricator@reviews.facebook.net" created="Mon, 3 Jun 2013 06:02:20 +0000"  >&lt;p&gt;navis requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4645&quot; title=&quot;Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4645&quot;&gt;&lt;del&gt;HIVE-4645&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4645&quot; title=&quot;Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4645&quot;&gt;&lt;del&gt;HIVE-4645&lt;/del&gt;&lt;/a&gt; Stat information like numFiles and totalSize is not correct when sub-directory is exists&lt;/p&gt;

&lt;p&gt;The test &quot;infer_bucket_sort_list_bucket.q&quot; returns 4096 as totalSize but it&apos;s size of parent directory, not sum of file size.&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11037&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11037&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java&lt;br/&gt;
  ql/src/test/results/clientpositive/infer_bucket_sort_list_bucket.q.out&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/26361/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/26361/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13680565" author="brocknoland" created="Tue, 11 Jun 2013 19:13:55 +0000"  >&lt;p&gt;Click &quot;Submit Patch&quot; show this shows up in the patch review queue.&lt;/p&gt;</comment>
                            <comment id="13681897" author="navis" created="Thu, 13 Jun 2013 03:54:13 +0000"  >&lt;p&gt;Passed all tests&lt;/p&gt;</comment>
                            <comment id="13696288" author="ashutoshc" created="Sun, 30 Jun 2013 06:36:38 +0000"  >&lt;p&gt;It seems like there is a bug in Utilities.getFileStatusRecurse() You have avoided that function and wrote a new function. Shouldn&apos;t we just update getFileStatusRecurse so that it does the right thing? That way we squash the root cause of bug, instead of doing local fix.&lt;/p&gt;</comment>
                            <comment id="13697399" author="navis" created="Tue, 2 Jul 2013 01:17:46 +0000"  >&lt;p&gt;I forgot some context but I remember some tests would fail if Utilities.getFileStatusRecurse() is modified. Utilities.getFileStatusRecurse() has various use cases and it seemed hard to track all of them (even it&apos;s only recursing only when path contains trailing &quot;/*&quot;)&lt;/p&gt;</comment>
                            <comment id="13713267" author="navis" created="Fri, 19 Jul 2013 02:17:14 +0000"  >&lt;p&gt;Running test&lt;/p&gt;</comment>
                            <comment id="13713715" author="hiveqa" created="Fri, 19 Jul 2013 14:42:48 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12585802/HIVE-4645.D11037.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12585802/HIVE-4645.D11037.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 all tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/92/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/92/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/92/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/92/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;br/&gt;
Executing org.apache.hive.ptest.execution.CleanupPhase&lt;br/&gt;
Executing org.apache.hive.ptest.execution.PrepPhase&lt;br/&gt;
Executing org.apache.hive.ptest.execution.ExecutionPhase&lt;br/&gt;
Executing org.apache.hive.ptest.execution.ReportingPhase&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13713718" author="appodictic" created="Fri, 19 Jul 2013 14:45:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; Can you add java-doc to the summary method and state the reasons above you created another method.&lt;/p&gt;</comment>
                            <comment id="13715957" author="navis" created="Tue, 23 Jul 2013 01:18:27 +0000"  >&lt;p&gt;Addressing comments, I found this patch could make possibly wrong result for LB. I&apos;ll check that.&lt;/p&gt;</comment>
                            <comment id="13739438" author="phabricator@reviews.facebook.net" created="Wed, 14 Aug 2013 09:12:48 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4645&quot; title=&quot;Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4645&quot;&gt;&lt;del&gt;HIVE-4645&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot;.&lt;/p&gt;

&lt;p&gt;  Fixed more stats on LB&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11037&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11037&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11037?vs=34215&amp;amp;id=37857#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11037?vs=34215&amp;amp;id=37857#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java&lt;br/&gt;
  ql/src/test/results/clientpositive/infer_bucket_sort_list_bucket.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/list_bucket_dml_7.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/list_bucket_dml_8.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13740279" author="hiveqa" created="Wed, 14 Aug 2013 22:14:43 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12597929/HIVE-4645.D11037.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12597929/HIVE-4645.D11037.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 2858 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/438/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/438/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/438/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/438/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13741025" author="phabricator@reviews.facebook.net" created="Thu, 15 Aug 2013 14:53:49 +0000"  >&lt;p&gt;brock has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4645&quot; title=&quot;Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4645&quot;&gt;&lt;del&gt;HIVE-4645&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot;.&lt;/p&gt;

&lt;p&gt;  Navis,&lt;/p&gt;

&lt;p&gt;  This looks good to me!!  I am seeing a failure (for hadoop2) for both the list_bucket_dml_&lt;/p&gt;
{7,8}
&lt;p&gt; tests due to the ordering of results. In both cases it looks like we just need to add an ORDER BY clause to the following:&lt;/p&gt;

&lt;p&gt;  select * from srcpart where ds = &apos;2008-04-08&apos; and key = &apos;484&apos; and value = &apos;val_484&apos;;&lt;/p&gt;

&lt;p&gt;  If you want to do that here that is great. Otherwise we can take it up in a future change.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11037&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11037&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: brock&lt;/p&gt;</comment>
                            <comment id="13741027" author="phabricator@reviews.facebook.net" created="Thu, 15 Aug 2013 14:55:51 +0000"  >&lt;p&gt;brock has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4645&quot; title=&quot;Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4645&quot;&gt;&lt;del&gt;HIVE-4645&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot;.&lt;/p&gt;

&lt;p&gt;  FWIW, here is what I am seeing for list_bucket_dml_7 and list_bucket_dml_8:&lt;/p&gt;

&lt;p&gt;      &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Running: diff -a /home/brock/workspaces/hive-apache/hive/build/ql/test/logs/clientpositive/list_bucket_dml_7.q.out /home/brock/workspaces/hive-apache/hive/ql/src/test/results/clientpositive/list_bucket_dml_7.q.out&lt;br/&gt;
      &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 1079d1078&lt;br/&gt;
      &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;lt; 484	val_484	2008-04-08	11&lt;br/&gt;
      &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 1080a1080&lt;br/&gt;
      &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; 484	val_484	2008-04-08	11&lt;br/&gt;
      &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Exception: Client execution results failed with error code = 1&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11037&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11037&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: brock&lt;/p&gt;</comment>
                            <comment id="13743486" author="phabricator@reviews.facebook.net" created="Mon, 19 Aug 2013 02:25:49 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4645&quot; title=&quot;Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4645&quot;&gt;&lt;del&gt;HIVE-4645&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot;.&lt;/p&gt;

&lt;p&gt;  I cannot reproduce the changes you&apos;ve mentioned, but I suspect it&apos;s from difference of Mac and Linux (ordering of files returned by File.list()). Considered to remove that query but just added order by clause on HR.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11037&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11037&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11037?vs=37857&amp;amp;id=38277#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11037?vs=37857&amp;amp;id=38277#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/list_bucket_dml_7.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/list_bucket_dml_8.q&lt;br/&gt;
  ql/src/test/results/clientpositive/infer_bucket_sort_list_bucket.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/list_bucket_dml_7.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/list_bucket_dml_8.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: brock&lt;/p&gt;</comment>
                            <comment id="13743545" author="hiveqa" created="Mon, 19 Aug 2013 05:38:05 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12598700/HIVE-4645.D11037.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12598700/HIVE-4645.D11037.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 2885 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_noscan_2
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/471/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/471/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/471/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/471/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13743801" author="brocknoland" created="Mon, 19 Aug 2013 13:21:14 +0000"  >&lt;p&gt;Patch looks great but I was able to reproduce stats_noscan_2.q. It looks like it just needs to be updated.&lt;/p&gt;</comment>
                            <comment id="13744095" author="hiveqa" created="Mon, 19 Aug 2013 18:41:43 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12598700/HIVE-4645.D11037.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12598700/HIVE-4645.D11037.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 2885 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_bucket5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats_noscan_2
org.apache.hcatalog.pig.TestHCatLoaderStorer.testSmallTinyInt
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_infer_bucket_sort_reducers_power_two
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/476/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/476/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/476/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/476/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13744626" author="phabricator@reviews.facebook.net" created="Tue, 20 Aug 2013 02:28:52 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4645&quot; title=&quot;Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4645&quot;&gt;&lt;del&gt;HIVE-4645&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot;.&lt;/p&gt;

&lt;p&gt;  Fixed skiping stats aggregation by FileNotFoundException&lt;br/&gt;
  Fixed invalid stats for external tables not on HDFS&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11037&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11037&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11037?vs=38277&amp;amp;id=38397#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11037?vs=38277&amp;amp;id=38397#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/list_bucket_dml_7.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/list_bucket_dml_8.q&lt;br/&gt;
  ql/src/test/results/clientpositive/infer_bucket_sort_list_bucket.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/list_bucket_dml_7.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/list_bucket_dml_8.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/stats_noscan_2.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: brock&lt;/p&gt;</comment>
                            <comment id="13744802" author="hiveqa" created="Tue, 20 Aug 2013 09:08:51 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12598893/HIVE-4645.D11037.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12598893/HIVE-4645.D11037.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 2885 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/484/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/484/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/484/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/484/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13745114" author="brocknoland" created="Tue, 20 Aug 2013 16:45:26 +0000"  >&lt;p&gt;I committed this to trunk! Thank you very much for the contribution!!&lt;/p&gt;</comment>
                            <comment id="13745115" author="phabricator@reviews.facebook.net" created="Tue, 20 Aug 2013 16:46:53 +0000"  >&lt;p&gt;brock has accepted the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4645&quot; title=&quot;Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4645&quot;&gt;&lt;del&gt;HIVE-4645&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot;.&lt;/p&gt;

&lt;p&gt;  Thanks Navis!!&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11037&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11037&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4645&quot; title=&quot;Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4645&quot;&gt;&lt;del&gt;HIVE-4645&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, brock, navis&lt;br/&gt;
Cc: brock&lt;/p&gt;</comment>
                            <comment id="13745300" author="hudson" created="Tue, 20 Aug 2013 19:14:11 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #65 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/65/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/65/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4645&quot; title=&quot;Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4645&quot;&gt;&lt;del&gt;HIVE-4645&lt;/del&gt;&lt;/a&gt;: Stat information like numFiles and totalSize is not correct when sub-directory is exists (Navis via Brock Noland) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1515865&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1515865&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/list_bucket_dml_7.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/list_bucket_dml_8.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/infer_bucket_sort_list_bucket.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/list_bucket_dml_7.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/list_bucket_dml_8.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/stats_noscan_2.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13745413" author="hudson" created="Tue, 20 Aug 2013 20:53:21 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #134 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/134/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/134/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4645&quot; title=&quot;Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4645&quot;&gt;&lt;del&gt;HIVE-4645&lt;/del&gt;&lt;/a&gt;: Stat information like numFiles and totalSize is not correct when sub-directory is exists (Navis via Brock Noland) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1515865&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1515865&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/list_bucket_dml_7.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/list_bucket_dml_8.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/infer_bucket_sort_list_bucket.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/list_bucket_dml_7.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/list_bucket_dml_8.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/stats_noscan_2.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13746001" author="hudson" created="Wed, 21 Aug 2013 12:33:19 +0000"  >&lt;p&gt;ABORTED: Integrated in Hive-trunk-hadoop2 #373 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/373/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/373/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4645&quot; title=&quot;Stat information like numFiles and totalSize is not correct when sub-directory is exists&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4645&quot;&gt;&lt;del&gt;HIVE-4645&lt;/del&gt;&lt;/a&gt;: Stat information like numFiles and totalSize is not correct when sub-directory is exists (Navis via Brock Noland) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1515865&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1515865&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/list_bucket_dml_7.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/list_bucket_dml_8.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/infer_bucket_sort_list_bucket.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/list_bucket_dml_7.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/list_bucket_dml_8.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/stats_noscan_2.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13795951" author="ashutoshc" created="Tue, 15 Oct 2013 23:29:59 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12629407">HIVE-3949</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12585802" name="HIVE-4645.D11037.1.patch" size="4736" author="phabricator@reviews.facebook.net" created="Mon, 3 Jun 2013 06:02:20 +0000"/>
                            <attachment id="12597929" name="HIVE-4645.D11037.2.patch" size="18649" author="phabricator@reviews.facebook.net" created="Wed, 14 Aug 2013 09:12:48 +0000"/>
                            <attachment id="12598700" name="HIVE-4645.D11037.3.patch" size="23520" author="phabricator@reviews.facebook.net" created="Mon, 19 Aug 2013 02:25:49 +0000"/>
                            <attachment id="12598893" name="HIVE-4645.D11037.4.patch" size="24974" author="phabricator@reviews.facebook.net" created="Tue, 20 Aug 2013 02:28:52 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 3 Jun 2013 06:02:20 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330890</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l32v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331223</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4646] skewjoin.q is failing in hadoop2</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4646</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-538&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HDFS-538&lt;/a&gt; changed to throw exception instead of returning null for not-existing path. But skew resolver depends on old behavior.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650572">HIVE-4646</key>
            <summary>skewjoin.q is failing in hadoop2</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12629407">HIVE-3949</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis</assignee>
                                    <reporter username="navis">Navis</reporter>
                        <labels>
                    </labels>
                <created>Mon, 3 Jun 2013 07:38:03 +0000</created>
                <updated>Tue, 15 Oct 2013 23:30:46 +0000</updated>
                            <resolved>Tue, 4 Jun 2013 13:37:20 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13672876" author="phabricator@reviews.facebook.net" created="Mon, 3 Jun 2013 07:42:20 +0000"  >&lt;p&gt;navis requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4646&quot; title=&quot;skewjoin.q is failing in hadoop2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4646&quot;&gt;&lt;del&gt;HIVE-4646&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; skewjoin.q is failing in hadoop2&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4646&quot; title=&quot;skewjoin.q is failing in hadoop2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4646&quot;&gt;&lt;del&gt;HIVE-4646&lt;/del&gt;&lt;/a&gt; skewjoin.q is failing in hadoop2&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-538&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HDFS-538&lt;/a&gt; changed to throw exception instead of returning null for not-existing path. But skew resolver depends on old behavior.&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11043&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11043&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverSkewJoin.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/26367/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/26367/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13673998" author="phabricator@reviews.facebook.net" created="Tue, 4 Jun 2013 03:34:21 +0000"  >&lt;p&gt;ashutoshc has accepted the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4646&quot; title=&quot;skewjoin.q is failing in hadoop2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4646&quot;&gt;&lt;del&gt;HIVE-4646&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; skewjoin.q is failing in hadoop2&quot;.&lt;/p&gt;

&lt;p&gt;  Stuffing this in shim probably is cleaner, but feels like overkill.  utility method is fine too.&lt;br/&gt;
  +1&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11043&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11043&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4646&quot; title=&quot;skewjoin.q is failing in hadoop2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4646&quot;&gt;&lt;del&gt;HIVE-4646&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;/p&gt;</comment>
                            <comment id="13674377" author="ashutoshc" created="Tue, 4 Jun 2013 13:37:20 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Navis!&lt;/p&gt;</comment>
                            <comment id="13675656" author="hudson" created="Wed, 5 Jun 2013 07:16:21 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2128 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2128/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2128/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4646&quot; title=&quot;skewjoin.q is failing in hadoop2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4646&quot;&gt;&lt;del&gt;HIVE-4646&lt;/del&gt;&lt;/a&gt; : skewjoin.q is failing in hadoop2 (Navis via Ashutosh Chauhan) (Revision 1489441)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1489441&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1489441&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/build.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverSkewJoin.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13676475" author="hudson" created="Wed, 5 Jun 2013 23:24:21 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #226 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/226/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/226/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4646&quot; title=&quot;skewjoin.q is failing in hadoop2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4646&quot;&gt;&lt;del&gt;HIVE-4646&lt;/del&gt;&lt;/a&gt; : skewjoin.q is failing in hadoop2 (Navis via Ashutosh Chauhan) (Revision 1489441)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1489441&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1489441&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/build.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverSkewJoin.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13796070" author="ashutoshc" created="Tue, 15 Oct 2013 23:30:46 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12585807" name="HIVE-4646.D11043.1.patch" size="1779" author="phabricator@reviews.facebook.net" created="Mon, 3 Jun 2013 07:42:20 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 3 Jun 2013 07:42:20 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330899</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l34v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331232</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4647] RetryingHMSHandler logs too many error messages</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4647</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;NoSuchObjectException on invocation of methods like getTable/getPartition need not to be logged because it might be normal.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650589">HIVE-4647</key>
            <summary>RetryingHMSHandler logs too many error messages</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.svg">Trivial</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis</assignee>
                                    <reporter username="navis">Navis</reporter>
                        <labels>
                    </labels>
                <created>Mon, 3 Jun 2013 09:06:02 +0000</created>
                <updated>Tue, 15 Oct 2013 23:29:07 +0000</updated>
                            <resolved>Sun, 30 Jun 2013 16:41:29 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13680900" author="phabricator@reviews.facebook.net" created="Wed, 12 Jun 2013 02:12:21 +0000"  >&lt;p&gt;navis requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4647&quot; title=&quot;RetryingHMSHandler logs too many error messages&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4647&quot;&gt;&lt;del&gt;HIVE-4647&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; RetryingHMSHandler logs too many error messages&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4647&quot; title=&quot;RetryingHMSHandler logs too many error messages&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4647&quot;&gt;&lt;del&gt;HIVE-4647&lt;/del&gt;&lt;/a&gt; RetryingHMSHandler logs too many error messages&lt;/p&gt;

&lt;p&gt;NoSuchObjectException on invocation of methods like getTable/getPartition need not to be logged because it might be normal.&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D11235&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D11235&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/RetryingHMSHandler.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/26727/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/26727/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13696290" author="ashutoshc" created="Sun, 30 Jun 2013 06:41:43 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13696368" author="ashutoshc" created="Sun, 30 Jun 2013 16:41:29 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Navis!&lt;/p&gt;</comment>
                            <comment id="13696591" author="hudson" created="Mon, 1 Jul 2013 05:25:49 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2171 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2171/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2171/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4647&quot; title=&quot;RetryingHMSHandler logs too many error messages&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4647&quot;&gt;&lt;del&gt;HIVE-4647&lt;/del&gt;&lt;/a&gt; : RetryingHMSHandler logs too many error messages (Navis via Ashutosh Chauhan) (Revision 1498149)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1498149&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1498149&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/RetryingHMSHandler.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13696735" author="hudson" created="Mon, 1 Jul 2013 11:20:59 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #266 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/266/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/266/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4647&quot; title=&quot;RetryingHMSHandler logs too many error messages&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4647&quot;&gt;&lt;del&gt;HIVE-4647&lt;/del&gt;&lt;/a&gt; : RetryingHMSHandler logs too many error messages (Navis via Ashutosh Chauhan) (Revision 1498149)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1498149&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1498149&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/RetryingHMSHandler.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13795846" author="ashutoshc" created="Tue, 15 Oct 2013 23:29:07 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12587361" name="HIVE-4647.D11235.1.patch" size="1375" author="phabricator@reviews.facebook.net" created="Wed, 12 Jun 2013 02:12:21 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 12 Jun 2013 02:12:21 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>330916</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l38n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331249</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4648] Add ability to set hadoop conf overrides in JDBC for HiveServer2</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4648</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;It&apos;s possible in BeeLine to specify set command overides of hadoop config variables, but I haven&apos;t seen any example code of how to do this in JDBC with HiveServer2.&lt;/p&gt;

&lt;p&gt;We need an ability to specify hadoop conf overrides on a per session basis or even half way through the session. See this Hive ticket for some background:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4644&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-4644&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650681">HIVE-4648</key>
            <summary>Add ability to set hadoop conf overrides in JDBC for HiveServer2</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="8">Not A Problem</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="harisekhon">Hari Sekhon</reporter>
                        <labels>
                    </labels>
                <created>Mon, 3 Jun 2013 16:48:21 +0000</created>
                <updated>Mon, 3 Jun 2013 19:38:03 +0000</updated>
                            <resolved>Mon, 3 Jun 2013 19:16:50 +0000</resolved>
                                    <version>0.10.0</version>
                                                    <component>HiveServer2</component>
                    <component>JDBC</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13673367" author="shreepadma" created="Mon, 3 Jun 2013 17:57:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=harisekhon&quot; class=&quot;user-hover&quot; rel=&quot;harisekhon&quot;&gt;Hari Sekhon&lt;/a&gt;: It is possible to set and unset config variables through JDBC that can be set/unset through the command line. To do so, you&apos;d need to do an execute statement with &quot;set config.var = value&quot;. To set the scratch dir, you can do the following in JDBC,&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;statement.execute(&quot;set hive.exec.scratchdir = /tmp/mydir&quot;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that this property is set for the particular JDBC connection. &lt;/p&gt;</comment>
                            <comment id="13673369" author="shreepadma" created="Mon, 3 Jun 2013 17:58:58 +0000"  >&lt;p&gt;Please note that setting hive.exec.scratchdir is just an example of doing sets through JDBC.&lt;/p&gt;</comment>
                            <comment id="13673473" author="harisekhon" created="Mon, 3 Jun 2013 19:38:03 +0000"  >&lt;p&gt;Thanks. Is there a particular doc that I missed?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 3 Jun 2013 17:57:50 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331008</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 34 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l3t3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331341</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4649] Unit test failure in TestColumnScalarOperationVectorExpressionEvaluation </title>
                <link>https://issues.apache.org/jira/browse/HIVE-4649</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The test fails due to bug in ColumnCompareScalar.txt&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650739">HIVE-4649</key>
            <summary>Unit test failure in TestColumnScalarOperationVectorExpressionEvaluation </summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jnp">Jitendra Nath Pandey</assignee>
                                    <reporter username="jnp">Jitendra Nath Pandey</reporter>
                        <labels>
                    </labels>
                <created>Mon, 3 Jun 2013 21:03:33 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:21 +0000</updated>
                            <resolved>Mon, 3 Jun 2013 21:30:06 +0000</resolved>
                                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13673585" author="jnp" created="Mon, 3 Jun 2013 21:16:57 +0000"  >&lt;p&gt;Attached patch fixes the issue.&lt;/p&gt;</comment>
                            <comment id="13673600" author="ashutoshc" created="Mon, 3 Jun 2013 21:30:06 +0000"  >&lt;p&gt;Committed to branch. Thanks, Jitendra!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12585955" name="HIVE-4649.1.patch" size="30065" author="jnp" created="Mon, 3 Jun 2013 21:16:57 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 3 Jun 2013 21:30:06 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331066</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 34 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l45r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331399</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4650] Getting Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTask on auto convert to MapJoin after upgrade to Hive-0.11.0.x from hive-0.10.0.x</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4650</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;working from a simple table in Hive &lt;/p&gt;

&lt;p&gt;hive&amp;gt; desc cmnt&lt;br/&gt;
    &amp;gt; ;&lt;br/&gt;
OK&lt;br/&gt;
x1                      int                     None                &lt;br/&gt;
x2                      int                     None                &lt;br/&gt;
x3                      int                     None                &lt;br/&gt;
x4                      int                     None                &lt;br/&gt;
y                       double                  None             &lt;/p&gt;

&lt;p&gt;hive&amp;gt; select * from cmnt;&lt;br/&gt;
OK&lt;br/&gt;
7       26      6       60      78.5&lt;br/&gt;
1       29      15      52      74.3&lt;br/&gt;
11      56      8       20      104.3&lt;br/&gt;
11      31      8       47      87.6&lt;br/&gt;
7       52      6       33      95.9&lt;br/&gt;
11      55      9       22      109.2&lt;br/&gt;
3       71      17      6       102.7&lt;br/&gt;
1       31      22      44      72.5&lt;br/&gt;
2       54      18      22      93.1&lt;br/&gt;
21      47      4       26      115.9&lt;br/&gt;
1       40      23      34      83.8&lt;br/&gt;
11      66      9       12      113.3&lt;br/&gt;
10      68      8       12      109.4&lt;/p&gt;

&lt;p&gt;A query that joins and transforms against this table : &lt;/p&gt;

&lt;p&gt;select * from (select VAL001 x1,VAL002 x2,VAL003 x3,VAL004 x4,VAL005 y from ( select /*+ mapjoin(v2) */ (VAL001- mu1) * 1/(sd1) VAL001,(VAL002- mu2) * 1/(sd2) VAL002,(VAL003- mu3) * 1/(sd3) VAL003,(VAL004- mu4) * 1/(sd4) VAL004,(VAL005- mu5) * 1/(sd5) VAL005 from ( select * from ( select x1 VAL001,x2 VAL002,x3 VAL003,x4 VAL004,y VAL005 from cmnt ) obj1_3 ) v3 join (select count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; c, avg(VAL001) mu1,avg(VAL002) mu2,avg(VAL003) mu3,avg(VAL004) mu4,avg(VAL005) mu5, stddev_pop(VAL001) sd1,stddev_pop(VAL002) sd2,stddev_pop(VAL003) sd3,stddev_pop(VAL004) sd4,stddev_pop(VAL005) sd5 from ( select * from ( select x1 VAL001,x2 VAL002,x3 VAL003,x4 VAL004,y VAL005 from cmnt ) obj1_3 ) v1) v2 ) obj1_7) obj1_6 ;&lt;/p&gt;

&lt;p&gt;Generates during Stage-3 : &lt;br/&gt;
setting HADOOP_USER_NAME        test&lt;br/&gt;
Execution log at: /tmp/test/.log&lt;br/&gt;
2013-06-03 12:40:55     Starting to launch local task to process map join;      maximum memory = 1065484288&lt;br/&gt;
2013-06-03 12:40:56     Processing rows:        1       Hashtable size: 1       Memory usage:   7175528   rate:   0.007&lt;br/&gt;
2013-06-03 12:40:56     Dump the hashtable into file: &lt;a href=&quot;file:/tmp/test/hive_2013-06-03_00-40-21_708_6820064283161196136/-local-10003/HashTable-Stage-3/MapJoin-mapfile00--.hashtable&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/tmp/test/hive_2013-06-03_00-40-21_708_6820064283161196136/-local-10003/HashTable-Stage-3/MapJoin-mapfile00--.hashtable&lt;/a&gt;&lt;br/&gt;
2013-06-03 12:40:56     Upload 1 File to: &lt;a href=&quot;file:/tmp/test/hive_2013-06-03_00-40-21_708_6820064283161196136/-local-10003/HashTable-Stage-3/MapJoin-mapfile00--.hashtable&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/tmp/test/hive_2013-06-03_00-40-21_708_6820064283161196136/-local-10003/HashTable-Stage-3/MapJoin-mapfile00--.hashtable&lt;/a&gt; File size: 334&lt;br/&gt;
2013-06-03 12:40:56     End of local task; Time Taken: 0.726 sec.&lt;br/&gt;
Execution completed successfully&lt;br/&gt;
Mapred Local Task Succeeded . Convert the Join into MapJoin&lt;br/&gt;
Mapred Local Task Succeeded . Convert the Join into MapJoin&lt;br/&gt;
Launching Job 2 out of 2&lt;br/&gt;
Number of reduce tasks is set to 0 since there&apos;s no reduce operator&lt;br/&gt;
Starting Job = job_201306022123_0045, Tracking URL = &lt;a href=&quot;http://sun1vm3:50030/jobdetails.jsp?jobid=job_201306022123_0045&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://sun1vm3:50030/jobdetails.jsp?jobid=job_201306022123_0045&lt;/a&gt;&lt;br/&gt;
Kill Command = /usr/lib/hadoop/libexec/../bin/hadoop job  -kill job_201306022123_0045&lt;br/&gt;
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0&lt;br/&gt;
2013-06-03 00:41:05,895 Stage-3 map = 0%,  reduce = 0%&lt;br/&gt;
2013-06-03 00:41:40,687 Stage-3 map = 100%,  reduce = 100%&lt;br/&gt;
Ended Job = job_201306022123_0045 with errors&lt;br/&gt;
Error during job, obtaining debugging information...&lt;br/&gt;
Job Tracking URL: &lt;a href=&quot;http://sun1vm3:50030/jobdetails.jsp?jobid=job_201306022123_0045&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://sun1vm3:50030/jobdetails.jsp?jobid=job_201306022123_0045&lt;/a&gt;&lt;br/&gt;
Examining task ID: task_201306022123_0045_m_000002 (and more) from job job_201306022123_0045&lt;/p&gt;

&lt;p&gt;Task with the most failures(4): &lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Task ID:&lt;br/&gt;
  task_201306022123_0045_m_000000&lt;/p&gt;

&lt;p&gt;URL:&lt;br/&gt;
  &lt;a href=&quot;http://sun1vm3:50030/taskdetails.jsp?jobid=job_201306022123_0045&amp;amp;tipid=task_201306022123_0045_m_000000&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://sun1vm3:50030/taskdetails.jsp?jobid=job_201306022123_0045&amp;amp;tipid=task_201306022123_0045_m_000000&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Diagnostic Messages for this Task:&lt;br/&gt;
java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.ExecMapper.map(ExecMapper.java:162)&lt;br/&gt;
        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)&lt;br/&gt;
        at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:429)&lt;br/&gt;
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:365)&lt;br/&gt;
        at org.apache.hadoop.mapred.Child$4.run(Child.java:255)&lt;br/&gt;
        at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
        at javax.security.auth.Subject.doAs(Subject.java:396)&lt;br/&gt;
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)&lt;br/&gt;
        at org.apache.hadoop.mapred.Child.main(Child.java:249)&lt;br/&gt;
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.MapJoinOperator.loadHashTable(MapJoinOperator.java:198)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.MapJoinOperator.cleanUpInputFileChangedOp(MapJoinOperator.java:212)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1377)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1381)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1381)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:611)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.ExecMapper.map(ExecMapper.java:144)&lt;br/&gt;
        ... 8 more&lt;br/&gt;
Caused by: java.lang.NullPointerException&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.MapJoinOperator.loadHashTable(MapJoinOperator.java:186)&lt;br/&gt;
        ... 14 more&lt;/p&gt;


&lt;p&gt;FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTask&lt;/p&gt;

&lt;p&gt;If &quot;hive.auto.convert.join = false&quot; is set then the all the query stages work OK. The same scenario worked OK in Hive-0.10.0.x and Hive-0.9.x with MapJoin working.&lt;/p&gt;

</description>
                <environment>&lt;p&gt;HortonWorks 1.3 distro on x86_64 Centos 6 &lt;/p&gt;</environment>
        <key id="12650797">HIVE-4650</key>
            <summary>Getting Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTask on auto convert to MapJoin after upgrade to Hive-0.11.0.x from hive-0.10.0.x</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="brucenelson6655">Bruce Nelson</reporter>
                        <labels>
                    </labels>
                <created>Tue, 4 Jun 2013 02:09:51 +0000</created>
                <updated>Thu, 17 Oct 2013 22:01:43 +0000</updated>
                            <resolved>Tue, 23 Jul 2013 00:55:34 +0000</resolved>
                                    <version>0.11.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13673947" author="brucenelson6655" created="Tue, 4 Jun 2013 02:11:04 +0000"  >&lt;p&gt;If &quot;hive.auto.convert.join = false&quot; is set then the all the query stages work OK. The same scenario worked OK in Hive-0.10.0.x and Hive-0.9.x with MapJoin working.&lt;/p&gt;</comment>
                            <comment id="13677618" author="vikram.dixit" created="Thu, 6 Jun 2013 22:42:23 +0000"  >&lt;p&gt;This is related to the issue &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt;. I have verified that the plans generated for this query with the existing patch on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt; look fine. I will close this based on the resolution of that issue.&lt;/p&gt;</comment>
                            <comment id="13678925" author="brucenelson6655" created="Sun, 9 Jun 2013 03:41:06 +0000"  >&lt;p&gt;Vikram : I took a look at JIRA &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt; and Hortonworks hive-0.11.0.1.3.0.0-170 (HWorx 1.3.0) has &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt;-1.patch already applied in the src. I did verify compiling the source and running the May 20th hive-0.11.0 package and the same failure exists. The &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt;.D10695.patch is not possible because of differences in code. I will report this on JIRA &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt; as well. So it appears that 4502 is not a fix for this particular issue.  &lt;/p&gt;</comment>
                            <comment id="13678928" author="brucenelson6655" created="Sun, 9 Jun 2013 03:48:27 +0000"  >&lt;p&gt;Correction - typo on my part its hive-0.11.0.1.3.0.0-107 not *-170&lt;/p&gt;</comment>
                            <comment id="13678958" author="vikram.dixit" created="Sun, 9 Jun 2013 07:04:54 +0000"  >&lt;p&gt;Bruce: I meant the patch &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt;.D10695.patch is the one that fixes the issue. &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt;-1.patch is not going to be the patch for it as it does not fix this case. Those differences that you mention is because of the inherent version differences and will need to be resolved. I have attached the results from a test I ran to verify a case similar to yours.&lt;/p&gt;</comment>
                            <comment id="13678967" author="brucenelson6655" created="Sun, 9 Jun 2013 07:43:21 +0000"  >&lt;p&gt;Vikram:  I was looking at D10695 and I can how it would work - since patch &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt;-1 is already applied to HWORX&apos;s 1.3.0 code I will sharpen my pencil and see what I can do and publish it back to this JIRA. &lt;/p&gt;</comment>
                            <comment id="13678968" author="vikram.dixit" created="Sun, 9 Jun 2013 08:00:20 +0000"  >&lt;p&gt;Bruce,&lt;/p&gt;

&lt;p&gt;I have already done that. Once I have the test results, it will be&lt;br/&gt;
committed.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Vikram.&lt;/p&gt;






&lt;p&gt;&amp;#8211; &lt;br/&gt;
Nothing better than when appreciated for hard work.&lt;br/&gt;
-Mark&lt;/p&gt;</comment>
                            <comment id="13678969" author="vikram.dixit" created="Sun, 9 Jun 2013 08:06:20 +0000"  >&lt;p&gt;Typo. I mean it will be updated.&lt;/p&gt;






&lt;p&gt;&amp;#8211; &lt;br/&gt;
Nothing better than when appreciated for hard work.&lt;br/&gt;
-Mark&lt;/p&gt;</comment>
                            <comment id="13715941" author="ashutoshc" created="Tue, 23 Jul 2013 00:55:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt; has been checked in which is suppose to fix the issue. If you can still reproduce feel free to reopen.&lt;/p&gt;</comment>
                            <comment id="13716002" author="brucenelson6655" created="Tue, 23 Jul 2013 03:04:46 +0000"  >&lt;p&gt;Ashtoush &lt;/p&gt;

&lt;p&gt;Thanks - I was going to write and see if we have a resolution out of 4502. Will we see a patch in Hortonworks on 0.11 - looks like 0.12 will be the fix. &lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;

&lt;p&gt;&amp;#8211; &lt;/p&gt;

&lt;p&gt;Bruce Nelson | Principal Sales Consultant&lt;br/&gt;
Big Data Area Lead West&lt;br/&gt;
Hadoop noSQL Big Data Specialist&lt;br/&gt;
Phone: +1 8188173046 | Mobile: +1 3102667111 &lt;br/&gt;
Oracle North America Technology Organization&lt;br/&gt;
15760 Ventura Boulevard Siute 1400 | Encino, California 91436 &lt;/p&gt;

&lt;p&gt;Oracle is committed to developing practices and products that help protect the environment&lt;/p&gt;

</comment>
                            <comment id="13716019" author="ashutoshc" created="Tue, 23 Jul 2013 03:53:57 +0000"  >&lt;p&gt;Bruce,&lt;br/&gt;
I will encourage you to ask this question on Hortonworks mailing list which is the best place to ask questions about Hortonworks distribution. &lt;br/&gt;
The next apache release of Hive will definitely contain this fix.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12646157">HIVE-4502</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12586931" name="join32_lessSize.q.out" size="10859" author="vikram.dixit" created="Sun, 9 Jun 2013 07:04:54 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 6 Jun 2013 22:42:23 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331124</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 26 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l4in:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331457</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4651] TestVectorGroupByOperator causes asserts in StandardStructObjectInspector.init</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4651</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The number of output columns passed to StandardStructObjectInspector.init must be correct. VGByOp tests that have a GROUP BY key do not set this proper. Assert manifests only when JUnit starts the VM with -ea&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650832">HIVE-4651</key>
            <summary>TestVectorGroupByOperator causes asserts in StandardStructObjectInspector.init</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rusanu">Remus Rusanu</assignee>
                                    <reporter username="rusanu">Remus Rusanu</reporter>
                        <labels>
                    </labels>
                <created>Tue, 4 Jun 2013 07:19:11 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:12 +0000</updated>
                            <resolved>Tue, 4 Jun 2013 18:46:24 +0000</resolved>
                                    <version>vectorization-branch</version>
                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13674131" author="rusanu" created="Tue, 4 Jun 2013 07:22:32 +0000"  >&lt;p&gt;Added dummy _col1 when required&lt;/p&gt;</comment>
                            <comment id="13674185" author="rusanu" created="Tue, 4 Jun 2013 08:50:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/11624/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11624/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13674695" author="ashutoshc" created="Tue, 4 Jun 2013 18:46:24 +0000"  >&lt;p&gt;Committed to branch. Thanks, Remus!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12586063" name="hive-4651.0.patch.txt" size="939" author="rusanu" created="Tue, 4 Jun 2013 07:23:28 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 4 Jun 2013 18:46:24 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331159</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 33 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l4qf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331492</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4652]  VectorHashKeyWrapperBatch.java should be in vector package (instead of exec)</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4652</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;As the title says&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650836">HIVE-4652</key>
            <summary> VectorHashKeyWrapperBatch.java should be in vector package (instead of exec)</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rusanu">Remus Rusanu</assignee>
                                    <reporter username="rusanu">Remus Rusanu</reporter>
                        <labels>
                    </labels>
                <created>Tue, 4 Jun 2013 07:38:15 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:20 +0000</updated>
                            <resolved>Tue, 4 Jun 2013 16:30:16 +0000</resolved>
                                    <version>vectorization-branch</version>
                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13674177" author="rusanu" created="Tue, 4 Jun 2013 08:45:44 +0000"  >&lt;p&gt;Had to mark methods in parent KeyWrapper class as public because of package change of derived class. Methinks KeyWrapper should be an interface not a class.&lt;/p&gt;</comment>
                            <comment id="13674184" author="rusanu" created="Tue, 4 Jun 2013 08:50:32 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/11625/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11625/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13674536" author="ashutoshc" created="Tue, 4 Jun 2013 16:30:16 +0000"  >&lt;p&gt;Committed to branch. Thanks, Remus!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12586072" name="HIVE-4652.0.patch.txt" size="60830" author="rusanu" created="Tue, 4 Jun 2013 08:46:02 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 4 Jun 2013 16:30:16 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331163</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 33 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l4rb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331496</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4653] Favor serde2.io Writable classes over hadoop.io ones</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4653</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;&quot;The Writables are originally from org.apache.hadoop.io. I tend to assume that they have been re-defined in hive if the original implementation was not considered good enough.&lt;br/&gt;
However, I don&apos;t understand why some are defined twice in hive itself. I noticed that ByteWritable in o.a.h.hive.ql.exec is not being used anywhere. The ByteWritable in serde2.io is being referred to in bunch of places. Therefore, I would suggest to just use the one in serde2.io.&quot;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650851">HIVE-4653</key>
            <summary>Favor serde2.io Writable classes over hadoop.io ones</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="rusanu">Remus Rusanu</assignee>
                                    <reporter username="rusanu">Remus Rusanu</reporter>
                        <labels>
                    </labels>
                <created>Tue, 4 Jun 2013 09:52:22 +0000</created>
                <updated>Thu, 6 Jun 2013 08:34:00 +0000</updated>
                            <resolved>Thu, 6 Jun 2013 08:34:00 +0000</resolved>
                                    <version>vectorization-branch</version>
                                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13676838" author="jnp" created="Thu, 6 Jun 2013 08:34:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4665&quot; title=&quot;error at VectorExecMapper.close in group-by-agg query over ORC, vectorized&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4665&quot;&gt;&lt;del&gt;HIVE-4665&lt;/del&gt;&lt;/a&gt; will fix this.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 6 Jun 2013 08:34:00 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331178</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 33 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l4un:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331511</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4654] Remove unused org.apache.hadoop.hive.ql.exec Writables</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4654</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The Writables are originally from org.apache.hadoop.io. I tend to assume that they have been re-defined in hive if the original implementation was not considered good enough.&lt;br/&gt;
However, I don&apos;t understand why some are defined twice in hive itself. I noticed that ByteWritable in o.a.h.hive.ql.exec is not being used anywhere. The ByteWritable in serde2.io is being referred to in bunch of places. Therefore, I would suggest to just use the one in serde2.io. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12650852">HIVE-4654</key>
            <summary>Remove unused org.apache.hadoop.hive.ql.exec Writables</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="rusanu">Remus Rusanu</reporter>
                        <labels>
                    </labels>
                <created>Tue, 4 Jun 2013 09:53:53 +0000</created>
                <updated>Thu, 6 Jun 2013 08:38:06 +0000</updated>
                                                                            <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13676529" author="ehans" created="Thu, 6 Jun 2013 00:12:21 +0000"  >&lt;p&gt;This appears related to some functional bugs. See &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4665&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-4665&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13676842" author="jnp" created="Thu, 6 Jun 2013 08:38:06 +0000"  >&lt;p&gt;I think this is more general than vectorization effort. We should generally remove unused classes.&lt;br/&gt;
I would suggest to remove it from subtasks of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4160&quot; title=&quot;Vectorized Query Execution in Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4160&quot;&gt;&lt;del&gt;HIVE-4160&lt;/del&gt;&lt;/a&gt; and make it a top level bug.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 6 Jun 2013 00:12:21 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331179</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 33 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l4uv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331512</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4655] Vectorization not working with negative constants, hive doesn&apos;t fold constants.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4655</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;  Hive optimizer doesn&apos;t fold the constants, however vectorized code path assumes that constants have been folded. This should be fixed in hive optimizer. &lt;br/&gt;
  In this jira we just fix vectorization path to handle folding for negative constants. This is needed because hive plan treats negative constants as unary-minus expression on constants, therefore these expressions also need constant folding.&lt;br/&gt;
This fix will become redundant once constant folding is appropriately implemented in hive optimizer. (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-746&quot; title=&quot;constant folding&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-746&quot;&gt;HIVE-746&lt;/a&gt;)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650942">HIVE-4655</key>
            <summary>Vectorization not working with negative constants, hive doesn&apos;t fold constants.</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jnp">Jitendra Nath Pandey</assignee>
                                    <reporter username="jnp">Jitendra Nath Pandey</reporter>
                        <labels>
                    </labels>
                <created>Tue, 4 Jun 2013 17:47:12 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:22 +0000</updated>
                            <resolved>Tue, 4 Jun 2013 18:55:56 +0000</resolved>
                                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13675100" author="ehans" created="Tue, 4 Jun 2013 18:53:31 +0000"  >&lt;p&gt;Can you put this on review board please? &lt;/p&gt;</comment>
                            <comment id="13675102" author="ashutoshc" created="Tue, 4 Jun 2013 18:55:56 +0000"  >&lt;p&gt;Committed to branch. Thanks, Jitendra!&lt;/p&gt;</comment>
                            <comment id="13675103" author="jnp" created="Tue, 4 Jun 2013 18:56:20 +0000"  >&lt;p&gt;Review board entry.&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/11634/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11634/&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12586142" name="HIVE-4655.1.patch" size="8322" author="jnp" created="Tue, 4 Jun 2013 18:28:16 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 4 Jun 2013 18:53:31 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331269</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 33 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l5ev:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331602</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4656] Implement vectorized text reader to read vectorized data from Text file </title>
                <link>https://issues.apache.org/jira/browse/HIVE-4656</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Input format and vectorized serde implementation for Text file.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12650995">HIVE-4656</key>
            <summary>Implement vectorized text reader to read vectorized data from Text file </summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png" description="A patch for this issue has been uploaded to JIRA by a contributor.">Patch Available</status>
                    <statusCategory id="4" key="indeterminate" colorName="yellow"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="sarvesh.sn">Sarvesh Sakalanaga</assignee>
                                    <reporter username="sarvesh.sn">Sarvesh Sakalanaga</reporter>
                        <labels>
                    </labels>
                <created>Tue, 4 Jun 2013 21:49:16 +0000</created>
                <updated>Tue, 4 Jun 2013 21:54:19 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13675307" author="sarvesh.sn" created="Tue, 4 Jun 2013 21:51:11 +0000"  >&lt;p&gt;Patch available. &lt;/p&gt;</comment>
                            <comment id="13675311" author="sarvesh.sn" created="Tue, 4 Jun 2013 21:53:24 +0000"  >&lt;p&gt;Review at: &lt;a href=&quot;https://reviews.apache.org/r/11636/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11636/&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12586188" name="Hive-4656.0.patch" size="51557" author="sarvesh.sn" created="Tue, 4 Jun 2013 21:51:11 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331321</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 33 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l5qf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331654</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>
