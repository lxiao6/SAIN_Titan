<!--
RSS generated by JIRA (7.6.3#76005-sha1:8a4e38d34af948780dbf52044e7aafb13a7cae58) at Tue Jan 22 15:12:20 UTC 2019

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<!-- If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
    <channel>
        <title>ASF JIRA</title>
        <link>https://issues.apache.org/jira/issues/?jql=project+%3D+HIVE+AND+created+%3E%3D+2008-11-18+AND+created+%3C%3D+2008-11-25+ORDER+BY+key+ASC</link>
        <description>An XML representation of a search request</description>
                <language>en-uk</language>
                        <issue start="0" end="12" total="12"/>
                <build-info>
            <version>7.6.3</version>
            <build-number>76005</build-number>
            <build-date>09-01-2018</build-date>
        </build-info>

<item>
            <title>[HIVE-67] Short-circuiting of the OR operator doesn&apos;t seem to be happening</title>
                <link>https://issues.apache.org/jira/browse/HIVE-67</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;An example case is&lt;/p&gt;

&lt;p&gt;select t.date from t where t.date = &apos;&apos; or month(t.date) = &apos;12&apos;; &lt;/p&gt;

&lt;p&gt;This still seems to be produce errors like &lt;/p&gt;

&lt;p&gt;java.io.IOException: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to execute method public java.lang.Boolean org.apache.hadoop.hive.ql.udf.UDFBaseCompare.evaluate(java.lang.Number,java.lang.String)  on object org.apache.hadoop.hive.ql.udf.UDFOPEqual@14e0e90 of class org.apache.hadoop.hive.ql.udf.UDFOPEqual with arguments &lt;/p&gt;
{null, 05:java.lang.String}
&lt;p&gt; of size 2:null&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.ExecReducer.reduce(ExecReducer.java:169)&lt;br/&gt;
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:391)&lt;br/&gt;
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2139)&lt;br/&gt;
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to execute method public java.lang.Boolean org.apache.hadoop.hive.ql.udf.UDFBaseCompare.evaluate(java.lang.Number,java.lang.String)  on object org.apache.hadoop.hive.ql.udf.UDFOPEqual@14e0e90 of class org.apache.hadoop.hive.ql.udf.UDFOPEqual with arguments &lt;/p&gt;
{null, 05:java.lang.String}
&lt;p&gt; of size 2:null&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.invoke(FunctionRegistry.java:394)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.ExprNodeFuncEvaluator.evaluate(ExprNodeFuncEvaluator.java:75)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.ExprNodeFuncEvaluator.evaluate(ExprNodeFuncEvaluator.java:72)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.ExprNodeFuncEvaluator.evaluate(ExprNodeFuncEvaluator.java:72)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.ExprNodeFuncEvaluator.evaluate(ExprNodeFuncEvaluator.java:72)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.FilterOperator.process(FilterOperator.java:62)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:260)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.JoinOperator.createForwardJoinObject(JoinOperator.java:257)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.JoinOperator.genObject(JoinOperator.java:477)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.JoinOperator.genObject(JoinOperator.java:467)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.JoinOperator.genObject(JoinOperator.java:467)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.JoinOperator.checkAndGenObject(JoinOperator.java:507)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.JoinOperator.endGroup(JoinOperator.java:489)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.ExecReducer.reduce(ExecReducer.java:140)&lt;br/&gt;
	... 2 more&lt;/p&gt;

&lt;p&gt;nulls are being produced in month(); &lt;br/&gt;
The month() function produces nulls when the string is &apos;&apos;; but those strings should never be touched by month(). &lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;note that this is a faked test case, come talk to me if you need a real example.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;

</description>
                <environment></environment>
        <key id="12408702">HIVE-67</key>
            <summary>Short-circuiting of the OR operator doesn&apos;t seem to be happening</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="5">Cannot Reproduce</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="indigoviolet">Venky Iyer</reporter>
                        <labels>
                    </labels>
                <created>Tue, 18 Nov 2008 02:17:16 +0000</created>
                <updated>Thu, 12 Mar 2009 01:11:19 +0000</updated>
                            <resolved>Thu, 12 Mar 2009 01:11:19 +0000</resolved>
                                                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="12648457" author="zshao" created="Tue, 18 Nov 2008 02:23:11 +0000"  >&lt;p&gt;Right we don&apos;t have short-circuit for OR and AND for now. It should be easy to add though.&lt;br/&gt;
All the changes will be in UDFOPOr and UDFOPAnd.&lt;/p&gt;

&lt;p&gt;I will fix it when I come back in 2 weeks.&lt;/p&gt;

&lt;p&gt;There seems to be another problem with UDFOPEqual. It seems it cannot deal with null values gracefully.&lt;/p&gt;</comment>
                            <comment id="12656800" author="electrum" created="Mon, 15 Dec 2008 23:22:48 +0000"  >&lt;p&gt;This should be resolved &quot;Invalid&quot; as SQL (due to it&apos;s declarative nature) does not define subexpression evaluation order.  For example, see &quot;4.2.12. Expression Evaluation Rules&quot;:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.postgresql.org/docs/8.3/interactive/sql-expressions.html#SYNTAX-EXPRESS-EVAL&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.postgresql.org/docs/8.3/interactive/sql-expressions.html#SYNTAX-EXPRESS-EVAL&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As mentioned at the above link, CASE can be used to force evaluation order when necessary.  Defining evaluation order allows users to write code that is non-standard and invalid with other database systems, causing confusion for readers who are not familiar with this aspect of Hive.  It also ties the optimizer&apos;s hands and eliminates many potential optimizations.&lt;/p&gt;</comment>
                            <comment id="12680971" author="athusoo" created="Wed, 11 Mar 2009 18:35:35 +0000"  >&lt;p&gt;Why is this a blocker?&lt;/p&gt;

&lt;p&gt;There is a work around for this no?&lt;/p&gt;</comment>
                            <comment id="12681029" author="namit" created="Wed, 11 Mar 2009 21:10:50 +0000"  >&lt;p&gt;From the stack trace, it looks like a bug in UDFOPEqual which should be present even if the above query is issued:&lt;/p&gt;

&lt;p&gt;select t.date from t where month(t.date) = &apos;12&apos;;&lt;/p&gt;

&lt;p&gt;I need to verify it - since it looked like a suspect, I marked it as a blocker.&lt;/p&gt;</comment>
                            <comment id="12681127" author="zshao" created="Thu, 12 Mar 2009 01:11:19 +0000"  >&lt;p&gt;I tried 2 similar queries but both of them passed. &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
hive&amp;gt; create table zshao_null_test (a string, b string) stored as textfile;
hive&amp;gt; load data local inpath &lt;span class=&quot;code-quote&quot;&gt;&apos;a&apos;&lt;/span&gt; overwrite into table zshao_null_test;
hive&amp;gt; select * from zshao_null_test;
NULL    NULL
hive&amp;gt; select * from zshao_null_test where a IS NULL;
NULL    NULL
hive&amp;gt; select * from zshao_null_test where a = NULL;

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 18 Nov 2008 02:23:11 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 46 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7nb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121889</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-68] Casting to short not working</title>
                <link>https://issues.apache.org/jira/browse/HIVE-68</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Casting to and from short does not work.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12408703">HIVE-68</key>
            <summary>Casting to short not working</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="athusoo">Ashish Thusoo</assignee>
                                    <reporter username="athusoo">Ashish Thusoo</reporter>
                        <labels>
                    </labels>
                <created>Tue, 18 Nov 2008 02:17:39 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:57 +0000</updated>
                            <resolved>Wed, 19 Nov 2008 01:58:11 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12648456" author="athusoo" created="Tue, 18 Nov 2008 02:18:21 +0000"  >&lt;p&gt;Using cast to cast from or to short gives a null pointer exception. Short is the same as SMALLINT in the language.&lt;/p&gt;</comment>
                            <comment id="12648473" author="athusoo" created="Tue, 18 Nov 2008 03:25:54 +0000"  >&lt;p&gt;Patch uploaded.&lt;/p&gt;</comment>
                            <comment id="12648474" author="athusoo" created="Tue, 18 Nov 2008 03:27:16 +0000"  >&lt;p&gt;submitted patch.&lt;/p&gt;</comment>
                            <comment id="12648475" author="athusoo" created="Tue, 18 Nov 2008 03:28:14 +0000"  >&lt;p&gt;Ran the tests and the tail is as follows:&lt;/p&gt;

&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Test testTBinarySortableProtocol passed!&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; bytes in text =234	firstStringsecondString	firstKey1secondKey2&amp;gt;&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; compare to    =234	firstStringsecondString	firstKey1secondKey2&amp;gt;&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o class = class java.util.ArrayList&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o size = 3&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt; class = class java.lang.Integer&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; class = class java.util.ArrayList&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt; class = class java.util.HashMap&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o = [234, &lt;span class=&quot;error&quot;&gt;&amp;#91;firstString, secondString&amp;#93;&lt;/span&gt;, &lt;/p&gt;
{firstKey=1, secondKey=2}]&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; bytes in text =234	firstStringsecondString	firstKey1secondKey2&amp;gt;&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; compare to    =234	firstStringsecondString	firstKey1secondKey2&amp;gt;&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o class = class java.util.ArrayList&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o size = 3&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o = [234, null, {firstKey=1, secondKey=2}
&lt;p&gt;]&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Tests run: 9, Failures: 0, Errors: 0, Time elapsed: 0.434 sec&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Running org.apache.hadoop.hive.serde2.objectinspector.TestObjectInspectorUtils&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 0.173 sec&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Running org.apache.hadoop.hive.serde2.objectinspector.TestReflectionObjectInspectors&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 0.166 sec&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Running org.apache.hadoop.hive.serde2.objectinspector.TestStandardObjectInspectors&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Tests run: 4, Failures: 0, Errors: 0, Time elapsed: 0.163 sec&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Running org.apache.hadoop.hive.serde2.objectinspector.TestThriftObjectInspectors&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 0.172 sec&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Running org.apache.hadoop.hive.serde2.objectinspector.TestUnionStructObjectInspector&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 0.159 sec&lt;/p&gt;

&lt;p&gt;BUILD SUCCESSFUL&lt;br/&gt;
Total time: 13 minutes 12 seconds&lt;/p&gt;</comment>
                            <comment id="12648696" author="namit" created="Tue, 18 Nov 2008 18:35:36 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="12648876" author="dhruba" created="Wed, 19 Nov 2008 01:58:11 +0000"  >&lt;p&gt;I just committed this. Thanks Ashish!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12394127" name="patch-68.txt" size="24874" author="athusoo" created="Tue, 18 Nov 2008 03:27:16 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 18 Nov 2008 18:35:36 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73806</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 10 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7nj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121890</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-69] genMapRedTasks does not use the tree walker and uses implicit state which makes it difficult to enhance</title>
                <link>https://issues.apache.org/jira/browse/HIVE-69</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;In SemanticAnalyzer, genmapredtasks() does not use a tree walker. For map-side joins, the taskplan needs to be enhanced to be possibly&lt;br/&gt;
broken at MapSink also. Basically, the code is very difficult to enhance since there are implicit assumptions that reduce sink is the only&lt;br/&gt;
operator where the plan breaks.&lt;/p&gt;

&lt;p&gt;This should be enhanced so that the user can implement their own task generation logic which is independent of the tree walking.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12408753">HIVE-69</key>
            <summary>genMapRedTasks does not use the tree walker and uses implicit state which makes it difficult to enhance</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="namit">Namit Jain</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Tue, 18 Nov 2008 18:38:49 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:27 +0000</updated>
                            <resolved>Wed, 3 Dec 2008 02:43:56 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12648792" author="athusoo" created="Tue, 18 Nov 2008 22:59:34 +0000"  >&lt;p&gt;General comment - need a lot of javadocs and documentation of how the state machine works. I think it works correctly but lets document as I have indicated below.&lt;/p&gt;

&lt;p&gt;Also the state should not be maintained in the plan but should be in the treewalker. The state is never really used in the execution time and we should only try to put things that are used in the execution time in the plan.&lt;/p&gt;

&lt;p&gt;Otherwise, this looks much cleaner than the pervious monolithic blob that we had. Thanks...&lt;br/&gt;
Inline Comments&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java:32	Is this just a place holder right now?&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java:112	Lets add proper javadocs!!&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java:132	javadocs. What is this used for?&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/parse/GenMapRedTaskProcessor.java:57	Move the new into the constructor?&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/parse/GenMapRedTaskProcessor.java:1	javadocs needed.&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/parse/GenMapRedTaskProcessor.java:117	Please put a comment on how this state machine works. What are the transitions, how the transitions are made and what are the actions taken by each transition.&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/plan/mapredWork.java:28	This is purely compile time information that is used to generate the plan (cut the plan into multiple map reduce plans), so we should not be storing this in the plan. This seems to be specific to the GenMapRedPlanWalker, so I think we should be maintaining this state there in a hashmap.&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:2986	Looks much cleaner with the walker stuff... This is cool...&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/parse/GenMapRedWalker.java:44	I thought we were going to move this logic into the dispatcher? no?&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/parse/GenMapRedTaskProcessor.java:116	Also a description of the call stack that leads to there transitions would be very helpful.&lt;/p&gt;</comment>
                            <comment id="12648800" author="rsm" created="Tue, 18 Nov 2008 23:11:09 +0000"  >&lt;p&gt;ql/src/java/org/apache/hadoop/hive/ql/parse/GenMapRedTaskProcessor.java:128 As we discussed, this switch statement can be replaced with a more scalable framework for rules. You would then have a tree pattern matcher (actually just a path matcher initially) and a lookup for the associated transformer. With this switch statement code structure, adding a new rule would either mean writing a new visitor (duplicated code) or adding more cases to this switch statement (resulting in huge functions).&lt;/p&gt;</comment>
                            <comment id="12652181" author="namit" created="Mon, 1 Dec 2008 22:10:46 +0000"  >
&lt;p&gt;The following query will not work:&lt;/p&gt;

&lt;p&gt;select count(1) FROM ( select a.x as x from x  UNION  ALL  select b.x as x from b ) out;&lt;/p&gt;

&lt;p&gt;Union followed by reduce sink will not work  - since we have already made the child of reduce sink null.&lt;/p&gt;

&lt;p&gt;It can be easily fixed in the new framework since tree walking/splitting etc. are independent&lt;/p&gt;



</comment>
                            <comment id="12652248" author="athusoo" created="Tue, 2 Dec 2008 02:54:57 +0000"  >&lt;p&gt;Namit,&lt;/p&gt;

&lt;p&gt;Can you upload the patch here. The following are my comments on the latest patch &lt;/p&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;some minor issues are indicated below. Lets create separate JIRAs to address those...&lt;/p&gt;

&lt;p&gt;mostly minor comments.&lt;br/&gt;
Inline Comments&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java:169	should add @Override here.&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java:51	nitpick - start with a capital letter.&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java:112	nitpick - please fix the comment here.&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/parse/DefaultDispatcher.java:26	imported twice?&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/parse/DefaultOpGraphWalker.java:69	should stack be parametrized here?&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/parse/RuleRegExp.java:34	javadocs for all of these...&lt;br/&gt;
hadoop/hive/ql/parse/SemanticAnalyzer.java:2999	These can be packaged into ParseContext.&lt;br/&gt;
hadoop/hive/ql/parse/OperatorProcessor.java:52	Since all the process calls are being made using reflection, we can get rid of all the process functions.&lt;br/&gt;
hadoop/hive/ql/parse/OperatorProcessor.java:40	This can be made an interface instead of a class.&lt;br/&gt;
hadoop/hive/ql/parse/SemanticAnalyzer.java:3035	Ideally this could also be done through a second pass walker, or it could be done in the same walker as above?&lt;br/&gt;
hadoop/hive/ql/parse/RuleRegExp.java:39	Some description would help.&lt;br/&gt;
hadoop/hive/ql/parse/DefaultDispatcher.java:26	double inclusion!!&lt;br/&gt;
hadoop/hive/ql/parse/DefaultDispatcher.java:63	probably this can just be OperatorProcessorContext.class instead of taking the class name and then getting the class out of it.&lt;br/&gt;
hadoop/hive/ql/parse/DefaultRuleDispatcher.java:40	javadocs for each of these variables.&lt;br/&gt;
hadoop/hive/ql/optimizer/GenMRFileSink1.java:37	javadocs&lt;br/&gt;
hadoop/hive/ql/optimizer/GenMRFileSink1.java:68	Why is there a mapping from null to currTask.&lt;br/&gt;
hadoop/hive/ql/optimizer/GenMRFileSink1.java:62	Can you explain what is being done here. In the original SemanticAnalyzer, we were just setting up the dependency from the MR task to move task when we saw the FileSinkOperator. What is the rest of the logic for?&lt;/p&gt;</comment>
                            <comment id="12652644" author="namit" created="Wed, 3 Dec 2008 01:27:08 +0000"  >
&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; compare to    =234  firstString^AsecondString firstKey^D1^AsecondKey^D2&amp;gt;&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o class = class java.util.ArrayList&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o size = 3&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt; class = class java.lang.Integer&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; class = class java.util.ArrayList&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt; class = class java.util.HashMap&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o = [234, &lt;span class=&quot;error&quot;&gt;&amp;#91;firstString, secondString&amp;#93;&lt;/span&gt;, &lt;/p&gt;
{firstKey=1, secondKey=2}]&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; bytes in text =234  firstString^AsecondString firstKey^D1^AsecondKey^D2&amp;gt;&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; compare to    =234  firstString^AsecondString firstKey^D1^AsecondKey^D2&amp;gt;&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o class = class java.util.ArrayList&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o size = 3&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; o = [234, null, {firstKey=1, secondKey=2}
&lt;p&gt;]&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Tests run: 9, Failures: 0, Errors: 0, Time elapsed: 0.498 sec&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Running org.apache.hadoop.hive.serde2.objectinspector.TestObjectInspectorUtils&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 0.191 sec&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Running org.apache.hadoop.hive.serde2.objectinspector.TestReflectionObjectInspectors&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 0.172 sec&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Running org.apache.hadoop.hive.serde2.objectinspector.TestStandardObjectInspectors&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Tests run: 4, Failures: 0, Errors: 0, Time elapsed: 0.175 sec&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Running org.apache.hadoop.hive.serde2.objectinspector.TestThriftObjectInspectors&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 0.181 sec&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Running org.apache.hadoop.hive.serde2.objectinspector.TestUnionStructObjectInspector&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 0.165 sec&lt;/p&gt;

&lt;p&gt;BUILD SUCCESSFUL&lt;br/&gt;
Total time: 15 minutes 27 seconds&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;njain@dev119 trunk&amp;#93;&lt;/span&gt;$ pwd&lt;br/&gt;
/home/njain/workspace/hadoophive/trunk&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;njain@dev119 trunk&amp;#93;&lt;/span&gt;$ svn diff &amp;gt; /tmp/patch.txt&lt;/p&gt;


&lt;p&gt;The tests ran successfully&lt;/p&gt;</comment>
                            <comment id="12652656" author="zshao" created="Wed, 3 Dec 2008 02:43:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-69&quot; title=&quot;genMapRedTasks does not use the tree walker and uses implicit state which makes it difficult to enhance&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-69&quot;&gt;&lt;del&gt;HIVE-69&lt;/del&gt;&lt;/a&gt;. genMapRedTasks uses tree walker. (Namit through zshao)&lt;/p&gt;</comment>
                            <comment id="12652657" author="zshao" created="Wed, 3 Dec 2008 02:44:15 +0000"  >&lt;p&gt;Committed revision 722723. Thanks Namit. &lt;/p&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12395152" name="patch.txt" size="410369" author="namit" created="Wed, 3 Dec 2008 01:26:35 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 18 Nov 2008 22:59:34 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73805</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 8 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7nr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121891</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-70] provide option to limit standard error output by user scripts</title>
                <link>https://issues.apache.org/jira/browse/HIVE-70</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;runaway user scripts emitting every row to standard error overwhelm our log partitions. We need to provide an option to limit standard error size per task.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12408755">HIVE-70</key>
            <summary>provide option to limit standard error output by user scripts</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jsensarma">Joydeep Sen Sarma</assignee>
                                    <reporter username="jsensarma">Joydeep Sen Sarma</reporter>
                        <labels>
                    </labels>
                <created>Tue, 18 Nov 2008 18:50:35 +0000</created>
                <updated>Sat, 17 Dec 2011 00:09:06 +0000</updated>
                            <resolved>Wed, 19 Nov 2008 02:12:17 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>CLI</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12648877" author="dhruba" created="Wed, 19 Nov 2008 01:59:27 +0000"  >&lt;p&gt;+1 Code looks good.&lt;/p&gt;</comment>
                            <comment id="12648881" author="dhruba" created="Wed, 19 Nov 2008 02:12:17 +0000"  >&lt;p&gt;I just committed this. Thanks Joydeep!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12394204" name="hive-70.txt" size="2829" author="jsensarma" created="Wed, 19 Nov 2008 00:14:37 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 19 Nov 2008 01:59:27 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73804</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 10 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7nz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121892</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-71] log details on rows that cause hive exceptions</title>
                <link>https://issues.apache.org/jira/browse/HIVE-71</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;users are logging all rows in order to find out the row that&apos;s causing exceptions. instead we should just log as much information as possible on the row that causes exception in hive stack&lt;/p&gt;</description>
                <environment></environment>
        <key id="12408757">HIVE-71</key>
            <summary>log details on rows that cause hive exceptions</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jsensarma">Joydeep Sen Sarma</reporter>
                        <labels>
                    </labels>
                <created>Tue, 18 Nov 2008 18:54:02 +0000</created>
                <updated>Tue, 5 Apr 2011 22:57:54 +0000</updated>
                                                                            <component>Diagnosability</component>
                    <component>Logging</component>
                    <component>Query Processor</component>
                    <component>Serializers/Deserializers</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42904</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 10 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7o7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121893</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-72] wrong results if partition pruning not strict and no mep-reduce job needed</title>
                <link>https://issues.apache.org/jira/browse/HIVE-72</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Suppose T is a partitioned table on ds, where ds is a string column, the following queries:&lt;/p&gt;

&lt;p&gt; SELECT a.* FROM T a WHERE a.ds=2008-09-08 LIMIT 1;&lt;br/&gt;
 SELECT a.* FROM T a WHERE a.ds=2008-11-10 LIMIT 1;&lt;/p&gt;


&lt;p&gt;return the first row from the first partition.&lt;/p&gt;



&lt;p&gt;This is because of the typecast to double.&lt;/p&gt;

&lt;p&gt;for a.ds=2008-01-01 or anything (a.ds=1),&lt;/p&gt;

&lt;p&gt; evaluate (Double, Double) is invoked at partition pruning.&lt;/p&gt;

&lt;p&gt;Since &apos;2008-11-01&apos; is not a valid double, it is converted to a null, and therefore the result of pruning returns null (unknown) - not FALSE.&lt;br/&gt;
All unknowns are also accepted, therefore all partitions are accepted which explains this behavior.&lt;/p&gt;

&lt;p&gt;filter is not invoked since it is a select * query, so map-reduce job is started.&lt;br/&gt;
We just turn off this optimization if pruning indicates that there can be unknown partitions. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12408781">HIVE-72</key>
            <summary>wrong results if partition pruning not strict and no mep-reduce job needed</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="namit">Namit Jain</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Tue, 18 Nov 2008 22:22:20 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:30 +0000</updated>
                            <resolved>Thu, 20 Nov 2008 22:29:49 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12648794" author="athusoo" created="Tue, 18 Nov 2008 23:05:54 +0000"  >&lt;p&gt;I think the correct way for this is to return something from the prune call to indicate that there were some unknown partitions.&lt;/p&gt;

&lt;p&gt;Inline Comments&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/parse/PartitionPruner.java:278	incomplete javadocs.&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:2938	What happens in case the parts are actually 0 i.e. no parts match the criteria (they are not unknown but they all return false). We would in that case not be making this optimization. The test case for that would be select * from srcpart where srcpart.ds = &apos;2000-01-01&apos; in our tests. We clearly do not want to turn off the optimization when this happens. right? &lt;/p&gt;</comment>
                            <comment id="12648838" author="namit" created="Wed, 19 Nov 2008 00:36:51 +0000"  >&lt;p&gt;changed prune() to return the two lists: confirmed and unknown separately and let the client handle it&lt;/p&gt;</comment>
                            <comment id="12649502" author="athusoo" created="Thu, 20 Nov 2008 22:14:12 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;looks good to me.&lt;/p&gt;</comment>
                            <comment id="12649509" author="dhruba" created="Thu, 20 Nov 2008 22:29:49 +0000"  >&lt;p&gt;I just committed this. Thanks Namit!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12394370" name="patch1.mapred.txt" size="8925" author="namit" created="Thu, 20 Nov 2008 22:11:20 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 18 Nov 2008 23:05:54 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73803</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 10 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7of:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121894</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-73] Thrift Server and Client for Hive</title>
                <link>https://issues.apache.org/jira/browse/HIVE-73</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently the hive cli directly calls the driver code. We need to be able to run a stand alone hive server that multiple clients can connect to. The hive server will allow clients to run queries as well as make meta data calls (by inheriting from the thrift metastore server)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12408847">HIVE-73</key>
            <summary>Thrift Server and Client for Hive</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rsm">Raghotham Murthy</assignee>
                                    <reporter username="rsm">Raghotham Murthy</reporter>
                        <labels>
                    </labels>
                <created>Wed, 19 Nov 2008 19:13:47 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:31 +0000</updated>
                            <resolved>Fri, 5 Dec 2008 08:28:43 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Clients</component>
                    <component>Server Infrastructure</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="12649137" author="rsm" created="Wed, 19 Nov 2008 19:15:08 +0000"  >&lt;p&gt;The patch for jdbc was becoming too big. So, we are going to stage the patches.&lt;/p&gt;</comment>
                            <comment id="12649140" author="jsensarma" created="Wed, 19 Nov 2008 19:20:56 +0000"  >&lt;p&gt;sounds good.&lt;/p&gt;

&lt;p&gt;can u take a look at hive-30 as well? there is some overlap:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;is the thrift server stateful (does it manage sessions)?&lt;/li&gt;
	&lt;li&gt;is the thrift api restricted to driver and metastore api? or does it extend to setting up client side session variables and runtime environment (files/jars and other resources)?&lt;/li&gt;
&lt;/ul&gt;

</comment>
                            <comment id="12649204" author="zshao" created="Wed, 19 Nov 2008 23:05:36 +0000"  >&lt;p&gt;If the query is a temporary query that returns results, will we return one row in one thrift call? (I guess thrift does not support data streaming).&lt;/p&gt;</comment>
                            <comment id="12649208" author="rsm" created="Wed, 19 Nov 2008 23:16:06 +0000"  >&lt;p&gt;@Joy&lt;br/&gt;
1. The thrift server is stateful. You can make multiple stateful calls if the transport is not closed between calls.&lt;br/&gt;
2. Right now I am just looking at driver and metastore. I guess the client side session variables can be via the &apos;set&apos; command which can be run as another query. And if the transport is not closed the session variables should persist.&lt;/p&gt;

&lt;p&gt;@Zheng&lt;br/&gt;
We are planning on supporting multiple fetch calls in the client - fetchOne, fetchN and fetchAll. Since the server is stateful, we should be able to loop through result rows one at a time if required. However, we are still debating if server should also support these methods. We were thinking of just supporting fetchOne and fetchN in the server and then implement fetchAll in the client by calling fetchN underneath. That way the server will not be overloaded in the case of fetchAll.&lt;/p&gt;</comment>
                            <comment id="12649210" author="rsm" created="Wed, 19 Nov 2008 23:22:10 +0000"  >&lt;p&gt;hive thrift service - attached patch&lt;/p&gt;</comment>
                            <comment id="12649211" author="rsm" created="Wed, 19 Nov 2008 23:22:33 +0000"  >&lt;p&gt;submitted patch - Look at the tests for usage.&lt;/p&gt;</comment>
                            <comment id="12649293" author="rsm" created="Thu, 20 Nov 2008 07:52:03 +0000"  >&lt;p&gt;attached new patch file&lt;/p&gt;</comment>
                            <comment id="12649590" author="rsm" created="Fri, 21 Nov 2008 04:17:34 +0000"  >&lt;p&gt;Attaching a smaller diff file without any of the generated code or include files. This should be useful to actually review the code. Note that this file is not the complete patch. I&apos;ll upload another file with the full diff after review comments.&lt;/p&gt;

&lt;p&gt;In this patch, the schema of the result is now available at the server. It required some hacking of the hive/ql code since there is currently no way to access the schema of the result of a query.&lt;/p&gt;

&lt;p&gt;The plan is for the JDBC or other clients to instantiate a DynamicSerDe with the schema string that is returned by the server. The row returned by the server is actually serialized using the MetadataTypedColumnSetSerDe. Pete mentioned that DynamicSerDe can deserialize this row if it is initialized with the right schema and protocol. I&apos;ll add that next.&lt;/p&gt;</comment>
                            <comment id="12649892" author="rsm" created="Sat, 22 Nov 2008 03:01:18 +0000"  >&lt;p&gt;attaching new (readable) diff without generated code/include files. In this patch, added test code to read data returned by server using DynamicSerDe.&lt;/p&gt;

&lt;p&gt;Discovered a couple of bugs (in other parts of hive) while testing this code.&lt;br/&gt;
1. select * queries dont generate schema of the result&lt;br/&gt;
2. ColumnInfo (type) of the result columns are not generated correctly. for example, create table test(num int). Then the ColumnInfo for the result of query &apos;select num from test where num &amp;gt; 10&apos; (added num &amp;gt; 10 to get past bug 1) has type &apos;string&apos;.&lt;/p&gt;

&lt;p&gt;I am not sure these two bugs need to be fixed as part of this jira.&lt;/p&gt;</comment>
                            <comment id="12650110" author="michim" created="Mon, 24 Nov 2008 05:15:49 +0000"  >&lt;p&gt;This patch (hive-73.5.txt) implements:&lt;/p&gt;

&lt;p&gt;HiveInterface.fetchOne()&lt;br/&gt;
HiveInterface.fetchN()&lt;br/&gt;
HiveInterface.fetchAll()&lt;/p&gt;

&lt;p&gt;Ragho implemented getSchema(). Now we should be able to implement basic jdbc functionality.&lt;/p&gt;</comment>
                            <comment id="12650306" author="wyckoff" created="Mon, 24 Nov 2008 20:11:23 +0000"  >&lt;p&gt;overall looks good, but some comments on the code:&lt;/p&gt;

&lt;p&gt;1. there&apos;s a lot of weird directories in some of the config/startup scripts. /mnt/vol/hive, ...&lt;br/&gt;
2. why do you need the C++ headers for thrift here?  without all of thrift, they cannot compile/run anyway&lt;br/&gt;
3. for the get type when generating dynamic serde, do you not need to translate types like int to i32?&lt;br/&gt;
4. many of the exceptions have no info other than the stack trace - i.e., you don&apos;t instantiate them with a meaningful string.&lt;br/&gt;
5. are you sure all the fb303 functions you are using are in the current public release of thrift?&lt;/p&gt;


</comment>
                            <comment id="12650415" author="michim" created="Tue, 25 Nov 2008 00:40:06 +0000"  >&lt;p&gt;Hi Pete, thanks for your feedback.&lt;/p&gt;

&lt;p&gt;4. many of the exceptions have no info other than the stack trace - i.e., you don&apos;t instantiate them with a meaningful string.&lt;br/&gt;
Yes, I&apos;ll fix this.&lt;/p&gt;

&lt;p&gt;You need to check with Ragho on 1,2,3, and 5. &lt;/p&gt;

&lt;p&gt;--Michi&lt;/p&gt;</comment>
                            <comment id="12650423" author="rsm" created="Tue, 25 Nov 2008 00:50:15 +0000"  >&lt;p&gt;1. there&apos;s a lot of weird directories in some of the config/startup scripts. /mnt/vol/hive, ...&lt;/p&gt;

&lt;p&gt;removed.&lt;/p&gt;

&lt;p&gt;2. why do you need the C++ headers for thrift here? without all of thrift, they cannot compile/run anyway&lt;/p&gt;

&lt;p&gt;right now just copied over all thrift specific files from metastore since we were going to get rid of the thrift directories from metastore. ideally, we would expect users to install thrift if they want to compile stuff. so, we can remove it. but will remove it later.&lt;/p&gt;

&lt;p&gt;3. for the get type when generating dynamic serde, do you not need to translate types like int to i32?&lt;/p&gt;

&lt;p&gt;nice catch. made the change now.&lt;/p&gt;

&lt;p&gt;4. many of the exceptions have no info other than the stack trace - i.e., you don&apos;t instantiate them with a meaningful string.&lt;/p&gt;

&lt;p&gt;fixed.&lt;/p&gt;

&lt;p&gt;5. are you sure all the fb303 functions you are using are in the current public release of thrift?&lt;/p&gt;

&lt;p&gt;yes. need to install the python modules in thrift/lib/py and thrift/contrib/fb303/py. the fb303_simple_mgmt script has to be copied over from thrift/contrib/fb303/scripts/.&lt;/p&gt;

&lt;p&gt;Attaching a new patch.&lt;/p&gt;</comment>
                            <comment id="12650432" author="michim" created="Tue, 25 Nov 2008 01:17:32 +0000"  >&lt;p&gt;By the way, how often do you guys commit to svn? It&apos;s kind of painful and error-prone to keep passing around patches for a long time. &lt;/p&gt;

&lt;p&gt;--Michi&lt;/p&gt;</comment>
                            <comment id="12650812" author="athusoo" created="Wed, 26 Nov 2008 00:21:56 +0000"  >&lt;p&gt;Michi.. I think with the following code review encapsulates many of the discussions.. once these are addressed we can move to commit this in...&lt;/p&gt;

&lt;p&gt;This is from a combined code review with Namit, Ashish and Raghu...&lt;/p&gt;

&lt;p&gt;Please use the functions in MetastoreUtils.java to create the thrift DDL from tableDesc stored in fetchTask via that loadFileWork.&lt;/p&gt;

&lt;p&gt;Rest of the comments are inlined.&lt;br/&gt;
Inline Comments&lt;br/&gt;
service/src/java/org/apache/hadoop/hive/service/HiveServer.java:195	We should avoid the copy here. It is better to accumulate only the necessary number of rows and then pass that list out.&lt;br/&gt;
service/src/java/org/apache/hadoop/hive/service/HiveServer.java:134	Can you make this a utility function.&lt;br/&gt;
service/src/java/org/apache/hadoop/hive/service/HiveServer.java:71	Can you move this to HiveConf.&lt;br/&gt;
service/src/java/org/apache/hadoop/hive/service/HiveServer.java:85	Since JDBC support multiple statements per session, we need to have a mapping from session to statements and then from statement to driver.&lt;br/&gt;
service/src/java/org/apache/hadoop/hive/service/HiveServer.java:220	Can you add javadocs.&lt;br/&gt;
service/src/java/org/apache/hadoop/hive/service/HiveServer.java:221	These are not in the thrift interface?&lt;br/&gt;
service/src/java/org/apache/hadoop/hive/service/HiveServer.java:87	Session state is not thread safe (it is a singleton), so this is blocked on the thread safety JIRA&lt;br/&gt;
service/src/java/org/apache/hadoop/hive/service/HiveClient.java:41	javadocs.&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java:1869	Should use tableDesc here.&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/Driver.java:73	javadocs..&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/Driver.java:85	javadocs..&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/Driver.java:73	javadocs&lt;/p&gt;</comment>
                            <comment id="12650839" author="jsensarma" created="Wed, 26 Nov 2008 01:53:29 +0000"  >&lt;p&gt;should have hive-77 fixed in a day or two unless something unexpected comes up&lt;/p&gt;</comment>
                            <comment id="12650863" author="rsm" created="Wed, 26 Nov 2008 05:12:19 +0000"  >&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;now using only tableDesc from FetchTask instead of passing around colInfos&lt;/li&gt;
	&lt;li&gt;removed buffering in HiveServer. Changed Driver/FetchTask to return the required number of rows.&lt;/li&gt;
	&lt;li&gt;added javadocs&lt;/li&gt;
	&lt;li&gt;added getStatus and getVersion to thrift interface&lt;/li&gt;
	&lt;li&gt;can now run test on stand alone server by setting test.service.standalone.server in data/conf/hive-site.xml. Need to start the server by running sh service/scripts/start_hive_thrift_server.sh from the top level directory&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12651096" author="athusoo" created="Wed, 26 Nov 2008 18:43:46 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;Please file a cleanup JIRA for HiveConf and utility function changes mentioned above and a separate one for multiple statements per session.&lt;/p&gt;

&lt;p&gt;Once that is done we can proceed to commit this.&lt;/p&gt;</comment>
                            <comment id="12651118" author="rsm" created="Wed, 26 Nov 2008 19:26:45 +0000"  >&lt;p&gt;I have filed &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-80&quot; title=&quot;Add testcases for concurrent query execution&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-80&quot;&gt;HIVE-80&lt;/a&gt; for the multiple statements feature.&lt;/p&gt;

&lt;p&gt;I have already made changes to HiveConf (missed mentioning it in the previous comment). Also, I dont need the utility function since I am now using a pre-existing function in MetaStoreUtils to get the thrift DDL from the deserializer.&lt;/p&gt;</comment>
                            <comment id="12651135" author="jsensarma" created="Wed, 26 Nov 2008 20:40:39 +0000"  >&lt;p&gt;quick comment:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;console.printInfo(&quot;OK&quot;);&lt;br/&gt;
+    console.printError(&quot;OK&quot;);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;not on board with this - perhaps the stdout was causing grief to the final results (not clear to me)? anyway - if this is the case - please mark the session as silent (see SessionState.java) - instead of changing the print directives. &lt;/p&gt;</comment>
                            <comment id="12651140" author="jsensarma" created="Wed, 26 Nov 2008 20:54:44 +0000"  >&lt;p&gt;start_hive_thrift_server.sh has serious issues. i can&apos;t understand why this is different from bin/hive. everytime we fork this logic - we miss out on stuff. look at stuff that&apos;s missing (wrt bin/hive):&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;auxlibs?&lt;/li&gt;
	&lt;li&gt;hardcoding lib/native location - this is just not the way to do this - when we go through bin/hive (which goes through hadoop) -  this gets set to the directory corresponding to java version and machine arch&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;why is it not possible to &apos;case&apos; bin/hive to launch different classes based on some input parameters (as was discussed in hive-30 - which hopefully Edward is also working on?)&lt;/p&gt;</comment>
                            <comment id="12651144" author="wyckoff" created="Wed, 26 Nov 2008 21:08:09 +0000"  >&lt;p&gt;some other issues:&lt;/p&gt;

&lt;p&gt;1. hardcoded path: +$JAVA_HOME/bin/java -Dcom.sun.management.jmxremote -Djava.library.path=/mnt/hive/production/cluster/lib/native/Linux-amd64-64/ \&lt;br/&gt;
2. getStatus and getVersion are already defined in fb303, so why re-defining them?&lt;br/&gt;
3. usually fb303 services take advantage of set/getcounter to provide stats on #of various ops and also exceptions. e.g., incrementCounter(&quot;queryExceptions&quot;);&lt;/p&gt;
</comment>
                            <comment id="12651444" author="michim" created="Fri, 28 Nov 2008 01:09:25 +0000"  >&lt;p&gt;Some minor chages:&lt;/p&gt;

&lt;p&gt;data/conf/hive-site.xml: &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Added description to test.service.standalone.server.&lt;/li&gt;
	&lt;li&gt;Changed default to false so that unit test uses embedded mode by default.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;service/src/test/org/apache/hadoop/hive/service/TestHiveServer.java:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Uses getBoolean() to read test.service.standalone.server parameter.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;You should be able to apply this patch and run the unit test under service directory without any additional steps. &lt;/p&gt;

&lt;p&gt;--Michi&lt;/p&gt;</comment>
                            <comment id="12651703" author="michim" created="Sat, 29 Nov 2008 09:47:19 +0000"  >&lt;p&gt;A few more small changes:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Added a test for dynamic serde. Right now it&apos;s failing with this schema: struct result 
{ string _c0}&lt;/li&gt;
	&lt;li&gt;Added usefile attribute to junit formatter tag. Set it to false and junit will print output to stdout. Handy when debugging.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12652149" author="rsm" created="Mon, 1 Dec 2008 20:51:28 +0000"  >&lt;p&gt;@joy:&lt;br/&gt;
&amp;gt; 1. printInfo vs printError &lt;/p&gt;

&lt;p&gt;ideally none of the console outputs other than the data itself should go to stdout. Or we should make &quot;hive -e&quot; default to quiet. We shouldnt have to specify more parameters to just get the data out. I have reverted this change for now. will file another jira for this.&lt;/p&gt;

&lt;p&gt;&amp;gt; 2. start_hive_thrift_server.sh has serious issues: &lt;/p&gt;

&lt;p&gt;I have removed these scripts. for now made a simple change to bin/hive to start the server if &apos;service is provided as the first argument. note that this does not daemonize the server.&lt;/p&gt;

&lt;p&gt;@pete:&lt;br/&gt;
&amp;gt; 1. hardcoded path: +$JAVA_HOME/bin/java -Dcom.sun.management.jmxremote -Djava.library.path=/mnt/hive/production/cluster/lib/native/Linux-amd64-64/ \&lt;/p&gt;

&lt;p&gt;No longer hardcoded sice i modified bin/hive&lt;/p&gt;

&lt;p&gt;&amp;gt; 2. getStatus and getVersion are already defined in fb303, so why re-defining them?&lt;br/&gt;
&amp;gt; 3. usually fb303 services take advantage of set/getcounter to provide stats on #of various ops and also exceptions. e.g., incrementCounter(&quot;queryExceptions&quot;);&lt;/p&gt;

&lt;p&gt;I have gotten rid of fb303 daemonizing stuff until we have a clear way of just using bin/hive for everything. i&apos;d like the client and the server to be two different scripts. but, we could discuss that in a separate jira.&lt;/p&gt;

&lt;p&gt;@michi&lt;br/&gt;
I have disabled the failing test (should file a separate jira on serde)&lt;/p&gt;</comment>
                            <comment id="12652246" author="jsensarma" created="Tue, 2 Dec 2008 02:51:46 +0000"  >&lt;p&gt;regarding the silent mode - we simply followed mysql and sqlplus precedent - in both of these a &apos;silent&apos; mode has to be explicitly specified to get only data (even in the equivalent of the &apos;-e&apos; mode). not sure there&apos;s any pressing reason to change as long as things are well documented (which probably they aren&apos;t - but that&apos;s a separate issue).&lt;/p&gt;

&lt;p&gt;bin/hive - Edward also made similar changes i think (haven&apos;t seen). some coordination with hive-30 may be needed ..&lt;/p&gt;</comment>
                            <comment id="12652297" author="michim" created="Tue, 2 Dec 2008 06:55:12 +0000"  >&lt;p&gt;&amp;gt; @michi&lt;br/&gt;
&amp;gt; I have disabled the failing test (should file a separate jira on serde)&lt;/p&gt;

&lt;p&gt;I filed a bug on this (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-99&quot; title=&quot;serde fails when field name starts with underscore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-99&quot;&gt;&lt;del&gt;HIVE-99&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;</comment>
                            <comment id="12652567" author="jsensarma" created="Tue, 2 Dec 2008 22:43:30 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;do u need to move test.standalone.... to HiveConf.java&lt;/p&gt;</comment>
                            <comment id="12653085" author="rsm" created="Thu, 4 Dec 2008 00:30:47 +0000"  >&lt;p&gt;@joy, we dont need to move test.standalone to HiveConf.java. The latest patch adds standalone to build-common.xml so that ant -Dstandalone=true test will result in using the standalone server.&lt;/p&gt;</comment>
                            <comment id="12653674" author="rsm" created="Fri, 5 Dec 2008 07:57:37 +0000"  >&lt;p&gt;fixed build-common.xml&lt;/p&gt;</comment>
                            <comment id="12653693" author="zshao" created="Fri, 5 Dec 2008 08:28:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-73&quot; title=&quot;Thrift Server and Client for Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-73&quot;&gt;&lt;del&gt;HIVE-73&lt;/del&gt;&lt;/a&gt;. Thrift Server and Client for Hive (Raghu through zshao).&lt;br/&gt;
svn revision 723645.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12403853">HIVE-48</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12409031">HIVE-77</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12409622">HIVE-99</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12409485">HIVE-87</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12467528">HIVE-1423</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12394289" name="hive-73.1.patch" size="544904" author="rsm" created="Wed, 19 Nov 2008 23:22:10 +0000"/>
                            <attachment id="12395056" name="hive-73.10.patch" size="427763" author="rsm" created="Tue, 2 Dec 2008 00:52:40 +0000"/>
                            <attachment id="12395153" name="hive-73.11.patch" size="424644" author="rsm" created="Wed, 3 Dec 2008 01:32:28 +0000"/>
                            <attachment id="12395376" name="hive-73.12.patch" size="427808" author="rsm" created="Fri, 5 Dec 2008 07:57:36 +0000"/>
                            <attachment id="12394326" name="hive-73.2.patch" size="586472" author="rsm" created="Thu, 20 Nov 2008 08:43:30 +0000"/>
                            <attachment id="12394399" name="hive-73.3.txt" size="29242" author="rsm" created="Fri, 21 Nov 2008 04:17:34 +0000"/>
                            <attachment id="12394474" name="hive-73.4.txt" size="31406" author="rsm" created="Sat, 22 Nov 2008 03:04:34 +0000"/>
                            <attachment id="12394531" name="hive-73.5.txt" size="624305" author="michim" created="Mon, 24 Nov 2008 05:15:49 +0000"/>
                            <attachment id="12394624" name="hive-73.6.patch" size="392342" author="rsm" created="Tue, 25 Nov 2008 02:01:59 +0000"/>
                            <attachment id="12394716" name="hive-73.7.patch" size="415299" author="rsm" created="Wed, 26 Nov 2008 05:12:19 +0000"/>
                            <attachment id="12394868" name="hive-73.8.patch" size="467973" author="michim" created="Fri, 28 Nov 2008 01:09:24 +0000"/>
                            <attachment id="12394921" name="hive-73.9.patch" size="468553" author="michim" created="Sat, 29 Nov 2008 09:47:19 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>12.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 19 Nov 2008 19:20:56 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73802</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 8 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7on:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121895</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-74] Hive can use CombineFileInputFormat for when the input are many small files</title>
                <link>https://issues.apache.org/jira/browse/HIVE-74</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;There are cases when the input to a Hive job are thousands of small files. In this case, there is a mapper for each file. Most of the overhead for spawning all these mappers can be avoided if Hive used CombineFileInputFormat introduced via &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-4565&quot; title=&quot;MultiFileInputSplit can use data locality information to create splits&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-4565&quot;&gt;&lt;del&gt;HADOOP-4565&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Options to control this behavior:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;hive.input.format (org.apache.hadoop.hive.ql.io.CombineHiveInputFormat (&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; empty), or org.apache.hadoop.hive.ql.io.HiveInputFormat)
mapred.min.split.size.per.node (the minimum bytes of data to create a node-local partition, otherwise the data will combine to rack level. &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;:0)
mapred.min.split.size.per.rack (the minimum bytes of data to create a rack-local partition, otherwise the data will combine to global level. &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;:0)
mapred.max.split.size (the max size of each split, will be exceeded because we stop accumulating *after* reaching it, instead of before)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The 3 numbers above must be in non-descending order.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12408891">HIVE-74</key>
            <summary>Hive can use CombineFileInputFormat for when the input are many small files</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rajesh.balamohan">Rajesh Balamohan</assignee>
                                    <reporter username="dhruba">dhruba borthakur</reporter>
                        <labels>
                    </labels>
                <created>Thu, 20 Nov 2008 09:40:38 +0000</created>
                <updated>Tue, 26 Jan 2016 00:03:09 +0000</updated>
                            <resolved>Tue, 15 Sep 2009 00:07:11 +0000</resolved>
                                                    <fixVersion>0.5.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="12649306" author="dhruba" created="Thu, 20 Nov 2008 09:45:03 +0000"  >&lt;p&gt;This code is for review purposes only. I would rather create a new classes called HiveCombineInputFormat HiveCombineRecordReader and put in all this new code into there without changing existing classes.&lt;/p&gt;</comment>
                            <comment id="12649490" author="jsensarma" created="Thu, 20 Nov 2008 21:36:03 +0000"  >&lt;p&gt;looks like in the right direction. only thing i didn&apos;t understand is how we are conveying to the combinefileinputformat that combined splits cannot span tables? there should be some data structure that captures this information that we need to push from hive to combineinputformat.&lt;/p&gt;

&lt;p&gt;also - how is the required number of splits configured? &lt;/p&gt;</comment>
                            <comment id="12674404" author="dhruba" created="Tue, 17 Feb 2009 23:57:36 +0000"  >&lt;p&gt;Allow Hive to use CombineInputFormat. This will not compile against 0.17 and 0.19 because CombineInputFormat is available only in 0.20 (&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-4565&quot; title=&quot;MultiFileInputSplit can use data locality information to create splits&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-4565&quot;&gt;&lt;del&gt;HADOOP-4565&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;</comment>
                            <comment id="12674742" author="jsensarma" created="Wed, 18 Feb 2009 19:10:33 +0000"  >&lt;p&gt;Is it possible to do this in a way that Hive continues to compile against 0.17/18/19?. I think this is almost a hard requirement.&lt;/p&gt;

&lt;p&gt;One possibility is to have a new version of HiveInputSplit that only compiles against 0.20 - and have this conditionally in the code only for 0.20 and onwards. (for example in HiveInputFormat.java - there&apos;s a conditional tag (//&lt;span class=&quot;error&quot;&gt;&amp;#91;exclude_0_19&amp;#93;&lt;/span&gt;) that does some conditional code inclusion). I am not sure how this was implemented.&lt;/p&gt;

&lt;p&gt;But even this is less than ideal. How will we deploy this with 17 (with combinefilesplit and related patches) (unless we are not using the open source version directly)&lt;/p&gt;</comment>
                            <comment id="12674769" author="jsensarma" created="Wed, 18 Feb 2009 20:25:45 +0000"  >&lt;p&gt;where are the pools for the combinefileinputformat created (one per table)?&lt;/p&gt;</comment>
                            <comment id="12701036" author="dhruba" created="Tue, 21 Apr 2009 03:42:23 +0000"  >&lt;p&gt;This combines multiple blocks from files into a single split. All files of the same table are part of a single pool.&lt;/p&gt;</comment>
                            <comment id="12749152" author="hammer" created="Sat, 29 Aug 2009 14:30:19 +0000"  >&lt;p&gt;What is the status of this patch?&lt;/p&gt;</comment>
                            <comment id="12749372" author="namit" created="Mon, 31 Aug 2009 04:31:23 +0000"  >&lt;p&gt;I was busy with some other things - will get back to it soon&lt;/p&gt;</comment>
                            <comment id="12753791" author="rsm" created="Thu, 10 Sep 2009 19:55:02 +0000"  >&lt;p&gt;Why does Hadoop18Shims.java have &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;+    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.hadoop.hive.ql.io.CombineHiveInputFormat&quot;&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12753928" author="namit" created="Fri, 11 Sep 2009 00:50:59 +0000"  >&lt;p&gt;talked with Raghu offline - will load a new patch after incorporating his comments&lt;/p&gt;</comment>
                            <comment id="12754825" author="namit" created="Mon, 14 Sep 2009 05:14:04 +0000"  >&lt;p&gt;@Raghu, verified that the file CombineFileRecordReader.java has not changed in hadoop 21&lt;/p&gt;</comment>
                            <comment id="12755087" author="rsm" created="Mon, 14 Sep 2009 17:24:01 +0000"  >&lt;p&gt;looks good. will commit once tests pass.&lt;/p&gt;</comment>
                            <comment id="12755260" author="rsm" created="Tue, 15 Sep 2009 00:07:11 +0000"  >&lt;p&gt;Committed. Thanks Namit.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12435486">HIVE-826</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12407630">HADOOP-4565</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12435374">HIVE-824</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12435486">HIVE-826</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12435374">HIVE-824</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12419204" name="hive.74.1.patch" size="36963" author="namit" created="Thu, 10 Sep 2009 18:12:17 +0000"/>
                            <attachment id="12419340" name="hive.74.2.patch" size="37681" author="namit" created="Fri, 11 Sep 2009 21:17:54 +0000"/>
                            <attachment id="12400365" name="hiveCombineSplit.patch" size="14971" author="dhruba" created="Tue, 17 Feb 2009 23:57:36 +0000"/>
                            <attachment id="12394333" name="hiveCombineSplit.patch" size="13838" author="dhruba" created="Thu, 20 Nov 2008 09:45:03 +0000"/>
                            <attachment id="12405988" name="hiveCombineSplit2.patch" size="15646" author="dhruba" created="Tue, 21 Apr 2009 03:42:23 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 20 Nov 2008 21:36:03 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73801</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 20 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7ov:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121896</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-74&quot; title=&quot;Hive can use CombineFileInputFormat for when the input are many small files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-74&quot;&gt;&lt;strike&gt;HIVE-74&lt;/strike&gt;&lt;/a&gt;. Hive can use CombineFileInputFormat for when the input has many&lt;br/&gt;
small files (Namit Jain via rmurthy)&lt;br/&gt;
</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-75] limit does not work if applied to outer most block and it is not a query</title>
                <link>https://issues.apache.org/jira/browse/HIVE-75</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;limit does not work if applied to outer most block and it is not a query&lt;/p&gt;

&lt;p&gt;For eg&lt;/p&gt;

&lt;p&gt;insert into T1 select ... from T2 limit 10;&lt;/p&gt;

&lt;p&gt;will be executed as a map-job only.&lt;/p&gt;


&lt;p&gt;which means that the total number of rows in T1 is bounded by 10 * number of mappers.&lt;/p&gt;

&lt;p&gt;We need another map-reduce job to fix this or the move task needs to be modified.&lt;/p&gt;

&lt;p&gt;For now, the simpler fix of another map-reduce job should be ok, in future we can further optimize it by modifying the move task&lt;/p&gt;</description>
                <environment></environment>
        <key id="12408932">HIVE-75</key>
            <summary>limit does not work if applied to outer most block and it is not a query</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="namit">Namit Jain</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Thu, 20 Nov 2008 17:48:00 +0000</created>
                <updated>Sat, 17 Dec 2011 00:09:06 +0000</updated>
                            <resolved>Thu, 20 Nov 2008 23:44:23 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12649523" author="rsm" created="Thu, 20 Nov 2008 23:01:24 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;looks good&lt;/p&gt;</comment>
                            <comment id="12649540" author="dhruba" created="Thu, 20 Nov 2008 23:44:23 +0000"  >&lt;p&gt;I just committed this. Thanks Namit!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12394362" name="patch1.txt" size="8452" author="namit" created="Thu, 20 Nov 2008 19:33:49 +0000"/>
                            <attachment id="12394368" name="patch2.txt" size="11507" author="namit" created="Thu, 20 Nov 2008 20:51:24 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 20 Nov 2008 23:01:24 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73800</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 10 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7p3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121897</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-76] Column number mismatch between query and destination tables when alias.* expressions are present in the select list of a join</title>
                <link>https://issues.apache.org/jira/browse/HIVE-76</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Column number mismatch between query and destination tables when alias.* expressions are present in the select list of a join. The reason is due to a bug in how the row resolver is constructed in SemanticAnalyzer.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12408974">HIVE-76</key>
            <summary>Column number mismatch between query and destination tables when alias.* expressions are present in the select list of a join</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="athusoo">Ashish Thusoo</assignee>
                                    <reporter username="athusoo">Ashish Thusoo</reporter>
                        <labels>
                    </labels>
                <created>Fri, 21 Nov 2008 04:14:01 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:38 +0000</updated>
                            <resolved>Sun, 23 Nov 2008 15:42:18 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12649591" author="athusoo" created="Fri, 21 Nov 2008 04:18:06 +0000"  >&lt;p&gt;The following test case leads to the error:&lt;/p&gt;

&lt;p&gt;CREATE TABLE dest1(key1 INT, value1 STRING, key2 INT, value2 STRING) STORED AS TEXTFILE;&lt;/p&gt;

&lt;p&gt;FROM src src1 JOIN src src2 ON (src1.key = src2.key)&lt;br/&gt;
INSERT OVERWRITE TABLE dest1 SELECT src1.&lt;b&gt;, src2.&lt;/b&gt;;&lt;/p&gt;

&lt;p&gt;where src has two columns (key INT, value STRING)&lt;/p&gt;

&lt;p&gt;In this situation we should not be getting a column mismatch error as the destination has 4 columns and SELECT src1.&lt;b&gt;, src2.&lt;/b&gt; also should&lt;br/&gt;
have 4 columns. However, due to a bug in SemanticAnalyzer we add all the columns in the select list to the row resolver as many times as an&lt;br/&gt;
expression of the form alias.* appears.&lt;/p&gt;

&lt;p&gt;As a result it is impossible to insert into a destination table. A workaround is to enumerate all the columns and not use alias.* in the select list&lt;br/&gt;
with joins when inserting the results into a table.&lt;/p&gt;</comment>
                            <comment id="12649598" author="athusoo" created="Fri, 21 Nov 2008 05:12:56 +0000"  >&lt;p&gt;Fix for the bug and test case.&lt;/p&gt;</comment>
                            <comment id="12649599" author="athusoo" created="Fri, 21 Nov 2008 05:13:18 +0000"  >&lt;p&gt;submitted patch.&lt;/p&gt;</comment>
                            <comment id="12649708" author="namit" created="Fri, 21 Nov 2008 17:11:58 +0000"  >&lt;p&gt;can you add a select also in join10.q.&lt;br/&gt;
I mean select without the explain also, like all other tests&lt;/p&gt;</comment>
                            <comment id="12649813" author="athusoo" created="Fri, 21 Nov 2008 21:48:50 +0000"  >&lt;p&gt;New patch which also fixes join10.q&lt;/p&gt;

&lt;p&gt;Note that join10.q was already broken before.&lt;/p&gt;</comment>
                            <comment id="12649819" author="namit" created="Fri, 21 Nov 2008 21:58:31 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="12650028" author="dhruba" created="Sun, 23 Nov 2008 15:42:18 +0000"  >&lt;p&gt;I just committed this. Thanks Ashish!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12394400" name="patch-76.txt" size="38656" author="athusoo" created="Fri, 21 Nov 2008 05:12:56 +0000"/>
                            <attachment id="12394452" name="patch-76_1.txt" size="52150" author="athusoo" created="Fri, 21 Nov 2008 21:48:50 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 21 Nov 2008 17:11:58 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73799</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 10 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7pb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121898</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-77] thread safe query execution</title>
                <link>https://issues.apache.org/jira/browse/HIVE-77</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;this came up in hive-30 where there&apos;s a multithreaded hive server in the works. at the minimum, the sessionstate objects should be thread local singletons. but filing a more general bug that can cover this issue + code audit for any other static variables + test suite for running queries from a multi-threaded environment&lt;/p&gt;</description>
                <environment></environment>
        <key id="12409031">HIVE-77</key>
            <summary>thread safe query execution</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jsensarma">Joydeep Sen Sarma</assignee>
                                    <reporter username="jsensarma">Joydeep Sen Sarma</reporter>
                        <labels>
                    </labels>
                <created>Fri, 21 Nov 2008 21:53:35 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:27 +0000</updated>
                            <resolved>Fri, 5 Dec 2008 10:11:39 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Server Infrastructure</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12651321" author="jsensarma" created="Thu, 27 Nov 2008 10:58:15 +0000"  >&lt;p&gt;this patch includes:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;test for multithreaded execution&lt;/li&gt;
	&lt;li&gt;fixes to SessionState.java and CliDriver.java for MT safe (and to run MT tests)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;however - the test is disabled. while this seems to fix issues with session management etc. - there are bugs in metastore client code that are not resolved. i would like to file a separate jira for those.&lt;/p&gt;

&lt;p&gt;unfortunately metastore client issues are not limited to DDLTasks only - regular table metadata fetches are also affected. (the patch allows testing of clientpositive queries without running DDL commands in MT mode - but in an extremely hacky way)&lt;/p&gt;</comment>
                            <comment id="12652188" author="athusoo" created="Mon, 1 Dec 2008 22:42:57 +0000"  >&lt;p&gt;Comments are inlined.&lt;/p&gt;

&lt;p&gt;There are two major ones:&lt;br/&gt;
1. static LOG - we do that all over our code. Will that cause a problem or do we have to clean that up in the same way that you have done for CliDriver and SessionState.&lt;br/&gt;
2. This is the bigger one - I think we should just extend QTestUtil so that it can run in a multi threaded mode instead of creating another class to run those tests. We can then call QTestUtil in two modes and pass the list of tests that want it to executed in the multi threaded mode. That would be more maintainable in the long run.&lt;/p&gt;

&lt;p&gt;Rest a few minor things like missing javadocs..&lt;br/&gt;
Inline Comments&lt;br/&gt;
ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java:687	Please add javadocs for these.&lt;br/&gt;
ql/src/test/org/apache/hadoop/hive/ql/TestMTQueries.java:0	This file needs javadocs.&lt;br/&gt;
ql/src/test/org/apache/hadoop/hive/ql/TestMTQueries.java:32	Can we pass the names into this instead of hardcoding these in the code.&lt;br/&gt;
ql/src/test/org/apache/hadoop/hive/ql/TestMTQueries.java:0	Also instead of a brand new test class, it is perhaps better to extend QTestUtil to run using the Runner and then run it in two modes, concurrent and serial. We would be able to avoid duplicate code and just have a single utility to test out both the concurrent and serial tests.&lt;br/&gt;
ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java:202	Can we create a similar array as source array for destination tables and destination files and then loop over those arrays.&lt;br/&gt;
ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java:391	javadocs.&lt;br/&gt;
ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java:391	Where is this function called from?&lt;br/&gt;
build-common.xml:226	why are we excluding TestMTQueries here?&lt;br/&gt;
cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:62	Would static log not work. If so, we have that all over the code and just fixing it here will not work.&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java:265	javadocs for these.&lt;/p&gt;</comment>
                            <comment id="12652195" author="jsensarma" created="Mon, 1 Dec 2008 23:05:44 +0000"  >&lt;p&gt;thx - will fix the inline comments.&lt;/p&gt;

&lt;p&gt;static LOG: this is not a blocking issue. I am assuming that log4j itself is multithread safe. The main issue is that all log events are going to end up in the same log file - and log entries from different sessions will be interleaved without any clear headers. There&apos;s something called NDC that&apos;s apparently used widely in multi-threaded environments to put prefixes on log entries per thread (in our case session). we can use NDC interfaces from log4j - but it&apos;s more work - potentially more disruptive changes.&lt;/p&gt;

&lt;p&gt;QTestUtil: don&apos;t understand this. today every query file is run independently in a different junit test. if QTestUtil ran all of them (either in sequence or in parallel) - this would not be possible. can u explain a bit more?&lt;/p&gt;</comment>
                            <comment id="12652211" author="appodictic" created="Tue, 2 Dec 2008 00:10:32 +0000"  >&lt;p&gt;Log4j has a variable that will print the thread name. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://logging.apache.org/log4j/1.2/apidocs/org/apache/log4j/PatternLayout.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://logging.apache.org/log4j/1.2/apidocs/org/apache/log4j/PatternLayout.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;%t should do it.&lt;/p&gt;</comment>
                            <comment id="12652247" author="athusoo" created="Tue, 2 Dec 2008 02:52:57 +0000"  >&lt;p&gt;@Joy&lt;/p&gt;

&lt;p&gt;I meant rolling up the TestMTQueries into QTestUtil so that we just have a single tool to deal with when it comes to query testing.&lt;/p&gt;

&lt;p&gt;%t as suggested by Edward should work for now. Later when we expand this so that a thread is able to handle multiple sessions (a requirement on JDBC) we can start exploring NDC and MDCs to log thread specific information.&lt;/p&gt;</comment>
                            <comment id="12652448" author="jsensarma" created="Tue, 2 Dec 2008 18:25:09 +0000"  >&lt;p&gt;fixed all the inline comments and moved multithreaded query harness to QTestUtil. &lt;/p&gt;

&lt;p&gt;&amp;gt; ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java:391 Where is this function called from?&lt;br/&gt;
This is a temporary hack for non-DDL related metastore issues.&lt;/p&gt;

&lt;p&gt;also - i am actually able to run TestMTqueries succesfully now. funnily all the metastore issues are not showing up. There were some more changes required:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;randomize hadoop execution directories for local mode execution (otherwise there are collisions when submitting jobs concurrently)&lt;/li&gt;
	&lt;li&gt;fix taskfactory id to be threadlocal static&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12653035" author="jsensarma" created="Wed, 3 Dec 2008 23:04:30 +0000"  >&lt;p&gt;another one after resolving Namit&apos;s changes.&lt;/p&gt;</comment>
                            <comment id="12653510" author="athusoo" created="Thu, 4 Dec 2008 22:03:19 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;looks good to me.&lt;/p&gt;

&lt;p&gt;Zheng can you checkin...&lt;/p&gt;</comment>
                            <comment id="12653729" author="zshao" created="Fri, 5 Dec 2008 10:11:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-77&quot; title=&quot;thread safe query execution&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-77&quot;&gt;&lt;del&gt;HIVE-77&lt;/del&gt;&lt;/a&gt;. Thread safe query execution. (Joydeep through zshao)&lt;br/&gt;
Committed revision 723699.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12408847">HIVE-73</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12407155">HIVE-30</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12409298">HIVE-80</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12394837" name="hive-77.patch.1" size="31517" author="jsensarma" created="Thu, 27 Nov 2008 10:50:25 +0000"/>
                            <attachment id="12395105" name="hive-77.patch.2" size="38823" author="jsensarma" created="Tue, 2 Dec 2008 18:06:45 +0000"/>
                            <attachment id="12395108" name="hive-77.patch.3" size="40748" author="jsensarma" created="Tue, 2 Dec 2008 18:25:46 +0000"/>
                            <attachment id="12395226" name="hive-77.patch.4" size="47867" author="jsensarma" created="Wed, 3 Dec 2008 23:04:30 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 1 Dec 2008 22:42:57 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73798</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 8 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0l7pj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>121899</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-78] Authorization infrastructure for Hive</title>
                <link>https://issues.apache.org/jira/browse/HIVE-78</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Allow hive to integrate with existing user repositories for authentication and authorization infromation.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12409037">HIVE-78</key>
            <summary>Authorization infrastructure for Hive</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="he yongqiang">He Yongqiang</assignee>
                                    <reporter username="athusoo">Ashish Thusoo</reporter>
                        <labels>
                            <label>authorization</label>
                    </labels>
                <created>Fri, 21 Nov 2008 23:04:28 +0000</created>
                <updated>Thu, 2 May 2013 02:29:35 +0000</updated>
                            <resolved>Wed, 12 Jan 2011 06:58:53 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Authorization</component>
                    <component>Metastore</component>
                    <component>Query Processor</component>
                    <component>Security</component>
                    <component>Server Infrastructure</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>21</watches>
                                                                <comments>
                            <comment id="12649855" author="appodictic" created="Fri, 21 Nov 2008 23:45:07 +0000"  >&lt;p&gt;LDAP seems like a good way to handle this. We have a few alternatives. &lt;/p&gt;

&lt;p&gt;Any posixAccount can log into hive. LDAP search would be (&amp;amp;(objectClass=posixAccount (uid=&amp;lt;user&amp;gt;))&lt;/p&gt;

&lt;p&gt;We could enforce that the user must be have some other attribute (&amp;amp;(objectClass)=posixAccount (uid=&amp;lt;user&amp;gt;)(businessCategory=&quot;hiveuser&quot;))&lt;/p&gt;

&lt;p&gt;We could enforce that the user must be valid and they must be inside of a specific groupOfUniqueNames &lt;br/&gt;
(&amp;amp;(objectClass=posixAccount (uid=&amp;lt;user&amp;gt;)     and memberof (hiveGroup)  apache mod_ldap can do this&lt;/p&gt;

&lt;p&gt;We can create a supplemental schema attribute we can append to already exists ldap users.&lt;/p&gt;</comment>
                            <comment id="12650271" author="athusoo" created="Mon, 24 Nov 2008 18:41:33 +0000"  >&lt;p&gt;+1 on this.&lt;/p&gt;

&lt;p&gt;I also wanted to integrate this with AD through kerberos as that is perhaps the dominant user repositories in most enterprises and at least internally we have some users that do not have unix accounts (mostly analysts). We could use samba to provide the bridge to AD as there are certain nuances when it comes to Kerberos with AD as well as NTLM and NTLMv2 auths that samba has already solved.&lt;/p&gt;

&lt;p&gt;Also we should also think of providing integration with unix accounts - those maintained in passwd db specially for folks who want to just test authentication specific features.&lt;/p&gt;

&lt;p&gt;In the past the most dominant directories that I have found in enterprise environments as AD (can be bridged through LDAP and Samba), Sun Java One, Novell and OID (all LDAP directories) and Unix accounts.&lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;</comment>
                            <comment id="12650289" author="appodictic" created="Mon, 24 Nov 2008 19:25:50 +0000"  >&lt;p&gt;I wanted to mention one more solution. JDBCRealm. This is pretty well established in tomcat. It should be easy to retrofit. It has support for roles.&lt;br/&gt;
Password file is a good solution as well. &lt;/p&gt;

&lt;p&gt;Q. Active Directory is an LDAP at its core. What is a case that you need samba to get at data in LDAP? It seems like we should be able to support active directory and LDAP using JNDI-- &lt;a href=&quot;http://forums.sun.com/thread.jspa?threadID=581425&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://forums.sun.com/thread.jspa?threadID=581425&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;I was thinking about &apos;roles&apos;. hiveuser - Can issue queries kill their own queries ,  hiveadmin - can kill users queries&lt;/p&gt;</comment>
                            <comment id="12650407" author="athusoo" created="Tue, 25 Nov 2008 00:19:49 +0000"  >&lt;p&gt;For Active Directory I think JNDI will work as long as we work off GSSAPI - so I think Kerb V should work with JNDI.&lt;/p&gt;

&lt;p&gt;However, the traditional authentication mechanisms of NTLM and NTLMv2, I think those will not work with AD as they are proprietary protocols and the only public domain implementations of those are present in Samba. They are mostly an issue for old machines and old directory installations. We may as well do JNDI for now and then &lt;br/&gt;
address these later.&lt;/p&gt;

&lt;p&gt;Will check out JDBCRealm, I have not used those in the past.&lt;/p&gt;

&lt;p&gt;For query side roles we could just model those on mysql privileges. Some of the basic ones include:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;SELECT&lt;/li&gt;
	&lt;li&gt;INSERT&lt;/li&gt;
	&lt;li&gt;ALTER TABLE&lt;/li&gt;
	&lt;li&gt;CREATE&lt;/li&gt;
	&lt;li&gt;DROP&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;And on the server administration side, things like:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;KILL SESSION(QUERY)&lt;/li&gt;
	&lt;li&gt;SHUTDOWN&lt;/li&gt;
	&lt;li&gt;STARTUP&lt;/li&gt;
	&lt;li&gt;VIEW SESSIONS&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;are useful...&lt;/p&gt;

&lt;p&gt;We could role these privileges up into role objects so essentially your&lt;/p&gt;

&lt;p&gt;hiveuser role would become SELECT, INSERT, CREATE&lt;br/&gt;
while hiveadmin would become KILL SESSION, SHUTDOWN, STARTUP, VIEW SESSIONS, DROP, ALTER + whatever is in hiveusers&lt;/p&gt;



</comment>
                            <comment id="12652077" author="athusoo" created="Mon, 1 Dec 2008 17:59:34 +0000"  >&lt;p&gt;Assigning to Edward as he is going to start on this... Thanks Edward!!&lt;/p&gt;</comment>
                            <comment id="12652083" author="appodictic" created="Mon, 1 Dec 2008 18:21:30 +0000"  >&lt;p&gt;I would like to leverage the &apos;REALM&apos; has already been done with tomcat. This would give us the ability to plug into many standard authentication architectures.&lt;br/&gt;
&lt;a href=&quot;http://tomcat.apache.org/tomcat-4.1-doc/catalina/docs/api/org/apache/catalina/realm/package-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://tomcat.apache.org/tomcat-4.1-doc/catalina/docs/api/org/apache/catalina/realm/package-tree.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If we including a jar file in a binary format from tomcat should it be part of the patch or should we fork some of the tomcat source? We should have not have to alter the original code we will be using it directly or extending it.&lt;/p&gt;</comment>
                            <comment id="12652091" author="athusoo" created="Mon, 1 Dec 2008 18:51:01 +0000"  >&lt;p&gt;On the first looks Realms seems to be a nice fit for this problem.&lt;/p&gt;

&lt;p&gt;One capability that is missing there and which may become an issue later is the ability to compose roles into higher level roles. To me it seems that roles are strictly flat and are not hierarchical, so I cannot create an admin role that has the basic roles within it . Can this be achieved with Realms? I have not used it before so I am not sure that if it is achievable?&lt;/p&gt;

&lt;p&gt;The other issue that I can think of is whether Realms is generic enough to protect any kind of a resource and not just limited to web resourrces. We have tables and partitions, servers etc. Could you elaborate on how this would work for the capabilities that I listed in my previous comments.&lt;/p&gt;
</comment>
                            <comment id="12652162" author="appodictic" created="Mon, 1 Dec 2008 21:25:10 +0000"  >&lt;p&gt;Recursive Role processing is probably not possible with JDBCRealm.&lt;/p&gt;

&lt;p&gt;Recursive Role processing is generally difficult to implement. N.I.S. Net Groups is an example of this, because of the recursive nature you have a more complicated implementation. Firstly, you have to check for loops in the group definition. Role1 memberOf-&amp;gt; Role2-&amp;gt; memberOf Role3-&amp;gt; memberOf -&amp;gt;Role1. This needs to be done when the rule is created, or evaluated, or both. I have found (in my experience) dynamic/recursive groups are are less practical then they originally seem. They do have merit however.&lt;/p&gt;

&lt;p&gt;The roles you mentioned were:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;SELECT&lt;/li&gt;
	&lt;li&gt;INSERT&lt;/li&gt;
	&lt;li&gt;ALTER TABLE&lt;/li&gt;
	&lt;li&gt;CREATE&lt;/li&gt;
	&lt;li&gt;DROP&lt;/li&gt;
	&lt;li&gt;KILL SESSION(QUERY)&lt;/li&gt;
	&lt;li&gt;SHUTDOWN&lt;/li&gt;
	&lt;li&gt;STARTUP&lt;/li&gt;
	&lt;li&gt;VIEW SESSIONS&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;IMPORTANT: Are roles global or per object? Realms really only make sense with global permissions.&lt;/p&gt;

&lt;p&gt;Lets look at a scenario:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Hive
	&lt;ul&gt;
		&lt;li&gt;tableA&lt;/li&gt;
		&lt;li&gt;tableB&lt;/li&gt;
		&lt;li&gt;tableC&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Users
	&lt;ul&gt;
		&lt;li&gt;john
		&lt;ul&gt;
			&lt;li&gt;uid 3000&lt;/li&gt;
			&lt;li&gt;gid 3000,4000&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
		&lt;li&gt;bob
		&lt;ul&gt;
			&lt;li&gt;uid 3001&lt;/li&gt;
			&lt;li&gt;gid 3001,4000&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Groups
	&lt;ul&gt;
		&lt;li&gt;john
		&lt;ul&gt;
			&lt;li&gt;gid 3000&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
		&lt;li&gt;bob
		&lt;ul&gt;
			&lt;li&gt;gid 3001&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
		&lt;li&gt;hr
		&lt;ul&gt;
			&lt;li&gt;gid 4000&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Goal to implement root has full access to all tables, john has access to table a, and bob has access to table b. tablec can be read by anyone in hr&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Realms
	&lt;ul&gt;
		&lt;li&gt;tableA_select
		&lt;ul&gt;
			&lt;li&gt;root&lt;/li&gt;
			&lt;li&gt;john&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
		&lt;li&gt;tableA_insert
		&lt;ul&gt;
			&lt;li&gt;root&lt;/li&gt;
			&lt;li&gt;john&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
		&lt;li&gt;tableB_select
		&lt;ul&gt;
			&lt;li&gt;root&lt;/li&gt;
			&lt;li&gt;bob&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
		&lt;li&gt;tableB_insert
		&lt;ul&gt;
			&lt;li&gt;root&lt;/li&gt;
			&lt;li&gt;bob&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
		&lt;li&gt;tableC_select
		&lt;ul&gt;
			&lt;li&gt;root&lt;/li&gt;
			&lt;li&gt;bob&lt;/li&gt;
			&lt;li&gt;john&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Using &apos;_&apos; as a delimiter and constructing several roles per table is a slightly non standard for realms, but it would work. User lists are flat. &lt;/p&gt;

&lt;p&gt;About these permissions:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;SELECT&lt;/li&gt;
	&lt;li&gt;INSERT&lt;/li&gt;
	&lt;li&gt;ALTER TABLE&lt;/li&gt;
	&lt;li&gt;CREATE&lt;/li&gt;
	&lt;li&gt;DROP&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;If an external table was created. If my UID has access to the file through HDFS I would expect to have select access inside Hive. If I could not write the file in HDFS hive would not expect hive to give me these permissions. I think we should clearly define the difference between  AUTHENTICATION and ACCESS.&lt;/p&gt;

&lt;p&gt;For example, the AUTHENTICATION information for a user is commonly stored in Active Directory. However ACCESS information like, what tables a user may run SELECT on can not be stored in Active Directory without changing the Active Directory schema.&lt;/p&gt;

&lt;p&gt;Realm or JAAS gives us a quick way to answer the authorization question.  As to the ACCESS we either have to store that information in the meta store or an external system. &lt;/p&gt;</comment>
                            <comment id="12652252" author="athusoo" created="Tue, 2 Dec 2008 03:18:25 +0000"  >&lt;p&gt;The roles are actually per object. I would say that these are atleast per table, if not per partition. I don&apos;t have a use case for the later but seperation on the basis of table is actually very very desirable.&lt;/p&gt;

&lt;p&gt;Given that, and the fact that currently we have around 5000 tables in our warehouse, do you have some idea of how realms with scale with such a large number of objects.&lt;/p&gt;

&lt;p&gt;I agree that a generic recursive role infrastructure does not have a lot of utility, but considering that we have so many permissions, I would think that it would be quite cumbersome for an administrator to enumerate all of them for every user that is created (though some good defaults can surely alleviate some of the concerns here). So I think being able to package permissions into some higher level roles would help. Note that we do not need a generic role within a role, but it would be nice to have a role be a set of permissions on certain objects and an ability to allow authorization framework to be able to associate a role or permission with a user.&lt;/p&gt;

&lt;p&gt;The other way to do this is to define groups which can be assigned a set of permissions and a set of users. That level of indirection would also work in reducing the number of user to permission assignments that we would have to make otherwise.&lt;/p&gt;

&lt;p&gt;I agree that authentication and authorization (much of what I have been talking about in this comment), need to be separated out  and while we use the directory infrastructure for authentication, we should store the authorization information in the metastore as that is specific to our application and no sane directory administrator would allow us to touch the directory to support custom attributes.&lt;/p&gt;

&lt;p&gt;If we do that separation, then Realms perhaps can take care of just the authentication portion, and once the user is authenticated, the authorization infrastructure looks up the user by ID in metastore to figure out what capabilities the user has.&lt;/p&gt;

&lt;p&gt;Is that what you have in mind?&lt;/p&gt;

&lt;p&gt;In this scenario, I presume that we would have a realm for AD and just have all the users authenticate with that realm. So the number of realms would be a function of the number of directories or user repositories as opposed to being a function of the number of objects.&lt;/p&gt;</comment>
                            <comment id="12682719" author="appodictic" created="Tue, 17 Mar 2009 16:46:00 +0000"  >&lt;p&gt;We also have to look at this on the file system level. For example, files in my warehouse are owned by the user who created the table.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;/user/hive/warehouse/edward      &amp;lt;dir&amp;gt;           2008-10-30 17:13        rwxr-xr-x       edward supergroup&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Regardless of what permissions are granted in the metastore (via this jira), hadoop ACL governs what a user can do to that file. &lt;/p&gt;

&lt;p&gt;This is not an issue in mysql. In a typical mysql deployment all of the data files are owned by a mysql user. &lt;/p&gt;

&lt;p&gt;I do not see a clear cut solution for this. &lt;/p&gt;

&lt;p&gt;In one scenario we make sure all the files in the warehouse are owned RW to all, or owned by a specific user. A component like HiveServer, CLI, or HWI would decide if the user action would succeed based on the meta data.&lt;/p&gt;

&lt;p&gt;The other option is that an operation like &apos;GRANT SELECT&apos; would have to physically modify the Hadoop ACL/owner. This method will not help us get the fine grained control we desire.&lt;/p&gt;
</comment>
                            <comment id="12698305" author="coderplay" created="Mon, 13 Apr 2009 01:55:44 +0000"  >&lt;p&gt;Is there any further progess on this issue?&lt;/p&gt;</comment>
                            <comment id="12698771" author="appodictic" created="Tue, 14 Apr 2009 13:33:07 +0000"  >&lt;p&gt;My last comment is a blocker in my mind. How can we implement complex access controls at the Hive level when we have basic file ownership issues at the file level? Daemons like HiveService and HiveWebInterface will have to run as supergroup or a hive group? How is this  this effect the CLI that will run as the individual user? &lt;/p&gt;

&lt;p&gt;These are not as much Hive issues as they are environment/setup issues, but I do not want to assume my environment is the target environment. Will we be assuming users are members of a &apos;hive&apos; posix group or that all the files in the warehouse are owned by user &apos;Hive&apos; group &apos;Hive&apos;? I wanted to get others opinion on this.&lt;/p&gt;</comment>
                            <comment id="12699247" author="appodictic" created="Wed, 15 Apr 2009 15:53:58 +0000"  >&lt;p&gt;GRANT &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;SELECT&lt;/li&gt;
	&lt;li&gt;ALTER&lt;/li&gt;
	&lt;li&gt;INSERT&lt;/li&gt;
	&lt;li&gt;UPDATE --RESERVED&lt;/li&gt;
	&lt;li&gt;DROP&lt;/li&gt;
	&lt;li&gt;CREATE&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;GLOBAL GRANT PERMISSIONS&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;PROCESS_LIST -List Query&lt;/li&gt;
	&lt;li&gt;PROCESS_KILL -Kill query&lt;/li&gt;
	&lt;li&gt;RC - start shutdown&lt;/li&gt;
	&lt;li&gt;WITH_GRANT - Give user permission to grant other permissions&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;SPECIAL&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&apos;ALL&apos; ALL PERMISSIONS&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Target Objects: ALL, DataBase, Table, Partition, Column&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Permissions are additive&lt;/li&gt;
	&lt;li&gt;Upper level implies lower level i.e. select on table implies select on all columns in table&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Suggested Syntax&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;GRANT WITH_GRANT,RC, ON &apos;*&apos; TO &apos;USER1&apos;,&apos;USER2&apos; AS my_permission&lt;/li&gt;
	&lt;li&gt;GRANT SELECT ON &apos;cat1&apos;,&apos;cat2&apos; TO &apos;USER1&apos; AS my_permission&lt;/li&gt;
	&lt;li&gt;GRANT SELECT ON &apos;cat1.*&apos;, &apos;cat2.homes.name&apos;  TO &apos;USER4&apos;, &apos;%GROUP1&apos; AS my_permission&lt;/li&gt;
	&lt;li&gt;GRANT SELECT on &apos;cat1.*&apos;, &apos;cat2.homes.PARTITION=&quot;5.5.4&quot;.owner&apos; TO &apos;USER5&apos; AS my_permission&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In the metastore we can store the permissions like this:&lt;br/&gt;
PERMISSION SET {&lt;br/&gt;
	Vector &amp;lt;User|GROUP&amp;gt; ,&lt;br/&gt;
	Vector &amp;lt;TargetObject&amp;gt;,&lt;br/&gt;
 	Vector &amp;lt;PRIV&amp;gt;,&lt;br/&gt;
	String Name&lt;br/&gt;
}&lt;/p&gt;

</comment>
                            <comment id="12699253" author="prasadc" created="Wed, 15 Apr 2009 16:10:28 +0000"  >&lt;p&gt;This is great. I have few questions..&lt;br/&gt;
1) What would be the syntax to create user/passwd combos and logging in?&lt;br/&gt;
2) Are the permissions stored in metastore are per user or per table or a combo? &lt;br/&gt;
3) Do we really need groups? I don&apos;t think MySQL implements groups.&lt;br/&gt;
4) I am totally naive in authentication systems, but I am assuming only access details are stored in metastore and authentication is done by one of the systems discussed. is that correct?&lt;/p&gt;</comment>
                            <comment id="12699270" author="appodictic" created="Wed, 15 Apr 2009 16:39:19 +0000"  >&lt;p&gt;&amp;gt;&amp;gt; 1) What would be the syntax to create user/passwd combos and logging in?&lt;br/&gt;
username and password would come externally. I notice a hadoop Jira on authenticate via Kerb4 and LDAP. We are best off splitting the authentication and authorization as we spoke of above. user and group are your external posix groups&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; 2) Are the permissions stored in metastore are per user or per table or a combo? &lt;br/&gt;
They should be stored in the metastore.  a rule like GRANT * on &apos;&lt;b&gt;&apos; TO &apos;&lt;/b&gt;&apos; AS my_permission would have to be stored everywhere and that would be a PITA.&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; 3) Do we really need groups? I don&apos;t think MySQL implements groups&lt;br/&gt;
 The group is your posix login group. Allowing groups is a simple way to reduce the number of per user rules.&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; 4) &lt;br/&gt;
Right again. The separation here is we let the authentication system carry all the burden of username, groups and password. The metastore is only concerned with what that user can do inside hive. &lt;/p&gt;</comment>
                            <comment id="12699306" author="athusoo" created="Wed, 15 Apr 2009 18:25:18 +0000"  >&lt;p&gt;I agree, it is best to punt authentication to the authentication systems (LDAP, kerb etc. etc.) and concentrate on authorization (privileges) here.&lt;/p&gt;

&lt;p&gt;About the syntax:&lt;/p&gt;

&lt;p&gt;1.  I am not sure what AS is used for.&lt;br/&gt;
2. column level permissions are good but they can perhaps be addressed with views and treating permissions on views as we do for tables.&lt;br/&gt;
3. I would add the key word TABLE in the GRANT statement, like mysql because we may have permissions on User defined functions and types in future... so something like..&lt;br/&gt;
   GRANT SELECT ON TABLE &apos;cat1&apos; TO &apos;USER1&apos; &lt;br/&gt;
4. Also maybe in the TO clause make the user and group explict - TO USERS a, b, c GROUPS g1, g2  otherwise the reader of the command may not know what is a group and what is a user. I presume this would also make the authorization logic somewhat simpler as you would know exactly what to look for?&lt;/p&gt;

&lt;p&gt;About the blocker that you mentioned, we should perhaps let the hadoop file permissions be independent of Hive ACLs. Of course you need both to be able to do anything on the table. Can be tricky though.. Will spend a bit more time thinking about this - this looks pretty cool...&lt;/p&gt;</comment>
                            <comment id="12699313" author="appodictic" created="Wed, 15 Apr 2009 18:55:08 +0000"  >&lt;p&gt;All those points make sense. &lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;1. I am not sure what AS is used for.&lt;br/&gt;
I am thinking AS is the way to name the PermissionSet. Imagine a rule like this:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;GRANT WITH_GRANT,RC, ON &apos;*&apos; TO &apos;USER1&apos;,&apos;USER2&apos; AS my_permission
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;At some point &apos;USER3&apos; might become an administrator. It would be nice to issue a command like:  &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ALTER GRANT my_permission add USER &apos;USER3&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It also makes the grant self documenting.&lt;/p&gt;</comment>
                            <comment id="12717814" author="appodictic" created="Tue, 9 Jun 2009 20:47:16 +0000"  >&lt;p&gt;The metastore would be a good place to start the ball rolling. Any comments?&lt;/p&gt;
</comment>
                            <comment id="12755876" author="coderplay" created="Wed, 16 Sep 2009 04:32:53 +0000"  >&lt;p&gt;we will take over this issue, it would be finished in two weeks.  Here are the sql statements will be added:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;CREATE USER, 
DROP USER;
ALTER USER SET PASSOWRD;
GRANT;
REVOKE
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Metadata is stored at some sort of persistent media such as mysql DBMS through jdo.  We will add three tables for this issue, they are USER, DBS_PRIV, TABLES_PRIV. Privileges can be granted at several levels, each table above are corresponding to a privilege level. &lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Global level&lt;br/&gt;
Global privileges apply to all databases on a given server. These privileges are stored in the USER table. GRANT ALL ON &lt;b&gt;.&lt;/b&gt; and REVOKE ALL ON &lt;b&gt;.&lt;/b&gt; grant and revoke only global privileges. &lt;br/&gt;
GRANT ALL ON &lt;b&gt;.&lt;/b&gt; TO &apos;someuser&apos;;&lt;br/&gt;
GRANT SELECT, INSERT ON &lt;b&gt;.&lt;/b&gt; TO &apos;someuser&apos;;&lt;/li&gt;
&lt;/ol&gt;


&lt;ol&gt;
	&lt;li&gt;Database level&lt;br/&gt;
Database privileges apply to all objects in a given database. These privileges are stored in the DBS_PRIV table. GRANT ALL ON db_name.* and REVOKE ALL ON db_name.* grant and revoke only database privileges. &lt;br/&gt;
GRANT ALL ON mydb.* TO &apos;someuser&apos;;&lt;br/&gt;
GRANT SELECT, INSERT ON mydb.* TO &apos;someuser&apos;;&lt;br/&gt;
Although we can&apos;t create DBs currently,  it would take a reserved place till hive support.&lt;/li&gt;
&lt;/ol&gt;


&lt;ol&gt;
	&lt;li&gt;Table level&lt;br/&gt;
Table privileges apply to all columns in a given table. These privileges are stored in the TABLES_PRIV table. GRANT ALL ON db_name.tbl_name and REVOKE ALL ON db_name.tbl_name grant and revoke only table privileges. &lt;br/&gt;
GRANT ALL ON mydb.mytbl TO &apos;someuser&apos;;&lt;br/&gt;
GRANT SELECT, INSERT ON mydb.mytbl TO &apos;someuser&apos;;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Hive account information is stored in USER table, includes username, password and kinds of privileges. User who has been granted any privilege to, such as select/insert/drop on a particular table, always have a right to show that table.&lt;/p&gt;
</comment>
                            <comment id="12755882" author="coderplay" created="Wed, 16 Sep 2009 04:47:21 +0000"  >&lt;p&gt; We currently use seperated mysql dbs for achieving an isolated CLI environment, which is not practical. An authentication infrastructure is urgently needed for us.&lt;/p&gt;

&lt;p&gt;Almost all statements would be influenced, for example&lt;br/&gt;
SELECT &lt;br/&gt;
INSERT&lt;br/&gt;
SHOW TABLES&lt;br/&gt;
SHOW PARTITIONS&lt;br/&gt;
DESCRIBE TABLE&lt;br/&gt;
MSCK&lt;br/&gt;
CREATE TABLE&lt;br/&gt;
CREATE FUNCTION &amp;#8211; we are considering how to control people creating udfs.&lt;br/&gt;
DROP TABLE&lt;br/&gt;
DROP FUNCTION&lt;br/&gt;
LOAD&lt;br/&gt;
added with GRANT/REVOKE themselft, and CREATE USER/DROP USER/SET PASSWORD. Even includes some non-sql commands like set , add file ,add jar. &lt;/p&gt;</comment>
                            <comment id="12756068" author="appodictic" created="Wed, 16 Sep 2009 14:56:12 +0000"  >&lt;p&gt;Min,&lt;/p&gt;

&lt;p&gt;First, let me say you have probably come along much farther then me on this issue.&lt;/p&gt;

&lt;p&gt;Your approach is too strong. Hive is an open-community process. Through it is not very detailed we have loosely agreed on a spec (above), in that spec we have decided not to store username/password information in hive. Rather upstream is still going to be responsible for this information. We also agreed on syntax.&lt;/p&gt;

&lt;p&gt;You should not throw up a new spec, and some code, and say something along the lines of  &quot;We are going to take over and do it this way&quot;. Imagine if each jira issue you working on you were 20% to 50% done. And then someone jumped in and said &quot;I already finished it a different way&quot;, that would be rather annoying. It would be a &quot;first patch wins&quot; system. &lt;/p&gt;

&lt;p&gt;First, before you are going to write a line of code you should let someone know your intention to work on it. Otherwise what is the point of having two people work on something where one version gets thrown away? It is a waste, and this would be the second issue this has happened to me. &lt;/p&gt;

&lt;p&gt;Second even if you want to starting coding it up it has to be what people agreed on. We agreed not to store user/pass (hadoop will be doing this upstream soon), and we agreed on syntax, if you want to reopen that issue you should discuss it before coding it. It has to be good for the community, not just your deployment.&lt;/p&gt;

&lt;p&gt;So where do we go from here? Do we go back to the design phase and describe all the syntax we want to support?&lt;/p&gt;</comment>
                            <comment id="12756335" author="coderplay" created="Thu, 17 Sep 2009 02:26:33 +0000"  >&lt;p&gt;@Edward&lt;/p&gt;

&lt;p&gt;Sorry for my abuse of some words,  I hope this will not affect our work.  &lt;/p&gt;

&lt;p&gt;Can you give me the jiras you decided not to store username/password information in hive and hadoop will?  	&lt;br/&gt;
I think most companies are using hadoop versions from 0.17 to 0.20 , which don&apos;t have good password securities. Once  a company takes a particular version, upgrades for them is a very important issue, many companies will adopt a more stable version. Moreover, now hadoop still do not have that feature, which may cost a very long time to implement.  Why should we are waiting for, rather than accomplish it? I think Hive is necessary to support user/password at least for current versions of hadoop. There are many companies who are using hive reflected that current hive is inconvenient for multi-user, as long as environment isolation, table sharing, security, etc. We must try to meet the requirements of most of them.&lt;/p&gt;

&lt;p&gt;Regarding the syntax, I guess we can do it in two steps. &lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;support GRANT/REVOKE privileges to users.&lt;/li&gt;
	&lt;li&gt;support some sort of server administration privileges as Ashish metioned.&lt;br/&gt;
The GRANT statement enables system administrators to create Hive user accounts and to grant rights to accounts. To use GRANT, you must have the GRANT OPTION privilege, and you must have the privileges that you are grantingad. The REVOKE statement is related and enables ministrators to remove account privileges.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt; File hive-78-syntax-v1.patch modifies the syntax. Any comments on that?&lt;/p&gt;</comment>
                            <comment id="12756662" author="namit" created="Thu, 17 Sep 2009 17:57:13 +0000"  >&lt;p&gt;I think, we should spend some time on finalizing the functionality before implementing it - it is very difficult to change something once it is out, due to all kinds of backward compatibility issues.&lt;/p&gt;

&lt;p&gt;For the syntax, AS&lt;/p&gt;

&lt;p&gt;wont it be simpler to add permissions to a role, and then assign roles to a user.&lt;/p&gt;



&lt;p&gt;GRANT WITH_GRANT,RC, ON &apos;*&apos; TO &apos;USER1&apos;,&apos;USER2&apos; AS my_permission&lt;/p&gt;

&lt;p&gt;ALTER GRANT my_permission add USER &apos;USER3&apos;&lt;/p&gt;


&lt;p&gt;Can I revoke some privileges from my_permissions ?&lt;/p&gt;

&lt;p&gt;If yes, how is it different from doing the two things differently ?&lt;/p&gt;


&lt;p&gt;CREATE ROLE my_permission AS GRANT WITH_GRANT,RC, ON &apos;*&apos; ;&lt;br/&gt;
GRANT my_permission to USER1, USER2;&lt;/p&gt;

&lt;p&gt;later&lt;/p&gt;

&lt;p&gt;GRANT my_permission to USER3;&lt;/p&gt;</comment>
                            <comment id="12756817" author="appodictic" created="Thu, 17 Sep 2009 22:18:17 +0000"  >&lt;p&gt;@namit,&lt;/p&gt;

&lt;p&gt;I think, I can explain why AS made sense at the time. My plan was not to decouple users from a rule. See my little patch.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+struct AccessControl {
+  1: list&amp;lt;string&amp;gt;	user,
+  2: list&amp;lt;string&amp;gt;	group,
+  3: list&amp;lt;string&amp;gt;	database,
+  4: list&amp;lt;string&amp;gt;	table,
+  5: list&amp;lt;string&amp;gt;	partition,
+  6: list&amp;lt;string&amp;gt;	column,
+  7: list&amp;lt;string&amp;gt;	priv,
+  8: string		name
+}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I wanted to be more or less immutable or support really simple syntax.&lt;/p&gt;

&lt;p&gt;Something like this is doable&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;GRANT my_permission to USER3;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;But it seems to imply that users are decoupled from the rule. &lt;br/&gt;
This is really not true (in my design) a user or group is just another multivalued attribute of the rule. &lt;/p&gt;

&lt;p&gt;I would like the format to be inter-changable &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ALTER my_permission add db &apos;db&apos;;
ALTER my_permission add table &apos;db.table&apos;;
ALTER my_permission drop table &apos;db.table&apos;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;@Min,&lt;br/&gt;
Above in this Jira see Ashish&apos;s comment..&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;I agree, it is best to punt authentication to the authentication systems (LDAP, kerb etc. etc.) and concentrate on authorization (privileges) here. 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The goal here is to trust the User/group information as hadoop does, and create a system that grants/revokes privileges.  Authentication and Authorization are two separate things so our Jira is misnamed &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I will review your patch, just to see what you came up with. As I said, you are farther along then I am, and this has been off my radar so I don&apos;t mind passing the baton, but Namit is right we have to agree on the syntax because and what we are controlling because down the road it will be an issue.&lt;/p&gt;


</comment>
                            <comment id="12756823" author="athusoo" created="Thu, 17 Sep 2009 22:35:02 +0000"  >&lt;p&gt;@Min&lt;/p&gt;

&lt;p&gt;I agree with Edwards thought here. We have to foster a collaborative environment and not be dismissive of each others ideas and approaches. Much of the work in the community happens on a volunteer basis and whatever time anyone puts on the project is a bonus and should be respected by all. &lt;/p&gt;

&lt;p&gt;It does make sense to keep authentication separate from authorization because in most environments there are already directories which deal with the former. Creating yet another store for passwords just leads to an administration nightmare as the account administrators have to create accounts for new users at multiple places. So lets just focus on authorization and let the directory infrastructure deal with authentication. Will look at your patch as well.&lt;/p&gt;

</comment>
                            <comment id="12756904" author="coderplay" created="Fri, 18 Sep 2009 02:04:00 +0000"  >&lt;p&gt;Let me guess, you are all talking about CLI. But we are using HiveServer as a multi-user server, not just support only one user  like mysqld does.&lt;/p&gt;</comment>
                            <comment id="12756936" author="appodictic" created="Fri, 18 Sep 2009 03:18:28 +0000"  >&lt;p&gt;@Min&lt;/p&gt;

&lt;p&gt;I would think the code should apply to any client cli, hive server, or HWI. &lt;/p&gt;

&lt;p&gt;We should probably also provide a configuration variable &lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&amp;lt;property&amp;gt;
   &amp;lt;name&amp;gt;hive.authorize&amp;lt;/name&amp;gt;
   &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12756949" author="coderplay" created="Fri, 18 Sep 2009 03:54:09 +0000"  >&lt;p&gt;I do not think the HiveServer in your mind is the same as mine, which support multiple users, not only one.&lt;/p&gt;</comment>
                            <comment id="12756951" author="coderplay" created="Fri, 18 Sep 2009 03:59:14 +0000"  >&lt;p&gt;From the words you commented:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Daemons like HiveService and HiveWebInterface will have to run as supergroup or a hive group? 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12757179" author="appodictic" created="Fri, 18 Sep 2009 14:25:39 +0000"  >&lt;p&gt;@Min&lt;br/&gt;
(this may be somewhat mistated but) Hadoop-Core gets the user/group information for a posix user by running shell commands like,&lt;br/&gt;
WHOAMI, GROUPS, ID, etc. The hive CLI will inherit this information as does HiveServer, HWI.&lt;/p&gt;

&lt;p&gt;The hive web interface starts as the user sho ran the start script. The first screen on the web interface is a defacto log-in screen. This allows the user to enter their user and group information in text boxes. &lt;/p&gt;

&lt;p&gt;When HWI starts the session on behalf of the user it runs &quot;SET hadoop.ugi=&lt;/p&gt;
{what user entered in the test box}
&lt;p&gt;&quot; at that point if the user initiates a hive job, the output of that job should be files owned by that user. I am pretty sure the code in QL just chown&apos;s the files at job end or perhaps the entire job runs as that user (I cant remember).&lt;/p&gt;

&lt;p&gt;My comment above is just referencing the fact that in some cases Hadoop ACL and our Hive authorization rules would conflict. IE&lt;br/&gt;
If the files were owned by mzhou. &quot;saying grant delete to * user edward&quot; would not give me privileges to drop files you owned. In that case sections of the HiveServer would have to run as superuser to elevate privileges, but we punted on that issue too. (We are like a football team with bad offense. always punting)&lt;/p&gt;

&lt;p&gt;(If we were going to tackle password we could do it in this way)&lt;br/&gt;
I would think if we wanted to enforce strong user/password authentication we could do this &lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&amp;lt;property&amp;gt;
   &amp;lt;name&amp;gt;hive.password.insession&amp;lt;/true&amp;gt;
  &amp;lt;value&amp;gt;hive_password&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;empty for no password checking, if defined this is the session variable to look for password&quot;&amp;lt;/descripton&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this way QL would read this value and would not execute any task for the user unless they had  run &quot;set hive_password=XYXYXYY&quot;&lt;/p&gt;

&lt;p&gt;Does that make sense? Session already holds the user. It could hold the password as well. Do you see anything wrong with that approach?&lt;/p&gt;

&lt;p&gt;I will trim down some of the stuff I have and get upload it for reference&lt;/p&gt;
</comment>
                            <comment id="12757252" author="namit" created="Fri, 18 Sep 2009 16:43:54 +0000"  >&lt;p&gt;coping a earlier comment from the jira:&lt;/p&gt;

&lt;p&gt;I agree that authentication and authorization (much of what I have been talking about in this comment), need to be separated out and while we use the directory infrastructure for authentication, we should store the authorization information in the metastore as that is specific to our application and no sane directory administrator would allow us to touch the directory to support custom attributes.&lt;/p&gt;

&lt;p&gt;I agree with the above - it might be a good idea to not do password handling in hive in the first step - we can add it later if need be. Let us assume that the user has already been authenticated by some external entity,&lt;br/&gt;
and proceed from there. What do you think ?&lt;/p&gt;</comment>
                            <comment id="12757299" author="appodictic" created="Fri, 18 Sep 2009 17:56:25 +0000"  >&lt;p&gt;@namit,&lt;/p&gt;

&lt;p&gt;Yes, I agree/agreed. I was off topic there, describing how we could do it if we wanted to. I will open a separate Jira for that. &lt;/p&gt;

&lt;p&gt;Upcoming at Hadoop World NYC someone is going to present the new authentication code in Hadoop, I would like to watch that then we(I) might better understand what the long term strategy is for Hadoop. I will split off authentication and authorization into two separate Jira to avoid confusion.&lt;/p&gt;</comment>
                            <comment id="12757300" author="appodictic" created="Fri, 18 Sep 2009 17:58:18 +0000"  >&lt;p&gt;This deals with authorization not authentication&lt;/p&gt;</comment>
                            <comment id="12757311" author="appodictic" created="Fri, 18 Sep 2009 18:19:07 +0000"  >&lt;p&gt;Fit authorization and authentication together&lt;/p&gt;</comment>
                            <comment id="12757615" author="coderplay" created="Sat, 19 Sep 2009 02:36:03 +0000"  >&lt;p&gt;well, I&apos;ve written a another Authorizer like your Authenticator yesterday&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;public enum Privilege {
   SELECT_PRIV,
   INSERT_PRIV,
   CREATE_PRIV,
   ALTER_PRIV,
   DROP_PRIV,
   CREATE_USER_PRIV,
   GRANT_PRIV,
   SUPER_PRIV
}
public interface Authenticator {
  public boolean authenticate(Privilege priv);
  public boolean authenticate(Privilege priv, Table table);
  public boolean authenticate(Privilege priv,  List&amp;lt;Table&amp;gt; table);
}

public class GenericAuthenticator {
  public GenericAuthenticator (Hive db, User user);
   ...
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and added a Authenticator instance info thread local SessionState.&lt;/p&gt;</comment>
                            <comment id="12757616" author="coderplay" created="Sat, 19 Sep 2009 02:36:55 +0000"  >&lt;p&gt;sorry, &lt;/p&gt;
{nofromat}&lt;br/&gt;
public class GenericAuthenticator extends  Authenticator {&lt;br/&gt;
  public GenericAuthenticator (Hive db, User user);&lt;br/&gt;
   ...&lt;br/&gt;
}{nofromat}</comment>
                            <comment id="12757621" author="appodictic" created="Sat, 19 Sep 2009 03:23:17 +0000"  >&lt;p&gt;@Min, &lt;/p&gt;

&lt;p&gt;I think you are on the right track. I think you might have your terminology mixed up. In AAA&lt;br/&gt;
The first A is authentication which usually implies supply a user/password.&lt;br/&gt;
second A authorize means what privileges the user has &lt;br/&gt;
third A is accounting ( we already have that)&lt;/p&gt;

&lt;p&gt;The interfaces you supplied above looks like an Authorizer.... not Authenticator. I think &lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;public interface Authorizer {
  public boolean authorize(Privilege priv);
  public boolean authorize(Privilege priv, Table table);
  public boolean authorize(Privilege priv,  List&amp;lt;Table&amp;gt; table);
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But you seem to be on a role. I will hang back and wait to see what you come up with.&lt;/p&gt;</comment>
                            <comment id="12757622" author="coderplay" created="Sat, 19 Sep 2009 03:35:43 +0000"  >&lt;p&gt;oops,  my code wasn&apos;t in my machine. I just pasted yours and modified it into mine. &lt;br/&gt;
here is a patch show my code on that.&lt;/p&gt;</comment>
                            <comment id="12757998" author="namit" created="Mon, 21 Sep 2009 19:12:42 +0000"  >&lt;p&gt;Looking at Min&apos;s patch createuser-v1.patch, &lt;/p&gt;

&lt;p&gt;I dont think we need create user/drop user etc. at all.&lt;/p&gt;

&lt;p&gt;As Edward mentioned before,&lt;br/&gt;
When HWI starts the session on behalf of the user it runs &quot;SET hadoop.ugi=&lt;/p&gt;
{what user entered in the test box}
&lt;p&gt;&quot; at that point if the user initiates a hive job, the output of that job should be files owned by that user. I am pretty sure the code in QL just chown&apos;s the files at job end or perhaps the entire job runs as that user (I cant remember).&lt;/p&gt;

&lt;p&gt;the user is always available from the environment and for now, let us assume that all authorizations happen to that user.&lt;/p&gt;</comment>
                            <comment id="12758112" author="coderplay" created="Tue, 22 Sep 2009 03:58:14 +0000"  >&lt;p&gt;@Namit&lt;/p&gt;

&lt;p&gt;Got your meaning.  We are maintaining a version of our own, it needs couples of weeks for adapting  to the trunk.&lt;/p&gt;</comment>
                            <comment id="12775117" author="royce" created="Mon, 9 Nov 2009 20:34:50 +0000"  >&lt;p&gt;I&apos;m very interested in working on this issue this week but don&apos;t want to tread on anyone&apos;s work.  What&apos;s the status?  &lt;br/&gt;
is anything checked in yet.  I&apos;d like to get this done as soon as possible. &lt;/p&gt;</comment>
                            <comment id="12802720" author="aaa" created="Wed, 20 Jan 2010 07:14:46 +0000"  >&lt;p&gt;I am also very curious what is latest on this jira, no updates since Sept of last year. Min, did you stop working on this? &lt;/p&gt;

&lt;p&gt;&amp;#8211; amr&lt;/p&gt;</comment>
                            <comment id="12919104" author="namit" created="Thu, 7 Oct 2010 23:48:53 +0000"  >&lt;p&gt;Is anyone working on this ?&lt;/p&gt;</comment>
                            <comment id="12923597" author="cwsteinbach" created="Thu, 21 Oct 2010 19:31:05 +0000"  >&lt;p&gt;Authorization proposal on the wiki: &lt;a href=&quot;http://wiki.apache.org/hadoop/Hive/AuthDev&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Hive/AuthDev&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12923598" author="namit" created="Thu, 21 Oct 2010 19:34:58 +0000"  >&lt;p&gt;Please comment - we would like to hear all use cases before finalizing the design.&lt;/p&gt;</comment>
                            <comment id="12923624" author="dhruba" created="Thu, 21 Oct 2010 20:42:32 +0000"  >&lt;p&gt;Can somebody pl comment on how this ties in with HDFS permission/authorization? There is a small subsection in the doc about this issue, but I am unable to understand that part.&lt;/p&gt;</comment>
                            <comment id="12923642" author="he yongqiang" created="Thu, 21 Oct 2010 21:12:46 +0000"  >&lt;p&gt;@dhruba&lt;br/&gt;
HDFS has its own authorization. So if we allow an access in Hive layer and pass this access to HDFS (by setting the correct hdfs username and groups), the job can fail with HDFS permission problem. &lt;br/&gt;
So need to solve the problem from 2 layer independent authorization.&lt;br/&gt;
One way to allow all accesses to HDFS, and let hive do the authorization. So hive runs as root in terms of HDFS.&lt;br/&gt;
The other way is to plug in HDFS authorization to Hive layer, and only accept one access if both of Hive and HDFS say YES.  A user belongs to different unix groups, and set hdfs permission based on the unix group. [ I am not sure about how many groups a user can have in terms of HDFS. I mean how many group settings you can put to a hdfs file. Let&apos;s simply say i want these 2 groups to be able to read the file.]  The another problem is the column level privileges.&lt;br/&gt;
This is very open for discussion, please comment on it.&lt;/p&gt;


&lt;p&gt;About the proposal, there is one authorization rule that we are not sure about. It&apos;s the simple rule: one deny then deny.&lt;/p&gt;

&lt;p&gt;Let&apos;s say this example:&lt;br/&gt;
5.3.1 I want to grant everyone (new people may join at anytime) to db_name.*, and then later i want to protect one table db_name.T from ALL users but a few&lt;br/&gt;
1) Add all users to a group &apos;users&apos;. (assumption: new users will automatically join this group). And grant &apos;users&apos; ALL privileges to db_name.*&lt;br/&gt;
2) Add those few users to a new group &apos;users2&apos;. AND REMOVE them from &apos;users&apos;&lt;br/&gt;
3) DENY &apos;users&apos; to db_name.T&lt;br/&gt;
4) Grant ALL on db_name.T to users2&lt;/p&gt;

&lt;p&gt;The main problem in this approach is that &quot;REMOVE them from &apos;users&apos;&quot; is not practicable. &lt;/p&gt;


&lt;p&gt;The other options that we have thought about is another rule.&lt;/p&gt;

&lt;p&gt;First try user name:&lt;/p&gt;

&lt;p&gt;first try to deny this access by look up the deny tables by user name:&lt;/p&gt;

&lt;p&gt;1. If there is an entry in &apos;user&apos; that deny this access, return DENY&lt;br/&gt;
2. If there is an entry in &apos;db&apos;  that deny this access, return DENY&lt;br/&gt;
3. If there is an entry in &apos;table&apos;  that deny this access, return DENY&lt;br/&gt;
4. If there is an entry in &apos;column&apos;  that deny this access, return DENY&lt;/p&gt;

&lt;p&gt;If we got one deny, will return deny for this attempt.&lt;/p&gt;

&lt;p&gt;if deny failed, go through all privilege levels with the user name:&lt;/p&gt;

&lt;p&gt;5. If there is an entry in &apos;user&apos; that accept this access, return ACCEPT&lt;br/&gt;
6. If there is an entry in &apos;db&apos;  that accept this access, return ACCEPT&lt;br/&gt;
7. If there is an entry in &apos;table&apos;  that accept this access, return ACCEPT&lt;br/&gt;
8. If there is an entry in &apos;column&apos;  that accept this access, return ACCEPT&lt;/p&gt;


&lt;p&gt;Second try the user&apos;s group/role names one by one until we get an ACCEPT. If we get an ACCEPT from one group/role, will ACCEPT this access. Else deny.&lt;/p&gt;

&lt;p&gt;For each role/group, we do the same routine as we did for user name.&lt;br/&gt;
The problem with this approach is it&apos;s a little bit complex and we did not find any system that use this. For mysql, there is no deny. For sql server, it&apos;s one deny then deny.&lt;/p&gt;</comment>
                            <comment id="12923667" author="he yongqiang" created="Thu, 21 Oct 2010 22:17:42 +0000"  >&lt;p&gt;The other option we came up from offline discussion is the rule of &quot;one accept then accept&quot; but in a hierarchy style. First check privileges granted the user and groups. One accept then accept; One deny then deny. And then check role level privileges, one accept then accept; one deny then deny.&lt;/p&gt;

&lt;p&gt;We prefer to go with this rule. Please comment, and if no concerns on this, i will update the wiki.&lt;/p&gt;</comment>
                            <comment id="12923671" author="he yongqiang" created="Thu, 21 Oct 2010 22:25:43 +0000"  >&lt;p&gt;Sorry, in the previous comment: by &quot;one accept then accept; one deny then deny&quot;, i mean &quot;Accept overwrite deny. one accept then accept; no accept then deny&quot;&lt;/p&gt;</comment>
                            <comment id="12923719" author="tlipcon" created="Fri, 22 Oct 2010 00:50:47 +0000"  >&lt;p&gt;I&apos;m a little unclear on how the user identity is passed down to the MR layer. Carl and I had chatted about this a few weeks back &amp;#8211; is the idea now that all hive queries will run MR jobs as a &quot;hive&quot; user, rather than &quot;todd&quot;? If so, we need to add authorization control for UDFs and TRANSFORM as well, since a user could trivially take over the &quot;hive&quot; user credentials from within a UDF. If the MR jobs will continue to run as &quot;todd&quot;, then I don&apos;t understand how we can apply any permissions model that is any different than HDFS permissions. More restrictive is impossible because I can just read the files myself, and less restrictive is impossible because HDFS is applying permissions based on the &quot;todd&quot; identity.&lt;/p&gt;</comment>
                            <comment id="12923733" author="cwsteinbach" created="Fri, 22 Oct 2010 01:42:42 +0000"  >&lt;p&gt;The issue that Todd raised is pretty important and needs to be addressed in the proposal.&lt;br/&gt;
My personal opinion is that running all queries as a &quot;hive&quot; super-user is the most&lt;br/&gt;
practical approach and will also yield behavior that is familiar to users of traditional&lt;br/&gt;
RDBMS systems (who I expect will increasingly define the average Hive user/administrator).&lt;/p&gt;

&lt;p&gt;There are some other follow-on issues that need to be decided if we end up settling&lt;br/&gt;
on this approach:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;This approach to authorization presupposes that users are accessing Hive through a HiveServer process. This follows from the fact that A) you want Hive to execute the query plans as the Hive superuser, and B) that user can circumvent the authorization model if they are given direct access to the MetaStore DB. It would be nice if the proposal explicitly stated this requirement and mentioned some of the follow-on work that this necessitates, e.g. fixing concurrency issues in HiveServer, reducing the memory requirements of HiveServer, etc.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;We need to apply the authorization model to the &apos;&lt;tt&gt;add &lt;span class=&quot;error&quot;&gt;&amp;#91;archive|file|jar&amp;#93;&lt;/span&gt;&lt;/tt&gt;&apos; commands as well as &lt;tt&gt;add temorary function&lt;/tt&gt;. &lt;tt&gt;add jar&lt;/tt&gt; and &lt;tt&gt;add file&lt;/tt&gt; both currently allow the user to inject code into MR jobs, and &lt;tt&gt;add jar&lt;/tt&gt; in conjunction with &lt;tt&gt;add temporary function&lt;/tt&gt; allows the user to inject and execute arbitrary code within the HiveServer process. We may also want to add a new &lt;tt&gt;add executable&lt;/tt&gt; command for adding executable scripts that has a different permission model than &lt;tt&gt;add file&lt;/tt&gt;.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I think there also may be security issues stemming from external tables, e.g. if I create an external table that points to another user&apos;s home directory and then run a query on it which executes with Hive&apos;s superuser permissions.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Loading date into the Hive warehouse from an arbitrary HDFS location and exporting data to other locations in HDFS are two issues that need to be considered. In each case I think the correct behavior depends on both the Hive process&apos;s permissions and those of the user.&lt;/li&gt;
&lt;/ul&gt;


</comment>
                            <comment id="12923734" author="he yongqiang" created="Fri, 22 Oct 2010 01:49:14 +0000"  >&lt;p&gt;By-passing the hdfs permission from hive layer is just one option. And the implementation should also support setting user groups in the hdfs side. And let the mapreduce job run as the user.&lt;/p&gt;

&lt;p&gt;Just a quick update about the authorization rule:&lt;/p&gt;

&lt;p&gt;In the offline discussion we had internally this afternoon, remove DENY should also another option to be considered. And we examined our use cased with this (without DENY), it works. So remove DENY from the authorization will simplify the implementation a lot.&lt;/p&gt;

&lt;p&gt;And regarding view and index, for the first version, we should not do that. And we can do them later when we have a better understanding after we implement the first version.&lt;/p&gt;</comment>
                            <comment id="12924026" author="namit" created="Fri, 22 Oct 2010 21:03:23 +0000"  >&lt;p&gt;Overall, there are many security holes in the system. and we are not proposing to close all of them.&lt;/p&gt;

&lt;p&gt;To start with, it is an attempt for good users, it is not meant for the malicious users - &lt;br/&gt;
the idea is to prevent good users from committing a mistake.&lt;/p&gt;</comment>
                            <comment id="12924032" author="jvs" created="Fri, 22 Oct 2010 21:20:20 +0000"  >&lt;p&gt;(implementation note)&lt;/p&gt;

&lt;p&gt;If we really need multiple metastore tables, let&apos;s name them consistently:&lt;/p&gt;

&lt;p&gt;user_priv&lt;br/&gt;
db_priv&lt;br/&gt;
tbl_priv&lt;br/&gt;
col_priv&lt;/p&gt;</comment>
                            <comment id="12924039" author="cwsteinbach" created="Fri, 22 Oct 2010 21:32:04 +0000"  >&lt;p&gt;@Namit: I think it&apos;s fine to take an incremental approach with this, but then it&apos;s important&lt;br/&gt;
to spell out what the known security holes are so users and administrators&lt;br/&gt;
know what they&apos;re getting. Otherwise we&apos;re going to spend a lot of time answering&lt;br/&gt;
questions on the hive-user list.&lt;/p&gt;
</comment>
                            <comment id="12928136" author="he yongqiang" created="Thu, 4 Nov 2010 06:28:47 +0000"  >&lt;p&gt;Attach two patches. One is including thrift generated code in case anyone wants to try it. &lt;br/&gt;
The other is just java code changes for a clean review.&lt;/p&gt;

&lt;p&gt;These two patches only contains DDL and metadata changes. There are no integration code with query execution part. will do that in the following patch.&lt;/p&gt;

&lt;p&gt;Some examples:&lt;/p&gt;

&lt;p&gt;    &amp;gt; show grant user `test` on table `src`;                 &lt;br/&gt;
OK&lt;br/&gt;
Time taken: 0.081 seconds&lt;/p&gt;

&lt;p&gt;hive&amp;gt; grant `select` on table src to user test, group grp;   &lt;br/&gt;
OK&lt;br/&gt;
Time taken: 0.118 seconds&lt;/p&gt;

&lt;p&gt;hive&amp;gt; show grant user `test` on table `src`;              &lt;br/&gt;
OK&lt;br/&gt;
dbName:default&lt;br/&gt;
tableName:src&lt;br/&gt;
userName:test&lt;br/&gt;
isRole:false&lt;br/&gt;
isGroup:false&lt;br/&gt;
privileges:Select&lt;br/&gt;
grantTime:1288850969&lt;br/&gt;
grantor:&lt;br/&gt;
grantor:&lt;br/&gt;
Time taken: 0.09 seconds&lt;/p&gt;

&lt;p&gt;hive&amp;gt; show grant group `grp` on table `src`;                 &lt;br/&gt;
OK&lt;br/&gt;
dbName:default&lt;br/&gt;
tableName:src&lt;br/&gt;
userName:grp&lt;br/&gt;
isRole:false&lt;br/&gt;
isGroup:true&lt;br/&gt;
privileges:Select&lt;br/&gt;
grantTime:1288850969&lt;br/&gt;
grantor:&lt;br/&gt;
grantor:&lt;br/&gt;
Time taken: 0.08 seconds&lt;/p&gt;

&lt;p&gt;hive&amp;gt; revoke `select` on table src from user test;           &lt;br/&gt;
OK&lt;br/&gt;
Time taken: 0.041 seconds&lt;/p&gt;

&lt;p&gt;hive&amp;gt; show grant user `test` on table `src`;      &lt;br/&gt;
OK&lt;br/&gt;
Time taken: 0.078 seconds&lt;/p&gt;

&lt;p&gt;hive&amp;gt; show grant group `grp` on table `src`;      &lt;br/&gt;
OK&lt;br/&gt;
dbName:default&lt;br/&gt;
tableName:src&lt;br/&gt;
userName:grp&lt;br/&gt;
isRole:false&lt;br/&gt;
isGroup:true&lt;br/&gt;
privileges:Select&lt;br/&gt;
grantTime:1288850969&lt;br/&gt;
grantor:&lt;br/&gt;
grantor:&lt;br/&gt;
Time taken: 0.079 seconds&lt;/p&gt;

&lt;p&gt;&amp;gt;grant `select`(key, value) on table src to user test;&lt;br/&gt;
OK&lt;br/&gt;
Time taken: 0.174 seconds&lt;/p&gt;

&lt;p&gt;&amp;gt; show grant user `test` on table `src`(key);       &lt;br/&gt;
OK&lt;br/&gt;
dbName:default&lt;br/&gt;
tableName:src&lt;br/&gt;
columnName:key&lt;br/&gt;
userName:test&lt;br/&gt;
isRole:false&lt;br/&gt;
isGroup:false&lt;br/&gt;
privileges:Select&lt;br/&gt;
grantTime:1288851160&lt;br/&gt;
grantor:&lt;br/&gt;
grantor:&lt;br/&gt;
Time taken: 6.722 seconds&lt;/p&gt;

&lt;p&gt;hive&amp;gt; show grant user `test` on table `src`(key, value);&lt;br/&gt;
OK&lt;br/&gt;
dbName:default&lt;br/&gt;
tableName:src&lt;br/&gt;
columnName:key&lt;br/&gt;
userName:test&lt;br/&gt;
isRole:false&lt;br/&gt;
isGroup:false&lt;br/&gt;
privileges:Select&lt;br/&gt;
grantTime:1288851160&lt;br/&gt;
grantor:&lt;br/&gt;
dbName:default&lt;br/&gt;
tableName:src&lt;br/&gt;
columnName:value&lt;br/&gt;
userName:test&lt;br/&gt;
isRole:false&lt;br/&gt;
isGroup:false&lt;br/&gt;
privileges:Select&lt;br/&gt;
grantTime:1288851160&lt;br/&gt;
grantor:&lt;br/&gt;
grantor:&lt;/p&gt;</comment>
                            <comment id="12929888" author="jvs" created="Tue, 9 Nov 2010 02:01:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/55/diff/#index_header&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/55/diff/#index_header&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12929896" author="jvs" created="Tue, 9 Nov 2010 02:20:59 +0000"  >&lt;p&gt;It looks like &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-78&quot; title=&quot;Authorization infrastructure for Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-78&quot;&gt;&lt;del&gt;HIVE-78&lt;/del&gt;&lt;/a&gt;.1.nothrift.patch still has a bunch of thrift-generate files in it (metastore/src/gen-javabean/org/apache/hadoop/hive/metastore/api/*)&lt;/p&gt;</comment>
                            <comment id="12930820" author="pkamath" created="Wed, 10 Nov 2010 22:50:32 +0000"  >&lt;p&gt;Will there be a way to turn off authorization (through some configuration property) OR is there a way to allow all access OR is authorization implementation going to be pluggable? Since howl is looking at a different authorization model based on dfs permissions, one of these options would be needed for howl.&lt;/p&gt;</comment>
                            <comment id="12930822" author="he yongqiang" created="Wed, 10 Nov 2010 23:06:40 +0000"  >&lt;p&gt;&amp;gt;&amp;gt;Will there be a way to turn off authorization (through some configuration property) &lt;br/&gt;
Yes.&lt;br/&gt;
&amp;gt;&amp;gt;is authorization implementation going to be pluggable? &lt;br/&gt;
Yes. This is exactly what we wanted.&lt;/p&gt;

&lt;p&gt;I think Howl can just plug in its own authorization implementation. &lt;/p&gt;</comment>
                            <comment id="12930946" author="he yongqiang" created="Thu, 11 Nov 2010 06:47:35 +0000"  >&lt;p&gt;Attached 2 new draft patches.  &lt;/p&gt;

&lt;p&gt;There maybe some bugs since i only did a few simple tests. But i think they are ready for early review.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-78&quot; title=&quot;Authorization infrastructure for Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-78&quot;&gt;&lt;del&gt;HIVE-78&lt;/del&gt;&lt;/a&gt;.2.nothrift.patch does not include the thrift changes.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-78&quot; title=&quot;Authorization infrastructure for Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-78&quot;&gt;&lt;del&gt;HIVE-78&lt;/del&gt;&lt;/a&gt;.2.thrift.patch is a complete patch.&lt;/p&gt;</comment>
                            <comment id="12931504" author="namit" created="Fri, 12 Nov 2010 19:25:22 +0000"  >&lt;p&gt;Can you add the tests in the non-thrift patch ? It becomes easier to review&lt;/p&gt;</comment>
                            <comment id="12931518" author="namit" created="Fri, 12 Nov 2010 20:19:55 +0000"  >&lt;p&gt;Also, can you refresh and re-apply the patch ? It does not apply cleanly and is therefore not possible to actually compile/test and understand.&lt;/p&gt;</comment>
                            <comment id="12932306" author="namit" created="Tue, 16 Nov 2010 01:27:01 +0000"  >&lt;p&gt;Few minor comments:&lt;/p&gt;

&lt;p&gt;1. Can you add more comments in M* files (the new files in the metastore) ?&lt;br/&gt;
2. MRoleEntiry needs a database name - so does the thirft file ?&lt;br/&gt;
3. Can you verify that create and create table as select works for hive replication ?&lt;br/&gt;
4. Can you check who adds inputs/outputs for locking operations ?&lt;/p&gt;</comment>
                            <comment id="12932354" author="namit" created="Tue, 16 Nov 2010 06:41:25 +0000"  >&lt;p&gt;Driver:&lt;br/&gt;
      //do the authorization check&lt;br/&gt;
385         if (HiveConf.getBoolVar(conf,&lt;br/&gt;
386                   HiveConf.ConfVars.HIVE_AUTHORIZATION_ENABLED)) {&lt;br/&gt;
387                           boolean pass = doAuthorization(sem);&lt;br/&gt;
388                                   if (!pass) &lt;/p&gt;
{
389                                             console.printError(&quot;Authrizatio\
n failed (not enough privileges found t?
o run the query.).&quot;);
390             return (400);
391                     }
&lt;p&gt;392                           }&lt;/p&gt;


&lt;p&gt;Can we print the reason which privilege was missing ?&lt;/p&gt;



&lt;p&gt;Can we optimize the scenario - we are checking for all partitions one-by-one&lt;br/&gt;
both for inputs and outputs ? What if the user/group/role has the table&lt;br/&gt;
privilege - we dont need to go over all the partitions one by one.&lt;br/&gt;
We can even do this in a follow-up&lt;/p&gt;



&lt;p&gt;Why do we need the change in QueryPlan ?&lt;/p&gt;

&lt;p&gt;showGrants: should the output have a schema ? Going forwad, it will&lt;br/&gt;
be easier for JDBC clients to parse.&lt;/p&gt;

&lt;p&gt;No need	to change WriteEntity etc. ?&lt;/p&gt;

&lt;p&gt;user cannot be made a reserved word - ~20 tables have a	column called &apos;user&apos;&lt;br/&gt;
in facebook - please check &apos;role&apos; and &apos;option&apos;.&lt;/p&gt;

&lt;p&gt;SemanticAnalyzer: 3511 not needed&lt;/p&gt;


&lt;p&gt;What happens to	replication of roles - needs to	be done&lt;/p&gt;


&lt;p&gt;Where are the privileges copied	for a newly created partition ?&lt;/p&gt;</comment>
                            <comment id="12932587" author="namit" created="Tue, 16 Nov 2010 18:33:02 +0000"  >&lt;p&gt;In case of dynamic partitions, you can also have DummyPartition outputs.&lt;br/&gt;
They will contain the correct Table definition.&lt;br/&gt;
Are you taking care of them ?&lt;/p&gt;</comment>
                            <comment id="12933291" author="he yongqiang" created="Thu, 18 Nov 2010 02:11:18 +0000"  >&lt;p&gt;&amp;gt;&amp;gt;Can you check who adds inputs/outputs for locking operations ?&lt;/p&gt;

&lt;p&gt;It seems no inputs and outputs for lock/unlock.&lt;/p&gt;</comment>
                            <comment id="12933694" author="he yongqiang" created="Fri, 19 Nov 2010 06:21:54 +0000"  >&lt;p&gt;Attached 2 new patched. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-78&quot; title=&quot;Authorization infrastructure for Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-78&quot;&gt;&lt;del&gt;HIVE-78&lt;/del&gt;&lt;/a&gt;.4.complete.patch is a complete patch. &lt;br/&gt;
And &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-78&quot; title=&quot;Authorization infrastructure for Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-78&quot;&gt;&lt;del&gt;HIVE-78&lt;/del&gt;&lt;/a&gt;.4.no_thrift.patch does not contain thrift generated codes.&lt;/p&gt;</comment>
                            <comment id="12934719" author="he yongqiang" created="Tue, 23 Nov 2010 02:58:42 +0000"  >&lt;p&gt;A new patch.&lt;/p&gt;

&lt;p&gt;Had an internal group code review, the main changes are:&lt;br/&gt;
1) instead of calling metastore again to get partition&apos;s privilege information, pack user&apos;s privileges in Partition object when getting partition.&lt;br/&gt;
2) added a few configs for grant behavior on new tables.&lt;/p&gt;

&lt;p&gt;&amp;lt;property&amp;gt;&lt;br/&gt;
  &amp;lt;name&amp;gt;hive.exec.security.authorization.table.owner.grants&amp;lt;/name&amp;gt;&lt;br/&gt;
  &amp;lt;value&amp;gt;&amp;lt;/value&amp;gt;&lt;br/&gt;
  &amp;lt;description&amp;gt;the privileges automatically granted to the owner&amp;lt;/description&amp;gt;&lt;br/&gt;
&amp;lt;/property&amp;gt;&lt;/p&gt;

&lt;p&gt;&amp;lt;property&amp;gt;&lt;br/&gt;
  &amp;lt;name&amp;gt;hive.exec.security.authorization.table.user.grants&amp;lt;/name&amp;gt;&lt;br/&gt;
  &amp;lt;value&amp;gt;&amp;lt;/value&amp;gt;&lt;br/&gt;
  &amp;lt;description&amp;gt;the privileges automatically granted to some users whenenve a table gets created. &lt;br/&gt;
   An example like &quot;userX,userY:select;userZ:create&quot; will grant select privilege to userX and userY, &lt;br/&gt;
   and grant create privilege to userZ whenenve a new table created.&amp;lt;/description&amp;gt;&lt;br/&gt;
&amp;lt;/property&amp;gt;&lt;/p&gt;

&lt;p&gt;&amp;lt;property&amp;gt;&lt;br/&gt;
  &amp;lt;name&amp;gt;hive.exec.security.authorization.table.group.grants&amp;lt;/name&amp;gt;&lt;br/&gt;
  &amp;lt;value&amp;gt;&amp;lt;/value&amp;gt;&lt;br/&gt;
  &amp;lt;description&amp;gt;the privileges automatically granted to some groups whenenve a table gets created. &lt;br/&gt;
   An example like &quot;groupX,groupY:select;groupZ:create&quot; will grant select privilege to groupX and groupY, &lt;br/&gt;
   and grant create privilege to groupZ whenenve a new table created.&amp;lt;/description&amp;gt;&lt;br/&gt;
&amp;lt;/property&amp;gt;&lt;/p&gt;

&lt;p&gt;&amp;lt;property&amp;gt;&lt;br/&gt;
  &amp;lt;name&amp;gt;hive.exec.security.authorization.table.role.grants&amp;lt;/name&amp;gt;&lt;br/&gt;
  &amp;lt;value&amp;gt;&amp;lt;/value&amp;gt;&lt;br/&gt;
  &amp;lt;description&amp;gt;the privileges automatically granted to some groups whenenve a table gets created. &lt;br/&gt;
   An example like &quot;roleX,roleY:select;roleZ:create&quot; will grant select privilege to roleX and roleY, &lt;br/&gt;
   and grant create privilege to roleZ whenenve a new table created.&amp;lt;/description&amp;gt;&lt;br/&gt;
&amp;lt;/property&amp;gt;&lt;/p&gt;

&lt;p&gt;3) changed privilege &apos;Overwrite&apos; to &apos;update&apos;&lt;/p&gt;</comment>
                            <comment id="12969890" author="jvs" created="Thu, 9 Dec 2010 19:35:38 +0000"  >&lt;p&gt;Taking a first look at this one; I will have a number of suggestions on naming/structure for thrift and JDO.  I think you accidentally omitted the org.apache.hadoop.hive.ql.security.authorization package since I see references to it but no code.&lt;/p&gt;</comment>
                            <comment id="12969896" author="he yongqiang" created="Thu, 9 Dec 2010 19:46:14 +0000"  >&lt;p&gt;You can find it from the complete patch.&lt;/p&gt;

&lt;p&gt;will rebase the patch against the new thrift.&lt;/p&gt;</comment>
                            <comment id="12969962" author="he yongqiang" created="Thu, 9 Dec 2010 22:07:18 +0000"  >&lt;p&gt;refresh patch against the trunk.&lt;/p&gt;</comment>
                            <comment id="12970662" author="jvs" created="Sun, 12 Dec 2010 21:44:24 +0000"  >&lt;p&gt;First batch of review comments.&lt;/p&gt;

&lt;p&gt;JDO:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Do we want roles to be contained by databases?  Let&apos;s discuss this&lt;br/&gt;
  at next design review.&lt;/li&gt;
	&lt;li&gt;Instead of two separate flags (IS_ROLE/IS_GROUP) should we instead use&lt;br/&gt;
  an enum for principal type 
{ USER, GROUP, ROLE }
&lt;p&gt;?&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;Naming suggestions (if accepted, propagate to Thrift API also):
	&lt;ul&gt;
		&lt;li&gt;SECURITYROLE -&amp;gt; ROLES&lt;/li&gt;
		&lt;li&gt;SECURITYROLEMAP -&amp;gt; ROLE_MAP&lt;/li&gt;
		&lt;li&gt;SECURITYUSER -&amp;gt; GLOBAL_PRIVS&lt;/li&gt;
		&lt;li&gt;SECURITYDB -&amp;gt; DB_PRIVS&lt;/li&gt;
		&lt;li&gt;SECURITYTBLPART -&amp;gt; TBLPART_PRIVS&lt;/li&gt;
		&lt;li&gt;SECURITYCOLUMN -&amp;gt; COL_PRIVS&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;VARCHAR precision for &quot;privileges&quot; fields should be 4000&lt;/li&gt;
	&lt;li&gt;Since we&apos;re going to need to record GRANT OPTION eventually, maybe&lt;br/&gt;
  we should add it now so that we don&apos;t have to ALTER TABLE later?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Thrift API:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Avoid embedding objects inside of other objects except where&lt;br/&gt;
  necessary.  For example, in the definition of struct Role, use&lt;br/&gt;
  dbName instead of a Database object (assuming we keep roles as&lt;br/&gt;
  contained by databases).  Likewise, in PrivilegeBag, the map keys&lt;br/&gt;
  should be identifiers, not objects.  This applies to quite a few of&lt;br/&gt;
  the new structs.&lt;/li&gt;
	&lt;li&gt;Can we reduce the number of new structs and API calls by&lt;br/&gt;
  consolidating different object types?  For example, for the&lt;br/&gt;
  get_XXX_privilege_set calls, just have one, and take object&lt;br/&gt;
  type+identifier.&lt;/li&gt;
	&lt;li&gt;Add comments for all new methods.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Config:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Why is hive.exec.security used for some config params instead of&lt;br/&gt;
  hive.security?  Also, those parameter names should make it clear&lt;br/&gt;
  that they are default grants.  Also, do we really need owner grants&lt;br/&gt;
  (don&apos;t owners automatically have full privileges implicitly)?&lt;/li&gt;
	&lt;li&gt;Looks like hive.variable.substitute crept in from some other patch.&lt;/li&gt;
	&lt;li&gt;Comments for plugin-loading parameters should make it explicit&lt;br/&gt;
  exactly which interface they are supposed to implement.&lt;/li&gt;
	&lt;li&gt;Comment for role grants says &quot;to some groups&quot; instead.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Pluggable Interfaces:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;I don&apos;t think we need the factory classes; just add new methods to&lt;br/&gt;
  HiveUtils (and follow the classloading pattern used there)&lt;/li&gt;
	&lt;li&gt;Rename AuthorizationProvider to HiveAuthorizationProvider&lt;br/&gt;
  and make it extend Configurable&lt;/li&gt;
	&lt;li&gt;Rename AuthorizationProviderManager to AbstractAuthorizationProvider&lt;/li&gt;
	&lt;li&gt;All outside references should be to the interface (HiveAuthorizationProvider)&lt;br/&gt;
  not the abstract class.&lt;/li&gt;
	&lt;li&gt;Rename Authenticator to HiveAuthenticationProvider and make it&lt;br/&gt;
  extend Configurable&lt;/li&gt;
	&lt;li&gt;Javadoc?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Typos:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;principla&lt;/li&gt;
	&lt;li&gt;Authrization&lt;/li&gt;
	&lt;li&gt;GrantInfor&lt;/li&gt;
	&lt;li&gt;privielges&lt;/li&gt;
	&lt;li&gt;&quot;Table is partitioned, but partition spec found&quot;&lt;/li&gt;
	&lt;li&gt;DummpyAuthenticator&lt;/li&gt;
	&lt;li&gt;detroy&lt;/li&gt;
	&lt;li&gt;wheenve&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Implementation:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;why does doAuthorization return a boolean when it just throws&lt;br/&gt;
  anyway?&lt;/li&gt;
	&lt;li&gt;more coming...&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12971161" author="jvs" created="Tue, 14 Dec 2010 04:31:30 +0000"  >&lt;p&gt;Some more from me:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;There&apos;s a bug when attempting to grant multiple privileges at once;&lt;br/&gt;
  only one of them is getting granted (what I showed you in CLI)&lt;/li&gt;
	&lt;li&gt;Multiple grants from the same grantor to the same grantee should not&lt;br/&gt;
  result in duplicates (verify against Oracle), and we should collapse&lt;br/&gt;
  everything into one row no matter whether the grants were made at&lt;br/&gt;
  the same or different times (sort privilege names for determinism)&lt;/li&gt;
	&lt;li&gt;revokeAllPrivileges should revoke role grants as well&lt;/li&gt;
	&lt;li&gt;Role cycle is not being prevented&lt;/li&gt;
	&lt;li&gt;try/finally around transactions in ObjectStore should be used&lt;br/&gt;
  consistently (I know there are some cases which were already missing&lt;br/&gt;
  them, but we shouldn&apos;t make it worse)&lt;/li&gt;
	&lt;li&gt;Don&apos;t use printStackTrace&lt;/li&gt;
	&lt;li&gt;show &lt;span class=&quot;error&quot;&gt;&amp;#91;role&amp;#93;&lt;/span&gt; grant role unknown should fail (even though we have to&lt;br/&gt;
  tolerate unknown for user/group since we don&apos;t have a table for those)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Some additional points noted at code review session:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Need many many negative tests&lt;/li&gt;
	&lt;li&gt;Provide a way to make partitions inherit from table (and make it the&lt;br/&gt;
  default)&lt;/li&gt;
	&lt;li&gt;Define a UNIQUE key for the priv tables in JDO&lt;/li&gt;
	&lt;li&gt;GRANT should mark WriteEntity for replication etc&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;More Typos:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;candicate&lt;/li&gt;
	&lt;li&gt;anaylze&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I have some more code-level comments but not all of them may be relevant after&lt;br/&gt;
the issues above have been resolved, so I&apos;ll do another pass after the&lt;br/&gt;
next patch.&lt;/p&gt;</comment>
                            <comment id="12971412" author="he yongqiang" created="Tue, 14 Dec 2010 21:11:32 +0000"  >&lt;p&gt;A new patch addressed some of the comments.&lt;/p&gt;

&lt;p&gt;I can not resolve all the comments in this big patch. Please put the left to follow-up jiras.&lt;/p&gt;</comment>
                            <comment id="12971419" author="he yongqiang" created="Tue, 14 Dec 2010 21:26:11 +0000"  >&lt;p&gt;Needs to open follow-up jiras for:&lt;br/&gt;
1. Avoid embedding objects inside of other objects except where necessary.&lt;br/&gt;
2. revokeAllPrivileges should revoke role grants as well&lt;br/&gt;
3. Role cycle is not being prevented&lt;br/&gt;
4. try/finally around transactions in ObjectStore should be used consistently &lt;br/&gt;
5. more negative tests&lt;br/&gt;
6. GRANT should mark WriteEntity for replication etc&lt;br/&gt;
7. Provide a way to make partitions inherit from table (and make it the default)&lt;br/&gt;
8: Multiple grants from the same grantor to the same grantee should not result in duplicates&lt;/p&gt;</comment>
                            <comment id="12971428" author="he yongqiang" created="Tue, 14 Dec 2010 21:56:18 +0000"  >&lt;p&gt;Let&apos;s get this in asap and do follow-ups. It is really painful to maintain it. &lt;br/&gt;
And there are not a few big changes from the first patch. Just need to update it few weeks later after the previous patches. &lt;/p&gt;</comment>
                            <comment id="12971442" author="jvs" created="Tue, 14 Dec 2010 22:27:39 +0000"  >&lt;p&gt;We can&apos;t take the size of a patch as a justification for checking in code which doesn&apos;t pass review, especially for things like JDO and Thrift API&apos;s which are going to be there forever.  I discussed it with Namit and his suggestion was to break it down into smaller patches to be committed in sequence so that we can divide-and-conquer the review process.  For future projects, it would be great if we can do the same for the design process itself so that the coding doesn&apos;t get too far ahead of the design (which is how we end up with giant patches).&lt;/p&gt;

&lt;p&gt;The items below are OK for followups&lt;/p&gt;

&lt;p&gt;2. revokeAllPrivileges should revoke role grants as well&lt;br/&gt;
3. Role cycle is not being prevented&lt;br/&gt;
6. GRANT should mark WriteEntity for replication etc&lt;/p&gt;

&lt;p&gt;For this one, we should at least work out the metastore model as part of the JDO changes:&lt;/p&gt;

&lt;p&gt;7. Provide a way to make partitions inherit from table (and make it the default)&lt;/p&gt;

&lt;p&gt;The rest need to be addressed up front as part of the relevant patches.&lt;/p&gt;

&lt;p&gt;Separately, maybe using git for branch+merge would help make development of a feature of this size more manageable?  (If you&apos;re not already.)&lt;/p&gt;</comment>
                            <comment id="12971455" author="he yongqiang" created="Tue, 14 Dec 2010 22:46:59 +0000"  >&lt;p&gt;No. I do not think i need to make changes in short term for the JDO and thrift apis. If you want, do follow ups on them.&lt;/p&gt;

&lt;p&gt;7. Provide a way to make partitions inherit from table (and make it the default)&lt;br/&gt;
This can be done in a follow-up jira.&lt;/p&gt;</comment>
                            <comment id="12971460" author="he yongqiang" created="Tue, 14 Dec 2010 23:05:25 +0000"  >&lt;p&gt;By &quot;If you want, do follow ups on them.&quot; I meant &quot;if you want, open follow up jiras and assign to me&quot;&lt;/p&gt;

&lt;p&gt;Here are some points that why they are not easy to do:&lt;br/&gt;
For JDO embedding,&lt;br/&gt;
Mostly in the new Objects, there are Table object, Database object, Partition object.&lt;/p&gt;

&lt;p&gt;If we only keep name for them, It&apos;s ok for database. But for Table, need to user dbName, tableName, For partition need dbName, tableName, partName.&lt;br/&gt;
And need to fetch the object on client side to see the object exist or not. And pass the names to meta-store, the metastore will do another lookup to find ids for db/tbl/part to put into new objects.&lt;/p&gt;

&lt;p&gt;For thrift apis, one benefit of consolidating into one is reducing the api numbers. &lt;/p&gt;</comment>
                            <comment id="12971555" author="jvs" created="Wed, 15 Dec 2010 05:41:59 +0000"  >&lt;p&gt;Regarding pass-by-name vs pass-by-value for object references in the Thrift API, take a look at how drop table works.  We already fetch the table descriptor in DDLTask (so that we can include its info in the posthook).  But then, when we drop the table, we pass dbname+tblname (not the actual table object).  So I don&apos;t see the need to invent a new pattern here.  &lt;/p&gt;

&lt;p&gt;For dealing with compound names, it&apos;s fine to define a new struct ObjectReference with object type plus various optional components, then pass that.  (In the future, we could also decide to hide an ID in there for the lookup-skipping optimization you mention if it turns out to be warranted.)&lt;/p&gt;</comment>
                            <comment id="12971793" author="he yongqiang" created="Wed, 15 Dec 2010 19:18:39 +0000"  >&lt;p&gt;@John &lt;br/&gt;
Regarding the thrift API&apos;s object embedding, do you mean define some new object in thrift like:&lt;br/&gt;
strung TableRef {&lt;br/&gt;
string dbname&lt;br/&gt;
string tablename&lt;br/&gt;
}&lt;br/&gt;
and similar to Partition?&lt;/p&gt;

&lt;p&gt;That sounds good to me.&lt;/p&gt;</comment>
                            <comment id="12972233" author="alangates" created="Thu, 16 Dec 2010 22:03:20 +0000"  >&lt;p&gt;There&apos;s been quite a bit of discussion back and forth in this JIRA on who owns the files (Hive or the user) and who MR jobs execute as.  The answers to these questions are very important, but I wasn&apos;t able to decipher from the JIRA how they were answered.  Was one approach or another selected?&lt;/p&gt;</comment>
                            <comment id="12972256" author="he yongqiang" created="Thu, 16 Dec 2010 22:37:13 +0000"  >&lt;p&gt;I think this jira is just a first step towards a fulfilled security feature. It just does the meta-store check to see if a given user be able to issue the query or not.&lt;br/&gt;
There is no integration with HDFS/MR part. So the file owner and the job executer are just the same as now. &lt;br/&gt;
A long term plan is to set up HiveServer.&lt;/p&gt;</comment>
                            <comment id="12972377" author="he yongqiang" created="Fri, 17 Dec 2010 07:30:30 +0000"  >&lt;p&gt;New patches. &lt;br/&gt;
Addressed John&apos;s comments on must-do items. &lt;br/&gt;
Need to open follow up jiras for :&lt;br/&gt;
1. revokeAllPrivileges should revoke role grants as well&lt;br/&gt;
2. Role cycle is not being prevented&lt;br/&gt;
3. GRANT should mark WriteEntity for replication etc&lt;br/&gt;
4. group partitions according to Table. If the partition level privilege is disabled, this can help to perform just one check instead of using a loop for each partition.&lt;br/&gt;
5. do authorization check for &apos;grant/revoke&apos;&lt;/p&gt;</comment>
                            <comment id="12972622" author="alangates" created="Fri, 17 Dec 2010 19:50:49 +0000"  >&lt;p&gt;Having Hive own all the files and run all the jobs presents serious security issues since UDFs would be running code as root.  This would also pose problems for Howl, as Pig and MR can&apos;t runs jobs as Hive.  Maybe this isn&apos;t the right forum for this discussion.  If there&apos;s a better one, let me know.&lt;/p&gt;</comment>
                            <comment id="12972626" author="jvs" created="Fri, 17 Dec 2010 19:57:13 +0000"  >&lt;p&gt;@Alan:  we discussed this in depth at the last Hive contributor meeting:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://wiki.apache.org/hadoop/Hive/Development/ContributorsMeetings/HiveContributorsMinutes101025&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Hive/Development/ContributorsMeetings/HiveContributorsMinutes101025&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let&apos;s talk to Carl about scheduling the next one and make sure we find a timeslot where you can make it.&lt;/p&gt;</comment>
                            <comment id="12972643" author="jvs" created="Fri, 17 Dec 2010 20:53:15 +0000"  >&lt;p&gt;@Yongqiang:&lt;/p&gt;

&lt;p&gt;New review comments in &lt;a href=&quot;https://reviews.apache.org/r/183/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/183/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The patch is applying cleanly for me now (I must have forgotten to svn up), so I&apos;ll do some testing later.&lt;/p&gt;

</comment>
                            <comment id="12972644" author="jvs" created="Fri, 17 Dec 2010 20:54:51 +0000"  >&lt;p&gt;I added one comment about referring to &quot;grantee&quot; instead of &quot;principal&quot; in some of the API&apos;s, but I did not do it consistently.  I think this would be clearer across thrift/JDO to distinguish the grantor from the grantee in all cases, but if you want to leave it as is, just ignore that comment.&lt;/p&gt;</comment>
                            <comment id="12973289" author="he yongqiang" created="Mon, 20 Dec 2010 18:24:11 +0000"  >&lt;p&gt;A new no_thrift patch addressed John&apos;s review comments. Thanks John!&lt;/p&gt;

&lt;p&gt;Running tests. And will upload a new complete patch after tests (and incorporate new comments).&lt;/p&gt;</comment>
                            <comment id="12973388" author="jvs" created="Mon, 20 Dec 2010 22:26:05 +0000"  >&lt;p&gt;A few more comments on patch 10 in&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/187/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/187/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12975689" author="namit" created="Wed, 29 Dec 2010 00:34:04 +0000"  >&lt;p&gt;hive-default.xml:&lt;/p&gt;

&lt;p&gt;&amp;lt;property&amp;gt;&lt;br/&gt;
  &amp;lt;name&amp;gt;hive.variable.substitute&amp;lt;/name&amp;gt;&lt;br/&gt;
  &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;&lt;br/&gt;
  &amp;lt;description&amp;gt;This enables substitution using syntax like ${var} ${system:var} and ${env:var}.&amp;lt;/description&amp;gt;&lt;br/&gt;
&amp;lt;/property&amp;gt;&lt;/p&gt;

&lt;p&gt;seems like a merge problem.&lt;/p&gt;




&lt;p&gt;package.jdo:&lt;/p&gt;

&lt;p&gt;no index needed on ROLE_ID&lt;/p&gt;


&lt;p&gt;ALTER TABLE authorization_part SET TBLPROPERTIES (&quot;PARTITION_LEVEL_PRIVILEGE&quot;=&quot;TRUE&quot;);&lt;/p&gt;


&lt;p&gt;Dont load partition specific priviliges for tables that do no have a separate partition level priv.&lt;/p&gt;

&lt;p&gt;ObjectStore.java: add comments for getGrantObjects&lt;/p&gt;

&lt;p&gt;HiveMetaStoreClient.java: no need for setEmpotyGrantList()&lt;br/&gt;
you should always create a empty list for a user,role or group.&lt;/p&gt;



&lt;p&gt;DefaultHiveAuthorizationProvider.java:&lt;/p&gt;

&lt;p&gt;Can you	add comments for all the (private) functions ?&lt;br/&gt;
It is not obvious what is the meaning of the return value ?&lt;/p&gt;



&lt;p&gt;Still reviewing.&lt;/p&gt;</comment>
                            <comment id="12975708" author="namit" created="Wed, 29 Dec 2010 03:40:53 +0000"  >&lt;p&gt;HadoopDefaultAuthenticator&lt;/p&gt;

&lt;p&gt;System.out.println() present&lt;/p&gt;


&lt;p&gt;PrivilegeObjectDesc.java:&lt;br/&gt;
@Explain(displayName=&quot;privilege subject&quot;)&lt;/p&gt;

&lt;p&gt;can you use Privilege Object instead ?&lt;/p&gt;

&lt;p&gt;  private String object; -&amp;gt; can you change it to tableName ?&lt;/p&gt;


&lt;p&gt;PrivilegeObjectDesc.java: should contain a list of columns.&lt;/p&gt;

&lt;p&gt;Remove columns from PrivilegeDesc. -&amp;gt; PrivilegeDesc can be removed all together&lt;br/&gt;
It is same as Privilege&lt;/p&gt;</comment>
                            <comment id="12975710" author="namit" created="Wed, 29 Dec 2010 03:52:15 +0000"  >&lt;p&gt;I think you can do the following optimization: feel free to do it in a followup.&lt;/p&gt;

&lt;p&gt;There are many queries which have lots of input partitions for the same input table.&lt;br/&gt;
If the table under consideration has the same privilege for all the partitions, you&lt;br/&gt;
dont need to check the permissions for all the partitions. You can find the common&lt;br/&gt;
tables and skip the partitions altogether&lt;/p&gt;</comment>
                            <comment id="12975711" author="namit" created="Wed, 29 Dec 2010 03:54:23 +0000"  >&lt;p&gt;Can you check if &apos;USER&apos;, &apos;ROLE&apos; and &apos;OPTION&apos; are not used as column names in any table ?&lt;/p&gt;</comment>
                            <comment id="12978175" author="namit" created="Thu, 6 Jan 2011 06:56:13 +0000"  >&lt;p&gt;My bad, I committed &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1840&quot; title=&quot;Support ALTER DATABASE to change database properties&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1840&quot;&gt;&lt;del&gt;HIVE-1840&lt;/del&gt;&lt;/a&gt; just now.&lt;br/&gt;
Can you regenerate the patch ?&lt;/p&gt;</comment>
                            <comment id="12978978" author="namit" created="Fri, 7 Jan 2011 21:42:26 +0000"  >&lt;p&gt;I am getting some compilation errors - can you regenerate the patch ?&lt;/p&gt;</comment>
                            <comment id="12978984" author="he yongqiang" created="Fri, 7 Jan 2011 22:01:22 +0000"  >&lt;p&gt;refresh the patch&lt;/p&gt;</comment>
                            <comment id="12979827" author="ashutoshc" created="Mon, 10 Jan 2011 22:48:44 +0000"  >&lt;p&gt;John&apos;s latest comment on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1696&quot; title=&quot;Add delegation token support to metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1696&quot;&gt;&lt;del&gt;HIVE-1696&lt;/del&gt;&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1696?focusedCommentId=12978176&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12978176&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1696?focusedCommentId=12978176&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12978176&lt;/a&gt; seems to indicate that &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1696&quot; title=&quot;Add delegation token support to metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1696&quot;&gt;&lt;del&gt;HIVE-1696&lt;/del&gt;&lt;/a&gt; is blocked on this getting committed. Do we know how far we are on this issue and how long it may take before it gets committed? That will help to estimate commit date for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1696&quot; title=&quot;Add delegation token support to metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1696&quot;&gt;&lt;del&gt;HIVE-1696&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12979868" author="namit" created="Tue, 11 Jan 2011 00:24:07 +0000"  >&lt;p&gt;All the tests are passing - we are blocked on the names of the new reserved words, we have introduced.&lt;br/&gt;
We are trying to get it in asap&lt;/p&gt;</comment>
                            <comment id="12979892" author="ashutoshc" created="Tue, 11 Jan 2011 01:09:37 +0000"  >&lt;p&gt;@Namit,&lt;/p&gt;

&lt;p&gt;Sounds good. Thanks for the info.&lt;/p&gt;</comment>
                            <comment id="12979931" author="he yongqiang" created="Tue, 11 Jan 2011 03:41:39 +0000"  >&lt;p&gt;John shared this link &lt;a href=&quot;http://www.antlr.org/wiki/pages/viewpage.action?pageId=1741&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.antlr.org/wiki/pages/viewpage.action?pageId=1741&lt;/a&gt; offline to me. The new patch uses the first option in that link to solve the keyword conflict. &lt;/p&gt;

&lt;p&gt;Right now only did the work for keyword user and role. If needed, can open followup for others. But it will be better to try to import the second option to Hive. Or both depending on different cases. The second one is cleaner and can be default option. This can be further investigated in follow up jiras.&lt;/p&gt;</comment>
                            <comment id="12980313" author="he yongqiang" created="Tue, 11 Jan 2011 20:22:31 +0000"  >&lt;p&gt;refresh the patch&lt;/p&gt;</comment>
                            <comment id="12980351" author="he yongqiang" created="Tue, 11 Jan 2011 21:43:27 +0000"  >&lt;p&gt;the last patch missed a few files, and won&apos;t compile. upload a new one.&lt;/p&gt;</comment>
                            <comment id="12980597" author="namit" created="Wed, 12 Jan 2011 06:58:53 +0000"  >&lt;p&gt;Committed. Thanks Yongqiang&lt;/p&gt;</comment>
                            <comment id="12980971" author="he yongqiang" created="Wed, 12 Jan 2011 22:26:15 +0000"  >&lt;p&gt;Here is mysql upgrade script:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://wiki.apache.org/hadoop/Hive/AuthDev#A8._Metastore_upgrade_script_for_mysql&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Hive/AuthDev#A8._Metastore_upgrade_script_for_mysql&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13013754" author="devaraj" created="Thu, 31 Mar 2011 00:08:48 +0000"  >&lt;p&gt;BTW, was any thought put in to implement the authorization checks in the ObjectStore? In the model where a MetaStore server is deployed separately, applications (map/reduce tasks for example), can make programmatic calls to the MetaStore to, for example, drop random tables/partitions, and they will pass.. Just wondering whether this usecase was considered.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12496755">HIVE-1928</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12436081">HIVE-842</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12494785">HIVE-1891</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12494784">HIVE-1890</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12459773">HIVE-1264</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12494777">HIVE-1887</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12494992">HIVE-1902</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12494992">HIVE-1902</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12494785">HIVE-1891</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12494784">HIVE-1890</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12458799" name="HIVE-78.1.nothrift.patch" size="1741981" author="he yongqiang" created="Thu, 4 Nov 2010 06:28:47 +0000"/>
                            <attachment id="12458798" name="HIVE-78.1.thrift.patch" size="3367173" author="he yongqiang" created="Thu, 4 Nov 2010 06:28:47 +0000"/>
                            <attachment id="12466650" name="HIVE-78.10.no_thrift.patch" size="752563" author="he yongqiang" created="Mon, 20 Dec 2010 18:22:41 +0000"/>
                            <attachment id="12467463" name="HIVE-78.11.patch" size="3775322" author="he yongqiang" created="Tue, 4 Jan 2011 20:17:00 +0000"/>
                            <attachment id="12467764" name="HIVE-78.12.2.patch" size="3781014" author="he yongqiang" created="Fri, 7 Jan 2011 22:01:21 +0000"/>
                            <attachment id="12467967" name="HIVE-78.12.3.patch" size="3786926" author="he yongqiang" created="Tue, 11 Jan 2011 03:41:38 +0000"/>
                            <attachment id="12468051" name="HIVE-78.12.4.patch" size="3761313" author="he yongqiang" created="Tue, 11 Jan 2011 20:22:30 +0000"/>
                            <attachment id="12468061" name="HIVE-78.12.5.patch" size="3786877" author="he yongqiang" created="Tue, 11 Jan 2011 21:43:26 +0000"/>
                            <attachment id="12467685" name="HIVE-78.12.patch" size="3780822" author="he yongqiang" created="Thu, 6 Jan 2011 23:01:14 +0000"/>
                            <attachment id="12459328" name="HIVE-78.2.nothrift.patch" size="278725" author="he yongqiang" created="Thu, 11 Nov 2010 06:47:34 +0000"/>
                            <attachment id="12459329" name="HIVE-78.2.thrift.patch" size="3519327" author="he yongqiang" created="Thu, 11 Nov 2010 06:47:34 +0000"/>
                            <attachment id="12459976" name="HIVE-78.4.complete.patch" size="3947348" author="he yongqiang" created="Fri, 19 Nov 2010 06:21:53 +0000"/>
                            <attachment id="12459977" name="HIVE-78.4.no_thrift.patch" size="645230" author="he yongqiang" created="Fri, 19 Nov 2010 06:21:54 +0000"/>
                            <attachment id="12460227" name="HIVE-78.5.complete.patch" size="4346421" author="he yongqiang" created="Tue, 23 Nov 2010 02:58:41 +0000"/>
                            <attachment id="12460228" name="HIVE-78.5.no_thrift.patch" size="666954" author="he yongqiang" created="Tue, 23 Nov 2010 02:58:42 +0000"/>
                            <attachment id="12465944" name="HIVE-78.6.complete.patch" size="5310159" author="he yongqiang" created="Thu, 9 Dec 2010 22:07:17 +0000"/>
                            <attachment id="12465945" name="HIVE-78.6.no_thrift.patch" size="664645" author="he yongqiang" created="Thu, 9 Dec 2010 22:07:18 +0000"/>
                            <attachment id="12466250" name="HIVE-78.7.no_thrift.patch" size="673383" author="he yongqiang" created="Tue, 14 Dec 2010 21:11:31 +0000"/>
                            <attachment id="12466251" name="HIVE-78.7.patch" size="5007485" author="he yongqiang" created="Tue, 14 Dec 2010 21:11:31 +0000"/>
                            <attachment id="12466447" name="HIVE-78.9.no_thrift.patch" size="781187" author="he yongqiang" created="Fri, 17 Dec 2010 07:30:29 +0000"/>
                            <attachment id="12466448" name="HIVE-78.9.patch" size="4301130" author="he yongqiang" created="Fri, 17 Dec 2010 07:30:29 +0000"/>
                            <attachment id="12420120" name="createuser-v1.patch" size="26656" author="coderplay" created="Sat, 19 Sep 2009 03:36:12 +0000"/>
                            <attachment id="12419757" name="hive-78-metadata-v1.patch" size="15516" author="coderplay" created="Wed, 16 Sep 2009 11:05:57 +0000"/>
                            <attachment id="12419724" name="hive-78-syntax-v1.patch" size="9716" author="coderplay" created="Wed, 16 Sep 2009 04:35:49 +0000"/>
                            <attachment id="12410253" name="hive-78.diff" size="1319" author="appodictic" created="Tue, 9 Jun 2009 20:47:16 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 21 Nov 2008 23:45:07 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>64488</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 43 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i06akv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>34645</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>
</channel>
</rss>
