<!--
RSS generated by JIRA (7.6.3#76005-sha1:8a4e38d34af948780dbf52044e7aafb13a7cae58) at Tue Jan 22 15:16:20 UTC 2019

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<!-- If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
    <channel>
        <title>ASF JIRA</title>
        <link>https://issues.apache.org/jira/issues/?jql=project+%3D+HIVE+AND+created+%3E%3D+2010-8-4+AND+created+%3C%3D+2010-8-11+ORDER+BY+key+ASC</link>
        <description>An XML representation of a search request</description>
                <language>en-uk</language>
                        <issue start="0" end="18" total="18"/>
                <build-info>
            <version>7.6.3</version>
            <build-number>76005</build-number>
            <build-date>09-01-2018</build-date>
        </build-info>

<item>
            <title>[HIVE-1509] Monitor the working set of the number of files </title>
                <link>https://issues.apache.org/jira/browse/HIVE-1509</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12470776">HIVE-1509</key>
            <summary>Monitor the working set of the number of files </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nzhang">Ning Zhang</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Wed, 4 Aug 2010 00:07:51 +0000</created>
                <updated>Fri, 16 Dec 2011 23:59:29 +0000</updated>
                            <resolved>Thu, 5 Aug 2010 07:38:58 +0000</resolved>
                                    <version>0.6.0</version>
                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12895106" author="namit" created="Wed, 4 Aug 2010 00:31:48 +0000"  >&lt;p&gt;With dynamic partitions, the number of intermediate files can grow very fast.&lt;/p&gt;

&lt;p&gt;For example, consider a query with 10,000 mappers and 100 files per mapper - it can create up to 1 million files before merging them at the end.&lt;br/&gt;
The cluster may be down by the time the query finishes.&lt;/p&gt;

&lt;p&gt;It is a good idea to track the number of files through a counter, and kill the query if the number exceeds a given threshold&lt;/p&gt;</comment>
                            <comment id="12895312" author="jsensarma" created="Wed, 4 Aug 2010 16:42:06 +0000"  >&lt;p&gt;couple of comments:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;use ProgressCounter.CREATED_FILES directly instead of using valueOf(&quot;CREATED_FILES&quot;)&lt;/li&gt;
	&lt;li&gt;can we move the check for total number of created files to inside checkFatalErrors? we are duplicating some code (for example we just fixed a problem where getCounters() can return null and ignoring that inside checkFatal).&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12895321" author="nzhang" created="Wed, 4 Aug 2010 17:05:39 +0000"  >&lt;p&gt;Good points Joy. Uploading a new patch with these changes. &lt;/p&gt;</comment>
                            <comment id="12895322" author="jsensarma" created="Wed, 4 Aug 2010 17:08:58 +0000"  >&lt;p&gt;can u try bucketmapjoin2.q in clientpositive. it&apos;s failing for me&lt;/p&gt;</comment>
                            <comment id="12895327" author="nzhang" created="Wed, 4 Aug 2010 17:31:52 +0000"  >&lt;p&gt;found the bug. I&apos;ll a new patch after running the tests. &lt;/p&gt;</comment>
                            <comment id="12895355" author="nzhang" created="Wed, 4 Aug 2010 18:39:33 +0000"  >&lt;p&gt;Uploading &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1509&quot; title=&quot;Monitor the working set of the number of files &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1509&quot;&gt;&lt;del&gt;HIVE-1509&lt;/del&gt;&lt;/a&gt;.3.patch which fixed a bug. It passed hadoop 0.17 tests. I&apos;m running 0.20 tests. &lt;/p&gt;</comment>
                            <comment id="12895384" author="jsensarma" created="Wed, 4 Aug 2010 19:46:48 +0000"  >&lt;p&gt;let me know once the tests pass 0.20 and i can commit.&lt;/p&gt;

&lt;p&gt;one more question:&lt;br/&gt;
+    MAXCREATEDFILES(&quot;hive.exec.max.created.files&quot;, 100000),&lt;/p&gt;

&lt;p&gt;i think u may have to append a &apos;L&apos; to 100000 since u are trying to later on do a:&lt;/p&gt;

&lt;p&gt;+      long upperLimit =  HiveConf.getLongVar(job, HiveConf.ConfVars.MAXCREATEDFILES);&lt;/p&gt;

&lt;p&gt;(or switch to using getIntVar). i am a little surprised how this is working because the 100000 would be interpreted as Integer, go to the integer constructor which should leave the long default to -1. (or i guess i have forgotten how this works)&lt;/p&gt;</comment>
                            <comment id="12895404" author="nzhang" created="Wed, 4 Aug 2010 20:23:59 +0000"  >&lt;p&gt;Attaching &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1509&quot; title=&quot;Monitor the working set of the number of files &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1509&quot;&gt;&lt;del&gt;HIVE-1509&lt;/del&gt;&lt;/a&gt;.4.patch to change 100000 to 100000L. I think it passed because we have the parameter set up in hive-default.xml as well.&lt;/p&gt;

&lt;p&gt;All unit tests passed on 0.20 except index_compact_2.q. It is strange that this particular test passed when I run it individually. It also passed when I ran the whole tests again. &lt;/p&gt;</comment>
                            <comment id="12895411" author="jsensarma" created="Wed, 4 Aug 2010 20:43:38 +0000"  >&lt;p&gt;ok - i will run tests on 20 and commit if all clear.&lt;/p&gt;</comment>
                            <comment id="12895472" author="jsensarma" created="Wed, 4 Aug 2010 23:50:45 +0000"  >&lt;p&gt;the test result for dyn_part3.q is not matching the one provided in the patch. it seems that testnegativeclidriver is not executing anything but the first query in the .q file:&lt;/p&gt;


&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; diff -a -I file: -I pfile: -I /tmp/ -I invalidscheme: -I lastUpdateTime -I lastAccessTime -I \&lt;br/&gt;
owner -I transient_lastDdlTime -I java.lang.RuntimeException -I at org -I at sun -I at java -I at junit -\&lt;br/&gt;
I Caused by: -I &lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;0-9&amp;#93;&lt;/span&gt;* more /data/users/jssarma/hive_trunk/build/ql/test/logs/clientnegative/dy\&lt;br/&gt;
n_part3.q.out&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 9a10,27&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: query: create table nzhang_part( key string) partitioned by (value string)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: type: CREATETABLE&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; POSTHOOK: query: create table nzhang_part( key string) partitioned by (value string)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; POSTHOOK: type: CREATETABLE&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; POSTHOOK: Output: default@nzhang_part&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: query: insert overwrite table nzhang_part partition(value) select key, value from \&lt;br/&gt;
src&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: type: QUERY&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: Input: default@src&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTask&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: query: create table nzhang_part( key string) partitioned by (value string)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: type: CREATETABLE&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; POSTHOOK: query: create table nzhang_part( key string) partitioned by (value string)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; POSTHOOK: type: CREATETABLE&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; POSTHOOK: Output: default@nzhang_part&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: query: insert overwrite table nzhang_part partition(value) select key, value from \&lt;br/&gt;
src&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: type: QUERY&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; PREHOOK: Input: default@src&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTask&lt;/p&gt;</comment>
                            <comment id="12895523" author="nzhang" created="Thu, 5 Aug 2010 02:49:56 +0000"  >&lt;p&gt;It&apos;s strange. I didn&apos;t get this diff on both 17 and 20. I&apos;ll run TestNegativeCliDriver again.&lt;/p&gt;</comment>
                            <comment id="12895526" author="nzhang" created="Thu, 5 Aug 2010 03:01:24 +0000"  >&lt;p&gt;The TestNegativeCliDriver ran successfully. In terms of the number of queries in the .q files in neg, I think as long as there is no queries after the first exception, it should be fine. At least this is what dyn_part&lt;span class=&quot;error&quot;&gt;&amp;#91;12&amp;#93;&lt;/span&gt;.q was doing (only the last query thrown expected exception).&lt;/p&gt;</comment>
                            <comment id="12895534" author="jsensarma" created="Thu, 5 Aug 2010 03:33:58 +0000"  >&lt;p&gt;strange - let me retry. can u check the patch one last time? (perhaps it&apos;s not up to date with contents of ur tree?)&lt;/p&gt;</comment>
                            <comment id="12895537" author="nzhang" created="Thu, 5 Aug 2010 04:05:47 +0000"  >&lt;p&gt;Yes, I check the svn diff in my working directory is the same as &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1509&quot; title=&quot;Monitor the working set of the number of files &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1509&quot;&gt;&lt;del&gt;HIVE-1509&lt;/del&gt;&lt;/a&gt;.4.patch. &lt;/p&gt;</comment>
                            <comment id="12895605" author="jsensarma" created="Thu, 5 Aug 2010 07:38:58 +0000"  >&lt;p&gt;committed - thanks Ning.&lt;/p&gt;

&lt;p&gt;it seems that the test problems were likely because there was a problem applying the patch.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12451235" name="HIVE-1509.2.patch" size="14131" author="nzhang" created="Wed, 4 Aug 2010 17:05:39 +0000"/>
                            <attachment id="12451246" name="HIVE-1509.3.patch" size="14445" author="nzhang" created="Wed, 4 Aug 2010 18:39:33 +0000"/>
                            <attachment id="12451260" name="HIVE-1509.4.patch" size="14446" author="nzhang" created="Wed, 4 Aug 2010 20:23:59 +0000"/>
                            <attachment id="12451204" name="HIVE-1509.patch" size="14131" author="nzhang" created="Wed, 4 Aug 2010 07:28:07 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 4 Aug 2010 16:42:06 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72865</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 25 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lffr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123151</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1510] HiveCombineInputFormat should not use prefix matching to find the partitionDesc for a given path</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1510</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;&lt;/p&gt;

&lt;p&gt;drop table combine_3_srcpart_seq_rc;&lt;/p&gt;

&lt;p&gt;create table combine_3_srcpart_seq_rc (key int , value string) partitioned by (ds string, hr string) stored as sequencefile;&lt;/p&gt;

&lt;p&gt;insert overwrite table combine_3_srcpart_seq_rc partition (ds=&quot;2010-08-03&quot;, hr=&quot;00&quot;) select * from src;&lt;/p&gt;

&lt;p&gt;alter table combine_3_srcpart_seq_rc set fileformat rcfile;&lt;br/&gt;
insert overwrite table combine_3_srcpart_seq_rc partition (ds=&quot;2010-08-03&quot;, hr=&quot;001&quot;) select * from src;&lt;/p&gt;

&lt;p&gt;desc extended combine_3_srcpart_seq_rc partition(ds=&quot;2010-08-03&quot;, hr=&quot;00&quot;);&lt;br/&gt;
desc extended combine_3_srcpart_seq_rc partition(ds=&quot;2010-08-03&quot;, hr=&quot;001&quot;);&lt;/p&gt;

&lt;p&gt;select * from combine_3_srcpart_seq_rc where ds=&quot;2010-08-03&quot; order by key;&lt;/p&gt;

&lt;p&gt;drop table combine_3_srcpart_seq_rc;&lt;/p&gt;


&lt;p&gt;will fail.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12470780">HIVE-1510</key>
            <summary>HiveCombineInputFormat should not use prefix matching to find the partitionDesc for a given path</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="he yongqiang">He Yongqiang</assignee>
                                    <reporter username="he yongqiang">He Yongqiang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 4 Aug 2010 00:50:33 +0000</created>
                <updated>Fri, 16 Dec 2011 23:59:59 +0000</updated>
                            <resolved>Sat, 21 Aug 2010 13:07:35 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12895370" author="namit" created="Wed, 4 Aug 2010 19:03:50 +0000"  >&lt;p&gt;Some minor comments&lt;br/&gt;
TestHiveFileFormatUtils:&lt;/p&gt;

&lt;p&gt;1. Use a different PartitionDesc every time instead of partDesc_1 for the partitions.&lt;br/&gt;
2. Spelling mistakes: forth group&lt;/p&gt;


&lt;p&gt;Otherwise, it looks good to me. Ning, can you also OK it , since we spent a lot of time debugging in the past.&lt;/p&gt;

&lt;p&gt;Also, before checking it, can you try the following 4 types of queries (with CombineHiveInputFormat):&lt;/p&gt;

&lt;p&gt;1. hadoop 17 normal query&lt;br/&gt;
2. hadoop 17 sampling query&lt;br/&gt;
3. hadoop 20 normal query&lt;br/&gt;
4. hadoop 20 sampling query&lt;/p&gt;
</comment>
                            <comment id="12895381" author="nzhang" created="Wed, 4 Aug 2010 19:36:53 +0000"  >&lt;p&gt;In HiveFileFormatUtils, removing scheme and authorities from the URI and only retain the path part may cause problem when the URI is har:// rather than hdfs://. This is one of the bugs that Paul fixed in hadoop for HAR to be able to work with CHIF. &lt;/p&gt;

&lt;p&gt;As a general comment, is it easier to just modify the pathToPartitionInfo to add a Path.SEPARATER at the end? You don&apos;t need to introduce the recursive checking and still can use the prefix matching. &lt;/p&gt;</comment>
                            <comment id="12895386" author="he yongqiang" created="Wed, 4 Aug 2010 19:49:31 +0000"  >&lt;p&gt;will also test against har. even the old code also remove the scheme and authorities part when try to match partitionDesc.&lt;br/&gt;
no offense &amp;#8211; the old code is not very clear, and not efficient.  The new code does the same thing with simplified logic.&lt;/p&gt;</comment>
                            <comment id="12895428" author="nzhang" created="Wed, 4 Aug 2010 21:23:56 +0000"  >&lt;p&gt;It&apos;s fine for me if you feel strong for it. The concern from me (besides har+CHIF support) is the performance implication when using CHIF merging large number of small files inside a partition. Siying has a use case where the pathToPartitionInfo is very large and the # of files in the splits is also very large. Determining whether partitionDesc for each input path takes a long time. In your patch, you have another HashMap for the path part of the pathToPartitionInfo (which trade memory for speed), but introduced another loop for comparing parent of paths. It would be nice (better performance) if you could avoid this loop by simply appending &apos;/&apos; at the end.  But if it doesn&apos;t hurt the performance or appending &apos;/&apos; doesn&apos;t work, the current patch is fine for me too.&lt;/p&gt;

&lt;p&gt;As an aside, we should find out why pathToPartitionInfo in some cases contains paths only rather than the full URI. The ideal case is that it should always contains the full URI so that we don&apos;t rely on heuristics. But this could be another JIRA.&lt;/p&gt;</comment>
                            <comment id="12896752" author="he yongqiang" created="Tue, 10 Aug 2010 00:53:27 +0000"  >&lt;p&gt;Will update the patch once &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1515&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1515&lt;/a&gt; is in.&lt;/p&gt;</comment>
                            <comment id="12899086" author="he yongqiang" created="Mon, 16 Aug 2010 20:58:46 +0000"  >&lt;p&gt;Since &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1515&quot; title=&quot;archive is not working when multiple partitions inside one table are archived.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1515&quot;&gt;HIVE-1515&lt;/a&gt; depends on Hadoop, can we close this jira without adding new archive testcases.&lt;/p&gt;</comment>
                            <comment id="12900057" author="nzhang" created="Wed, 18 Aug 2010 21:58:52 +0000"  >&lt;p&gt;As discussed offline with Yongqiang, we should clean up the pathToPartitionInfo to contain only canonical representations for each partition. This could result in much cleaner code. If we do that IOPrepareCache is not needed at all and the function getPartitionDescFromPath is just simple hash lookup. We can make it as a follow up JIRA along with cleaning up the unnecessary info in pathToPartitionInfo as well.&lt;/p&gt;

&lt;p&gt;Here&apos;s some comments on the current patch:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;the IOPrepareCache is cleared in Driver, which should only contain generic code irrespect to task types. Can you do it in ExecDriver.execute()? This will new cache is only used in ExecDriver anyways.&lt;/li&gt;
	&lt;li&gt;some comments on why you need a new hash map keyed with the paths only will be helpful.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12900063" author="he yongqiang" created="Wed, 18 Aug 2010 22:08:05 +0000"  >&lt;p&gt;&amp;gt;&amp;gt;the IOPrepareCache is cleared in Driver, which should only contain generic code irrespect to task types. Can you do it in ExecDriver.execute()? This will new cache is only used in ExecDriver anyways.&lt;/p&gt;

&lt;p&gt;ExecDriver is per map-reduce task. Driver is per query. We should do this for query granularity. I think the pathToPartitionDesc is also per query map?&lt;/p&gt;


&lt;p&gt;&amp;gt;&amp;gt;some comments on why you need a new hash map keyed with the paths only will be helpful.&lt;br/&gt;
will do it in a next patch.&lt;/p&gt;</comment>
                            <comment id="12900074" author="he yongqiang" created="Wed, 18 Aug 2010 22:33:51 +0000"  >&lt;p&gt;About the additional hashmap added, it is used to match path to partitionDesc by discarding partitionDesc&apos;s schema information. &lt;/p&gt;

&lt;p&gt;In the long run, we should normalize all input path to let them contain full schema and authorization information. This is a must to let hive work with multiple hdfs clusters.&lt;/p&gt;</comment>
                            <comment id="12900113" author="nzhang" created="Wed, 18 Aug 2010 23:49:41 +0000"  >&lt;p&gt;Other than the clean architecture concerns (Driver should be generic and should not assume tasks contain MR jobs), it seems also doesn&apos;t work if parallel execution is enabled: IOPrepareCache is thread local and parallel MR jobs are launched in different threads.&lt;/p&gt;
</comment>
                            <comment id="12900417" author="nzhang" created="Thu, 19 Aug 2010 19:53:34 +0000"  >&lt;p&gt;+1, will commit if tests pass&lt;/p&gt;</comment>
                            <comment id="12900567" author="nzhang" created="Fri, 20 Aug 2010 04:06:12 +0000"  >&lt;p&gt;Yongqiang, the 0.17 test failed on index_compact3.q and script_pipe.q (the latter may be a false alarm). Can you take a look?&lt;/p&gt;</comment>
                            <comment id="12900904" author="he yongqiang" created="Fri, 20 Aug 2010 23:01:27 +0000"  >&lt;p&gt;even without this patch, the 0.17 test failed on index_compat3.q. Please file a separate jira for this issue. &lt;/p&gt;</comment>
                            <comment id="12900940" author="nzhang" created="Sat, 21 Aug 2010 00:15:11 +0000"  >&lt;p&gt;it does&apos;t fail on trunk but caused by parallel test. &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1576&quot; title=&quot;index_compact*.q should not share common result file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1576&quot;&gt;HIVE-1576&lt;/a&gt; was filed for this. &lt;/p&gt;

&lt;p&gt;Will tes again and commit once &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1307&quot; title=&quot;More generic and efficient merge method&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1307&quot;&gt;&lt;del&gt;HIVE-1307&lt;/del&gt;&lt;/a&gt; is committed.&lt;/p&gt;</comment>
                            <comment id="12901025" author="nzhang" created="Sat, 21 Aug 2010 13:07:35 +0000"  >&lt;p&gt;Committed. Thanks Yongqiang!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12451184" name="hive-1510.1.patch" size="36610" author="he yongqiang" created="Wed, 4 Aug 2010 01:05:57 +0000"/>
                            <attachment id="12452442" name="hive-1510.3.patch" size="42081" author="he yongqiang" created="Wed, 18 Aug 2010 19:46:09 +0000"/>
                            <attachment id="12452551" name="hive-1510.4.patch" size="42845" author="he yongqiang" created="Thu, 19 Aug 2010 17:33:37 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 4 Aug 2010 19:03:50 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72864</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 23 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lffz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123152</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1511] Hive plan serialization is slow</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1511</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;As reported by Edward Capriolo:&lt;/p&gt;

&lt;p&gt;For reference I did this as a test case....&lt;br/&gt;
SELECT * FROM src where&lt;br/&gt;
key=0 OR key=0 OR key=0 OR  key=0 OR key=0 OR key=0 OR key=0 OR key=0&lt;br/&gt;
OR key=0 OR key=0 OR key=0 OR&lt;br/&gt;
key=0 OR key=0 OR key=0 OR  key=0 OR key=0 OR key=0 OR key=0 OR key=0&lt;br/&gt;
OR key=0 OR key=0 OR key=0 OR&lt;br/&gt;
...(100 more of these)&lt;/p&gt;

&lt;p&gt;No OOM but I gave up after the test case did not go anywhere for about&lt;br/&gt;
2 minutes.&lt;/p&gt;

</description>
                <environment></environment>
        <key id="12470820">HIVE-1511</key>
            <summary>Hive plan serialization is slow</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="kamrul">Mohammad Kamrul Islam</assignee>
                                    <reporter username="nzhang">Ning Zhang</reporter>
                        <labels>
                            <label>TODOC13</label>
                    </labels>
                <created>Wed, 4 Aug 2010 18:08:33 +0000</created>
                <updated>Sat, 5 Jul 2014 08:08:44 +0000</updated>
                            <resolved>Mon, 9 Sep 2013 13:58:02 +0000</resolved>
                                    <version>0.7.0</version>
                    <version>0.11.0</version>
                                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>12</watches>
                                                                <comments>
                            <comment id="12895343" author="nzhang" created="Wed, 4 Aug 2010 18:08:59 +0000"  >&lt;p&gt;The issue seems to be the fact that we serialize the plan by writing to HDFS file directly. We probably should cache it locally and then write it to HDFS. &lt;/p&gt;</comment>
                            <comment id="12895352" author="appodictic" created="Wed, 4 Aug 2010 18:23:58 +0000"  >&lt;p&gt;Also possibly a clever way to remove duplicate expressions that evaluate to the same result such as multiple key=0&lt;/p&gt;</comment>
                            <comment id="13138832" author="ashutoshc" created="Fri, 28 Oct 2011 22:01:15 +0000"  >&lt;p&gt;@Ning,&lt;br/&gt;
Now that plan file is distributed through Distributed Cache, that could not be a a bottleneck. Any other reason why this could be slow apart from what Edward is referring to?&lt;/p&gt;</comment>
                            <comment id="13709005" author="ashutoshc" created="Mon, 15 Jul 2013 21:24:57 +0000"  >&lt;p&gt;Plan serialization and deserialization is still because of java serialization is way too slow. I played with Kryo library ( &lt;a href=&quot;http://code.google.com/p/kryo/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://code.google.com/p/kryo/&lt;/a&gt; ) which is super-fast for java object graph serialization and initial results looks promising. &lt;/p&gt;</comment>
                            <comment id="13709312" author="appodictic" created="Tue, 16 Jul 2013 00:59:14 +0000"  >&lt;p&gt;Maybe protobuf since we have it in trunk now.&lt;/p&gt;</comment>
                            <comment id="13709323" author="ashutoshc" created="Tue, 16 Jul 2013 01:06:14 +0000"  >&lt;p&gt;AFAIK Protobuf can serialize / deserialize protobuff generated classes, not arbitrary java object graph. So, I think protobuff cant be used here.&lt;/p&gt;</comment>
                            <comment id="13713048" author="ashutoshc" created="Thu, 18 Jul 2013 23:08:06 +0000"  >&lt;p&gt;I took this following artificial query which is in description of this jira:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;SELECT * FROM src where
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0 OR
key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0 OR key=0
OR key=0 OR key=0 OR key=0;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In my ubuntu vm, it took 8 seconds in plan serialization before the patch. After patch, it takes 200 millis to do serialization. There is a similiar savings on deserialization side as well. &lt;/p&gt;</comment>
                            <comment id="13713058" author="xuefuz" created="Thu, 18 Jul 2013 23:15:01 +0000"  >&lt;p&gt;I guess this will also help solve &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4885&quot; title=&quot;Alternative object serialization for execution plan in hive testing &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4885&quot;&gt;&lt;del&gt;HIVE-4885&lt;/del&gt;&lt;/a&gt;, where XMLEncoder generates different XML doc for the plan from JDK6 to JDK7.&lt;/p&gt;</comment>
                            <comment id="13713160" author="appodictic" created="Fri, 19 Jul 2013 00:26:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;Xuefu Zhang&lt;/a&gt;When you filed your ticket my comment was referencing this one.&lt;/p&gt;

&lt;p&gt;This looks good. I want to start looking at the jar jar plugin, because I do not like how the hive-exec jar is getting larger and larger and possible classpath conflicts can happen. But that is something down the road.&lt;/p&gt;

&lt;p&gt;I like this speed up, maybe we should try jackson as well since we already have it on the classpath and it will still keep the plan readable.&lt;/p&gt;

&lt;p&gt;I am assuming you do not want to go +1 because you still have println in there.&lt;/p&gt;</comment>
                            <comment id="13713219" author="xuefuz" created="Fri, 19 Jul 2013 01:05:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=appodictic&quot; class=&quot;user-hover&quot; rel=&quot;appodictic&quot;&gt;Edward Capriolo&lt;/a&gt; Before noticing this one, I was thinking of Jackson too. Jackson is pretty good at XML/JSON serialization/de- with reasonably good performance, and widely adopted, especially for XML/JSON. I used it for java bean serialization, so am not sure of how well it handles object graph as it&apos;s our case. It&apos;s something to figure out.&lt;/p&gt;

&lt;p&gt;This new comer seems very impressive in performance, which may not be super critical in Hive&apos;s use case. However, are you suggesting that the serialized form isn&apos;t human-readable? I didn&apos;t see the output, so wouldn&apos;t know.&lt;/p&gt;</comment>
                            <comment id="13713251" author="appodictic" created="Fri, 19 Jul 2013 01:52:19 +0000"  >&lt;p&gt;Good point I made the assumption that Kairos was not readable but it may be. &lt;/p&gt;

&lt;p&gt;I guess we have to have a bake off and decide what the value of ahuman readable files is. Theoretically we could support more then one but that seems bothersome. Maybe something to get a wider range of optionions on.&lt;/p&gt;</comment>
                            <comment id="13713291" author="appodictic" created="Fri, 19 Jul 2013 02:53:33 +0000"  >&lt;p&gt;BTW the original query was not very artificial. This came up way back when with someone generating a query that had thousands of or conditions. Of course they ended up doing it a different way, but if we can make this more optimal that is good as well.&lt;/p&gt;</comment>
                            <comment id="13716695" author="xuefuz" created="Tue, 23 Jul 2013 18:27:40 +0000"  >&lt;p&gt;It appears that kryo generates binary output, which is thus not human-readable.&lt;/p&gt;

&lt;p&gt;I had difficulty to serialize Hive plan objects using Jackson, which seems good only for POJOs. For non-POJOs, annotations are needed to instruct Jackson what to serialize and what to ignore. However, I&apos;m close to make such a conclusion. &lt;/p&gt;</comment>
                            <comment id="13718358" author="appodictic" created="Wed, 24 Jul 2013 13:30:07 +0000"  >&lt;p&gt;The big challenge with a non readable format is that we diff the plans in unit tests.sometime . changes to the planner result in changes across all the plans. If we go with non readable im not sure how those tests will work.&lt;/p&gt;</comment>
                            <comment id="13731491" author="ashutoshc" created="Wed, 7 Aug 2013 00:35:03 +0000"  >&lt;p&gt;Made some more progress with kryo plan serialization. Check-pointing WIP patch.&lt;/p&gt;</comment>
                            <comment id="13732227" author="ashutoshc" created="Wed, 7 Aug 2013 18:00:47 +0000"  >&lt;p&gt;Another checkpoint.&lt;/p&gt;</comment>
                            <comment id="13734737" author="romixlev" created="Fri, 9 Aug 2013 12:50:29 +0000"  >&lt;p&gt;Hi Ashutosh,&lt;br/&gt;
The bug in Kryo that you reported on Kryo&apos;s mailing list is fixed now. It was related to handling of generic type parameters.&lt;br/&gt;
You can retry with the Kryo trunk version now (2.22-SNAPSHOT).&lt;/p&gt;

&lt;p&gt;-Leo&lt;/p&gt;</comment>
                            <comment id="13737218" author="ashutoshc" created="Mon, 12 Aug 2013 18:53:13 +0000"  >&lt;p&gt;More progress. Some testcases still failing.&lt;/p&gt;</comment>
                            <comment id="13737324" author="ashutoshc" created="Mon, 12 Aug 2013 20:52:22 +0000"  >&lt;p&gt;Had a brief chat with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kamrul&quot; class=&quot;user-hover&quot; rel=&quot;kamrul&quot;&gt;Mohammad Kamrul Islam&lt;/a&gt; who expressed interest in working on this. Assigning it to him.&lt;/p&gt;</comment>
                            <comment id="13739096" author="brocknoland" created="Wed, 14 Aug 2013 00:54:13 +0000"  >&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;How many test cases are failing? Is there anyway I can help with this effort?&lt;/p&gt;

&lt;p&gt;Brock&lt;/p&gt;</comment>
                            <comment id="13739226" author="ashutoshc" created="Wed, 14 Aug 2013 04:57:53 +0000"  >&lt;p&gt;Currently, auto_sortmerge_join_&lt;b&gt;.q, bucketcontext_&lt;/b&gt;.q,bucketsortoptimize_insert_&lt;b&gt;.q,smb_mapjoin_&lt;/b&gt;.q are the testcases  which are failing with current patch.&lt;/p&gt;</comment>
                            <comment id="13739810" author="romixlev" created="Wed, 14 Aug 2013 16:03:40 +0000"  >&lt;p&gt;@Ashutosh: I tried out your latest patch. My results and conclusions are:&lt;br/&gt;
1) auto_sortmerge_join-*.q failure: it seems like copyMRWork method still uses XML serializer instead of Kryo based on the stacktrace of exception that I get &lt;/p&gt;

&lt;p&gt;2) bucketcontext_*.q fails because it seems to produce wrong numeric results. And test compares expected number to the one delivered by the test run. So, it seems to be a semantic error, not a usual exception during (de)serialization.&lt;/p&gt;

&lt;p&gt;3) I tried randomly some of smb_mapjoin_*.q tests. All of them seem to finish successfully.&lt;/p&gt;

&lt;p&gt;Regarding reporting problems: It would be nice if reports would provide exceptions with stacktraces and may be other information that could be useful to identify real problems. It helps a lot.&lt;/p&gt;

&lt;p&gt;-Leo&lt;/p&gt;</comment>
                            <comment id="13739841" author="ashutoshc" created="Wed, 14 Aug 2013 16:30:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=romixlev&quot; class=&quot;user-hover&quot; rel=&quot;romixlev&quot;&gt;Leo Romanoff&lt;/a&gt; Thanks for taking a look. Appreciate your continued help. The reason I have not reported these failures on kryo list is exactly the same as you have identified. I am not yet sure that these failures are because of bugs in kryo. We need to do more digging at our end to validate that our usage of Kryo is correct and the patch is correct as well.&lt;/p&gt;</comment>
                            <comment id="13740289" author="brocknoland" created="Wed, 14 Aug 2013 22:19:27 +0000"  >&lt;p&gt;FWIW I altered this patch to use Kryo as opposed to the XML Encoder as part my work on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5068&quot; title=&quot;Some queries fail due to XMLEncoder error on JDK7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5068&quot;&gt;&lt;del&gt;HIVE-5068&lt;/del&gt;&lt;/a&gt;. The test auto_join25.q gives me the error below:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;com.esotericsoftware.kryo.KryoException: Class cannot be created (missing no-arg constructor): org.antlr.runtime.CommonToken
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;which is a similar probably to what I am fighting with in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5068&quot; title=&quot;Some queries fail due to XMLEncoder error on JDK7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5068&quot;&gt;&lt;del&gt;HIVE-5068&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13740380" author="ashutoshc" created="Wed, 14 Aug 2013 23:07:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt; I think that field could be marked transient. We don&apos;t even ship antlr to backend, so this field can&apos;t be used anyways at backend, so not serializing it is best.&lt;/p&gt;</comment>
                            <comment id="13740391" author="brocknoland" created="Wed, 14 Aug 2013 23:19:44 +0000"  >&lt;p&gt;Yeah I&apos;ll play with that tomorrow. XMLEncoder wasn&apos;t respecting the transient field. It seems to have it&apos;s &lt;a href=&quot;http://www.oracle.com/technetwork/java/persistence4-140124.html#transient&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;own idea about what fields are transient&lt;/a&gt; but I am assuming Kryo does.&lt;/p&gt;</comment>
                            <comment id="13740411" author="ashutoshc" created="Wed, 14 Aug 2013 23:30:36 +0000"  >&lt;p&gt;Kryo indeed does. &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4967&quot; title=&quot;Don&amp;#39;t serialize unnecessary fields in query plan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4967&quot;&gt;&lt;del&gt;HIVE-4967&lt;/del&gt;&lt;/a&gt; was motivated because of these issues only.&lt;/p&gt;</comment>
                            <comment id="13740962" author="brocknoland" created="Thu, 15 Aug 2013 13:37:01 +0000"  >&lt;p&gt;I was able to get auto_join25.q to pass with JDK7 with the attached patch plus the following changes:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Change Utilities.copyMRWork to use the new kryo serialization methods&lt;/li&gt;
	&lt;li&gt;Remove transient flag from ColumnInfo.objectInspector&lt;/li&gt;
	&lt;li&gt;Add transient flag to all types in QBJoinTree containing an ASTNode such as rhsSemiJoin, expressions, filters, filtersForPushing.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13741098" author="ashutoshc" created="Thu, 15 Aug 2013 15:57:07 +0000"  >&lt;p&gt;Good progress, Brock. Would you like to attach your patch and let HIVE QA have a go at it so that we know where we are w.r.t other testcases.&lt;/p&gt;</comment>
                            <comment id="13741101" author="appodictic" created="Thu, 15 Aug 2013 15:59:29 +0000"  >&lt;p&gt;Here is the little funny corner case of this ticket. By adding Kryo to the distributed cache needed to launch jobs we ARE slowing down queries. The better serialization helps more for the very large queries, but for the standard case we may be adding time. &lt;/p&gt;</comment>
                            <comment id="13741103" author="ashutoshc" created="Thu, 15 Aug 2013 16:00:21 +0000"  >&lt;p&gt;By the way, Brock not sure if you noticed this already or not, because of &lt;a href=&quot;https://groups.google.com/forum/#!topic/kryo-users/BsELAOZcxKI&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://groups.google.com/forum/#!topic/kryo-users/BsELAOZcxKI&lt;/a&gt; we need to work with kryo trunk snapshot, not 2.21 as used in current patch.&lt;/p&gt;</comment>
                            <comment id="13741362" author="romixlev" created="Thu, 15 Aug 2013 19:04:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=appodictic&quot; class=&quot;user-hover&quot; rel=&quot;appodictic&quot;&gt;Edward Capriolo&lt;/a&gt; Regarding the speed: I already mentioned these ideas on Kryo mailing list, but may be it was overlooked. Kryo is very fast when used properly.&lt;/p&gt;

&lt;p&gt;Here are some possible improvements:&lt;/p&gt;

&lt;p&gt;1) Do not create new Kryo instances every time you need to (de)serialize. It is a pretty costly operation. Reuse Kryo instances instead. Use object pooling for Kryo instances. But be careful with multi-threading. Kryo instances cannot be used by different threads at &lt;em&gt;the same time&lt;/em&gt;. &lt;/p&gt;

&lt;p&gt;2) Preregister classes (use Kryo.register) to be serialized if possible. It makes serialization faster and serialized representations shorter.&lt;/p&gt;</comment>
                            <comment id="13741385" author="brocknoland" created="Thu, 15 Aug 2013 19:35:04 +0000"  >&lt;p&gt;Patch wip4 contains the changes I described earlier. I haven&apos;t this run will be with 2.21 and then update to the 2.22-SNAPSHOT.&lt;/p&gt;</comment>
                            <comment id="13741386" author="brocknoland" created="Thu, 15 Aug 2013 19:35:18 +0000"  >&lt;p&gt;Marking PA to see a full run.&lt;/p&gt;</comment>
                            <comment id="13742217" author="brocknoland" created="Fri, 16 Aug 2013 13:40:17 +0000"  >&lt;p&gt;Named the patch incorrectly to get precommit tests. Renamed as &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1511&quot; title=&quot;Hive plan serialization is slow&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1511&quot;&gt;&lt;del&gt;HIVE-1511&lt;/del&gt;&lt;/a&gt;.4.patch.&lt;/p&gt;</comment>
                            <comment id="13742430" author="hiveqa" created="Fri, 16 Aug 2013 17:36:03 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12598462/HIVE-1511.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12598462/HIVE-1511.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 134 failed/errored test(s), 2879 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_date_4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_8
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_14
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_19
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ctas_date
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_to_unix_timestamp
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join_filters
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_12
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multiMapJoin2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_11
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sort_merge_join_desc_5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input8
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_cast1
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_ppd_key_range
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_date_1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join32_lessSize
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ptf
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join8
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testxpath
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_20
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_date_udf
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_part1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_18
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_17
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join35
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_smb_mapjoin_14
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin9
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_subq
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join31
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input20
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ptf_npath
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_16
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testxpath2
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_pushdown
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ptf_register_tblfn
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_format_number
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_infer_bucket_sort_map_operators
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf_when
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testsequencefile
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join29
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_ppd_key_ranges
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sort_merge_join_desc_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_filters
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample7
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_22
org.apache.hive.jdbc.TestJdbcDriver2.testPrepareStatement
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join32
org.apache.hadoop.hive.ql.parse.TestParse.testParse_case_sensitivity
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_15
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join_nulls
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_15
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multiMapJoin1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sort_merge_join_desc_2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input9
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join31
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_udtf_not_supported2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_8
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_date
org.apache.hadoop.hive.ql.parse.TestParse.testParse_union
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_9
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_udfnull
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union22
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_14
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketizedhiveinputformat_auto
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input16
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join30
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_8
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_25
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_infer_bucket_sort_reducers_power_two
org.apache.hadoop.hive.jdbc.TestJdbcDriver.testPrepareStatement
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sort_merge_join_desc_3
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_external_table_ppd
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_13
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf_case
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_13
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_7
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_smb_mapjoin_8
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/464/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/464/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/464/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/464/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 134 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13742507" author="brocknoland" created="Fri, 16 Aug 2013 18:39:36 +0000"  >&lt;p&gt;I looked a bunch of failures and it looks like the issue Ashutosh reported. I&apos;ll upload a version of the patch with 2.22-SNAPSHOT version shortly.&lt;/p&gt;</comment>
                            <comment id="13742555" author="brocknoland" created="Fri, 16 Aug 2013 19:43:28 +0000"  >&lt;p&gt;Uploading &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1511&quot; title=&quot;Hive plan serialization is slow&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1511&quot;&gt;&lt;del&gt;HIVE-1511&lt;/del&gt;&lt;/a&gt;.5.patch which uses 2.22-SNAPSHOT for testing purposes.&lt;/p&gt;</comment>
                            <comment id="13742782" author="hiveqa" created="Sat, 17 Aug 2013 01:30:31 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12598520/HIVE-1511.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12598520/HIVE-1511.5.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 105 failed/errored test(s), 2885 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_date_4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_8
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_14
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_19
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join_filters
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ctas_date
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_to_unix_timestamp
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multiMapJoin2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input8
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_cast1
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_ppd_key_range
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_date_1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join32_lessSize
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input7
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join8
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testxpath
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_20
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_date_udf
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_part1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_18
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join35
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_subq
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join31
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input20
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_4
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_pushdown
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testxpath2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_format_number
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf_when
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testsequencefile
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join29
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_ppd_key_ranges
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample7
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join_nulls
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_22
org.apache.hive.jdbc.TestJdbcDriver2.testPrepareStatement
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_15
org.apache.hadoop.hive.ql.parse.TestParse.testParse_case_sensitivity
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multiMapJoin1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input9
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join31
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_udtf_not_supported2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_8
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_2
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_udfnull
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_date
org.apache.hadoop.hive.ql.parse.TestParse.testParse_union
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_9
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union22
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketizedhiveinputformat_auto
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input16
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join30
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_8
org.apache.hadoop.hive.jdbc.TestJdbcDriver.testPrepareStatement
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_6
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_external_table_ppd
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_13
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf_case
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_7
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/466/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/466/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/466/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/466/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 105 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13743799" author="brocknoland" created="Mon, 19 Aug 2013 13:19:18 +0000"  >&lt;p&gt;Two example errors I found below. &lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.ql.parse.SemanticException: Generate Map Join Task Error: Class cannot be created (missing no-arg constructor): org.antlr.runtime.CommonToken
Serialization trace:
token (org.apache.hadoop.hive.ql.parse.ASTNode)
children (org.apache.hadoop.hive.ql.parse.ASTNode)
expressionMap (org.apache.hadoop.hive.ql.parse.RowResolver)
rr (org.apache.hadoop.hive.ql.parse.OpParseContext)
opParseCtxMap (org.apache.hadoop.hive.ql.plan.MapWork)
mapWork (org.apache.hadoop.hive.ql.plan.MapredWork)
  at org.apache.hadoop.hive.ql.optimizer.physical.CommonJoinTaskDispatcher.processCurrentTask(CommonJoinTaskDispatcher.java:532)
  at org.apache.hadoop.hive.ql.optimizer.physical.AbstractJoinTaskDispatcher.dispatch(AbstractJoinTaskDispatcher.java:182)
  at org.apache.hadoop.hive.ql.lib.TaskGraphWalker.dispatch(TaskGraphWalker.java:111)
  at org.apache.hadoop.hive.ql.lib.TaskGraphWalker.walk(TaskGraphWalker.java:194)
  at org.apache.hadoop.hive.ql.lib.TaskGraphWalker.startWalking(TaskGraphWalker.java:139)
  at org.apache.hadoop.hive.ql.optimizer.physical.CommonJoinResolver.resolve(CommonJoinResolver.java:79)
  at org.apache.hadoop.hive.ql.optimizer.physical.PhysicalOptimizer.optimize(PhysicalOptimizer.java:90)
  at org.apache.hadoop.hive.ql.parse.MapReduceCompiler.compile(MapReduceCompiler.java:292)
  at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:8338)
  at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:278)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2013-08-16 17:38:11,297 ERROR ql.Driver (SessionState.java:printError(416)) - FAILED: ArrayIndexOutOfBoundsException 1
java.lang.ArrayIndexOutOfBoundsException: 1
  at org.apache.hadoop.hive.ql.metadata.Partition.getBucketPath(Partition.java:427)
  at org.apache.hadoop.hive.ql.optimizer.SamplePruner.prune(SamplePruner.java:199)
  at org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils.setTaskPlan(GenMapRedUtils.java:558)
  at org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils.setTaskPlan(GenMapRedUtils.java:398)
  at org.apache.hadoop.hive.ql.optimizer.GenMRFileSink1.processFS(GenMRFileSink1.java:715)
  at org.apache.hadoop.hive.ql.optimizer.GenMRFileSink1.process(GenMRFileSink1.java:160)
  at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)
  at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:94)
  at org.apache.hadoop.hive.ql.parse.GenMapRedWalker.walk(GenMapRedWalker.java:54)
  at org.apache.hadoop.hive.ql.parse.GenMapRedWalker.walk(GenMapRedWalker.java:65)
  at org.apache.hadoop.hive.ql.parse.GenMapRedWalker.walk(GenMapRedWalker.java:65)
  at org.apache.hadoop.hive.ql.parse.GenMapRedWalker.walk(GenMapRedWalker.java:65)
  at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:109)
  at org.apache.hadoop.hive.ql.parse.MapReduceCompiler.compile(MapReduceCompiler.java:259)
  at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:8338)
  at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:278)
  at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:437)
  at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:341)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13743880" author="ashutoshc" created="Mon, 19 Aug 2013 15:04:12 +0000"  >&lt;p&gt;First exception looks tractable. &lt;br/&gt;
Second one I have no idea. Only useful info w.r.t second one I have is if you simulate this exact testcase (with same data and queries) on real cluster it doesn&apos;t reproduce. Can&apos;t figure out why though? &lt;/p&gt;</comment>
                            <comment id="13744043" author="brocknoland" created="Mon, 19 Aug 2013 17:39:10 +0000"  >&lt;p&gt;Indeed, it is odd.  I disabled the deleting of the test tables in QTestUtil.&lt;/p&gt;

&lt;p&gt;Bad:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ find build/ql/test/data/warehouse/test_table* -type f | grep -v crc | xargs ls -l
-rwxrwxrwx 1 brock brock  48 Aug 19 12:27 build/ql/test/data/warehouse/test_table1/ds=1/000000_0
-rwxrwxrwx 1 brock brock  32 Aug 19 12:27 build/ql/test/data/warehouse/test_table1/ds=1/000001_0
-rwxrwxrwx 1 brock brock  48 Aug 19 12:27 build/ql/test/data/warehouse/test_table1/ds=2/000000_0
-rwxrwxrwx 1 brock brock  32 Aug 19 12:27 build/ql/test/data/warehouse/test_table1/ds=2/000001_0
-rwxrwxrwx 1 brock brock 468 Aug 19 12:27 build/ql/test/data/warehouse/test_table2/ds=1/000000_0
-rwxrwxrwx 1 brock brock 352 Aug 19 12:27 build/ql/test/data/warehouse/test_table2/ds=1/000001_0
-rwxrwxrwx 1 brock brock 468 Aug 19 12:27 build/ql/test/data/warehouse/test_table2/ds=2/000000_0
-rwxrwxrwx 1 brock brock 352 Aug 19 12:27 build/ql/test/data/warehouse/test_table2/ds=2/000001_0
-rwxrwxrwx 1 brock brock 156 Aug 19 12:27 build/ql/test/data/warehouse/test_table3/ds=1/(ds%3D1)000000_0
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Good:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ find build/ql/test/data/warehouse/test_table* -type f | grep -v crc | xargs ls -l
-rwxrwxrwx 1 noland noland  48 Aug 19 12:32 build/ql/test/data/warehouse/test_table1/ds=1/000000_0
-rwxrwxrwx 1 noland noland  32 Aug 19 12:32 build/ql/test/data/warehouse/test_table1/ds=1/000001_0
-rwxrwxrwx 1 noland noland  48 Aug 19 12:32 build/ql/test/data/warehouse/test_table1/ds=2/000000_0
-rwxrwxrwx 1 noland noland  32 Aug 19 12:32 build/ql/test/data/warehouse/test_table1/ds=2/000001_0
-rwxrwxrwx 1 noland noland 468 Aug 19 12:32 build/ql/test/data/warehouse/test_table2/ds=1/000000_0
-rwxrwxrwx 1 noland noland 352 Aug 19 12:32 build/ql/test/data/warehouse/test_table2/ds=1/000001_0
-rwxrwxrwx 1 noland noland 468 Aug 19 12:32 build/ql/test/data/warehouse/test_table2/ds=2/000000_0
-rwxrwxrwx 1 noland noland 352 Aug 19 12:32 build/ql/test/data/warehouse/test_table2/ds=2/000001_0
-rwxrwxrwx 1 noland noland 156 Aug 19 12:32 build/ql/test/data/warehouse/test_table3/ds=1/(ds%3D1)000000_0
-rwxrwxrwx 1 noland noland 130 Aug 19 12:33 build/ql/test/data/warehouse/test_table3/ds=1/(ds%3D1)000001_0
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13744066" author="ashutoshc" created="Mon, 19 Aug 2013 17:57:27 +0000"  >&lt;p&gt;What was different in Good and Bad case? Sorry, I didnt get this.&lt;/p&gt;</comment>
                            <comment id="13744067" author="brocknoland" created="Mon, 19 Aug 2013 17:58:45 +0000"  >&lt;p&gt;Sorry I thought I should have added some info! Bad is with the patch, testing failing, good is without the patch, test passing.&lt;/p&gt;</comment>
                            <comment id="13744123" author="brocknoland" created="Mon, 19 Aug 2013 19:08:10 +0000"  >&lt;p&gt;Got that one. MapWork.useBucketizedHiveInputFormat is transient and should not be.&lt;/p&gt;</comment>
                            <comment id="13744217" author="ashutoshc" created="Mon, 19 Aug 2013 21:06:38 +0000"  >&lt;p&gt;Cool. I think this will knock off other join failures too which are failing with missing records.&lt;/p&gt;</comment>
                            <comment id="13744331" author="brocknoland" created="Mon, 19 Aug 2013 22:08:59 +0000"  >&lt;p&gt;I was hoping to get a patch with that change uploaded today but I spent too much time trying to fix the other failures so my current tree has other changes. I&apos;ll upload a patch with the useBuck* change tomorrow morning unless someone else does so before then.&lt;/p&gt;

&lt;p&gt;What do you think about the TestParse tests?  If we are not using XML serialization those won&apos;t work.&lt;/p&gt;</comment>
                            <comment id="13744359" author="ashutoshc" created="Mon, 19 Aug 2013 22:22:58 +0000"  >&lt;p&gt;Yeah, I have been thinking about TestParse. I have not seen much value out of those tests. All this while I am on the project, those tests didnt for once caught any regressions. If anything, they are just a hassle which adds useless time to test runs and needs to get updated everytime we change the plan. We already do explain in our .q files to keep track of plans, so there is no extra info in Parse tests anyway. I will vote to drop those tests altogether. What do you think?&lt;/p&gt;</comment>
                            <comment id="13744370" author="xuefuz" created="Mon, 19 Aug 2013 22:28:30 +0000"  >&lt;p&gt;Drop the test, or just the part of comparing plans. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
These tests still compare query outputs additionally.&lt;/p&gt;</comment>
                            <comment id="13744401" author="ashutoshc" created="Mon, 19 Aug 2013 22:54:49 +0000"  >&lt;p&gt;Actually both (those queries or there variant are already covered in .q). But, atleast we can drop the plan comparison part.&lt;/p&gt;</comment>
                            <comment id="13745139" author="brocknoland" created="Tue, 20 Aug 2013 17:10:12 +0000"  >&lt;p&gt;v6 of the patch.&lt;/p&gt;</comment>
                            <comment id="13745157" author="brocknoland" created="Tue, 20 Aug 2013 17:25:16 +0000"  >&lt;p&gt;I keep running into this:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;com.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 20
Serialization trace:
opParseCtxMap (org.apache.hadoop.hive.ql.plan.MapWork)
mapWork (org.apache.hadoop.hive.ql.plan.MapredWork)
  at com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:119)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13745185" author="brocknoland" created="Tue, 20 Aug 2013 17:41:50 +0000"  >&lt;p&gt;Making MapredWork.opParseCtxMap transient seems to fix that. Not sure if that will cause us problems later.&lt;/p&gt;</comment>
                            <comment id="13745232" author="brocknoland" created="Tue, 20 Aug 2013 18:17:23 +0000"  >&lt;p&gt;v7 changes opParseCtxMap to transient.&lt;/p&gt;</comment>
                            <comment id="13746492" author="brocknoland" created="Wed, 21 Aug 2013 15:45:29 +0000"  >&lt;p&gt;opParseCtxMap cannot be transient since we need this for the clone operation. v8 removes this and adds some debug code which I will comment about shortly.&lt;/p&gt;</comment>
                            <comment id="13746496" author="brocknoland" created="Wed, 21 Aug 2013 15:51:33 +0000"  >&lt;p&gt;I am leaving for vacation this afternoon so I won&apos;t be able to help with this effort for over a week. I&apos;ve been working with the test bucketsortoptimize_insert_2.q which fails with &quot;KryoException: Encountered unregistered class ID: 20&quot; during clone of the query plan. All other serialization seems to work fine.  I added some debug code to the Utilities class to help debug this issue. It appears that either the data written out is corrupt or it gets confused on read. Below I have the trace logs to show it.&lt;/p&gt;

&lt;p&gt;Here is the write logs, I have placed a comment where the write and read log start differing:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;00:42 TRACE: [kryo] Write field: rowSchema (org.apache.hadoop.hive.ql.parse.RowResolver) pos=873
00:42 TRACE: [kryo] Write class name reference 21: org.apache.hadoop.hive.ql.exec.RowSchema
00:42 TRACE: [kryo] setGenerics
00:42 TRACE: [kryo] Write initial object reference 1014: _col0: int_col1: string_col6: string)
00:42 DEBUG: [kryo] Write: _col0: int_col1: string_col6: string)
00:42 TRACE: [kryo] FieldSerializer.write fields of class org.apache.hadoop.hive.ql.exec.RowSchema
00:42 TRACE: [kryo] Write field: signature (org.apache.hadoop.hive.ql.exec.RowSchema) pos=876
00:42 TRACE: [kryo] Write class name reference 9: java.util.ArrayList
00:42 DEBUG: [kryo] Write object reference 625: [_col0: int, _col1: string, _col6: string]
00:42 TRACE: [kryo] Write field: rslvMap (org.apache.hadoop.hive.ql.parse.RowResolver) pos=880
00:42 TRACE: [kryo] Write class name reference 30: java.util.HashMap
00:42 TRACE: [kryo] Write initial object reference 1015: {b={value=_col6: string}, a={key=_col0: int, value=_col1: string}}
00:42 DEBUG: [kryo] Write: {b={value=_col6: string}, a={key=_col0: int, value=_col1: string}}
00:42 DEBUG: [kryo] Write object reference 436: b
00:42 TRACE: [kryo] Write class name reference 1: java.util.LinkedHashMap
00:42 TRACE: [kryo] Write initial object reference 1016: {value=_col6: string}
00:42 DEBUG: [kryo] Write: {value=_col6: string}
00:42 DEBUG: [kryo] Write object reference 479: value
############# Here is where it it gets confused on the read side ###############
00:42 DEBUG: [kryo] Write object reference 628: _col6: string
00:42 DEBUG: [kryo] Write object reference 429: a
00:42 TRACE: [kryo] Write class name reference 1: java.util.LinkedHashMap
00:42 TRACE: [kryo] Write initial object reference 1017: {key=_col0: int, value=_col1: string}
00:42 DEBUG: [kryo] Write: {key=_col0: int, value=_col1: string}
00:42 TRACE: [kryo] Write class 1: String
00:42 DEBUG: [kryo] Write object reference 477: key
00:42 TRACE: [kryo] Write class name reference 22: org.apache.hadoop.hive.ql.exec.ColumnInfo
00:42 DEBUG: [kryo] Write object reference 626: _col0: int
00:42 TRACE: [kryo] Write class 1: String
00:42 DEBUG: [kryo] Write object reference 479: value
00:42 TRACE: [kryo] Write class name reference 22: org.apache.hadoop.hive.ql.exec.ColumnInfo
00:42 DEBUG: [kryo] Write object reference 627: _col1: string
00:42 TRACE: [kryo] Write class name reference 10: org.apache.hadoop.hive.ql.exec.SMBMapJoinOperator
00:42 DEBUG: [kryo] Write object reference 372: MAPJOIN[12]
00:42 TRACE: [kryo] Write class name reference 43: org.apache.hadoop.hive.ql.parse.OpParseContext
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As you can see above, after writing &quot;Write object reference 479: value&quot; Kryo writes &quot;Write object reference 628: _col6: string&quot;. Below we are able to read &quot;Read object reference 479: value&quot; but then it starts reading junk and fails shortly thereafter.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;00:45 TRACE: [kryo] Read field: rowSchema (org.apache.hadoop.hive.ql.parse.RowResolver) pos=873
00:45 TRACE: [kryo] Read class name reference 21: org.apache.hadoop.hive.ql.exec.RowSchema
00:45 TRACE: [kryo] setGenerics
00:45 TRACE: [kryo] Read initial object reference 1014: org.apache.hadoop.hive.ql.exec.RowSchema
00:45 TRACE: [kryo] Read field: signature (org.apache.hadoop.hive.ql.exec.RowSchema) pos=876
00:45 TRACE: [kryo] Read class name reference 9: java.util.ArrayList
00:45 DEBUG: [kryo] Read object reference 625: [_col0: int, _col1: string, _col6: string]
00:45 DEBUG: [kryo] Read: _col0: int_col1: string_col6: string)
00:45 TRACE: [kryo] Read field: rslvMap (org.apache.hadoop.hive.ql.parse.RowResolver) pos=880
00:45 TRACE: [kryo] Read class name reference 30: java.util.HashMap
00:45 TRACE: [kryo] Read initial object reference 1015: java.util.HashMap
00:45 DEBUG: [kryo] Read object reference 436: b
00:45 TRACE: [kryo] Read class name reference 1: java.util.LinkedHashMap
00:45 TRACE: [kryo] Read initial object reference 1016: java.util.LinkedHashMap
00:45 DEBUG: [kryo] Read object reference 479: value
########### Here it appears to get confused #############
00:45 TRACE: [kryo] Read: -216
00:45 DEBUG: [kryo] Read: {value=-216}
00:45 TRACE: [kryo] Read initial object reference 1017: String
00:45 TRACE: [kryo] Read: _
00:45 TRACE: [kryo] Read initial object reference 1018: String
00:45 TRACE: [kryo] Read: t
00:45 DEBUG: [kryo] Read: {_=t, b={value=-216}}
00:45 DEBUG: [kryo] Read: RowResolver
00:45 DEBUG: [kryo] Read: org.apache.hadoop.hive.ql.parse.OpParseContext
00:45 TRACE: [kryo] Read class 2: float
00:45 TRACE: [kryo] Read: 1.3225001E-36
00:45 TRACE: [kryo] Object graph complete.
Exception: Client Execution failed with error code = 40000
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Additionally this version of the patch saves the byte arrays to disk, you&apos;ll note during bucketsortoptimize_insert_2.q two files are written out, the second one is the corrupt one:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ ls -l /tmp/kryo-mapredwork-*
-rw-r--r-- 1 brock brock 10365 Aug 21 10:25 /tmp/kryo-mapredwork-1
-rw-r--r-- 1 brock brock 19981 Aug 21 10:25 /tmp/kryo-mapredwork-2
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13746695" author="hiveqa" created="Wed, 21 Aug 2013 18:35:44 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12599211/HIVE-1511.8.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12599211/HIVE-1511.8.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 415 failed/errored test(s), 2895 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_named_struct
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_show_indexes_edge_cases
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_map_keys
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_quote2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap_auto
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_covar_pop
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_escape1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input18
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_date_4
org.apache.hive.jdbc.TestJdbcDriver2.testResultSetMetaData
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_create_escape
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input_part10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_find_in_set
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_lateral_view
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap_compression
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_degrees
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union15
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_xpath_int
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_14
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_create_genericudaf
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_case_thrift
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_num_op_type_conv
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_second
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_joins
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_compression
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_nested_complex
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap_rc
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ctas_date
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_columnstats_tbllvl
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_load_dyn_part14
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_lateralview
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_unix_timestamp
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multiMapJoin2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_compute_stats_string
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_compute_stats_binary
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_insert_into5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_to_unix_timestamp
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppr_pushdown2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_field
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_virtual_column
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ptf_general_queries
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join_filters
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_min
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_load_dyn_part15
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_orc_empty_files
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_compact_3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_div
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_map
org.apache.hadoop.hive.ql.parse.TestParse.testParse_cast1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_literal_string
org.apache.hive.jdbc.TestJdbcDriver2.testNullType
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_sort_skew_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_substr
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_partitioned
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input_dynamicserde
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_context_ngrams
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_null_column
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_compact_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_filters_overlap
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input8
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_date_3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_to_short
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppr_pushdown
org.apache.hive.jdbc.TestJdbcDriver2.testDuplicateColumnNameOrder
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_show_indexes_syntax
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_index_compact_entry_limit
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_to_string
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_type_cast_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_array
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_percentile
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_multiple
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_date_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_compact_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_acos
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_empty
org.apache.hadoop.hive.cli.TestContribCliDriver.testCliDriver_udf_example_format
org.apache.hadoop.hive.jdbc.TestJdbcDriver.testNullType
org.apache.hadoop.hive.cli.TestContribCliDriver.testCliDriver_udtf_explode2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join32_lessSize
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_greaterthan
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_array_contains
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_decimal_precision
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_view
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap1
org.apache.hive.jdbc.TestJdbcDriver2.testDataTypes2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_translate
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union26
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_coalesce
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_negative
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_constant_prop
org.apache.hive.jdbc.TestJdbcDriver2.testBuiltInUDFCol
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_timestamp_lazy
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_disallow_incompatible_type_change_on2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_elt
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_complex_types_multi_single_reducer
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_part1
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_bucket_num_reducers
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_date2
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_udf_assert_true
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input_testxpath
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testxpath
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample5
org.apache.hadoop.hive.cli.TestContribCliDriver.testCliDriver_lateral_view_explode2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_special_char
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_timestamp_udf
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_conv
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_create_struct_table
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_newline
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_covar_samp
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_dynamic_partition_skip_default
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_macro
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join8
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_like
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_binary_constant
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_radians
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_date_udf
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_filter_join_breaktask2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_PI
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap_auto_partitioned
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_type_widening
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_literal_ints
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_global_limit
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_bitmap_or
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_compact
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_minute
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_atan
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input4
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_binary_map_queries_prefix
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_xpath_long
org.apache.hadoop.hive.cli.TestContribCliDriver.testCliDriver_udaf_example_max_n
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_tan
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_to_boolean
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input38
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_query_with_semi
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_binary_map_queries
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partcols1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_lateral_view_outer
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_unhex
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_rpad
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_load_dyn_part13
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_self_join
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_combine2_hadoop20
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_compute_stats_long
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union17
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_literal_decimal
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_lessthan
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join35
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union12
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udtf_stack
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input_testxpath4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_merge4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_null_cast
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_index_compact_size_limit
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_to_float
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union11
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_columnarserde_create_shortcut
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_xpath_float
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_E
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby3_map_skew
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_locate
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cast1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_notop
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join31
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_space
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_xpath_double
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_corr
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_collect_set
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_query_result_fileformat
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_concat
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_complex_types
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_script_env_var1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_columnstats_partlvl
org.apache.hadoop.hive.ql.parse.TestParse.testParse_subq
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_ngrams
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input20
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_grouping_sets3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_compute_stats_empty_table
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_mult_tables
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_serde
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_split
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_str_to_map
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_format_number
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_insert_overwrite_local_directory_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input49
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_array
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join29
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union14
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_regexp
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_histogram_numeric
org.apache.hadoop.hive.jdbc.TestJdbcDriver.testResultSetMetaData
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_reflect2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_orc_empty_strings
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_lower
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_udf_assert_true2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_round_3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_decode_name
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_transform1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_explode
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_compute_stats_double
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testxpath2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_decimal_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union20
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf_when
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testsequencefile
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_sort_array
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_to_byte
org.apache.hadoop.hive.cli.TestContribCliDriver.testCliDriver_udaf_example_group_concat
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_xpath
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_autogen_colalias
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ql_rewrite_gbtoidx
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_get_json_object
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_update
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_lateral_view_cp
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_compact_binary_search
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_round
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_sign
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_sin
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_xpath_string
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_struct
org.apache.hadoop.hive.cli.TestContribCliDriver.testCliDriver_udaf_example_avg
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_pcr
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union21
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udtf_explode
org.apache.hadoop.hive.cli.TestContribCliDriver.testCliDriver_udaf_example_min_n
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_thrift
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_to_long
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_max
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_rcfile_merge2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_script_env_var2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_timestamp_comparison
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_unused
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_creation
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_disallow_incompatible_type_change_on1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_timestamp_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ppd_union_view
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_15
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_round_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_orc_create
org.apache.hive.jdbc.TestJdbcDriver2.testPrepareStatement
org.apache.hadoop.hive.ql.parse.TestParse.testParse_case_sensitivity
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_percentile_approx_20
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_allcolref_in_udf
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_isnull_isnotnull
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input_testxpath3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_stale_partitioned
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join_nulls
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_bitmap_and
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_logic_java_boolean
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input_columnarserde
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats19
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union19
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_hash
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multiMapJoin1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_lessthanorequal
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_file_format
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input9
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_disallow_incompatible_type_change_off
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_weekofyear
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_cos
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_lateral_view_noalias
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample6
org.apache.hadoop.hive.cli.TestContribCliDriver.testCliDriver_udf_example_add
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_divide
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketsortoptimize_insert_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join31
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_decimal_udf
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_bin
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_when
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf9
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_regexp_extract
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_test_outer
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union18
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_date
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_hex
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_printf
org.apache.hadoop.hive.ql.parse.TestParse.testParse_union
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_9
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_explode_null
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auth
org.apache.hadoop.hive.jdbc.TestJdbcDriver.testDataTypes
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_compute_stats_boolean
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_create_genericudf
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_concat_insert2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input_testxpath2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_stale
org.apache.hive.jdbc.TestJdbcDriver2.testDataTypes
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_ascii
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_if
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_test_boolean_whereclause
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_udfnull
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_timestamp_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union22
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_create_view
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input16
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_instr
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_xpath_boolean
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multi_insert_lateral_view
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_xpath_short
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join30
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_8
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_parse_url
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_hour
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_timestamp_3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_decimal_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_literal_double
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_bitmap_empty
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_asin
org.apache.hadoop.hive.jdbc.TestJdbcDriver.testPrepareStatement
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_mult_tables_compact
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_sort_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby3_map
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_in
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_greaterthanorequal
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_inline
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_abs
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_repeat
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_escape2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udtf_json_tuple
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udtf_parse_url_tuple
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input_lazyserde
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_size
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_windowing
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_number_format
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_case
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_database_drop
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_stats3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_orc_dictionary_threshold
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf8
org.apache.hive.jdbc.TestJdbcDriver2.testExprCol
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_lpad
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_skewjoinopt10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_nvl
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_case_sensitivity
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_pmod
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_to_double
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_concat_ws
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby3_map_multi_distinct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input45
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_table_access_keys_stats
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_avro_nullable_fields
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf_case
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_column_access_stats
org.apache.hadoop.hive.cli.TestContribCliDriver.testCliDriver_udf_example_arraymapstruct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ops_comparison
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_queries
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_date_comparison
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_map_values
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_lateral_view_ppd
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input17
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_union
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_insert1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_infer_bucket_sort
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_10_trims
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_sentences
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_equal
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/495/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/495/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/495/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/495/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 415 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13747338" author="romixlev" created="Thu, 22 Aug 2013 07:30:15 +0000"  >&lt;p&gt;@&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt; The problem with deserialization that you reported am 21 August seems interesting. It could be an indication of a bug in Kryo. At the first glance it looks as if there is a bug in serialization of strings or in writing/reading object references. I&apos;ll look into it if time permits.&lt;/p&gt;

&lt;p&gt;It would be very nice to get a reduced version of this test (e.g. only the data structure that fails and the content of fields that leads to it), which can be easily reproduced as a JUnit-test for Kryo. &lt;/p&gt;

&lt;p&gt;-Leo&lt;/p&gt;</comment>
                            <comment id="13747864" author="kamrul" created="Thu, 22 Aug 2013 20:37:11 +0000"  >&lt;p&gt;Let me take it from where you left.&lt;/p&gt;</comment>
                            <comment id="13752239" author="kamrul" created="Wed, 28 Aug 2013 09:30:28 +0000"  >&lt;p&gt;Thanks to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt; for moving it to this far!&lt;/p&gt;

&lt;p&gt;I think I isolated the issue in some extent. Looks like it is a bug in Kryo.&lt;/p&gt;

&lt;p&gt;At first, I created an XML plan file for the failed case using our existing java based serialization.&lt;/p&gt;

&lt;p&gt;Then I wrote (copied from Ashutosh) an independent java class that deserializes the plan XML in MapRedWork object using XMLDecoder. After that, the code serializes the MapredWork object using Kryo. At last, deserialize it using Kryo. In this case, serialization with Kryo succeeds but deserialization with Kryo fails with the following exception. It is important to note that the simpler version of plan XML succeeds using the same utility.&lt;/p&gt;


&lt;p&gt;I&apos;m going to attach three files:&lt;br/&gt;
1. Independent Java code to test &amp;lt;KryoHiveTest.java&amp;gt;.&lt;br/&gt;
2. Script to compile and run &amp;lt;run.sh&amp;gt;. (Run with &quot;run.sh generated_plan.xml&quot;)&lt;br/&gt;
3. Generated plan in XML &amp;lt;generated_plan.xml&amp;gt; that fails.&lt;/p&gt;

&lt;p&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=romixlev&quot; class=&quot;user-hover&quot; rel=&quot;romixlev&quot;&gt;Leo Romanoff&lt;/a&gt; : do you have any suggestion? I think you are also active in Kryo. Should i send an email to kayo list?&lt;/p&gt;




&lt;p&gt;Exception:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Exception in thread &quot;main&quot; com.esotericsoftware.kryo.KryoException: java.lang.IndexOutOfBoundsException: Index: 12416, Size: 1504&lt;br/&gt;
Serialization trace:&lt;br/&gt;
rslvMap (org.apache.hadoop.hive.ql.parse.RowResolver)&lt;br/&gt;
rr (org.apache.hadoop.hive.ql.parse.OpParseContext)&lt;br/&gt;
opParseCtxMap (org.apache.hadoop.hive.ql.plan.MapWork)&lt;br/&gt;
mapWork (org.apache.hadoop.hive.ql.plan.MapredWork)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:485)&lt;br/&gt;
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:679)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:485)&lt;br/&gt;
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:760)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:139)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:17)&lt;br/&gt;
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:679)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:485)&lt;br/&gt;
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:679)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:485)&lt;br/&gt;
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:657)&lt;br/&gt;
	at KryoHiveTest.fun(KryoHiveTest.java:51)&lt;br/&gt;
	at KryoHiveTest.main(KryoHiveTest.java:25)&lt;br/&gt;
Caused by: java.lang.IndexOutOfBoundsException: Index: 12416, Size: 1504&lt;br/&gt;
	at java.util.ArrayList.RangeCheck(ArrayList.java:547)&lt;br/&gt;
	at java.util.ArrayList.get(ArrayList.java:322)&lt;br/&gt;
	at com.esotericsoftware.kryo.util.MapReferenceResolver.getReadObject(MapReferenceResolver.java:42)&lt;br/&gt;
	at com.esotericsoftware.kryo.Kryo.readReferenceOrNull(Kryo.java:804)&lt;br/&gt;
	at com.esotericsoftware.kryo.Kryo.readObjectOrNull(Kryo.java:728)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:127)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:17)&lt;br/&gt;
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:679)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106)&lt;br/&gt;
	... 16 more&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="13753681" author="romixlev" created="Thu, 29 Aug 2013 14:45:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kamrul&quot; class=&quot;user-hover&quot; rel=&quot;kamrul&quot;&gt;Mohammad Kamrul Islam&lt;/a&gt; I think I fixed the problem you reported. Your test seems to pass now on my side. I fixed the bug in Kryo (and it was a serious one related to usage of nested generic classes, e.g. Maps of Maps) and it is just committed into Kryo trunk. Simply update your Kryo 2.22-SNAPSHOT to make sure it uses the latest trunk and you should be fine.&lt;/p&gt;

&lt;p&gt;-Leo&lt;/p&gt;</comment>
                            <comment id="13754031" author="kamrul" created="Thu, 29 Aug 2013 20:44:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=romixlev&quot; class=&quot;user-hover&quot; rel=&quot;romixlev&quot;&gt;Leo Romanoff&lt;/a&gt; Thanks a lot for quick fix.&lt;/p&gt;

&lt;p&gt;Now working on the next failed one.&lt;/p&gt;
</comment>
                            <comment id="13754035" author="brocknoland" created="Thu, 29 Aug 2013 20:47:23 +0000"  >&lt;p&gt;Great to hear guys! When you are at a point where it makes sense it&apos;d be interesting to see another run of the precommit tests.&lt;/p&gt;</comment>
                            <comment id="13755059" author="kamrul" created="Fri, 30 Aug 2013 19:34:15 +0000"  >&lt;p&gt;Sure. Made some more progress.&lt;br/&gt;
Will upload a new WIP patch soon.&lt;/p&gt;</comment>
                            <comment id="13755143" author="brocknoland" created="Fri, 30 Aug 2013 21:06:42 +0000"  >&lt;p&gt;FWIW the changes to Kryo also fixed my JDK7 problems.&lt;/p&gt;</comment>
                            <comment id="13755420" author="kamrul" created="Sat, 31 Aug 2013 05:32:07 +0000"  >&lt;p&gt;WIP patch.  auto_sortmerge_join_9.q and bucketsortoptimize_insert_4.q are failing with similar exception. Most possibly, it is another Kryo bug. Writing in one format and  Reading differently. Will try to create an independent test to recreate. &lt;/p&gt;</comment>
                            <comment id="13755460" author="kamrul" created="Sat, 31 Aug 2013 08:37:37 +0000"  >&lt;p&gt;Running after another probable Kryo bug.&lt;br/&gt;
Got the following exception  when ran with the attached plan XML file.&lt;/p&gt;

&lt;p&gt;Exception in thread &quot;main&quot; com.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 115&lt;br/&gt;
Serialization trace:&lt;br/&gt;
opParseCtxMap (org.apache.hadoop.hive.ql.plan.MapWork)&lt;br/&gt;
mapWork (org.apache.hadoop.hive.ql.plan.MapredWork)&lt;br/&gt;
	at com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:119)&lt;br/&gt;
	at com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:642)&lt;br/&gt;
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:753)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:131)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:17)&lt;br/&gt;
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:680)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:485)&lt;br/&gt;
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:680)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106)&lt;br/&gt;
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:485)&lt;br/&gt;
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:658)&lt;br/&gt;
	at KryoHiveTest.fun(KryoHiveTest.java:54)&lt;br/&gt;
	at KryoHiveTest.main(KryoHiveTest.java:27)&lt;/p&gt;</comment>
                            <comment id="13755495" author="brocknoland" created="Sat, 31 Aug 2013 12:13:38 +0000"  >&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I am re-uploading your patch &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1511&quot; title=&quot;Hive plan serialization is slow&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1511&quot;&gt;&lt;del&gt;HIVE-1511&lt;/del&gt;&lt;/a&gt;.wip.9.patch as &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1511&quot; title=&quot;Hive plan serialization is slow&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1511&quot;&gt;&lt;del&gt;HIVE-1511&lt;/del&gt;&lt;/a&gt;.9.patch so the &lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Hive+PreCommit+Patch+Testing&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;tests will execute&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13755497" author="hiveqa" created="Sat, 31 Aug 2013 12:29:20 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12600944/HIVE-1511.9.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12600944/HIVE-1511.9.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/587/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/587/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/587/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/587/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-587/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf build hcatalog/build hcatalog/core/build hcatalog/storage-handlers/hbase/build hcatalog/server-extensions/build hcatalog/webhcat/svr/build hcatalog/webhcat/java-client/build hcatalog/hcatalog-pig-adapter/build common/src/gen
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1519174.

At revision 1519174.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0 to p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13755500" author="romixlev" created="Sat, 31 Aug 2013 12:50:22 +0000"  >&lt;p&gt;This XML file can be read properly by the latest Kryo snapshot without any additional changes on my side. Are you sure you use the latest build of the latest Kryo snapshot (2.22-SNAPSHOT)?&lt;/p&gt;

&lt;p&gt;-Leo&lt;/p&gt;</comment>
                            <comment id="13756291" author="ashutoshc" created="Tue, 3 Sep 2013 00:55:47 +0000"  >&lt;p&gt;With .10 patch, I am able to get all tests to pass in CliDriver &amp;amp; NegativeCliDriver except:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;TestCliDriver_input16.q&lt;/li&gt;
	&lt;li&gt;TestNegativeCliDriver_udfnull.q&lt;br/&gt;
*&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13756295" author="hiveqa" created="Tue, 3 Sep 2013 01:10:25 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12601094/HIVE-1511.10.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12601094/HIVE-1511.10.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/590/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/590/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/590/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/590/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-590/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;ql/src/test/results/clientpositive/groupby_cube1.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/groupby2_map_skew.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/reduce_deduplicate_extended.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/groupby_rollup1.q.out&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/ReduceSinkDeDuplication.java&apos;
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf build hcatalog/build hcatalog/core/build common/src/gen
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1519535.

At revision 1519535.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file contrib/src/java/org/apache/hadoop/hive/contrib/udtf/example/GenericUDTFCount2.java
patching file contrib/src/java/org/apache/hadoop/hive/contrib/udtf/example/GenericUDTFExplode2.java
patching file hcatalog/pom.xml
patching file ivy/ivysettings.xml
patching file ivy/libraries.properties
patching file ql/build.xml
patching file ql/ivy.xml
patching file ql/src/java/org/apache/hadoop/hive/ql/Driver.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/ColumnInfo.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/ExprNodeColumnEvaluator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableDummyOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/RowSchema.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapRedTask.java
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/BucketingSortingCtx.java
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/GenMRSkewJoinProcessor.java
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/LocalMapJoinProcFactory.java
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/SortMergeJoinTaskDispatcher.java
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/QBJoinTree.java
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/RowResolver.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/MapWork.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/MapredWork.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDesc.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/PartitionDesc.java
patching file ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFnGrams.java
patching file ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFArray.java
patching file ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBridge.java
patching file ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFFormatNumber.java
patching file ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFIndex.java
patching file ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFNamedStruct.java
patching file ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFStruct.java
patching file ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToUnixTimeStamp.java
patching file ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFExplode.java
patching file ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFJSONTuple.java
patching file ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFParseUrlTuple.java
patching file ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFStack.java
+ [[ true == \t\r\u\e ]]
+ rm -rf /data/hive-ptest/working/ivy /data/hive-ptest/working/maven
+ mkdir /data/hive-ptest/working/ivy /data/hive-ptest/working/maven
+ ant -Dtest.continue.on.failure=true -Dtest.silent=false -Divy.default.ivy.user.dir=/data/hive-ptest/working/ivy -Dmvn.local.repo=/data/hive-ptest/working/maven clean package test -Dtestcase=nothing
Buildfile: /data/hive-ptest/working/apache-svn-trunk-source/build.xml

clean:
     [echo] Project: hive

clean:
     [echo] Project: anttasks

clean:
     [echo] Project: shims

clean:
     [echo] Project: common

clean:
     [echo] Project: serde

clean:
     [echo] Project: metastore

clean:
     [echo] Project: ql

clean:
     [echo] Project: contrib

clean:
     [echo] Project: service

clean:
     [echo] Project: cli

clean:
     [echo] Project: jdbc

clean:
     [echo] Project: beeline

clean:
     [echo] Project: hwi

clean:
     [echo] Project: hbase-handler

clean:
     [echo] Project: testutils

clean:
     [echo] hcatalog

clean:
     [echo] hcatalog-core

clean:
     [echo] hcatalog-pig-adapter

clean:
     [echo] hcatalog-server-extensions

clean:
     [echo] webhcat

clean:
     [echo] webhcat-java-client

clean:

clean:
     [echo] Project: odbc
     [exec] rm -rf /data/hive-ptest/working/apache-svn-trunk-source/build/odbc /data/hive-ptest/working/apache-svn-trunk-source/build/service/objs /data/hive-ptest/working/apache-svn-trunk-source/build/ql/objs /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/objs

clean-online:
     [echo] Project: hive

clean-offline:

ivy-init-dirs:
     [echo] Project: hive
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/maven

ivy-download:
     [echo] Project: hive
      [get] Getting: http://repo2.maven.org/maven2/org/apache/ivy/ivy/2.3.0/ivy-2.3.0.jar
      [get] To: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/ivy-2.3.0.jar

ivy-probe-antlib:
     [echo] Project: hive

ivy-init-antlib:
     [echo] Project: hive

compile-ant-tasks:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jexl/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

ivy-init-settings:
     [echo] Project: anttasks

ivy-resolve:
     [echo] Project: anttasks
[ivy:resolve] :: Apache Ivy 2.3.0 - 20130110142753 :: http://ant.apache.org/ivy/ ::
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-anttasks;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found velocity#velocity;1.5 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-lang/commons-lang/2.4/commons-lang-2.4.jar ...
[ivy:resolve] ..... (255kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-lang#commons-lang;2.4!commons-lang.jar (33ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/velocity/velocity/1.5/velocity-1.5.jar ...
[ivy:resolve] ....... (382kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] velocity#velocity;1.5!velocity.jar (23ms)
[ivy:resolve] :: resolution report :: resolve 5372ms :: artifacts dl 79ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-anttasks-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-anttasks-default.html

ivy-retrieve:
     [echo] Project: anttasks
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-anttasks
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	2 artifacts copied, 0 already retrieved (638kB/7ms)

compile:
     [echo] anttasks
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ant/build.xml:38: warning: &apos;includeantruntime&apos; was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds
    [javac] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.

deploy-ant-tasks:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

ivy-init-settings:
     [echo] Project: anttasks

ivy-resolve:
     [echo] Project: anttasks
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-anttasks;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found velocity#velocity;1.5 in maven2
[ivy:resolve] :: resolution report :: resolve 469ms :: artifacts dl 3ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-anttasks-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-anttasks-default.html

ivy-retrieve:
     [echo] Project: anttasks
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-anttasks
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	0 artifacts copied, 2 already retrieved (0kB/7ms)

compile:
     [echo] anttasks
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/ant/build.xml:38: warning: &apos;includeantruntime&apos; was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds

jar:
     [echo] anttasks
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/classes/org/apache/hadoop/hive/ant
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/hive-anttasks-0.12.0-SNAPSHOT.jar

init:
     [echo] Project: hive

create-dirs:
     [echo] Project: anttasks
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources does not exist.

init:
     [echo] Project: anttasks

create-dirs:
     [echo] Project: shims
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/test/resources does not exist.

init:
     [echo] Project: shims

create-dirs:
     [echo] Project: common
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/resources
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/build/common/test/resources

init:
     [echo] Project: common

create-dirs:
     [echo] Project: serde
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources does not exist.

init:
     [echo] Project: serde

create-dirs:
     [echo] Project: metastore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources does not exist.

init:
     [echo] Project: metastore

create-dirs:
     [echo] Project: ql
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/resources
     [copy] Copying 3 files to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/test/resources

init:
     [echo] Project: ql

create-dirs:
     [echo] Project: contrib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources does not exist.

init:
     [echo] Project: contrib

create-dirs:
     [echo] Project: service
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/service/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources does not exist.

init:
     [echo] Project: service

create-dirs:
     [echo] Project: cli
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/resources does not exist.

init:
     [echo] Project: cli

create-dirs:
     [echo] Project: jdbc
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/test/resources does not exist.

init:
     [echo] Project: jdbc

create-dirs:
     [echo] Project: beeline
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/test/resources does not exist.

init:
     [echo] Project: beeline

create-dirs:
     [echo] Project: hwi
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources does not exist.

init:
     [echo] Project: hwi

create-dirs:
     [echo] Project: hbase-handler
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources does not exist.

init:
     [echo] Project: hbase-handler

create-dirs:
     [echo] Project: testutils
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/src
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/classes
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/test/resources
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources does not exist.

init:
     [echo] Project: testutils

init:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build/hcatalog-0.12.0-SNAPSHOT

jar:
     [echo] Project: hive

ivy-init-settings:
     [echo] Project: shims

check-ivy:
     [echo] Project: shims

ivy-resolve:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.zookeeper#zookeeper;3.4.3 in maven2
[ivy:resolve] 	found org.apache.thrift#libthrift;0.9.0 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.4 in maven2
[ivy:resolve] 	found commons-logging#commons-logging-api;1.0.4 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.4 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar ...
[ivy:resolve] .............. (749kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.3!zookeeper.jar (21ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar ...
[ivy:resolve] ....... (339kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.thrift#libthrift;0.9.0!libthrift.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging/1.0.4/commons-logging-1.0.4.jar ...
[ivy:resolve] .. (37kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-logging#commons-logging;1.0.4!commons-logging.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging-api/1.0.4/commons-logging-api-1.0.4.jar ...
[ivy:resolve] .. (25kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-logging#commons-logging-api;1.0.4!commons-logging-api.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar ...
[ivy:resolve] ..... (222kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-core-asl;1.8.8!jackson-core-asl.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar ...
[ivy:resolve] ............ (652kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-mapper-asl;1.8.8!jackson-mapper-asl.jar (18ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/log4j/log4j/1.2.16/log4j-1.2.16.jar ...
[ivy:resolve] ......... (470kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] log4j#log4j;1.2.16!log4j.jar(bundle) (16ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/guava/guava/11.0.2/guava-11.0.2.jar ...
[ivy:resolve] ........................... (1609kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.guava#guava;11.0.2!guava.jar (35ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-io/commons-io/2.4/commons-io-2.4.jar ...
[ivy:resolve] .... (180kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-io#commons-io;2.4!commons-io.jar (9ms)
[ivy:resolve] :: resolution report :: resolve 9572ms :: artifacts dl 163ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   9   |   9   |   0   ||   9   |   9   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-shims-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-shims-default.html

make-pom:
     [echo] Project: shims
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: shims
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/test/resources does not exist.

init:
     [echo] Project: shims

ivy-retrieve:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	9 artifacts copied, 0 already retrieved (4287kB/38ms)

compile:
     [echo] Project: shims
     [echo] Building shims 0.20

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20/java against hadoop 0.20.2 (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-0.20.2)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.20.shim]
[ivy:resolve] 	found org.apache.hadoop#hadoop-core;0.20.2 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.0.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.3 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.3 in maven2
[ivy:resolve] 	found commons-net#commons-net;1.4.1 in maven2
[ivy:resolve] 	found oro#oro;2.0.8 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api-2.5;6.1.14 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.12 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.12 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-api-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.eclipse.jdt#core;3.1.1 in maven2
[ivy:resolve] 	found ant#ant;1.6.5 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.7.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found net.sf.kosmosfs#kfs;0.3 in maven2
[ivy:resolve] 	found junit#junit;4.5 in maven2
[ivy:resolve] 	found hsqldb#hsqldb;1.8.0.10 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-tools;0.20.2 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-test;0.20.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftplet-api;1.0.0 in maven2
[ivy:resolve] 	found org.apache.mina#mina-core;2.0.0-M5 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.5.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-core;1.0.0 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-core/0.20.2/hadoop-core-0.20.2.jar ...
[ivy:resolve] ............................................. (2624kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-core;0.20.2!hadoop-core.jar (52ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-tools/0.20.2/hadoop-tools-0.20.2.jar ...
[ivy:resolve] ... (68kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-tools;0.20.2!hadoop-tools.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-test/0.20.2/hadoop-test-0.20.2.jar ...
[ivy:resolve] .......................... (1527kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-test;0.20.2!hadoop-test.jar (32ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-cli/commons-cli/1.2/commons-cli-1.2.jar ...
[ivy:resolve] .. (40kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-cli#commons-cli;1.2!commons-cli.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/xmlenc/xmlenc/0.52/xmlenc-0.52.jar ...
[ivy:resolve] .. (14kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] xmlenc#xmlenc;0.52!xmlenc.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar ...
[ivy:resolve] ...... (273kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-httpclient#commons-httpclient;3.0.1!commons-httpclient.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-codec/commons-codec/1.3/commons-codec-1.3.jar ...
[ivy:resolve] .. (45kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-codec#commons-codec;1.3!commons-codec.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar ...
[ivy:resolve] .... (176kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-net#commons-net;1.4.1!commons-net.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty/6.1.14/jetty-6.1.14.jar ...
[ivy:resolve] ......... (504kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty;6.1.14!jetty.jar (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.14/jetty-util-6.1.14.jar ...
[ivy:resolve] .... (159kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty-util;6.1.14!jetty-util.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar ...
[ivy:resolve] ... (74kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-runtime;5.5.12!jasper-runtime.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar ...
[ivy:resolve] ........ (395kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-compiler;5.5.12!jasper-compiler.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar ...
[ivy:resolve] .... (131kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jsp-api-2.1;6.1.14!jsp-api-2.1.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar ...
[ivy:resolve] ................. (1000kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jsp-2.1;6.1.14!jsp-2.1.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-el/commons-el/1.0/commons-el-1.0.jar ...
[ivy:resolve] ... (109kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-el#commons-el;1.0!commons-el.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar ...
[ivy:resolve] ....... (368kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.java.dev.jets3t#jets3t;0.7.1!jets3t.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar ...
[ivy:resolve] .... (129kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#servlet-api-2.5;6.1.14!servlet-api-2.5.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar ...
[ivy:resolve] .. (11kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.sf.kosmosfs#kfs;0.3!kfs.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/4.5/junit-4.5.jar ...
[ivy:resolve] ..... (194kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] junit#junit;4.5!junit.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar ...
[ivy:resolve] ............. (690kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] hsqldb#hsqldb;1.8.0.10!hsqldb.jar (18ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/oro/oro/2.0.8/oro-2.0.8.jar ...
[ivy:resolve] .. (63kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] oro#oro;2.0.8!oro.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar ...
[ivy:resolve] .................................................................................................................................... (3483kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.eclipse.jdt#core;3.1.1!core.jar (85ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/ant/ant/1.6.5/ant-1.6.5.jar ...
[ivy:resolve] .................. (1009kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] ant#ant;1.6.5!ant.jar (24ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar ...
[ivy:resolve] .. (59kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-logging#commons-logging;1.1.1!commons-logging.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftplet-api/1.0.0/ftplet-api-1.0.0.jar ...
[ivy:resolve] .. (22kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftplet-api;1.0.0!ftplet-api.jar(bundle) (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/mina/mina-core/2.0.0-M5/mina-core-2.0.0-M5.jar ...
[ivy:resolve] ........... (622kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.mina#mina-core;2.0.0-M5!mina-core.jar(bundle) (19ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftpserver-core/1.0.0/ftpserver-core-1.0.0.jar ...
[ivy:resolve] ...... (264kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftpserver-core;1.0.0!ftpserver-core.jar(bundle) (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/ftpserver/ftpserver-deprecated/1.0.0-M2/ftpserver-deprecated-1.0.0-M2.jar ...
[ivy:resolve] .. (31kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2!ftpserver-deprecated.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.5.2/slf4j-api-1.5.2.jar ...
[ivy:resolve] .. (16kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-api;1.5.2!slf4j-api.jar (6ms)
[ivy:resolve] :: resolution report :: resolve 34394ms :: artifacts dl 559ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	junit#junit;3.8.1 by [junit#junit;4.5] in [hadoop0.20.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.0.3 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20.shim]
[ivy:resolve] 	commons-codec#commons-codec;1.2 by [commons-codec#commons-codec;1.3] in [hadoop0.20.shim]
[ivy:resolve] 	commons-httpclient#commons-httpclient;3.1 by [commons-httpclient#commons-httpclient;3.0.1] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M4 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.ftpserver#ftplet-api;1.0.0-M2 by [org.apache.ftpserver#ftplet-api;1.0.0] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.ftpserver#ftpserver-core;1.0.0-M2 by [org.apache.ftpserver#ftpserver-core;1.0.0] in [hadoop0.20.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M2 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20.shim]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|  hadoop0.20.shim |   37  |   30  |   30  |   8   ||   29  |   29  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.20.shim]
[ivy:retrieve] 	29 artifacts copied, 0 already retrieved (14115kB/57ms)
    [javac] Compiling 17 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [echo] Building shims 0.20S

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/common-secure/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.20S/java against hadoop 1.1.2 (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-1.1.2)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.20S.shim]
[ivy:resolve] 	found org.apache.hadoop#hadoop-core;1.1.2 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-core;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-json;1.8 in maven2
[ivy:resolve] 	found org.codehaus.jettison#jettison;1.1 in maven2
[ivy:resolve] 	found stax#stax-api;1.0.1 in maven2
[ivy:resolve] 	found com.sun.xml.bind#jaxb-impl;2.2.3-1 in maven2
[ivy:resolve] 	found javax.xml.bind#jaxb-api;2.2.2 in maven2
[ivy:resolve] 	found javax.xml.stream#stax-api;1.0-2 in maven2
[ivy:resolve] 	found javax.activation#activation;1.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-jaxrs;1.7.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-xc;1.7.1 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-server;1.8 in maven2
[ivy:resolve] 	found asm#asm;3.1 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.1 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.0.1 in maven2
[ivy:resolve] 	found junit#junit;3.8.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.3 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.commons#commons-math;2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found commons-digester#commons-digester;1.8 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils;1.7.0 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils-core;1.8.0 in maven2
[ivy:resolve] 	found commons-net#commons-net;1.4.1 in maven2
[ivy:resolve] 	found oro#oro;2.0.8 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api;2.5-20081211 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.12 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.12 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-api-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api-2.5;6.1.14 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jsp-2.1;6.1.14 in maven2
[ivy:resolve] 	found org.eclipse.jdt#core;3.1.1 in maven2
[ivy:resolve] 	found ant#ant;1.6.5 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.6.1 in maven2
[ivy:resolve] 	found hsqldb#hsqldb;1.8.0.10 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-tools;1.1.2 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-test;1.1.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftplet-api;1.0.0 in maven2
[ivy:resolve] 	found org.apache.mina#mina-core;2.0.0-M5 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.5.2 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-core;1.0.0 in maven2
[ivy:resolve] 	found org.apache.ftpserver#ftpserver-deprecated;1.0.0-M2 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-core/1.1.2/hadoop-core-1.1.2.jar ...
[ivy:resolve] ................................................................................................... (3941kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-core;1.1.2!hadoop-core.jar (79ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-tools/1.1.2/hadoop-tools-1.1.2.jar ...
[ivy:resolve] ...... (299kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-tools;1.1.2!hadoop-tools.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-test/1.1.2/hadoop-test-1.1.2.jar ...
[ivy:resolve] .............................................. (2712kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-test;1.1.2!hadoop-test.jar (52ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar ...
[ivy:resolve] ........ (447kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-core;1.8!jersey-core.jar(bundle) (22ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar ...
[ivy:resolve] .... (144kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-json;1.8!jersey-json.jar(bundle) (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar ...
[ivy:resolve] ............ (678kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey#jersey-server;1.8!jersey-server.jar(bundle) (19ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-io/commons-io/2.1/commons-io-2.1.jar ...
[ivy:resolve] .... (159kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-io#commons-io;2.1!commons-io.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-codec/commons-codec/1.4/commons-codec-1.4.jar ...
[ivy:resolve] .. (56kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-codec#commons-codec;1.4!commons-codec.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-math/2.1/commons-math-2.1.jar ...
[ivy:resolve] .............. (812kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.commons#commons-math;2.1!commons-math.jar (19ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar ...
[ivy:resolve] ...... (291kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-configuration#commons-configuration;1.6!commons-configuration.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar ...
[ivy:resolve] .......... (527kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty;6.1.26!jetty.jar (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar ...
[ivy:resolve] .... (172kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#jetty-util;6.1.26!jetty-util.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar ...
[ivy:resolve] ...... (314kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] net.java.dev.jets3t#jets3t;0.6.1!jets3t.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar ...
[ivy:resolve] ... (66kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jettison#jettison;1.1!jettison.jar(bundle) (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar ...
[ivy:resolve] ............... (869kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.xml.bind#jaxb-impl;2.2.3-1!jaxb-impl.jar (34ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.7.1/jackson-jaxrs-1.7.1.jar ...
[ivy:resolve] .. (17kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-jaxrs;1.7.1!jackson-jaxrs.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar ...
[ivy:resolve] .. (30kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-xc;1.7.1!jackson-xc.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/stax/stax-api/1.0.1/stax-api-1.0.1.jar ...
[ivy:resolve] .. (25kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] stax#stax-api;1.0.1!stax-api.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar ...
[ivy:resolve] ... (102kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.xml.bind#jaxb-api;2.2.2!jaxb-api.jar (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar ...
[ivy:resolve] .. (22kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.xml.stream#stax-api;1.0-2!stax-api.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/activation/activation/1.1/activation-1.1.jar ...
[ivy:resolve] .. (61kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.activation#activation;1.1!activation.jar (12ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/asm/asm/3.1/asm-3.1.jar ...
[ivy:resolve] .. (42kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] asm#asm;3.1!asm.jar (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/3.8.1/junit-3.8.1.jar ...
[ivy:resolve] ... (118kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] junit#junit;3.8.1!junit.jar (20ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar ...
[ivy:resolve] .......... (561kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-collections#commons-collections;3.2.1!commons-collections.jar (39ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-digester/commons-digester/1.8/commons-digester-1.8.jar ...
[ivy:resolve] .... (140kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-digester#commons-digester;1.8!commons-digester.jar (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar ...
[ivy:resolve] ..... (201kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-beanutils#commons-beanutils-core;1.8.0!commons-beanutils-core.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar ...
[ivy:resolve] .... (184kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-beanutils#commons-beanutils;1.7.0!commons-beanutils.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar ...
[ivy:resolve] .... (130kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mortbay.jetty#servlet-api;2.5-20081211!servlet-api.jar (11ms)
[ivy:resolve] :: resolution report :: resolve 31235ms :: artifacts dl 648ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	org.codehaus.jackson#jackson-core-asl;1.7.1 by [org.codehaus.jackson#jackson-core-asl;1.8.8] in [hadoop0.20S.shim]
[ivy:resolve] 	org.codehaus.jackson#jackson-mapper-asl;1.7.1 by [org.codehaus.jackson#jackson-mapper-asl;1.8.8] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.0.3 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-codec#commons-codec;1.2 by [commons-codec#commons-codec;1.4] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-logging#commons-logging;1.1 by [commons-logging#commons-logging;1.1.1] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-codec#commons-codec;1.3 by [commons-codec#commons-codec;1.4] in [hadoop0.20S.shim]
[ivy:resolve] 	commons-httpclient#commons-httpclient;3.1 by [commons-httpclient#commons-httpclient;3.0.1] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M4 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.ftpserver#ftplet-api;1.0.0-M2 by [org.apache.ftpserver#ftplet-api;1.0.0] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.ftpserver#ftpserver-core;1.0.0-M2 by [org.apache.ftpserver#ftpserver-core;1.0.0] in [hadoop0.20S.shim]
[ivy:resolve] 	org.apache.mina#mina-core;2.0.0-M2 by [org.apache.mina#mina-core;2.0.0-M5] in [hadoop0.20S.shim]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	| hadoop0.20S.shim |   62  |   30  |   30  |   11  ||   51  |   28  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.20S.shim]
[ivy:retrieve] 	51 artifacts copied, 0 already retrieved (22876kB/77ms)
    [javac] Compiling 15 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [echo] Building shims 0.23

build-shims:
     [echo] Project: shims
     [echo] Compiling /data/hive-ptest/working/apache-svn-trunk-source/shims/src/common/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/common-secure/java;/data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.23/java against hadoop 2.0.5-alpha (/data/hive-ptest/working/apache-svn-trunk-source/build/hadoopcore/hadoop-2.0.5-alpha)

ivy-init-settings:
     [echo] Project: shims

ivy-resolve-hadoop-shim:
     [echo] Project: shims
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-shims;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [hadoop0.23.shim]
[ivy:resolve] 	found org.apache.hadoop#hadoop-common;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-annotations;2.0.5-alpha in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-math;2.1 in maven2
[ivy:resolve] 	found xmlenc#xmlenc;0.52 in maven2
[ivy:resolve] 	found commons-httpclient#commons-httpclient;3.1 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.1 in maven2
[ivy:resolve] 	found commons-net#commons-net;3.1 in maven2
[ivy:resolve] 	found javax.servlet#servlet-api;2.5 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.26 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-core;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-json;1.8 in maven2
[ivy:resolve] 	found org.codehaus.jettison#jettison;1.1 in maven2
[ivy:resolve] 	found stax#stax-api;1.0.1 in maven2
[ivy:resolve] 	found com.sun.xml.bind#jaxb-impl;2.2.3-1 in maven2
[ivy:resolve] 	found javax.xml.bind#jaxb-api;2.2.2 in maven2
[ivy:resolve] 	found javax.activation#activation;1.1 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-jaxrs;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-xc;1.8.8 in maven2
[ivy:resolve] 	found com.sun.jersey#jersey-server;1.8 in maven2
[ivy:resolve] 	found asm#asm;3.2 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.17 in maven2
[ivy:resolve] 	found net.java.dev.jets3t#jets3t;0.6.1 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.5 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-digester#commons-digester;1.8 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils;1.7.0 in maven2
[ivy:resolve] 	found commons-beanutils#commons-beanutils-core;1.8.0 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.5.3 in maven2
[ivy:resolve] 	found com.thoughtworks.paranamer#paranamer;2.3 in maven2
[ivy:resolve] 	found org.xerial.snappy#snappy-java;1.0.3.2 in maven2
[ivy:resolve] 	found net.sf.kosmosfs#kfs;0.3 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.0a in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-auth;2.0.5-alpha in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found com.jcraft#jsch;0.1.42 in maven2
[ivy:resolve] 	found org.apache.zookeeper#zookeeper;3.4.2 in maven2
[ivy:resolve] 	found tomcat#jasper-compiler;5.5.23 in maven2
[ivy:resolve] 	found tomcat#jasper-runtime;5.5.23 in maven2
[ivy:resolve] 	found commons-el#commons-el;1.0 in maven2
[ivy:resolve] 	found javax.servlet.jsp#jsp-api;2.1 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-core;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-common;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-api;2.0.5-alpha in maven2
[ivy:resolve] 	found com.google.inject.extensions#guice-servlet;3.0 in maven2
[ivy:resolve] 	found com.google.inject#guice;3.0 in maven2
[ivy:resolve] 	found javax.inject#javax.inject;1 in maven2
[ivy:resolve] 	found aopalliance#aopalliance;1.0 in maven2
[ivy:resolve] 	found org.sonatype.sisu.inject#cglib;2.2.1-v20090111 in maven2
[ivy:resolve] 	found io.netty#netty;3.5.11.Final in maven2
[ivy:resolve] 	found com.sun.jersey.jersey-test-framework#jersey-test-framework-grizzly2;1.8 in maven2
[ivy:resolve] 	found com.sun.jersey.contribs#jersey-guice;1.8 in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-archives;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-hdfs;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-common;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-client;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-common;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-tests;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-nodemanager;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-resourcemanager;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-yarn-server-web-proxy;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-app;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.0.5-alpha in maven2
[ivy:resolve] 	found org.apache.hadoop#hadoop-mapreduce-client-hs;2.0.5-alpha in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.0.5-alpha/hadoop-common-2.0.5-alpha.jar ...
[ivy:resolve] ........................................ (2295kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-common;2.0.5-alpha!hadoop-common.jar (72ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.0.5-alpha/hadoop-common-2.0.5-alpha-tests.jar ...
[ivy:resolve] .................... (1151kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-common;2.0.5-alpha!hadoop-common.jar(tests) (26ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-core/2.0.5-alpha/hadoop-mapreduce-client-core-2.0.5-alpha.jar ...
[ivy:resolve] ...................... (1325kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-core;2.0.5-alpha!hadoop-mapreduce-client-core.jar (27ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-archives/2.0.5-alpha/hadoop-archives-2.0.5-alpha.jar ...
[ivy:resolve] .. (20kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-archives;2.0.5-alpha!hadoop-archives.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.0.5-alpha/hadoop-hdfs-2.0.5-alpha.jar ...
[ivy:resolve] ....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................... (4241kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs;2.0.5-alpha!hadoop-hdfs.jar (344ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.0.5-alpha/hadoop-hdfs-2.0.5-alpha-tests.jar ...
[ivy:resolve] ............................. (1631kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs;2.0.5-alpha!hadoop-hdfs.jar(tests) (34ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.0.5-alpha/hadoop-mapreduce-client-jobclient-2.0.5-alpha-tests.jar ...
[ivy:resolve] ....................... (1350kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.0.5-alpha!hadoop-mapreduce-client-jobclient.jar(tests) (29ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.0.5-alpha/hadoop-mapreduce-client-jobclient-2.0.5-alpha.jar ...
[ivy:resolve] .. (32kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.0.5-alpha!hadoop-mapreduce-client-jobclient.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-common/2.0.5-alpha/hadoop-mapreduce-client-common-2.0.5-alpha.jar ...
[ivy:resolve] ........... (579kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-common;2.0.5-alpha!hadoop-mapreduce-client-common.jar (18ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-tests/2.0.5-alpha/hadoop-yarn-server-tests-2.0.5-alpha-tests.jar ...
[ivy:resolve] .. (39kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-tests;2.0.5-alpha!hadoop-yarn-server-tests.jar(tests) (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-app/2.0.5-alpha/hadoop-mapreduce-client-app-2.0.5-alpha.jar ...
[ivy:resolve] ......... (463kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-app;2.0.5-alpha!hadoop-mapreduce-client-app.jar (20ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-hs/2.0.5-alpha/hadoop-mapreduce-client-hs-2.0.5-alpha.jar ...
[ivy:resolve] ... (111kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-hs;2.0.5-alpha!hadoop-mapreduce-client-hs.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-annotations/2.0.5-alpha/hadoop-annotations-2.0.5-alpha.jar ...
[ivy:resolve] .. (16kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-annotations;2.0.5-alpha!hadoop-annotations.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar ...
[ivy:resolve] ...... (297kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-httpclient#commons-httpclient;3.1!commons-httpclient.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-net/commons-net/3.1/commons-net-3.1.jar ...
[ivy:resolve] ...... (266kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-net#commons-net;3.1!commons-net.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar ...
[ivy:resolve] ... (102kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.servlet#servlet-api;2.5!servlet-api.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/log4j/log4j/1.2.17/log4j-1.2.17.jar ...
[ivy:resolve] ......... (478kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] log4j#log4j;1.2.17!log4j.jar(bundle) (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-lang/commons-lang/2.5/commons-lang-2.5.jar ...
[ivy:resolve] ...... (272kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-lang#commons-lang;2.5!commons-lang.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar ...
[ivy:resolve] .. (24kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-api;1.6.1!slf4j-api.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro/1.5.3/avro-1.5.3.jar ...
[ivy:resolve] ...... (257kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro;1.5.3!avro.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.4.0a/protobuf-java-2.4.0a.jar ...
[ivy:resolve] ........ (439kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.protobuf#protobuf-java;2.4.0a!protobuf-java.jar (13ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-auth/2.0.5-alpha/hadoop-auth-2.0.5-alpha.jar ...
[ivy:resolve] .. (46kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-auth;2.0.5-alpha!hadoop-auth.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar ...
[ivy:resolve] .... (181kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.jcraft#jsch;0.1.42!jsch.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.2/zookeeper-3.4.2.jar ...
[ivy:resolve] ............. (746kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.2!zookeeper.jar (18ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar ...
[ivy:resolve] .. (32kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.code.findbugs#jsr305;1.3.9!jsr305.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.8.8/jackson-jaxrs-1.8.8.jar ...
[ivy:resolve] .. (17kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-jaxrs;1.8.8!jackson-jaxrs.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.8.8/jackson-xc-1.8.8.jar ...
[ivy:resolve] .. (31kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.codehaus.jackson#jackson-xc;1.8.8!jackson-xc.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/asm/asm/3.2/asm-3.2.jar ...
[ivy:resolve] .. (42kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] asm#asm;3.2!asm.jar (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar ...
[ivy:resolve] .. (28kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.3!paranamer.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.0.3.2/snappy-java-1.0.3.2.jar ...
[ivy:resolve] ................. (972kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.0.3.2!snappy-java.jar(bundle) (22ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar ...
[ivy:resolve] .. (9kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.slf4j#slf4j-log4j12;1.6.1!slf4j-log4j12.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar ...
[ivy:resolve] ........ (398kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-compiler;5.5.23!jasper-compiler.jar (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar ...
[ivy:resolve] ... (75kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] tomcat#jasper-runtime;5.5.23!jasper-runtime.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar ...
[ivy:resolve] ... (98kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.servlet.jsp#jsp-api;2.1!jsp-api.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-common/2.0.5-alpha/hadoop-yarn-common-2.0.5-alpha.jar ...
[ivy:resolve] .................. (1050kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-common;2.0.5-alpha!hadoop-yarn-common.jar (24ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar ...
[ivy:resolve] .. (63kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.inject.extensions#guice-servlet;3.0!guice-servlet.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/io/netty/netty/3.5.11.Final/netty-3.5.11.Final.jar ...
[ivy:resolve] ................... (1106kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] io.netty#netty;3.5.11.Final!netty.jar(bundle) (24ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-api/2.0.5-alpha/hadoop-yarn-api-2.0.5-alpha.jar ...
[ivy:resolve] .................. (1014kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-api;2.0.5-alpha!hadoop-yarn-api.jar (23ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/inject/guice/3.0/guice-3.0.jar ...
[ivy:resolve] ............. (693kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.inject#guice;3.0!guice.jar (17ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/jersey-test-framework/jersey-test-framework-grizzly2/1.8/jersey-test-framework-grizzly2-1.8.jar ...
[ivy:resolve] .. (12kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey.jersey-test-framework#jersey-test-framework-grizzly2;1.8!jersey-test-framework-grizzly2.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/sun/jersey/contribs/jersey-guice/1.8/jersey-guice-1.8.jar ...
[ivy:resolve] .. (14kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.sun.jersey.contribs#jersey-guice;1.8!jersey-guice.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/inject/javax.inject/1/javax.inject-1.jar ...
[ivy:resolve] .. (2kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.inject#javax.inject;1!javax.inject.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/aopalliance/aopalliance/1.0/aopalliance-1.0.jar ...
[ivy:resolve] .. (4kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] aopalliance#aopalliance;1.0!aopalliance.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/sonatype/sisu/inject/cglib/2.2.1-v20090111/cglib-2.2.1-v20090111.jar ...
[ivy:resolve] ...... (272kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.sonatype.sisu.inject#cglib;2.2.1-v20090111!cglib.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-client/2.0.5-alpha/hadoop-yarn-client-2.0.5-alpha.jar ...
[ivy:resolve] .. (28kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-client;2.0.5-alpha!hadoop-yarn-client.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-common/2.0.5-alpha/hadoop-yarn-server-common-2.0.5-alpha.jar ...
[ivy:resolve] .... (148kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-common;2.0.5-alpha!hadoop-yarn-server-common.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.0.5-alpha/hadoop-yarn-server-nodemanager-2.0.5-alpha.jar ...
[ivy:resolve] ........ (404kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-nodemanager;2.0.5-alpha!hadoop-yarn-server-nodemanager.jar (19ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.0.5-alpha/hadoop-yarn-server-resourcemanager-2.0.5-alpha.jar ...
[ivy:resolve] .......... (517kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-resourcemanager;2.0.5-alpha!hadoop-yarn-server-resourcemanager.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.0.5-alpha/hadoop-yarn-server-web-proxy-2.0.5-alpha.jar ...
[ivy:resolve] .. (24kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-web-proxy;2.0.5-alpha!hadoop-yarn-server-web-proxy.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.0.5-alpha/hadoop-mapreduce-client-shuffle-2.0.5-alpha.jar ...
[ivy:resolve] .. (20kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.0.5-alpha!hadoop-mapreduce-client-shuffle.jar (5ms)
[ivy:resolve] :: resolution report :: resolve 65938ms :: artifacts dl 1086ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|  hadoop0.23.shim |   74  |   47  |   47  |   0   ||   77  |   50  |
	---------------------------------------------------------------------

ivy-retrieve-hadoop-shim:
     [echo] Project: shims
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-shims
[ivy:retrieve] 	confs: [hadoop0.23.shim]
[ivy:retrieve] 	77 artifacts copied, 0 already retrieved (31997kB/111ms)
    [javac] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/src/0.23/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.

jar:
     [echo] Project: shims
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-shims;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 21:05:45 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/shims/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-shims
[ivy:publish] 	published hive-shims to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.12.0-SNAPSHOT/jars/hive-shims.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: common

check-ivy:
     [echo] Project: common

ivy-resolve:
     [echo] Project: common
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-common;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-shims/0.12.0-SNAPSHOT/jars/hive-shims.jar ...
[ivy:resolve] .... (140kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-shims;0.12.0-SNAPSHOT!hive-shims.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar ...
[ivy:resolve] ..... (235kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.commons#commons-compress;1.4.1!commons-compress.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/tukaani/xz/1.0/xz-1.0.jar ...
[ivy:resolve] ... (92kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.tukaani#xz;1.0!xz.jar (8ms)
[ivy:resolve] :: resolution report :: resolve 2388ms :: artifacts dl 30ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   6   |   3   |   3   |   0   ||   6   |   3   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-common-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-common-default.html

make-pom:
     [echo] Project: common
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/common/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: common

init:
     [echo] Project: common

setup:
     [echo] Project: common

ivy-retrieve:
     [echo] Project: common
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-common
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	4 artifacts copied, 2 already retrieved (508kB/5ms)

compile:
     [echo] Project: common
    [javac] Compiling 25 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/common/src/java/org/apache/hadoop/hive/common/ObjectPair.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes

jar:
     [echo] Project: common
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/common/hive-common-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-common;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 21:05:50 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/common/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-common
[ivy:publish] 	published hive-common to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.12.0-SNAPSHOT/jars/hive-common.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: serde

check-ivy:
     [echo] Project: serde

ivy-resolve:
     [echo] Project: serde
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-serde;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-common/0.12.0-SNAPSHOT/jars/hive-common.jar ...
[ivy:resolve] ... (95kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-common;0.12.0-SNAPSHOT!hive-common.jar (3ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar ...
[ivy:resolve] ....................... (1315kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.mockito#mockito-all;1.8.2!mockito-all.jar (27ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar ...
[ivy:resolve] ...... (268kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.thrift#libfb303;0.9.0!libfb303.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro/1.7.1/avro-1.7.1.jar ...
[ivy:resolve] ...... (290kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro;1.7.1!avro.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar ...
[ivy:resolve] .... (164kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.avro#avro-mapred;1.7.1!avro-mapred.jar (8ms)
[ivy:resolve] :: resolution report :: resolve 6604ms :: artifacts dl 75ms
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   14  |   5   |   5   |   0   ||   14  |   5   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-serde-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-serde-default.html

make-pom:
     [echo] Project: serde
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: serde
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources does not exist.

init:
     [echo] Project: serde

ivy-retrieve:
     [echo] Project: serde
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-serde
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	8 artifacts copied, 6 already retrieved (2227kB/24ms)

dynamic-serde:

compile:
     [echo] Project: serde
    [javac] Compiling 325 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes/org/apache/hadoop/hive/serde2/typeinfo/package-info.class

jar:
     [echo] Project: serde
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/serde/hive-serde-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-serde;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 21:06:09 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/serde/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-serde
[ivy:publish] 	published hive-serde to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.12.0-SNAPSHOT/jars/hive-serde.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: metastore

check-ivy:
     [echo] Project: metastore

ivy-resolve:
     [echo] Project: metastore
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-metastore;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-serde/0.12.0-SNAPSHOT/jars/hive-serde.jar ...
[ivy:resolve] ............ (662kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-serde;0.12.0-SNAPSHOT!hive-serde.jar (20ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/antlr/3.4/antlr-3.4.jar ...
[ivy:resolve] ................... (1086kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.antlr#antlr;3.4!antlr.jar (24ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar ...
[ivy:resolve] .... (160kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.antlr#antlr-runtime;3.4!antlr-runtime.jar (15ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/antlr/ST4/4.0.4/ST4-4.0.4.jar ...
[ivy:resolve] ..... (231kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.antlr#ST4;4.0.4!ST4.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar ...
[ivy:resolve] ... (112kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.jolbox#bonecp;0.7.1.RELEASE!bonecp.jar(bundle) (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar ...
[ivy:resolve] ... (93kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] commons-pool#commons-pool;1.5.4!commons-pool.jar (7ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar ...
[ivy:resolve] ....... (329kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.datanucleus#datanucleus-api-jdo;3.2.1!datanucleus-api-jdo.jar (14ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar ...
[ivy:resolve] ............................. (1759kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.datanucleus#datanucleus-core;3.2.2!datanucleus-core.jar (34ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar ...
[ivy:resolve] .............................. (1728kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.datanucleus#datanucleus-rdbms;3.2.1!datanucleus-rdbms.jar (35ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar ...
[ivy:resolve] ..... (196kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javax.jdo#jdo-api;3.0.1!jdo-api.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar ...
[ivy:resolve] ......................................... (2389kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.derby#derby;10.4.2.0!derby.jar (46ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/guava/guava/r08/guava-r08.jar ...
[ivy:resolve] ................... (1088kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.guava#guava;r08!guava.jar (24ms)
[ivy:resolve] :: resolution report :: resolve 10275ms :: artifacts dl 272ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   27  |   12  |   12  |   1   ||   26  |   12  |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-metastore-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-metastore-default.html

make-pom:
     [echo] Project: metastore
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: metastore
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources does not exist.

init:
     [echo] Project: metastore

metastore-init:
     [echo] Project: metastore
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/gen/antlr/gen-java/org/apache/hadoop/hive/metastore/parser

ivy-retrieve:
     [echo] Project: metastore
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-metastore
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	12 artifacts copied, 14 already retrieved (9837kB/31ms)

build-grammar:
     [echo] Project: metastore
     [echo] Building Grammar /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g  ....

model-compile:
     [echo] Project: metastore
    [javac] Compiling 24 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes

core-compile:
     [echo] Project: metastore
    [javac] Compiling 104 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes/org/apache/hadoop/hive/metastore/parser/package-info.class

model-enhance:
     [echo] Project: metastore
[datanucleusenhancer] log4j:WARN No appenders could be found for logger (DataNucleus.General).
[datanucleusenhancer] log4j:WARN Please initialize the log4j system properly.
[datanucleusenhancer] log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
[datanucleusenhancer] DataNucleus Enhancer (version 3.2.2) for API &quot;JDO&quot; using JRE &quot;1.6&quot;
[datanucleusenhancer] DataNucleus Enhancer : Classpath
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/common/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/serde/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/shims/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/anttasks/hive-anttasks-0.12.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/common/hive-common-0.12.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/serde/hive-serde-0.12.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.12.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/activation-1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ant-1.6.5.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/asm-3.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-beanutils-1.7.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-beanutils-core-1.8.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-cli-1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-codec-1.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-collections-3.2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-configuration-1.6.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-digester-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-el-1.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-httpclient-3.0.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-io-2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-lang-2.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-logging-1.1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-math-2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/commons-net-1.4.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/core-3.1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftplet-api-1.0.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftpserver-core-1.0.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/ftpserver-deprecated-1.0.0-M2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-core-1.1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-test-1.1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hadoop-tools-1.1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/hsqldb-1.8.0.10.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-core-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-jaxrs-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-mapper-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jackson-xc-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jasper-compiler-5.5.12.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jasper-runtime-5.5.12.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jaxb-api-2.2.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jaxb-impl-2.2.3-1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-core-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-json-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jersey-server-1.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jets3t-0.6.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jettison-1.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jetty-6.1.26.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jetty-util-6.1.26.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jsp-2.1-6.1.14.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/jsp-api-2.1-6.1.14.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/junit-3.8.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/mina-core-2.0.0-M5.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/oro-2.0.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/servlet-api-2.5-20081211.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/servlet-api-2.5-6.1.14.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/slf4j-api-1.5.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/stax-api-1.0-2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/stax-api-1.0.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/hadoop0.20S.shim/xmlenc-0.52.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/ST4-4.0.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/antlr-3.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/antlr-runtime-3.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-mapred-1.7.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/bonecp-0.7.1.RELEASE.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-cli-1.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-codec-1.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-compress-1.4.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-io-2.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-lang-2.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-logging-1.0.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-logging-api-1.0.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-pool-1.5.4.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-api-jdo-3.2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-core-3.2.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/datanucleus-rdbms-3.2.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/derby-10.4.2.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/guava-11.0.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/guava-r08.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-common-0.12.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-serde-0.12.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/hive-shims-0.12.0-SNAPSHOT.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-core-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-mapper-asl-1.8.8.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jdo-api-3.0.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libfb303-0.9.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libthrift-0.9.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/log4j-1.2.16.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/mockito-all-1.8.2.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/slf4j-api-1.6.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/slf4j-log4j12-1.6.1.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/velocity-1.5.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/xz-1.0.jar
[datanucleusenhancer] &amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/zookeeper-3.4.3.jar
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDatabase
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFieldSchema
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MType
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTable
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MOrder
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStringList
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartition
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MIndex
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRole
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRoleMap
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MMasterKey
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDelegationToken
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics
[datanucleusenhancer] ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics
[datanucleusenhancer] DataNucleus Enhancer completed with success for 24 classes. Timings : input=679 ms, enhance=1133 ms, total=1812 ms. Consult the log for full details

compile:
     [echo] Project: metastore

jar:
     [echo] Project: metastore
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/hive-metastore-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-metastore;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 21:06:46 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-metastore
[ivy:publish] 	published hive-metastore to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.12.0-SNAPSHOT/jars/hive-metastore.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: ql

check-ivy:
     [echo] Project: ql

ivy-resolve:
     [echo] Project: ql
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-exec;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found com.esotericsoftware.kryo#kryo;2.22-SNAPSHOT in sonatype-snapshot
[ivy:resolve] 	found com.esotericsoftware.reflectasm#reflectasm;1.07 in maven2
[ivy:resolve] 	found org.ow2.asm#asm;4.0 in maven2
[ivy:resolve] 	found com.esotericsoftware.minlog#minlog;1.2 in maven2
[ivy:resolve] 	found org.objenesis#objenesis;1.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-metastore/0.12.0-SNAPSHOT/jars/hive-metastore.jar ...
[ivy:resolve] ..................................................... (3267kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-metastore;0.12.0-SNAPSHOT!hive-metastore.jar (57ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.4.1/protobuf-java-2.4.1.jar ...
[ivy:resolve] ........ (439kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.protobuf#protobuf-java;2.4.1!protobuf-java.jar (22ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/iq80/snappy/snappy/0.2/snappy-0.2.jar ...
[ivy:resolve] .. (47kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.iq80.snappy#snappy;0.2!snappy.jar (11ms)
[ivy:resolve] downloading https://oss.sonatype.org/content/repositories/snapshots/com/esotericsoftware/kryo/kryo/2.22-SNAPSHOT/kryo-2.22-20130829.144349-38.jar ...
[ivy:resolve] ............................................................................................ (414kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.esotericsoftware.kryo#kryo;2.22-SNAPSHOT!kryo.jar(bundle) (663ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/json/json/20090211/json-20090211.jar ...
[ivy:resolve] .. (44kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.json#json;20090211!json.jar (8ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar ...
[ivy:resolve] .. (16kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.googlecode.javaewah#JavaEWAH;0.3.2!JavaEWAH.jar (5ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/javolution/javolution/5.5.1/javolution-5.5.1.jar ...
[ivy:resolve] ........ (385kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] javolution#javolution;5.5.1!javolution.jar(bundle) (11ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/jline/jline/0.9.94/jline-0.9.94.jar ...
[ivy:resolve] ... (85kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] jline#jline;0.9.94!jline.jar (24ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar ...
[ivy:resolve] .... (64kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.esotericsoftware.reflectasm#reflectasm;1.07!reflectasm.jar (47ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar ...
[ivy:resolve] .. (4kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.esotericsoftware.minlog#minlog;1.2!minlog.jar (52ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/objenesis/objenesis/1.2/objenesis-1.2.jar ...
[ivy:resolve] .... (35kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.objenesis#objenesis;1.2!objenesis.jar (20ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/ow2/asm/asm/4.0/asm-4.0.jar ...
[ivy:resolve] .... (44kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.ow2.asm#asm;4.0!asm.jar (21ms)
[ivy:resolve] :: resolution report :: resolve 17577ms :: artifacts dl 1011ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   43  |   12  |   12  |   2   ||   41  |   12  |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-exec-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-exec-default.html

make-pom:
     [echo] Project: ql
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: ql

init:
     [echo] Project: ql

ql-init:
     [echo] Project: ql
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/gen/antlr/gen-java/org/apache/hadoop/hive/ql/parse

ivy-retrieve:
     [echo] Project: ql
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-exec
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	15 artifacts copied, 26 already retrieved (5736kB/29ms)

build-grammar:
     [echo] Project: ql
     [echo] Building Grammar /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g  ....
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:866:5: 
     [java] Decision can match input such as &quot;Identifier KW_RENAME KW_TO&quot; using multiple alternatives: 1, 10
     [java] 
     [java] As a result, alternative(s) 10 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1167:5: 
     [java] Decision can match input such as &quot;KW_TEXTFILE&quot; using multiple alternatives: 2, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1167:5: 
     [java] Decision can match input such as &quot;KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1167:5: 
     [java] Decision can match input such as &quot;KW_ORCFILE&quot; using multiple alternatives: 4, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1167:5: 
     [java] Decision can match input such as &quot;KW_RCFILE&quot; using multiple alternatives: 3, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1180:23: 
     [java] Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1180:23: 
     [java] Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1180:23: 
     [java] Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:23: 
     [java] Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:23: 
     [java] Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:23: 
     [java] Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_PRETTY KW_PARTITION&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_PRETTY {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_PRETTY Identifier&quot; using multiple alternatives: 3, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_FORMATTED {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_FORMATTED KW_PARTITION&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:29: 
     [java] Decision can match input such as &quot;KW_FORMATTED Identifier&quot; using multiple alternatives: 1, 4
     [java] 
     [java] As a result, alternative(s) 4 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1476:116: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_DIRECTORIES&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_INPUTFORMAT&quot; using multiple alternatives: 5, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_ORCFILE&quot; using multiple alternatives: 4, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_RCFILE&quot; using multiple alternatives: 3, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: 
     [java] Decision can match input such as &quot;KW_STORED KW_AS KW_TEXTFILE&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): SelectClauseParser.g:149:5: 
     [java] Decision can match input such as &quot;KW_NULL DOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): SelectClauseParser.g:149:5: 
     [java] Decision can match input such as &quot;KW_NULL DOT Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:127:2: 
     [java] Decision can match input such as &quot;KW_LATERAL KW_VIEW KW_OUTER&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:25: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral RPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:25: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral EQUAL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:25: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral COMMA&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:179:68: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): FromClauseParser.g:237:16: 
     [java] Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL GREATERTHAN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL GREATERTHANOREQUALTO&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LESSTHAN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LESSTHANOREQUALTO&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL DOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN CharSetName&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL NOTEQUAL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL EQUAL_NS&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL {DIV..DIVIDE, MOD, STAR}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL BITWISEXOR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL EQUAL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT Identifier&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL RPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_AND&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CAST LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL BITWISEOR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_BETWEEN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_CASE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_NOT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_IN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_NULL&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_IF&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL AMPERSAND&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LSQUARE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_MAP&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL {KW_LIKE, KW_REGEXP, KW_RLIKE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT Number&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL {MINUS, PLUS}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN CharSetName CharSetLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE BigintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_DATE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_TRUE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_WHEN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_FALSE&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_IS&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN StringLiteral StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_DATE StringLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NULL KW_OR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT TinyintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT SmallintLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_CASE KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN LPAREN KW_CAST&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:68:4: 
     [java] Decision can match input such as &quot;LPAREN KW_NOT DecimalLiteral&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:108:5: 
     [java] Decision can match input such as &quot;KW_ORDER KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:121:5: 
     [java] Decision can match input such as &quot;KW_CLUSTER KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:133:5: 
     [java] Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:144:5: 
     [java] Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:155:5: 
     [java] Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:172:7: 
     [java] Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2
     [java] 
     [java] As a result, alternative(s) 2 were disabled for that input
     [java] warning(200): IdentifiersParser.g:185:5: 
     [java] Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): IdentifiersParser.g:185:5: 
     [java] Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): IdentifiersParser.g:185:5: 
     [java] Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6
     [java] 
     [java] As a result, alternative(s) 6 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 8
     [java] 
     [java] As a result, alternative(s) 8 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_DATE StringLiteral&quot; using multiple alternatives: 2, 3
     [java] 
     [java] As a result, alternative(s) 3 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 3, 8
     [java] 
     [java] As a result, alternative(s) 8 were disabled for that input
     [java] warning(200): IdentifiersParser.g:267:5: 
     [java] Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 3, 8
     [java] 
     [java] As a result, alternative(s) 8 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 6, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:390:5: 
     [java] Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 7
     [java] 
     [java] As a result, alternative(s) 7 were disabled for that input
     [java] warning(200): IdentifiersParser.g:514:5: 
     [java] Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3
     [java] 
     [java] As a result, alternative(s) 3 were disabled for that input

compile:
     [echo] Project: ql
    [javac] Compiling 918 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/exec/package-info.class
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/io/orc/package-info.class
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/udf/generic/package-info.class
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/exec/errors/package-info.class
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes/org/apache/hadoop/hive/ql/lockmgr/package-info.class
     [copy] Copying 1 file to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/classes

jar:
     [echo] Project: ql
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/libthrift-0.9.0.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/thrift/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/commons-lang-2.4.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/commons-lang/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/json-20090211.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/json/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/JavaEWAH-0.3.2.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/javaewah/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-1.7.1.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/avro/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/avro-mapred-1.7.1.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/avro-mapred/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/javolution-5.5.1.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/javolution/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/kryo-2.22-SNAPSHOT.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/kryo/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/protobuf-java-2.4.1.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/protobuf-java/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/guava-11.0.2.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/guava/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/snappy-0.2.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/snappy/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-core-asl-1.8.8.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/jackson-core-asl/classes
    [unzip] Expanding: /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/lib/default/jackson-mapper-asl-1.8.8.jar into /data/hive-ptest/working/apache-svn-trunk-source/build/jackson-mapper-asl/classes
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/ql/hive-exec-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-exec;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 21:07:52 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/ql/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-exec
[ivy:publish] 	published hive-exec to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-exec/0.12.0-SNAPSHOT/jars/hive-exec.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-exec/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: contrib

check-ivy:
     [echo] Project: contrib

ivy-resolve:
     [echo] Project: contrib
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-contrib;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-exec;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found com.esotericsoftware.kryo#kryo;2.22-SNAPSHOT in sonatype-snapshot
[ivy:resolve] 	found com.esotericsoftware.reflectasm#reflectasm;1.07 in maven2
[ivy:resolve] 	found org.ow2.asm#asm;4.0 in maven2
[ivy:resolve] 	found com.esotericsoftware.minlog#minlog;1.2 in maven2
[ivy:resolve] 	found org.objenesis#objenesis;1.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-exec/0.12.0-SNAPSHOT/jars/hive-exec.jar ...
[ivy:resolve] ................................................................................................................................................ (9150kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-exec;0.12.0-SNAPSHOT!hive-exec.jar (126ms)
[ivy:resolve] :: resolution report :: resolve 8549ms :: artifacts dl 150ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   44  |   2   |   1   |   2   ||   42  |   1   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-contrib-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-contrib-default.html

make-pom:
     [echo] Project: contrib
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: contrib
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources does not exist.

init:
     [echo] Project: contrib

setup:
     [echo] Project: contrib

ivy-retrieve:
     [echo] Project: contrib
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-contrib
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	1 artifacts copied, 41 already retrieved (9150kB/74ms)

compile:
     [echo] Project: contrib
    [javac] Compiling 39 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/java/org/apache/hadoop/hive/contrib/udf/example/UDFExampleStructPrint.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/java/conf does not exist.

jar:
     [echo] Project: contrib
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/hive-contrib-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-contrib;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 21:08:02 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-contrib
[ivy:publish] 	published hive-contrib to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-contrib/0.12.0-SNAPSHOT/jars/hive-contrib.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-contrib/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: service

check-ivy:
     [echo] Project: service

ivy-resolve:
     [echo] Project: service
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-service;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-exec;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found com.esotericsoftware.kryo#kryo;2.22-SNAPSHOT in sonatype-snapshot
[ivy:resolve] 	found com.esotericsoftware.reflectasm#reflectasm;1.07 in maven2
[ivy:resolve] 	found org.ow2.asm#asm;4.0 in maven2
[ivy:resolve] 	found com.esotericsoftware.minlog#minlog;1.2 in maven2
[ivy:resolve] 	found org.objenesis#objenesis;1.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] :: resolution report :: resolve 8669ms :: artifacts dl 22ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   44  |   1   |   0   |   2   ||   42  |   0   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-service-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-service-default.html

make-pom:
     [echo] Project: service
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/service/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: service
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources does not exist.

init:
     [echo] Project: service

ivy-retrieve:
     [echo] Project: service
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-service
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	0 artifacts copied, 42 already retrieved (0kB/27ms)

compile:
     [echo] Project: service
    [javac] Compiling 151 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/service/classes
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.

jar:
     [echo] Project: service
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/service/hive-service-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-service;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 21:08:14 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/service/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-service
[ivy:publish] 	published hive-service to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-service/0.12.0-SNAPSHOT/jars/hive-service.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-service/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: cli

check-ivy:
     [echo] Project: cli

ivy-resolve:
     [echo] Project: cli
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-cli;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-service;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-exec;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found com.esotericsoftware.kryo#kryo;2.22-SNAPSHOT in sonatype-snapshot
[ivy:resolve] 	found com.esotericsoftware.reflectasm#reflectasm;1.07 in maven2
[ivy:resolve] 	found org.ow2.asm#asm;4.0 in maven2
[ivy:resolve] 	found com.esotericsoftware.minlog#minlog;1.2 in maven2
[ivy:resolve] 	found org.objenesis#objenesis;1.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-service/0.12.0-SNAPSHOT/jars/hive-service.jar ...
[ivy:resolve] ........................ (1468kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-service;0.12.0-SNAPSHOT!hive-service.jar (21ms)
[ivy:resolve] :: resolution report :: resolve 8457ms :: artifacts dl 42ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   45  |   2   |   1   |   2   ||   43  |   1   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-cli-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-cli-default.html

make-pom:
     [echo] Project: cli
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/cli/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: cli
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/resources does not exist.

init:
     [echo] Project: cli

setup:
     [echo] Project: cli

ivy-retrieve:
     [echo] Project: cli
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-cli
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	1 artifacts copied, 42 already retrieved (1468kB/42ms)

compile:
     [echo] Project: cli
    [javac] Compiling 4 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/cli/classes
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:71: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac] import sun.misc.Signal;
    [javac]                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:72: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac] import sun.misc.SignalHandler;
    [javac]                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:362: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac]     SignalHandler oldSignal = null;
    [javac]     ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:363: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]     Signal interupSignal = null;
    [javac]     ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:368: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]       interupSignal = new Signal(&quot;INT&quot;);
    [javac]                           ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:369: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac]       oldSignal = Signal.handle(interupSignal, new SignalHandler() {
    [javac]                                                    ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:369: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac]       oldSignal = Signal.handle(interupSignal, new SignalHandler() {
    [javac]                                                    ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:374: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]         public void handle(Signal signal) {
    [javac]                            ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:369: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]       oldSignal = Signal.handle(interupSignal, new SignalHandler() {
    [javac]                   ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:430: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]         Signal.handle(interupSignal, oldSignal);
    [javac]         ^
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/RCFileCat.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java uses unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] 10 warnings

jar:
     [echo] Project: cli
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/cli/hive-cli-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-cli;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 21:08:23 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/cli/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-cli
[ivy:publish] 	published hive-cli to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-cli/0.12.0-SNAPSHOT/jars/hive-cli.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-cli/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: jdbc

check-ivy:
     [echo] Project: jdbc

ivy-resolve:
     [echo] Project: jdbc
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-jdbc;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-cli;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-service;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-exec;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found com.esotericsoftware.kryo#kryo;2.22-SNAPSHOT in sonatype-snapshot
[ivy:resolve] 	found com.esotericsoftware.reflectasm#reflectasm;1.07 in maven2
[ivy:resolve] 	found org.ow2.asm#asm;4.0 in maven2
[ivy:resolve] 	found com.esotericsoftware.minlog#minlog;1.2 in maven2
[ivy:resolve] 	found org.objenesis#objenesis;1.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] downloading /data/hive-ptest/working/ivy/local/org.apache.hive/hive-cli/0.12.0-SNAPSHOT/jars/hive-cli.jar ...
[ivy:resolve] .. (33kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hive#hive-cli;0.12.0-SNAPSHOT!hive-cli.jar (3ms)
[ivy:resolve] :: resolution report :: resolve 8390ms :: artifacts dl 24ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   46  |   2   |   1   |   2   ||   44  |   1   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-jdbc-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-jdbc-default.html

make-pom:
     [echo] Project: jdbc
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: jdbc
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/test/resources does not exist.

init:
     [echo] Project: jdbc

ivy-retrieve:
     [echo] Project: jdbc
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-jdbc
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	1 artifacts copied, 43 already retrieved (33kB/13ms)

compile:
     [echo] Project: jdbc
    [javac] Compiling 28 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.

jar:
     [echo] Project: jdbc
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/hive-jdbc-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-jdbc;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 21:08:33 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-jdbc
[ivy:publish] 	published hive-jdbc to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-jdbc/0.12.0-SNAPSHOT/jars/hive-jdbc.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-jdbc/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: beeline

check-ivy:
     [echo] Project: beeline

ivy-resolve:
     [echo] Project: beeline
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-beeline;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-service;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-exec;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found com.esotericsoftware.kryo#kryo;2.22-SNAPSHOT in sonatype-snapshot
[ivy:resolve] 	found com.esotericsoftware.reflectasm#reflectasm;1.07 in maven2
[ivy:resolve] 	found org.ow2.asm#asm;4.0 in maven2
[ivy:resolve] 	found com.esotericsoftware.minlog#minlog;1.2 in maven2
[ivy:resolve] 	found org.objenesis#objenesis;1.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] 	found commons-io#commons-io;2.4 in maven2
[ivy:resolve] 	found commons-logging#commons-logging;1.0.4 in maven2
[ivy:resolve] 	found commons-logging#commons-logging-api;1.0.4 in maven2
[ivy:resolve] 	found org.apache.thrift#libthrift;0.9.0 in maven2
[ivy:resolve] :: resolution report :: resolve 9212ms :: artifacts dl 21ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   49  |   1   |   0   |   2   ||   47  |   0   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-beeline-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-beeline-default.html

make-pom:
     [echo] Project: beeline
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: beeline
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/test/resources does not exist.

init:
     [echo] Project: beeline

setup:
     [echo] Project: beeline

ivy-retrieve:
     [echo] Project: beeline
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-beeline
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	0 artifacts copied, 47 already retrieved (0kB/14ms)

compile:
     [echo] Project: beeline
    [javac] Compiling 29 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:28: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac] import sun.misc.Signal;
    [javac]                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:29: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac] import sun.misc.SignalHandler;
    [javac]                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:31: warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
    [javac] public class SunSignalHandler implements BeeLineSignalHandler, SignalHandler {
    [javac]                                                                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:44: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]   public void handle (Signal signal) {
    [javac]                       ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:37: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]     Signal.handle (new Signal (&quot;INT&quot;), this);
    [javac]                        ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:37: warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
    [javac]     Signal.handle (new Signal (&quot;INT&quot;), this);
    [javac]     ^
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] 6 warnings
     [copy] Copying 2 files to /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/classes

jar:
     [echo] Project: beeline
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/hive-beeline-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-beeline;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 21:08:43 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-beeline
[ivy:publish] 	published hive-beeline to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-beeline/0.12.0-SNAPSHOT/jars/hive-beeline.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-beeline/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: hwi

check-ivy:
     [echo] Project: hwi

ivy-resolve:
     [echo] Project: hwi
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-hwi;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-cli;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-service;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-exec;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found com.esotericsoftware.kryo#kryo;2.22-SNAPSHOT in sonatype-snapshot
[ivy:resolve] 	found com.esotericsoftware.reflectasm#reflectasm;1.07 in maven2
[ivy:resolve] 	found org.ow2.asm#asm;4.0 in maven2
[ivy:resolve] 	found com.esotericsoftware.minlog#minlog;1.2 in maven2
[ivy:resolve] 	found org.objenesis#objenesis;1.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#jetty-util;6.1.26 in maven2
[ivy:resolve] 	found org.mortbay.jetty#servlet-api;2.5-20081211 in maven2
[ivy:resolve] :: resolution report :: resolve 8948ms :: artifacts dl 21ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   49  |   1   |   0   |   2   ||   47  |   0   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-hwi-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-hwi-default.html

make-pom:
     [echo] Project: hwi
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: hwi
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources does not exist.

init:
     [echo] Project: hwi

setup:
     [echo] Project: hwi

ivy-retrieve:
     [echo] Project: hwi
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-hwi
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	3 artifacts copied, 44 already retrieved (831kB/33ms)

war:
     [echo] Project: hwi
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/hive-hwi-0.12.0-SNAPSHOT.war

compile:
     [echo] Project: hwi
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hwi/build.xml:67: warning: &apos;includeantruntime&apos; was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds
    [javac] Compiling 6 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/classes

jar:
     [echo] Project: hwi
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/hive-hwi-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-hwi;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 21:08:52 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-hwi
[ivy:publish] 	published hive-hwi to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-hwi/0.12.0-SNAPSHOT/jars/hive-hwi.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-hwi/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: hbase-handler

check-ivy:
     [echo] Project: hbase-handler

ivy-resolve:
     [echo] Project: hbase-handler
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-hbase-handler;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found org.apache.hive#hive-exec;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-metastore;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-serde;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-common;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found org.apache.hive#hive-shims;0.12.0-SNAPSHOT in local
[ivy:resolve] 	found commons-cli#commons-cli;1.2 in maven2
[ivy:resolve] 	found org.apache.commons#commons-compress;1.4.1 in maven2
[ivy:resolve] 	found org.tukaani#xz;1.0 in maven2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in maven2
[ivy:resolve] 	found log4j#log4j;1.2.16 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-api;1.6.1 in maven2
[ivy:resolve] 	found org.slf4j#slf4j-log4j12;1.6.1 in maven2
[ivy:resolve] 	found org.mockito#mockito-all;1.8.2 in maven2
[ivy:resolve] 	found org.apache.thrift#libfb303;0.9.0 in maven2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in maven2
[ivy:resolve] 	found org.apache.avro#avro;1.7.1 in maven2
[ivy:resolve] 	found org.apache.avro#avro-mapred;1.7.1 in maven2
[ivy:resolve] 	found org.antlr#antlr;3.4 in maven2
[ivy:resolve] 	found org.antlr#antlr-runtime;3.4 in maven2
[ivy:resolve] 	found org.antlr#ST4;4.0.4 in maven2
[ivy:resolve] 	found com.jolbox#bonecp;0.7.1.RELEASE in maven2
[ivy:resolve] 	found com.google.guava#guava;r08 in maven2
[ivy:resolve] 	found commons-pool#commons-pool;1.5.4 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-api-jdo;3.2.1 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-core;3.2.2 in maven2
[ivy:resolve] 	found org.datanucleus#datanucleus-rdbms;3.2.1 in maven2
[ivy:resolve] 	found javax.jdo#jdo-api;3.0.1 in maven2
[ivy:resolve] 	found org.apache.derby#derby;10.4.2.0 in maven2
[ivy:resolve] 	found com.google.protobuf#protobuf-java;2.4.1 in maven2
[ivy:resolve] 	found org.iq80.snappy#snappy;0.2 in maven2
[ivy:resolve] 	found com.esotericsoftware.kryo#kryo;2.22-SNAPSHOT in sonatype-snapshot
[ivy:resolve] 	found com.esotericsoftware.reflectasm#reflectasm;1.07 in maven2
[ivy:resolve] 	found org.ow2.asm#asm;4.0 in maven2
[ivy:resolve] 	found com.esotericsoftware.minlog#minlog;1.2 in maven2
[ivy:resolve] 	found org.objenesis#objenesis;1.2 in maven2
[ivy:resolve] 	found org.json#json;20090211 in maven2
[ivy:resolve] 	found commons-collections#commons-collections;3.2.1 in maven2
[ivy:resolve] 	found commons-configuration#commons-configuration;1.6 in maven2
[ivy:resolve] 	found com.googlecode.javaewah#JavaEWAH;0.3.2 in maven2
[ivy:resolve] 	found javolution#javolution;5.5.1 in maven2
[ivy:resolve] 	found jline#jline;0.9.94 in maven2
[ivy:resolve] 	found com.google.guava#guava;11.0.2 in maven2
[ivy:resolve] 	found com.google.code.findbugs#jsr305;1.3.9 in maven2
[ivy:resolve] 	found org.apache.hbase#hbase;0.94.6.1 in maven2
[ivy:resolve] 	found com.github.stephenc.high-scale-lib#high-scale-lib;1.1.1 in maven2
[ivy:resolve] 	found com.yammer.metrics#metrics-core;2.1.2 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-jaxrs;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-core-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-mapper-asl;1.8.8 in maven2
[ivy:resolve] 	found org.codehaus.jackson#jackson-xc;1.8.8 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hbase/hbase/0.94.6.1/hbase-0.94.6.1-tests.jar ...
[ivy:resolve] ......................................... (2360kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hbase#hbase;0.94.6.1!hbase.jar(test-jar) (82ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/apache/hbase/hbase/0.94.6.1/hbase-0.94.6.1.jar ...
[ivy:resolve] ............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. (4952kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.apache.hbase#hbase;0.94.6.1!hbase.jar (544ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/github/stephenc/high-scale-lib/high-scale-lib/1.1.1/high-scale-lib-1.1.1.jar ...
[ivy:resolve] ... (93kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.github.stephenc.high-scale-lib#high-scale-lib;1.1.1!high-scale-lib.jar (10ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/yammer/metrics/metrics-core/2.1.2/metrics-core-2.1.2.jar ...
[ivy:resolve] ... (80kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.yammer.metrics#metrics-core;2.1.2!metrics-core.jar (12ms)
[ivy:resolve] :: resolution report :: resolve 11783ms :: artifacts dl 707ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	com.google.guava#guava;r08 by [com.google.guava#guava;11.0.2] in [default]
[ivy:resolve] 	org.slf4j#slf4j-api;1.5.10 by [org.slf4j#slf4j-api;1.6.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   51  |   4   |   3   |   2   ||   50  |   4   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-hbase-handler-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-hbase-handler-default.html

make-pom:
     [echo] Project: hbase-handler
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: hbase-handler
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources does not exist.

init:
     [echo] Project: hbase-handler

setup:
     [echo] Project: hbase-handler

ivy-retrieve:
     [echo] Project: hbase-handler
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-hbase-handler
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	6 artifacts copied, 44 already retrieved (7536kB/56ms)

compile:
     [echo] Project: hbase-handler
    [javac] Compiling 13 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Creating empty /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/classes/org/apache/hadoop/hive/hbase/package-info.class
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/java/conf does not exist.

jar:
     [echo] Project: hbase-handler
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/hive-hbase-handler-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-hbase-handler;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 21:09:06 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-hbase-handler
[ivy:publish] 	published hive-hbase-handler to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-hbase-handler/0.12.0-SNAPSHOT/jars/hive-hbase-handler.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-hbase-handler/0.12.0-SNAPSHOT/ivys/ivy.xml

ivy-init-settings:
     [echo] Project: testutils

check-ivy:
     [echo] Project: testutils

ivy-resolve:
     [echo] Project: testutils
[ivy:resolve] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: org.apache.hive#hive-testutils;0.12.0-SNAPSHOT
[ivy:resolve] 	confs: [default]
[ivy:resolve] 	found junit#junit;4.10 in maven2
[ivy:resolve] 	found org.hamcrest#hamcrest-core;1.1 in maven2
[ivy:resolve] 	found com.google.code.tempus-fugit#tempus-fugit;1.1 in maven2
[ivy:resolve] downloading http://repo1.maven.org/maven2/junit/junit/4.10/junit-4.10.jar ...
[ivy:resolve] ..... (247kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] junit#junit;4.10!junit.jar (9ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/com/google/code/tempus-fugit/tempus-fugit/1.1/tempus-fugit-1.1.jar ...
[ivy:resolve] .. (54kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] com.google.code.tempus-fugit#tempus-fugit;1.1!tempus-fugit.jar (6ms)
[ivy:resolve] downloading http://repo1.maven.org/maven2/org/hamcrest/hamcrest-core/1.1/hamcrest-core-1.1.jar ...
[ivy:resolve] ... (74kB)
[ivy:resolve] .. (0kB)
[ivy:resolve] 	[SUCCESSFUL ] org.hamcrest#hamcrest-core;1.1!hamcrest-core.jar (6ms)
[ivy:resolve] :: resolution report :: resolve 2147ms :: artifacts dl 26ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	junit#junit;4.7 by [junit#junit;4.10] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   4   |   3   |   3   |   1   ||   3   |   3   |
	---------------------------------------------------------------------
[ivy:report] Processing /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/resolution-cache/org.apache.hive-hive-testutils-default.xml to /data/hive-ptest/working/apache-svn-trunk-source/build/ivy/report/org.apache.hive-hive-testutils-default.html

make-pom:
     [echo] Project: testutils
     [echo]  Writing POM to /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/pom.xml
[ivy:makepom] DEPRECATED: &apos;ivy.conf.file&apos; is deprecated, use &apos;ivy.settings.file&apos; instead
[ivy:makepom] :: loading settings :: file = /data/hive-ptest/working/apache-svn-trunk-source/ivy/ivysettings.xml

create-dirs:
     [echo] Project: testutils
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources does not exist.

init:
     [echo] Project: testutils

setup:
     [echo] Project: testutils

ivy-retrieve:
     [echo] Project: testutils
[ivy:retrieve] :: retrieving :: org.apache.hive#hive-testutils
[ivy:retrieve] 	confs: [default]
[ivy:retrieve] 	3 artifacts copied, 0 already retrieved (376kB/4ms)

compile:
     [echo] Project: testutils
    [javac] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/classes
     [copy] Warning: /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/java/conf does not exist.

jar:
     [echo] Project: testutils
      [jar] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/hive-testutils-0.12.0-SNAPSHOT.jar
[ivy:publish] :: delivering :: org.apache.hive#hive-testutils;0.12.0-SNAPSHOT :: 0.12.0-SNAPSHOT :: integration :: Mon Sep 02 21:09:08 EDT 2013
[ivy:publish] 	delivering ivy file to /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/ivy-0.12.0-SNAPSHOT.xml
[ivy:publish] :: publishing :: org.apache.hive#hive-testutils
[ivy:publish] 	published hive-testutils to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-testutils/0.12.0-SNAPSHOT/jars/hive-testutils.jar
[ivy:publish] 	published ivy to /data/hive-ptest/working/ivy/local/org.apache.hive/hive-testutils/0.12.0-SNAPSHOT/ivys/ivy.xml

init:

jar:

mvn-init:
     [echo] hcatalog-core
      [get] Getting: http://repo2.maven.org/maven2/org/apache/maven/maven-ant-tasks/2.1.3/maven-ant-tasks-2.1.3.jar
      [get] To: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build/maven-ant-tasks-2.1.3.jar

hive-mvn-publish:
     [echo] Installing local artifact for maven : shims
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/shims/hive-shims-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.12.0-SNAPSHOT/hive-shims-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : common
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/common/hive-common-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-common/0.12.0-SNAPSHOT/hive-common-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : serde
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/serde/hive-serde-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-serde/0.12.0-SNAPSHOT/hive-serde-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : metastore
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/metastore/hive-metastore-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.12.0-SNAPSHOT/hive-metastore-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : ql
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/ql/hive-exec-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-exec/0.12.0-SNAPSHOT/hive-exec-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : contrib
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/contrib/hive-contrib-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-contrib/0.12.0-SNAPSHOT/hive-contrib-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : service
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/service/hive-service-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-service/0.12.0-SNAPSHOT/hive-service-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : cli
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/cli/hive-cli-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-cli/0.12.0-SNAPSHOT/hive-cli-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : jdbc
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/jdbc/hive-jdbc-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-jdbc/0.12.0-SNAPSHOT/hive-jdbc-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : beeline
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/beeline/hive-beeline-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-beeline/0.12.0-SNAPSHOT/hive-beeline-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : hwi
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/hwi/hive-hwi-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hwi/0.12.0-SNAPSHOT/hive-hwi-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : hbase-handler
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/hbase-handler/hive-hbase-handler-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hbase-handler/0.12.0-SNAPSHOT/hive-hbase-handler-0.12.0-SNAPSHOT.jar
     [echo] Installing local artifact for maven : testutils
[artifact:install] [INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/build/testutils/hive-testutils-0.12.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-testutils/0.12.0-SNAPSHOT/hive-testutils-0.12.0-SNAPSHOT.jar

_check-mvn-dependencies:

mvn-dependencies:
     [echo] hcatalog-core
[artifact:dependencies] Downloading: com/google/guava/guava/11.0.2/guava-11.0.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google.guava:guava:pom:11.0.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/guava/guava/11.0.2/guava-11.0.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 5K from central
[artifact:dependencies] Downloading: com/google/guava/guava-parent/11.0.2/guava-parent-11.0.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google.guava:guava-parent:pom:11.0.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/guava/guava-parent/11.0.2/guava-parent-11.0.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/sonatype/oss/oss-parent/7/oss-parent-7.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.sonatype.oss:oss-parent:pom:7&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/sonatype/oss/oss-parent/7/oss-parent-7.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 5K from central
[artifact:dependencies] Downloading: com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google.code.findbugs:jsr305:pom:1.3.9&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-cli:0.12.0-SNAPSHOT: checking for updates from datanucleus
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-cli:0.12.0-SNAPSHOT: checking for updates from sonatype-snapshots
[artifact:dependencies] Downloading: jline/jline/0.9.94/jline-0.9.94.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;jline:jline:pom:0.9.94&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: jline/jline/0.9.94/jline-0.9.94.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 6K from central
[artifact:dependencies] Downloading: junit/junit/3.8.1/junit-3.8.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;junit:junit:pom:3.8.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: junit/junit/3.8.1/junit-3.8.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-service:0.12.0-SNAPSHOT: checking for updates from datanucleus
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-service:0.12.0-SNAPSHOT: checking for updates from sonatype-snapshots
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-exec:0.12.0-SNAPSHOT: checking for updates from datanucleus
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-exec:0.12.0-SNAPSHOT: checking for updates from sonatype-snapshots
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-metastore:0.12.0-SNAPSHOT: checking for updates from datanucleus
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-metastore:0.12.0-SNAPSHOT: checking for updates from sonatype-snapshots
[artifact:dependencies] Downloading: org/antlr/antlr/3.4/antlr-3.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:antlr:pom:3.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/antlr/3.4/antlr-3.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/antlr/antlr-master/3.4/antlr-master-3.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:antlr-master:pom:3.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/antlr-master/3.4/antlr-master-3.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:antlr-runtime:pom:3.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:stringtemplate:pom:3.2.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 7K from central
[artifact:dependencies] Downloading: antlr/antlr/2.7.7/antlr-2.7.7.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;antlr:antlr:pom:2.7.7&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: antlr/antlr/2.7.7/antlr-2.7.7.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/antlr/ST4/4.0.4/ST4-4.0.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:ST4:pom:4.0.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/ST4/4.0.4/ST4-4.0.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: org/antlr/antlr-runtime/3.3/antlr-runtime-3.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:antlr-runtime:pom:3.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/antlr-runtime/3.3/antlr-runtime-3.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/antlr/antlr-master/3.3/antlr-master-3.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:antlr-master:pom:3.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/antlr-master/3.3/antlr-master-3.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-serde:0.12.0-SNAPSHOT: checking for updates from datanucleus
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-serde:0.12.0-SNAPSHOT: checking for updates from sonatype-snapshots
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-common:0.12.0-SNAPSHOT: checking for updates from datanucleus
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-common:0.12.0-SNAPSHOT: checking for updates from sonatype-snapshots
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-shims:0.12.0-SNAPSHOT: checking for updates from datanucleus
[artifact:dependencies] [INFO] snapshot org.apache.hive:hive-shims:0.12.0-SNAPSHOT: checking for updates from sonatype-snapshots
[artifact:dependencies] Downloading: org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.zookeeper:zookeeper:pom:3.4.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-api:pom:1.6.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.6.1/slf4j-parent-1.6.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-parent:pom:1.6.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.6.1/slf4j-parent-1.6.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-log4j12:pom:1.6.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: log4j/log4j/1.2.16/log4j-1.2.16.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;log4j:log4j:pom:1.2.16&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: log4j/log4j/1.2.16/log4j-1.2.16.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 20K from central
[artifact:dependencies] Downloading: log4j/log4j/1.2.15/log4j-1.2.15.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;log4j:log4j:pom:1.2.15&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: log4j/log4j/1.2.15/log4j-1.2.15.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 17K from central
[artifact:dependencies] Downloading: javax/mail/mail/1.4/mail-1.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;javax.mail:mail:pom:1.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: javax.mail/poms/mail-1.4.pom from repository java.net at https://maven-repository.dev.java.net/nonav/repository
[artifact:dependencies] Error transferring file: maven-repository.dev.java.net
[artifact:dependencies] [WARNING] Unable to get resource &apos;javax.mail:mail:pom:1.4&apos; from repository java.net (https://maven-repository.dev.java.net/nonav/repository): Error transferring file: maven-repository.dev.java.net
[artifact:dependencies] Downloading: javax/mail/mail/1.4/mail-1.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: javax/activation/activation/1.1/activation-1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;javax.activation:activation:pom:1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: javax.activation/poms/activation-1.1.pom from repository java.net at https://maven-repository.dev.java.net/nonav/repository
[artifact:dependencies] Error transferring file: maven-repository.dev.java.net
[artifact:dependencies] [WARNING] Unable to get resource &apos;javax.activation:activation:pom:1.1&apos; from repository java.net (https://maven-repository.dev.java.net/nonav/repository): Error transferring file: maven-repository.dev.java.net
[artifact:dependencies] Downloading: javax/activation/activation/1.1/activation-1.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: javax/jms/jms/1.1/jms-1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 1K from datanucleus
[artifact:dependencies] [WARNING] *** CHECKSUM FAILED - Error retrieving checksum file for javax/jms/jms/1.1/jms-1.1.pom - IGNORING
[artifact:dependencies] Downloading: com/sun/jdmk/jmxtools/1.2.1/jmxtools-1.2.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 0K from datanucleus
[artifact:dependencies] [WARNING] *** CHECKSUM FAILED - Error retrieving checksum file for com/sun/jdmk/jmxtools/1.2.1/jmxtools-1.2.1.pom - IGNORING
[artifact:dependencies] Downloading: com/sun/jmx/jmxri/1.2.1/jmxri-1.2.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 0K from datanucleus
[artifact:dependencies] [WARNING] *** CHECKSUM FAILED - Error retrieving checksum file for com/sun/jmx/jmxri/1.2.1/jmxri-1.2.1.pom - IGNORING
[artifact:dependencies] Downloading: org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.jboss.netty:netty:pom:3.2.2.Final&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 23K from central
[artifact:dependencies] Downloading: org/jboss/jboss-parent/5/jboss-parent-5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.jboss:jboss-parent:pom:5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/jboss/jboss-parent/5/jboss-parent-5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 18K from central
[artifact:dependencies] Downloading: org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.thrift:libthrift:pom:0.9.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.8/slf4j-api-1.5.8.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-api:pom:1.5.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.8/slf4j-api-1.5.8.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.8/slf4j-parent-1.5.8.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-parent:pom:1.5.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.8/slf4j-parent-1.5.8.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 8K from central
[artifact:dependencies] Downloading: commons-lang/commons-lang/2.5/commons-lang-2.5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-lang:commons-lang:pom:2.5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-lang/commons-lang/2.5/commons-lang-2.5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 17K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/12/commons-parent-12.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-parent:pom:12&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/12/commons-parent-12.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 26K from central
[artifact:dependencies] Downloading: org/apache/apache/4/apache-4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache:apache:pom:4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/apache/4/apache-4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:httpclient:pom:4.1.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 6K from central
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcomponents-client/4.1.3/httpcomponents-client-4.1.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:httpcomponents-client:pom:4.1.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcomponents-client/4.1.3/httpcomponents-client-4.1.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 12K from central
[artifact:dependencies] Downloading: org/apache/httpcomponents/project/5/project-5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:project:pom:5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/project/5/project-5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 23K from central
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcore/4.1.4/httpcore-4.1.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:httpcore:pom:4.1.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcore/4.1.4/httpcore-4.1.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 7K from central
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcomponents-core/4.1.4/httpcomponents-core-4.1.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:httpcomponents-core:pom:4.1.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcomponents-core/4.1.4/httpcomponents-core-4.1.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 10K from central
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-logging:commons-logging:pom:1.1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 18K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/5/commons-parent-5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-parent:pom:5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/5/commons-parent-5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 16K from central
[artifact:dependencies] Downloading: commons-codec/commons-codec/1.4/commons-codec-1.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-codec:commons-codec:pom:1.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-codec/commons-codec/1.4/commons-codec-1.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 10K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/11/commons-parent-11.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-parent:pom:11&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/11/commons-parent-11.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 24K from central
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:httpcore:pom:4.1.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 7K from central
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcomponents-core/4.1.3/httpcomponents-core-4.1.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:httpcomponents-core:pom:4.1.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcomponents-core/4.1.3/httpcomponents-core-4.1.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 10K from central
[artifact:dependencies] Downloading: org/apache/httpcomponents/project/4.1.1/project-4.1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:project:pom:4.1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/project/4.1.1/project-4.1.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 16K from central
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.0.4/commons-logging-1.0.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-logging:commons-logging:pom:1.0.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.0.4/commons-logging-1.0.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 5K from central
[artifact:dependencies] Downloading: commons-logging/commons-logging-api/1.0.4/commons-logging-api-1.0.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-logging:commons-logging-api:pom:1.0.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-logging/commons-logging-api/1.0.4/commons-logging-api-1.0.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 0K from central
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.codehaus.jackson:jackson-core-asl:pom:1.8.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.codehaus.jackson:jackson-mapper-asl:pom:1.8.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: commons-io/commons-io/2.4/commons-io-2.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-io:commons-io:pom:2.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-io/commons-io/2.4/commons-io-2.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 10K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/25/commons-parent-25.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-parent:pom:25&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/25/commons-parent-25.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 47K from central
[artifact:dependencies] Downloading: org/apache/apache/9/apache-9.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache:apache:pom:9&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/apache/9/apache-9.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 15K from central
[artifact:dependencies] Downloading: commons-cli/commons-cli/1.2/commons-cli-1.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-cli:commons-cli:pom:1.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-cli/commons-cli/1.2/commons-cli-1.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 8K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-compress:pom:1.4.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 11K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/24/commons-parent-24.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-parent:pom:24&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/24/commons-parent-24.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 46K from central
[artifact:dependencies] Downloading: org/tukaani/xz/1.0/xz-1.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.tukaani:xz:pom:1.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/tukaani/xz/1.0/xz-1.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: commons-lang/commons-lang/2.4/commons-lang-2.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-lang:commons-lang:pom:2.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-lang/commons-lang/2.4/commons-lang-2.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 14K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/9/commons-parent-9.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-parent:pom:9&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/9/commons-parent-9.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 21K from central
[artifact:dependencies] Downloading: org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mockito:mockito-all:pom:1.8.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.thrift:libfb303:pom:0.9.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/apache/avro/avro/1.7.1/avro-1.7.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.avro:avro:pom:1.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/avro/avro/1.7.1/avro-1.7.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/apache/avro/avro-parent/1.7.1/avro-parent-1.7.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.avro:avro-parent:pom:1.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/avro/avro-parent/1.7.1/avro-parent-1.7.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 15K from central
[artifact:dependencies] Downloading: org/apache/avro/avro-toplevel/1.7.1/avro-toplevel-1.7.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.avro:avro-toplevel:pom:1.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/avro/avro-toplevel/1.7.1/avro-toplevel-1.7.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: org/apache/apache/10/apache-10.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache:apache:pom:10&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/apache/10/apache-10.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 14K from central
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer:pom:2.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-parent/2.3/paranamer-parent-2.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer-parent:pom:2.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-parent/2.3/paranamer-parent-2.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 11K from central
[artifact:dependencies] Downloading: org/codehaus/codehaus-parent/1/codehaus-parent-1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.codehaus:codehaus-parent:pom:1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/codehaus/codehaus-parent/1/codehaus-parent-1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.xerial.snappy:snappy-java:pom:1.0.4.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.6.4/slf4j-api-1.6.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-api:pom:1.6.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.6.4/slf4j-api-1.6.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.6.4/slf4j-parent-1.6.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-parent:pom:1.6.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.6.4/slf4j-parent-1.6.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 12K from central
[artifact:dependencies] Downloading: org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.avro:avro-mapred:pom:1.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.avro:avro-ipc:pom:1.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jetty:pom:6.1.26&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 6K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/project/6.1.26/project-6.1.26.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:project:pom:6.1.26&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/project/6.1.26/project-6.1.26.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty-parent/10/jetty-parent-10.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jetty-parent:pom:10&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty-parent/10/jetty-parent-10.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/eclipse/jetty/jetty-parent/14/jetty-parent-14.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.eclipse.jetty:jetty-parent:pom:14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/eclipse/jetty/jetty-parent/14/jetty-parent-14.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 16K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jetty-util:pom:6.1.26&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:servlet-api:pom:2.5-20081211&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty-parent/7/jetty-parent-7.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jetty-parent:pom:7&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty-parent/7/jetty-parent-7.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 13K from central
[artifact:dependencies] Downloading: io/netty/netty/3.4.0.Final/netty-3.4.0.Final.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;io.netty:netty:pom:3.4.0.Final&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: io/netty/netty/3.4.0.Final/netty-3.4.0.Final.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 24K from central
[artifact:dependencies] Downloading: org/apache/velocity/velocity/1.7/velocity-1.7.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.velocity:velocity:pom:1.7&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/velocity/velocity/1.7/velocity-1.7.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 11K from central
[artifact:dependencies] Downloading: commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-collections:commons-collections:pom:3.2.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 12K from central
[artifact:dependencies] Downloading: com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.jolbox:bonecp:pom:0.7.1.RELEASE&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: com/jolbox/bonecp-parent/0.7.1.RELEASE/bonecp-parent-0.7.1.RELEASE.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.jolbox:bonecp-parent:pom:0.7.1.RELEASE&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/jolbox/bonecp-parent/0.7.1.RELEASE/bonecp-parent-0.7.1.RELEASE.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 24K from central
[artifact:dependencies] Downloading: com/google/guava/guava/r08/guava-r08.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google.guava:guava:pom:r08&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/guava/guava/r08/guava-r08.pom from repository jboss-public-repository-group at http://repository.jboss.org/nexus/content/groups/public
[artifact:dependencies] Transferring 3K from jboss-public-repository-group
[artifact:dependencies] [WARNING] *** CHECKSUM FAILED - Error retrieving checksum file for com/google/guava/guava/r08/guava-r08.pom - IGNORING
[artifact:dependencies] Downloading: com/google/google/5/google-5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google:google:pom:5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/google/5/google-5.pom from repository jboss-public-repository-group at http://repository.jboss.org/nexus/content/groups/public
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google:google:pom:5&apos; in repository jboss-public-repository-group (http://repository.jboss.org/nexus/content/groups/public)
[artifact:dependencies] Downloading: com/google/google/5/google-5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.10/slf4j-api-1.5.10.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-api:pom:1.5.10&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.10/slf4j-api-1.5.10.pom from repository jboss-public-repository-group at http://repository.jboss.org/nexus/content/groups/public
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-api:pom:1.5.10&apos; in repository jboss-public-repository-group (http://repository.jboss.org/nexus/content/groups/public)
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.10/slf4j-api-1.5.10.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.10/slf4j-parent-1.5.10.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-parent:pom:1.5.10&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.10/slf4j-parent-1.5.10.pom from repository jboss-public-repository-group at http://repository.jboss.org/nexus/content/groups/public
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-parent:pom:1.5.10&apos; in repository jboss-public-repository-group (http://repository.jboss.org/nexus/content/groups/public)
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.10/slf4j-parent-1.5.10.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-pool:commons-pool:pom:1.5.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 11K from central
[artifact:dependencies] Downloading: org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 9K from datanucleus
[artifact:dependencies] Downloading: org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 14K from datanucleus
[artifact:dependencies] Downloading: org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 12K from datanucleus
[artifact:dependencies] Downloading: javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;javax.jdo:jdo-api:pom:3.0.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 8K from central
[artifact:dependencies] Downloading: javax/transaction/jta/1.1/jta-1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;javax.transaction:jta:pom:1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: javax/transaction/jta/1.1/jta-1.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.derby:derby:pom:10.4.2.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: com/google/protobuf/protobuf-java/2.4.1/protobuf-java-2.4.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google.protobuf:protobuf-java:pom:2.4.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/protobuf/protobuf-java/2.4.1/protobuf-java-2.4.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 7K from central
[artifact:dependencies] Downloading: com/google/google/1/google-1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google:google:pom:1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/google/1/google-1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/iq80/snappy/snappy/0.2/snappy-0.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.iq80.snappy:snappy:pom:0.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/iq80/snappy/snappy/0.2/snappy-0.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 14K from central
[artifact:dependencies] [INFO] snapshot com.esotericsoftware.kryo:kryo:2.22-SNAPSHOT: checking for updates from datanucleus
[artifact:dependencies] [INFO] snapshot com.esotericsoftware.kryo:kryo:2.22-SNAPSHOT: checking for updates from sonatype-snapshots
[artifact:dependencies] Downloading: com/esotericsoftware/kryo/kryo/2.22-SNAPSHOT/kryo-2.22-20130829.144349-38.pom from repository sonatype-snapshots at https://oss.sonatype.org/content/repositories/snapshots/
[artifact:dependencies] Downloading: com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.esotericsoftware.reflectasm:reflectasm:pom:1.07&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07.pom from repository sonatype-releases at https://oss.sonatype.org/content/repositories/releases
[artifact:dependencies] Downloading: org/ow2/asm/asm/4.0/asm-4.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.ow2.asm:asm:pom:4.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/ow2/asm/asm/4.0/asm-4.0.pom from repository sonatype-releases at https://oss.sonatype.org/content/repositories/releases
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.ow2.asm:asm:pom:4.0&apos; in repository sonatype-releases (https://oss.sonatype.org/content/repositories/releases)
[artifact:dependencies] Downloading: org/ow2/asm/asm/4.0/asm-4.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/ow2/asm/asm-parent/4.0/asm-parent-4.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.ow2.asm:asm-parent:pom:4.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/ow2/asm/asm-parent/4.0/asm-parent-4.0.pom from repository sonatype-releases at https://oss.sonatype.org/content/repositories/releases
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.ow2.asm:asm-parent:pom:4.0&apos; in repository sonatype-releases (https://oss.sonatype.org/content/repositories/releases)
[artifact:dependencies] Downloading: org/ow2/asm/asm-parent/4.0/asm-parent-4.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 5K from central
[artifact:dependencies] Downloading: org/ow2/ow2/1.3/ow2-1.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.ow2:ow2:pom:1.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/ow2/ow2/1.3/ow2-1.3.pom from repository sonatype-releases at https://oss.sonatype.org/content/repositories/releases
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.ow2:ow2:pom:1.3&apos; in repository sonatype-releases (https://oss.sonatype.org/content/repositories/releases)
[artifact:dependencies] Downloading: org/ow2/ow2/1.3/ow2-1.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.esotericsoftware.minlog:minlog:pom:1.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.pom from repository sonatype-releases at https://oss.sonatype.org/content/repositories/releases
[artifact:dependencies] Downloading: org/objenesis/objenesis/1.2/objenesis-1.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.objenesis:objenesis:pom:1.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/objenesis/objenesis/1.2/objenesis-1.2.pom from repository sonatype-releases at https://oss.sonatype.org/content/repositories/releases
[artifact:dependencies] Downloading: org/objenesis/objenesis-parent/1.2/objenesis-parent-1.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.objenesis:objenesis-parent:pom:1.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/objenesis/objenesis-parent/1.2/objenesis-parent-1.2.pom from repository sonatype-releases at https://oss.sonatype.org/content/repositories/releases
[artifact:dependencies] Downloading: org/json/json/20090211/json-20090211.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.json:json:pom:20090211&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/json/json/20090211/json-20090211.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: commons-configuration/commons-configuration/1.6/commons-configuration-1.6.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-configuration:commons-configuration:pom:1.6&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-configuration/commons-configuration/1.6/commons-configuration-1.6.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 13K from central
[artifact:dependencies] Downloading: commons-digester/commons-digester/1.8/commons-digester-1.8.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-digester:commons-digester:pom:1.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-digester/commons-digester/1.8/commons-digester-1.8.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 7K from central
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-beanutils:commons-beanutils:pom:1.7.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 0K from central
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.0.3/commons-logging-1.0.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-logging:commons-logging:pom:1.0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.0.3/commons-logging-1.0.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.1/commons-logging-1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-logging:commons-logging:pom:1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.1/commons-logging-1.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 6K from central
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-beanutils:commons-beanutils-core:pom:1.8.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.googlecode.javaewah:JavaEWAH:pom:0.3.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/sonatype/oss/oss-parent/5/oss-parent-5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.sonatype.oss:oss-parent:pom:5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/sonatype/oss/oss-parent/5/oss-parent-5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: javolution/javolution/5.5.1/javolution-5.5.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;javolution:javolution:pom:5.5.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: javolution/javolution/5.5.1/javolution-5.5.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 13K from central
[artifact:dependencies] Downloading: junit/junit/4.10/junit-4.10.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;junit:junit:pom:4.10&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: junit/junit/4.10/junit-4.10.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/hamcrest/hamcrest-core/1.1/hamcrest-core-1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.hamcrest:hamcrest-core:pom:1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/hamcrest/hamcrest-core/1.1/hamcrest-core-1.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 0K from central
[artifact:dependencies] Downloading: org/hamcrest/hamcrest-parent/1.1/hamcrest-parent-1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.hamcrest:hamcrest-parent:pom:1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/hamcrest/hamcrest-parent/1.1/hamcrest-parent-1.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 6K from central
[artifact:dependencies] Downloading: com/puppycrawl/tools/checkstyle/5.5/checkstyle-5.5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.puppycrawl.tools:checkstyle:pom:5.5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/puppycrawl/tools/checkstyle/5.5/checkstyle-5.5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 19K from central
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils-core/1.8.3/commons-beanutils-core-1.8.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-beanutils:commons-beanutils-core:pom:1.8.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils-core/1.8.3/commons-beanutils-core-1.8.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-tools/1.0.3/hadoop-tools-1.0.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.hadoop:hadoop-tools:pom:1.0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-tools/1.0.3/hadoop-tools-1.0.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-core/1.0.3/hadoop-core-1.0.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.hadoop:hadoop-core:pom:1.0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-core/1.0.3/hadoop-core-1.0.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: xmlenc/xmlenc/0.52/xmlenc-0.52.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;xmlenc:xmlenc:pom:0.52&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: xmlenc/xmlenc/0.52/xmlenc-0.52.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-httpclient:commons-httpclient:pom:3.0.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 8K from central
[artifact:dependencies] Downloading: commons-codec/commons-codec/1.2/commons-codec-1.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-codec:commons-codec:pom:1.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-codec/commons-codec/1.2/commons-codec-1.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-math/2.1/commons-math-2.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-math:pom:2.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-math/2.1/commons-math-2.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 10K from central
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/14/commons-parent-14.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-parent:pom:14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-parent/14/commons-parent-14.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 31K from central
[artifact:dependencies] Downloading: org/apache/apache/7/apache-7.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache:apache:pom:7&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/apache/7/apache-7.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 14K from central
[artifact:dependencies] Downloading: commons-net/commons-net/1.4.1/commons-net-1.4.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-net:commons-net:pom:1.4.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-net/commons-net/1.4.1/commons-net-1.4.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 5K from central
[artifact:dependencies] Downloading: oro/oro/2.0.8/oro-2.0.8.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;oro:oro:pom:2.0.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: oro/oro/2.0.8/oro-2.0.8.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 0K from central
[artifact:dependencies] Downloading: tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;tomcat:jasper-runtime:pom:5.5.12&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 0K from central
[artifact:dependencies] Downloading: tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;tomcat:jasper-compiler:pom:5.5.12&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 0K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jsp-api-2.1:pom:6.1.14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/project/6.1.14/project-6.1.14.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:project:pom:6.1.14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/project/6.1.14/project-6.1.14.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:servlet-api-2.5:pom:6.1.14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.pom from repository java.net at http://download.java.net/maven/2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:servlet-api-2.5:pom:6.1.14&apos; in repository java.net (http://download.java.net/maven/2)
[artifact:dependencies] Downloading: org.mortbay.jetty/poms/servlet-api-2.5-6.1.14.pom from repository m1.java.net at http://download.java.net/maven/1
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:servlet-api-2.5:pom:6.1.14&apos; in repository m1.java.net (http://download.java.net/maven/1)
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jsp-2.1:pom:6.1.14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 6K from central
[artifact:dependencies] Downloading: org/eclipse/jdt/core/3.1.1/core-3.1.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.eclipse.jdt:core:pom:3.1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/eclipse/jdt/core/3.1.1/core-3.1.1.pom from repository java.net at http://download.java.net/maven/2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.eclipse.jdt:core:pom:3.1.1&apos; in repository java.net (http://download.java.net/maven/2)
[artifact:dependencies] Downloading: org.eclipse.jdt/poms/core-3.1.1.pom from repository m1.java.net at http://download.java.net/maven/1
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.eclipse.jdt:core:pom:3.1.1&apos; in repository m1.java.net (http://download.java.net/maven/1)
[artifact:dependencies] Downloading: org/eclipse/jdt/core/3.1.1/core-3.1.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: ant/ant/1.6.5/ant-1.6.5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;ant:ant:pom:1.6.5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: ant/ant/1.6.5/ant-1.6.5.pom from repository java.net at http://download.java.net/maven/2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;ant:ant:pom:1.6.5&apos; in repository java.net (http://download.java.net/maven/2)
[artifact:dependencies] Downloading: ant/poms/ant-1.6.5.pom from repository m1.java.net at http://download.java.net/maven/1
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;ant:ant:pom:1.6.5&apos; in repository m1.java.net (http://download.java.net/maven/1)
[artifact:dependencies] Downloading: ant/ant/1.6.5/ant-1.6.5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: commons-el/commons-el/1.0/commons-el-1.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-el:commons-el:pom:1.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-el/commons-el/1.0/commons-el-1.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;net.java.dev.jets3t:jets3t:pom:0.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: commons-codec/commons-codec/1.3/commons-codec-1.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-codec:commons-codec:pom:1.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-codec/commons-codec/1.3/commons-codec-1.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 6K from central
[artifact:dependencies] Downloading: commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-httpclient:commons-httpclient:pom:3.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 8K from central
[artifact:dependencies] Downloading: net/sf/kosmosfs/kfs/0.3/kfs-0.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;net.sf.kosmosfs:kfs:pom:0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: net/sf/kosmosfs/kfs/0.3/kfs-0.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;hsqldb:hsqldb:pom:1.8.0.10&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-mapper-asl/1.0.1/jackson-mapper-asl-1.0.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.codehaus.jackson:jackson-mapper-asl:pom:1.0.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-mapper-asl/1.0.1/jackson-mapper-asl-1.0.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-test/1.0.3/hadoop-test-1.0.3.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.hadoop:hadoop-test:pom:1.0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-test/1.0.3/hadoop-test-1.0.3.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftplet-api/1.0.0/ftplet-api-1.0.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftplet-api:pom:1.0.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftplet-api/1.0.0/ftplet-api-1.0.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-parent/1.0.0/ftpserver-parent-1.0.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftpserver-parent:pom:1.0.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-parent/1.0.0/ftpserver-parent-1.0.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 13K from central
[artifact:dependencies] Downloading: org/apache/mina/mina-core/2.0.0-M5/mina-core-2.0.0-M5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.mina:mina-core:pom:2.0.0-M5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/mina/mina-core/2.0.0-M5/mina-core-2.0.0-M5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/apache/mina/mina-parent/2.0.0-M5/mina-parent-2.0.0-M5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.mina:mina-parent:pom:2.0.0-M5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/mina/mina-parent/2.0.0-M5/mina-parent-2.0.0-M5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 10K from central
[artifact:dependencies] Downloading: org/apache/mina/build/2.0.0-M5/build-2.0.0-M5.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.mina:build:pom:2.0.0-M5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/mina/build/2.0.0-M5/build-2.0.0-M5.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 8K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.2/slf4j-api-1.5.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-api:pom:1.5.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.2/slf4j-api-1.5.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.2/slf4j-parent-1.5.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-parent:pom:1.5.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.2/slf4j-parent-1.5.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 7K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-core/1.0.0/ftpserver-core-1.0.0.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftpserver-core:pom:1.0.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-core/1.0.0/ftpserver-core-1.0.0.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 6K from central
[artifact:dependencies] Downloading: org/apache/mina/mina-core/2.0.0-M4/mina-core-2.0.0-M4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.mina:mina-core:pom:2.0.0-M4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/mina/mina-core/2.0.0-M4/mina-core-2.0.0-M4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/apache/mina/build/2.0.0-M4/build-2.0.0-M4.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.mina:build:pom:2.0.0-M4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/mina/build/2.0.0-M4/build-2.0.0-M4.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 16K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-deprecated/1.0.0-M2/ftpserver-deprecated-1.0.0-M2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftpserver-deprecated:pom:1.0.0-M2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-deprecated/1.0.0-M2/ftpserver-deprecated-1.0.0-M2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-parent/1.0.0-M2/ftpserver-parent-1.0.0-M2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftpserver-parent:pom:1.0.0-M2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-parent/1.0.0-M2/ftpserver-parent-1.0.0-M2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 14K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftplet-api/1.0.0-M2/ftplet-api-1.0.0-M2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftplet-api:pom:1.0.0-M2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftplet-api/1.0.0-M2/ftplet-api-1.0.0-M2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-core/1.0.0-M2/ftpserver-core-1.0.0-M2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftpserver-core:pom:1.0.0-M2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-core/1.0.0-M2/ftpserver-core-1.0.0-M2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: org/apache/mina/mina-core/2.0.0-M2/mina-core-2.0.0-M2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.mina:mina-core:pom:2.0.0-M2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/mina/mina-core/2.0.0-M2/mina-core-2.0.0-M2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: org/apache/mina/build/2.0.0-M2/build-2.0.0-M2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.mina:build:pom:2.0.0-M2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/mina/build/2.0.0-M2/build-2.0.0-M2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 15K from central
[artifact:dependencies] Downloading: org/apache/pig/pig/0.10.1/pig-0.10.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.pig:pig:pom:0.10.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/pig/pig/0.10.1/pig-0.10.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: junit/junit/4.8.1/junit-4.8.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;junit:junit:pom:4.8.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: junit/junit/4.8.1/junit-4.8.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/apache/hadoop/avro/1.3.2/avro-1.3.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.hadoop:avro:pom:1.3.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/hadoop/avro/1.3.2/avro-1.3.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-mapper-asl/1.4.2/jackson-mapper-asl-1.4.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.codehaus.jackson:jackson-mapper-asl:pom:1.4.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-mapper-asl/1.4.2/jackson-mapper-asl-1.4.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.11/slf4j-api-1.5.11.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-api:pom:1.5.11&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.5.11/slf4j-api-1.5.11.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.11/slf4j-parent-1.5.11.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-parent:pom:1.5.11&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-parent/1.5.11/slf4j-parent-1.5.11.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 9K from central
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer/2.2/paranamer-2.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer:pom:2.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer/2.2/paranamer-2.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2K from central
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-parent/2.2/paranamer-parent-2.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer-parent:pom:2.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-parent/2.2/paranamer-parent-2.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 8K from central
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-ant/2.2/paranamer-ant-2.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer-ant:pom:2.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-ant/2.2/paranamer-ant-2.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-generator/2.2/paranamer-generator-2.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer-generator:pom:2.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-generator/2.2/paranamer-generator-2.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1K from central
[artifact:dependencies] Downloading: com/thoughtworks/qdox/qdox/1.10.1/qdox-1.10.1.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.qdox:qdox:pom:1.10.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/qdox/qdox/1.10.1/qdox-1.10.1.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 17K from central
[artifact:dependencies] Downloading: asm/asm/3.2/asm-3.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;asm:asm:pom:3.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: asm/asm/3.2/asm-3.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 0K from central
[artifact:dependencies] Downloading: asm/asm-parent/3.2/asm-parent-3.2.pom from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;asm:asm-parent:pom:3.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: asm/asm-parent/3.2/asm-parent-3.2.pom from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 4K from central
[artifact:dependencies] Downloading: commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer/2.2/paranamer-2.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/tukaani/xz/1.0/xz-1.0.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: commons-digester/commons-digester/1.8/commons-digester-1.8.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.derby:derby:jar:10.4.2.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-httpclient:commons-httpclient:jar:3.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.tukaani:xz:jar:1.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Transferring 298K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-digester:commons-digester:jar:1.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-digester/commons-digester/1.8/commons-digester-1.8.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Downloading: org/tukaani/xz/1.0/xz-1.0.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer:jar:2.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer/2.2/paranamer-2.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 140K from central
[artifact:dependencies] Transferring 92K from central
[artifact:dependencies] Transferring 2389K from central
[artifact:dependencies] Transferring 29K from central
[artifact:dependencies] Downloading: tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: jline/jline/0.9.94/jline-0.9.94.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.0.4/commons-logging-1.0.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;jline:jline:jar:0.9.94&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: jline/jline/0.9.94/jline-0.9.94.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 85K from central
[artifact:dependencies] Downloading: org/apache/pig/pig/0.10.1/pig-0.10.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;tomcat:jasper-runtime:jar:5.5.12&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:httpclient:jar:4.1.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 344K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-logging:commons-logging:jar:1.0.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-logging/commons-logging/1.0.4/commons-logging-1.0.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 75K from central
[artifact:dependencies] Downloading: ant/ant/1.6.5/ant-1.6.5.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 37K from central
[artifact:dependencies] Downloading: javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/objenesis/objenesis/1.2/objenesis-1.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.pig:pig:jar:0.10.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/pig/pig/0.10.1/pig-0.10.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;ant:ant:jar:1.6.5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: ant/ant/1.6.5/ant-1.6.5.jar from repository java.net at http://download.java.net/maven/2
[artifact:dependencies] Transferring 3010K from central
[artifact:dependencies] Downloading: antlr/antlr/2.7.7/antlr-2.7.7.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;ant:ant:jar:1.6.5&apos; in repository java.net (http://download.java.net/maven/2)
[artifact:dependencies] Downloading: ant/jars/ant-1.6.5.jar from repository m1.java.net at http://download.java.net/maven/1
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;ant:ant:jar:1.6.5&apos; in repository m1.java.net (http://download.java.net/maven/1)
[artifact:dependencies] Downloading: ant/ant/1.6.5/ant-1.6.5.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1010K from central
[artifact:dependencies] Downloading: org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;javax.jdo:jdo-api:jar:3.0.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 196K from central
[artifact:dependencies] Downloading: javolution/javolution/5.5.1/javolution-5.5.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-collections:commons-collections:jar:3.2.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 562K from central
[artifact:dependencies] Downloading: com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.objenesis:objenesis:jar:1.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/objenesis/objenesis/1.2/objenesis-1.2.jar from repository sonatype-releases at https://oss.sonatype.org/content/repositories/releases
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;antlr:antlr:jar:2.7.7&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: antlr/antlr/2.7.7/antlr-2.7.7.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 435K from central
[artifact:dependencies] Transferring 35K from sonatype-releases
[artifact:dependencies] Downloading: xmlenc/xmlenc/0.52/xmlenc-0.52.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: com/esotericsoftware/kryo/kryo/2.22-SNAPSHOT/kryo-2.22-20130829.144349-38.jar from repository sonatype-snapshots at https://oss.sonatype.org/content/repositories/snapshots/
[artifact:dependencies] Transferring 414K from sonatype-snapshots
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.xerial.snappy:snappy-java:jar:1.0.4.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 973K from central
[artifact:dependencies] Downloading: commons-cli/commons-cli/1.2/commons-cli-1.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;javolution:javolution:jar:5.5.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: javolution/javolution/5.5.1/javolution-5.5.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 386K from central
[artifact:dependencies] Downloading: org/apache/avro/avro/1.7.1/avro-1.7.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.jolbox:bonecp:jar:0.7.1.RELEASE&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 113K from central
[artifact:dependencies] Downloading: org/apache/velocity/velocity/1.7/velocity-1.7.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/ow2/asm/asm/4.0/asm-4.0.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;xmlenc:xmlenc:jar:0.52&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: xmlenc/xmlenc/0.52/xmlenc-0.52.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 15K from central
[artifact:dependencies] Downloading: commons-codec/commons-codec/1.4/commons-codec-1.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-cli:commons-cli:jar:1.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-cli/commons-cli/1.2/commons-cli-1.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 40K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.avro:avro:jar:1.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/avro/avro/1.7.1/avro-1.7.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.velocity:velocity:jar:1.7&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/velocity/velocity/1.7/velocity-1.7.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.ow2.asm:asm:jar:4.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/ow2/asm/asm/4.0/asm-4.0.jar from repository sonatype-releases at https://oss.sonatype.org/content/repositories/releases
[artifact:dependencies] Transferring 439K from central
[artifact:dependencies] Downloading: hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 291K from central
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.ow2.asm:asm:jar:4.0&apos; in repository sonatype-releases (https://oss.sonatype.org/content/repositories/releases)
[artifact:dependencies] Downloading: org/ow2/asm/asm/4.0/asm-4.0.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 45K from central
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-codec:commons-codec:jar:1.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-codec/commons-codec/1.4/commons-codec-1.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 57K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;hsqldb:hsqldb:jar:1.8.0.10&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 690K from central
[artifact:dependencies] Downloading: asm/asm/3.2/asm-3.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.codehaus.jackson:jackson-core-asl:jar:1.8.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Downloading: org/iq80/snappy/snappy/0.2/snappy-0.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 222K from central
[artifact:dependencies] Downloading: io/netty/netty/3.4.0.Final/netty-3.4.0.Final.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google.code.findbugs:jsr305:jar:1.3.9&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 32K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-beanutils:commons-beanutils:jar:1.7.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 184K from central
[artifact:dependencies] Downloading: com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;asm:asm:jar:3.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: asm/asm/3.2/asm-3.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 42K from central
[artifact:dependencies] Downloading: oro/oro/2.0.8/oro-2.0.8.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.iq80.snappy:snappy:jar:0.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/iq80/snappy/snappy/0.2/snappy-0.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;io.netty:netty:jar:3.4.0.Final&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: io/netty/netty/3.4.0.Final/netty-3.4.0.Final.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jetty:jar:6.1.26&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 935K from central
[artifact:dependencies] Transferring 527K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.esotericsoftware.minlog:minlog:jar:1.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar from repository sonatype-releases at https://oss.sonatype.org/content/repositories/releases
[artifact:dependencies] Transferring 48K from central
[artifact:dependencies] Downloading: com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;oro:oro:jar:2.0.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: oro/oro/2.0.8/oro-2.0.8.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 64K from central
[artifact:dependencies] Downloading: org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 5K from sonatype-releases
[artifact:dependencies] Downloading: com/thoughtworks/qdox/qdox/1.10.1/qdox-1.10.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.googlecode.javaewah:JavaEWAH:jar:0.3.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 17K from central
[artifact:dependencies] Downloading: net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.jboss.netty:netty:jar:3.2.2.Final&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 767K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.thrift:libthrift:jar:0.9.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 339K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-compress:jar:1.4.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 236K from central
[artifact:dependencies] Downloading: commons-lang/commons-lang/2.4/commons-lang-2.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: commons-net/commons-net/1.4.1/commons-net-1.4.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.qdox:qdox:jar:1.10.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/qdox/qdox/1.10.1/qdox-1.10.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 169K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;net.java.dev.jets3t:jets3t:jar:0.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Downloading: net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 369K from central
[artifact:dependencies] Downloading: org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-lang:commons-lang:jar:2.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-lang/commons-lang/2.4/commons-lang-2.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-net:commons-net:jar:1.4.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-net/commons-net/1.4.1/commons-net-1.4.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 256K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.esotericsoftware.reflectasm:reflectasm:jar:shaded:1.07&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar from repository sonatype-releases at https://oss.sonatype.org/content/repositories/releases
[artifact:dependencies] Transferring 177K from central
[artifact:dependencies] Downloading: com/google/guava/guava/11.0.2/guava-11.0.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/antlr/antlr/3.4/antlr-3.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;net.sf.kosmosfs:kfs:jar:0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.zookeeper:zookeeper:jar:3.4.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 750K from central
[artifact:dependencies] Transferring 12K from central
[artifact:dependencies] Downloading: org/json/json/20090211/json-20090211.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 64K from sonatype-releases
[artifact:dependencies] Downloading: com/google/protobuf/protobuf-java/2.4.1/protobuf-java-2.4.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google.guava:guava:jar:11.0.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/guava/guava/11.0.2/guava-11.0.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1610K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:antlr:jar:3.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/antlr/3.4/antlr-3.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1086K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/eclipse/jdt/core/3.1.1/core-3.1.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: commons-io/commons-io/2.4/commons-io-2.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.json:json:jar:20090211&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/json/json/20090211/json-20090211.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.google.protobuf:protobuf-java:jar:2.4.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/google/protobuf/protobuf-java/2.4.1/protobuf-java-2.4.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 440K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-api:jar:1.6.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.eclipse.jdt:core:jar:3.1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/eclipse/jdt/core/3.1.1/core-3.1.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 25K from central
[artifact:dependencies] Transferring 45K from central
[artifact:dependencies] Transferring 3483K from central
[artifact:dependencies] Downloading: org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: commons-el/commons-el/1.0/commons-el-1.0.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-tools/1.0.3/hadoop-tools-1.0.3.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-io:commons-io:jar:2.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-io/commons-io/2.4/commons-io-2.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 181K from central
[artifact:dependencies] Downloading: commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-el:commons-el:jar:1.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-el/commons-el/1.0/commons-el-1.0.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 110K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.hadoop:hadoop-tools:jar:1.0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-tools/1.0.3/hadoop-tools-1.0.3.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 329K from datanucleus
[artifact:dependencies] Downloading: javax/transaction/jta/1.1/jta-1.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 281K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-pool:commons-pool:jar:1.5.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 94K from central
[artifact:dependencies] Downloading: org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: log4j/log4j/1.2.16/log4j-1.2.16.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;javax.transaction:jta:jar:1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: javax/transaction/jta/1.1/jta-1.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 15K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mockito:mockito-all:jar:1.8.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-configuration:commons-configuration:jar:1.6&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1316K from central
[artifact:dependencies] Transferring 292K from central
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-ant/2.2/paranamer-ant-2.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;log4j:log4j:jar:1.2.16&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: log4j/log4j/1.2.16/log4j-1.2.16.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 470K from central
[artifact:dependencies] Downloading: commons-logging/commons-logging-api/1.0.4/commons-logging-api-1.0.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer-ant:jar:2.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-ant/2.2/paranamer-ant-2.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 5K from central
[artifact:dependencies] Downloading: org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-logging:commons-logging-api:jar:1.0.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-logging/commons-logging-api/1.0.4/commons-logging-api-1.0.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 26K from central
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;tomcat:jasper-compiler:jar:5.5.12&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 396K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.httpcomponents:httpcore:jar:4.1.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils-core/1.8.3/commons-beanutils-core-1.8.3.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 177K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.avro:avro-mapred:jar:1.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 165K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.codehaus.jackson:jackson-mapper-asl:jar:1.8.8&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 653K from central
[artifact:dependencies] Downloading: org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/apache/commons/commons-math/2.1/commons-math-2.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;commons-beanutils:commons-beanutils-core:jar:1.8.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: commons-beanutils/commons-beanutils-core/1.8.3/commons-beanutils-core-1.8.3.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 202K from central
[artifact:dependencies] Downloading: org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jetty-util:jar:6.1.26&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 173K from central
[artifact:dependencies] Downloading: org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-core/1.0.3/hadoop-core-1.0.3.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.thrift:libfb303:jar:0.9.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 269K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.commons:commons-math:jar:2.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/commons/commons-math/2.1/commons-math-2.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-generator/2.2/paranamer-generator-2.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 813K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:antlr-runtime:jar:3.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 161K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.hadoop:hadoop-core:jar:1.0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-core/1.0.3/hadoop-core-1.0.3.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 3836K from central
[artifact:dependencies] Downloading: org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.slf4j:slf4j-log4j12:jar:1.6.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 10K from central
[artifact:dependencies] Downloading: org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.thoughtworks.paranamer:paranamer-generator:jar:2.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/thoughtworks/paranamer/paranamer-generator/2.2/paranamer-generator-2.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 7K from central
[artifact:dependencies] Downloading: org/apache/hadoop/avro/1.3.2/avro-1.3.2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.avro:avro-ipc:jar:1.7.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:servlet-api:jar:2.5-20081211&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 181K from central
[artifact:dependencies] Transferring 131K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 1760K from datanucleus
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:stringtemplate:jar:3.2.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 145K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.hadoop:avro:jar:1.3.2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/hadoop/avro/1.3.2/avro-1.3.2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 332K from central
[artifact:dependencies] Downloading: org/antlr/ST4/4.0.4/ST4-4.0.4.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jsp-api-2.1:jar:6.1.14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 132K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.antlr:ST4:jar:4.0.4&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/antlr/ST4/4.0.4/ST4-4.0.4.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 231K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:servlet-api-2.5:jar:6.1.14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 129K from central
[artifact:dependencies] Downloading: org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.mortbay.jetty:jsp-2.1:jar:6.1.14&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 1001K from central
[artifact:dependencies] Downloading: org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Transferring 1728K from datanucleus
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/build/lib/compile
     [copy] Copying 92 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/build/lib/compile
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/build/lib/provided
[artifact:dependencies] Downloading: com/puppycrawl/tools/checkstyle/5.5/checkstyle-5.5.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/apache/ftpserver/ftplet-api/1.0.0/ftplet-api-1.0.0.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/apache/mina/mina-core/2.0.0-M5/mina-core-2.0.0-M5.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/hamcrest/hamcrest-core/1.1/hamcrest-core-1.1.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: junit/junit/4.10/junit-4.10.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftplet-api:jar:1.0.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.hamcrest:hamcrest-core:jar:1.1&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/hamcrest/hamcrest-core/1.1/hamcrest-core-1.1.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Downloading: org/apache/ftpserver/ftplet-api/1.0.0/ftplet-api-1.0.0.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;com.puppycrawl.tools:checkstyle:jar:5.5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: com/puppycrawl/tools/checkstyle/5.5/checkstyle-5.5.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 75K from central
[artifact:dependencies] [INFO] Unable to find resource &apos;junit:junit:jar:4.10&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.mina:mina-core:jar:2.0.0-M5&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/mina/mina-core/2.0.0-M5/mina-core-2.0.0-M5.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Downloading: junit/junit/4.10/junit-4.10.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 623K from central
[artifact:dependencies] Transferring 623K from central
[artifact:dependencies] Transferring 22K from central
[artifact:dependencies] Transferring 247K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-core/1.0.0/ftpserver-core-1.0.0.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-test/1.0.3/hadoop-test-1.0.3.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftpserver-core:jar:1.0.0&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-core/1.0.0/ftpserver-core-1.0.0.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 265K from central
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-deprecated/1.0.0-M2/ftpserver-deprecated-1.0.0-M2.jar from repository datanucleus at http://www.datanucleus.org/downloads/maven2
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.hadoop:hadoop-test:jar:1.0.3&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/hadoop/hadoop-test/1.0.3/hadoop-test-1.0.3.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 2594K from central
[artifact:dependencies] Unable to locate resource in repository
[artifact:dependencies] [INFO] Unable to find resource &apos;org.apache.ftpserver:ftpserver-deprecated:jar:1.0.0-M2&apos; in repository datanucleus (http://www.datanucleus.org/downloads/maven2)
[artifact:dependencies] Downloading: org/apache/ftpserver/ftpserver-deprecated/1.0.0-M2/ftpserver-deprecated-1.0.0-M2.jar from repository central at http://repo1.maven.org/maven2
[artifact:dependencies] Transferring 31K from central
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/build/lib/test
     [copy] Copying 100 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/build/lib/test
    [touch] Creating /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/build/lib/.mvn-dependencies.complete

compile:
     [echo] hcatalog-core
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/build/classes
    [javac] Compiling 74 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/build/classes
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java:53: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.DefaultOutputCommitterContainer
    [javac]         getBaseOutputCommitter().abortTask(HCatMapRedUtil.createTaskAttemptContext(context));
    [javac]                                            ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java:58: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.DefaultOutputCommitterContainer
    [javac]         getBaseOutputCommitter().commitTask(HCatMapRedUtil.createTaskAttemptContext(context));
    [javac]                                             ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java:63: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.DefaultOutputCommitterContainer
    [javac]         return getBaseOutputCommitter().needsTaskCommit(HCatMapRedUtil.createTaskAttemptContext(context));
    [javac]                                                         ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java:68: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.DefaultOutputCommitterContainer
    [javac]         getBaseOutputCommitter().setupJob(HCatMapRedUtil.createJobContext(context));
    [javac]                                           ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java:73: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.DefaultOutputCommitterContainer
    [javac]         getBaseOutputCommitter().setupTask(HCatMapRedUtil.createTaskAttemptContext(context));
    [javac]                                            ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java:78: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.DefaultOutputCommitterContainer
    [javac]         getBaseOutputCommitter().abortJob(HCatMapRedUtil.createJobContext(jobContext), state);
    [javac]                                           ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java:84: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.DefaultOutputCommitterContainer
    [javac]         getBaseOutputCommitter().commitJob(HCatMapRedUtil.createJobContext(jobContext));
    [javac]                                            ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/DefaultOutputCommitterContainer.java:90: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.DefaultOutputCommitterContainer
    [javac]         getBaseOutputCommitter().cleanupJob(HCatMapRedUtil.createJobContext(context));
    [javac]                                             ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:104: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]             getBaseOutputCommitter().abortTask(HCatMapRedUtil.createTaskAttemptContext(context));
    [javac]                                                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:113: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]             getBaseOutputCommitter().commitTask(HCatMapRedUtil.createTaskAttemptContext(context));
    [javac]                                                 ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:120: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]             return getBaseOutputCommitter().needsTaskCommit(HCatMapRedUtil.createTaskAttemptContext(context));
    [javac]                                                             ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:130: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]             getBaseOutputCommitter().setupJob(HCatMapRedUtil.createJobContext(context));
    [javac]                                               ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:138: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]             getBaseOutputCommitter().setupTask(HCatMapRedUtil.createTaskAttemptContext(context));
    [javac]                                                ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:148: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]             org.apache.hadoop.mapred.JobContext mapRedJobContext = HCatMapRedUtil
    [javac]                                                                    ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:202: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]                         HCatMapRedUtil.createJobContext(jobContext));
    [javac]                         ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:579: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]                         InternalUtil.createReporter(HCatMapRedUtil.createTaskAttemptContext(jobConf,
    [javac]                                                     ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileOutputCommitterContainer.java:576: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileOutputCommitterContainer
    [javac]                     JobContext currContext = HCatMapRedUtil.createJobContext(
    [javac]                                              ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileRecordWriterContainer.java:181: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileRecordWriterContainer
    [javac]                 org.apache.hadoop.mapred.TaskAttemptContext currTaskContext = HCatMapRedUtil.createTaskAttemptContext(context);
    [javac]                                                                               ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileRecordWriterContainer.java:206: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileRecordWriterContainer
    [javac]                 org.apache.hadoop.mapred.JobContext currJobContext = HCatMapRedUtil.createJobContext(currTaskContext);
    [javac]                                                                      ^
    [javac] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hcatalog/mapreduce/FileRecordWriterContainer.java:211: cannot find symbol
    [javac] symbol  : variable HCatMapRedUtil
    [javac] location: class org.apache.hcatalog.mapreduce.FileRecordWriterContainer
    [javac]                     HCatMapRedUtil.createTaskAttemptContext(currJobContext.getJobConf(),
    [javac]                     ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] 20 errors

BUILD FAILED
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:327: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:166: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/build.xml:168: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build.xml:68: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build-support/ant/build-common.xml:85: The following error occurred while executing this line:
/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/build-support/ant/build-common.xml:55: Compile failed; see the compiler error output for details.

Total time: 7 minutes 26 seconds
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13756646" author="brocknoland" created="Tue, 3 Sep 2013 14:16:12 +0000"  >&lt;p&gt;Looks like there was a compilation issue in Hcatalog. I see a ptest trunk build ran successfully after this so I kicked it off again.&lt;/p&gt;</comment>
                            <comment id="13756764" author="hiveqa" created="Tue, 3 Sep 2013 16:41:41 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12601094/HIVE-1511.10.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12601094/HIVE-1511.10.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 50 failed/errored test(s), 2905 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.ql.parse.TestParse.testParse_input2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_cast1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input8
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_ppd_key_range
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input7
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join8
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testxpath
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_part1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join7
org.apache.hadoop.hive.ql.parse.TestParse.testParse_subq
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input20
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testsequencefile
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf_when
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testxpath2
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_pushdown
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_ppd_key_ranges
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample7
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_case_sensitivity
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input9
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_udfnull
org.apache.hadoop.hive.ql.parse.TestParse.testParse_union
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input16
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join6
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_external_table_ppd
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf_case
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/591/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/591/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/591/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/591/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 50 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13757029" author="brocknoland" created="Tue, 3 Sep 2013 20:25:28 +0000"  >&lt;p&gt;v11 fixes the hbase tests.&lt;/p&gt;</comment>
                            <comment id="13757289" author="kamrul" created="Wed, 4 Sep 2013 00:19:56 +0000"  >&lt;p&gt;It appears there are  2 more test cases to knock them down:&lt;br/&gt;
1. input16.q&lt;br/&gt;
2. udfnull.q&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt; or &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt;  : Is any of you working on these two test cases? If no body is working , i can take a stab on those. I was able to isolate the problem and fix by manually adding a new jar. &lt;/p&gt;

&lt;p&gt;I basically want to avoid the duplication effort.&lt;/p&gt;






</comment>
                            <comment id="13757306" author="brocknoland" created="Wed, 4 Sep 2013 00:31:32 +0000"  >&lt;p&gt;I am not. Go ahead!&lt;/p&gt;</comment>
                            <comment id="13757351" author="hiveqa" created="Wed, 4 Sep 2013 01:06:07 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12601228/HIVE-1511.11.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12601228/HIVE-1511.11.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 188 failed/errored test(s), 2908 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_named_struct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_lateral_view
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap_compression
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_show_indexes_edge_cases
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_map_keys
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap_auto
org.apache.hcatalog.pig.TestOrcHCatLoaderComplexSchema.testTupleInBagInTupleInBag
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_covar_pop
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_create_genericudaf
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_case_thrift
org.apache.hive.jdbc.TestJdbcDriver2.testResultSetMetaData
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_nested_complex
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_compression
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap_rc
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_columnstats_tbllvl
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_virtual_column
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_lateralview
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_min
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_compute_stats_string
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_compute_stats_binary
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_context_ngrams
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_compact_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_compact_3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input8
org.apache.hadoop.hive.ql.parse.TestParse.testParse_cast1
org.apache.hive.jdbc.TestJdbcDriver2.testNullType
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_show_indexes_syntax
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input3
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_index_compact_entry_limit
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_partitioned
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input_dynamicserde
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_percentile
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_array
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_multiple
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_compact_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap1
org.apache.hive.jdbc.TestJdbcDriver2.testDataTypes2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_empty
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join4
org.apache.hadoop.hive.jdbc.TestJdbcDriver.testNullType
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_coalesce
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_constant_prop
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_decimal_precision
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input7
org.apache.hive.jdbc.TestJdbcDriver2.testBuiltInUDFCol
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_view
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join8
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input_testxpath
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testxpath
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_create_struct_table
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_covar_samp
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_complex_types_multi_single_reducer
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_part1
org.apache.hadoop.hive.cli.TestContribCliDriver.testCliDriver_udaf_example_max_n
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap_auto_partitioned
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_global_limit
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_bitmap_or
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_compact
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_lateral_view_outer
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input_testxpath4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_self_join
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_compute_stats_long
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_null_cast
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_index_compact_size_limit
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join13
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udtf_stack
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_complex_types
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_columnarserde_create_shortcut
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_columnstats_partlvl
org.apache.hadoop.hive.ql.parse.TestParse.testParse_subq
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_corr
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_ngrams
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_collect_set
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby3_map_skew
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input20
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby_grouping_sets3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_mult_tables
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_compute_stats_empty_table
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_serde
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_split
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_insert_overwrite_local_directory_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_transform1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_array
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_explode
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_compute_stats_double
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_histogram_numeric
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testxpath2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf_when
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testsequencefile
org.apache.hadoop.hive.jdbc.TestJdbcDriver.testResultSetMetaData
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_sort_array
org.apache.hadoop.hive.cli.TestContribCliDriver.testCliDriver_udaf_example_group_concat
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_struct
org.apache.hadoop.hive.cli.TestContribCliDriver.testCliDriver_udaf_example_avg
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_pcr
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_xpath
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union21
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ql_rewrite_gbtoidx
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_update
org.apache.hadoop.hive.cli.TestContribCliDriver.testCliDriver_udaf_example_min_n
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_thrift
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_lateral_view_cp
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_max
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_compact_binary_search
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample7
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_unused
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_creation
org.apache.hadoop.hive.ql.parse.TestParse.testParse_case_sensitivity
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_percentile_approx_20
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_allcolref_in_udf
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_isnull_isnotnull
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input_testxpath3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_stale_partitioned
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_bitmap_and
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_fetch_aggregation
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input_columnarserde
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_orc_create
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_file_format
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input9
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_decimal_udf
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input_testxpath2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_stale
org.apache.hadoop.hive.ql.parse.TestParse.testParse_union
org.apache.hive.jdbc.TestJdbcDriver2.testDataTypes
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_explode_null
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auth
org.apache.hadoop.hive.jdbc.TestJdbcDriver.testDataTypes
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_udfnull
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_compute_stats_boolean
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multi_insert_lateral_view
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input16
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_windowing
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_auto_mult_tables_compact
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby3_map
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_number_format
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_inline
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_limit_pushdown
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_database_drop
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf8
org.apache.hive.jdbc.TestJdbcDriver2.testExprCol
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_skewjoinopt10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_case_sensitivity
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby3_map_multi_distinct
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input45
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input_lazyserde
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_size
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input17
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_union
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_avro_nullable_fields
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf_case
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby10
org.apache.hadoop.hive.cli.TestContribCliDriver.testCliDriver_udf_example_arraymapstruct
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_sentences
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_map_values
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/597/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/597/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/597/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/597/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 188 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13757707" author="brocknoland" created="Wed, 4 Sep 2013 12:30:50 +0000"  >&lt;p&gt;I knew that was going to happen. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  The issue is that we need to have RowSchema non-transient in Operator because Utilities.setColumnNameList uses it. Having RowSchema non-transient introduces a bunch of failures we&apos;ll need to resolve. Since that is the only place I know we require RowSchema, perhaps we could re-write setColumnNameList?&lt;/p&gt;</comment>
                            <comment id="13757736" author="romixlev" created="Wed, 4 Sep 2013 13:19:28 +0000"  >&lt;p&gt;Just FYI, Kryo&apos;s FieldSerializer provides methods that allow you to exclude certain fields from (de)serialization, as if they are not present. This way you can make certain fields &quot;transient&quot; from the serialization point of view, even if they are not really transient in the Java sense.&lt;/p&gt;

&lt;p&gt;I don&apos;t know if it would help you, but you could try to do the following right after creation of Kryo instances and registration of classes (i.e. kryo.register(My.class)) using those instances:&lt;/p&gt;

&lt;p&gt;FieldSerializer ser = (FieldSerializer)kryo.getSerializer(MySpecialClass.class);&lt;br/&gt;
ser.removeField(&quot;fieldName&quot;);&lt;br/&gt;
// Now you can use your Kryo instance and it won&apos;t (de)serialize the field called fieldName&lt;/p&gt;

&lt;p&gt;-Leo&lt;/p&gt;</comment>
                            <comment id="13758131" author="ashutoshc" created="Wed, 4 Sep 2013 18:31:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt; I think rewriting setColumnNameList so that it doesn&apos;t require RowSchema is way to go forward. Because, RowSchema is designed to be used at compile time. For execution, we rely on OIs to carry all the type information. Not needing RowSchema to be serializable will make compile time and execution time data structures neatly decoupled.&lt;/p&gt;</comment>
                            <comment id="13759196" author="kamrul" created="Thu, 5 Sep 2013 16:19:56 +0000"  >&lt;p&gt;For some test cases (such as input16.q), Kryo failed to find the class. Although the jar is already in its class path. I debugged into Kryo and found it uses getClass().getClassLoader(). I changed it to getContextClassLoader() and it resolved the issue. In this respect, should we ask kayo to change its code? or we need to make sure the jar should be available through getClassLoader().&lt;/p&gt;

&lt;p&gt;I made the following code change at line 105 of src/com/esotericsoftware/kryo/Kryo.java&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private ClassLoader classLoader = getClass().getClassLoader();&lt;br/&gt;
+       private ClassLoader classLoader = Thread.currentThread().getContextClassLoader();&lt;/li&gt;
&lt;/ul&gt;


</comment>
                            <comment id="13759216" author="ashutoshc" created="Thu, 5 Sep 2013 16:44:37 +0000"  >&lt;p&gt;Nice find &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kamrul&quot; class=&quot;user-hover&quot; rel=&quot;kamrul&quot;&gt;Mohammad Kamrul Islam&lt;/a&gt; ! &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=romixlev&quot; class=&quot;user-hover&quot; rel=&quot;romixlev&quot;&gt;Leo Romanoff&lt;/a&gt; Will you consider fixing this in Kryo?&lt;/p&gt;</comment>
                            <comment id="13759306" author="romixlev" created="Thu, 5 Sep 2013 18:47:57 +0000"  >&lt;p&gt;Yes, we could consider this. Could you please file an issue at: &lt;a href=&quot;https://code.google.com/p/kryo/issues/list?&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://code.google.com/p/kryo/issues/list?&lt;/a&gt;&lt;br/&gt;
What I&apos;m wondering about is the fact that Kryo is used in many multi-threaded apps, but nobody complained so far. I think the easiest workaround is probably to allocate ThreadLocal Kryo instances or using something like object pooling Kryo of instances and using it by a thread pool where each worker thread has all required classes on the classpath. Would such a workaround solve your problems?&lt;/p&gt;</comment>
                            <comment id="13759335" author="romixlev" created="Thu, 5 Sep 2013 19:15:07 +0000"  >&lt;p&gt;Actually, Kryo provides a setClassLoader(classloader) method. So, in principle, your thread only needs to call&lt;br/&gt;
kryo.setClassLoader(Thread.currentThread().getContextClassLoader()) before doing any (de)serialization.&lt;/p&gt;</comment>
                            <comment id="13759367" author="kamrul" created="Thu, 5 Sep 2013 19:51:23 +0000"  >&lt;p&gt;Let me try with that.&lt;br/&gt;
I will update you.&lt;/p&gt;</comment>
                            <comment id="13759437" author="kamrul" created="Thu, 5 Sep 2013 20:50:24 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=romixlev&quot; class=&quot;user-hover&quot; rel=&quot;romixlev&quot;&gt;Leo Romanoff&lt;/a&gt;yes it works. In that case, I will upload a new patch soon.&lt;/p&gt;
</comment>
                            <comment id="13759508" author="kamrul" created="Thu, 5 Sep 2013 21:51:12 +0000"  >&lt;p&gt;New patch includes two things:&lt;br/&gt;
1. Setting ContextClassLoader for Kryo. &lt;br/&gt;
2. Modularize the Kryo object creation.&lt;/p&gt;</comment>
                            <comment id="13759634" author="kamrul" created="Thu, 5 Sep 2013 23:43:27 +0000"  >&lt;p&gt;This patch is based on patch 10.&lt;br/&gt;
The previous one was based on patch 11. I came to know that patch 10 has fewer failures.&lt;/p&gt;

&lt;p&gt;Still working on  similar issue for -ve test case.&lt;br/&gt;
udfnull.q&lt;/p&gt;</comment>
                            <comment id="13759955" author="hiveqa" created="Fri, 6 Sep 2013 05:37:55 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12601719/HIVE-1511.13.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12601719/HIVE-1511.13.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 57 failed/errored test(s), 3084 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.ql.parse.TestParse.testParse_input2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_cast1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input8
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_ppd_key_range
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby5
org.apache.hive.hcatalog.fileformats.TestOrcDynamicPartitioned.testHCatDynamicPartitionedTable
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join4
org.apache.hcatalog.listener.TestMsgBusConnection.testConnection
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input7
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join8
org.apache.hive.hcatalog.mapreduce.TestSequenceFileReadWrite.testSequenceTableWriteRead
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testxpath
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_part1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input4
org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned.testHCatPartitionedTable
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample1
org.apache.hive.hcatalog.mapreduce.TestSequenceFileReadWrite.testTextTableWriteRead
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join7
org.apache.hadoop.hive.ql.parse.TestParse.testParse_subq
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input20
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testsequencefile
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf_when
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testxpath2
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_pushdown
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_ppd_key_ranges
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample7
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input6
org.apache.hive.hcatalog.mapreduce.TestSequenceFileReadWrite.testSequenceTableWriteReadMR
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_case_sensitivity
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input9
org.apache.hive.hcatalog.mapreduce.TestSequenceFileReadWrite.testTextTableWriteReadMR
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_udfnull
org.apache.hadoop.hive.ql.parse.TestParse.testParse_union
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join6
org.apache.hive.hcatalog.listener.TestMsgBusConnection.testConnection
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_external_table_ppd
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf_case
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/636/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/636/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/636/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/636/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 57 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13760025" author="hiveqa" created="Fri, 6 Sep 2013 07:45:51 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12601719/HIVE-1511.13.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12601719/HIVE-1511.13.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 59 failed/errored test(s), 3084 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.ql.parse.TestParse.testParse_input2
org.apache.hive.hcatalog.pig.TestOrcHCatLoader.testReadDataBasic
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_cast1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input8
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_ppd_key_range
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input7
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join8
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testxpath
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample5
org.apache.hive.hcatalog.mapreduce.TestSequenceFileReadWrite.testSequenceTableWriteRead
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_part1
org.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join2
org.apache.hive.hcatalog.pig.TestOrcHCatLoader.testReadPartitionedBasic
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample1
org.apache.hive.hcatalog.mapreduce.TestSequenceFileReadWrite.testTextTableWriteRead
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join7
org.apache.hive.hcatalog.pig.TestOrcHCatLoader.testProjectionsBasic
org.apache.hadoop.hive.ql.parse.TestParse.testParse_subq
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input20
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testsequencefile
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf_when
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testxpath2
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_pushdown
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_ppd_key_ranges
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample7
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input6
org.apache.hive.hcatalog.mapreduce.TestSequenceFileReadWrite.testSequenceTableWriteReadMR
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_case_sensitivity
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input9
org.apache.hive.hcatalog.mapreduce.TestSequenceFileReadWrite.testTextTableWriteReadMR
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_udfnull
org.apache.hadoop.hive.ql.parse.TestParse.testParse_union
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join5
org.apache.hive.hcatalog.pig.TestHCatLoader.testGetInputBytes
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input1
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_external_table_ppd
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby1
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf_case
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/637/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/637/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/637/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/637/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 59 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13760074" author="kamrul" created="Fri, 6 Sep 2013 09:07:15 +0000"  >&lt;p&gt;Found the reason of &apos;udfnull.q&apos; failure. This is a negative test case. With Kryo, it failed early with exit code &apos;1&apos;. Whereas in existing java-based serialization , it failed with exit code &apos;2&apos;.&lt;/p&gt;

&lt;p&gt;If I change the exit code in  udfnull.q.out, the test case passes.&lt;br/&gt;
Do you see any issue with this?&lt;/p&gt;

&lt;p&gt;The diff of my proposed changes:&lt;/p&gt;

&lt;p&gt;diff --git a/ql/src/test/results/clientnegative/udfnull.q.out b/ql/src/test/results/clientnegative/udfnull.q.out&lt;/p&gt;

&lt;p&gt;-Execution failed with exit status: 2&lt;br/&gt;
+Execution failed with exit status: 1&lt;/p&gt;

&lt;p&gt;-FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask&lt;br/&gt;
+FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask&lt;/p&gt;</comment>
                            <comment id="13760265" author="ashutoshc" created="Fri, 6 Sep 2013 15:28:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt; For HBase tests, we can make RowScehma non-transient, but can keep ObjectInspector within ColumnInfo transient, that should do the trick?&lt;/p&gt;</comment>
                            <comment id="13760276" author="brocknoland" created="Fri, 6 Sep 2013 15:35:21 +0000"  >&lt;p&gt;Mohammad, I don&apos;t that change works. udfnull fails the error below which is related to kryo.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; [junit] Exception in thread &quot;main&quot; com.esotericsoftware.kryo.KryoException: Unable to find class: org.apache.hadoop.hive.contrib.udf.example.UDFExampleArraySum
 [junit] Serialization trace:
 [junit] udfClass (org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge)
 [junit] genericUDF (org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)
 [junit] colList (org.apache.hadoop.hive.ql.plan.SelectDesc)
 [junit] conf (org.apache.hadoop.hive.ql.exec.SelectOperator)
 [junit] childOperators (org.apache.hadoop.hive.ql.exec.TableScanOperator)
 [junit] aliasToWork (org.apache.hadoop.hive.ql.plan.MapWork)
 [junit] mapWork (org.apache.hadoop.hive.ql.plan.MapredWork)
 [junit] 	at com.esotericsoftware.kryo.util.DefaultClassResolver.readName(DefaultClassResolver.java:138)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13760278" author="brocknoland" created="Fri, 6 Sep 2013 15:35:39 +0000"  >&lt;p&gt;Ashutosh, IIRC that will cause some failures in the cli tests but it&apos;s worth a shot..&lt;/p&gt;</comment>
                            <comment id="13760280" author="brocknoland" created="Fri, 6 Sep 2013 15:36:06 +0000"  >&lt;p&gt;Got the udfnull error message here: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-Build-637/failed/TestNegativeCliDriver-nopart_insert.q-join_nonexistent_part.q-input41.q-and-489-more/ant-test.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-Build-637/failed/TestNegativeCliDriver-nopart_insert.q-join_nonexistent_part.q-input41.q-and-489-more/ant-test.txt&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13760335" author="ashutoshc" created="Fri, 6 Sep 2013 16:36:35 +0000"  >&lt;p&gt;I built on top of .13 patch. Essentially I refactored GenericUDFBridge class so that it no longer has udfclass field in it. This made udfnull.q to pass. Only remaining fails are now 4 hbase tests. &lt;/p&gt;</comment>
                            <comment id="13760336" author="ashutoshc" created="Fri, 6 Sep 2013 16:37:02 +0000"  >&lt;p&gt;Marking PA to have HIVE QA run on it.&lt;/p&gt;</comment>
                            <comment id="13760515" author="kamrul" created="Fri, 6 Sep 2013 18:57:57 +0000"  >&lt;p&gt;As per &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt;, there are 4 hbase-handler test cases are failing.&lt;/p&gt;

&lt;p&gt;Are any of you working on those?&lt;/p&gt;

&lt;p&gt;Otherwise, I can give a try.&lt;/p&gt;</comment>
                            <comment id="13760522" author="brocknoland" created="Fri, 6 Sep 2013 19:08:35 +0000"  >&lt;p&gt;I am not...thank you for your work on this!&lt;/p&gt;</comment>
                            <comment id="13760717" author="hiveqa" created="Fri, 6 Sep 2013 22:48:16 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12601845/HIVE-1511.14.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12601845/HIVE-1511.14.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 56 failed/errored test(s), 3064 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.ql.parse.TestParse.testParse_input2
org.apache.hive.hcatalog.pig.TestOrcHCatLoader.testReadDataBasic
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_cast1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input8
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_ppd_key_range
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input3
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataBasic
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input7
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join8
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testxpath
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_part1
org.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join2
org.apache.hive.hcatalog.pig.TestOrcHCatLoader.testReadPartitionedBasic
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample1
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join7
org.apache.hive.hcatalog.pig.TestOrcHCatLoader.testProjectionsBasic
org.apache.hadoop.hive.metastore.TestRetryingHMSHandler.testRetryingHMSHandler
org.apache.hadoop.hive.ql.parse.TestParse.testParse_subq
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input5
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input20
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testsequencefile
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf_when
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input_testxpath2
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_pushdown
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_ppd_key_ranges
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample7
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_case_sensitivity
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample2
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input9
org.apache.hadoop.hive.ql.parse.TestParse.testParse_union
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join5
org.apache.hive.hcatalog.pig.TestHCatLoader.testGetInputBytes
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join6
org.apache.hadoop.hive.ql.parse.TestParse.testParse_input1
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_external_table_ppd
org.apache.hadoop.hive.ql.parse.TestParse.testParse_sample4
org.apache.hadoop.hive.ql.parse.TestParse.testParse_join3
org.apache.hadoop.hive.ql.parse.TestParse.testParse_groupby1
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic
org.apache.hadoop.hive.ql.parse.TestParse.testParse_udf_case
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/649/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/649/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/649/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/649/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 56 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13761131" author="kamrul" created="Sat, 7 Sep 2013 21:59:32 +0000"  >&lt;p&gt;Updates:&lt;br/&gt;
Mixed news. &lt;br/&gt;
I was able to resolve the failed 5 hbase test cases after this modification in Operator.java.&lt;/p&gt;

&lt;p&gt;Form &lt;br/&gt;
private transient RowSchema rowSchema;&lt;br/&gt;
To&lt;br/&gt;
private RowSchema rowSchema;&lt;/p&gt;

&lt;p&gt;Basically I took out the transient from declaration.&lt;/p&gt;


&lt;p&gt;Although some failed testcases with NPE are resolved, it caused other testcases to fail. The common error message is missing of no-arg constructor.&lt;/p&gt;

&lt;p&gt;Two such examples,&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Exception in thread &quot;main&quot; com.esotericsoftware.kryo.KryoException: Class cannot be created (missing no-arg constructor): org.apache.hadoop.hive.serde2.objectinspector.StandardMapObjectInspector&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Exception in thread &quot;main&quot; com.esotericsoftware.kryo.KryoException: Class cannot be created (missing no-arg constructor): org.apache.hadoop.hive.serde2.objectinspector.StandardMapObjectInspector &lt;/p&gt;

&lt;p&gt;I know we talked about these (such as making transient or not). &lt;br/&gt;
Do you have any suggestion?&lt;/p&gt;
</comment>
                            <comment id="13761135" author="brocknoland" created="Sat, 7 Sep 2013 22:30:49 +0000"  >&lt;p&gt;Hey Mohammad,&lt;/p&gt;

&lt;p&gt;Yes, that is the change I made in patch 11. Ashutosh and I discussed this above and feel the best way forward is to change Utilities.setColumnNameList where RowSchema is required so as to keep RowSchema transient. One way to implement this would be to copy out the information required by Utilities.setColumnNameList in Operator.setRowSchema().&lt;/p&gt;

&lt;p&gt;Also FWIW I have commented on some Kryo 2.22 release discussions which are on-going.&lt;/p&gt;</comment>
                            <comment id="13761214" author="ashutoshc" created="Sun, 8 Sep 2013 07:10:20 +0000"  >&lt;p&gt;Wuhoo... finally got all the tests to pass with .16 patch Phabricator link at : &lt;a href=&quot;https://reviews.facebook.net/D12789&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12789&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I made serialization choice configurable, so now both kryo as well java-xml serialization is supported. This makes TestParse to succeed as well.&lt;/p&gt;</comment>
                            <comment id="13761238" author="hiveqa" created="Sun, 8 Sep 2013 09:22:32 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12602037/HIVE-1511.16.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12602037/HIVE-1511.16.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 3086 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.ql.security.TestAuthorizationPreEventListener.testListener
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/659/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/659/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/659/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/659/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13761498" author="ashutoshc" created="Sun, 8 Sep 2013 18:17:39 +0000"  >&lt;p&gt;New patch addressing Brock&apos;s review comments.&lt;/p&gt;</comment>
                            <comment id="13761523" author="hiveqa" created="Sun, 8 Sep 2013 20:28:18 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12602061/HIVE-1511.17.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12602061/HIVE-1511.17.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 3 failed/errored test(s), 3086 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hive.hcatalog.fileformats.TestOrcDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask
org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned.testHCatPartitionedTable
org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/663/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/663/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/663/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/663/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 3 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13761526" author="romixlev" created="Sun, 8 Sep 2013 20:59:51 +0000"  >&lt;p&gt;It is very cool that you got so far with Kryo! Could you report about the performance of this new Kryo-based approach vs the old one based on XML? Is it improved? How much faster/slower is it? &lt;/p&gt;

&lt;p&gt;If there is a need to improve it further, there are some further tricks that could be used to make Kryo even faster. You already reuse ThreadLocal Kryo instances which is good. But to further improve performance you could:&lt;br/&gt;
1) Start using Unsafe-based streams (e.g. UnsafeInput and UnsafeOutput. Or their direct-memory based versions, e.g.in case you want to write directly into off-heap memory). This can improve performance very significantly (e.g. 2X-30X). &lt;br/&gt;
2) Pre-register all of the classes. This may reduce the size of serialized representation and also improves performance a bi.&lt;/p&gt;

&lt;p&gt;-Leo&lt;/p&gt;</comment>
                            <comment id="13761532" author="ashutoshc" created="Sun, 8 Sep 2013 21:42:22 +0000"  >&lt;p&gt;Thanks Leo for taking a look. As I noted in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1511?focusedCommentId=13713048&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13713048&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1511?focusedCommentId=13713048&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13713048&lt;/a&gt; we see substantial gains in serialization times. Also, apart from performance, Brock has found that xml based serialization has issues on other platforms. See, &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1511?focusedCommentId=13755143&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13755143&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1511?focusedCommentId=13755143&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13755143&lt;/a&gt; So, in addition to performance we want to move to Kryo for that as well.&lt;/p&gt;

&lt;p&gt;For your suggestions w.r.t further improving perf, we will start taking look at those after this one gets in.&lt;/p&gt;</comment>
                            <comment id="13761861" author="ashutoshc" created="Mon, 9 Sep 2013 13:58:02 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Brock for review and helping fix test cases. Thanks, Mohammad for tracking down some nasty issues!&lt;/p&gt;</comment>
                            <comment id="13761981" author="hudson" created="Mon, 9 Sep 2013 16:17:57 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #89 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/89/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/89/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1511&quot; title=&quot;Hive plan serialization is slow&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1511&quot;&gt;&lt;del&gt;HIVE-1511&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Summary: Hive Plan Serialization&lt;/p&gt;

&lt;p&gt;Test Plan: Regression test suite&lt;/p&gt;

&lt;p&gt;Reviewers: brock&lt;/p&gt;

&lt;p&gt;Reviewed By: brock&lt;/p&gt;

&lt;p&gt;Differential Revision: &lt;a href=&quot;https://reviews.facebook.net/D12789&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12789&lt;/a&gt; (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521110&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521110&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/contrib/src/java/org/apache/hadoop/hive/contrib/udtf/example/GenericUDTFCount2.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/contrib/src/java/org/apache/hadoop/hive/contrib/udtf/example/GenericUDTFExplode2.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/pom.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ivy/ivysettings.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ivy/libraries.properties&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/build.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/ivy.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ColumnInfo.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ExprNodeColumnEvaluator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableDummyOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/RowSchema.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapRedTask.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/BucketingSortingCtx.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/GenMRSkewJoinProcessor.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/LocalMapJoinProcFactory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/SortMergeJoinTaskDispatcher.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/QBJoinTree.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeGenericFuncDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/MapWork.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/MapredWork.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/PartitionDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFnGrams.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFArray.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBridge.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFFormatNumber.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFIndex.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFNamedStruct.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFStruct.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToUnixTimeStamp.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFExplode.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFJSONTuple.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFParseUrlTuple.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFStack.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/exec/TestPlan.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/case_sensitivity.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/cast1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input20.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input8.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input9.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_part1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testxpath.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testxpath2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join8.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/subq.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf_case.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf_when.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/union.q.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13762000" author="hudson" created="Mon, 9 Sep 2013 16:31:13 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #157 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/157/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/157/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1511&quot; title=&quot;Hive plan serialization is slow&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1511&quot;&gt;&lt;del&gt;HIVE-1511&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Summary: Hive Plan Serialization&lt;/p&gt;

&lt;p&gt;Test Plan: Regression test suite&lt;/p&gt;

&lt;p&gt;Reviewers: brock&lt;/p&gt;

&lt;p&gt;Reviewed By: brock&lt;/p&gt;

&lt;p&gt;Differential Revision: &lt;a href=&quot;https://reviews.facebook.net/D12789&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12789&lt;/a&gt; (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521110&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521110&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/contrib/src/java/org/apache/hadoop/hive/contrib/udtf/example/GenericUDTFCount2.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/contrib/src/java/org/apache/hadoop/hive/contrib/udtf/example/GenericUDTFExplode2.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/pom.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ivy/ivysettings.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ivy/libraries.properties&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/build.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/ivy.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ColumnInfo.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ExprNodeColumnEvaluator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableDummyOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/RowSchema.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapRedTask.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/BucketingSortingCtx.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/GenMRSkewJoinProcessor.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/LocalMapJoinProcFactory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/SortMergeJoinTaskDispatcher.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/QBJoinTree.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeGenericFuncDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/MapWork.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/MapredWork.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/PartitionDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFnGrams.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFArray.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBridge.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFFormatNumber.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFIndex.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFNamedStruct.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFStruct.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToUnixTimeStamp.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFExplode.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFJSONTuple.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFParseUrlTuple.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFStack.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/exec/TestPlan.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/case_sensitivity.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/cast1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input20.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input8.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input9.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_part1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testxpath.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testxpath2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join8.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/subq.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf_case.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf_when.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/union.q.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13763239" author="hudson" created="Tue, 10 Sep 2013 17:12:39 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-h0.21 #2322 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2322/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2322/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1511&quot; title=&quot;Hive plan serialization is slow&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1511&quot;&gt;&lt;del&gt;HIVE-1511&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Summary: Hive Plan Serialization&lt;/p&gt;

&lt;p&gt;Test Plan: Regression test suite&lt;/p&gt;

&lt;p&gt;Reviewers: brock&lt;/p&gt;

&lt;p&gt;Reviewed By: brock&lt;/p&gt;

&lt;p&gt;Differential Revision: &lt;a href=&quot;https://reviews.facebook.net/D12789&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12789&lt;/a&gt; (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521110&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521110&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/contrib/src/java/org/apache/hadoop/hive/contrib/udtf/example/GenericUDTFCount2.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/contrib/src/java/org/apache/hadoop/hive/contrib/udtf/example/GenericUDTFExplode2.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/pom.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ivy/ivysettings.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ivy/libraries.properties&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/build.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/ivy.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ColumnInfo.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ExprNodeColumnEvaluator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableDummyOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/RowSchema.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapRedTask.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/BucketingSortingCtx.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/GenMRSkewJoinProcessor.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/LocalMapJoinProcFactory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/SortMergeJoinTaskDispatcher.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/QBJoinTree.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeGenericFuncDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/MapWork.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/MapredWork.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/PartitionDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFnGrams.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFArray.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBridge.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFFormatNumber.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFIndex.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFNamedStruct.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFStruct.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToUnixTimeStamp.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFExplode.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFJSONTuple.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFParseUrlTuple.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFStack.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/exec/TestPlan.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/case_sensitivity.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/cast1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input20.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input8.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input9.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_part1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testxpath.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testxpath2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join8.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/subq.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf_case.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf_when.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/union.q.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13763252" author="hudson" created="Tue, 10 Sep 2013 17:14:41 +0000"  >&lt;p&gt;ABORTED: Integrated in Hive-trunk-hadoop2 #419 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/419/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/419/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1511&quot; title=&quot;Hive plan serialization is slow&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1511&quot;&gt;&lt;del&gt;HIVE-1511&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Summary: Hive Plan Serialization&lt;/p&gt;

&lt;p&gt;Test Plan: Regression test suite&lt;/p&gt;

&lt;p&gt;Reviewers: brock&lt;/p&gt;

&lt;p&gt;Reviewed By: brock&lt;/p&gt;

&lt;p&gt;Differential Revision: &lt;a href=&quot;https://reviews.facebook.net/D12789&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12789&lt;/a&gt; (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521110&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521110&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/contrib/src/java/org/apache/hadoop/hive/contrib/udtf/example/GenericUDTFCount2.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/contrib/src/java/org/apache/hadoop/hive/contrib/udtf/example/GenericUDTFExplode2.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/pom.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ivy/ivysettings.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ivy/libraries.properties&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/build.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/ivy.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ColumnInfo.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ExprNodeColumnEvaluator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableDummyOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/RowSchema.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapRedTask.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/BucketingSortingCtx.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/GenMRSkewJoinProcessor.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/LocalMapJoinProcFactory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/SortMergeJoinTaskDispatcher.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/QBJoinTree.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeGenericFuncDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/MapWork.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/MapredWork.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/PartitionDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFnGrams.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFArray.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBridge.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFFormatNumber.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFIndex.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFNamedStruct.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFStruct.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToUnixTimeStamp.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFExplode.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFJSONTuple.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFParseUrlTuple.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDTFStack.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/QTestUtil.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/exec/TestPlan.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/case_sensitivity.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/cast1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input20.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input8.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input9.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_part1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testxpath.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testxpath2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join8.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/subq.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf_case.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf_when.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/union.q.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13783990" author="chenchun" created="Wed, 2 Oct 2013 14:18:21 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt; Kryo-2.22 is released yesterday, see &lt;a href=&quot;http://search.maven.org/#browse%7C1356509043&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://search.maven.org/#browse%7C1356509043&lt;/a&gt;. I think it is better to use a release version rather than a snapshop version. Sometimes I failed to compile hive due to bad network to download a latest snapshot version of kryo.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[ivy:resolve] 	  https:&lt;span class=&quot;code-comment&quot;&gt;//oss.sonatype.org/content/repositories/snapshots/com/esotericsoftware/kryo/kryo/2.22-SNAPSHOT/kryo-2.22-SNAPSHOT.pom
&lt;/span&gt;[ivy:resolve] 	  -- artifact com.esotericsoftware.kryo#kryo;2.22-SNAPSHOT!kryo.jar:
[ivy:resolve] 	  https:&lt;span class=&quot;code-comment&quot;&gt;//oss.sonatype.org/content/repositories/snapshots/com/esotericsoftware/kryo/kryo/2.22-SNAPSHOT/kryo-2.22-SNAPSHOT.jar
&lt;/span&gt;[ivy:resolve] 		::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve] 		::          UNRESOLVED DEPENDENCIES         ::
[ivy:resolve] 		::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve] 		:: com.esotericsoftware.kryo#kryo;2.22-SNAPSHOT: not found
[ivy:resolve] 		::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve] 
[ivy:resolve] :: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS
[ivy:resolve] :::: ERRORS
[ivy:resolve] 	Server access Error: Connection timed out url=https:&lt;span class=&quot;code-comment&quot;&gt;//oss.sonatype.org/content/repositories/snapshots/com/esotericsoftware/kryo/kryo/2.22-SNAPSHOT/maven-metadata.xml
&lt;/span&gt;
BUILD FAILED
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13784034" author="brocknoland" created="Wed, 2 Oct 2013 14:52:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5422&quot; title=&quot;Upgrade Kyro to 2.22 now that it is released&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5422&quot;&gt;&lt;del&gt;HIVE-5422&lt;/del&gt;&lt;/a&gt; will upgrade Kryo.&lt;/p&gt;</comment>
                            <comment id="13875837" author="lefty@hortonworks.com" created="Sun, 19 Jan 2014 08:24:25 +0000"  >&lt;p&gt;This patch adds hive.plan.serialization.format to HiveConf.java and hive-default.xml.template, so I&apos;ll put it in the wiki for Hive 0.13.0.&lt;/p&gt;

&lt;p&gt;The release note (&quot;Any 3rd party UDFs used must be declared as public classes&quot;) should probably go in the wiki somewhere too.&lt;/p&gt;</comment>
                            <comment id="14052819" author="lefty@hortonworks.com" created="Sat, 5 Jul 2014 08:08:44 +0000"  >&lt;p&gt;&lt;b&gt;hive.plan.serialization.format&lt;/b&gt; is documented in the wiki here:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.plan.serialization.format&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Configuration Properties &amp;#8211; hive.plan.serialization.format &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The release note (&quot;Any 3rd party UDFs used must be declared as public classes&quot;) could be added to these wikidocs:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/HivePlugins#HivePlugins-CreatingCustomUDFs&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Hive Plugins &amp;#8211; Creating Custom UDFs &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-CreateFunction&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;DDL &amp;#8211; Create Function &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Question:  Does the release note apply in general, or only in releases 0.13.0 and later?&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12658638">HIVE-4885</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12663262">HIVE-5064</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12667916">HIVE-5263</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                            <outwardlinks description="breaks">
                                        <issuelink>
            <issuekey id="12683982">HIVE-6005</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12667823">HIVE-5257</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12596468" name="HIVE-1511-wip.patch" size="20262" author="ashutoshc" created="Wed, 7 Aug 2013 00:35:03 +0000"/>
                            <attachment id="12596667" name="HIVE-1511-wip2.patch" size="14942" author="ashutoshc" created="Wed, 7 Aug 2013 18:00:47 +0000"/>
                            <attachment id="12597530" name="HIVE-1511-wip3.patch" size="33455" author="ashutoshc" created="Mon, 12 Aug 2013 18:53:13 +0000"/>
                            <attachment id="12598279" name="HIVE-1511-wip4.patch" size="36041" author="brocknoland" created="Thu, 15 Aug 2013 19:35:04 +0000"/>
                            <attachment id="12601094" name="HIVE-1511.10.patch" size="49948" author="ashutoshc" created="Tue, 3 Sep 2013 00:55:47 +0000"/>
                            <attachment id="12601228" name="HIVE-1511.11.patch" size="64505" author="brocknoland" created="Tue, 3 Sep 2013 20:25:28 +0000"/>
                            <attachment id="12601694" name="HIVE-1511.12.patch" size="65040" author="kamrul" created="Thu, 5 Sep 2013 21:51:12 +0000"/>
                            <attachment id="12601719" name="HIVE-1511.13.patch" size="52500" author="kamrul" created="Thu, 5 Sep 2013 23:43:27 +0000"/>
                            <attachment id="12601845" name="HIVE-1511.14.patch" size="54896" author="ashutoshc" created="Fri, 6 Sep 2013 16:36:35 +0000"/>
                            <attachment id="12602037" name="HIVE-1511.16.patch" size="380002" author="ashutoshc" created="Sun, 8 Sep 2013 07:10:20 +0000"/>
                            <attachment id="12602061" name="HIVE-1511.17.patch" size="382044" author="ashutoshc" created="Sun, 8 Sep 2013 18:17:39 +0000"/>
                            <attachment id="12598462" name="HIVE-1511.4.patch" size="36041" author="brocknoland" created="Fri, 16 Aug 2013 13:40:17 +0000"/>
                            <attachment id="12598520" name="HIVE-1511.5.patch" size="37903" author="brocknoland" created="Fri, 16 Aug 2013 19:43:28 +0000"/>
                            <attachment id="12598981" name="HIVE-1511.6.patch" size="44181" author="brocknoland" created="Tue, 20 Aug 2013 17:10:12 +0000"/>
                            <attachment id="12598996" name="HIVE-1511.7.patch" size="44507" author="brocknoland" created="Tue, 20 Aug 2013 18:17:23 +0000"/>
                            <attachment id="12599211" name="HIVE-1511.8.patch" size="46410" author="brocknoland" created="Wed, 21 Aug 2013 15:45:29 +0000"/>
                            <attachment id="12600944" name="HIVE-1511.9.patch" size="49626" author="brocknoland" created="Sat, 31 Aug 2013 12:13:38 +0000"/>
                            <attachment id="12592411" name="HIVE-1511.patch" size="6193" author="ashutoshc" created="Mon, 15 Jul 2013 21:24:57 +0000"/>
                            <attachment id="12600928" name="HIVE-1511.wip.9.patch" size="49626" author="kamrul" created="Sat, 31 Aug 2013 05:32:07 +0000"/>
                            <attachment id="12600360" name="KryoHiveTest.java" size="1637" author="kamrul" created="Wed, 28 Aug 2013 09:32:46 +0000"/>
                            <attachment id="12600938" name="failedPlan.xml" size="241198" author="kamrul" created="Sat, 31 Aug 2013 08:39:17 +0000"/>
                            <attachment id="12600359" name="generated_plan.xml" size="261912" author="kamrul" created="Wed, 28 Aug 2013 09:32:46 +0000"/>
                            <attachment id="12600358" name="run.sh" size="717" author="kamrul" created="Wed, 28 Aug 2013 09:32:46 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>23.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 4 Aug 2010 18:23:58 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42465</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10342"><![CDATA[Incompatible change]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 29 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08o5z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>48514</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Any 3rd party UDFs used must be declared as public classes.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1512] Need to get hive_hbase-handler to work with hbase versions 0.20.4  0.20.5 and cloudera CDH3 version</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1512</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;the current trunk  hive_hbase-handler only works with hbase 0.20.3, we need to get it to work with hbase versions 0.20.4  0.20.5 and cloudera CDH3 version&lt;/p&gt;</description>
                <environment></environment>
        <key id="12470850">HIVE-1512</key>
            <summary>Need to get hive_hbase-handler to work with hbase versions 0.20.4  0.20.5 and cloudera CDH3 version</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="bkm">Basab Maulik</assignee>
                                    <reporter username="jimmy888">Jimmy Hu</reporter>
                        <labels>
                    </labels>
                <created>Thu, 5 Aug 2010 00:06:08 +0000</created>
                <updated>Fri, 16 Dec 2011 23:59:28 +0000</updated>
                            <resolved>Mon, 23 Aug 2010 17:11:05 +0000</resolved>
                                    <version>0.7.0</version>
                                    <fixVersion>0.7.0</fixVersion>
                                    <component>HBase Handler</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                    <timeoriginalestimate seconds="172800">48h</timeoriginalestimate>
                            <timeestimate seconds="172800">48h</timeestimate>
                                        <comments>
                            <comment id="12895479" author="jimmy888" created="Thu, 5 Aug 2010 00:10:24 +0000"  >&lt;p&gt;patch for 3 files to make the hive-hbase-handler to be compatible with 0.20.4 and 0.20.5 and cloudera CDH3  hbase.&lt;/p&gt;</comment>
                            <comment id="12895829" author="jvs" created="Thu, 5 Aug 2010 21:52:12 +0000"  >&lt;p&gt;This patch can&apos;t be applied until we actually upgrade the Hbase libs, since it is incompatible with 0.20.3.  I&apos;ll link it to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1235&quot; title=&quot;use Ivy for fetching HBase dependencies&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1235&quot;&gt;&lt;del&gt;HIVE-1235&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Also, when supplying patches, please base them off of hive trunk (not off of a subdirectory).&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;</comment>
                            <comment id="12897948" author="bkm" created="Thu, 12 Aug 2010 21:03:07 +0000"  >&lt;p&gt;Quick clarification, the current code works fine against HBase 0.20.5 which I tested (and presumably against 0.20.4 as well). Be sure to use the correct version of the ZooKeeper libs, 3.2.2.&lt;/p&gt;

&lt;p&gt;A patch is needed to get it to build with hbase 0.89.0 snapshots.&lt;/p&gt;</comment>
                            <comment id="12898755" author="bkm" created="Sun, 15 Aug 2010 21:35:29 +0000"  >&lt;p&gt;This patch allows the HBase handler to work with both the hbase 0.20.x/ zookeeper 3.2.2 libraries and the hbase 0.89.0 snapshot / zk 3.3.1 libraries.&lt;/p&gt;

&lt;p&gt;The patch changes code to use HBase client API&apos;s which are not deprecated or removed in 0.89.0. Primarily we consistently use a column family / column qualifier pair for HBase client api&apos;s instead of  &quot;&amp;lt;column-family&amp;gt;:&amp;lt;column-qualifier&amp;gt;&quot; colon-separated form allowed in the 0.20.x apis.&lt;/p&gt;

&lt;p&gt;Tests pass with 0.20.3, 0.20.5 / zk 3.2.2 and 0.89.0 snapshot / zk 3.3.1.&lt;/p&gt;</comment>
                            <comment id="12898761" author="hbasereviewboard" created="Sun, 15 Aug 2010 22:57:48 +0000"  >&lt;p&gt;Message from: bkm.hadoop@gmail.com&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/660/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/660/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for Hive Developers and John Sichi.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Fixes Hive HBase storage handler to work with both HBase 0.89.0 SNAPSHOT releases and the 0.20.x releases.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1512&quot; title=&quot;Need to get hive_hbase-handler to work with hbase versions 0.20.4  0.20.5 and cloudera CDH3 version&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1512&quot;&gt;&lt;del&gt;HIVE-1512&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/HIVE-1512&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HIVE-1512&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDe.java 985559 &lt;br/&gt;
  trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java 985559 &lt;br/&gt;
  trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java 985559 &lt;br/&gt;
  trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/LazyHBaseRow.java 985559 &lt;br/&gt;
  trunk/hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestHBaseSerDe.java 985559 &lt;br/&gt;
  trunk/hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestLazyHBaseObject.java 985559 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.cloudera.org/r/660/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/660/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;TestHBaseSerDe, TestLazyHBaseObject, TestHBaseCliDriver, TestHBaseMinimrCliDriver tests pass.&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;bkm&lt;/p&gt;

</comment>
                            <comment id="12900495" author="jvs" created="Thu, 19 Aug 2010 22:21:11 +0000"  >&lt;p&gt;+1.  Will commit when tests pass.&lt;/p&gt;</comment>
                            <comment id="12900841" author="bkm" created="Fri, 20 Aug 2010 20:00:30 +0000"  >&lt;p&gt;Thanks John. This is a small change to the patch, fixes a potential NPE. Also, HBase 0.89.x introduces an additional runtime dependency for the tests, guava-r05.jar, I think the Google collections library jar.&lt;/p&gt;</comment>
                            <comment id="12901488" author="jvs" created="Mon, 23 Aug 2010 17:11:04 +0000"  >&lt;p&gt;Committed.  Thanks Basab!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12458734">HIVE-1235</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12452132" name="HIVE-1512.2.patch" size="50417" author="bkm" created="Sun, 15 Aug 2010 21:35:29 +0000"/>
                            <attachment id="12452659" name="HIVE-1512.3.patch" size="50506" author="bkm" created="Fri, 20 Aug 2010 20:00:30 +0000"/>
                            <attachment id="12451284" name="HIVE-1512.patch" size="1961" author="jimmy888" created="Thu, 5 Aug 2010 00:10:24 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 5 Aug 2010 21:52:12 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72863</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 23 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfg7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123153</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1513] hive starter scripts should load admin/user supplied script for configurability</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1513</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;it&apos;s difficult to add environment variables to Hive starter scripts except by modifying the scripts directly. this is undesirable (since they are source code). Hive starter scripts should load a admin supplied shell script for configurability. This would be similar to what hadoop does with hadoop-env.sh&lt;/p&gt;</description>
                <environment></environment>
        <key id="12470878">HIVE-1513</key>
            <summary>hive starter scripts should load admin/user supplied script for configurability</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jsensarma">Joydeep Sen Sarma</assignee>
                                    <reporter username="jsensarma">Joydeep Sen Sarma</reporter>
                        <labels>
                    </labels>
                <created>Thu, 5 Aug 2010 07:59:41 +0000</created>
                <updated>Sat, 17 Dec 2011 00:01:15 +0000</updated>
                            <resolved>Mon, 9 Aug 2010 03:48:06 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                    <component>CLI</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12895698" author="appodictic" created="Thu, 5 Aug 2010 14:31:01 +0000"  >&lt;p&gt;Anything you put in the bin/ext is sourced as part of the bootstrap process. Could you do something like bin/ext/mystuff.sh?&lt;/p&gt;</comment>
                            <comment id="12895959" author="jsensarma" created="Fri, 6 Aug 2010 05:52:32 +0000"  >&lt;p&gt;yes - it&apos;s possible. however a lot of variables etc. are initialized by the time we get to loading ext/&lt;b&gt;.sh. for example we allow HADOOP_HEAPSIZE to be specified via env var. but aside from doing an export before launching the hive script, there&apos;s no way to configure this externally. the ext/&lt;/b&gt; trick wouldn&apos;t work cause it&apos;s comes too late.&lt;/p&gt;

&lt;p&gt;i think this is simple enough - we can just source a conf/hive-env.sh or something of the sort so that admins can provide right values for all these vars based on their requirements via config files.&lt;/p&gt;</comment>
                            <comment id="12896081" author="jsensarma" created="Fri, 6 Aug 2010 16:44:20 +0000"  >&lt;p&gt;simple change to let hive started script include conf/hive-env.sh. a template is provided as an example. ran all tests on 20 and tested by hand that the inclusion works.&lt;/p&gt;</comment>
                            <comment id="12896219" author="jsensarma" created="Sat, 7 Aug 2010 05:18:33 +0000"  >&lt;p&gt;forgot to add one file&lt;/p&gt;</comment>
                            <comment id="12896229" author="nzhang" created="Sat, 7 Aug 2010 06:12:36 +0000"  >&lt;p&gt;Looks good in general. One minor question though. Currently the hive cli also set HADOOP_HEAPSIZE and HADOOP_OPTS right before hadoop is called (in bin/ext/util/execHiveCmd.sh). Should we rename conf/hive-env.sh.template to hive-env.sh and move these two parameter there? &lt;/p&gt;</comment>
                            <comment id="12896231" author="jsensarma" created="Sat, 7 Aug 2010 07:05:47 +0000"  >&lt;p&gt;HADOOP_HEAPSIZE: hive-config.sh only supplies a default. if the admin has specified a value in hive-env - it will be used instead.&lt;br/&gt;
HADOOP_OPTS: seems like it&apos;s appending a specific JVM flag. i agree this doesn&apos;t make sense (the admin should choose whether they want that flag or not). i will post another patch after taking it out.&lt;/p&gt;

&lt;p&gt;not sure about whether we should rename the template to .sh. hadoop-20 seems to have template files only. &lt;/p&gt;</comment>
                            <comment id="12896234" author="jsensarma" created="Sat, 7 Aug 2010 07:45:46 +0000"  >&lt;p&gt;Ning - u are right - i didn&apos;t notice the HEAP setting. in the internal tree - the heap setting is done differently (and i thought that the internal tree does not override these scripts).&lt;/p&gt;

&lt;p&gt;so i have incorporated both the suggestions (don&apos;t set opts/heap). also - the build script needed a slight change to make the .template file part of distribution.&lt;/p&gt;</comment>
                            <comment id="12896269" author="nzhang" created="Sat, 7 Aug 2010 15:56:48 +0000"  >&lt;p&gt;+1. will commit if tests pass. &lt;/p&gt;</comment>
                            <comment id="12896445" author="nzhang" created="Mon, 9 Aug 2010 03:48:06 +0000"  >&lt;p&gt;Committed. Thanks Joydeep!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12451443" name="1513.1.patch" size="1297" author="jsensarma" created="Fri, 6 Aug 2010 16:44:20 +0000"/>
                            <attachment id="12451490" name="1513.2.patch" size="2287" author="jsensarma" created="Sat, 7 Aug 2010 05:18:33 +0000"/>
                            <attachment id="12451494" name="hive-1513.3.patch" size="3977" author="jsensarma" created="Sat, 7 Aug 2010 07:45:46 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 5 Aug 2010 14:31:01 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72862</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 25 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfgf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123154</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1514] Be able to modify a partition&apos;s fileformat and file location information.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1514</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12470944">HIVE-1514</key>
            <summary>Be able to modify a partition&apos;s fileformat and file location information.</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="he yongqiang">He Yongqiang</assignee>
                                    <reporter username="he yongqiang">He Yongqiang</reporter>
                        <labels>
                    </labels>
                <created>Thu, 5 Aug 2010 21:46:47 +0000</created>
                <updated>Thu, 14 Jun 2012 03:42:47 +0000</updated>
                            <resolved>Tue, 10 Aug 2010 20:43:18 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Metastore</component>
                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12896777" author="namit" created="Tue, 10 Aug 2010 06:26:51 +0000"  >&lt;p&gt;+        new String[] &lt;/p&gt;
{ &quot;ALTERTABLE_FILEFORMAT&quot;, &quot;ALTERPARTITION_FILEFORMAR&quot; }
&lt;p&gt;);&lt;/p&gt;


&lt;p&gt;There is a spelling mistake - should be &lt;br/&gt;
new String[] &lt;/p&gt;
{ &quot;ALTERTABLE_FILEFORMAT&quot;, &quot;ALTERPARTITION_FILEFORMAT&quot; }
&lt;p&gt;);&lt;/p&gt;


&lt;p&gt;will result in changing a few log files.&lt;/p&gt;</comment>
                            <comment id="12896979" author="namit" created="Tue, 10 Aug 2010 17:45:05 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;will commit if the tests pass&lt;/p&gt;</comment>
                            <comment id="12897034" author="namit" created="Tue, 10 Aug 2010 20:43:18 +0000"  >&lt;p&gt;Committed. Thanks Yongqiang&lt;/p&gt;</comment>
                            <comment id="12898337" author="ashutoshc" created="Fri, 13 Aug 2010 17:46:20 +0000"  >&lt;p&gt;From jira description and discussions, its not clear to me what changes went in here.&lt;br/&gt;
It will be useful to summarize the use case which this jira satisfies. From cursory look of the patch, it seems following is now possible to do&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ALTER TABLE table_name [partitionSpec] SET LOCATION &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; location&quot;&lt;/span&gt; set fileformat rcfile
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; or some such. If so, is the use case the following: user created some data for a existing hive table externally (meaning through some process outside of hive) and now wants to use it to query from hive. So, she needs to do metadata operation as above (which is now enabled through this patch) ?&lt;/p&gt;</comment>
                            <comment id="12898350" author="he yongqiang" created="Fri, 13 Aug 2010 18:15:59 +0000"  >&lt;p&gt;I updated the wiki page here :&lt;br/&gt;
&lt;a href=&quot;http://wiki.apache.org/hadoop/Hive/LanguageManual/DDL#Alter_Table.2BAC8-Partition_Location&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Hive/LanguageManual/DDL#Alter_Table.2BAC8-Partition_Location&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This only change the metadata. With this patch, you will be able to let the partition point to some external places, and use a new fileformat. If the metadata you specified is correct, you will be able to do that.&lt;/p&gt;</comment>
                            <comment id="12898369" author="jvs" created="Fri, 13 Aug 2010 19:00:02 +0000"  >&lt;p&gt;Yongqiang, for reference doc updates, remember to add a phrase like &quot;(Note:  only available starting with 0.7.0)&quot; so that users of earlier Hive versions know they need to upgrade if they want the feature.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12451377" name="hive-1514.1.patch" size="28491" author="he yongqiang" created="Thu, 5 Aug 2010 21:48:31 +0000"/>
                            <attachment id="12451533" name="hive-1514.2.patch" size="114408" author="he yongqiang" created="Sun, 8 Aug 2010 20:18:04 +0000"/>
                            <attachment id="12451691" name="hive-1514.3.patch" size="114408" author="he yongqiang" created="Tue, 10 Aug 2010 17:38:36 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 10 Aug 2010 06:26:51 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72861</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 24 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfgn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123155</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1515] archive is not working when multiple partitions inside one table are archived.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1515</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;set hive.exec.compress.output = true;&lt;br/&gt;
set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;&lt;br/&gt;
set mapred.min.split.size=256;&lt;br/&gt;
set mapred.min.split.size.per.node=256;&lt;br/&gt;
set mapred.min.split.size.per.rack=256;&lt;br/&gt;
set mapred.max.split.size=256;&lt;/p&gt;

&lt;p&gt;set hive.archive.enabled = true;&lt;/p&gt;

&lt;p&gt;drop table combine_3_srcpart_seq_rc;&lt;/p&gt;

&lt;p&gt;create table combine_3_srcpart_seq_rc (key int , value string) partitioned by (ds string, hr string) stored as sequencefile;&lt;/p&gt;

&lt;p&gt;insert overwrite table combine_3_srcpart_seq_rc partition (ds=&quot;2010-08-03&quot;, hr=&quot;00&quot;) select * from src;&lt;/p&gt;

&lt;p&gt;insert overwrite table combine_3_srcpart_seq_rc partition (ds=&quot;2010-08-03&quot;, hr=&quot;001&quot;) select * from src;&lt;/p&gt;

&lt;p&gt;ALTER TABLE combine_3_srcpart_seq_rc ARCHIVE PARTITION (ds=&quot;2010-08-03&quot;, hr=&quot;00&quot;);&lt;br/&gt;
ALTER TABLE combine_3_srcpart_seq_rc ARCHIVE PARTITION (ds=&quot;2010-08-03&quot;, hr=&quot;001&quot;);&lt;/p&gt;

&lt;p&gt;select key, value, ds, hr from combine_3_srcpart_seq_rc where ds=&quot;2010-08-03&quot; order by key, hr limit 30;&lt;/p&gt;

&lt;p&gt;drop table combine_3_srcpart_seq_rc;&lt;/p&gt;


&lt;p&gt;will fail.&lt;/p&gt;

&lt;p&gt;java.io.IOException: Invalid file name: har:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/combine_3_srcpart_seq_rc/ds=2010-08-03/hr=001/data.har/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/combine_3_srcpart_seq_rc/ds=2010-08-03/hr=001 in har:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/combine_3_srcpart_seq_rc/ds=2010-08-03/hr=00/data.har&lt;/p&gt;

&lt;p&gt;The reason it fails is because:&lt;br/&gt;
there are 2 input paths (one for each partition) for the above query:&lt;br/&gt;
1): har:/Users/heyongqiang/Documents/workspace/Hive-Index/build/ql/test/data/warehouse/combine_3_srcpart_seq_rc/ds=2010-08-03/hr=00/data.har/Users/heyongqiang/Documents/workspace/Hive-Index/build/ql/test/data/warehouse/combine_3_srcpart_seq_rc/ds=2010-08-03/hr=00&lt;br/&gt;
2): har:/Users/heyongqiang/Documents/workspace/Hive-Index/build/ql/test/data/warehouse/combine_3_srcpart_seq_rc/ds=2010-08-03/hr=001/data.har/Users/heyongqiang/Documents/workspace/Hive-Index/build/ql/test/data/warehouse/combine_3_srcpart_seq_rc/ds=2010-08-03/hr=001&lt;br/&gt;
But when doing path.getFileSystem() for these 2 input paths. they both return same one file system instance which points the first caller, in this case which is har:/Users/heyongqiang/Documents/workspace/Hive-Index/build/ql/test/data/warehouse/combine_3_srcpart_seq_rc/ds=2010-08-03/hr=00/data.har&lt;/p&gt;

&lt;p&gt;The reason here is Hadoop&apos;s FileSystem has a global cache, and when trying to load a FileSystem instance from a given path, it only take the path&apos;s scheme and username to lookup the cache. So when we do Path.getFileSystem for the second har path, it actually returns the file system handle for the first path.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12470960">HIVE-1515</key>
            <summary>archive is not working when multiple partitions inside one table are archived.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="he yongqiang">He Yongqiang</reporter>
                        <labels>
                    </labels>
                <created>Fri, 6 Aug 2010 05:56:53 +0000</created>
                <updated>Fri, 13 Aug 2010 01:10:55 +0000</updated>
                                            <version>0.7.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="12896755" author="hbasereviewboard" created="Tue, 10 Aug 2010 01:11:19 +0000"  >&lt;p&gt;Message from: &quot;Yongqiang He&quot; &amp;lt;heyongqiangict@gmail.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/598/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/598/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for Hive Developers.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;archive is not working when multiple partitions inside one table are archived.&lt;/p&gt;


&lt;p&gt;This addresses bug hive-1515.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/hive-1515&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/hive-1515&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 982490 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/archive_2.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/archive_2.q.out PRE-CREATION &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.cloudera.org/r/598/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/598/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Yongqiang&lt;/p&gt;

</comment>
                            <comment id="12897533" author="pauly" created="Thu, 12 Aug 2010 01:09:37 +0000"  >&lt;p&gt;See comments on reviewboard.&lt;/p&gt;</comment>
                            <comment id="12897537" author="hbasereviewboard" created="Thu, 12 Aug 2010 01:20:25 +0000"  >&lt;p&gt;Message from: &quot;Paul Yang&quot; &amp;lt;pyang@facebook.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/598/#review853&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/598/#review853&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


&lt;p&gt;Talked to Yongqiang offline about this one. The way that this patch attempts to fix the caching issue is to append some path information to the host so that we create a new HAR filesystem instance for different HAR files. The way that this is implemented now, a &quot;&lt;del&gt;&quot; and path information in added to the host e.g. har://hdfs-localhost-user&lt;/del&gt;&lt;del&gt;warehouse&lt;/del&gt;&lt;del&gt;mytable:50030... if the original were har://hdfs-localhost:50030. However, the HAR filesystem does not ignore the stuff after the second &quot;&lt;/del&gt;&quot; and so has errors when trying to connect to the underlying filesystem. A possible fix would be to modify HiveHarFileSystem to extend the initialize() method so that the characters after the second &quot;-&quot; is ignored.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Paul&lt;/li&gt;
&lt;/ul&gt;



</comment>
                            <comment id="12898028" author="he yongqiang" created="Fri, 13 Aug 2010 01:10:21 +0000"  >&lt;p&gt;Attache a possible fix.&lt;/p&gt;

&lt;p&gt;Talked with Namit and Paul this afternoon about this issue. Actually there is config which can disable FileSystem cache: fs.%s.impl.disable.cache . where %s is the filesystem schema, for archive, it&apos;s har.&lt;/p&gt;

&lt;p&gt;So if you set &quot;fs.har.impl.disable.cache&quot; to false, the archive will automatically work. This should be the clean way to fix this issue.&lt;br/&gt;
In order to do this, you need to apply &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-6231&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HADOOP-6231&lt;/a&gt; if your hadoop does not include the code to disable FileSystem cache.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12451450" name="hive-1515.1.patch" size="10293" author="he yongqiang" created="Fri, 6 Aug 2010 18:41:03 +0000"/>
                            <attachment id="12451974" name="hive-1515.2.patch" size="7184" author="he yongqiang" created="Fri, 13 Aug 2010 01:10:20 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 10 Aug 2010 01:11:19 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42464</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 24 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfgv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123156</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-1516] optimize split sizes automatically taking into account amount of nature of map tasks</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1516</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;two immediate cases come to mind:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;pure filter job (ie. no map-side sort required)&lt;/li&gt;
	&lt;li&gt;full aggregate computations only (like count(1)).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;in these cases - the amount of data to be sorted is zero or negligible. so mapper parallelism (and split size) should be dictated by the size of the cluster. there&apos;s no point running 10000 mappers on a 500 node cluster for a pure filter job.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471000">HIVE-1516</key>
            <summary>optimize split sizes automatically taking into account amount of nature of map tasks</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jsensarma">Joydeep Sen Sarma</reporter>
                        <labels>
                    </labels>
                <created>Fri, 6 Aug 2010 19:21:26 +0000</created>
                <updated>Fri, 6 Aug 2010 19:21:26 +0000</updated>
                                                                            <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42463</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 25 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08nzz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>48487</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-1517] ability to select across a database</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1517</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;After  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-675&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-675&lt;/a&gt;, we need a way to be able to select across a database for this feature to be useful.&lt;/p&gt;


&lt;p&gt;For eg:&lt;/p&gt;

&lt;p&gt;use db1&lt;br/&gt;
create table foo(....);&lt;/p&gt;

&lt;p&gt;use db2&lt;br/&gt;
select .. from db1.foo.....&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471013">HIVE-1517</key>
            <summary>ability to select across a database</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sdong">Siying Dong</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Fri, 6 Aug 2010 21:21:47 +0000</created>
                <updated>Thu, 30 Aug 2012 01:27:15 +0000</updated>
                            <resolved>Wed, 23 Feb 2011 07:19:15 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="12896703" author="jvs" created="Mon, 9 Aug 2010 21:37:45 +0000"  >&lt;p&gt;This case needs to work:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;use db1;
create table t(...);

create view v as select * from t;

use db2;
select * from db1.v;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;What this means is that when we store the definition of v, we need to store a fully-qualified db1.t reference.  Otherwise, when we expand the view in the later query, we&apos;ll look for t in db2 (incorrect) rather than db1 (correct).&lt;/p&gt;</comment>
                            <comment id="12912621" author="jvs" created="Mon, 20 Sep 2010 18:14:47 +0000"  >&lt;p&gt;@Carl:  this is just a checkpoint patch, right?  Since this didn&apos;t make the Friday cut, can we move it to 0.7?&lt;/p&gt;</comment>
                            <comment id="12912710" author="cwsteinbach" created="Mon, 20 Sep 2010 21:04:45 +0000"  >&lt;p&gt;@John: Yes, it&apos;s a checkpoint patch. Moving this to 0.7.0.&lt;/p&gt;</comment>
                            <comment id="12965865" author="namit" created="Wed, 1 Dec 2010 21:56:54 +0000"  >&lt;p&gt;@Carl, are you working on it ?&lt;/p&gt;

&lt;p&gt;We might need it internally at facebook, so wanted to know if you are working on it currently.&lt;/p&gt;</comment>
                            <comment id="12966134" author="cwsteinbach" created="Thu, 2 Dec 2010 14:45:06 +0000"  >&lt;p&gt;@Namit: Yes, I&apos;m still working on this. I have everything working except for views. When do you need this done by?&lt;/p&gt;</comment>
                            <comment id="12966243" author="namit" created="Thu, 2 Dec 2010 19:26:26 +0000"  >&lt;p&gt;We would like to use it right away&lt;/p&gt;</comment>
                            <comment id="12986108" author="namit" created="Mon, 24 Jan 2011 23:41:28 +0000"  >&lt;p&gt;Blocker for 0.7&lt;/p&gt;</comment>
                            <comment id="12990431" author="namit" created="Fri, 4 Feb 2011 02:29:53 +0000"  >&lt;p&gt;@Carl, are you working on this ?&lt;br/&gt;
We really need it asap. If you dont have time, can we take it over ?&lt;/p&gt;</comment>
                            <comment id="12991637" author="cwsteinbach" created="Mon, 7 Feb 2011 21:54:41 +0000"  >&lt;p&gt;Attaching a rebased version of my other patch. This patch implements the ability to select across databases, and also updates a variety of DDL statements so that they are aware of canonical table names.&lt;/p&gt;</comment>
                            <comment id="12991685" author="cwsteinbach" created="Mon, 7 Feb 2011 22:59:09 +0000"  >&lt;p&gt;Quick note about the patch: the tests fail unless database.q is prepended with hive.support.concurrency = false. I didn&apos;t have time to workout the locking issues.&lt;/p&gt;</comment>
                            <comment id="12992139" author="sdong" created="Tue, 8 Feb 2011 19:51:18 +0000"  >&lt;p&gt;I notice that Carl&apos;s patch added cross database support for &apos;create table&apos;, &apos;load&apos;, etc, but now &apos;drop table&apos; and &apos;analyze table&apos;, which are very hard since they currently support dots as other meaning and would cause the ambiguity that we are not ready to handle. Also, it&apos;s hard for &apos;drop table&apos; or &apos;analyze table&apos; to give accurate error message if people try to use db.table. Do you think we want to keep it or we should remove all supports for DDL queries?&lt;/p&gt;</comment>
                            <comment id="12992158" author="cwsteinbach" created="Tue, 8 Feb 2011 20:25:12 +0000"  >&lt;p&gt;I&apos;m not sure I understand the problem with DROP TABLE. How is it ambiguous?&lt;/p&gt;

&lt;p&gt;As for ANALYZE TABLE, it looks like the definition of the tabTypeExpr&lt;br/&gt;
rule in the grammar is more complicated than it needs to be? Isn&apos;t this&lt;br/&gt;
just tableName from my patch?&lt;/p&gt;</comment>
                            <comment id="12992165" author="sdong" created="Tue, 8 Feb 2011 20:35:33 +0000"  >&lt;p&gt;Sorry, I mean DESCRIBE. DROP TABLE is fine.&lt;br/&gt;
You can do something like &apos;desc extended src.key;&apos;&lt;/p&gt;

&lt;p&gt;For ANALYZE TABLE, the syntax is similar to DESCRIBE, though I&apos;m not sure how it is used.&lt;/p&gt;

&lt;p&gt;Those are the two that I found you didn&apos;t replace Identification to tableName.&lt;/p&gt;</comment>
                            <comment id="12992199" author="sdong" created="Tue, 8 Feb 2011 21:48:57 +0000"  >&lt;p&gt;Looks like ANALYZE TABLE doesn&apos;t need the table.xxx syntax. I&apos;ll change that. Then the only problem left is DESCRIBE.&lt;/p&gt;</comment>
                            <comment id="12992212" author="cwsteinbach" created="Tue, 8 Feb 2011 22:22:31 +0000"  >&lt;p&gt;The syntax for DESCRIBE is broken. It should be:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;DESCRIBE [EXTENDED] [database DOT]table [column]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;but is actually&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;DESCRIBE [EXTENDED] table[DOT col_name]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Ref: &lt;a href=&quot;http://dev.mysql.com/doc/refman/5.0/en/describe.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://dev.mysql.com/doc/refman/5.0/en/describe.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;One solution (which I&apos;m not eager to see us take) is to extend Hive&apos;s non-standard as follows:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;DESCRIBE [EXTENDED] [database] table[DOT col_name]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Anyway, I think it&apos;s OK to fix this as a followup.&lt;/p&gt;</comment>
                            <comment id="12992215" author="sdong" created="Tue, 8 Feb 2011 22:33:14 +0000"  >&lt;p&gt;The concurrency issue seems to be that in the codes of acquiring locks, we always lock current database but when we locking every table or partition, we don&apos;t lock database of them, so that it breaks when we reference table from other databases. When I lock database for every table/partitions, the test passes.&lt;/p&gt;

&lt;p&gt;Namit, do you think I should remove the codes to lock the current database? Is there a reason we always lock current database?&lt;/p&gt;</comment>
                            <comment id="12992761" author="sdong" created="Wed, 9 Feb 2011 22:38:05 +0000"  >&lt;p&gt;Double check about character escaping. For db.table, we want the correct escaping format to be `db`.`table`. `db.table` Should be considered ilegal. Is that right?&lt;/p&gt;</comment>
                            <comment id="12992774" author="cwsteinbach" created="Wed, 9 Feb 2011 23:04:46 +0000"  >&lt;p&gt;&amp;gt; `db.table` Should be considered ilegal. Is that right?&lt;/p&gt;

&lt;p&gt;I think that&apos;s correct. See the following page for a complete discussion: &lt;a href=&quot;http://dev.mysql.com/doc/refman/5.0/en/identifiers.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://dev.mysql.com/doc/refman/5.0/en/identifiers.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It also looks like we need to tighten up the way the grammar handles Identifiers:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Identifier
    :
    (Letter | Digit) (Letter | Digit | &lt;span class=&quot;code-quote&quot;&gt;&apos;_&apos;&lt;/span&gt;)*
    | &lt;span class=&quot;code-quote&quot;&gt;&apos;`&apos;&lt;/span&gt; RegexComponent+ &lt;span class=&quot;code-quote&quot;&gt;&apos;`&apos;&lt;/span&gt;
    ;

RegexComponent
    : &lt;span class=&quot;code-quote&quot;&gt;&apos;a&apos;&lt;/span&gt;..&lt;span class=&quot;code-quote&quot;&gt;&apos;z&apos;&lt;/span&gt; | &lt;span class=&quot;code-quote&quot;&gt;&apos;A&apos;&lt;/span&gt;..&lt;span class=&quot;code-quote&quot;&gt;&apos;Z&apos;&lt;/span&gt; | &lt;span class=&quot;code-quote&quot;&gt;&apos;0&apos;&lt;/span&gt;..&lt;span class=&quot;code-quote&quot;&gt;&apos;9&apos;&lt;/span&gt; | &lt;span class=&quot;code-quote&quot;&gt;&apos;_&apos;&lt;/span&gt;
    | PLUS | STAR | QUESTION | MINUS | DOT
    | LPAREN | RPAREN | LSQUARE | RSQUARE | LCURLY | RCURLY
    | BITWISEXOR | BITWISEOR | DOLLAR
    ;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Defining quoted identifiers in terms of RegexComponent permits a lot of illegal characters.&lt;br/&gt;
I think we actually want something like this:&lt;/p&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Identifier
    : (Letter | Digit) (Letter | Digit | &lt;span class=&quot;code-quote&quot;&gt;&apos;_&apos;&lt;/span&gt;)*
    | &lt;span class=&quot;code-quote&quot;&gt;&apos;`&apos;&lt;/span&gt; (Letter | Digit) (Letter | Digit | &lt;span class=&quot;code-quote&quot;&gt;&apos;_&apos;&lt;/span&gt;)* &lt;span class=&quot;code-quote&quot;&gt;&apos;`&apos;&lt;/span&gt;
    ;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12992817" author="sdong" created="Thu, 10 Feb 2011 01:05:11 +0000"  >&lt;p&gt;Modify based on Carl&apos;s previous patch:&lt;br/&gt;
1. fix concurrency issue but locking DB for every table too&lt;br/&gt;
2. fix CREATE TABLE AS and CREATE TABLE LIKE. Also, CREATE TABLE AS to share the same codes to generate default path as CREATE TABLE&lt;br/&gt;
3. fix TABLESAMPLE, DROP TABLE, DROP TABLE, ALTER TABLE DROP PARTITION, etc.&lt;br/&gt;
4. fix the same table names in different databases in the same query. (PartitionPruner&apos;s key&apos;s problem)&lt;br/&gt;
5. fix character escaping problem.&lt;br/&gt;
6. fix TABLE ANALYZE to mistakely allow xxx.xxx&lt;br/&gt;
7. fix DynamicSerDe just to get unit test pass.&lt;br/&gt;
8. lots of test case results changes, since in DESCRIBE EXTENDED, table names are printed to be default.tab instead of tab. I found the possible way not to print &quot;default&quot; to make less change to test outputs is more risky. So I didn&apos;t try that. But I ever implemented it on my machine and make sure those test output modifications are right.&lt;/p&gt;

&lt;p&gt;Some issues:&lt;br/&gt;
1. I didn&apos;t figure out the necessity to modify SemanticAnalyzer.processTable() not to use aliasIndex in Carl&apos;s patch, so I revert them.&lt;br/&gt;
2. DESCRIBE a foreign table is not supported and we don&apos;t give good error message.&lt;br/&gt;
3. `db.tab` is not blocked so far since I found it&apos;s a pretty complicated issue and might need more thinking.&lt;br/&gt;
4. UnparseTranslator becomes a little bit urgly now to unescape identifiers. I found it&apos;s really hard to keep Carl&apos;s syntax rules and still support it in a clean way. Maybe as a follow-up to make DB and table two different tokens, instead of parsing &apos;xxx.xxx&apos; to semantic analyzer.&lt;/p&gt;

&lt;p&gt;I&apos;m still running test suites from the beginning to the end. There still can be something broken.&lt;/p&gt;</comment>
                            <comment id="12992823" author="sdong" created="Thu, 10 Feb 2011 01:13:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/413/diff/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/413/diff/&lt;/a&gt;&lt;br/&gt;
to better browse the patch.&lt;/p&gt;</comment>
                            <comment id="12992875" author="sdong" created="Thu, 10 Feb 2011 05:58:11 +0000"  >&lt;p&gt;Looks like we have some trouble with printing token location in error message. new CommonToken(int, String) doesn&apos;t include location information there, so that the error message will always be &quot;line 0:-1&quot;. Maybe we have to move from this approach to separate tokens for db and tab name.&lt;/p&gt;</comment>
                            <comment id="12993349" author="sdong" created="Fri, 11 Feb 2011 05:23:28 +0000"  >&lt;p&gt;Update from HIVE.1517.3.patch:&lt;/p&gt;

&lt;p&gt;Separate DB name and table name to different tokens and make respective changes.&lt;/p&gt;

&lt;p&gt;Unfortunately, most syntax tree changes so that most test outputs are changed.&lt;/p&gt;</comment>
                            <comment id="12993353" author="sdong" created="Fri, 11 Feb 2011 05:31:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/413/diff/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/413/diff/&lt;/a&gt;&lt;br/&gt;
for better browsing.&lt;/p&gt;</comment>
                            <comment id="12995146" author="namit" created="Wed, 16 Feb 2011 03:53:09 +0000"  >&lt;p&gt;We need to lock the current database, so that DROP DATABASE does not work while any table/partition is&lt;br/&gt;
being accessed/modified&lt;/p&gt;</comment>
                            <comment id="12995161" author="namit" created="Wed, 16 Feb 2011 04:41:59 +0000"  >&lt;p&gt;The changes look good - but I dont understand the need for Driver.java changes.&lt;br/&gt;
The concurerency should work&lt;/p&gt;</comment>
                            <comment id="12995182" author="sdong" created="Wed, 16 Feb 2011 06:02:23 +0000"  >&lt;p&gt;Namit, Driver.java just lock db of the table when locking any table, which should be the same reason as you explained &quot;DROP DATABASE does not work while any table/partition is&lt;br/&gt;
 being accessed/modified&quot;. Also, zookeeper path are something like /&amp;lt;PREFIX&amp;gt;/db/table_name. Without locking db in advance, parent path is missing and locking the tables will fail.&lt;/p&gt;</comment>
                            <comment id="12995211" author="namit" created="Wed, 16 Feb 2011 08:10:11 +0000"  >&lt;p&gt;Ideally, /&amp;lt;PREFIX&amp;gt;/db should be created as part of locking. You dont need to explicitly lock the db.&lt;/p&gt;</comment>
                            <comment id="12995213" author="namit" created="Wed, 16 Feb 2011 08:24:42 +0000"  >&lt;p&gt;Sorry, looked at the code again - your locking changes are good - will review the remaining patch&lt;/p&gt;</comment>
                            <comment id="12995242" author="namit" created="Wed, 16 Feb 2011 10:30:54 +0000"  >&lt;p&gt;The code changes look good - but I am getting a lot of errors while running tests.&lt;br/&gt;
Can you run tests again ?&lt;/p&gt;</comment>
                            <comment id="12995245" author="namit" created="Wed, 16 Feb 2011 10:51:35 +0000"  >&lt;p&gt;archive.q is the first test that fails - it works fine when run stand alone. &lt;br/&gt;
I havent debugged further&lt;/p&gt;</comment>
                            <comment id="12995440" author="sdong" created="Wed, 16 Feb 2011 18:26:37 +0000"  >&lt;p&gt;I applied that patch to a clean directory and I am running the tests. It is still running but archive.q already passed. Maybe try to do a clean before test?&lt;/p&gt;</comment>
                            <comment id="12995494" author="sdong" created="Wed, 16 Feb 2011 20:13:23 +0000"  >&lt;p&gt;When I sync up new codes and rebase, some tests break. Will fix it.&lt;/p&gt;</comment>
                            <comment id="12995643" author="sdong" created="Thu, 17 Feb 2011 02:32:08 +0000"  >&lt;p&gt;fix test outputs of two new added tests after rebasing.&lt;/p&gt;</comment>
                            <comment id="12995644" author="sdong" created="Thu, 17 Feb 2011 02:33:34 +0000"  >&lt;p&gt;not huge difference though. I fixed two test outputs but it doesn&apos;t seem to be related to Namit&apos;s test failures. Namit, can you do a &quot;ant clean&quot; and then &quot;ant package&quot; and then run the tests again?&lt;/p&gt;</comment>
                            <comment id="12995665" author="sdong" created="Thu, 17 Feb 2011 04:49:02 +0000"  >&lt;p&gt;This patch fixed a couple of test outputs for TestContriCliTest. &lt;/p&gt;</comment>
                            <comment id="12995667" author="namit" created="Thu, 17 Feb 2011 05:00:37 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;For some reason, the tests are failing in my environment.&lt;br/&gt;
While I fix the problem, Yongqiang, can you commit ?&lt;/p&gt;</comment>
                            <comment id="12995673" author="he yongqiang" created="Thu, 17 Feb 2011 05:22:30 +0000"  >&lt;p&gt;running tests, will commit after tests pass.&lt;/p&gt;</comment>
                            <comment id="12995686" author="sdong" created="Thu, 17 Feb 2011 06:49:24 +0000"  >&lt;p&gt;Yongqiang, please notice that I updated a latest one that fixed a couple of contrib tests.&lt;/p&gt;
</comment>
                            <comment id="12996300" author="sdong" created="Fri, 18 Feb 2011 09:11:17 +0000"  >&lt;p&gt;I fixed multiple tests. Two tests always fail:&lt;/p&gt;

&lt;p&gt;TestHBaseCliDriver&lt;br/&gt;
TestHBaseMinimrCliDriver&lt;/p&gt;

&lt;p&gt;They fail even without the patch. So I guess it is unrelated.&lt;/p&gt;</comment>
                            <comment id="12996601" author="sdong" created="Fri, 18 Feb 2011 21:39:36 +0000"  >&lt;p&gt;Sorry for so many updates. I fixed lineage. The lineage info seems to have some issues with &quot;table tablesample..&quot; even now. I didn&apos;t changed this behavior and keep it as it is today.&lt;/p&gt;

&lt;p&gt;Yongqiang verified that the HBase tests also fail on his machine. &lt;/p&gt;</comment>
                            <comment id="12996616" author="jvs" created="Fri, 18 Feb 2011 22:17:41 +0000"  >&lt;p&gt;HBase tests are passing in Hudson.  Siying and Yongqiang, can you guys try rebooting your dev boxes?  There were issues with port conflicts with FB dev boxes before, so maybe you still have some lingering processes/ports.&lt;/p&gt;</comment>
                            <comment id="12996628" author="sdong" created="Fri, 18 Feb 2011 22:44:23 +0000"  >&lt;p&gt;Resolve the conflict after rebasing. John asked me to try to reboot my machine before running the Hbase tests again. I&apos;ll try to do that too.&lt;/p&gt;</comment>
                            <comment id="12996641" author="jvs" created="Fri, 18 Feb 2011 23:01:36 +0000"  >&lt;p&gt;Hey Siying,&lt;/p&gt;

&lt;p&gt;This case from my original comment way at the top of this JIRA issue is not handled by your patch.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;create database db1;
use db1;
create table t(i int);

create view v as select * from t;

create database db2;
use db2;
select * from db1.v;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This will take some work in the unparse when we store the view definition.&lt;/p&gt;</comment>
                            <comment id="12996643" author="sdong" created="Fri, 18 Feb 2011 23:05:25 +0000"  >&lt;p&gt;John, how about for this JIRA, we just drop support (I&apos;ll modify the codes to report error if the view is referenced as &quot;db.view_name&quot;) for referencing foreign view and we do it as a follow-up?&lt;/p&gt;</comment>
                            <comment id="12996645" author="sdong" created="Fri, 18 Feb 2011 23:14:16 +0000"  >&lt;p&gt;I&apos;ll figure out the view support now.&lt;/p&gt;</comment>
                            <comment id="12996646" author="jvs" created="Fri, 18 Feb 2011 23:14:28 +0000"  >&lt;p&gt;Fine with me.&lt;/p&gt;</comment>
                            <comment id="12996679" author="sdong" created="Sat, 19 Feb 2011 01:38:27 +0000"  >&lt;p&gt;I tried some simple way to make it work. It doesn&apos;t seem to be such a simple task. Instead, I added this to block it:&lt;/p&gt;

&lt;p&gt;&amp;lt;pre&amp;gt;&lt;br/&gt;
 // TODO: add support to referencing views in foreign databases.&lt;br/&gt;
 if (!tab.getDbName().equals(db.getCurrentDatabase()))  &lt;/p&gt;
{
  throw new SemanticException(ErrorMsg.INVALID_TABLE_ALIAS.
                getMsg(&quot;Referencing view from foreign databases is not supported.&quot;));
 }

&lt;p&gt;I&apos;ll add the view support as a follow-up patch.&lt;/p&gt;</comment>
                            <comment id="12996757" author="namit" created="Sat, 19 Feb 2011 11:33:20 +0000"  >&lt;p&gt;I think that should be fine.&lt;/p&gt;</comment>
                            <comment id="12997612" author="sdong" created="Tue, 22 Feb 2011 00:33:19 +0000"  >&lt;p&gt;Passed HBase tests.&lt;/p&gt;

&lt;p&gt;HBaseStorageHandler used to use table name as Hbase table name if it is not assigned. Now we have a choice to use dbName.tabName or tabName. To keep it kind of compatible, Now we use tabName if DB Name is &quot;default&quot; and use dbName.tabName if not.&lt;/p&gt;</comment>
                            <comment id="12998199" author="he yongqiang" created="Wed, 23 Feb 2011 07:19:15 +0000"  >&lt;p&gt;Committed! Thanks Siying and Carl!&lt;/p&gt;</comment>
                            <comment id="12998245" author="cwsteinbach" created="Wed, 23 Feb 2011 08:46:25 +0000"  >&lt;p&gt;@Yongqiang: This needs to get backported to 0.7.0. Let me know if you want me to do it. Thanks.&lt;/p&gt;</comment>
                            <comment id="12998503" author="he yongqiang" created="Wed, 23 Feb 2011 19:01:28 +0000"  >&lt;p&gt;@Carl, it will great if you can do it. Thanks.&lt;/p&gt;</comment>
                            <comment id="12999207" author="cwsteinbach" created="Fri, 25 Feb 2011 03:50:30 +0000"  >&lt;p&gt;Backported to branch-0.7&lt;/p&gt;</comment>
                            <comment id="13444597" author="cos" created="Thu, 30 Aug 2012 01:27:15 +0000"  >&lt;p&gt;Do I understand correctly, that this fix has never been extended for the views?&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12436229">HIVE-849</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12511009">HIVE-2228</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12498035">HIVE-1977</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310040">
                    <name>Required</name>
                                            <outwardlinks description="requires">
                                        <issuelink>
            <issuekey id="12431185">HIVE-675</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12454910" name="HIVE-1517.1.patch.txt" size="3637" author="cwsteinbach" created="Fri, 17 Sep 2010 22:23:50 +0000"/>
                            <attachment id="12471450" name="HIVE-1517.10.patch" size="5055098" author="sdong" created="Sat, 19 Feb 2011 01:38:27 +0000"/>
                            <attachment id="12471587" name="HIVE-1517.11.patch" size="5085536" author="sdong" created="Tue, 22 Feb 2011 00:33:19 +0000"/>
                            <attachment id="12470508" name="HIVE-1517.2.patch.txt" size="50793" author="cwsteinbach" created="Mon, 7 Feb 2011 21:54:41 +0000"/>
                            <attachment id="12470747" name="HIVE-1517.3.patch" size="2069125" author="sdong" created="Thu, 10 Feb 2011 01:05:11 +0000"/>
                            <attachment id="12470835" name="HIVE-1517.4.patch" size="4381133" author="sdong" created="Fri, 11 Feb 2011 05:23:28 +0000"/>
                            <attachment id="12471246" name="HIVE-1517.5.patch" size="4387107" author="sdong" created="Thu, 17 Feb 2011 02:35:23 +0000"/>
                            <attachment id="12471249" name="HIVE-1517.6.patch" size="4449257" author="sdong" created="Thu, 17 Feb 2011 04:49:02 +0000"/>
                            <attachment id="12471382" name="HIVE-1517.7.patch" size="1899" author="sdong" created="Fri, 18 Feb 2011 09:11:17 +0000"/>
                            <attachment id="12471440" name="HIVE-1517.8.patch" size="5052224" author="sdong" created="Fri, 18 Feb 2011 21:39:36 +0000"/>
                            <attachment id="12471444" name="HIVE-1517.9.patch" size="5052202" author="sdong" created="Fri, 18 Feb 2011 22:44:23 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 9 Aug 2010 21:37:45 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>70717</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 21 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfh3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123157</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1518] context_ngrams() UDAF for estimating top-k contextual n-grams</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1518</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Create a new context_ngrams() function that generalizes the ngrams() UDAF to allow the user to specify context around n-grams. The analogy is &quot;fill-in-the-blanks&quot;, and is best illustrated with an example:&lt;/p&gt;

&lt;p&gt;SELECT context_ngrams(sentences(tweets), array(&quot;i&quot;, &quot;love&quot;, null), 300) FROM twitter;&lt;/p&gt;

&lt;p&gt;will estimate the top-300 words that follow the phrase &quot;i love&quot; in a database of tweets. The position of the null(s) specifies where to generate the n-gram from, and can be placed anywhere. For example:&lt;/p&gt;

&lt;p&gt;SELECT context_ngrams(sentences(tweets), array(&quot;i&quot;, &quot;love&quot;, null, &quot;but&quot;, &quot;hate&quot;, null), 300) FROM twitter;&lt;/p&gt;

&lt;p&gt;will estimate the top-300 word-pairs that fill in the blanks specified by null.&lt;/p&gt;

&lt;p&gt;POSSIBLE USES:&lt;br/&gt;
1. Pre-computing search lookaheads&lt;br/&gt;
2. Sentiment analysis for products or entities &amp;#8211; e.g., querying with context = array(&quot;twitter&quot;, &quot;is&quot;, null)&lt;br/&gt;
3. Navigation path analysis in URL databases&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471017">HIVE-1518</key>
            <summary>context_ngrams() UDAF for estimating top-k contextual n-grams</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mayanklahiri">Mayank Lahiri</assignee>
                                    <reporter username="mayanklahiri">Mayank Lahiri</reporter>
                        <labels>
                    </labels>
                <created>Fri, 6 Aug 2010 23:26:47 +0000</created>
                <updated>Fri, 16 Dec 2011 23:59:25 +0000</updated>
                            <resolved>Wed, 18 Aug 2010 23:00:51 +0000</resolved>
                                    <version>0.7.0</version>
                                    <fixVersion>0.7.0</fixVersion>
                                    <component>UDF</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12896187" author="mayanklahiri" created="Fri, 6 Aug 2010 23:29:05 +0000"  >&lt;p&gt;Note that this generalizes ngrams(), but is less efficient than ngrams(). For example,&lt;/p&gt;

&lt;p&gt;SELECT ngrams(sentences(tweets), 2, 100) &lt;/p&gt;

&lt;p&gt;is equivalent to:&lt;/p&gt;

&lt;p&gt;SELECT context_ngrams(sentences(tweets), array(null, null), 100)&lt;/p&gt;</comment>
                            <comment id="12897435" author="mayanklahiri" created="Wed, 11 Aug 2010 20:27:23 +0000"  >&lt;p&gt;&amp;#8211; abstracted n-gram estimation heuristic into a new class, refactored ngrams()&lt;br/&gt;
&amp;#8211; added context_ngrams()&lt;br/&gt;
&amp;#8211; new tests for both ngrams() and context_ngrams()&lt;/p&gt;</comment>
                            <comment id="12897974" author="mayanklahiri" created="Thu, 12 Aug 2010 22:09:52 +0000"  >&lt;p&gt;Found the source of the bug we were discussing &amp;#8211; the v1 patch is correct, but will submit another patch with the &quot;correct&quot; way to do things.&lt;/p&gt;</comment>
                            <comment id="12898420" author="jvs" created="Fri, 13 Aug 2010 21:11:51 +0000"  >&lt;p&gt;Submitted a review here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://review.cloudera.org/r/644/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://review.cloudera.org/r/644/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Some of my comments are on existing code which is being moved as part of this patch; consider them retroactive since I should have made them on the original ngrams patch.&lt;/p&gt;

&lt;p&gt;In general, see if you can use generics for collections wherever possible.&lt;/p&gt;</comment>
                            <comment id="12898421" author="hbasereviewboard" created="Fri, 13 Aug 2010 21:15:07 +0000"  >&lt;p&gt;Message from: &quot;John Sichi&quot; &amp;lt;jsichi@facebook.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/644/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/644/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for Hive Developers.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;review by JVS&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1518&quot; title=&quot;context_ngrams() UDAF for estimating top-k contextual n-grams&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1518&quot;&gt;&lt;del&gt;HIVE-1518&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/HIVE-1518&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HIVE-1518&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/data/files/text-en.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/data/files/text-en.txt&lt;/a&gt; 985013 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java&lt;/a&gt; 985013 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFContextNGrams.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFContextNGrams.java&lt;/a&gt; PRE-CREATION &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFnGrams.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFnGrams.java&lt;/a&gt; 985013 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/NGramEstimator.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/NGramEstimator.java&lt;/a&gt; PRE-CREATION &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/test/queries/clientpositive/udaf_context_ngrams.q&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/test/queries/clientpositive/udaf_context_ngrams.q&lt;/a&gt; PRE-CREATION &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/test/queries/clientpositive/udaf_ngrams.q&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/test/queries/clientpositive/udaf_ngrams.q&lt;/a&gt; 985013 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/test/results/clientpositive/show_functions.q.out&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/test/results/clientpositive/show_functions.q.out&lt;/a&gt; 985013 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/test/results/clientpositive/udaf_context_ngrams.q.out&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/test/results/clientpositive/udaf_context_ngrams.q.out&lt;/a&gt; PRE-CREATION &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/test/results/clientpositive/udaf_ngrams.q.out&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/test/results/clientpositive/udaf_ngrams.q.out&lt;/a&gt; 985013 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.cloudera.org/r/644/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/644/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;John&lt;/p&gt;

</comment>
                            <comment id="12898425" author="hbasereviewboard" created="Fri, 13 Aug 2010 21:32:20 +0000"  >&lt;p&gt;Message from: &quot;John Sichi&quot; &amp;lt;jsichi@facebook.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/644/#review902&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/644/#review902&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;



&lt;p&gt;&lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFContextNGrams.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFContextNGrams.java&lt;/a&gt;&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/644/#comment2936&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/644/#comment2936&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Shouldn&apos;t name=&quot;context_ngrams&quot;?&lt;/p&gt;




&lt;p&gt;&lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFContextNGrams.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFContextNGrams.java&lt;/a&gt;&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/644/#comment2937&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/644/#comment2937&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Here and elsewhere, why do you cast to ArrayList?  Can&apos;t you just use the List interface?  I don&apos;t think Hive makes any guarantee that an ArrayList will always be returned, even if that is currently the case.&lt;/p&gt;




&lt;p&gt;&lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/NGramEstimator.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/NGramEstimator.java&lt;/a&gt;&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/644/#comment2938&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/644/#comment2938&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    (I missed this in an earlier review):  can you use generics here to specify the HashMap&amp;lt;K,V&amp;gt; types and avoid so much casting?&lt;/p&gt;



&lt;p&gt;&lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/NGramEstimator.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/NGramEstimator.java&lt;/a&gt;&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/644/#comment2939&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/644/#comment2939&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    specify Comparator&amp;lt;Double&amp;gt; to avoid casting&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;John&lt;/li&gt;
&lt;/ul&gt;



</comment>
                            <comment id="12899602" author="mayanklahiri" created="Tue, 17 Aug 2010 21:35:42 +0000"  >&lt;p&gt;(1) Fixed casting issues&lt;br/&gt;
(2) Fixed trivial checkstyle issues in GenericUDAFHistogramNumeric.java&lt;/p&gt;</comment>
                            <comment id="12899624" author="jvs" created="Tue, 17 Aug 2010 22:27:27 +0000"  >&lt;p&gt;Now there are a bunch of redundant casts remaining, e.g.&lt;/p&gt;

&lt;p&gt;+      Double myval = (Double) ngrams.get(mykey);&lt;br/&gt;
+        Text word = (Text) other.get(i+j);&lt;/p&gt;

&lt;p&gt;For cases like this, you can avoid the cast by keeping around the originally typed object:&lt;/p&gt;

&lt;p&gt;+        ((ArrayList&amp;lt;Text&amp;gt;) curGram&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;).add(new Text(key.get(j)));&lt;/p&gt;

&lt;p&gt;And for the Comparator, you can use Comparator&amp;lt;Map.Entry&amp;lt;ArrayList&amp;lt;String&amp;gt;,Double&amp;gt;&amp;gt; to make it fully strongly typed and avoid casts.&lt;/p&gt;</comment>
                            <comment id="12899657" author="mayanklahiri" created="Tue, 17 Aug 2010 23:55:56 +0000"  >&lt;p&gt;Whoops--missed those, sorry! Also cleaned up some casts in two other UDAFs.&lt;/p&gt;</comment>
                            <comment id="12899682" author="jvs" created="Wed, 18 Aug 2010 01:11:50 +0000"  >&lt;p&gt;+1.  Will commit when tests pass.&lt;/p&gt;</comment>
                            <comment id="12899684" author="jvs" created="Wed, 18 Aug 2010 01:17:12 +0000"  >&lt;p&gt;Oops, I&apos;m getting a conflict when attempting to apply the patch on trunk (in udaf_ngrams.q.out, probably due to a recent commit which changes the hook output). &lt;/p&gt;</comment>
                            <comment id="12899923" author="mayanklahiri" created="Wed, 18 Aug 2010 17:35:12 +0000"  >&lt;p&gt;It was the new hook format. This should fix it.&lt;/p&gt;</comment>
                            <comment id="12900012" author="jvs" created="Wed, 18 Aug 2010 20:10:59 +0000"  >&lt;p&gt;Running through tests now.&lt;/p&gt;</comment>
                            <comment id="12900092" author="jvs" created="Wed, 18 Aug 2010 23:00:51 +0000"  >&lt;p&gt;Committed.  Thanks Mayank!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12451818" name="HIVE-1518.1.patch" size="100061" author="mayanklahiri" created="Wed, 11 Aug 2010 20:27:23 +0000"/>
                            <attachment id="12451963" name="HIVE-1518.2.patch" size="100045" author="mayanklahiri" created="Thu, 12 Aug 2010 22:41:03 +0000"/>
                            <attachment id="12452329" name="HIVE-1518.3.patch" size="101419" author="mayanklahiri" created="Tue, 17 Aug 2010 21:35:42 +0000"/>
                            <attachment id="12452338" name="HIVE-1518.4.patch" size="105216" author="mayanklahiri" created="Tue, 17 Aug 2010 23:55:56 +0000"/>
                            <attachment id="12452424" name="HIVE-1518.5.patch" size="104879" author="mayanklahiri" created="Wed, 18 Aug 2010 17:34:42 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 13 Aug 2010 21:11:51 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72860</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 23 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfhb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123158</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1519] Insertion should throw an error when partition order is different than create table</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1519</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Hive should throw an error when the partition order specified during insert is different from the order specified during table creation.&lt;/p&gt;

&lt;p&gt;Currently hive allows data insertion but further query of data doesn&apos;t return any result.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471086">HIVE-1519</key>
            <summary>Insertion should throw an error when partition order is different than create table</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="thiruvel">Thiruvel Thirumoolan</reporter>
                        <labels>
                    </labels>
                <created>Mon, 9 Aug 2010 07:20:48 +0000</created>
                <updated>Mon, 14 Feb 2011 21:02:11 +0000</updated>
                                                                            <component>CLI</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42462</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 25 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfhj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123159</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-1520] hive.mapred.local.mem should only be used in case of local mode job submissions</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1520</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently - whenever we submit a map-reduce job via a child jvm process, hive sets HADOOP_HEAPSIZE to hive.mapred.local.mem (thereby limiting the max heap memory of the child jvm). the assumption being that we are submitting a job for local mode execution and different memory limits apply for that.&lt;/p&gt;

&lt;p&gt;however - one can submit jobs via a child jvm for non local mode execution as well. This is useful, for example, if hive wants to submit jobs via different hadoop clients (for sending jobs to different hadoop clusters). in such case, we can use the &apos;hive.exec.submitviachild&apos; and &apos;hadoop.bin.path&apos; to dispatch job via an alternate hadoop client install point. however in such case, we don&apos;t need to set HADOOP_HEAPSIZE. all we are using the child jvm is to run the small bit of hive code that submits the job (and not for local mode execution).&lt;/p&gt;

&lt;p&gt;in this case - we shouldn&apos;t be setting the child jvm&apos;s memory limit and should leave it to what the parent&apos;s value is.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471140">HIVE-1520</key>
            <summary>hive.mapred.local.mem should only be used in case of local mode job submissions</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jsensarma">Joydeep Sen Sarma</reporter>
                        <labels>
                    </labels>
                <created>Mon, 9 Aug 2010 19:38:08 +0000</created>
                <updated>Fri, 16 Dec 2011 23:59:36 +0000</updated>
                            <resolved>Fri, 8 Oct 2010 04:42:45 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12919152" author="namit" created="Fri, 8 Oct 2010 04:42:45 +0000"  >&lt;p&gt;Committed. Thanks Joy&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12456556" name="1520.1.patch" size="1866" author="jsensarma" created="Wed, 6 Oct 2010 23:43:41 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 8 Oct 2010 04:42:45 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72859</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 16 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfhr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123160</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1521] compiling/testing against custom hadoop tree is broken</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1521</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;see:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://wiki.apache.org/hadoop/Hive/DeveloperGuide#Advanced_Mode&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Hive/DeveloperGuide#Advanced_Mode&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;compiling with specific value of hadoop.root no longer works because of the shims stuff. we should deprecate/fix this. it is still &lt;em&gt;very&lt;/em&gt; desirably to be able to test against a custom hadoop build (to test hive/hadoop integration).&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471152">HIVE-1521</key>
            <summary>compiling/testing against custom hadoop tree is broken</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jsensarma">Joydeep Sen Sarma</reporter>
                        <labels>
                    </labels>
                <created>Mon, 9 Aug 2010 22:48:27 +0000</created>
                <updated>Mon, 9 Aug 2010 22:48:27 +0000</updated>
                                                                            <component>Build Infrastructure</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42461</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 25 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfhz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123161</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-1522] replace columns should prohibit using partition column names.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1522</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;create table src_part_w(key int , value string) partitioned by (ds string, hr int);&lt;br/&gt;
alter table src_part_w  replace columns (key int, ds string, hr int, value string);&lt;/p&gt;

&lt;p&gt;should not be allowed. Once the &quot;alter table replace columns ...&quot; is done, all commands on this table will fail. And not able to change the schema back.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471153">HIVE-1522</key>
            <summary>replace columns should prohibit using partition column names.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="he yongqiang">He Yongqiang</reporter>
                        <labels>
                    </labels>
                <created>Mon, 9 Aug 2010 22:50:31 +0000</created>
                <updated>Wed, 20 Apr 2011 23:59:15 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42460</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 25 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfi7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123162</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-1523] ql tests no longer work in miniMR mode</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1523</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;as per title. here&apos;s the first exception i see:&lt;/p&gt;


&lt;p&gt;2010-08-09 18:05:11,259 ERROR hive.log (MetaStoreUtils.java:logAndThrowMetaException(743)) - Got exception: java.io.FileNotFoun\&lt;br/&gt;
dException File &lt;a href=&quot;file:/build/ql/test/data/warehouse/dest_j1&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/build/ql/test/data/warehouse/dest_j1&lt;/a&gt; does not exist.&lt;br/&gt;
2010-08-09 18:05:11,259 ERROR hive.log (MetaStoreUtils.java:logAndThrowMetaException(746)) - java.io.FileNotFoundException: Fil\&lt;br/&gt;
e &lt;a href=&quot;file:/build/ql/test/data/warehouse/dest_j1&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/build/ql/test/data/warehouse/dest_j1&lt;/a&gt; does not exist.&lt;br/&gt;
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:361)&lt;br/&gt;
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:245)&lt;br/&gt;
  at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:136)&lt;br/&gt;
  at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_table_core(HiveMetaStore.java:677)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471157">HIVE-1523</key>
            <summary>ql tests no longer work in miniMR mode</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jsensarma">Joydeep Sen Sarma</assignee>
                                    <reporter username="jsensarma">Joydeep Sen Sarma</reporter>
                        <labels>
                    </labels>
                <created>Tue, 10 Aug 2010 01:13:59 +0000</created>
                <updated>Thu, 2 May 2013 02:29:29 +0000</updated>
                            <resolved>Wed, 25 Aug 2010 21:09:12 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12899757" author="jsensarma" created="Wed, 18 Aug 2010 06:54:47 +0000"  >&lt;p&gt;fixed minimr test mode.&lt;/p&gt;

&lt;p&gt;enabled a couple of queries to always run (additionally) in minimr mode (like hbase-handler tests) when running standard tests. we should probably expand this to a larger number of queries (especially those requiring multiple reducers). i don&apos;t have good insight into this part - if people have ideas - we can expand the list easily.&lt;/p&gt;</comment>
                            <comment id="12900018" author="jvs" created="Wed, 18 Aug 2010 20:30:00 +0000"  >&lt;p&gt;+1.  Last time I talked to Ning about this, my take was that we should be able to re-run any subset of tests in either mode (without needing test codegen for it), but for now we can just get things working again this way.&lt;/p&gt;

&lt;p&gt;Some candidates for existing tests to add in to the minimr suite:&lt;/p&gt;

&lt;p&gt;jsichi-mac:clientpositive jsichi$ grep reducer *.q&lt;br/&gt;
bucket1.q:set hive.exec.reducers.max = 200;&lt;br/&gt;
bucket2.q:set hive.exec.reducers.max = 1;&lt;br/&gt;
bucket3.q:set hive.exec.reducers.max = 1;&lt;br/&gt;
bucket4.q:set hive.exec.reducers.max = 1;&lt;br/&gt;
bucketmapjoin6.q:set hive.exec.reducers.max=1;&lt;br/&gt;
disable_merge_for_bucketing.q:set hive.exec.reducers.max = 1;&lt;br/&gt;
reduce_deduplicate.q:set hive.exec.reducers.max = 1;&lt;br/&gt;
sample10.q:set hive.exec.reducers.max=4;&lt;br/&gt;
smb_mapjoin_6.q:set hive.exec.reducers.max = 1;&lt;br/&gt;
smb_mapjoin_7.q:set hive.exec.reducers.max = 1;&lt;br/&gt;
smb_mapjoin_8.q:set hive.exec.reducers.max = 1;&lt;br/&gt;
smb_mapjoin_8.q:set hive.exec.reducers.max = 1;&lt;br/&gt;
udaf_percentile_approx.q:set hive.exec.reducers.max=4&lt;/p&gt;</comment>
                            <comment id="12900048" author="jsensarma" created="Wed, 18 Aug 2010 21:47:24 +0000"  >&lt;p&gt;i am running through the above qfiles and see what executes successfully on minimr (because many dont).&lt;/p&gt;

&lt;p&gt;one concern is the length of the tests. i think we need to divide our tests into a short and long regression. otherwise development cycle is severely impacted if everything has to be tested on every iteration.&lt;/p&gt;</comment>
                            <comment id="12900096" author="jsensarma" created="Wed, 18 Aug 2010 23:11:03 +0000"  >&lt;p&gt;with modified list of minimr tests:&lt;/p&gt;

&lt;p&gt;+  &amp;lt;property name=&quot;minimr.query.files&quot; value=&quot;input16_cc.q,scriptfile1.q,bucket1.q,bucket2.q,bucket3.q,bucket4.q,bucketmapjoin6.q,disable_merge_for_bucketing.q,reduce_deduplicate.q,smb_mapjoin_6.q,smb_mapjoin_7.q,join1.q,groupby2.q&quot;/&amp;gt;                                                                                       &lt;/p&gt;

&lt;p&gt;i took the ones that worked from John&apos;s list. also added a couple of tests that had &apos;add jar&apos; and &apos;add file&apos; commands (since their interaction with real cluster is quite different).&lt;/p&gt;

</comment>
                            <comment id="12900141" author="jvs" created="Thu, 19 Aug 2010 01:28:00 +0000"  >&lt;p&gt;Yeah, shortreg/longreg split would be good.  The challenge is to keep longreg healthy since breakages don&apos;t get caught with every checkin, so we&apos;ll need&lt;/p&gt;

&lt;p&gt;(a) automation to run it constantly and report failures&lt;br/&gt;
(b) people to actually fix failures in a timely fashion&lt;/p&gt;</comment>
                            <comment id="12900143" author="jsensarma" created="Thu, 19 Aug 2010 01:39:53 +0000"  >&lt;p&gt;small change - fix 0.20 version match to pick the right jetty version. &lt;/p&gt;</comment>
                            <comment id="12901687" author="jsensarma" created="Tue, 24 Aug 2010 00:50:59 +0000"  >&lt;p&gt;can someone review/commit this? i don&apos;t think i am going to make more changes to this.&lt;/p&gt;

&lt;p&gt;will work on long regression framework separately.&lt;/p&gt;</comment>
                            <comment id="12901971" author="namit" created="Tue, 24 Aug 2010 17:15:27 +0000"  >&lt;p&gt;I will take a look&lt;/p&gt;</comment>
                            <comment id="12902025" author="namit" created="Tue, 24 Aug 2010 19:19:11 +0000"  >&lt;p&gt;The tests in miniMR will run twice, and the log files may get over-written.&lt;br/&gt;
They should be excluded from non-miniMR.&lt;/p&gt;</comment>
                            <comment id="12902526" author="jsensarma" created="Wed, 25 Aug 2010 17:11:44 +0000"  >&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;added exclude tests - minimr tests are excluded from regular clientpositive tests&lt;/li&gt;
	&lt;li&gt;did some subtle changes in how fs.default.name and mapred.job.tracker are specified to allow testing against external hadoop clusters&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12902558" author="namit" created="Wed, 25 Aug 2010 18:26:08 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;Running tests now - will file a new jira for the ability to run unit tests in parallel in miniMr mode&lt;/p&gt;</comment>
                            <comment id="12902560" author="jsensarma" created="Wed, 25 Aug 2010 18:39:00 +0000"  >&lt;p&gt;there&apos;s already a jira on running tests in parallel. i think i can cover it there itself.&lt;/p&gt;</comment>
                            <comment id="12902635" author="namit" created="Wed, 25 Aug 2010 21:09:11 +0000"  >&lt;p&gt;Committed. Thanks Joy&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12471947">HIVE-1560</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12471954">HIVE-1562</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12471969">HIVE-1565</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12471970">HIVE-1566</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12472034">HIVE-1569</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12472034">HIVE-1569</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12471952">HIVE-1561</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12471968">HIVE-1564</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12452369" name="hive-1523.1.patch" size="4551" author="jsensarma" created="Wed, 18 Aug 2010 06:54:47 +0000"/>
                            <attachment id="12452464" name="hive-1523.2.patch" size="4718" author="jsensarma" created="Wed, 18 Aug 2010 23:11:03 +0000"/>
                            <attachment id="12452479" name="hive-1523.3.patch" size="5955" author="jsensarma" created="Thu, 19 Aug 2010 01:39:52 +0000"/>
                            <attachment id="12453058" name="hive-1523.4.patch" size="10724" author="jsensarma" created="Wed, 25 Aug 2010 17:11:44 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 18 Aug 2010 20:30:00 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72858</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 22 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfif:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123163</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1524] parallel execution failed if mapred.job.name is set</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1524</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The plan file name was generated based on mapred.job.name. If the user specify mapred.job.name before the query, two parallel queries will have conflict plan file name. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12471165">HIVE-1524</key>
            <summary>parallel execution failed if mapred.job.name is set</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nzhang">Ning Zhang</assignee>
                                    <reporter username="nzhang">Ning Zhang</reporter>
                        <labels>
                    </labels>
                <created>Tue, 10 Aug 2010 06:32:00 +0000</created>
                <updated>Sat, 17 Dec 2011 00:03:46 +0000</updated>
                            <resolved>Wed, 29 Sep 2010 05:23:24 +0000</resolved>
                                                    <fixVersion>0.6.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="12896783" author="nzhang" created="Tue, 10 Aug 2010 06:44:12 +0000"  >&lt;p&gt;Using UUID to get a unique job ID for each MapRedTask and keep it in the JobConf. &lt;/p&gt;</comment>
                            <comment id="12896787" author="nzhang" created="Tue, 10 Aug 2010 07:03:27 +0000"  >&lt;p&gt;tests are still running now. &lt;/p&gt;</comment>
                            <comment id="12896992" author="jsensarma" created="Tue, 10 Aug 2010 18:26:21 +0000"  >&lt;p&gt;looks good to me.&lt;/p&gt;

&lt;p&gt;one comment: getJobID is a very confusing name (sounds like we are getting the hadoop jobid or something like that). it would be nice to make it more explicit (getHiveJobID perhaps?).&lt;/p&gt;</comment>
                            <comment id="12897033" author="nzhang" created="Tue, 10 Aug 2010 20:41:40 +0000"  >&lt;p&gt;changed getJobID() to getHiveJobID().&lt;/p&gt;</comment>
                            <comment id="12897037" author="jsensarma" created="Tue, 10 Aug 2010 20:54:48 +0000"  >&lt;p&gt;will commit once tests pass.&lt;/p&gt;</comment>
                            <comment id="12897080" author="jsensarma" created="Tue, 10 Aug 2010 23:13:33 +0000"  >&lt;p&gt;committed - thanks Ning.&lt;/p&gt;</comment>
                            <comment id="12915646" author="yourchanges" created="Tue, 28 Sep 2010 06:52:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1524&quot; title=&quot;parallel execution failed if mapred.job.name is set&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1524&quot;&gt;&lt;del&gt;HIVE-1524&lt;/del&gt;&lt;/a&gt; backporting to HIVE 0.6 branch&lt;/p&gt;</comment>
                            <comment id="12915651" author="nzhang" created="Tue, 28 Sep 2010 07:19:44 +0000"  >&lt;p&gt;Thanks for back porting to 0.6 yourchanges. The code changes look good. Can you include the other 2 files (parallel.q and parallel.q.out) in the patch as well? &lt;/p&gt;</comment>
                            <comment id="12915703" author="yourchanges" created="Tue, 28 Sep 2010 10:39:24 +0000"  >&lt;p&gt;I have re-upload this patch including parallel.q and parallel.q.out&lt;/p&gt;</comment>
                            <comment id="12915916" author="cwsteinbach" created="Tue, 28 Sep 2010 20:44:36 +0000"  >&lt;p&gt;Reopening for backport to 0.6&lt;/p&gt;</comment>
                            <comment id="12915949" author="nzhang" created="Tue, 28 Sep 2010 22:37:27 +0000"  >&lt;p&gt;Currently branch 0.6 is broken. It may be caused by &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-675&quot; title=&quot;Add Database/Schema support to Hive QL&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-675&quot;&gt;&lt;del&gt;HIVE-675&lt;/del&gt;&lt;/a&gt; patch. I&apos;ll run test after that one is resolved. &lt;/p&gt;</comment>
                            <comment id="12916108" author="yourchanges" created="Wed, 29 Sep 2010 11:26:22 +0000"  >&lt;p&gt;I have done the load test in our company using branch 0.6 with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1524&quot; title=&quot;parallel execution failed if mapred.job.name is set&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1524&quot;&gt;&lt;del&gt;HIVE-1524&lt;/del&gt;&lt;/a&gt; patch, it seems ok. &lt;br/&gt;
And another interesting thing is the &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1019&quot; title=&quot;java.io.FileNotFoundException: HIVE_PLAN (No such file or directory)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1019&quot;&gt;&lt;del&gt;HIVE-1019&lt;/del&gt;&lt;/a&gt; problem will be sloved by &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1524&quot; title=&quot;parallel execution failed if mapred.job.name is set&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1524&quot;&gt;&lt;del&gt;HIVE-1524&lt;/del&gt;&lt;/a&gt; as same time, if &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1524&quot; title=&quot;parallel execution failed if mapred.job.name is set&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1524&quot;&gt;&lt;del&gt;HIVE-1524&lt;/del&gt;&lt;/a&gt; works well with branch 0.6&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12455826" name="HIVE-1524-for-Hive-0.6.patch" size="37500" author="yourchanges" created="Tue, 28 Sep 2010 10:39:23 +0000"/>
                            <attachment id="12451708" name="HIVE-1524.2.patch" size="39717" author="nzhang" created="Tue, 10 Aug 2010 20:41:39 +0000"/>
                            <attachment id="12451640" name="HIVE-1524.patch" size="39705" author="nzhang" created="Tue, 10 Aug 2010 07:02:34 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 10 Aug 2010 18:26:21 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72857</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 17 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfin:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123164</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1525] deal with change/removal of columns covered by an index</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1525</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;If an index has been created on a column, should we prevent that column from being dropped or changed?&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471226">HIVE-1525</key>
            <summary>deal with change/removal of columns covered by an index</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="jvs">John Sichi</assignee>
                                    <reporter username="jvs">John Sichi</reporter>
                        <labels>
                    </labels>
                <created>Tue, 10 Aug 2010 20:00:39 +0000</created>
                <updated>Wed, 20 Apr 2011 23:59:36 +0000</updated>
                                            <version>0.7.0</version>
                                                    <component>Indexing</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42459</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 24 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i010ev:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3832</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-1526] Hive should depend on a release version of Thrift</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1526</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Hive should depend on a release version of Thrift, and ideally it should use Ivy to resolve this dependency.&lt;/p&gt;

&lt;p&gt;The Thrift folks are working on adding Thrift artifacts to a maven repository here: &lt;a href=&quot;https://issues.apache.org/jira/browse/THRIFT-363&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/THRIFT-363&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471232">HIVE-1526</key>
            <summary>Hive should depend on a release version of Thrift</summary>
                <type id="3" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21148&amp;avatarType=issuetype">Task</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cwsteinbach">Carl Steinbach</assignee>
                                    <reporter username="cwsteinbach">Carl Steinbach</reporter>
                        <labels>
                    </labels>
                <created>Tue, 10 Aug 2010 20:56:50 +0000</created>
                <updated>Thu, 2 May 2013 02:29:33 +0000</updated>
                            <resolved>Thu, 9 Dec 2010 18:32:54 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Build Infrastructure</component>
                    <component>Clients</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>11</watches>
                                                                <comments>
                            <comment id="12912765" author="tlipcon" created="Mon, 20 Sep 2010 23:01:42 +0000"  >&lt;p&gt;Planning on upgrading to 0.4.0. The main incompatible changes to deal with:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Methods that return enums now actually return a java enum type instead of an int (eg fb303&apos;s get_status method as well as the operator and stage getType() methods)&lt;/li&gt;
	&lt;li&gt;readBinary and writeBinary now use ByteBuffer instead of byte[]&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Unfortunately the maven situation is still not yet sorted out. I built a libthrift.jar and a libfb303.jar from the 0.4.0 release tree and will upload them here. Had to fix a minor issue to get fb303 to build (see &lt;a href=&quot;https://issues.apache.org/jira/browse/THRIFT-381&quot; title=&quot;Fail fast if configure detects C++ problems&quot; class=&quot;issue-link&quot; data-issue-key=&quot;THRIFT-381&quot;&gt;&lt;del&gt;THRIFT-381&lt;/del&gt;&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Aside from that, it seems pretty straightforward. I have a patch, running unit tests now.&lt;/p&gt;</comment>
                            <comment id="12912768" author="tlipcon" created="Mon, 20 Sep 2010 23:08:07 +0000"  >&lt;p&gt;Er, sorry, not &lt;a href=&quot;https://issues.apache.org/jira/browse/THRIFT-381&quot; title=&quot;Fail fast if configure detects C++ problems&quot; class=&quot;issue-link&quot; data-issue-key=&quot;THRIFT-381&quot;&gt;&lt;del&gt;THRIFT-381&lt;/del&gt;&lt;/a&gt;, but rather &lt;a href=&quot;https://issues.apache.org/jira/browse/THRIFT-907&quot; title=&quot;libfb303 doesn&amp;#39;t compile in 0.4.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;THRIFT-907&quot;&gt;&lt;del&gt;THRIFT-907&lt;/del&gt;&lt;/a&gt;. Too many browser tabs!&lt;/p&gt;</comment>
                            <comment id="12913259" author="jvs" created="Tue, 21 Sep 2010 21:18:10 +0000"  >&lt;p&gt;Note &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1527&quot; title=&quot;Remove Thrift generated code from version control&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1527&quot;&gt;HIVE-1527&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="12913824" author="tlipcon" created="Wed, 22 Sep 2010 22:36:01 +0000"  >&lt;p&gt;Here is a patch along with the newly built jars from Thrift 0.4.0.&lt;/p&gt;

&lt;p&gt;I agree that long term we should make codegen part of the build, but I think it&apos;s enough of a hassle to require everyone to install the same version of thrift, we should punt for now.&lt;/p&gt;</comment>
                            <comment id="12913843" author="nzhang" created="Wed, 22 Sep 2010 23:29:15 +0000"  >&lt;p&gt;The Hive ODBC code is dependent on Thrift as well. In particular the hive client and unixODBC libraries have to be linked with the new libthrift.so. Can you test if the ODBC code is compatible with the new thrift version?&lt;/p&gt;</comment>
                            <comment id="12913933" author="cwsteinbach" created="Thu, 23 Sep 2010 07:21:28 +0000"  >&lt;p&gt;@Todd: Can you please regenerate this patch? Both &apos;patch -p0&apos; and &apos;git apply -p0&apos; fail. Thanks.&lt;/p&gt;</comment>
                            <comment id="12914207" author="tlipcon" created="Thu, 23 Sep 2010 20:10:43 +0000"  >&lt;p&gt;Hi Carl. It appears to apply fine for me on today&apos;s trunk:&lt;/p&gt;

&lt;p&gt;todd@todd-laptop:~/git/hive$ git reset --hard HEAD&lt;br/&gt;
HEAD is now at 08d5e5b &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1661&quot; title=&quot;Default values for parameters&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1661&quot;&gt;&lt;del&gt;HIVE-1661&lt;/del&gt;&lt;/a&gt;. Default values for parameters (Siying Dong via He Yongqiang)&lt;br/&gt;
todd@todd-laptop:~/git/hive$ curl &apos;https://issues.apache.org/jira/secure/attachment/12455323/hive-1526.txt&apos; | patch -p0&lt;br/&gt;
... patch output....&lt;br/&gt;
todd@todd-laptop:~/git/hive$ &lt;/p&gt;

&lt;p&gt;Sure you&apos;re up to date on trunk?&lt;/p&gt;</comment>
                            <comment id="12914255" author="cwsteinbach" created="Thu, 23 Sep 2010 22:12:20 +0000"  >&lt;p&gt;Sorry, that was a false alarm about the patch. Turns out the github Hive mirror lags the main repo by about a week.&lt;/p&gt;

&lt;p&gt;@Todd: This patch introduces unsatisfied dependencies on slf4j-api and slf4j-log4j12. Can you please update the patch to pull these dependencies down with Ivy?&lt;/p&gt;</comment>
                            <comment id="12914384" author="cwsteinbach" created="Fri, 24 Sep 2010 09:12:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1526&quot; title=&quot;Hive should depend on a release version of Thrift&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1526&quot;&gt;&lt;del&gt;HIVE-1526&lt;/del&gt;&lt;/a&gt;.2.patch.txt:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Manage slf4j dependencies with Ivy.&lt;/li&gt;
	&lt;li&gt;Added slf4j dependencies to eclipse classpath.&lt;/li&gt;
	&lt;li&gt;Added &quot;thriftif&quot; macro to ${hive.root}/build.xml which triggers recompilation of all thrift stubs.&lt;/li&gt;
	&lt;li&gt;Modified odbc/Makefile to use Thrift libs and headers in THRIFT_HOME instead of the ones that were checked into service/include.&lt;/li&gt;
	&lt;li&gt;Modified odbc/Makefile to build thrift generated cpp artifacts in ql/src&lt;/li&gt;
	&lt;li&gt;Removed thrift headers/code from service/include (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1527&quot; title=&quot;Remove Thrift generated code from version control&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1527&quot;&gt;HIVE-1527&lt;/a&gt;)&lt;/li&gt;
	&lt;li&gt;Added some missing #includes to the hiveclient source files in odbc/src/cpp.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Testing:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Tested eclipse launch configurations.&lt;/li&gt;
	&lt;li&gt;Built CPP hiveclient lib and tested against HiveServer using HiveClientTestC program.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12916741" author="nzhang" created="Fri, 1 Oct 2010 00:30:35 +0000"  >&lt;p&gt;Carl and Todd, is this a blocking issue for 0.6? If not, we can make it in 0.7 and get 0.6 release ASAP.&lt;/p&gt;</comment>
                            <comment id="12916751" author="cwsteinbach" created="Fri, 1 Oct 2010 01:04:36 +0000"  >&lt;p&gt;@Ning: I removed the 0.6 tag. Can you please review this change? Thanks.&lt;/p&gt;</comment>
                            <comment id="12916798" author="nzhang" created="Fri, 1 Oct 2010 06:19:14 +0000"  >&lt;p&gt;I will take a look. &lt;/p&gt;</comment>
                            <comment id="12923715" author="tlipcon" created="Fri, 22 Oct 2010 00:40:03 +0000"  >&lt;p&gt;Hey Ning. Can you take a look at this change? It&apos;s no longer in sync with trunk, but I don&apos;t want to have to redo it twice (it&apos;s a pain since you have to regenerate all the files, etc). If the basics look OK I will resync with trunk and then we can commit soonafter.&lt;/p&gt;</comment>
                            <comment id="12924023" author="jvs" created="Fri, 22 Oct 2010 20:56:57 +0000"  >&lt;p&gt;Ning is currently working on some non-Hive tasks, so we&apos;ll get someone else to take a look.  If you have time after next Monday&apos;s contributor meeting, maybe we can do a quick review then in person.&lt;/p&gt;</comment>
                            <comment id="12924036" author="tlipcon" created="Fri, 22 Oct 2010 21:22:57 +0000"  >&lt;p&gt;Hey John. I&apos;m actually headed to Tokyo for the next two weeks so won&apos;t be at the contributors meeting. Perhaps Carl can look at this with you. Note that we should update the change to Thrift 0.5.0 release before committing, but the review can happen on current code.&lt;/p&gt;</comment>
                            <comment id="12924065" author="cwsteinbach" created="Fri, 22 Oct 2010 22:38:15 +0000"  >&lt;p&gt;I&apos;ll be at the contributors meeting. John, if you have time lets meet afterwards to&lt;br/&gt;
review this patch.&lt;/p&gt;</comment>
                            <comment id="12925018" author="pradeepkth" created="Tue, 26 Oct 2010 16:18:39 +0000"  >&lt;p&gt;Any update on this? I would like to submit a patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1696&quot; title=&quot;Add delegation token support to metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1696&quot;&gt;&lt;del&gt;HIVE-1696&lt;/del&gt;&lt;/a&gt; which depends on this and &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-842&quot; title=&quot;Authentication Infrastructure for Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-842&quot;&gt;&lt;del&gt;HIVE-842&lt;/del&gt;&lt;/a&gt;. Since this is currently broken against trunk, am waiting for the new patch (based off thrift-0.5 ?) so I can generate a patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1696&quot; title=&quot;Add delegation token support to metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1696&quot;&gt;&lt;del&gt;HIVE-1696&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="12925238" author="cwsteinbach" created="Wed, 27 Oct 2010 02:17:34 +0000"  >&lt;p&gt;We discussed this at the contributors meeting yesterday. I&apos;m going to rebase the patch,&lt;br/&gt;
modify it to use Thrift 0.5.0, and then make the patch easier to review by removing the&lt;br/&gt;
the thrift generated code. I plan to get to this sometime in the next couple of days.&lt;/p&gt;</comment>
                            <comment id="12927081" author="cwsteinbach" created="Mon, 1 Nov 2010 18:46:14 +0000"  >&lt;p&gt;Need to update this page once this change is committed: &lt;a href=&quot;http://wiki.apache.org/hadoop/Hive/HowToContribute#Generating_Code&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Hive/HowToContribute#Generating_Code&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12927549" author="pkamath" created="Tue, 2 Nov 2010 19:01:21 +0000"  >&lt;p&gt;Hi Carl - just wondering if you have had a chance to look at this - a new patch for this issue will help me create a patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1696&quot; title=&quot;Add delegation token support to metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1696&quot;&gt;&lt;del&gt;HIVE-1696&lt;/del&gt;&lt;/a&gt; (I suspect we will need to redo &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-842&quot; title=&quot;Authentication Infrastructure for Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-842&quot;&gt;&lt;del&gt;HIVE-842&lt;/del&gt;&lt;/a&gt; as well - I can take a stab at that once this patch is ready).&lt;/p&gt;</comment>
                            <comment id="12929632" author="pkamath" created="Mon, 8 Nov 2010 17:06:44 +0000"  >&lt;p&gt;Hi Carl - just wondering if you have had a chance to look at this..&lt;/p&gt;</comment>
                            <comment id="12929777" author="cwsteinbach" created="Mon, 8 Nov 2010 22:35:51 +0000"  >&lt;p&gt;@Pradeep: working on it now &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12933372" author="hbasereviewboard" created="Thu, 18 Nov 2010 09:26:15 +0000"  >&lt;p&gt;Message from: &quot;Carl Steinbach&quot; &amp;lt;carl@cloudera.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/1242/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/1242/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for Hive Developers.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Review request for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1526&quot; title=&quot;Hive should depend on a release version of Thrift&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1526&quot;&gt;&lt;del&gt;HIVE-1526&lt;/del&gt;&lt;/a&gt;: upgrade to Thrift 0.5.0&lt;/p&gt;

&lt;p&gt;This review request does not include the code generated by the Thrift compiler.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1526&quot; title=&quot;Hive should depend on a release version of Thrift&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1526&quot;&gt;&lt;del&gt;HIVE-1526&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/HIVE-1526&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HIVE-1526&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  .classpath._hbase 15fd1c5 &lt;br/&gt;
  build-common.xml 53fd1b1 &lt;br/&gt;
  build.xml dc20725 &lt;br/&gt;
  eclipse-templates/.classpath d06d6bd &lt;br/&gt;
  eclipse-templates/.classpath._hbase b81c24a &lt;br/&gt;
  ivy/libraries.properties fdd54c8 &lt;br/&gt;
  lib/README 72d90b7 &lt;br/&gt;
  lib/libfb303.LICENSE 6b5c3b1 &lt;br/&gt;
  lib/libfb303.jar 516b597 &lt;br/&gt;
  lib/libthrift.LICENSE 6b5c3b1 &lt;br/&gt;
  lib/libthrift.jar 7e7f90e &lt;br/&gt;
  lib/thrift-0.5.0.jar PRE-CREATION &lt;br/&gt;
  lib/thrift-fb303-0.5.0.jar PRE-CREATION &lt;br/&gt;
  lib/thrift-fb303.LICENSE PRE-CREATION &lt;br/&gt;
  lib/thrift.LICENSE PRE-CREATION &lt;br/&gt;
  metastore/build.xml ffb86c1 &lt;br/&gt;
  metastore/if/hive_metastore.thrift 9c314cc &lt;br/&gt;
  metastore/ivy.xml 2e39eb8 &lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java a4f1853 &lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java 4f5623c &lt;br/&gt;
  odbc/Makefile 816ffd4 &lt;br/&gt;
  odbc/build.xml 64cf988 &lt;br/&gt;
  odbc/src/cpp/HiveRowSet.cpp b4dc2c0 &lt;br/&gt;
  odbc/src/cpp/hiveclienthelper.cpp e2d48f3 &lt;br/&gt;
  ql/build.xml a025a2b &lt;br/&gt;
  ql/if/queryplan.thrift aca0e8f &lt;br/&gt;
  ql/ivy.xml e72a450 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/AbstractMapJoinOperator.java 5ccb909 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/CollectOperator.java 7daea2d &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ConditionalTask.java bf7b7a5 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/CopyTask.java 46b8bf4 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 0a9cdf4 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java af6e0af &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ExplainTask.java a572bcb &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ExtractOperator.java 7bf8886 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/FetchTask.java de2c42d &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java d510f95 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/FilterOperator.java 554bf25 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ForwardOperator.java 2a35c96 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionTask.java 1e6941e &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java 8423178 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableDummyOperator.java 87fc61c &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableSinkOperator.java 9fe35ec &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/JoinOperator.java e16df36 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/LateralViewForwardOperator.java c070aca &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/LateralViewJoinOperator.java 5eb9098 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/LimitOperator.java da5dbb9 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java 98571dd &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java 887ad30 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/MapRedTask.java 0fab63c &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/MapredLocalTask.java c5aa3d6 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java 7fbc586 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java 6c6ea89 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java 592f4f7 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java 001d1f0 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java 4f8b4bd &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java d644a33 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java 47adbed &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java 96e63b8 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java 893530c &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/UDTFOperator.java 682f38a &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/UnionOperator.java 2c42ed7 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/index/compact/CompactIndexHandler.java 0d60507 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/index/compact/IndexMetadataChangeTask.java 734bd72 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java c5fb22b &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java 7167196 &lt;br/&gt;
  serde/build.xml b64b142 &lt;br/&gt;
  serde/ivy.xml da69342 &lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/thrift/TBinarySortableProtocol.java 961c24f &lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/thrift/TCTLSeparatedProtocol.java e781a06 &lt;br/&gt;
  service/build.xml ffd1854 &lt;br/&gt;
  service/if/hive_service.thrift db9fab6 &lt;br/&gt;
  service/include/thrift/TLogging.h 2df82dd &lt;br/&gt;
  service/include/thrift/TProcessor.h f2d5279 &lt;br/&gt;
  service/include/thrift/TReflectionLocal.h e83e475 &lt;br/&gt;
  service/include/thrift/Thrift.h 27a6476 &lt;br/&gt;
  service/include/thrift/concurrency/Exception.h ec46629 &lt;br/&gt;
  service/include/thrift/concurrency/FunctionRunner.h 2216927 &lt;br/&gt;
  service/include/thrift/concurrency/Monitor.h 234bf32 &lt;br/&gt;
  service/include/thrift/concurrency/Mutex.h 73c73e0 &lt;br/&gt;
  service/include/thrift/concurrency/PosixThreadFactory.h d6d83a3 &lt;br/&gt;
  service/include/thrift/concurrency/Thread.h d4282ad &lt;br/&gt;
  service/include/thrift/concurrency/ThreadManager.h 6e5a178 &lt;br/&gt;
  service/include/thrift/concurrency/TimerManager.h dfbf0ea &lt;br/&gt;
  service/include/thrift/concurrency/Util.h 25fcc20 &lt;br/&gt;
  service/include/thrift/config.h 70264f2 &lt;br/&gt;
  service/include/thrift/fb303/FacebookBase.h fd169e6 &lt;br/&gt;
  service/include/thrift/fb303/FacebookService.h dcd843f &lt;br/&gt;
  service/include/thrift/fb303/FacebookService.cpp 4a34362 &lt;br/&gt;
  service/include/thrift/fb303/ServiceTracker.h 9304386 &lt;br/&gt;
  service/include/thrift/fb303/fb303_constants.h 19405bc &lt;br/&gt;
  service/include/thrift/fb303/fb303_constants.cpp 66b8782 &lt;br/&gt;
  service/include/thrift/fb303/fb303_types.h 18936f9 &lt;br/&gt;
  service/include/thrift/fb303/fb303_types.cpp f290125 &lt;br/&gt;
  service/include/thrift/fb303/if/fb303.thrift 66c8315 &lt;br/&gt;
  service/include/thrift/if/reflection_limited.thrift 993c46e &lt;br/&gt;
  service/include/thrift/processor/PeekProcessor.h 0f7c016 &lt;br/&gt;
  service/include/thrift/processor/StatsProcessor.h 820b3ad &lt;br/&gt;
  service/include/thrift/protocol/TBase64Utils.h 3def733 &lt;br/&gt;
  service/include/thrift/protocol/TBinaryProtocol.h 7fd3de6 &lt;br/&gt;
  service/include/thrift/protocol/TCompactProtocol.h b4e06f0 &lt;br/&gt;
  service/include/thrift/protocol/TDebugProtocol.h ab69e0c &lt;br/&gt;
  service/include/thrift/protocol/TDenseProtocol.h 7655a47 &lt;br/&gt;
  service/include/thrift/protocol/TJSONProtocol.h 2df499a &lt;br/&gt;
  service/include/thrift/protocol/TOneWayProtocol.h 6f08fe1 &lt;br/&gt;
  service/include/thrift/protocol/TProtocol.h 4025827 &lt;br/&gt;
  service/include/thrift/protocol/TProtocolException.h 33011b3 &lt;br/&gt;
  service/include/thrift/protocol/TProtocolTap.h 5580216 &lt;br/&gt;
  service/include/thrift/reflection_limited_types.h 677cb4a &lt;br/&gt;
  service/include/thrift/server/TNonblockingServer.h 8506507 &lt;br/&gt;
  service/include/thrift/server/TServer.h 5c4c588 &lt;br/&gt;
  service/include/thrift/server/TSimpleServer.h c4fc91c &lt;br/&gt;
  service/include/thrift/server/TThreadPoolServer.h 7b7e906 &lt;br/&gt;
  service/include/thrift/server/TThreadedServer.h 4d0811a &lt;br/&gt;
  service/include/thrift/transport/TBufferTransports.h 1908205 &lt;br/&gt;
  service/include/thrift/transport/TFDTransport.h bda5d82 &lt;br/&gt;
  service/include/thrift/transport/TFileTransport.h b08c5c8 &lt;br/&gt;
  service/include/thrift/transport/THttpClient.h f4be4c1 &lt;br/&gt;
  service/include/thrift/transport/TServerSocket.h a6be017 &lt;br/&gt;
  service/include/thrift/transport/TServerTransport.h 40bbc6c &lt;br/&gt;
  service/include/thrift/transport/TShortReadTransport.h 3df8a57 &lt;br/&gt;
  service/include/thrift/transport/TSimpleFileTransport.h 6cc52ea &lt;br/&gt;
  service/include/thrift/transport/TSocket.h b0f445a &lt;br/&gt;
  service/include/thrift/transport/TSocketPool.h 8c50669 &lt;br/&gt;
  service/include/thrift/transport/TTransport.h eb0d5df &lt;br/&gt;
  service/include/thrift/transport/TTransportException.h 330785c &lt;br/&gt;
  service/include/thrift/transport/TTransportUtils.h d65c916 &lt;br/&gt;
  service/include/thrift/transport/TZlibTransport.h 1439d9d &lt;br/&gt;
  service/src/java/org/apache/hadoop/hive/service/HiveServer.java 89cf336 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.cloudera.org/r/1242/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/1242/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Carl&lt;/p&gt;

</comment>
                            <comment id="12933377" author="cwsteinbach" created="Thu, 18 Nov 2010 09:49:02 +0000"  >&lt;p&gt;@Ning: Can you please take a look at this? Thanks!&lt;/p&gt;</comment>
                            <comment id="12933547" author="nzhang" created="Thu, 18 Nov 2010 19:52:54 +0000"  >&lt;p&gt;Thanks Carl for the work. I&apos;ll be returning to Hive the coming week. I&apos;ll review this JIRA as the highest priority then. &lt;/p&gt;</comment>
                            <comment id="12934401" author="ashutoshc" created="Mon, 22 Nov 2010 06:39:11 +0000"  >&lt;p&gt;I was testing this patch. It seems that fields defined in structs in thrift idl, thrift now generates them as private instead of as public in previous releases. As a result, tests in serde2 don&apos;t compile. This additional patch is required to compile the test sources in serde2/ .&lt;/p&gt;</comment>
                            <comment id="12934640" author="hbasereviewboard" created="Mon, 22 Nov 2010 22:38:15 +0000"  >&lt;p&gt;Message from: &quot;Ning Zhang&quot; &amp;lt;n.ning.z@gmail.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/1242/#review1958&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/1242/#review1958&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;



&lt;p&gt;.classpath._hbase&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/1242/#comment6177&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/1242/#comment6177&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Is deleting of this file because of we eliminated hadoop pre-0.20 versions? &lt;/p&gt;

&lt;p&gt;    John, can you confirm if this file can be deleted?&lt;/p&gt;



&lt;p&gt;ql/src/java/org/apache/hadoop/hive/ql/exec/MapRedTask.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/1242/#comment6207&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/1242/#comment6207&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    This should not be MAPREDLOCAL, but MAPRED. Since MapRedTask extends ExecDriver which implements getType(), this function should not be here in MapRedTask.&lt;/p&gt;



&lt;p&gt;ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/1242/#comment6208&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/1242/#comment6208&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    It would be better to define a new OperatorType for SMBMapJoinOperator.&lt;/p&gt;



&lt;p&gt;ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/1242/#comment6209&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/1242/#comment6209&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    commnet: -1 -&amp;gt; null&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Ning&lt;/li&gt;
&lt;/ul&gt;



</comment>
                            <comment id="12934643" author="hbasereviewboard" created="Mon, 22 Nov 2010 22:46:13 +0000"  >&lt;p&gt;Message from: &quot;Carl Steinbach&quot; &amp;lt;carl@cloudera.com&amp;gt;&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-11-22 14:37:20, Ning Zhang wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; .classpath._hbase, line 1&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/1242/diff/1/?file=17455#file17455line1&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/1242/diff/1/?file=17455#file17455line1&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Is deleting of this file because of we eliminated hadoop pre-0.20 versions? &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     John, can you confirm if this file can be deleted?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is an eclipse project classpath file. It should not have been checked in. &lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Carl&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/1242/#review1958&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/1242/#review1958&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


</comment>
                            <comment id="12934650" author="nzhang@fb.com" created="Mon, 22 Nov 2010 23:00:15 +0000"  >&lt;p&gt;I see. That&apos;s OK then. &lt;/p&gt;



</comment>
                            <comment id="12934651" author="nzhang@fb.com" created="Mon, 22 Nov 2010 23:00:19 +0000"  >&lt;p&gt;I see. That&apos;s OK then. &lt;/p&gt;



</comment>
                            <comment id="12934656" author="he yongqiang" created="Mon, 22 Nov 2010 23:13:02 +0000"  >&lt;p&gt;can we get this in after &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-78&quot; title=&quot;Authorization infrastructure for Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-78&quot;&gt;&lt;del&gt;HIVE-78&lt;/del&gt;&lt;/a&gt; since this is mostly auto-generated files?&lt;/p&gt;</comment>
                            <comment id="12934677" author="cwsteinbach" created="Tue, 23 Nov 2010 00:53:51 +0000"  >&lt;p&gt;@Yongqiang: that&apos;s fine with me, assuming that &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-78&quot; title=&quot;Authorization infrastructure for Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-78&quot;&gt;&lt;del&gt;HIVE-78&lt;/del&gt;&lt;/a&gt; is close to getting committed. I think this ticket is blocking some of the security work.&lt;/p&gt;</comment>
                            <comment id="12934681" author="devaraj" created="Tue, 23 Nov 2010 01:04:06 +0000"  >&lt;p&gt;Guys, it will be really appreciated if this patch can be committed now. This blocks the other jiras on Security - &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-842&quot; title=&quot;Authentication Infrastructure for Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-842&quot;&gt;&lt;del&gt;HIVE-842&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1696&quot; title=&quot;Add delegation token support to metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1696&quot;&gt;&lt;del&gt;HIVE-1696&lt;/del&gt;&lt;/a&gt;. Since Carl and others have done so much work on the thrift patch already, I think it makes sense to have this patch committed now. Thanks!&lt;/p&gt;</comment>
                            <comment id="12934685" author="he yongqiang" created="Tue, 23 Nov 2010 01:16:08 +0000"  >&lt;p&gt;ok. i am fine to get this committed before &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-78&quot; title=&quot;Authorization infrastructure for Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-78&quot;&gt;&lt;del&gt;HIVE-78&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="12934942" author="nzhang" created="Tue, 23 Nov 2010 18:00:25 +0000"  >&lt;p&gt;Carl, can you upload a new patch taking consideration of my other comments? I&apos;ll start test.&lt;/p&gt;</comment>
                            <comment id="12935073" author="cwsteinbach" created="Tue, 23 Nov 2010 21:59:12 +0000"  >&lt;p&gt;@Ning: working on it now.&lt;/p&gt;</comment>
                            <comment id="12964683" author="cwsteinbach" created="Mon, 29 Nov 2010 10:32:01 +0000"  >&lt;p&gt;Updated patch with changes suggested by Ning and Ashutosh.&lt;/p&gt;</comment>
                            <comment id="12964684" author="hbasereviewboard" created="Mon, 29 Nov 2010 10:32:39 +0000"  >&lt;p&gt;Message from: &quot;Carl Steinbach&quot; &amp;lt;carl@cloudera.com&amp;gt;&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-11-22 14:37:20, Ning Zhang wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; ql/src/java/org/apache/hadoop/hive/ql/exec/MapRedTask.java, line 416&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/1242/diff/1/?file=17504#file17504line416&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/1242/diff/1/?file=17504#file17504line416&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     This should not be MAPREDLOCAL, but MAPRED. Since MapRedTask extends ExecDriver which implements getType(), this function should not be here in MapRedTask.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Removed.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-11-22 14:37:20, Ning Zhang wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java, line 592&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/1242/diff/1/?file=17509#file17509line592&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/1242/diff/1/?file=17509#file17509line592&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     It would be better to define a new OperatorType for SMBMapJoinOperator.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Done.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-11-22 14:37:20, Ning Zhang wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java, line 348&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/1242/diff/1/?file=17514#file17514line348&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/1242/diff/1/?file=17514#file17514line348&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     commnet: -1 -&amp;gt; null&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I made this method abstract.&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Carl&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/1242/#review1958&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/1242/#review1958&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


</comment>
                            <comment id="12964685" author="hbasereviewboard" created="Mon, 29 Nov 2010 10:32:40 +0000"  >&lt;p&gt;Message from: &quot;Carl Steinbach&quot; &amp;lt;carl@cloudera.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/1242/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/1242/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2010-11-29 02:30:23.538215)&lt;/p&gt;


&lt;p&gt;Review request for Hive Developers.&lt;/p&gt;


&lt;p&gt;Changes&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Patch updated with changes suggested by Ning and Ashutosh.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Review request for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1526&quot; title=&quot;Hive should depend on a release version of Thrift&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1526&quot;&gt;&lt;del&gt;HIVE-1526&lt;/del&gt;&lt;/a&gt;: upgrade to Thrift 0.5.0&lt;/p&gt;

&lt;p&gt;This review request does not include the code generated by the Thrift compiler.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1526&quot; title=&quot;Hive should depend on a release version of Thrift&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1526&quot;&gt;&lt;del&gt;HIVE-1526&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/HIVE-1526&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HIVE-1526&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  .classpath._hbase 15fd1c5 &lt;br/&gt;
  .gitignore e54804f &lt;br/&gt;
  build-common.xml 53fd1b1 &lt;br/&gt;
  build.xml dc20725 &lt;br/&gt;
  eclipse-templates/.classpath d06d6bd &lt;br/&gt;
  eclipse-templates/.classpath._hbase b81c24a &lt;br/&gt;
  ivy/libraries.properties fdd54c8 &lt;br/&gt;
  lib/README 72d90b7 &lt;br/&gt;
  lib/libfb303.LICENSE 6b5c3b1 &lt;br/&gt;
  lib/libfb303.jar 516b597 &lt;br/&gt;
  lib/libthrift.LICENSE 6b5c3b1 &lt;br/&gt;
  lib/libthrift.jar 7e7f90e &lt;br/&gt;
  lib/thrift-0.5.0.jar PRE-CREATION &lt;br/&gt;
  lib/thrift-fb303-0.5.0.jar PRE-CREATION &lt;br/&gt;
  lib/thrift-fb303.LICENSE PRE-CREATION &lt;br/&gt;
  lib/thrift.LICENSE PRE-CREATION &lt;br/&gt;
  metastore/build.xml ffb86c1 &lt;br/&gt;
  metastore/if/hive_metastore.thrift 0e47312 &lt;br/&gt;
  metastore/ivy.xml 2e39eb8 &lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 96ef5b7 &lt;br/&gt;
  metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java 4c977b8 &lt;br/&gt;
  odbc/Makefile 816ffd4 &lt;br/&gt;
  odbc/build.xml 64cf988 &lt;br/&gt;
  odbc/src/cpp/HiveRowSet.cpp b4dc2c0 &lt;br/&gt;
  odbc/src/cpp/hiveclienthelper.cpp e2d48f3 &lt;br/&gt;
  ql/build.xml a025a2b &lt;br/&gt;
  ql/if/queryplan.thrift aca0e8f &lt;br/&gt;
  ql/ivy.xml e72a450 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/AbstractMapJoinOperator.java 5ccb909 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/CollectOperator.java 7daea2d &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ConditionalTask.java bf7b7a5 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/CopyTask.java 46b8bf4 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 7168884 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java 49e708c &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ExplainTask.java a572bcb &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ExtractOperator.java 7bf8886 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/FetchTask.java de2c42d &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java d510f95 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/FilterOperator.java 554bf25 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ForwardOperator.java 2a35c96 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionTask.java 1e6941e &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java 8423178 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableDummyOperator.java 87fc61c &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableSinkOperator.java 4cf055f &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/JoinOperator.java e16df36 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/LateralViewForwardOperator.java c070aca &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/LateralViewJoinOperator.java 5eb9098 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/LimitOperator.java da5dbb9 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java c9f99ac &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java 887ad30 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/MapRedTask.java 0fab63c &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/MapredLocalTask.java c5aa3d6 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java 7fbc586 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java 6c6ea89 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java 592f4f7 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java 001d1f0 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java 4f8b4bd &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java d644a33 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java 47adbed &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java 96e63b8 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java 893530c &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/UDTFOperator.java 682f38a &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/UnionOperator.java 2c42ed7 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/index/compact/CompactIndexHandler.java 0d60507 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/index/compact/IndexMetadataChangeTask.java 734bd72 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java 5d33550 &lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java 7167196 &lt;br/&gt;
  serde/build.xml b64b142 &lt;br/&gt;
  serde/ivy.xml da69342 &lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/thrift/TBinarySortableProtocol.java 961c24f &lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/thrift/TCTLSeparatedProtocol.java e781a06 &lt;br/&gt;
  serde/src/test/org/apache/hadoop/hive/serde2/objectinspector/TestObjectInspectorUtils.java 4bdcf88 &lt;br/&gt;
  serde/src/test/org/apache/hadoop/hive/serde2/objectinspector/TestThriftObjectInspectors.java 99b0e90 &lt;br/&gt;
  service/build.xml ffd1854 &lt;br/&gt;
  service/if/hive_service.thrift db9fab6 &lt;br/&gt;
  service/include/thrift/TLogging.h 2df82dd &lt;br/&gt;
  service/include/thrift/TProcessor.h f2d5279 &lt;br/&gt;
  service/include/thrift/TReflectionLocal.h e83e475 &lt;br/&gt;
  service/include/thrift/Thrift.h 27a6476 &lt;br/&gt;
  service/include/thrift/concurrency/Exception.h ec46629 &lt;br/&gt;
  service/include/thrift/concurrency/FunctionRunner.h 2216927 &lt;br/&gt;
  service/include/thrift/concurrency/Monitor.h 234bf32 &lt;br/&gt;
  service/include/thrift/concurrency/Mutex.h 73c73e0 &lt;br/&gt;
  service/include/thrift/concurrency/PosixThreadFactory.h d6d83a3 &lt;br/&gt;
  service/include/thrift/concurrency/Thread.h d4282ad &lt;br/&gt;
  service/include/thrift/concurrency/ThreadManager.h 6e5a178 &lt;br/&gt;
  service/include/thrift/concurrency/TimerManager.h dfbf0ea &lt;br/&gt;
  service/include/thrift/concurrency/Util.h 25fcc20 &lt;br/&gt;
  service/include/thrift/config.h 70264f2 &lt;br/&gt;
  service/include/thrift/fb303/FacebookBase.h fd169e6 &lt;br/&gt;
  service/include/thrift/fb303/FacebookService.h dcd843f &lt;br/&gt;
  service/include/thrift/fb303/FacebookService.cpp 4a34362 &lt;br/&gt;
  service/include/thrift/fb303/ServiceTracker.h 9304386 &lt;br/&gt;
  service/include/thrift/fb303/fb303_constants.h 19405bc &lt;br/&gt;
  service/include/thrift/fb303/fb303_constants.cpp 66b8782 &lt;br/&gt;
  service/include/thrift/fb303/fb303_types.h 18936f9 &lt;br/&gt;
  service/include/thrift/fb303/fb303_types.cpp f290125 &lt;br/&gt;
  service/include/thrift/fb303/if/fb303.thrift 66c8315 &lt;br/&gt;
  service/include/thrift/if/reflection_limited.thrift 993c46e &lt;br/&gt;
  service/include/thrift/processor/PeekProcessor.h 0f7c016 &lt;br/&gt;
  service/include/thrift/processor/StatsProcessor.h 820b3ad &lt;br/&gt;
  service/include/thrift/protocol/TBase64Utils.h 3def733 &lt;br/&gt;
  service/include/thrift/protocol/TBinaryProtocol.h 7fd3de6 &lt;br/&gt;
  service/include/thrift/protocol/TCompactProtocol.h b4e06f0 &lt;br/&gt;
  service/include/thrift/protocol/TDebugProtocol.h ab69e0c &lt;br/&gt;
  service/include/thrift/protocol/TDenseProtocol.h 7655a47 &lt;br/&gt;
  service/include/thrift/protocol/TJSONProtocol.h 2df499a &lt;br/&gt;
  service/include/thrift/protocol/TOneWayProtocol.h 6f08fe1 &lt;br/&gt;
  service/include/thrift/protocol/TProtocol.h 4025827 &lt;br/&gt;
  service/include/thrift/protocol/TProtocolException.h 33011b3 &lt;br/&gt;
  service/include/thrift/protocol/TProtocolTap.h 5580216 &lt;br/&gt;
  service/include/thrift/reflection_limited_types.h 677cb4a &lt;br/&gt;
  service/include/thrift/server/TNonblockingServer.h 8506507 &lt;br/&gt;
  service/include/thrift/server/TServer.h 5c4c588 &lt;br/&gt;
  service/include/thrift/server/TSimpleServer.h c4fc91c &lt;br/&gt;
  service/include/thrift/server/TThreadPoolServer.h 7b7e906 &lt;br/&gt;
  service/include/thrift/server/TThreadedServer.h 4d0811a &lt;br/&gt;
  service/include/thrift/transport/TBufferTransports.h 1908205 &lt;br/&gt;
  service/include/thrift/transport/TFDTransport.h bda5d82 &lt;br/&gt;
  service/include/thrift/transport/TFileTransport.h b08c5c8 &lt;br/&gt;
  service/include/thrift/transport/THttpClient.h f4be4c1 &lt;br/&gt;
  service/include/thrift/transport/TServerSocket.h a6be017 &lt;br/&gt;
  service/include/thrift/transport/TServerTransport.h 40bbc6c &lt;br/&gt;
  service/include/thrift/transport/TShortReadTransport.h 3df8a57 &lt;br/&gt;
  service/include/thrift/transport/TSimpleFileTransport.h 6cc52ea &lt;br/&gt;
  service/include/thrift/transport/TSocket.h b0f445a &lt;br/&gt;
  service/include/thrift/transport/TSocketPool.h 8c50669 &lt;br/&gt;
  service/include/thrift/transport/TTransport.h eb0d5df &lt;br/&gt;
  service/include/thrift/transport/TTransportException.h 330785c &lt;br/&gt;
  service/include/thrift/transport/TTransportUtils.h d65c916 &lt;br/&gt;
  service/include/thrift/transport/TZlibTransport.h 1439d9d &lt;br/&gt;
  service/src/java/org/apache/hadoop/hive/service/HiveServer.java 89cf336 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.cloudera.org/r/1242/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/1242/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Carl&lt;/p&gt;

</comment>
                            <comment id="12965138" author="nzhang" created="Tue, 30 Nov 2010 07:42:25 +0000"  >&lt;p&gt;The patch looks good from the cloudera review board. However there&apos;s system errors when I tried to download the latest patches. Carl, I&apos;m not sure if this is a transient error, but if it persist tomorrow, can you send me the patch by email (nzhang@fb.com)? &lt;/p&gt;</comment>
                            <comment id="12965436" author="cwsteinbach" created="Tue, 30 Nov 2010 21:00:16 +0000"  >&lt;p&gt;@Ning: I had the same problem downloading the patch so it must be corrupted. I attached new copies and verified that I can download them. Please try again.&lt;/p&gt;</comment>
                            <comment id="12965542" author="nzhang" created="Wed, 1 Dec 2010 02:11:16 +0000"  >&lt;p&gt;Thanks Carl. I&apos;ll start testing tonight. &lt;/p&gt;</comment>
                            <comment id="12965770" author="nzhang" created="Wed, 1 Dec 2010 18:03:37 +0000"  >&lt;p&gt;hi Carl, I tried compiling based on your complete patch and it gave compilation error related to thrift (something like serde/src/gen-javabean/org/apache/hadoop/hive/serde/test/InnerStruct.java:29: type org.apache.thrift.TBase does not take parameters). I did copied the thrift and fb303 jars to lib.&lt;/p&gt;

&lt;p&gt;I also tried to generate thrift files from your non-generated patch. The compilation also got some error. So do you need to do settings with the patches?&lt;/p&gt;</comment>
                            <comment id="12965793" author="ashutoshc" created="Wed, 1 Dec 2010 18:49:04 +0000"  >&lt;p&gt;Hey Ning, &lt;/p&gt;

&lt;p&gt;Can you paste the full stack trace? I did the following and everything worked as expected:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;$ svn co http:&lt;span class=&quot;code-comment&quot;&gt;//svn.apache.org/repos/asf/hive/trunk .
&lt;/span&gt;$ curl https:&lt;span class=&quot;code-comment&quot;&gt;//issues.apache.org/jira/secure/attachment/12464952/HIVE-1526-complete.5.patch.txt | patch -p0
&lt;/span&gt;$ cd lib/
$ wget https:&lt;span class=&quot;code-comment&quot;&gt;//issues.apache.org/jira/secure/attachment/12459901/thrift-fb303-0.5.0.jar 
&lt;/span&gt;$ wget https:&lt;span class=&quot;code-comment&quot;&gt;//issues.apache.org/jira/secure/attachment/12459901/thrift-fb303-0.5.0.jar
&lt;/span&gt;$ cd ..
$ ant &lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;
BUILD SUCCESSFUL
$ ant test
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now running the tests. Havent seen any failure yet. Will post back when tests finish.&lt;/p&gt;</comment>
                            <comment id="12965818" author="nzhang" created="Wed, 1 Dec 2010 19:40:10 +0000"  >&lt;p&gt;Attached the complete output of &apos;ant package: compile.err. Also note that the patch still include the lib/libthrift.jar and lib/libfb303.jar which are the old versions. But the error is the same even though replacing libthrft.jar and libfb303.jar with thrift-0.5.0.jar and thrift-fb303-0.5.0.jar.&lt;/p&gt;</comment>
                            <comment id="12965856" author="ashutoshc" created="Wed, 1 Dec 2010 21:40:28 +0000"  >&lt;p&gt;I greped for one of the classes which are reported as being not found in your compile.err&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;$ jar -tvf lib/thrift-0.5.0.jar | grep  TBaseHelper.class
 6739 Sun Nov 07 23:34:36 PST 2010 org/apache/thrift/TBaseHelper.class
$ jar -tvf libthrift.jar | grep  TBaseHelper.class
$
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;So, it seems like in your class path still libthrift.jar is getting picked up somehow instead of thrift-0.5.0.jar Can you try completely deleting libthrift.jar and libfb303.jar from your ${HIVE_ROOT}/ dir and then just have   thrift-0.5.0.jar and thrift-fb303-0.5.0.jar in your lib/ dir and then build again.&lt;/p&gt;</comment>
                            <comment id="12965903" author="nzhang" created="Wed, 1 Dec 2010 22:54:22 +0000"  >&lt;p&gt;Thanks for debugging for me Ashutosh! It was due to my fault: somehow my thrift-0.5.0.jar is the same as thrift-fb303-0.5.0.jar. Now it compiles correctly and I started testing. &lt;/p&gt;</comment>
                            <comment id="12965955" author="nzhang" created="Thu, 2 Dec 2010 01:35:14 +0000"  >&lt;p&gt;The unit test failed on implicit_cast1.q (reproducible by the command ant test -Dtestcase=TestCliDriver -Dqfile=implicit_cast1.q). It seems to be caused by dynamic_serde which uses thrift. &lt;/p&gt;

&lt;p&gt;Carl, can you take a look? Ashutosh, did you see the same?&lt;/p&gt;</comment>
                            <comment id="12966030" author="ashutoshc" created="Thu, 2 Dec 2010 09:11:43 +0000"  >&lt;p&gt;Ning, I don&apos;t see the failure. &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;$ ant test -Dtestcase=TestCliDriver -Dqfile=implicit_cast1.q
[junit] Done query: implicit_cast1.q
[junit] Cleaning up TestCliDriver
[junit] Tests run: 2, Failures: 0, Errors: 0, Time elapsed: 17.215 sec
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Not sure, what might have caused the failures.  Did you get any other test failures?&lt;/p&gt;</comment>
                            <comment id="12966209" author="cwsteinbach" created="Thu, 2 Dec 2010 18:03:12 +0000"  >&lt;p&gt;The test passes for me, but while running it does generate a stack trace that gets directed to stderr. &lt;br/&gt;
I&apos;m not sure if this should be a blocker, especially since DynamicSerde is deprecated and slated for removal.&lt;/p&gt;</comment>
                            <comment id="12966284" author="nzhang" created="Thu, 2 Dec 2010 21:13:11 +0000"  >&lt;p&gt;I debugged it a little bit and found it may be related to the thrift generated java and java:bean under serde. &lt;/p&gt;

&lt;p&gt;A new problem is that if you run ant -Dthrift.home=&amp;lt;thrift-0.5-home&amp;gt; thriftif and then run ant package, there will be compilation error. &lt;/p&gt;

&lt;p&gt;A similar problem can be reproduced by removing all svn deleted files under serde/src and run ant package. &lt;/p&gt;

&lt;p&gt;So I think the serde/build.xml should be fixed.&lt;/p&gt;</comment>
                            <comment id="12966391" author="cwsteinbach" created="Fri, 3 Dec 2010 02:04:20 +0000"  >&lt;blockquote&gt;&lt;p&gt;A new problem is that if you run ant -Dthrift.home=&amp;lt;thrift-0.5-home&amp;gt; thriftif and then run ant package, there will be compilation error.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I was unable to reproduce the compilation error. Are you sure that you&apos;re using Thrift 0.5.0? Did you apply the complete patch before executing the thriftif target? Which files were modified as a result of executing the thriftif target?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;A similar problem can be reproduced by removing all svn deleted files under serde/src and run ant package.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think I understand what you did. How can you remove files that were already svn deleted? Or are you saying that you did something similar to &quot;rm &lt;del&gt;rf serde/src/gen&lt;/del&gt;*&quot;? If so that&apos;s going to produce errors because in the process you also blew away protobuf generated code located in the serde/src/gen-java directory.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I debugged it a little bit and found it may be related to the thrift generated java and java:bean under serde.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The code in serde/src/gen-java is protobuf code, not Thrift code. This directory used to contain Thrift generated code, but that code now gets placed in the gen-javabean directory. If this directory contains any Thrift code then I think the patch was not applied correctly.&lt;/p&gt;</comment>
                            <comment id="12966395" author="nzhang" created="Fri, 3 Dec 2010 02:17:49 +0000"  >&lt;p&gt;Carl, I figured out why there is a thrift compilation error: the serde/build.xml:70 need to changed from &lt;/p&gt;

&lt;p&gt;executable=&quot;thrift&quot;  to executable=&quot;${thrift.home}/bin/thrift&quot;.&lt;/p&gt;

&lt;p&gt;I have a different version of thrift installed on /usr/local/bin, and that was used to generate. &lt;/p&gt;

&lt;p&gt;Even after resolving this the unit tests failed with the same error (dynamic serde). I&apos;m attaching the full log file here. &lt;/p&gt;</comment>
                            <comment id="12966709" author="ashutoshc" created="Fri, 3 Dec 2010 22:47:42 +0000"  >&lt;p&gt;Looking at the logs Ning posted, I can only see two failures in his log and they reproduce in my environment as well.  &lt;/p&gt;

&lt;p&gt;ant test -Dtestcase=TestMinimrCliDriver -Dqfile=bucketmapjoin6.q&lt;br/&gt;
ant test -Dtestcase=TestCliDriver -Dqfile=join_filters.q&lt;/p&gt;

&lt;p&gt;I verified that these two don&apos;t fail on current trunk. So, looks like an issue with a patch. Looks like both fail with a similar root cause of assert failure in source code (not in testcase) &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[junit] Exception: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
 [junit] java.lang.AssertionError
 [junit]     at org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils.initPlan(GenMapRedUtils.java:119)
 [junit]     at org.apache.hadoop.hive.ql.optimizer.GenMRRedSink1.process(GenMRRedSink1.java:76)
 [junit]     at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:89)
 [junit]     at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:88)
 [junit]     at org.apache.hadoop.hive.ql.parse.GenMapRedWalker.walk(GenMapRedWalker.java:55)
 [junit]     at org.apache.hadoop.hive.ql.parse.GenMapRedWalker.walk(GenMapRedWalker.java:67)
 [junit]     at org.apache.hadoop.hive.ql.parse.GenMapRedWalker.walk(GenMapRedWalker.java:67)
 [junit]     at org.apache.hadoop.hive.ql.parse.GenMapRedWalker.walk(GenMapRedWalker.java:67)
 [junit]     at org.apache.hadoop.hive.ql.parse.GenMapRedWalker.walk(GenMapRedWalker.java:67)
 [junit]     at org.apache.hadoop.hive.ql.parse.GenMapRedWalker.walk(GenMapRedWalker.java:67)
 [junit]     at org.apache.hadoop.hive.ql.parse.GenMapRedWalker.walk(GenMapRedWalker.java:67)
 [junit]     at org.apache.hadoop.hive.ql.parse.GenMapRedWalker.walk(GenMapRedWalker.java:67)
 [junit]     at org.apache.hadoop.hive.ql.parse.GenMapRedWalker.walk(GenMapRedWalker.java:67)
 [junit]     at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:102)
 [junit]     at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genMapRedTasks(SemanticAnalyzer.java:6274)
 [junit]     at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:6553)
 [junit]     at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:238)
 [junit]     at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:332)
 [junit]     at org.apache.hadoop.hive.ql.Driver.run(Driver.java:686)
 [junit]     at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:142)
 [junit]     at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:216)
 [junit]     at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:589)
 [junit]     at org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_filters(TestCliDriver.java:107)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12967147" author="cwsteinbach" created="Mon, 6 Dec 2010 10:32:03 +0000"  >&lt;p&gt;@Ning: The errors in join_filters.q and bucketmapjoin6.q are due to the change in &lt;br/&gt;
SMBMapJoinOperator.getType(), which I have reverted in the latest patch. &lt;/p&gt;

&lt;p&gt;I am currently running tests.&lt;/p&gt;</comment>
                            <comment id="12967262" author="cwsteinbach" created="Mon, 6 Dec 2010 17:23:18 +0000"  >&lt;p&gt;I observed a timeout in sample6.q and a failure in TestSemanticAnalyzerHookLoading, but was unable to reproduce these errors by running the tests individually. I&apos;m rerunning everything again now.&lt;/p&gt;</comment>
                            <comment id="12968367" author="ashutoshc" created="Mon, 6 Dec 2010 19:07:28 +0000"  >&lt;p&gt;With the latest patch, I see no failures for any of bucketmapjoin6.q, join_filters.q, sample6.q and TestSemanticAnalyzerHookLoading. So, no known failures. For TestSemanticAnalyzerHookLoading, Carl did you see &quot;FAILED: Error in semantic analysis: CTAS not supported.&quot; and assumed it failed? if so, thats a negative test case and that print is actually valid. &lt;/p&gt;</comment>
                            <comment id="12968369" author="nzhang" created="Mon, 6 Dec 2010 19:08:16 +0000"  >&lt;p&gt;Hi Carl, the latest patch has a compilation error building odbc (ant -Dthrift.home=... compile-cpp). I think it is due to the fact that the thrift generated code are under src/gen/thrift/gen-cpp etc. You may need to change the Makefile to reflect that. &lt;/p&gt;

&lt;p&gt;Also there are still exceptions on dynamic serde. When you run &apos;ant -Dthrift.home=... -Dtestcase=TestDynamicSerde&apos; it throws org.apache.thrift.transport.TTransportException (they also appear in the test.log I uploaded before) although at last ant showed &apos;BUILD SUCCESSFUL&apos;. In the trunk there is no such exception. &lt;/p&gt;

&lt;p&gt;I agree that dynamic serde itself may not as important and we are considering to deprecate it, but it is one of the few (if not the only) test cases in our unit tests that uses the thrift library. I think we should find out the reason why there are exceptions before we can commit the changes. &lt;/p&gt;</comment>
                            <comment id="12968548" author="ashutoshc" created="Tue, 7 Dec 2010 02:28:03 +0000"  >&lt;blockquote&gt;&lt;p&gt;Also there are still exceptions on dynamic serde. When you run &apos;ant -Dthrift.home=... -Dtestcase=TestDynamicSerde&apos; it throws  org.apache.thrift.transport.TTransportException ...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This was because of a change in Thrift from 0.3 to 0.5 in TIOStreamTransport where earlier it was returning bytesRead as -1 in case of EOF but now throws Exception. It can be fixed with following:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Index: serde/src/java/org/apache/hadoop/hive/serde2/thrift/TCTLSeparatedProtocol.java
===================================================================
--- serde/src/java/org/apache/hadoop/hive/serde2/thrift/TCTLSeparatedProtocol.java      (revision 1042747)
+++ serde/src/java/org/apache/hadoop/hive/serde2/thrift/TCTLSeparatedProtocol.java      (working copy)
@@ -239,6 +240,10 @@
         }
         tokenizer = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StringTokenizer(row, separator, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;);
       } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (TTransportException e) {
+        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(e.getType() == TTransportException.END_OF_FILE){
+          tokenizer = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StringTokenizer(&quot;&quot;, separator, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;);
+          &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
+        }
         e.printStackTrace();
         tokenizer = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
         &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;Carl, can you include this fix in your next patch?&lt;/p&gt;</comment>
                            <comment id="12968564" author="cwsteinbach" created="Tue, 7 Dec 2010 04:06:55 +0000"  >&lt;p&gt;@Ashutosh: Thanks for the tip! I&apos;ll roll this into the next version of the patch (coming soon).&lt;/p&gt;</comment>
                            <comment id="12968611" author="cwsteinbach" created="Tue, 7 Dec 2010 07:26:15 +0000"  >&lt;p&gt;Attaching a new patch that fixes the cpp ant targets and the various dynamic serde tests.&lt;/p&gt;</comment>
                            <comment id="12968907" author="nzhang" created="Tue, 7 Dec 2010 19:33:53 +0000"  >&lt;p&gt;Thanks Ashutosh and Carl! The changes look good and all unit tests have passed. However, there are conflicts after another JIRA is committed. Carl, can you pelase regenerate the patch yet another time? I&apos;ll try my best to test and commit ASAP to avoid conflicts again. &lt;/p&gt;</comment>
                            <comment id="12969610" author="cwsteinbach" created="Thu, 9 Dec 2010 02:10:41 +0000"  >&lt;p&gt;Attaching a new version of the patch that incorporates the recent Thrift metastore changes.&lt;br/&gt;
I verified that all tests pass.&lt;/p&gt;</comment>
                            <comment id="12969633" author="namit" created="Thu, 9 Dec 2010 06:06:06 +0000"  >&lt;p&gt;@Ning, can you take care of this ?&lt;br/&gt;
So many other patches are waiting for this ?&lt;/p&gt;</comment>
                            <comment id="12969643" author="nzhang" created="Thu, 9 Dec 2010 06:50:45 +0000"  >&lt;p&gt;Sorry I missed Carl&apos;s last update. I&apos;m now testing the new patch. &lt;/p&gt;</comment>
                            <comment id="12969854" author="nzhang" created="Thu, 9 Dec 2010 18:32:54 +0000"  >&lt;p&gt;Committed. Thanks Carl, Todd and Ashutosh!&lt;/p&gt;</comment>
                            <comment id="12969868" author="ashutoshc" created="Thu, 9 Dec 2010 19:01:34 +0000"  >&lt;p&gt;Great !&lt;/p&gt;

&lt;p&gt;Carl, you noted above:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Need to update this page once this change is committed: &lt;a href=&quot;http://wiki.apache.org/hadoop/Hive/HowToContribute#Generating_Code&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Hive/HowToContribute#Generating_Code&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Now that its in, the wiki page can now be updated as well. Otherwise, similar number of iterations will take place when we upgrade to next version of thrift &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12969906" author="cwsteinbach" created="Thu, 9 Dec 2010 19:55:45 +0000"  >&lt;p&gt;@Ashutosh: Thanks for reminding me. I&apos;ll see that this gets updated.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12471240">HIVE-1527</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12436081">HIVE-842</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12423356">HIVE-438</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12416574">THRIFT-363</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12436081">HIVE-842</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12464835" name="ASF.LICENSE.NOT.GRANTED--HIVE-1526-complete.4.patch.txt" size="4416149" author="cwsteinbach" created="Mon, 29 Nov 2010 10:24:07 +0000"/>
                            <attachment id="12464834" name="ASF.LICENSE.NOT.GRANTED--HIVE-1526-no-codegen.4.patch.txt" size="492014" author="cwsteinbach" created="Mon, 29 Nov 2010 10:18:56 +0000"/>
                            <attachment id="12464952" name="HIVE-1526-complete.5.patch.txt" size="4416149" author="cwsteinbach" created="Tue, 30 Nov 2010 10:15:49 +0000"/>
                            <attachment id="12465370" name="HIVE-1526-complete.6.patch.txt" size="7476725" author="cwsteinbach" created="Mon, 6 Dec 2010 10:29:53 +0000"/>
                            <attachment id="12465670" name="HIVE-1526-complete.7.patch.txt" size="7477569" author="cwsteinbach" created="Tue, 7 Dec 2010 07:26:13 +0000"/>
                            <attachment id="12465875" name="HIVE-1526-complete.8.patch.txt" size="7494882" author="cwsteinbach" created="Thu, 9 Dec 2010 02:10:38 +0000"/>
                            <attachment id="12459899" name="HIVE-1526-no-codegen.3.patch.txt" size="488984" author="cwsteinbach" created="Thu, 18 Nov 2010 09:25:50 +0000"/>
                            <attachment id="12464953" name="HIVE-1526-no-codegen.5.patch.txt" size="492014" author="cwsteinbach" created="Tue, 30 Nov 2010 10:15:50 +0000"/>
                            <attachment id="12465371" name="HIVE-1526-no-codegen.6.patch.txt" size="499987" author="cwsteinbach" created="Mon, 6 Dec 2010 10:29:55 +0000"/>
                            <attachment id="12465671" name="HIVE-1526-no-codegen.7.patch.txt" size="500831" author="cwsteinbach" created="Tue, 7 Dec 2010 07:26:15 +0000"/>
                            <attachment id="12465876" name="HIVE-1526-no-codegen.8.patch.txt" size="500510" author="cwsteinbach" created="Thu, 9 Dec 2010 02:10:40 +0000"/>
                            <attachment id="12455476" name="HIVE-1526.2.patch.txt" size="4124415" author="cwsteinbach" created="Fri, 24 Sep 2010 09:12:52 +0000"/>
                            <attachment id="12459902" name="HIVE-1526.3.patch.txt" size="4351306" author="cwsteinbach" created="Thu, 18 Nov 2010 09:36:32 +0000"/>
                            <attachment id="12465063" name="compile.err" size="24882" author="nzhang" created="Wed, 1 Dec 2010 19:40:10 +0000"/>
                            <attachment id="12455323" name="hive-1526.txt" size="3639811" author="tlipcon" created="Wed, 22 Sep 2010 22:36:00 +0000"/>
                            <attachment id="12455325" name="libfb303.jar" size="176072" author="tlipcon" created="Wed, 22 Sep 2010 22:36:01 +0000"/>
                            <attachment id="12455324" name="libthrift.jar" size="231946" author="tlipcon" created="Wed, 22 Sep 2010 22:36:01 +0000"/>
                            <attachment id="12460155" name="serde2_test.patch" size="2057" author="ashutoshc" created="Mon, 22 Nov 2010 06:39:11 +0000"/>
                            <attachment id="12459904" name="svn_rm.sh" size="1565" author="cwsteinbach" created="Thu, 18 Nov 2010 09:48:07 +0000"/>
                            <attachment id="12465200" name="test.log" size="1204114" author="nzhang" created="Fri, 3 Dec 2010 02:17:49 +0000"/>
                            <attachment id="12459900" name="thrift-0.5.0.jar" size="262241" author="cwsteinbach" created="Thu, 18 Nov 2010 09:25:51 +0000"/>
                            <attachment id="12459901" name="thrift-fb303-0.5.0.jar" size="174466" author="cwsteinbach" created="Thu, 18 Nov 2010 09:25:51 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>22.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 20 Sep 2010 23:01:42 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72856</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10342"><![CDATA[Incompatible change]]></customfieldvalue>
    <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 7 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfiv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123165</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>thrift ivy</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>
</channel>
</rss>
