<!--
RSS generated by JIRA (7.6.3#76005-sha1:8a4e38d34af948780dbf52044e7aafb13a7cae58) at Tue Jan 22 15:12:09 UTC 2019

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<!-- If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
    <channel>
        <title>ASF JIRA</title>
        <link>https://issues.apache.org/jira/issues/?jql=project+%3D+HIVE+AND+created+%3E%3D+2008-10-22+AND+created+%3C%3D+2008-10-28+ORDER+BY+key+ASC</link>
        <description>An XML representation of a search request</description>
                <language>en-uk</language>
                        <issue start="0" end="8" total="8"/>
                <build-info>
            <version>7.6.3</version>
            <build-number>76005</build-number>
            <build-date>09-01-2018</build-date>
        </build-info>

<item>
            <title>[HIVE-14] selecting fields from a complex object column in transform clause is throwing a Parse Error.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-14</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;For a thrift table whose columns are complex objects the following query throws up an error&lt;/p&gt;

&lt;p&gt;from ( from cdx select transform(cdx.a.b) as tx using &apos;mapper&apos; cluster by tx ) mo insert into output select tx;&lt;/p&gt;

&lt;p&gt;the error thrown on the second . of expresion &apos;cdx.a.b&apos;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12407041">HIVE-14</key>
            <summary>selecting fields from a complex object column in transform clause is throwing a Parse Error.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="prasadc">Prasad Chakka</reporter>
                        <labels>
                    </labels>
                <created>Wed, 22 Oct 2008 22:19:43 +0000</created>
                <updated>Mon, 4 Jul 2011 08:59:11 +0000</updated>
                                                                            <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12661563" author="athusoo" created="Wed, 7 Jan 2009 13:38:41 +0000"  >&lt;p&gt;I think this has also been addressed. Will verify and then close out.&lt;/p&gt;</comment>
                            <comment id="12668628" author="athusoo" created="Thu, 29 Jan 2009 22:00:16 +0000"  >&lt;p&gt;Prasad,&lt;/p&gt;

&lt;p&gt;can you verify if this works and close out...&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Ashish&lt;/p&gt;</comment>
                            <comment id="13059364" author="miloveme" created="Mon, 4 Jul 2011 08:59:11 +0000"  >&lt;p&gt;I think that this query&apos;s syntax is wrong. &quot;as tx&quot; must follows &quot;using &apos;mapper&apos;&quot;. so this query should is changed like&lt;br/&gt;
&quot;from (from cdx select transform(cdx.a.b) using &apos;mapper&apos; as tx cluster by tx) mo insert into output select tx;&quot;. also hive should be patched about &quot;insert into&quot; - &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2207&quot; title=&quot;INSERT INTO&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2207&quot;&gt;&lt;del&gt;HIVE-2207&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 7 Jan 2009 13:38:41 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42924</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 30 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0iv1z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>108125</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-25] [Hive] cluster by does not work with column aliasing</title>
                <link>https://issues.apache.org/jira/browse/HIVE-25</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;                    SELECT b.*  &lt;br/&gt;
                    FROM                                                 &lt;br/&gt;
                    (                                                    &lt;br/&gt;
                      SELECT x.col1, x.col2&lt;br/&gt;
                      FROM tmp x              &lt;br/&gt;
                      WHERE x.col2= 10&lt;br/&gt;
                      CLUSTER BY col2                                  &lt;br/&gt;
                    ) b&quot;&lt;/p&gt;


&lt;p&gt;The above query works, but if I change the cluster by to:&lt;/p&gt;

&lt;p&gt;CLUSTER BY x.col2, &lt;/p&gt;

&lt;p&gt;it croaks.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12407101">HIVE-25</key>
            <summary>[Hive] cluster by does not work with column aliasing</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="prasadc">Prasad Chakka</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Oct 2008 16:18:53 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:56 +0000</updated>
                            <resolved>Wed, 21 Jan 2009 00:58:23 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12662714" author="prasadc" created="Sun, 11 Jan 2009 02:44:23 +0000"  >&lt;p&gt;Attached is the proposed code changes. Fix for this seems to be more complex that I originally thought.&lt;/p&gt;

&lt;p&gt;This fix will work for below type of queries. The fix attempts to make all column references with in a parenthesis refer to tables specified in the from clause.&lt;/p&gt;

&lt;p&gt;SELECT x.*  FROM SRC x CLUSTER BY x.key;&lt;/p&gt;

&lt;p&gt;SELECT y.* from (SELECT x.* FROM SRC x CLUSTER BY key) y where y.key = 20;&lt;/p&gt;

&lt;p&gt;SELECT y.* from (SELECT x.* FROM SRC x CLUSTER BY x.key) y where y.key = 20;&lt;/p&gt;

&lt;p&gt;Would appreciate your thoughts on this.&lt;/p&gt;</comment>
                            <comment id="12662715" author="prasadc" created="Sun, 11 Jan 2009 02:47:19 +0000"  >&lt;p&gt;this contains changes to tests as well...&lt;/p&gt;</comment>
                            <comment id="12663519" author="athusoo" created="Tue, 13 Jan 2009 22:43:19 +0000"  >&lt;p&gt;In Hive.g the change to the rule for columnNameOrder will also change the ddl (the tablebuckets rule) and there we clearly do not have a notion of tableColumn as there is no table alias. &lt;/p&gt;

&lt;p&gt;We need to think a bit to see if we really want to lift this restriction. The reason it was modeled like this was because of the transform operator. Basically, the cluster by clause addresses the alias list instead of the select expressions. There are no tangible select expressions in the transform case. &lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;</comment>
                            <comment id="12663560" author="prasadc" created="Wed, 14 Jan 2009 00:11:42 +0000"  >&lt;p&gt;I will change Hive.g so that sortOrder in DDL can only have identifiers and not column refs.&lt;/p&gt;

&lt;p&gt;The way I want to do this is to allow select columns to be referenced in cluster/distributed/sort clauses according to following rules&lt;/p&gt;

&lt;p&gt;1) column has an alias in the select clause. this column can only be referred with the alias in the above 3 clauses&lt;br/&gt;
2) column doesn&apos;t have an alias but it may have table alias. this column can be referred with the columnName or tabAlias.columnName in the above 3 clauses.&lt;/p&gt;

&lt;p&gt;where clause can only contain tabAlias.columnName and is different from above rules.&lt;/p&gt;

&lt;p&gt;I will upload modified patch with tests for all the above conditions. How about it?&lt;/p&gt;</comment>
                            <comment id="12663579" author="prasadc" created="Wed, 14 Jan 2009 00:58:56 +0000"  >&lt;p&gt;here is the correct patch with the changes mentioned above.&lt;/p&gt;

&lt;p&gt;cluster.q contains following queries and clustern1.q and clustern2.q contains negative testcases&lt;/p&gt;

&lt;p&gt;EXPLAIN&lt;br/&gt;
SELECT x.key, x.value as v1, y.*  FROM SRC x JOIN SRC y ON (x.key = y.key) CLUSTER BY v1;&lt;/p&gt;

&lt;p&gt;EXPLAIN&lt;br/&gt;
SELECT x.key, x.value as v1, y.*  FROM SRC x JOIN SRC y ON (x.key = y.key) CLUSTER BY x.key;&lt;/p&gt;

&lt;p&gt;EXPLAIN&lt;br/&gt;
SELECT x.key, x.value as v1, y.key as yk  FROM SRC x JOIN SRC y ON (x.key = y.key) CLUSTER BY key;&lt;/p&gt;

&lt;p&gt;EXPLAIN&lt;br/&gt;
SELECT * FROM SRC x CLUSTER BY x.key;&lt;/p&gt;

&lt;p&gt;EXPLAIN&lt;br/&gt;
SELECT * FROM SRC x CLUSTER BY key;&lt;/p&gt;

&lt;p&gt;EXPLAIN&lt;br/&gt;
SELECT x.* FROM SRC x CLUSTER BY key;&lt;/p&gt;

&lt;p&gt;EXPLAIN&lt;br/&gt;
SELECT x.*  FROM SRC x CLUSTER BY x.key;&lt;/p&gt;

&lt;p&gt;EXPLAIN&lt;br/&gt;
SELECT x.key, x.value as v1 FROM SRC x CLUSTER BY key;&lt;/p&gt;

&lt;p&gt;EXPLAIN&lt;br/&gt;
SELECT x.key, x.value as v1 FROM SRC x CLUSTER BY x.key;&lt;/p&gt;

&lt;p&gt;EXPLAIN&lt;br/&gt;
SELECT x.key, x.value as v1  FROM SRC x CLUSTER BY v1;&lt;/p&gt;
</comment>
                            <comment id="12664641" author="athusoo" created="Fri, 16 Jan 2009 19:33:15 +0000"  >&lt;p&gt;Comments from the code review with Prasad:&lt;/p&gt;

&lt;p&gt;1. Please run the queries also apart from the explain plans in the test cases&lt;br/&gt;
2. Union all case should also be added to the tests&lt;br/&gt;
3. In SemanticAnalyzer.java:1085 the check for identifier is not needed.&lt;br/&gt;
4. getColAliasFromRef does nothing so it can be removed.&lt;/p&gt;

&lt;p&gt;Also as we discussed, bigger changes are needed to support:&lt;br/&gt;
1. select a.key, a.key from a&lt;br/&gt;
2. complex columns are broken in the query because the table alias is optional.&lt;/p&gt;

&lt;p&gt;Please file separate JIRAs for those.&lt;/p&gt;</comment>
                            <comment id="12664718" author="prasadc" created="Fri, 16 Jan 2009 22:39:44 +0000"  >&lt;p&gt;queries of the form &apos;select a.key. a.key from a&apos; seem to be working.&lt;/p&gt;

&lt;p&gt;i will upload patch that adds the new testcases as suggested.&lt;/p&gt;</comment>
                            <comment id="12665488" author="prasadc" created="Tue, 20 Jan 2009 18:09:33 +0000"  >&lt;p&gt;added more tests as suggested&lt;/p&gt;</comment>
                            <comment id="12665579" author="athusoo" created="Tue, 20 Jan 2009 21:50:31 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;looks good to me.&lt;/p&gt;</comment>
                            <comment id="12665596" author="athusoo" created="Tue, 20 Jan 2009 22:24:24 +0000"  >&lt;p&gt;I am seeing a number of test failures both in clientpositive and clientnegative...&lt;/p&gt;

&lt;p&gt;Can you rerun and check that all the tests are passing.&lt;/p&gt;</comment>
                            <comment id="12665644" author="prasadc" created="Wed, 21 Jan 2009 00:23:54 +0000"  >&lt;p&gt;couple of new tests were added that were breaking which i fixed them.&lt;br/&gt;
remove CliDriver.java which got into previous patch by mistake and which was breaking TestNegativeCliDriver tests.&lt;/p&gt;</comment>
                            <comment id="12665664" author="athusoo" created="Wed, 21 Jan 2009 00:58:23 +0000"  >&lt;p&gt;committed. Thanks Prasad!!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12412636">HIVE-238</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12397631" name="hive-25-code-changes.patch" size="9752" author="prasadc" created="Sun, 11 Jan 2009 02:44:23 +0000"/>
                            <attachment id="12397846" name="hive-25.2.patch" size="86791" author="prasadc" created="Wed, 14 Jan 2009 00:58:55 +0000"/>
                            <attachment id="12398317" name="hive-25.3.patch" size="139050" author="prasadc" created="Tue, 20 Jan 2009 18:09:33 +0000"/>
                            <attachment id="12398356" name="hive-25.4.patch" size="139509" author="prasadc" created="Wed, 21 Jan 2009 00:23:54 +0000"/>
                            <attachment id="12397632" name="hive-25.patch" size="63500" author="prasadc" created="Sun, 11 Jan 2009 02:47:18 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 11 Jan 2009 02:44:23 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73826</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 1 week, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0iv2n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>108128</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>enables table aliases in cluster by, distribute by, sort by clauses.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-26] [Hive] uppercase alias with a join not working</title>
                <link>https://issues.apache.org/jira/browse/HIVE-26</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;EXPLAIN FROM &lt;br/&gt;
(SELECT src.* FROM src) x&lt;br/&gt;
JOIN &lt;br/&gt;
(SELECT src.* FROM src) Y&lt;br/&gt;
ON (x.key = Y.key)&lt;br/&gt;
SELECT Y.*;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12407214">HIVE-26</key>
            <summary>[Hive] uppercase alias with a join not working</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="namit">Namit Jain</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Sat, 25 Oct 2008 00:50:37 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:33 +0000</updated>
                            <resolved>Wed, 3 Dec 2008 22:28:19 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12652060" author="athusoo" created="Mon, 1 Dec 2008 17:08:01 +0000"  >&lt;p&gt;Namit can you confirm that this has been fixed.&lt;/p&gt;</comment>
                            <comment id="12653007" author="namit" created="Wed, 3 Dec 2008 22:28:19 +0000"  >&lt;p&gt;Was fixed as part of the big merge&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 1 Dec 2008 17:08:01 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>66883</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 8 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0iv3z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>108134</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-27] [Hive] bad error reporting</title>
                <link>https://issues.apache.org/jira/browse/HIVE-27</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;By mistake, if I type the following query: (note that it is x.c3.x.c4 instead of x.c3,x.c4)&lt;/p&gt;

&lt;p&gt;select x.c1,x.c2,x.c3.x.c4 from table x where ...&lt;/p&gt;


&lt;p&gt;I get a bizarre error - class not found exception which takes a long time to debug - the error reporting should be improved&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12407042">HIVE-27</key>
            <summary>[Hive] bad error reporting</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="5">Cannot Reproduce</resolution>
                                        <assignee username="lars_francke">Lars Francke</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Wed, 22 Oct 2008 22:26:23 +0000</created>
                <updated>Tue, 5 Aug 2014 22:00:25 +0000</updated>
                            <resolved>Tue, 5 Aug 2014 22:00:25 +0000</resolved>
                                                                    <component>Clients</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="14086859" author="lars_francke" created="Tue, 5 Aug 2014 22:00:25 +0000"  >&lt;p&gt;This has been fixed in the meanwhile. I just tested and got this:&lt;/p&gt;

&lt;p&gt;Hive CLI:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;FAILED: SemanticException &lt;span class=&quot;error&quot;&gt;&amp;#91;Error 10042&amp;#93;&lt;/span&gt;: Line 1:7 . Operator is only supported on struct or list of struct types &apos;x&apos;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Beeline:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Error: Error while compiling statement: FAILED: SemanticException &lt;span class=&quot;error&quot;&gt;&amp;#91;Error 10042&amp;#93;&lt;/span&gt;: Line 1:7 . Operator is only supported on struct or list of struct types &apos;x&apos; (state=42000,code=10042)&lt;/p&gt;&lt;/blockquote&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 5 Aug 2014 22:00:25 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42920</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 24 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0iv27:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>108126</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-30] Hive web interface</title>
                <link>https://issues.apache.org/jira/browse/HIVE-30</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Hive needs a web interface. The initial checkin should have:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;simple schema browsing&lt;/li&gt;
	&lt;li&gt;query submission&lt;/li&gt;
	&lt;li&gt;query history (similar to MySQL&apos;s SHOW PROCESSLIST)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;A suggested feature: the ability to have a query notify the user when it&apos;s completed.&lt;/p&gt;

&lt;p&gt;Edward Capriolo has expressed some interest in driving this process.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12407155">HIVE-30</key>
            <summary>Hive web interface</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="appodictic">Edward Capriolo</assignee>
                                    <reporter username="hammer">Jeff Hammerbacher</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Oct 2008 07:35:29 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:45 +0000</updated>
                            <resolved>Wed, 4 Feb 2009 00:08:20 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Web UI</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="12642541" author="athusoo" created="Fri, 24 Oct 2008 20:52:43 +0000"  >&lt;p&gt;+1 to this...&lt;/p&gt;

&lt;p&gt;will be quite awesome to have this. Zheng and all have developed something similar at FB but that is just not open source able as that is intertwined with the FB site code and technologies.&lt;/p&gt;</comment>
                            <comment id="12642545" author="zshao" created="Fri, 24 Oct 2008 21:16:09 +0000"  >&lt;p&gt;Inside FB we build this with PHP (based on metastore thrift server and some shell scripts).&lt;/p&gt;

&lt;p&gt;A more consistent approach here would be directly write the web interface in JSP.&lt;br/&gt;
That eliminated the need of a metastore thrift server.&lt;/p&gt;

&lt;p&gt;We might also need a daemon to monitor all the running hipal jobs, in order to support MySQL&apos;s SHOW PROCESSLIST.&lt;/p&gt;

&lt;p&gt;I will put up a preliminary design for discussion soon.&lt;/p&gt;</comment>
                            <comment id="12643012" author="appodictic" created="Mon, 27 Oct 2008 18:46:30 +0000"  >&lt;p&gt;+1 here too. &lt;/p&gt;

&lt;p&gt;I was started down on the same path. I think the best way to handle this would be to have a Runnable instance that is handled by a startup servlet. You would need a runnable instance because you are not going to want to block after query submission.  I also think some tag libraries might be in order to display things like lists, and maps inside the web interface. I think we can also design some html code to color code hive QL, also have a check syntax function. &lt;/p&gt;

&lt;p&gt;Also we should have a way that the MapReduce processes started by hive can be easily linked from the Hive Web Interface. This way the process can be easily followed across the hadoop web applications.&lt;/p&gt;

&lt;p&gt;I have a catchy name for it too &apos;Beeswax&apos; &lt;/p&gt;
</comment>
                            <comment id="12643055" author="appodictic" created="Mon, 27 Oct 2008 20:54:34 +0000"  >&lt;p&gt;Inside Hadoop components like NameNode implement HttpServlet directly. &lt;/p&gt;

&lt;p&gt;I think we should replicate the bin/hive to bin/hiveweb this would kick off a management application. &lt;br/&gt;
$hadoop/webapps/hiveweb would be the home for the JSP files&lt;/p&gt;

&lt;p&gt;I think we should have a Threaded application running inside the servlet engine. &lt;/p&gt;

&lt;p&gt;If a user runs a query that would have output to the console we should save that data into temporary file?&lt;br/&gt;
If so where would that data be save?&lt;br/&gt;
How long before if should be cleaned up?&lt;br/&gt;
If it creates a temporary file should we impose a limit on the size? Select * could be really big where would that&lt;br/&gt;
local data go?&lt;/p&gt;

&lt;p&gt;We could offer a browse of the database by using the meta information and the HDFS files directly? A simple Next 100 Previous 100.&lt;/p&gt;</comment>
                            <comment id="12643403" author="zshao" created="Wed, 29 Oct 2008 03:20:20 +0000"  >&lt;p&gt;I think in most cases we can try to follow what phpmyadmin does for MySQL.&lt;/p&gt;

&lt;p&gt;Hive does support SELECT table.* from table LIMIT 100; so that we can show only the first 100 lines.  The query is optimized in that it directly reads HDFS files (instead of doing a map-reduce job).&lt;/p&gt;

&lt;p&gt;There is a difference in that MySQL has a mysqld daemon while hive does not. So the web interface need to have some process/thread/query management capability built-in.&lt;/p&gt;

&lt;p&gt;Another difference is that Hive queries may run much longer than MySQL queries because a single Hive query may go against terabytes of data.&lt;/p&gt;</comment>
                            <comment id="12643540" author="athusoo" created="Wed, 29 Oct 2008 17:37:09 +0000"  >&lt;p&gt;For the server you could use the JDBC server that is being developed as part of another JIRA (once the code has been separated out into the client and server portions)&lt;/p&gt;</comment>
                            <comment id="12644463" author="zshao" created="Fri, 31 Oct 2008 23:48:01 +0000"  >&lt;p&gt;Edward,  let me know if you need any help on this.&lt;/p&gt;</comment>
                            <comment id="12645100" author="appodictic" created="Tue, 4 Nov 2008 23:12:35 +0000"  >&lt;p&gt;I have a draft/in progress version here:&lt;br/&gt;
&lt;a href=&quot;http://www.jointhegrid.com/jtgwebrepo/beeswax/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.jointhegrid.com/jtgwebrepo/beeswax/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;HWIServer - This component reads in /conf/hwi-default.xml and /conf/hwi-set.xml starts an embedded Jetty Server. Started by a script like the hive shell script that starts this file rather then the CLI.&lt;br/&gt;
HWIContentListener - This is used to load a Runnable of HiveSessionManager,&lt;br/&gt;
HiveSessionManager - Container a Vector of SessionItem, this also lives in the web server application scope&lt;br/&gt;
SessionItem - A Client Session state object wrapped. Status functions to block changes while query running, etc.&lt;br/&gt;
All the jsp pages interact with the HiveSessionManager running in the jetty application scope.&lt;/p&gt;


&lt;p&gt;So the hwi (Hive Web Interface) holds multiple session states. Session states would be named by a string and optionally protected by a password. User would log in and see all sessions in a ListSessions page. All the output from a session state would be written to a file since we can&apos;t write it to the console, we also can not write it to a buffer as the result of a hive query could be large. If you set the output to /dev/null none of the output stream would be captured.&lt;/p&gt;

&lt;p&gt;Some things I could use help with:&lt;br/&gt;
1) I am sure hadoop reads the configuration files a different/better way. I will have to look at this.&lt;br/&gt;
2) jetty wac.setWAR SEEMS to require ANT libraries, I do not understand why really adding them is trivial I copied /opt/ant/lib /opt/hive/lib&lt;br/&gt;
3) I&apos;m using netbeans. I do not think the ant scripts it generates will be what we want in a hadoop commit. At some point if someone wants to tell / port what I am working on to something that fits in very tight with hadoop that would be great. I am not too familiar yet with the hadoop/src structure.&lt;br/&gt;
4) Does anyone know how to extract the hadoop job names from the CLISession. The CLI used to output them when a query started.&lt;/p&gt;

&lt;p&gt;Does anyone have any comments? I know without front end JSP understanding the application might be difficult, but I wanted to make sure people like/understand the Jetty-SessionListenter-Runnable approach. &lt;/p&gt;</comment>
                            <comment id="12645688" author="athusoo" created="Fri, 7 Nov 2008 05:25:50 +0000"  >&lt;p&gt;Apologies on not being able to reply earlier.. I am at apachecon and could not get a chance to reply to this.&lt;/p&gt;

&lt;p&gt;I am generally fine with Jetty-SessionListener-Runnable approach.&lt;/p&gt;

&lt;p&gt;A few questions though, what is contained in conf/hwi-default.xml and conf/hwi-site.xml. Are these similar to the conf/hive-default.xml and conf/hive-site.xml. If they are then we may want to keep the configuration files the same. One persistent problems that we have seen at FB is the proliferation of configuration files and adding more seems to me that it will complicate things further.&lt;/p&gt;

&lt;p&gt;About netbeans, hadoop has eclipse templates and that fit in well with development and that would perhaps make it much easier to integrate later.&lt;/p&gt;

&lt;p&gt;Also it may be worthwhile to think about how this is going to integrate with the JDBC driver thingy that is going on in the following JIRA&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-4101&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HADOOP-4101&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For job names in jobname, you can get them from&lt;/p&gt;

&lt;p&gt;conf.getVar(HiveConf.ConfVars.HADOOPJOBNAME)&lt;/p&gt;

&lt;p&gt;conf is available in CLISessionState&lt;/p&gt;</comment>
                            <comment id="12645790" author="appodictic" created="Fri, 7 Nov 2008 15:23:41 +0000"  >&lt;p&gt;The hwi-site and hwi-default set three variables&lt;br/&gt;
hwi.war.file = /opt/hive/lib/hwi.war path to the war for the web application. This is passed to jetty as it is started up.&lt;br/&gt;
hwi.listen.host= 0.0.0.0 listen on all interfaces&lt;br/&gt;
hwi.listen.port=9999 the port the jetty server will start on.&lt;/p&gt;

&lt;p&gt;Theoretically there could be more in the future.&lt;/p&gt;

&lt;p&gt;If you do not want separate configuration files hwi could pull them from the hive-site. I have avoided patching any upstream files. If you want to add those properties upstream I am cool with that.&lt;/p&gt;

&lt;p&gt;I am not sure of the time line on the JDBC drivers. I do not want to to be a blocker issue. When the JDBC drivers are mature I suggest this simple technique of  having both of them work from the web interface.&lt;/p&gt;

&lt;p&gt;Right now a SessionItem manages the CLISessionState.&lt;br/&gt;
We create a JDBCSessionItem that manages a JDBC session.&lt;/p&gt;

&lt;p&gt;Both of them can have a parent class AbstractSession, any shared properties like QUERY can be defined in the parent class. The webserver manages long running queries,  the results may need to be written to a file. The function is the same, submit and manage, just the internals are handled with a resultSet rather then an output stream.&lt;/p&gt;

&lt;p&gt;Thank you for the tip on the JobName.&lt;/p&gt;


</comment>
                            <comment id="12646044" author="appodictic" created="Sun, 9 Nov 2008 03:18:20 +0000"  >&lt;p&gt;I have a working version that handles multiple sessions, no schema browsing yet but you can submit jobs.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.jointhegrid.com/jtgweb/hivewebinterface/index.jsp&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.jointhegrid.com/jtgweb/hivewebinterface/index.jsp&lt;/a&gt; &lt;/p&gt;</comment>
                            <comment id="12646622" author="athusoo" created="Tue, 11 Nov 2008 18:46:05 +0000"  >&lt;p&gt;I will check this out today and send you feedback. &lt;/p&gt;

&lt;p&gt;Also hive JIRAs and mailing lists have moved to &lt;/p&gt;

&lt;p&gt;hive-user@hadoop.apache.org&lt;br/&gt;
hive-dev@hadoop.apache.org&lt;br/&gt;
hive-commits@hadoop.apache.org&lt;/p&gt;

&lt;p&gt;in case  you want to subscribe to those&lt;/p&gt;</comment>
                            <comment id="12646766" author="zshao" created="Wed, 12 Nov 2008 01:12:41 +0000"  >&lt;p&gt;Please send emails to these addresses (note: -subscribe) to subscribe to the lists:&lt;/p&gt;

&lt;p&gt;hive-user-subscribe@hadoop.apache.org&lt;br/&gt;
hive-dev-subscribe@hadoop.apache.org&lt;br/&gt;
hive-commits-subscribe@hadoop.apache.org&lt;/p&gt;
</comment>
                            <comment id="12647299" author="athusoo" created="Thu, 13 Nov 2008 14:23:17 +0000"  >&lt;p&gt;I was not able to get the hwi script to work. I get the following errors... I do not have an instance of hive in /opt/lib but in some other directory.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;athusoo@dev053.snc1 ~/dist/hive&amp;#93;&lt;/span&gt;$ /bin/bash ./bin/hwi &lt;br/&gt;
: command not found&lt;br/&gt;
: command not found &lt;br/&gt;
: command not found &lt;br/&gt;
: No such file or directoryin&lt;br/&gt;
: command not found &lt;br/&gt;
: No such file or directorysers/athusoo/hadoop_local_ws1/trunk/fbhive/build/dist/hive&lt;br/&gt;
: command not found &lt;br/&gt;
: command not found &lt;br/&gt;
: command not found &lt;br/&gt;
&apos;/bin/hwi: line 45: syntax error near unexpected token `do&lt;br/&gt;
&apos;/bin/hwi: line 45: `for f in ${HIVE_LIB}/*.jar; do&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;athusoo@dev053.snc1 /data/users/athusoo/hadoop_local_ws1/trunk/fbhive/build/dist/hive&amp;#93;&lt;/span&gt;$ ./bin/hwi  &lt;br/&gt;
: No such file or directory&lt;/p&gt;</comment>
                            <comment id="12647319" author="appodictic" created="Thu, 13 Nov 2008 15:31:45 +0000"  >&lt;p&gt;This file got into a windows format. #dos2unix hwi  should cure this. As for the directory differences, it should not be an issue. with two exceptions:&lt;br/&gt;
1)&lt;br/&gt;
at end of hwi:&lt;br/&gt;
exec $HADOOP jar $AUX_JARS_CMD_LINE ${HIVE_LIB}/hwi.jar org.apache.hadoop.hive.hwi.HWIServer $HIVE_OPTS &quot;$@&quot;&lt;br/&gt;
hwi.jar needs to be in the HIVE_LIB or you need to specify the full path.&lt;/p&gt;

&lt;p&gt;2)  .HWIServer.java&lt;br/&gt;
if ( System.getProperty(&quot;hwi.war.file&quot;)!=null )&lt;/p&gt;
{
      wac.setWAR(System.getProperty(&quot;hwi.war.file&quot;));
    }
&lt;p&gt; else &lt;/p&gt;
{
      wac.setWAR(&quot;/opt/hive/lib/hwi.war&quot;);
    }
&lt;p&gt;Catch 22 with our discussion above. Since we have not decided where this property lives it is hard coded right now. The war needs to be in that spot so HWIServer can find it and load it. If you need any other help you can email me directly.&lt;/p&gt;</comment>
                            <comment id="12648434" author="appodictic" created="Tue, 18 Nov 2008 00:35:44 +0000"  >&lt;p&gt;This patch allows a fairly function web interface with schema browsing and query submission.&lt;/p&gt;</comment>
                            <comment id="12648846" author="athusoo" created="Wed, 19 Nov 2008 00:49:58 +0000"  >&lt;p&gt;cool contribution...&lt;/p&gt;

&lt;p&gt;still going through the jsp code, but the following are some of the review comments..&lt;/p&gt;

&lt;p&gt;Inline Comments&lt;br/&gt;
hwi/build.xml:48	This should already be there in the classpath settings in build-common.xml. Can you check on that and see whether you need another one?&lt;br/&gt;
hwi/src/java/org/apache/hadoop/hive/hwi/HWIServer.java:53	Can you look at the code in HiveConf.java on how to deal with configurations. This mimics what hadoop does with hadoop-default.xml and hadoop-site.xml. The confdir is then simply setup by using --config like it is done for the rest of the hadoop. Joydeep may be able to highlight this better as he set that up for hive.&lt;br/&gt;
hwi/src/java/org/apache/hadoop/hive/hwi/HWIServer.java:64	Same as the previous comment.&lt;br/&gt;
hwi/src/java/org/apache/hadoop/hive/hwi/HWIServer.java:80	It is better to use the HiveConf infrastructure here.&lt;br/&gt;
hwi/src/java/org/apache/hadoop/hive/hwi/HWIServer.java:147	javadocs&lt;br/&gt;
hwi/src/java/org/apache/hadoop/hive/hwi/HWIServer.java:151	javadocs&lt;br/&gt;
hwi/src/java/org/apache/hadoop/hive/hwi/HiveSessionManager.java:108	should the command line arguments be stored away in the SessionManager instead of reading it from the system properties all the time?&lt;br/&gt;
hwi/src/java/org/apache/hadoop/hive/hwi/HiveSessionManager.java:60	After you come out of the goOn loop, it is probably good to cleanup any sessions that may still be around or are we gauranteed that goOn will be set to false only after all the threads have been cleaned up?&lt;br/&gt;
hwi/src/java/org/apache/hadoop/hive/hwi/SessionItem.java:32	Please remove the author tag as indicated by the hadoop coding guidelines.&lt;br/&gt;
hwi/src/java/org/apache/hadoop/hive/hwi/SessionItem.java:55	javadocs for these.&lt;br/&gt;
hwi/src/java/org/apache/hadoop/hive/hwi/SessionItem.java:91	I could not find the stage1 and stage2 functions of the OpionsProcessor in this diff.&lt;br/&gt;
hwi/web/start_session_state.jsp:16	hello world.. does this need to go. I presume this was put in for some testing?&lt;/p&gt;</comment>
                            <comment id="12648882" author="appodictic" created="Wed, 19 Nov 2008 02:15:59 +0000"  >&lt;p&gt;hwi/build.xml:48 &amp;#8211; The default classpath will not find the servlet.jar or jetty jars. I learned ant an hour before the patch. So maybe someone can suggest a better way. build fails with refid=classpath&lt;br/&gt;
HWIServer:53,64,80 &amp;#8211; Agreed, in my first draft i wanted to avoid patching too much upstream. With your suggestion I will patch hive.conf&lt;br/&gt;
HWIServer:147 -Agreed&lt;br/&gt;
HWIServer 151 -method will be removed in favor of hive.conf.&lt;br/&gt;
HiveSessionManager.java:108 --Actually, I toiled over this for a while. I did it this way because I would have ended up explicitly passing this from HWIServer to HiveSessionManager to HiveSession. It seemed awkward to pass one variable around so many times thus far it is the only variable like this. Not many variables are explicitly passed across hadoop/hive. Read from hive.conf?  &lt;br/&gt;
SessionItem.java:32 --Sorry &lt;br/&gt;
hwi/src/java/org/apache/hadoop/hive/hwi/SessionItem.java:55 --will do&lt;br/&gt;
hwi/src/java/org/apache/hadoop/hive/hwi/SessionItem.java:91 --OptionsProcessor is upstream. I used options processor and session state like the CLIDriver does. If you could explain what I am missing in more detail I will add it. As far as I can tell I am doing everything I need to.&lt;br/&gt;
hwi/web/start_session_state.jsp:16--Its important. I will put more information about its usage inside the page.&lt;/p&gt;</comment>
                            <comment id="12649124" author="jsensarma" created="Wed, 19 Nov 2008 18:55:22 +0000"  >&lt;p&gt;just started looking at this.&lt;/p&gt;

&lt;p&gt;bin/hwi - seems like this replicates all the bin/hive logic. it will be troublesome to maintain replicated code. can we try to have the same shell harness and then launch hwi based on command line parameters?. ie:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;bin/hive --&amp;gt; launches cli&lt;/li&gt;
	&lt;li&gt;bin/hive --mode hwi  --&amp;gt; launches hwi server? (or some switch like that)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;this type of setup could also be useful for adding more standalone hive utilities in future&lt;/p&gt;</comment>
                            <comment id="12649129" author="athusoo" created="Wed, 19 Nov 2008 19:02:21 +0000"  >&lt;p&gt;Assigned to Edward and made him a contributor for Hive.&lt;/p&gt;</comment>
                            <comment id="12649169" author="appodictic" created="Wed, 19 Nov 2008 21:32:12 +0000"  >&lt;p&gt;&amp;gt;&amp;gt;bin/hwi - seems like this replicates all the bin/hive logic. it will be troublesome to maintain replicated code. can we try to have the same shell harness and then launch hwi based on command line parameters?&lt;/p&gt;

&lt;p&gt;I follow your logic. This is the same file with a few exceptions: &lt;br/&gt;
The CLASSNAME  &lt;br/&gt;
HWI_WAR_FILE&lt;br/&gt;
HWI_JAR_FILE&lt;/p&gt;

&lt;p&gt;The other major difference is that Jetty requires the ant jars. I have resolved this by copying ant jars to my hive/lib. It seems possible to reuse, but its hard to predict what other classpath or environment variables one application needs vs another.&lt;/p&gt;</comment>
                            <comment id="12649171" author="jsensarma" created="Wed, 19 Nov 2008 21:39:43 +0000"  >&lt;p&gt;i have a broader concern about how many servers we will end up having and what the server represents. with the jdbc/hive-73 effort - seems like there&apos;s at least one more hive server. if the server manages state - then it doesn&apos;t make sense that there is more than one. with the hadoop analogy - there would seem to be one server (like the namenode) that would expose a jsp interface (in addition to other interfaces like jdbc/odbc)&lt;/p&gt;

&lt;p&gt;we should also have one server side to manage common abstractions like userids and such. for example - we would find this patch unusable inside facebook since it does not set userids for hive queries - and this breaks the way we manage hadoop compute resources (we have fair sharing and compute quotas set up per userid) and hive tables (all tables will be created with same userid).&lt;/p&gt;

&lt;p&gt;at a very fundamental level - it&apos;s not clear to me what the  &apos;SHOW PROCESSLIST&apos; equivalent even means for Hive. With namenode for example - we associate a set of data nodes. with jobtracker - we associate a set of compute resources. Hive does not control (as clearly) any resources. A Hive query brings together a (Hive) metadata server, a map-reduce instance, one or more dfs instances (tables/databases can span hdfs instances) and the client side compute resources required to run the query. A collection of hive queries (unlike a collection of mysql queries to the same mysql server) may not have much in common and hence the show processlist abstraction is not that meaningful (at least to me). &lt;/p&gt;

&lt;p&gt;that aside - comments on the patch itself - i am ok with the way configuration stuff is being used (looks like we are using hiveconf for the most part - just not for the hwi stuff), but:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;we seem to be initializing HiveConf for each show table/database - but it seems that one would need just one hiveconf per session and continue using that&lt;/li&gt;
	&lt;li&gt;how are the logs going to be managed? logs for all sessions are going to the same server side log file. we should figure out a way to have the session id prepended to the log entries at least .. (for debugging)&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12649184" author="athusoo" created="Wed, 19 Nov 2008 22:24:01 +0000"  >&lt;p&gt;I don&apos;t completely understand the show processlist thingy that you are mentioning here. I am not sure if there is a show processlist notion here. Are you talking about SessionItem? I think that you have a completely stateless implementation where the execute and fetch is all done within the http call but then you would still need to maintain state somewhere if you want to share the session results (hipal does this persistently through mysql while here there is a transient state maintained in the SessionItem set in the server). Are you referring to the SessionItem set when you talk about processlist?&lt;/p&gt;

&lt;p&gt;Regarding the userid and authentication stuff, I think the best there is to use pam based scheme to tie this in with an existing LDAP repository or unix accounts. But that can perhaps be done as a follow up transaction?&lt;/p&gt;</comment>
                            <comment id="12649198" author="appodictic" created="Wed, 19 Nov 2008 22:48:15 +0000"  >&lt;p&gt;I understand the concern about having multiple session servers. However, I believe the state belongs to the client. I might want to make a swing application that uses three SessionStates, etc. A generic SessionState server is just an extra abstraction at this phase. You never know how the client will want to use the SessionState.  &lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;we should also have one server side to manage common abstractions like userids and such&lt;br/&gt;
...True. The &apos;userid&apos; and &apos;password&apos; in hwi is just a nice way of naming the session. Imagine a web server managing thousands of jobs, the SHOW_SERVER_STATUS page would be thousands of meaningless session ids. I decided to attach a human readable name to the hive sessions. A simple password mechanism just protects Bob from from editing Sara&apos;s session. It was a throw in feature. If you set the password to empty string it has no effect. My goal for was not to create a wide reaching security implication for hive/hadoop but to simply give the user the ability to name and optionally protect their session since anyone who goes to the web server can get at the session. -&lt;del&gt;Lets talk more about passing that information from a web interface&lt;/del&gt;-&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;we seem to be initializing HiveConf for each show table/database&lt;br/&gt;
True. I am using the thrift API for the meta operations. Using the web interface it is possible to view the schema without starting a session state. Those two parts of the application are different. The schema browsing is more or less stateless, that is why the HiveConf is reloaded per request.&lt;br/&gt;
&amp;gt;&amp;gt;how are the logs going to be managed?--Right now there is no logging. JSP Session ID might make sense over Hive Session ID &lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;Regarding the userid and authentication stuff, I think the best there is to use pam based scheme to tie this in with an existing LDAP repository or unix accounts. But that can perhaps be done as a follow up transaction?&lt;br/&gt;
Again, my goal was to name the sessions and give a simple password mechanism. I know there is a hadoop jira open for kerberos.  I work a lot with LDAP, in the end you can force the hadoop property from inside java, right? Also my LDAP server uses public key authentication, I actually do not have a password in the entire server. So LDAP brings other complications.&lt;/p&gt;</comment>
                            <comment id="12649213" author="jsensarma" created="Wed, 19 Nov 2008 23:43:36 +0000"  >&lt;p&gt;@Ashish - i think what u are saying makes total sense (in terms of managing state for one client/session). but the other angle is that this jsp page becomes the place where i can go and see all running sessions (it&apos;s both in the code as well as one of the features mentioned in the jira-description). that&apos;s what confuses me.&lt;/p&gt;

&lt;p&gt;something like show processlist is very useful for admins - but the adminstrative entity is not clear (unlike in mysql case). that&apos;s where my confusion is - what is the resource that we are administering? the compounding factor is that there are ways of submitting queries that do not go through the jsp gateway (or that there can be multiple jsp gateways) - so we are not going to be able to capture all running sessions/queries. ie. - if there&apos;s utility in capturing current/historic queries in one place - then we had better have a single server side for all access methods.&lt;/p&gt;

&lt;p&gt;also - longer term - i think the actual act of running a hive query is fairly heavyweight (this is just a guess) - since there are many data path operations that we would want to move to the client itself. also - if someone is extracting bulk data - we would like this (if possible) to be a direct interaction between client and hdfs and remove any central session manager out of this datapath.&lt;/p&gt;

&lt;p&gt;so what would make sense to me is to have a single session manager for all hive access paths (within a deployment say). cli/jsp/jdbc can all open, close, authenticate and get queries compiled into physical plans from this session manager (which can also take care of authentication etc.). the centralized session manager would be the administrative control point for the deployment. but the actual execution of the physical plan is then separated from centralized session management. cli clients or jsp or jdbc servers would take the physical plans and execute them in their own process (interacting with map-reduce and/or other resources as required).&lt;/p&gt;

&lt;p&gt;does this make sense? (I am hoping we can have a single coherent client-server model rather than independent pieces of work that do not mix&apos;n&apos;match with each other). we could start/extend this patch to be the central session manager that the cli could talk to as well (and future jdbc servers could also talk to).&lt;/p&gt;</comment>
                            <comment id="12649247" author="athusoo" created="Thu, 20 Nov 2008 02:50:57 +0000"  >&lt;p&gt;hmm...&lt;/p&gt;

&lt;p&gt;Ideally the HiveServer that is being done as part of JDBC driver should be able to handle all the session creation, processlist, authentication and be a single gateway for submitting the queries, and as Joy says the client side libraries for that server should be managing the data path. Regarding the state belonging to the client, there is some state that needs to be there on the server as the typical JDBC is session oriented and calls are within the context of a session.&lt;/p&gt;

&lt;p&gt;The web server that is being done as part of this JIRA and the cli would then communicate to the HiveServer for all those services as well as for query compilation and submission. Having said that there would still be some web client specific session information that the web server would have&lt;br/&gt;
to maintain, things like if a websession is free to take some other queries, whether it has been named and initialized etc. Maybe we should call SessionItem, WebSessionItem. All the administrative options that this JIRA then provides for now are then only over WebSessions and not any other sessions started by other clients (cli or programs like JDBC). We can expand the capabilities of the Web Client to provide administration over those sesssions once the HiveServer is ready and able to do all those things.&lt;/p&gt;

&lt;p&gt;I think the current implementation of the HWIServer is also a vestige of the fact that we do not have a server implementation for hive and our compiler essentially runs as a client library today. One could see the SessionState(or some equivalent of it) class be subsumed in the HiveServer and be provided to the clients through the HiveServer interfaces (essentially a client side handle). If we think of it in those terms then the current implementation is not too much off the mark. SessionItem becomes WebSession. Processlist becomes WebSessionLists. The authentication stuff that Edward is pointing to becomes authentication for manipulating websessions only (though in the long term it will be better to integrate the notion of authority there with the notion of authority in HiveServer - which does not have any right now - maybe that should get pulled into the Hive Server). WebSession holds the SessionState which is the client side representation of a HiveServer session and allows the websession to access the corresponding session on the HiveServer side. Something on those lines...&lt;/p&gt;

&lt;p&gt;Note in this model there is a single HiveServer (similar to a mysql or Oracle instance), JDBC is a client side driver that just talks to this server, the Web Server talks to this server too for much of the stuff (it is doing this through the metastore server for metadata stuff and the HiveServer as proposed currently by Ragu and Michi just includes those thrift calls as well - it is super set of the MetaStore and the data operations).&lt;/p&gt;

&lt;p&gt;Makes sense?&lt;/p&gt;</comment>
                            <comment id="12649263" author="appodictic" created="Thu, 20 Nov 2008 05:05:01 +0000"  >&lt;p&gt;I do understand the concept of having a session server. A simplified superset of meta store and data operations would be a good thing. A lite client is better then the &apos;fat client&apos; that exists now. I understand that Thift is language neutral but I see the thrift server looks like it is implemented in c++ (correct me if I am wrong.)&lt;/p&gt;

&lt;p&gt;Playing devils advocate:&lt;br/&gt;
From the prospective a guy writing a Java JSP application. I should be able to harness direct Java classes. JDBC and Thrift Servers should sit on top of those. I would get a little cranky if the only way I could hook into some particular library was to go out and start getting c++ libraries, so I could start a C++ based thrift server to get at some data in Java. &lt;/p&gt;

&lt;p&gt;Can the superset be a pure Java facade and thrift jdbc on top of that? &lt;/p&gt;

&lt;p&gt;That being said, if a SessionServer is out there I will gladly hook into it. &lt;/p&gt;</comment>
                            <comment id="12649299" author="rsm" created="Thu, 20 Nov 2008 08:06:48 +0000"  >&lt;p&gt;Thrift allows the server to be written in Java as well. The patch for Hive-73 might make things more clear.&lt;/p&gt;</comment>
                            <comment id="12649303" author="jsensarma" created="Thu, 20 Nov 2008 08:50:00 +0000"  >&lt;p&gt;@Edward - the thrift Hive Server is implemented in Java - all that C++ code is generated thrift code for the client side stubs in all likelihood.&lt;/p&gt;

&lt;p&gt;@ashish - from what i see - the thrift hiveserver does not manage sessions right now. I think at this point we are all in agreement and perhaps we should spec out what the hive session manager common to all access paths does:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;start/stop session&lt;/li&gt;
	&lt;li&gt;validate user credentials and maintain stats/logs per user/session&lt;/li&gt;
	&lt;li&gt;compile queries&lt;/li&gt;
	&lt;li&gt;submit any map-reduce jobs&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;submitting a map-reduce task by itself is low overhead - and also desirable in the session manager (so that an admin can come to the session manager and see and kill running map-reduce jobs). however - beyond this - any actual reading of the data files ought to definitely occur in the client (ie. cli/jdbc server/hwi). &lt;/p&gt;

&lt;p&gt;given that the thrift server does not manage sessions right now - and the current patch has the beginnings of a session manager - we could as well begin here by teasing apart the generic session management code/server and then starting to adapt other clients to it .. &lt;/p&gt;

&lt;p&gt;comments?&lt;/p&gt;</comment>
                            <comment id="12649310" author="rsm" created="Thu, 20 Nov 2008 10:05:19 +0000"  >&lt;p&gt;@Joy - The SessionManager can also be implemented as a Thrift service. Then the HiveInterface will include the SessionManager interface like how it is including the MetaStore interface.&lt;/p&gt;</comment>
                            <comment id="12649394" author="appodictic" created="Thu, 20 Nov 2008 15:47:42 +0000"  >&lt;p&gt;There is one more thing it should handle if it does not do already. If a user issues a large query where does the intermediate data go? And how much of it should be kept? For example a user from the web interface may issues a query like &quot;SELECT people.* FROM people. Lets assume this results in 2GB of results. If I were using a command line interface I would expect the data to be stream to my console. If I were using a web interface I would expect that data to be saved somewhere. Currently, HWI is saving the the data to a local file. I was thinking to implement a FIFO queue that would hold a variable number of rows in memory.  Or a similar setting that would clean up the file. A JDBC style driver with a cursor is still and issue because it will be blocked until the user returns for that data, which could be never. Most queries will end up creating a new table of file in HDFS so its not a major issue. &lt;/p&gt;

&lt;p&gt;Above someone mentioned not being able to take advantage of Fair Share scheduling and tables names. I think you can do that from the HWI interface. The user has access to the SetProcessor through a JSP page, so they should be able to set and hive/hadoop variables from HWI. There is nothing stopping me from using someone else&apos;s credentials, however the same is true for the hive CLI. Correct?&lt;/p&gt;</comment>
                            <comment id="12649414" author="athusoo" created="Thu, 20 Nov 2008 17:10:10 +0000"  >&lt;p&gt;Actually Hive CLI today does not have any credentials at all currently.&lt;/p&gt;

&lt;p&gt;@Joy&lt;br/&gt;
I would say that we put the work for credentials out to a separate JIRA and not include the notions of credentials and SessionManager as part of this JIRA. We spec that out as part of a separate JIRA. With that part in place we anyway will have to rework the CLI, JDBC driver and HWI. Should we get the intial web UI in first and then go and fix ti and the other clients to use the SessionManager as part of another JIRA?&lt;/p&gt;

&lt;p&gt;@Edward&lt;br/&gt;
If you are not reading the entire data in one shot and making repeated fetch calls you have the problem of how to age out sessions. An easy way is to have some session timeout after which the session is aged out. I am not sure if FIFO is going to be helpful&lt;br/&gt;
unless the user is going to be scrolling up and down the result data a lot and the client side buffers are not big enough to deal with that. I &lt;br/&gt;
would say that for now, keep it simple and just read out the stuff from the temporary file directly (Hive is already producing a temporary&lt;br/&gt;
directory in hdfs for you which is held on till close is called on the dirver handle (which could be tied to an explicit close done by the user or &lt;br/&gt;
an aged out session) and let the client application deal with any buffering.&lt;/p&gt;

&lt;p&gt;Internally we punted on this altogether by allowing the user to download the data into a local file or spreadsheet and so we did not have&lt;br/&gt;
to maintain any cursors inside the hipal application. Bascially in hipal&lt;/p&gt;

&lt;p&gt;SELECT people.* FROM people &lt;/p&gt;

&lt;p&gt;becomes&lt;/p&gt;

&lt;p&gt;CREATE TABLE tmp_hwi_&amp;lt;QUERYID&amp;gt; ();&lt;br/&gt;
ALTER TABLE tmp_hwi_&amp;lt;QUERYID&amp;gt; SET TBLPROPERTIES (&apos;RETENTION&apos;=&apos;7&apos;);&lt;/p&gt;

&lt;p&gt;INSERT OVERWRITE TABLE tmp_hwi_&amp;lt;QUERYID&amp;gt;&lt;br/&gt;
SELECT people.* FROM people;&lt;/p&gt;

&lt;p&gt;with retention set to 7 so that a cleanup tool can cleanup any of these tables which are more than 7 days old.&lt;/p&gt;

&lt;p&gt;creating a temporary table has the added advantage that the run results could also be shared with the rest of the users without them&lt;br/&gt;
having to run the same query again and again.&lt;/p&gt;
</comment>
                            <comment id="12649429" author="jsensarma" created="Thu, 20 Nov 2008 17:44:28 +0000"  >&lt;p&gt;@ashish - agreed on making the session manager thing a separate jira. would be reasonable amount of work to tease it out from existing clients.&lt;/p&gt;

&lt;p&gt;@edward - yeah - the userid thing is not too strong right now - but it works in a cooperative environment. as long as it&apos;s too painful to fake another user - most people will not. the problem with the web stuff is that there&apos;s no good default (unlike unix userid in the cli). HiPal uses facebook login id.&lt;/p&gt;</comment>
                            <comment id="12649601" author="athusoo" created="Fri, 21 Nov 2008 05:25:31 +0000"  >&lt;p&gt;So where do we stand on this. What are the modifications needed to this patch after which we can +1 this and get it into the repo.&lt;/p&gt;</comment>
                            <comment id="12649712" author="jsensarma" created="Fri, 21 Nov 2008 17:31:00 +0000"  >&lt;p&gt;Blockers from my side:&lt;/p&gt;

&lt;p&gt;hwi shell script: i would like to see this merged with the hive cli shell script and written as a generic harness to launch hive utilities. given that the bulk of the libraries are common - it seems perfectly fine to add more jars and classname to be executed based on the actual utility name (cli vs. hwi)&lt;/p&gt;

&lt;p&gt;also - i think it will be fairly critical to take in userids and propagate them to hive/hadoop (by setting user.name property). why don&apos;t we just replace &apos;sessionname&apos; with &apos;userid&apos; ? that should also automatically generate a separate log file for each user on the hwi server - so it will be somewhat easy to grok at logs if required.&lt;/p&gt;

&lt;p&gt;Another thing i just noticed - Hive&apos;s current runtime assumes a singleton SessionState object. That&apos;s just not going to work here (since there&apos;s a singleton per execution thread now). There are in fact some comments to this effect in SessionState.java - we need to make it a thread-local singleton. This has to be fixed - otherwise concurrent queries/sessions would be trampling over each other. (we can do this in a separate jira - although it would be a blocker for this one)&lt;/p&gt;

&lt;p&gt;regarding ss.out: in order to capture data only in the results file - please set the session to silent mode. otherwise the output will be polluted with informational messages. (perhaps this is highlighting that we need to get informational messages in a different stream (potentially) than the actual results - which is very doable - but not the way things are setup now)&lt;/p&gt;

&lt;p&gt;all of these are really asking the question: how was this tested? both of the last two issues are fairly major.&lt;/p&gt;

&lt;p&gt;other usability issues that are going to be very important (based on observing hipal): one cannot destroy a running session - but one of the most common operations that users will want to do is monitor the map-reduce tasks that have been spawned by a query and kill them (for example - if the job is too long or the jobconf parameter setting need to be fixed). &lt;/p&gt;


&lt;p&gt;Good to have things (in decreasing order of importance):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;regarding reloading HiveConf - if schema browsing is not associated with a session - then the same hiveconf can be cached and re-used. minor point - but loading the hiveconf is big enough that i think you won&apos;t be happy if this tool becomes really popular &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/li&gt;
	&lt;li&gt;any reason why QUERY_SET etc. should not be an enum type?&lt;/li&gt;
	&lt;li&gt;spell check clientDestory&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12649717" author="jsensarma" created="Fri, 21 Nov 2008 17:51:37 +0000"  >&lt;p&gt;on second thoughts - the thread safety issue goes beyond SessionState. We have never run/tested Hive client side code in a multithreaded environment. without auditing the code carefully and having some good tests - all bets are off. (hipal executes each query in a different process using bin/hive -e &quot;query&quot; - so it&apos;s not affected by this issue).&lt;/p&gt;</comment>
                            <comment id="12649771" author="appodictic" created="Fri, 21 Nov 2008 19:24:57 +0000"  >&lt;p&gt;&amp;gt;&amp;gt;hwi shell script:&lt;br/&gt;
I see what you are saying.  Ill add this capability. This would make the hive script work more like /bin/hadoop&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;I think it will be fairly critical to take in userids and propagate them to hive/hadoop (by setting user.name property).&lt;br/&gt;
Once you have started the hive session. You have access to the set processor. You should be able to do. SET user.name=ecapriolo. I could make a form to this effect to make setting these things easier, but the session_set_processor.jsp allows for set commands. &lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;Another thing i just noticed - Hive&apos;s current runtime assumes a singleton SessionState object. &lt;br/&gt;
I had not looked deep into that part of the API. That would block me. I guess it did not come up on any ones radar till now.&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;why don&apos;t we just replace &apos;sessionname&apos; with &apos;userid&apos; ?&lt;br/&gt;
I was looking at this like a user can have more then one session, that being the case a name would identify it. &lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;please set the session to silent mode. &lt;br/&gt;
Sounds good. I figured most queries would output to a HDFS file. I viewed the result file as a good way to debug. A normal user would expect whatever came out of the CLI to be in the results file. I will add a debug switch. In the API&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;how was this tested? &lt;br/&gt;
Me and a live server. Smaller data sets, simple queries. I did not pick up on the &apos;singleton SessionState object&apos; issue.&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;any reason why QUERY_SET etc. should not be an enum type?&lt;br/&gt;
I&apos;m just old school. I will change it to enum.&lt;/p&gt;</comment>
                            <comment id="12649831" author="jsensarma" created="Fri, 21 Nov 2008 22:20:37 +0000"  >&lt;p&gt;ok - i filed hive-77. i think it makes sense to do any multi-threading cleanup in a separate jira (since that could be an issue for other server code as well). also we need a good test suite for this kind of execution environment.&lt;/p&gt;

&lt;p&gt;if u can make progress on some of the other issue - i can take a stab at hive-77 in parallel. &lt;/p&gt;

&lt;p&gt;regarding the username vs. session: would it be fair to say that passwords are usually on a per user basis. ie. i am wondering if the flow should be &apos;specify username/password&apos; and then &apos;start new session&apos;, &apos;list sessions&apos; etc. - all within the context of one userid. i am a little skeptical of the &apos;set&apos; approach - i think most people will not set anything unless they have to. for the administrator - it&apos;s critical that userid be set - otherwise all load on the map-reduce cluster and all tables look like they are owned by one user - which is pretty terrible.&lt;/p&gt;

&lt;p&gt;I understand that this can be easily faked - but at least it sets expectations and sets up for future ldap etc. integration. Perhaps others can chime in here as well?&lt;/p&gt;
</comment>
                            <comment id="12649841" author="athusoo" created="Fri, 21 Nov 2008 23:03:22 +0000"  >&lt;p&gt;I think user.name should be implicitly set in the session and should be implicitly populated with some javascript code to mimic the user from the web clients host OS.&lt;/p&gt;

&lt;p&gt;For sessionname, I think we should just punt on the userid thingy for now considering that we do not have any notion of a user at all and we should do once we have the common authentication stuff setup for that (will file an alternate JIRA for that).&lt;/p&gt;

&lt;p&gt;If we go with the current sessionname abstractions we can easily though in a whole user management layer on top of that once the user authentication/authorization infrastructure is ready.&lt;/p&gt;</comment>
                            <comment id="12652056" author="appodictic" created="Mon, 1 Dec 2008 16:48:04 +0000"  >&lt;p&gt;Patch is an upgrade of the last patch.&lt;/p&gt;

&lt;p&gt;1) Added silent mode support. Silent mode is a text box controls output to the result file&lt;br/&gt;
2) removed HWI script. Modified bin/hive to accept a component argument bin/hive cli | hwi&lt;br/&gt;
3) Code/comment cleanup&lt;br/&gt;
4) Shutdown issues join(2000) to any running thread&lt;/p&gt;

&lt;p&gt;Still blocked by thread session state issues. Wanted to get input on new bin/hive script mostly.&lt;/p&gt;</comment>
                            <comment id="12652166" author="jsensarma" created="Mon, 1 Dec 2008 21:40:49 +0000"  >&lt;p&gt;regarding the bin/hive changes, couple of requests:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;please make &quot;cli&quot; the default component (since that&apos;s the common case for users right now)&lt;/li&gt;
	&lt;li&gt;ANT_LIB - do you want to give users a way to configure this? (default to /opt .. but allow override with env variable)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;regarding the multi-threaded session stuff - i do have a patch for hive-77 out (needs review). as mentioned in that - it doesn&apos;t solve the metastore client issue - but at least prevents basic output and configuration collision. i think the code here looks good wrt to hive-77 (the only requirement is that a thread when it starts processing a session calls SessionState.start() with that session object - and i think this is being followed here - so we should be good). the only thing we would need is some testing of both of these together.&lt;/p&gt;

&lt;p&gt;did u get a chance to think about userid vs. sessionname stuff? I can&apos;t imagine using this without forcing entry of usernames and making sure they are carried through to jobtracker and hive metastore.&lt;/p&gt;</comment>
                            <comment id="12657486" author="appodictic" created="Wed, 17 Dec 2008 19:01:33 +0000"  >&lt;p&gt;@Ashish&lt;br/&gt;
I am closing in on releasing another patch. The HWISessionManager now holds a map of &amp;lt;HWIUser,Set&amp;lt;SessionItem&amp;gt;&amp;gt;. &lt;/p&gt;

&lt;p&gt;HWIUser:&lt;br/&gt;
-String user,&lt;br/&gt;
-String [] groups&lt;/p&gt;

&lt;p&gt;The start page of the web interface will be a &apos;login&apos; screen.&lt;/p&gt;

&lt;p&gt;Assume the user enters:&lt;br/&gt;
User: user1&lt;br/&gt;
Groups: user1 group1&lt;/p&gt;

&lt;p&gt;During the SessionItem initialization this will be run:&lt;/p&gt;

&lt;p&gt;set hadoop.job.ugi=user1,user1&lt;/p&gt;

&lt;p&gt;Does that handle setting the group permissions properly?&lt;/p&gt;</comment>
                            <comment id="12657854" author="athusoo" created="Thu, 18 Dec 2008 18:52:29 +0000"  >&lt;p&gt;I think that should work.&lt;/p&gt;

&lt;p&gt;Joy can you confirm.&lt;/p&gt;</comment>
                            <comment id="12658031" author="jsensarma" created="Fri, 19 Dec 2008 07:49:44 +0000"  >&lt;p&gt;sounds pretty good to me. i don&apos;t think Hive uses the unixusergroup stuff yet (we are still using user.name) - but this seems like the right direction. we need to change hive to do the right thing ..&lt;/p&gt;</comment>
                            <comment id="12658984" author="appodictic" created="Tue, 23 Dec 2008 22:40:13 +0000"  >&lt;p&gt;Did some major re factoring based on comments.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;authorization to set hadoop/hive user/group Vectors&lt;/li&gt;
	&lt;li&gt;log4j support&lt;/li&gt;
	&lt;li&gt;kill support via join (needs some testing)&lt;/li&gt;
	&lt;li&gt;changed status to enumeration&lt;/li&gt;
	&lt;li&gt;added two configuration options to HiveConf vs System.property&lt;/li&gt;
	&lt;li&gt;added HWIException vs int/enum status returns&lt;/li&gt;
	&lt;li&gt;managed close threads on shutdown&lt;/li&gt;
	&lt;li&gt;better/consistent class naming&lt;/li&gt;
	&lt;li&gt;silent mode as a selectable option&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Still going to produce a final patch with some cleanup/JUNIT tests&lt;/p&gt;</comment>
                            <comment id="12659126" author="appodictic" created="Wed, 24 Dec 2008 17:51:56 +0000"  >&lt;p&gt;Also I have ran into something that I would like to discuss. The ExecDriver produces this output via printInfo()&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Starting Job = job_200812241109_0004, Tracking URL = http://hadoop1:50030/jobdetails.jsp?jobid=job_200812241109_0004
Kill Command = /opt/hadoop/hadoop-0.19.0/bin/../bin/hadoop job  -Dmapred.job.tracker=hadoop1:54311 -kill job_200812241109_0004
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I am trying to mimick this behaivor.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;public String getJobTrackerURI(){
		StringBuffer sb = new StringBuffer();
		sb.append(&quot;http://&quot;);
		sb.append( conf.get(&quot;mapred.job.tracker.http.address&quot;) );
		sb.append(&quot;/jobdetails.jsp?jobid=&quot;);
		sb.append(this.conf.getVar(HiveConf.ConfVars.HADOOPJOBNAME));
		return sb.toString();
	}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is not correct as HADOOPJOBNAME would actually be the HQL query. &lt;/p&gt;

&lt;p&gt;With the SessionState you can not reference SessionState-&amp;gt;ExecDriver-&amp;gt;JobConf. The only way I can determine this information is by not letting the session be silent and reading/parsing raw data. My usage of SessionState is a bit different then the current CLI session state. A fix would be to have the exec driver set a read only HashMap in the Session State. &lt;/p&gt;
</comment>
                            <comment id="12659924" author="athusoo" created="Tue, 30 Dec 2008 20:06:00 +0000"  >&lt;p&gt;Does&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-176&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-176&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;provide you a mechanism to read this out from the log.&lt;/p&gt;</comment>
                            <comment id="12659930" author="athusoo" created="Tue, 30 Dec 2008 20:16:39 +0000"  >&lt;p&gt;Alternatively, you could just use&lt;/p&gt;

&lt;p&gt;Job.getJobId to populate a new configuration parameter in HiveConf. This would have to be populated for each job that is started in Driver.java.&lt;/p&gt;</comment>
                            <comment id="12662666" author="athusoo" created="Sat, 10 Jan 2009 15:11:18 +0000"  >&lt;p&gt;Hi Edward,&lt;/p&gt;

&lt;p&gt;Any progress on this? I hope you are not gated on us for anything. Let us know.&lt;/p&gt;</comment>
                            <comment id="12663917" author="appodictic" created="Wed, 14 Jan 2009 22:55:58 +0000"  >&lt;p&gt;No blockers on my end. I am looking to have a release by Friday.&lt;/p&gt;</comment>
                            <comment id="12663919" author="athusoo" created="Wed, 14 Jan 2009 23:01:43 +0000"  >&lt;p&gt;Thanks for the update!&lt;/p&gt;</comment>
                            <comment id="12666628" author="appodictic" created="Fri, 23 Jan 2009 17:54:59 +0000"  >&lt;p&gt;This patch has:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;More javadoc&lt;/li&gt;
	&lt;li&gt;log4j across the code&lt;/li&gt;
	&lt;li&gt;A File View with ability to view result file by chunk&lt;/li&gt;
	&lt;li&gt;manage_session page shows the queries return status from qp.run(String)&lt;/li&gt;
	&lt;li&gt;Helper page that lists the kill URL for every running job&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This patch does not have:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Kill operation will have to open a new jira, not possible to determine Job ID from session&lt;/li&gt;
&lt;/ul&gt;


</comment>
                            <comment id="12666998" author="appodictic" created="Sat, 24 Jan 2009 21:30:26 +0000"  >&lt;p&gt;Added a test case. Fixed a possible null pointer if running standalone.&lt;/p&gt;</comment>
                            <comment id="12667480" author="athusoo" created="Mon, 26 Jan 2009 23:01:13 +0000"  >&lt;p&gt;This looks pretty good to me. I am trying to deploy it out here and try the GUI. Code wise there is some moderate issues and a few minor issues. Which are as follows (without the fix to hwi/build.xml:31 I do not think that this will compile with any other version of hadoop i.e. with -Dhadoop.version=&quot;0.17.0&quot; for example)&lt;/p&gt;

&lt;p&gt;Moderate points..&lt;br/&gt;
Inline Comments&lt;br/&gt;
hwi/build.xml:31	This is already included in the classpath, so you can eliminate this. Otherwise, this will not compile with other versions of hadoop.&lt;br/&gt;
hwi/build.xml:35	Is this also there in the classpath definition of build-common.xml?&lt;/p&gt;

&lt;p&gt;Minor points..&lt;br/&gt;
hwi/src/java/org/apache/hadoop/hive/hwi/HWIAuth.java:70	Should the comparison here ignore case? Does xyz user name differ from XyZ?&lt;br/&gt;
hwi/src/java/org/apache/hadoop/hive/hwi/HWIServer.java:65	Can we encode this in HiveConf.java as well. Similar to the stuff that we do with HADOOP_HOME..&lt;/p&gt;</comment>
                            <comment id="12667504" author="appodictic" created="Mon, 26 Jan 2009 23:55:33 +0000"  >&lt;p&gt;As to the build file. I modeled what I was doing off jdbc/build.xml and service/build.xml&lt;/p&gt;

&lt;p&gt;Both of these seem to define the classpath again. All I really need to accomplish that is non standard is this:&lt;br/&gt;
&amp;lt;jar jarfile=&quot;../build/hive_hwi.war&quot; basedir=&quot;${basedir}/web&quot;/&amp;gt;&lt;/p&gt;

&lt;p&gt;Can someone suggest a way I can run a standard compile or deploy and tack this operation on the end? &lt;/p&gt;

&lt;p&gt;hwi/src/java/org/apache/hadoop/hive/hwi/HWIAuth.java:70- I think we should retain case sensitivity. posix user&lt;br/&gt;
XYZ is not the same user as XYz &lt;/p&gt;

&lt;p&gt;hwi/src/java/org/apache/hadoop/hive/hwi/HWIServer.java:65-No problem&lt;/p&gt;</comment>
                            <comment id="12667537" author="athusoo" created="Tue, 27 Jan 2009 01:14:20 +0000"  >&lt;p&gt;what I meant was that hardcoding hadoop-0.19.0 in the classpath will ensure that the code will not compile when -Dhadoop.version=&quot;0.17.0&quot; for example.&lt;/p&gt;

&lt;p&gt;If you just need to override the compile target, you could do that by removing classpath-hwi completely and putting refid=&quot;classpath&quot; in the compile target that you have in hwi/build.xml. It will automatically get the classpath settings from build-common.xml that you are importing into the build file.&lt;/p&gt;

&lt;p&gt;I am fine with the case sensitivity thingy...&lt;/p&gt;</comment>
                            <comment id="12668510" author="appodictic" created="Thu, 29 Jan 2009 16:43:34 +0000"  >&lt;p&gt;This patch adds:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;the WAR location to be specified in hive-site.conf (changed to HiveConf)&lt;/li&gt;
	&lt;li&gt;also the class path refers to hadoop.root&lt;br/&gt;
rather then a hardcoded version ie 0.19.0&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12668624" author="athusoo" created="Thu, 29 Jan 2009 21:54:26 +0000"  >&lt;p&gt;Hi Edward,&lt;/p&gt;

&lt;p&gt;It seems like the latest patch has the output for svn stat instead of svn diff... &lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Ashish&lt;/p&gt;</comment>
                            <comment id="12668697" author="appodictic" created="Fri, 30 Jan 2009 01:21:30 +0000"  >&lt;p&gt;Newest patch. (not a svn stat DOH!)&lt;/p&gt;</comment>
                            <comment id="12669074" author="athusoo" created="Fri, 30 Jan 2009 23:17:07 +0000"  >&lt;p&gt;Hi Edward,&lt;/p&gt;

&lt;p&gt;I used the following command to compile and run the tests...&lt;/p&gt;

&lt;p&gt;&amp;gt; ant -lib testlibs clean package clean-test test&lt;/p&gt;

&lt;p&gt;I am getting the following error while compiling...&lt;/p&gt;

&lt;p&gt;jar:&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;echo&amp;#93;&lt;/span&gt; Jar: jdbc&lt;br/&gt;
      &lt;span class=&quot;error&quot;&gt;&amp;#91;jar&amp;#93;&lt;/span&gt; Building jar: /data/users/athusoo/commits/hive_trunk_ws2/build/jdbc/hive_jdbc.jar&lt;/p&gt;

&lt;p&gt;deploy:&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;echo&amp;#93;&lt;/span&gt; hive: jdbc&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;copy&amp;#93;&lt;/span&gt; Copying 1 file to /data/users/athusoo/commits/hive_trunk_ws2/build&lt;/p&gt;

&lt;p&gt;compile:&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;echo&amp;#93;&lt;/span&gt; Compiling: hwi&lt;/p&gt;

&lt;p&gt;BUILD FAILED&lt;br/&gt;
/data/users/athusoo/commits/hive_trunk_ws2/build.xml:108: The following error occurred while executing this line:&lt;br/&gt;
/data/users/athusoo/commits/hive_trunk_ws2/hwi/build.xml:16: destination directory &quot;/data/users/athusoo/commits/hive_trunk_ws2/build/hwi/classes&quot; does not exist or is not a directory&lt;/p&gt;
</comment>
                            <comment id="12669082" author="appodictic" created="Fri, 30 Jan 2009 23:45:04 +0000"  >&lt;p&gt;Added a target to create build directories and then made compile depend on it. To solve make issue.&lt;/p&gt;</comment>
                            <comment id="12670071" author="athusoo" created="Tue, 3 Feb 2009 19:28:36 +0000"  >&lt;p&gt;looks good to me..&lt;/p&gt;

&lt;p&gt;There is one minor thing though that is causing some test failures in my run.&lt;/p&gt;

&lt;p&gt;I think TestHWISessionManager.java does not drop the test_hwi_table.&lt;/p&gt;

&lt;p&gt;As a result if it happens to run before the TestCliDriver it causes the outputs of show tables to changes and that causes some tests to fail in TestCliDriver.&lt;/p&gt;

&lt;p&gt;Can you fix that. Once I get a clean run, I can get this in...&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Ashish&lt;/p&gt;</comment>
                            <comment id="12670159" author="appodictic" created="Tue, 3 Feb 2009 22:58:32 +0000"  >&lt;p&gt;This patch properly cleans up files in the test case.&lt;br/&gt;
Tested with two successive runs of &apos;ant test&apos; in hwi directory.&lt;/p&gt;</comment>
                            <comment id="12670184" author="athusoo" created="Tue, 3 Feb 2009 23:54:41 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;Looks good. All the tests run clean. I am going to check this in.&lt;/p&gt;

&lt;p&gt;Thanks for a great contribution...&lt;/p&gt;</comment>
                            <comment id="12670188" author="athusoo" created="Wed, 4 Feb 2009 00:08:20 +0000"  >&lt;p&gt;committed. Thanks Edward for a great contribution!! Please put up info about the web UI on the wiki.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12409031">HIVE-77</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12398592" name="HIVE-30-5.patch" size="65642" author="appodictic" created="Fri, 23 Jan 2009 17:54:59 +0000"/>
                            <attachment id="12398668" name="HIVE-30-6.patch" size="69071" author="appodictic" created="Sat, 24 Jan 2009 21:30:26 +0000"/>
                            <attachment id="12396701" name="HIVE-30-A.patch" size="56028" author="appodictic" created="Tue, 23 Dec 2008 22:40:13 +0000"/>
                            <attachment id="12395026" name="HIVE-30.patch" size="63726" author="appodictic" created="Mon, 1 Dec 2008 16:48:04 +0000"/>
                            <attachment id="12394116" name="HIVE-30.patch" size="66093" author="appodictic" created="Tue, 18 Nov 2008 00:37:42 +0000"/>
                            <attachment id="12399180" name="hive-30-10.patch" size="69477" author="appodictic" created="Fri, 30 Jan 2009 23:45:04 +0000"/>
                            <attachment id="12399397" name="hive-30-11.patch" size="69800" author="appodictic" created="Tue, 3 Feb 2009 22:58:32 +0000"/>
                            <attachment id="12399018" name="hive-30-7.patch" size="1651" author="appodictic" created="Thu, 29 Jan 2009 16:43:34 +0000"/>
                            <attachment id="12399082" name="hive-30-9.patch" size="69287" author="appodictic" created="Fri, 30 Jan 2009 01:21:30 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 24 Oct 2008 20:52:43 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73824</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 51 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0iv3b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>108131</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-33] [Hive]: Add optimizer statistics in Hive</title>
                <link>https://issues.apache.org/jira/browse/HIVE-33</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Add commands to collect partition and column level statistics in hive.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12407019">HIVE-33</key>
            <summary>[Hive]: Add optimizer statistics in Hive</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="athusoo">Ashish Thusoo</reporter>
                        <labels>
                            <label>statistics</label>
                    </labels>
                <created>Wed, 22 Oct 2008 18:41:50 +0000</created>
                <updated>Wed, 5 Jul 2017 14:29:23 +0000</updated>
                            <resolved>Wed, 5 Jul 2017 14:29:22 +0000</resolved>
                                                                    <component>Query Processor</component>
                    <component>Statistics</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>22</watches>
                                                                                                            <comments>
                            <comment id="12641939" author="athusoo" created="Wed, 22 Oct 2008 18:56:36 +0000"  >&lt;p&gt;Type of statistics:&lt;br/&gt;
The following types of statistics can be collected on hive partitions -&amp;gt;&lt;/p&gt;

&lt;p&gt;For each partition of the table:&lt;br/&gt;
1. Number of Rows&lt;br/&gt;
2. Size of the partition&lt;br/&gt;
3. Average size of a row&lt;br/&gt;
4. Number of blocks&lt;/p&gt;

&lt;p&gt;For a column in the partition:&lt;br/&gt;
1. Number of distinct values&lt;br/&gt;
2. Number of null values&lt;br/&gt;
3. minimum 3 values&lt;br/&gt;
4. maximum 3 values&lt;br/&gt;
5. Histogram: Frequency histogram or a height balanced histogram (the former has equi range bins while the later has the same height for all the bins)&lt;/p&gt;

&lt;p&gt;The column level statistics could also be calculated for distributions in an average block&lt;/p&gt;

&lt;p&gt;Language Elements:&lt;br/&gt;
ANALYZE TABLE &amp;lt;t&amp;gt; PARTITION(&amp;lt;partitionspec&amp;gt;) COMPUTE STATISTICS - this computes the partition level statistics&lt;br/&gt;
ANALYZE TABLE &amp;lt;t&amp;gt; PARTITION(&amp;lt;partitionspec&amp;gt;) COMPUTE STATISTICS FOR ALL COLUMNS SIZE n - this computes the column level statistics for all columns with n being the number of bins in the historgram&lt;br/&gt;
ANALYZE TABLE &amp;lt;t&amp;gt; PARTITION(&amp;lt;partitionspec&amp;gt;) COMPUTE STATISTICS FOR COLUMNS SIZE m c1 SIZE n1, c2 SIZE n2, c3 - this computes the column level statistics for columns c1 (using n1 bins for the histogram), c2(using n2 bins) and c3 (using the defaut m bins)&lt;/p&gt;

&lt;p&gt;We can later extend these so that these commands can work on samples and be able to extrapolate the results to the entire data set. For that we could use the ESTIMATE STATISTICS SAMPLE n ROWS or ESTIMATE STATISTICS SAMPLE n%&lt;/p&gt;

&lt;p&gt;e.g.&lt;/p&gt;

&lt;p&gt;ANALYZE TABLE &amp;lt;t&amp;gt; PARTITION(&amp;lt;partitionspec&amp;gt;) ESTIMATE STATISTICS 10%&lt;/p&gt;

&lt;p&gt;More details on the actual implementation to follow...&lt;/p&gt;</comment>
                            <comment id="12641947" author="prasadc" created="Wed, 22 Oct 2008 19:10:49 +0000"  >&lt;p&gt;some comments and questions&lt;/p&gt;

&lt;p&gt;1- For each partition (or table for non-partitioned tables), we should store number of files as well (so we can optimize on number of mappers)&lt;/p&gt;

&lt;p&gt;2- We should make the number of bins optional and use default. We might need some trial and error to figure out the optional number depending on number of distinct values/rowcount.&lt;/p&gt;

&lt;p&gt;3- how do you do distinct values for floats? by rounding them or not store at all?&lt;/p&gt;

&lt;p&gt;4- for string we could store stats for some prefix of the string?&lt;/p&gt;

&lt;p&gt;5- in histograms, we should store number distinct values as well in the bucket.&lt;/p&gt;

&lt;p&gt;6- can we store correlation between two columns?  it would help figuring out selectivity more accurately.&lt;/p&gt;
</comment>
                            <comment id="12642266" author="athusoo" created="Thu, 23 Oct 2008 20:30:15 +0000"  >&lt;p&gt;all good points... comments are as follows:&lt;/p&gt;

&lt;p&gt;for 1. yes we can store this relatively easily - will add it.&lt;br/&gt;
for 2. the number of bins is optional and not mandatory. We can store the system default as we do for the other variables in hive-conf.xml&lt;br/&gt;
for 3. I am just planning to store the distinct values - no rounding or not storing them at all. Don&apos;t want to overload the semantics of this. Not sure how useful rounding is given that&lt;br/&gt;
for 4. there are a number of other useful stats about strings, clearly prefixes are useful for like &apos;xyz%&apos; kind of operations. We can perhaps add these later considering that we do not even have the base level stats. We can discuss this more to see what makes sense for like and regex kind of predicates.&lt;br/&gt;
for 5. possible... though if we have sufficient number of bins the utility of this stat decreases. But will evaluate this nonetheless.&lt;br/&gt;
for 6. implementable though computationally prohibitive and it is not very clear as to how much benefit this would give - clearly if most of the columns are weekly correlated (independent) then this is not of much use and many times that is quite true. Again this is more advanced stuff. Probably better in a follow on after the base level stats are working...&lt;/p&gt;

&lt;p&gt;Will also add to this list the avg size per column that you were mentioning yesterday.&lt;/p&gt;

&lt;p&gt;So the new list is:&lt;/p&gt;

&lt;p&gt;Table stats:&lt;br/&gt;
1. # rows&lt;br/&gt;
2. size of partition&lt;br/&gt;
3. Avg size of a row&lt;br/&gt;
4. # blocks&lt;br/&gt;
5. # files&lt;/p&gt;

&lt;p&gt;Columns stats:&lt;br/&gt;
1. # distinct values&lt;br/&gt;
2. # null values&lt;br/&gt;
3. min 3 values&lt;br/&gt;
4. max 3 values&lt;br/&gt;
5. histogram: frequency and height balanced.&lt;br/&gt;
6. avg size of column&lt;/p&gt;</comment>
                            <comment id="12896635" author="nzhang" created="Mon, 9 Aug 2010 17:36:37 +0000"  >&lt;p&gt;Ahmed is almost ready to submit the patch for one of the dependent JIRA (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1361&quot; title=&quot;table/partition level statistics&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1361&quot;&gt;&lt;del&gt;HIVE-1361&lt;/del&gt;&lt;/a&gt;). He also put up a design doc on &lt;a href=&quot;http://wiki.apache.org/hadoop/Hive/StatsDev&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Hive/StatsDev&lt;/a&gt;. Any comments/suggestions are welcome (please comment on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1361&quot; title=&quot;table/partition level statistics&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1361&quot;&gt;&lt;del&gt;HIVE-1361&lt;/del&gt;&lt;/a&gt; for table/partition level stats). &lt;/p&gt;</comment>
                            <comment id="12910358" author="nzhang" created="Thu, 16 Sep 2010 22:22:12 +0000"  >&lt;p&gt;Patches for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1361&quot; title=&quot;table/partition level statistics&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1361&quot;&gt;&lt;del&gt;HIVE-1361&lt;/del&gt;&lt;/a&gt; are ready for review. Comments are welcome!&lt;/p&gt;</comment>
                            <comment id="13687777" author="mantonov" created="Wed, 19 Jun 2013 08:40:36 +0000"  >&lt;p&gt;The last comment is almost 3 years old, may be it&apos;s good to clarify the status of the ticket here?&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                            <outwardlinks description="incorporates">
                                        <issuelink>
            <issuekey id="12465175">HIVE-1361</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12465176">HIVE-1362</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12525237">HIVE-2472</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12497405">HIVE-1940</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12555278">HIVE-3027</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12497287">HIVE-1938</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12628388">HIVE-3917</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                            <subtask id="12465175">HIVE-1361</subtask>
                            <subtask id="12465176">HIVE-1362</subtask>
                            <subtask id="12474333">HIVE-1648</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 22 Oct 2008 19:10:49 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42917</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 31 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i00x7b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3311</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-47] [Hive] CLI not supporting multiline queries from an input file</title>
                <link>https://issues.apache.org/jira/browse/HIVE-47</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;calling &quot;hive -f filename&quot; allows to pass HQL queries from a file.&lt;br/&gt;
but the queries can&apos;t be on multiple lines as we would expect by reading Hive documentation.&lt;/p&gt;

&lt;p&gt;a proposed fix is to modify CliDriver.processReader.&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12407048">HIVE-47</key>
            <summary>[Hive] CLI not supporting multiline queries from an input file</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.svg">Trivial</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="athusoo">Ashish Thusoo</assignee>
                                    <reporter username="mimizone">Jeremy Huylebroeck</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Oct 2008 00:31:18 +0000</created>
                <updated>Sat, 17 Dec 2011 00:08:27 +0000</updated>
                            <resolved>Wed, 10 Dec 2008 22:58:26 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Clients</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="12642023" author="mimizone" created="Thu, 23 Oct 2008 00:43:38 +0000"  >&lt;p&gt;uploaded patch against 0.17 hive code&lt;br/&gt;
(hive code available at &lt;a href=&quot;http://mirror.facebook.com/facebook/hive/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://mirror.facebook.com/facebook/hive/&lt;/a&gt;)&lt;/p&gt;</comment>
                            <comment id="12642030" author="mimizone" created="Thu, 23 Oct 2008 01:06:35 +0000"  >&lt;p&gt;uploaded a patch for CliDriver for hadoop trunk&lt;/p&gt;</comment>
                            <comment id="12642207" author="athusoo" created="Thu, 23 Oct 2008 17:26:28 +0000"  >&lt;p&gt;Hi Jeremy,&lt;/p&gt;

&lt;p&gt;Thanks a bunch for the patch. &lt;/p&gt;

&lt;p&gt;One comment though - it would be great if the patch is able to pass all the empty lines around to the parser for debuggability purposes. Otherwise, it will be impossible for the users to figure out where the error happened in a statement. &lt;/p&gt;

&lt;p&gt;you bring up a good point about processLine calling the trim function. We should move that to the checks in processCmd and not trim the line in processLine and we should pass the command as is to qp.run(cmd) call in processCmd.&lt;/p&gt;

&lt;p&gt;What do think?&lt;/p&gt;</comment>
                            <comment id="12642211" author="prasadc" created="Thu, 23 Oct 2008 17:39:21 +0000"  >&lt;p&gt;The patch looks good except for trimming that Ashish pointed out. there is some code in CliDriver.main() which does similar thing but little differently. Could you make the two uniform so that multi-line query behaves the same both from a file and from command line?&lt;/p&gt;</comment>
                            <comment id="12642212" author="prasadc" created="Thu, 23 Oct 2008 17:47:36 +0000"  >&lt;p&gt;also, mysql client assume that a newline is a word break. so &apos;select\n* from tabA;&apos; is a valid query in mysql but not in the code above or in main() function. I think we do want to make it as similar to mysql client as possible.&lt;/p&gt;</comment>
                            <comment id="12644447" author="mimizone" created="Fri, 31 Oct 2008 22:32:57 +0000"  >&lt;p&gt;proposed new patch for 0.17:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;supports comments properly (lines started with &quot;--&quot;)&lt;/li&gt;
	&lt;li&gt;keeps empty lines etc... so error position is closer to reality, easier to debug.&lt;/li&gt;
	&lt;li&gt;shows the number of line offset in the INFO log to ease debugging of the error position (not very pretty implementation but it helps)&lt;/li&gt;
	&lt;li&gt;some cleanup&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12644449" author="mimizone" created="Fri, 31 Oct 2008 22:36:43 +0000"  >&lt;p&gt;Prasad, I don&apos;t observe the issue with something like &apos;select\n* tabl;&apos;&lt;br/&gt;
I do all the time this in my hql files without problems.&lt;br/&gt;
do you have an actual example?&lt;/p&gt;</comment>
                            <comment id="12644451" author="prasadc" created="Fri, 31 Oct 2008 22:40:59 +0000"  >&lt;p&gt;oh the problem i mentioned only if you are using interactive shell. so first line enter select and on second prompt enter a.* from tabA a;&lt;/p&gt;</comment>
                            <comment id="12644452" author="mimizone" created="Fri, 31 Oct 2008 22:52:00 +0000"  >&lt;p&gt;your example is actually working for me in 0.17.3, at least with the patched version.&lt;br/&gt;
I remember observing something similar when using 0.19, but only for some time. But I was changing the code and playing with multiple combinaisons of hive/hadoop versions at the time. can you try the new patch?&lt;/p&gt;</comment>
                            <comment id="12644818" author="prasadc" created="Mon, 3 Nov 2008 21:50:09 +0000"  >&lt;p&gt;Hi Jeremy,&lt;/p&gt;

&lt;p&gt;Couple of issues&lt;br/&gt;
1) Should line 166 be in inside the if (m.matches()) condition?&lt;br/&gt;
2) line 185: i think if loop gets executed even if the last line doesn&apos;t end with a &apos;;&apos;&lt;br/&gt;
3) I think processLine should be used instead of processCmd. Otherwise the code can&apos;t handle cmds like &apos;select a.* from tabA a; select \nb.* from tabB b&apos;&lt;br/&gt;
4) also, could you update the patch with new code available for 0.17. There have been some changes that make the commands case insensitive.&lt;/p&gt;

&lt;p&gt;It will be good if you can make similar changes to code that handles interactive commands (in main()). If not we can do that in a separate JIRA as well. &lt;/p&gt;</comment>
                            <comment id="12644820" author="athusoo" created="Mon, 3 Nov 2008 21:55:06 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;Jeremy, the patch looks good to me. Thanks for the contribution.&lt;/p&gt;

&lt;p&gt;One thing though.&lt;/p&gt;

&lt;p&gt;1. The latest patch is generated from the directory that contains CliDriver.java so I think the hadoop QA will fail as it expects the patch to be generated from the root of the source tree.&lt;/p&gt;

&lt;p&gt;Prasad,&lt;/p&gt;

&lt;p&gt;is your issue resolved?&lt;/p&gt;</comment>
                            <comment id="12644826" author="prasadc" created="Mon, 3 Nov 2008 22:11:11 +0000"  >&lt;p&gt;yeah, my issue is resolved but see the comments above.&lt;/p&gt;</comment>
                            <comment id="12654814" author="athusoo" created="Tue, 9 Dec 2008 15:04:45 +0000"  >&lt;p&gt;Simplified the fix for this in order to address prasad&apos;s concerns.&lt;/p&gt;

&lt;p&gt;I have tested this to a limited extent inside fb. However, without getting the test harness in place for cli tests, I am not able to add unit tests for this at this time. (I think we should get the test harness for the cli in place as soon as possible - I tried to do it in QTestUtil but the changes there are more involved than what I would have liked to put in this transaction)&lt;/p&gt;

&lt;p&gt;Incidentally, the fix here mimics what QTestUtils.java does for calling the internal cli driver for its test (The issue is that there is no test harness for bin/hive scripts).&lt;/p&gt;

&lt;p&gt;Please review and provide any feedback.&lt;/p&gt;</comment>
                            <comment id="12654858" author="jsensarma" created="Tue, 9 Dec 2008 17:26:17 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="12655045" author="zshao" created="Wed, 10 Dec 2008 00:45:33 +0000"  >&lt;p&gt;The patch didn&apos;t pass unit tests.&lt;/p&gt;

&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 08/12/09 16:42:57 ERROR ql.Driver: FAILED: Parse Error: line 0:-1 cannot recognize input &apos;&amp;lt;EOF&amp;gt;&apos;&lt;/p&gt;

&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; org.apache.hadoop.hive.ql.parse.ParseException: line 0:-1 cannot recognize input &apos;&amp;lt;EOF&amp;gt;&apos;&lt;/p&gt;

&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:258)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.ql.Driver.run(Driver.java:163)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:174)&lt;/p&gt;</comment>
                            <comment id="12655051" author="athusoo" created="Wed, 10 Dec 2008 01:01:34 +0000"  >&lt;p&gt;I am checking into this.&lt;/p&gt;</comment>
                            <comment id="12655053" author="athusoo" created="Wed, 10 Dec 2008 01:03:12 +0000"  >&lt;p&gt;Just want to confirm that you are not seeing this in the negative tests. The negative tests do generate this on the ant output though they finally report that the tests passed. Which particular test is failing?&lt;/p&gt;</comment>
                            <comment id="12655328" author="athusoo" created="Wed, 10 Dec 2008 19:25:40 +0000"  >&lt;p&gt;Resubmitting after fixing the test run and capturing new logs.&lt;/p&gt;</comment>
                            <comment id="12655391" author="jsensarma" created="Wed, 10 Dec 2008 22:36:26 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="12655400" author="zshao" created="Wed, 10 Dec 2008 22:57:57 +0000"  >&lt;p&gt;Committed revision 725472.&lt;/p&gt;</comment>
                            <comment id="12655401" author="zshao" created="Wed, 10 Dec 2008 22:58:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-47&quot; title=&quot;[Hive] CLI not supporting multiline queries from an input file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-47&quot;&gt;&lt;del&gt;HIVE-47&lt;/del&gt;&lt;/a&gt;. CLI to support multiline queries from an input file.&lt;br/&gt;
(Ashish through zshao)&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12392689" name="patch-0.17.txt" size="2569" author="mimizone" created="Thu, 23 Oct 2008 00:43:38 +0000"/>
                            <attachment id="12395650" name="patch-47_4.txt" size="2064" author="athusoo" created="Tue, 9 Dec 2008 15:04:45 +0000"/>
                            <attachment id="12395753" name="patch-47_5.txt" size="4269" author="athusoo" created="Wed, 10 Dec 2008 19:25:40 +0000"/>
                            <attachment id="12392691" name="patch-trunk.txt" size="1759" author="mimizone" created="Thu, 23 Oct 2008 01:06:35 +0000"/>
                            <attachment id="12393179" name="patch2-0.17.txt" size="4606" author="mimizone" created="Fri, 31 Oct 2008 22:32:57 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 23 Oct 2008 17:26:28 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73816</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 7 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0iv2f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>108127</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-57] [hive] bad error reporting if a FROM is missing in the nested query in case of JOIN</title>
                <link>https://issues.apache.org/jira/browse/HIVE-57</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;EXPLAIN FROM &lt;br/&gt;
(SELECT DISTINCT C_CXT.USERID FROM C_CXT) A &lt;br/&gt;
JOIN &lt;br/&gt;
(SELECT FCT_INVITES.*  WHERE FCT_INVITES.INVITER_ID &amp;lt;&amp;gt; 0 AND FCT_INVITES.DS = &apos;2008-10-01&apos;) B &lt;br/&gt;
ON (A.USERID = B.INVITER_ID)  SELECT B.*&lt;/p&gt;

&lt;p&gt;The above is missing FROM in the 2nd subquery (B), but the parser returns an error in JOIN&lt;/p&gt;</description>
                <environment></environment>
        <key id="12407210">HIVE-57</key>
            <summary>[hive] bad error reporting if a FROM is missing in the nested query in case of JOIN</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="namit">Namit Jain</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Oct 2008 23:43:32 +0000</created>
                <updated>Mon, 1 Dec 2008 17:18:11 +0000</updated>
                                                                            <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42907</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 14 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0iv3r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>108133</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>
