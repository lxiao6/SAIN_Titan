<!--
RSS generated by JIRA (7.6.3#76005-sha1:8a4e38d34af948780dbf52044e7aafb13a7cae58) at Tue Jan 22 15:21:21 UTC 2019

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<!-- If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
    <channel>
        <title>ASF JIRA</title>
        <link>https://issues.apache.org/jira/issues/?jql=project+%3D+HIVE+AND+created+%3E%3D+2012-7-18+AND+created+%3C%3D+2012-7-25+ORDER+BY+key+ASC</link>
        <description>An XML representation of a search request</description>
                <language>en-uk</language>
                        <issue start="0" end="30" total="30"/>
                <build-info>
            <version>7.6.3</version>
            <build-number>76005</build-number>
            <build-date>09-01-2018</build-date>
        </build-info>

<item>
            <title>[HIVE-3266] Hive queries over thrift binary fields fail</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3266</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12599204">HIVE-3266</key>
            <summary>Hive queries over thrift binary fields fail</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="traviscrawford">Travis Crawford</assignee>
                                    <reporter username="traviscrawford">Travis Crawford</reporter>
                        <labels>
                    </labels>
                <created>Wed, 18 Jul 2012 00:51:09 +0000</created>
                <updated>Wed, 18 Jul 2012 15:13:37 +0000</updated>
                            <resolved>Wed, 18 Jul 2012 15:13:37 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13416782" author="traviscrawford" created="Wed, 18 Jul 2012 00:54:57 +0000"  >&lt;p&gt;The following exception is thrown on trunk when trying to read a &quot;binary&quot; field through ThriftDeserializer:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2012-07-18 00:45:49,532 ERROR CliDriver (SessionState.java:printError(400)) - Failed with exception java.io.IOException:java.lang.ClassCastExceptio
n: [B cannot be &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt; to org.apache.hadoop.hive.serde2.lazy.ByteArrayRef
java.io.IOException: java.lang.ClassCastException: [B cannot be &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt; to org.apache.hadoop.hive.serde2.lazy.ByteArrayRef
        at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:173)
        at org.apache.hadoop.hive.ql.Driver.getResults(Driver.java:1375)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:270)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:412)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:750)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:613)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:186)
Caused by: java.lang.ClassCastException: [B cannot be &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt; to org.apache.hadoop.hive.serde2.lazy.ByteArrayRef
        at org.apache.hadoop.hive.serde2.objectinspector.primitive.JavaBinaryObjectInspector.getPrimitiveWritableObject(JavaBinaryObjectInspector.java:48)
        at org.apache.hadoop.hive.serde2.SerDeUtils.buildJSONString(SerDeUtils.java:276)
        at org.apache.hadoop.hive.serde2.SerDeUtils.buildJSONString(SerDeUtils.java:349)
        at org.apache.hadoop.hive.serde2.SerDeUtils.getJSONString(SerDeUtils.java:219)
        at org.apache.hadoop.hive.serde2.DelimitedJSONSerDe.serializeField(DelimitedJSONSerDe.java:59)
        at org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe.serialize(LazySimpleSerDe.java:365)
        at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:163)
        ... 11 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here we see the object is already a byte[], but we&apos;re trying to use it as a ByteArrayRef. A small patch handles this case.&lt;/p&gt;</comment>
                            <comment id="13417153" author="traviscrawford" created="Wed, 18 Jul 2012 15:13:37 +0000"  >&lt;p&gt;Marking as a duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3246&quot; title=&quot;java primitive type for binary datatype should be byte[]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3246&quot;&gt;&lt;del&gt;HIVE-3246&lt;/del&gt;&lt;/a&gt;. I patched that in and no longer experienced the issue.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12598095">HIVE-3246</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12536933" name="HIVE-3266.1.patch" size="977" author="traviscrawford" created="Wed, 18 Jul 2012 00:56:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>259153</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 27 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ln5b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>124400</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3267] escaped columns in cluster/distribute/order/sort by are not working</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3267</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The following query:&lt;/p&gt;

&lt;p&gt;select `key`, value from src cluster by `key`, value;&lt;/p&gt;


&lt;p&gt;fails&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599219">HIVE-3267</key>
            <summary>escaped columns in cluster/distribute/order/sort by are not working</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="namit">Namit Jain</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Wed, 18 Jul 2012 05:24:46 +0000</created>
                <updated>Thu, 10 Jan 2013 19:54:04 +0000</updated>
                            <resolved>Fri, 20 Jul 2012 01:05:36 +0000</resolved>
                                    <version>0.10.0</version>
                                    <fixVersion>0.10.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13416917" author="namit" created="Wed, 18 Jul 2012 07:14:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.facebook.net/D4203&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4203&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13418563" author="kevinwilfong" created="Thu, 19 Jul 2012 18:40:18 +0000"  >&lt;p&gt;+1 Running tests&lt;/p&gt;</comment>
                            <comment id="13418851" author="kevinwilfong" created="Fri, 20 Jul 2012 01:05:36 +0000"  >&lt;p&gt;Committed, thanks Namit.&lt;/p&gt;</comment>
                            <comment id="13418990" author="hudson" created="Fri, 20 Jul 2012 07:41:19 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1554 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1554/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1554/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3267&quot; title=&quot;escaped columns in cluster/distribute/order/sort by are not working&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3267&quot;&gt;&lt;del&gt;HIVE-3267&lt;/del&gt;&lt;/a&gt;. escaped columns in cluster/distribute/order/sort by are not working. (njain via kevinwilfong) (Revision 1363610)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
kevinwilfong : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1363610&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1363610&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/RowResolver.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/escape_clusterby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/escape_distributeby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/escape_orderby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/escape_sortby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/escape_clusterby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/escape_distributeby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/escape_orderby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/escape_sortby1.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13548086" author="hudson" created="Wed, 9 Jan 2013 10:24:20 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #54 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3267&quot; title=&quot;escaped columns in cluster/distribute/order/sort by are not working&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3267&quot;&gt;&lt;del&gt;HIVE-3267&lt;/del&gt;&lt;/a&gt;. escaped columns in cluster/distribute/order/sort by are not working. (njain via kevinwilfong) (Revision 1363610)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
kevinwilfong : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1363610&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1363610&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/RowResolver.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/escape_clusterby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/escape_distributeby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/escape_orderby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/escape_sortby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/escape_clusterby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/escape_distributeby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/escape_orderby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/escape_sortby1.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13550278" author="ashutoshc" created="Thu, 10 Jan 2013 19:54:04 +0000"  >&lt;p&gt;This issue is fixed and released as part of 0.10.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 19 Jul 2012 18:40:18 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>259154</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 2 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ln5j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>124401</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3268] expressions in cluster by are not working</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3268</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The following query fails:&lt;/p&gt;

&lt;p&gt;select key+key, value from src cluster by key+key, value;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599228">HIVE-3268</key>
            <summary>expressions in cluster by are not working</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="namit">Namit Jain</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Wed, 18 Jul 2012 08:11:23 +0000</created>
                <updated>Thu, 22 Aug 2013 20:40:10 +0000</updated>
                            <resolved>Thu, 16 Aug 2012 16:54:53 +0000</resolved>
                                                    <fixVersion>0.10.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13419075" author="namit" created="Fri, 20 Jul 2012 12:02:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.facebook.net/D4269&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4269&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13420239" author="namit" created="Sun, 22 Jul 2012 16:58:30 +0000"  >&lt;p&gt;Currently, we get a random error.&lt;br/&gt;
It would be much nicer to throw a good semantic error instead.&lt;/p&gt;</comment>
                            <comment id="13421260" author="namit" created="Tue, 24 Jul 2012 08:17:08 +0000"  >&lt;p&gt;Some tests failed - debugging&lt;/p&gt;</comment>
                            <comment id="13426719" author="namit" created="Wed, 1 Aug 2012 16:11:16 +0000"  >&lt;p&gt;refresh&lt;/p&gt;</comment>
                            <comment id="13429267" author="kevinwilfong" created="Mon, 6 Aug 2012 17:06:02 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13429389" author="cwsteinbach" created="Mon, 6 Aug 2012 20:15:40 +0000"  >&lt;p&gt;Please attach the latest version of this patch to the ticket.&lt;/p&gt;</comment>
                            <comment id="13429413" author="cwsteinbach" created="Mon, 6 Aug 2012 20:48:28 +0000"  >&lt;p&gt;@Namit: I added comments on phabricator. Thanks.&lt;/p&gt;</comment>
                            <comment id="13429955" author="namit" created="Tue, 7 Aug 2012 06:03:19 +0000"  >&lt;p&gt;comments addressed, latest patch attached&lt;/p&gt;</comment>
                            <comment id="13434409" author="kevinwilfong" created="Tue, 14 Aug 2012 19:23:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cwsteinbach&quot; class=&quot;user-hover&quot; rel=&quot;cwsteinbach&quot;&gt;Carl Steinbach&lt;/a&gt; It&apos;s been a week without further comments.&lt;/p&gt;

&lt;p&gt;I remain +1 on it.&lt;/p&gt;</comment>
                            <comment id="13436094" author="kevinwilfong" created="Thu, 16 Aug 2012 16:54:53 +0000"  >&lt;p&gt;Committed, thanks Namit.&lt;/p&gt;</comment>
                            <comment id="13436365" author="hudson" created="Thu, 16 Aug 2012 22:22:29 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1611 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1611/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1611/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3268&quot; title=&quot;expressions in cluster by are not working&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3268&quot;&gt;&lt;del&gt;HIVE-3268&lt;/del&gt;&lt;/a&gt;. expressions in cluster by are not working. (njain via kevinwilfong) (Revision 1373918)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
kevinwilfong : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1373918&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1373918&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/QBParseInfo.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_clusterby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_distributeby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_distributeby_sortby_1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_orderby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_sortby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_clusterby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_distributeby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_distributeby_sortby_1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_orderby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_sortby1.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13475835" author="hudson" created="Sun, 14 Oct 2012 13:19:17 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1737 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1737/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1737/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3573&quot; title=&quot;Revert HIVE-3268&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3573&quot;&gt;&lt;del&gt;HIVE-3573&lt;/del&gt;&lt;/a&gt;. Revert &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3268&quot; title=&quot;expressions in cluster by are not working&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3268&quot;&gt;&lt;del&gt;HIVE-3268&lt;/del&gt;&lt;/a&gt;. (njain via kevinwilfong) (Revision 1397994)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
kevinwilfong : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1397994&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1397994&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/QBParseInfo.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_clusterby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_distributeby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_distributeby_sortby_1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_orderby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_sortby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_clusterby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_distributeby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_distributeby_sortby_1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_orderby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_sortby1.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13548088" author="hudson" created="Wed, 9 Jan 2013 10:24:20 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #54 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3573&quot; title=&quot;Revert HIVE-3268&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3573&quot;&gt;&lt;del&gt;HIVE-3573&lt;/del&gt;&lt;/a&gt;. Revert &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3268&quot; title=&quot;expressions in cluster by are not working&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3268&quot;&gt;&lt;del&gt;HIVE-3268&lt;/del&gt;&lt;/a&gt;. (njain via kevinwilfong) (Revision 1397994)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3268&quot; title=&quot;expressions in cluster by are not working&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3268&quot;&gt;&lt;del&gt;HIVE-3268&lt;/del&gt;&lt;/a&gt;. expressions in cluster by are not working. (njain via kevinwilfong) (Revision 1373918)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
kevinwilfong : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1397994&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1397994&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/QBParseInfo.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_clusterby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_distributeby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_distributeby_sortby_1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_orderby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_sortby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_clusterby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_distributeby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_distributeby_sortby_1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_orderby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_sortby1.q.out&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;kevinwilfong : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1373918&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1373918&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/QBParseInfo.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_clusterby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_distributeby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_distributeby_sortby_1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_orderby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/expr_sortby1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_clusterby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_distributeby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_distributeby_sortby_1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_orderby1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/expr_sortby1.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13550175" author="ashutoshc" created="Thu, 10 Jan 2013 19:53:40 +0000"  >&lt;p&gt;This issue is fixed and released as part of 0.10.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                            <outwardlinks description="breaks">
                                        <issuelink>
            <issuekey id="12611568">HIVE-3572</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310051">
                    <name>Supercedes</name>
                                                                <inwardlinks description="is superceded by">
                                        <issuelink>
            <issuekey id="12611608">HIVE-3573</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12538128" name="hive.3268.1.patch" size="18398" author="namit" created="Fri, 27 Jul 2012 05:22:54 +0000"/>
                            <attachment id="12539425" name="hive.3268.2.patch" size="22900" author="namit" created="Tue, 7 Aug 2012 06:03:03 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 6 Aug 2012 17:06:02 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>248031</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 2 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i09l0n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>53838</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3269] selectlist needs to be superset of the cluster list</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3269</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The query:&lt;/p&gt;

&lt;p&gt;create table T (key1 string, key2 string, key3 string);&lt;br/&gt;
select key1, key2 from T cluster by key1, key2, key3;&lt;/p&gt;

&lt;p&gt;fails.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599240">HIVE-3269</key>
            <summary>selectlist needs to be superset of the cluster list</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Wed, 18 Jul 2012 09:42:47 +0000</created>
                <updated>Wed, 18 Jul 2012 10:31:20 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13416971" author="navis" created="Wed, 18 Jul 2012 10:03:53 +0000"  >&lt;p&gt;I failed to solve similar issue(&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2954&quot; title=&quot;The statement fails when a column part of an ORDER BY is not specified in the SELECT.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2954&quot;&gt;HIVE-2954&lt;/a&gt;). There should be a entity something like BlockAliasResolver, which handles various column aliases in SELECT/GROUPBY/ORDERBY/CLUSTERBYs.&lt;/p&gt;</comment>
                            <comment id="13416978" author="namit" created="Wed, 18 Jul 2012 10:25:35 +0000"  >&lt;p&gt;Wont it be good to take a similar approach like groupby ?&lt;br/&gt;
I mean, have a dummy select first, and then cluster by/order by can resolve.&lt;/p&gt;

&lt;p&gt;But then, it would be difficult to support column aliases.&lt;/p&gt;</comment>
                            <comment id="13416979" author="navis" created="Wed, 18 Jul 2012 10:31:20 +0000"  >&lt;p&gt;Yes, adding dummy column was not hard. But alias problem was quite difficult.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12551070">HIVE-2954</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 18 Jul 2012 10:03:53 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>259155</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 27 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ln5r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>124402</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-3270] SMBJoin should be applied atomically </title>
                <link>https://issues.apache.org/jira/browse/HIVE-3270</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;For using smbjoin, mapjoin hint(/&lt;b&gt;+MAPJOIN(..)&lt;/b&gt;/) + bucket mapjoin configuration(hive.optimize.bucketmapjoin) also should be preceded.&lt;/p&gt;

&lt;p&gt;But when BucketMapJoinOptimizer or SortedMergeBucketMapJoinOptimizer fails to convert mapjoin to smbjoin by some reason, it will be executed as a (bucket) mapjoin, which possibly cause OOM in map task.&lt;/p&gt;

&lt;p&gt;I think there should be a hint for SMBJoin, which tries to convert common-join to smbjoin and when it fails, simply fallbacks to common-join.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599242">HIVE-3270</key>
            <summary>SMBJoin should be applied atomically </summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="navis">Navis</reporter>
                        <labels>
                    </labels>
                <created>Wed, 18 Jul 2012 09:57:55 +0000</created>
                <updated>Wed, 22 Aug 2012 23:25:09 +0000</updated>
                            <resolved>Wed, 22 Aug 2012 23:25:09 +0000</resolved>
                                                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13439941" author="navis" created="Wed, 22 Aug 2012 23:25:09 +0000"  >&lt;p&gt;This is duplicated by &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3403&quot; title=&quot;user should not specify mapjoin to perform sort-merge bucketed join&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3403&quot;&gt;&lt;del&gt;HIVE-3403&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12599816">HIVE-3289</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>259156</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 22 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ln5z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>124403</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3271] Privilege can be granted by any user(not owner) to any user(even to the same user)</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3271</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;I have created two users user &apos;unni&apos; and user &apos;sachin&apos;. user unni created a table &apos;test3&apos; so that user sachin cannot view that table. But user sachin is able to grant all permission to the table test3.&lt;br/&gt;
I have set &lt;br/&gt;
1)hive.security.authorization.enabled=true(in hive-site.xml)&lt;br/&gt;
2)dfs.permissions=true(in hdfs-site.xml)&lt;br/&gt;
3)dfs.permissions.supergroup=supergroup(in hdfs-site.xml)&lt;br/&gt;
User sachin and user unni are in supergroup group.&lt;br/&gt;
The user sachin is even able to revoke all permissions from the owner of the table user unni.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599261">HIVE-3271</key>
            <summary>Privilege can be granted by any user(not owner) to any user(even to the same user)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="unnivt">Unnikrishnan V T</reporter>
                        <labels>
                    </labels>
                <created>Wed, 18 Jul 2012 12:55:17 +0000</created>
                <updated>Wed, 8 Jul 2015 23:51:18 +0000</updated>
                                            <version>0.8.1</version>
                                                    <component>Authorization</component>
                    <component>Security</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13417063" author="unnivt" created="Wed, 18 Jul 2012 13:21:08 +0000"  >&lt;p&gt;Another user who is not a supergroup member can also view the table.&lt;/p&gt;</comment>
                            <comment id="13418205" author="unnivt" created="Thu, 19 Jul 2012 10:31:11 +0000"  >&lt;p&gt;I have created two users user &apos;unni&apos; and user &apos;sachin&apos;. user unni created a table &apos;test3&apos; so that user sachin cannot view that table. But user sachin is able to grant all permission to the table test3.&lt;br/&gt;
I have set&lt;br/&gt;
1)hive.security.authorization.enabled=true(in hive-site.xml)&lt;br/&gt;
2)dfs.permissions=true(in hdfs-site.xml)&lt;br/&gt;
3)dfs.permissions.supergroup=supergroup(in hdfs-site.xml)&lt;br/&gt;
user unni is in supergroup group.&lt;br/&gt;
The user sachin is even able to revoke all permissions from the owner of the table user unni. User sachin is not a member of supergroup.&lt;/p&gt;</comment>
                            <comment id="13670610" author="mantonov" created="Thu, 30 May 2013 19:08:54 +0000"  >&lt;p&gt;Just to make sure - does that happen for you when user &quot;sachin&quot; is &lt;em&gt;not&lt;/em&gt; in supergroup, or regardless of whether he is in supergroup or not?&lt;/p&gt;</comment>
                            <comment id="13670612" author="mantonov" created="Thu, 30 May 2013 19:09:46 +0000"  >&lt;p&gt;Curious if anyone has looked into this bug and decided on it&apos;s severity? Bug is almost 1 year old.&lt;/p&gt;</comment>
                            <comment id="13671119" author="unnivt" created="Fri, 31 May 2013 03:56:20 +0000"  >&lt;p&gt;It happens regardless of whether the user is a superuser or not.&lt;/p&gt;</comment>
                            <comment id="14619604" author="saisandeep2104" created="Wed, 8 Jul 2015 23:51:18 +0000"  >&lt;p&gt;I&apos;m having the same issue. &lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12536979" name="Screenshot.png" size="57189" author="unnivt" created="Wed, 18 Jul 2012 13:00:22 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 30 May 2013 19:08:54 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>245459</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 28 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i06am7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>34651</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-3272] RetryingRawStore will perform partial transaction on retry</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3272</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;By the time the RetryingRawStore retries a command the transaction encompassing it has already been rolled back.  This means that it will perform the remainder of the raw store commands outside of a transaction, unless there is another one encapsulating it which is definitely not always the case, and then fail when it tries to commit the transaction as there is none open.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599328">HIVE-3272</key>
            <summary>RetryingRawStore will perform partial transaction on retry</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="kevinwilfong">Kevin Wilfong</reporter>
                        <labels>
                    </labels>
                <created>Wed, 18 Jul 2012 19:38:46 +0000</created>
                <updated>Thu, 27 Mar 2014 20:01:17 +0000</updated>
                            <resolved>Thu, 27 Mar 2014 18:51:19 +0000</resolved>
                                    <version>0.10.0</version>
                                    <fixVersion>0.13.0</fixVersion>
                                    <component>Metastore</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13540333" author="ashutoshc" created="Fri, 28 Dec 2012 05:50:44 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kevinwilfong&quot; class=&quot;user-hover&quot; rel=&quot;kevinwilfong&quot;&gt;Kevin Wilfong&lt;/a&gt; : I believe this is still an issue in spite of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3826&quot; title=&quot;Rollbacks and retries of drops cause org.datanucleus.exceptions.NucleusObjectNotFoundException: No such database row)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3826&quot;&gt;&lt;del&gt;HIVE-3826&lt;/del&gt;&lt;/a&gt; &lt;/p&gt;</comment>
                            <comment id="13542282" author="kevinwilfong" created="Wed, 2 Jan 2013 18:41:14 +0000"  >&lt;p&gt;Yes, this is a totally separate issue from &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3826&quot; title=&quot;Rollbacks and retries of drops cause org.datanucleus.exceptions.NucleusObjectNotFoundException: No such database row)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3826&quot;&gt;&lt;del&gt;HIVE-3826&lt;/del&gt;&lt;/a&gt;.  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3826&quot; title=&quot;Rollbacks and retries of drops cause org.datanucleus.exceptions.NucleusObjectNotFoundException: No such database row)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3826&quot;&gt;&lt;del&gt;HIVE-3826&lt;/del&gt;&lt;/a&gt; will happen even when the RetryingRawStore tries only once (never retries).&lt;/p&gt;</comment>
                            <comment id="13949785" author="szehon" created="Thu, 27 Mar 2014 18:51:19 +0000"  >&lt;p&gt;Its fixed in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4996&quot; title=&quot;unbalanced calls to openTransaction/commitTransaction&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4996&quot;&gt;&lt;del&gt;HIVE-4996&lt;/del&gt;&lt;/a&gt; as RetryingRawStore is removed.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12661631">HIVE-4996</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 28 Dec 2012 05:50:44 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>259157</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 43 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ln67:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>124404</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3273] Add avro jars into hive execution classpath</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3273</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;avro*.jar should be added to hive execution classpath&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599373">HIVE-3273</key>
            <summary>Add avro jars into hive execution classpath</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="zhenxiao">Zhenxiao Luo</assignee>
                                    <reporter username="zhenxiao">Zhenxiao Luo</reporter>
                        <labels>
                    </labels>
                <created>Wed, 18 Jul 2012 23:07:42 +0000</created>
                <updated>Thu, 10 Jan 2013 19:54:13 +0000</updated>
                            <resolved>Tue, 31 Jul 2012 19:15:58 +0000</resolved>
                                                    <fixVersion>0.10.0</fixVersion>
                                    <component>Build Infrastructure</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13417805" author="zhenxiao" created="Wed, 18 Jul 2012 23:11:30 +0000"  >&lt;p&gt;Since Hadoop classpath is not setting correctly in build-common.xml &quot;test&quot; target, even currently we did not add avro jars into hive execution classpath, it is still running OK.&lt;/p&gt;

&lt;p&gt;While, we may get class def not found error, if not putting avro jars into the hive mapreduce job execution classpath:&lt;/p&gt;

&lt;p&gt;Caused by: java.lang.ClassNotFoundException: org.apache.avro.io.DatumReader&lt;/p&gt;</comment>
                            <comment id="13417807" author="zhenxiao" created="Wed, 18 Jul 2012 23:15:50 +0000"  >&lt;p&gt;review request submitted:&lt;br/&gt;
&lt;a href=&quot;https://reviews.facebook.net/D4209&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4209&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13418210" author="appodictic" created="Thu, 19 Jul 2012 10:46:56 +0000"  >&lt;p&gt;I can see this happening but when exactly do we get this error?&lt;/p&gt;</comment>
                            <comment id="13418478" author="zhenxiao" created="Thu, 19 Jul 2012 17:31:59 +0000"  >&lt;p&gt;@Edward:&lt;/p&gt;

&lt;p&gt;I found this error when I am backporting &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-895&quot; title=&quot;Add SerDe for Avro serialized data&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-895&quot;&gt;&lt;del&gt;HIVE-895&lt;/del&gt;&lt;/a&gt; to an old version of Hive(CDH3), where I did not put avro jars into hive execution classpath, and kept having the following exception:&lt;/p&gt;

&lt;p&gt;java.lang.ClassNotFoundException: org.apache.avro.io.DatumReader&lt;/p&gt;

&lt;p&gt;We do not have this error on current trunk, since Hadoop classpath is not setting correctly in build-common.xml &quot;test&quot; target. I think this should be fixed in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3274&quot; title=&quot;Fix the Hadoop classpath in build-common.xml &amp;quot;test&amp;quot; target&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3274&quot;&gt;HIVE-3274&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I think fixing this would emphasis that it is not enough to put avro jars in the hive client classpath. Avro jars should be put in hive execution(the mapreduce job) classpath. This would prevent future bugs.&lt;/p&gt;

&lt;p&gt;What do you think about it?&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Zhenxiao&lt;/p&gt;</comment>
                            <comment id="13425365" author="cwsteinbach" created="Mon, 30 Jul 2012 23:19:21 +0000"  >&lt;p&gt;+1. Will commit if tests pass.&lt;/p&gt;</comment>
                            <comment id="13426038" author="cwsteinbach" created="Tue, 31 Jul 2012 19:15:58 +0000"  >&lt;p&gt;Committed to trunk. Thanks Zhenxiao!&lt;/p&gt;</comment>
                            <comment id="13426321" author="hudson" created="Wed, 1 Aug 2012 04:19:08 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1581 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1581/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1581/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3273&quot; title=&quot;Add avro jars into hive execution classpath&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3273&quot;&gt;&lt;del&gt;HIVE-3273&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Add avro jars into hive execution classpath&lt;br/&gt;
(Zhenxiao Luo via Carl Steinbach)&lt;/p&gt;

&lt;p&gt;Summary:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3273&quot; title=&quot;Add avro jars into hive execution classpath&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3273&quot;&gt;&lt;del&gt;HIVE-3273&lt;/del&gt;&lt;/a&gt;: Add avro jars into hive execution classpath&lt;/p&gt;

&lt;p&gt;avro*.jar should be added to hive execution classpath&lt;/p&gt;

&lt;p&gt;Test Plan: EMPTY&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA, cwsteinbach&lt;/p&gt;

&lt;p&gt;Reviewed By: cwsteinbach&lt;/p&gt;

&lt;p&gt;Differential Revision: &lt;a href=&quot;https://reviews.facebook.net/D4209&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4209&lt;/a&gt; (Revision 1367708)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
cws : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1367708&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1367708&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/build.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13548119" author="hudson" created="Wed, 9 Jan 2013 10:24:28 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #54 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3273&quot; title=&quot;Add avro jars into hive execution classpath&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3273&quot;&gt;&lt;del&gt;HIVE-3273&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Add avro jars into hive execution classpath&lt;br/&gt;
(Zhenxiao Luo via Carl Steinbach)&lt;/p&gt;

&lt;p&gt;Summary:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3273&quot; title=&quot;Add avro jars into hive execution classpath&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3273&quot;&gt;&lt;del&gt;HIVE-3273&lt;/del&gt;&lt;/a&gt;: Add avro jars into hive execution classpath&lt;/p&gt;

&lt;p&gt;avro*.jar should be added to hive execution classpath&lt;/p&gt;

&lt;p&gt;Test Plan: EMPTY&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA, cwsteinbach&lt;/p&gt;

&lt;p&gt;Reviewed By: cwsteinbach&lt;/p&gt;

&lt;p&gt;Differential Revision: &lt;a href=&quot;https://reviews.facebook.net/D4209&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4209&lt;/a&gt; (Revision 1367708)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
cws : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1367708&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1367708&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/build.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13550316" author="ashutoshc" created="Thu, 10 Jan 2013 19:54:13 +0000"  >&lt;p&gt;This issue is fixed and released as part of 0.10.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12599375">HIVE-3274</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12600246">HIVE-3301</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12537094" name="HIVE-3273.1.patch.txt" size="1572" author="zhenxiao" created="Wed, 18 Jul 2012 23:17:04 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 19 Jul 2012 10:46:56 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>242374</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 2 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02u6v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>14492</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3274] Fix the Hadoop classpath in build-common.xml &quot;test&quot; target</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3274</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;the Hadoop classpath is set incorrectly in the &quot;test&quot; target in build-common.xml. &lt;br/&gt;
This classpath should match the classpath that bin/hadoop would run with.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599375">HIVE-3274</key>
            <summary>Fix the Hadoop classpath in build-common.xml &quot;test&quot; target</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="zhenxiao">Zhenxiao Luo</assignee>
                                    <reporter username="zhenxiao">Zhenxiao Luo</reporter>
                        <labels>
                    </labels>
                <created>Wed, 18 Jul 2012 23:09:00 +0000</created>
                <updated>Wed, 18 Jul 2012 23:09:39 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                    <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12599373">HIVE-3273</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>259158</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 27 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ln6f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>124405</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-3275] Fix autolocal1.q testcase failure when building hive on hadoop0.23 MR2</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3275</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;autolocal1.q is failing only on hadoop0.23 MR2, due to cluster initialization problem:&lt;/p&gt;

&lt;p&gt;Begin query: autolocal1.q&lt;br/&gt;
diff -a /var/lib/jenkins/workspace/zhenxiao-CDH4-Hive-0.9.0/build/ql/test/logs/clientnegative/autolocal1.q.out /var/lib/jenkins/workspace/zhenxiao-CDH4-Hive-0.9.0/ql/src/test/results/clientnegative/autolocal1.q.out&lt;br/&gt;
5c5&lt;br/&gt;
&amp;lt; Job Submission failed with exception &apos;java.io.IOException(Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.)&apos;&lt;br/&gt;
&#8212;&lt;br/&gt;
&amp;gt; Job Submission failed with exception &apos;java.lang.IllegalArgumentException(Does not contain a valid host:port authority: abracadabra)&apos;&lt;br/&gt;
Exception: Client execution results failed with error code = 1&lt;br/&gt;
See build/ql/tmp/hive.log, or try &quot;ant test ... -Dtest.silent=false&quot; to get more logs.&lt;br/&gt;
Failed query: autolocal1.q&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599389">HIVE-3275</key>
            <summary>Fix autolocal1.q testcase failure when building hive on hadoop0.23 MR2</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="zhenxiao">Zhenxiao Luo</assignee>
                                    <reporter username="zhenxiao">Zhenxiao Luo</reporter>
                        <labels>
                    </labels>
                <created>Thu, 19 Jul 2012 01:34:18 +0000</created>
                <updated>Thu, 10 Jan 2013 19:53:53 +0000</updated>
                            <resolved>Thu, 26 Jul 2012 05:43:05 +0000</resolved>
                                                    <fixVersion>0.10.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13417952" author="zhenxiao" created="Thu, 19 Jul 2012 01:36:15 +0000"  >&lt;p&gt;After adding the following to autolocal1.q to initialize MR2 yarn framework:&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;~/Code/hive&amp;#93;&lt;/span&gt;git diff ql/src/test/queries/clientnegative/autolocal1.q&lt;br/&gt;
diff --git a/ql/src/test/queries/clientnegative/autolocal1.q b/ql/src/test/queries/clientnegative/autolocal1.q&lt;br/&gt;
index 6bee177..8623eb5 100644&lt;br/&gt;
&amp;#8212; a/ql/src/test/queries/clientnegative/autolocal1.q&lt;br/&gt;
+++ b/ql/src/test/queries/clientnegative/autolocal1.q&lt;br/&gt;
@@ -1,3 +1,4 @@&lt;br/&gt;
+set mapreduce.framework.name=yarn;&lt;br/&gt;
 set mapred.job.tracker=abracadabra;&lt;br/&gt;
 set hive.exec.mode.local.auto.inputbytes.max=1;&lt;br/&gt;
 set hive.exec.mode.local.auto=true;&lt;/p&gt;

&lt;p&gt;Still getting the following diffs:&lt;/p&gt;

&lt;p&gt;diff -a /home/cloudera/Code/hive/build/ql/test/logs/clientnegative/autolocal1.q.out /home/cloudera/Code/hive/ql/src/test/results/clientnegative/autolocal1.q.out&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 5c5&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;lt; Job Submission failed with exception &apos;java.lang.reflect.UndeclaredThrowableException(null)&apos;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &#8212;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &amp;gt; Job Submission failed with exception &apos;java.lang.IllegalArgumentException(Does not contain a valid host:port authority: abracadabra)&apos;&lt;/p&gt;</comment>
                            <comment id="13417965" author="zhenxiao" created="Thu, 19 Jul 2012 01:49:29 +0000"  >&lt;p&gt;The reason is:&lt;/p&gt;

&lt;p&gt;1. On hadoop0.20 or Hadoop0.23 MR1,&lt;/p&gt;

&lt;p&gt;JobClient jc = new JobClient(job);&lt;/p&gt;

&lt;p&gt;this line is throwing exception in ExecDriver.java.&lt;/p&gt;

&lt;p&gt;It calls into JobClient.java:&lt;/p&gt;

&lt;p&gt;public JobClient(JobConf conf) throws IOException &lt;/p&gt;
{
    setConf(conf);
    init(conf);
  }

&lt;p&gt;  /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Connect to the default 
{@link JobTracker}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@param conf the job configuration.&lt;/li&gt;
	&lt;li&gt;@throws IOException&lt;br/&gt;
   */&lt;br/&gt;
  public void init(JobConf conf) throws IOException 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    String tracker = conf.get(&amp;quot;mapred.job.tracker&amp;quot;, &amp;quot;local&amp;quot;);    if (&amp;quot;local&amp;quot;.equals(tracker)) {
      this.jobSubmitClient = new LocalJobRunner(conf);
    } else {
      this.jobSubmitClient = createRPCProxy(JobTracker.getAddress(conf), conf);
    }  }&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;When createRPCProxy() is called, jobtracker is trying to getAddress(conf) of the non-existed host(abracadabra), and throws the expected exception:&lt;br/&gt;
java.lang.IllegalArgumentException: Does not contain a valid host:port authority: abracadabra&lt;/p&gt;

&lt;p&gt;Here is the log and stack trace when running in hadoop0.20 to proof the above observation:&lt;/p&gt;

&lt;p&gt;2012-07-18 17:53:38,210 ERROR exec.Task (SessionState.java:printError(400)) - Job Submission failed with exception &apos;java.lang.IllegalArgumentException(Does not contain a valid host:port authority: abracadabra)&apos;&lt;br/&gt;
java.lang.IllegalArgumentException: Does not contain a valid host:port authority: abracadabra     &lt;br/&gt;
    at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:206)&lt;br/&gt;
    at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:158)                         &lt;br/&gt;
    at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:147)                         &lt;br/&gt;
    at org.apache.hadoop.mapred.JobTracker.getAddress(JobTracker.java:2119)                       &lt;br/&gt;
    at org.apache.hadoop.mapred.JobClient.init(JobClient.java:497)&lt;br/&gt;
    at org.apache.hadoop.mapred.JobClient.&amp;lt;init&amp;gt;(JobClient.java:469)                              &lt;br/&gt;
    at org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:418)                     &lt;br/&gt;
    at org.apache.hadoop.hive.ql.exec.MapRedTask.execute(MapRedTask.java:136)                     &lt;br/&gt;
    at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:134)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:57)                &lt;br/&gt;
    at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1324)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1110)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.Driver.run(Driver.java:944)&lt;br/&gt;
    at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:258)                   &lt;br/&gt;
    at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:215)&lt;br/&gt;
    at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:406)                       &lt;br/&gt;
    at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:341)                       &lt;br/&gt;
    at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:671)                      &lt;br/&gt;
    at org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_autolocal1(TestNegativeCliDriver.java:117)&lt;br/&gt;
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)              &lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)      &lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:616)&lt;br/&gt;
    at junit.framework.TestCase.runTest(TestCase.java:168)&lt;br/&gt;
    at junit.framework.TestCase.runBare(TestCase.java:134)                                        &lt;br/&gt;
    at junit.framework.TestResult$1.protect(TestResult.java:110)                                  &lt;br/&gt;
    at junit.framework.TestResult.runProtected(TestResult.java:128)                               &lt;br/&gt;
    at junit.framework.TestResult.run(TestResult.java:113)&lt;br/&gt;
    at junit.framework.TestCase.run(TestCase.java:124)&lt;br/&gt;
    at junit.framework.TestSuite.runTest(TestSuite.java:243)                                      &lt;br/&gt;
    at junit.framework.TestSuite.run(TestSuite.java:238)                                          &lt;br/&gt;
    at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420) &lt;br/&gt;
    at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)   &lt;br/&gt;
    at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)&lt;/p&gt;

&lt;p&gt;2012-07-18 17:53:38,215 ERROR ql.Driver (SessionState.java:printError(400)) - FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.MapRedTask &lt;/p&gt;

&lt;p&gt;2. When running in hadoop0.23 MR2. MapReduce2 is using Yarn framework,&lt;/p&gt;

&lt;p&gt;JobClient jc = new JobClient(job)&lt;/p&gt;

&lt;p&gt;this line in ExecDriver.java is calling into MR2&apos;s implementation of JobClient:&lt;/p&gt;

&lt;p&gt;public JobClient(Configuration conf) throws IOException &lt;/p&gt;
{
    init(new JobConf(conf));
  }

&lt;p&gt;  /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Connect to the default cluster&lt;/li&gt;
	&lt;li&gt;@param conf the job configuration.&lt;/li&gt;
	&lt;li&gt;@throws IOException&lt;br/&gt;
   */&lt;br/&gt;
  public void init(JobConf conf) throws IOException 
{
    setConf(conf);
    cluster = new Cluster(conf);
    clientUgi = UserGroupInformation.getCurrentUser();
  }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In MR2&apos;s implementation of init(JobConf), it does not try to getAddress(conf) of the non-existed host(abracadabra). It only tries to initialize the cluster. This is working OK with a proof of the following log:&lt;/p&gt;

&lt;p&gt;2012-07-18 17:34:26,539 INFO  exec.ExecDriver (ExecDriver.java:addInputPaths(860)) - Adding input file pfile:/home/cloudera/Code/hive/build/ql/test/data/warehouse/src&lt;br/&gt;
2012-07-18 17:34:26,539 INFO  exec.Utilities (Utilities.java:isEmptyPath(1804)) - Content Summary pfile:/home/cloudera/Code/hive/build/ql/test/data/warehouse/srclength: 5868 num files: 2 num directories: 1&lt;br/&gt;
2012-07-18 17:34:26,877 DEBUG mapreduce.Cluster (Cluster.java:initialize(91)) - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider&lt;br/&gt;
2012-07-18 17:34:26,877 DEBUG mapreduce.Cluster (Cluster.java:initialize(109)) - Cannot pick org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider - returned null protocol&lt;br/&gt;
2012-07-18 17:34:26,879 DEBUG mapreduce.Cluster (Cluster.java:initialize(91)) - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider&lt;br/&gt;
2012-07-18 17:34:26,972 DEBUG ipc.YarnRPC (YarnRPC.java:create(57)) - Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC&lt;br/&gt;
2012-07-18 17:34:27,000 DEBUG mapred.ResourceMgrDelegate (ResourceMgrDelegate.java:&amp;lt;init&amp;gt;(89)) - Connecting to ResourceManager at /0.0.0.0:8032&lt;br/&gt;
2012-07-18 17:34:27,002 DEBUG ipc.HadoopYarnProtoRPC (HadoopYarnProtoRPC.java:getProxy(45)) - Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ClientRMProtocol&lt;br/&gt;
2012-07-18 17:34:27,038 DEBUG ipc.Server (Server.java:registerProtocolEngine(197)) - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWritable, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@1b34cd7b&lt;br/&gt;
2012-07-18 17:34:27,166 DEBUG mapred.ResourceMgrDelegate (ResourceMgrDelegate.java:&amp;lt;init&amp;gt;(93)) - Connected to ResourceManager at /0.0.0.0:8032&lt;br/&gt;
2012-07-18 17:34:27,172 DEBUG security.UserGroupInformation (UserGroupInformation.java:logPrivilegedAction(1254)) - PrivilegedAction as:cloudera (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:319)&lt;br/&gt;
2012-07-18 17:34:27,186 DEBUG mapreduce.Cluster (Cluster.java:initialize(104)) - Picked org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider&lt;/p&gt;

&lt;p&gt;An exception occurs in ExecDriver.java, when it is submitting the job to yarn:&lt;/p&gt;

&lt;p&gt;rj = jc.submitJob(job);&lt;/p&gt;

&lt;p&gt;Due to the non-existed host(abracadabra), JobClient.submitJob() fails with exception, with a proof of the following log:&lt;/p&gt;

&lt;p&gt;2012-07-18 17:34:27,235 DEBUG mapred.ResourceMgrDelegate (ResourceMgrDelegate.java:getStagingAreaDir(276)) - getStagingAreaDir: dir=/tmp/hadoop-yarn/staging/cloudera/.staging&lt;br/&gt;
2012-07-18 17:34:27,280 DEBUG ipc.Client (Client.java:&amp;lt;init&amp;gt;(262)) - The ping interval is 60000 ms.&lt;br/&gt;
2012-07-18 17:34:27,287 DEBUG ipc.Client (Client.java:&amp;lt;init&amp;gt;(305)) - Use SIMPLE authentication for protocol ClientRMProtocolPB&lt;br/&gt;
2012-07-18 17:34:27,287 DEBUG ipc.Client (Client.java:setupIOstreams(560)) - Connecting to /0.0.0.0:8032&lt;br/&gt;
2012-07-18 17:34:28,295 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s).&lt;br/&gt;
2012-07-18 17:34:29,297 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s).&lt;br/&gt;
2012-07-18 17:34:30,299 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s).&lt;br/&gt;
2012-07-18 17:34:31,301 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s).&lt;br/&gt;
2012-07-18 17:34:32,303 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s).&lt;br/&gt;
2012-07-18 17:34:33,305 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s).&lt;br/&gt;
2012-07-18 17:34:34,306 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s).&lt;br/&gt;
2012-07-18 17:34:35,308 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s).&lt;br/&gt;
2012-07-18 17:34:36,311 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s).&lt;br/&gt;
2012-07-18 17:34:37,312 INFO  ipc.Client (Client.java:handleConnectionFailure(683)) - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s).&lt;br/&gt;
2012-07-18 17:34:37,314 DEBUG ipc.Client (Client.java:close(917)) - closing ipc connection to 0.0.0.0/0.0.0.0:8032: Connection refused&lt;br/&gt;
java.net.ConnectException: Connection refused&lt;br/&gt;
    at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)&lt;br/&gt;
    at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:592)&lt;br/&gt;
    at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)&lt;br/&gt;
    at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:524)&lt;br/&gt;
    at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)&lt;br/&gt;
    at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:472)&lt;br/&gt;
    at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:566)&lt;br/&gt;
    at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:215)&lt;br/&gt;
    at org.apache.hadoop.ipc.Client.getConnection(Client.java:1271)&lt;br/&gt;
    at org.apache.hadoop.ipc.Client.call(Client.java:1141)&lt;br/&gt;
    at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:184)&lt;br/&gt;
    at $Proxy9.getNewApplication(Unknown Source)&lt;br/&gt;
    at org.apache.hadoop.yarn.api.impl.pb.client.ClientRMProtocolPBClientImpl.getNewApplication(ClientRMProtocolPBClientImpl.java:132)&lt;br/&gt;
    at org.apache.hadoop.mapred.ResourceMgrDelegate.getNewJobID(ResourceMgrDelegate.java:181)&lt;br/&gt;
    at org.apache.hadoop.mapred.YARNRunner.getNewJobID(YARNRunner.java:214)&lt;br/&gt;
    at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:338)&lt;br/&gt;
    at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1226)&lt;br/&gt;
    at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1223)&lt;br/&gt;
    at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
    at javax.security.auth.Subject.doAs(Subject.java:416)&lt;br/&gt;
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)&lt;br/&gt;
    at org.apache.hadoop.mapreduce.Job.submit(Job.java:1223)&lt;br/&gt;
    at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:617)&lt;br/&gt;
    at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:612)&lt;br/&gt;
    at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
    at javax.security.auth.Subject.doAs(Subject.java:416)&lt;br/&gt;
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)&lt;br/&gt;
    at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:612)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:435)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.exec.MapRedTask.execute(MapRedTask.java:136)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:134)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:57)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1324)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1110)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.Driver.run(Driver.java:944)&lt;br/&gt;
    at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:258)&lt;br/&gt;
    at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:215)&lt;br/&gt;
    at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:406)&lt;br/&gt;
    at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:341)&lt;br/&gt;
    at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:671)&lt;br/&gt;
    at org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_autolocal1(TestNegativeCliDriver.java:117)&lt;br/&gt;
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)&lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:616)&lt;br/&gt;
    at junit.framework.TestCase.runTest(TestCase.java:168)&lt;/p&gt;

</comment>
                            <comment id="13417972" author="zhenxiao" created="Thu, 19 Jul 2012 01:55:35 +0000"  >&lt;p&gt;My plan is to keep autolocal1.q running only in hadoop0.20.&lt;/p&gt;</comment>
                            <comment id="13417990" author="zhenxiao" created="Thu, 19 Jul 2012 02:19:00 +0000"  >&lt;p&gt;review request submitted at:&lt;br/&gt;
&lt;a href=&quot;https://reviews.facebook.net/D4221&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4221&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13417998" author="zhenxiao" created="Thu, 19 Jul 2012 02:29:18 +0000"  >&lt;p&gt;In summary,&lt;/p&gt;

&lt;p&gt;In hadoop0.20,&lt;/p&gt;

&lt;p&gt;JobClient initialization would try to get JobTracker&apos;s address, which throws the expected exception.&lt;/p&gt;

&lt;p&gt;While, in hadoop0.23,&lt;/p&gt;

&lt;p&gt;JobClient Initialization would try which protocol to choose.&lt;/p&gt;

&lt;p&gt;If MR1, it would do the same as hadoop0.20.&lt;/p&gt;

&lt;p&gt;If MR2, it does not try to get JobTracker&apos;s address in JobClient initialization. No exception thrown at this time.&lt;/p&gt;

&lt;p&gt;This will be an exception when the jobClient submitJob.&lt;/p&gt;

&lt;p&gt;Since the expected exception on hadoop0.23 diffs for MR1 and MR2, and the execution path has changed for MR1 and MR2, My plan is only running this test on hadoop0.20.&lt;/p&gt;</comment>
                            <comment id="13417999" author="zhenxiao" created="Thu, 19 Jul 2012 02:32:27 +0000"  >&lt;p&gt;@Joydeep:&lt;/p&gt;

&lt;p&gt;Any comments are appreciated. I&apos;d like to know the idea from autolocal1.q&apos;s original author.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Zhenxiao&lt;/p&gt;</comment>
                            <comment id="13418029" author="jsensarma" created="Thu, 19 Jul 2012 03:27:06 +0000"  >&lt;p&gt;that sounds like a reasonable approach. it&apos;s a hive test, not hadoop - so as long as hive is trying to generate a non-local mode job (i am guessing that&apos;s what&apos;s being tested here) and that&apos;s verified against some hadoop tree - we are good.&lt;/p&gt;</comment>
                            <comment id="13422739" author="ashutoshc" created="Wed, 25 Jul 2012 23:50:59 +0000"  >&lt;p&gt;Even between 0.20 and 1.x series, Exception type has changed from RuntimeException to IllegalArgumentTypeException as well as exception message has changed. I don&apos;t see any easy way to keep our testcases to succeed with such changes given our diff based comparisons. I think its fine to just make sure it run against one version and gives desired behavior. +1. will commit if tests pass.&lt;/p&gt;</comment>
                            <comment id="13422911" author="ashutoshc" created="Thu, 26 Jul 2012 05:43:05 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Zhenxiao!&lt;/p&gt;</comment>
                            <comment id="13423662" author="hudson" created="Fri, 27 Jul 2012 04:21:50 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1569 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1569/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1569/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3275&quot; title=&quot;Fix autolocal1.q testcase failure when building hive on hadoop0.23 MR2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3275&quot;&gt;&lt;del&gt;HIVE-3275&lt;/del&gt;&lt;/a&gt; : Fix autolocal1.q testcase failure when building hive on hadoop0.23 MR2 (Zhenxiao Luo via Ashutosh Chauhan) (Revision 1365888)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1365888&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1365888&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/autolocal1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/autolocal1.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13548117" author="hudson" created="Wed, 9 Jan 2013 10:24:27 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #54 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3275&quot; title=&quot;Fix autolocal1.q testcase failure when building hive on hadoop0.23 MR2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3275&quot;&gt;&lt;del&gt;HIVE-3275&lt;/del&gt;&lt;/a&gt; : Fix autolocal1.q testcase failure when building hive on hadoop0.23 MR2 (Zhenxiao Luo via Ashutosh Chauhan) (Revision 1365888)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1365888&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1365888&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/autolocal1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/autolocal1.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13550230" author="ashutoshc" created="Thu, 10 Jan 2013 19:53:53 +0000"  >&lt;p&gt;This issue is fixed and released as part of 0.10.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12600246">HIVE-3301</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12537123" name="HIVE-3275.1.patch.txt" size="1853" author="zhenxiao" created="Thu, 19 Jul 2012 02:19:41 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 19 Jul 2012 03:27:06 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>242371</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 2 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02u67:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>14489</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3276] optimize union sub-queries</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3276</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;It might be a good idea to optimize simple union queries containing map-reduce jobs in at least one of the sub-qeuries.&lt;/p&gt;

&lt;p&gt;For eg:&lt;/p&gt;

&lt;p&gt;a query like:&lt;/p&gt;



&lt;p&gt;insert overwrite table T1 partition P1&lt;br/&gt;
select * from &lt;br/&gt;
(&lt;br/&gt;
  subq1&lt;br/&gt;
    union all&lt;br/&gt;
  subq2&lt;br/&gt;
) u;&lt;/p&gt;


&lt;p&gt;today creates 3 map-reduce jobs, one for subq1, another for subq2 and &lt;br/&gt;
the final one for the union. &lt;/p&gt;

&lt;p&gt;It might be a good idea to optimize this. Instead of creating the union &lt;br/&gt;
task, it might be simpler to create a move task (or something like a move&lt;br/&gt;
task), where the outputs of the two sub-queries will be moved to the final &lt;br/&gt;
directory. This can easily extend to more than 2 sub-queries in the union.&lt;/p&gt;

&lt;p&gt;This is very useful if there is a select * followed by filesink after the&lt;br/&gt;
union. This can be independently useful, and also be used to optimize the&lt;br/&gt;
skewed joins &amp;#8211; &lt;br/&gt;
&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Skewed+Join+Optimization&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/Skewed+Join+Optimization&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If there is a select, filter between the union and the filesink, the select&lt;br/&gt;
and the filter can be moved before the union, and the follow-up job can&lt;br/&gt;
still be removed.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599401">HIVE-3276</key>
            <summary>optimize union sub-queries</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="namit">Namit Jain</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Thu, 19 Jul 2012 04:42:51 +0000</created>
                <updated>Mon, 15 Sep 2014 03:03:28 +0000</updated>
                            <resolved>Tue, 30 Oct 2012 23:40:02 +0000</resolved>
                                    <version>0.10.0</version>
                                    <fixVersion>0.10.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>12</watches>
                                                                <comments>
                            <comment id="13422533" author="nadeemoidu" created="Wed, 25 Jul 2012 19:23:53 +0000"  >&lt;p&gt;A wiki page has been added for the same here &lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Union+Optimization&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/Union+Optimization&lt;/a&gt; . I have started work on this and will be uploading the patch soon. Feel free to give any feedback on the same. Thanks.&lt;/p&gt;</comment>
                            <comment id="13427510" author="nadeemoidu" created="Thu, 2 Aug 2012 18:20:15 +0000"  >&lt;p&gt;The patch is partially complete. &lt;a href=&quot;https://reviews.facebook.net/D4431&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4431&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13428996" author="namit" created="Mon, 6 Aug 2012 06:49:20 +0000"  >&lt;p&gt;Looked at it in more detail.&lt;/p&gt;

&lt;p&gt;It might be cleaner to add a optimization step for this, which changes the operator tree.&lt;br/&gt;
The current approach is simpler to quickly get the code out, but may not be a good idea in the long run.&lt;br/&gt;
We have tried to keep all the optimizations pluggable, it helps with roll-outs, fixing bugs slowly etc.&lt;br/&gt;
With the current approach, it is very difficult to make this pluggable. Again, it it possible to check&lt;br/&gt;
the new conf. in GenMRUnion1, but it looks like a hacky approach.&lt;/p&gt;</comment>
                            <comment id="13432909" author="namit" created="Mon, 13 Aug 2012 04:13:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.facebook.net/D4623&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4623&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13433080" author="namit" created="Mon, 13 Aug 2012 11:51:18 +0000"  >&lt;p&gt;Some tests need to be added for this which should only be &lt;br/&gt;
enabled for hadoop 23.&lt;/p&gt;

&lt;p&gt;I am not able to run tests for hadoop 23.&lt;/p&gt;</comment>
                            <comment id="13436105" author="kevinwilfong" created="Thu, 16 Aug 2012 17:03:06 +0000"  >&lt;p&gt;Namit, is this ready for review?  You mention that more test need to be added, but the JIRA is marked Patch Available.&lt;/p&gt;</comment>
                            <comment id="13436176" author="namit" created="Thu, 16 Aug 2012 18:06:57 +0000"  >&lt;p&gt;I was able to run tests for hadoop 23.&lt;br/&gt;
I will upload the new patch soon.&lt;/p&gt;</comment>
                            <comment id="13436201" author="namit" created="Thu, 16 Aug 2012 18:32:39 +0000"  >&lt;p&gt;ShimLoader changes are copied from &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3029&quot; title=&quot;Update ShimLoader to work with Hadoop 2.x&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3029&quot;&gt;&lt;del&gt;HIVE-3029&lt;/del&gt;&lt;/a&gt;, only to run tests on hadoop 23.&lt;br/&gt;
Once &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3029&quot; title=&quot;Update ShimLoader to work with Hadoop 2.x&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3029&quot;&gt;&lt;del&gt;HIVE-3029&lt;/del&gt;&lt;/a&gt; is checked in, this file will be reverted&lt;/p&gt;

&lt;p&gt;Also, to run tests for thew newly added tests only on hadoop 23:&lt;/p&gt;

&lt;p&gt;ant clean package&lt;/p&gt;


&lt;p&gt;ant test -Dhadoop.mr.rev=23 -Dtest.print.classpath=true -Dhadoop.version=2.0.0-alpha -Dhadoop.security.version=2.0.0-alpha -Dtestcase=TestCliDriver -Dqfile=union_remove_1.q,union_remove_2.q,union_remove_3.q,union_remove_4.q,union_remove_5.q,union_remove_6.q,union_remove_7.q,union_remove_8.q,union_remove_9.q,union_remove_10.q,union_remove_11.q,union_remove_12.q,union_remove_13.q,union_remove_14.q,union_remove_15.q,union_remove_16.q,union_remove_17.q,union_remove_18.q&lt;/p&gt;</comment>
                            <comment id="13436202" author="namit" created="Thu, 16 Aug 2012 18:32:58 +0000"  >&lt;p&gt;@Kevin, this is ready for review.&lt;/p&gt;</comment>
                            <comment id="13445843" author="namit" created="Fri, 31 Aug 2012 11:14:59 +0000"  >&lt;p&gt;refreshed&lt;/p&gt;</comment>
                            <comment id="13460188" author="namit" created="Fri, 21 Sep 2012 04:12:50 +0000"  >&lt;p&gt;All the tests ran fine&lt;/p&gt;</comment>
                            <comment id="13467221" author="kevinwilfong" created="Mon, 1 Oct 2012 21:44:54 +0000"  >&lt;p&gt;I posted a couple of minor comments and a bunch of questions in Phabricator.&lt;/p&gt;</comment>
                            <comment id="13467471" author="namit" created="Tue, 2 Oct 2012 04:30:44 +0000"  >&lt;p&gt;addressing comments on phabricator&lt;/p&gt;</comment>
                            <comment id="13468414" author="namit" created="Wed, 3 Oct 2012 08:38:12 +0000"  >&lt;p&gt;comments addressed&lt;/p&gt;</comment>
                            <comment id="13468682" author="namit" created="Wed, 3 Oct 2012 17:20:46 +0000"  >&lt;p&gt;The tests finished fine&lt;/p&gt;</comment>
                            <comment id="13473244" author="namit" created="Wed, 10 Oct 2012 14:10:15 +0000"  >&lt;p&gt;will address comments on phabricator&lt;/p&gt;</comment>
                            <comment id="13473935" author="cwsteinbach" created="Thu, 11 Oct 2012 08:04:52 +0000"  >&lt;p&gt;@Namit: I added two comments on phabricator. I&apos;m looking at this pretty late so feel free to ignore them.&lt;/p&gt;</comment>
                            <comment id="13475058" author="namit" created="Fri, 12 Oct 2012 15:11:05 +0000"  >&lt;p&gt;@Carl, comments addressed.&lt;/p&gt;</comment>
                            <comment id="13478012" author="namit" created="Wed, 17 Oct 2012 16:35:57 +0000"  >&lt;p&gt;addressed comments&lt;/p&gt;</comment>
                            <comment id="13478348" author="kevinwilfong" created="Wed, 17 Oct 2012 20:39:18 +0000"  >&lt;p&gt;I suspect this patch will introduce failures where a union involves a column of type double on one side and non-double on the other until this fix is in.&lt;/p&gt;</comment>
                            <comment id="13478349" author="kevinwilfong" created="Wed, 17 Oct 2012 20:39:53 +0000"  >&lt;p&gt;I was referring to  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3544&quot; title=&quot;union involving double column with a map join subquery will fail or give wrong results&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3544&quot;&gt;&lt;del&gt;HIVE-3544&lt;/del&gt;&lt;/a&gt; in the above comment.&lt;/p&gt;</comment>
                            <comment id="13485957" author="namit" created="Mon, 29 Oct 2012 11:05:36 +0000"  >&lt;p&gt;addressed comments - added new tests for double/bigint conversion&lt;br/&gt;
refreshed patch + test outputs&lt;/p&gt;</comment>
                            <comment id="13486554" author="kevinwilfong" created="Tue, 30 Oct 2012 00:38:58 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13487374" author="kevinwilfong" created="Tue, 30 Oct 2012 23:40:02 +0000"  >&lt;p&gt;Committed, thanks Namit.&lt;/p&gt;</comment>
                            <comment id="13487852" author="hudson" created="Wed, 31 Oct 2012 15:27:29 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1767 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1767/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1767/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3276&quot; title=&quot;optimize union sub-queries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3276&quot;&gt;&lt;del&gt;HIVE-3276&lt;/del&gt;&lt;/a&gt;. optimize union sub-queries. (njain via kevinwilfong) (Revision 1403928)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
kevinwilfong : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1403928&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1403928&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ColumnInfo.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FilterOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRProcContext.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/unionproc/UnionProcContext.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/unionproc/UnionProcFactory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/unionproc/UnionProcessor.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverMergeFiles.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/FileSinkDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/SelectDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/skewjoin_union_remove_1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/skewjoin_union_remove_2.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_10.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_11.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_12.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_13.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_14.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_15.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_16.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_17.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_18.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_19.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_2.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_20.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_21.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_22.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_23.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_24.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_3.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_4.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_5.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_6.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_7.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_8.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_9.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/skewjoin_union_remove_1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/skewjoin_union_remove_2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_10.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_11.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_12.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_13.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_14.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_15.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_16.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_17.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_18.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_19.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_20.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_21.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_22.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_23.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_24.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_5.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_6.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_7.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_8.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_9.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13548115" author="hudson" created="Wed, 9 Jan 2013 10:24:27 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #54 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3276&quot; title=&quot;optimize union sub-queries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3276&quot;&gt;&lt;del&gt;HIVE-3276&lt;/del&gt;&lt;/a&gt;. optimize union sub-queries. (njain via kevinwilfong) (Revision 1403928)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
kevinwilfong : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1403928&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1403928&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ColumnInfo.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FilterOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRProcContext.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/unionproc/UnionProcContext.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/unionproc/UnionProcFactory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/unionproc/UnionProcessor.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverMergeFiles.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/FileSinkDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/SelectDesc.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/skewjoin_union_remove_1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/skewjoin_union_remove_2.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_10.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_11.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_12.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_13.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_14.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_15.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_16.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_17.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_18.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_19.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_2.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_20.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_21.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_22.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_23.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_24.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_3.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_4.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_5.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_6.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_7.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_8.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/union_remove_9.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/skewjoin_union_remove_1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/skewjoin_union_remove_2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_10.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_11.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_12.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_13.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_14.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_15.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_16.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_17.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_18.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_19.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_20.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_21.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_22.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_23.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_24.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_5.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_6.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_7.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_8.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_remove_9.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13550076" author="ashutoshc" created="Thu, 10 Jan 2013 19:53:17 +0000"  >&lt;p&gt;This issue is fixed and released as part of 0.10.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.&lt;/p&gt;</comment>
                            <comment id="13979331" author="lefty@hortonworks.com" created="Thu, 24 Apr 2014 05:59:04 +0000"  >&lt;p&gt;For the record:  This added configuration parameters &lt;b&gt;hive.optimize.union.remove&lt;/b&gt; and &lt;b&gt;hive.mapred.supports.subdirectories&lt;/b&gt; to HiveConf.java and hive-default.xml.template.&lt;/p&gt;</comment>
                            <comment id="13996244" author="lefty@hortonworks.com" created="Tue, 13 May 2014 10:17:31 +0000"  >&lt;p&gt;The configuration parameters are now documented in the wiki:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.optimize.union.remove&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;hive.optimize.union.remove &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.mapred.supports.subdirectories&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;hive.mapred.supports.subdirectories &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12740835">HIVE-8054</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12607176">HIVE-3451</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12614075">HIVE-3643</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12602076">HIVE-3341</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12610746">HIVE-3544</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12603387">HIVE-3380</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12538931" name="HIVE-3276.1.patch" size="21684" author="nadeemoidu" created="Thu, 2 Aug 2012 18:22:03 +0000"/>
                            <attachment id="12547512" name="hive.3276.10.patch" size="490520" author="namit" created="Wed, 3 Oct 2012 08:37:59 +0000"/>
                            <attachment id="12548593" name="hive.3276.11.patch" size="491249" author="namit" created="Wed, 10 Oct 2012 17:57:10 +0000"/>
                            <attachment id="12548900" name="hive.3276.12.patch" size="491291" author="namit" created="Fri, 12 Oct 2012 15:10:50 +0000"/>
                            <attachment id="12549528" name="hive.3276.13.patch" size="492377" author="namit" created="Wed, 17 Oct 2012 16:35:45 +0000"/>
                            <attachment id="12551179" name="hive.3276.14.patch" size="509694" author="namit" created="Mon, 29 Oct 2012 11:04:49 +0000"/>
                            <attachment id="12540630" name="hive.3276.2.patch" size="293239" author="namit" created="Mon, 13 Aug 2012 09:16:28 +0000"/>
                            <attachment id="12541259" name="hive.3276.3.patch" size="319504" author="namit" created="Thu, 16 Aug 2012 18:31:09 +0000"/>
                            <attachment id="12543252" name="hive.3276.4.patch" size="314054" author="namit" created="Fri, 31 Aug 2012 11:14:48 +0000"/>
                            <attachment id="12545858" name="hive.3276.5.patch" size="373981" author="namit" created="Thu, 20 Sep 2012 06:02:49 +0000"/>
                            <attachment id="12545887" name="hive.3276.6.patch" size="462501" author="namit" created="Thu, 20 Sep 2012 11:37:59 +0000"/>
                            <attachment id="12545996" name="hive.3276.7.patch" size="463023" author="namit" created="Fri, 21 Sep 2012 04:07:34 +0000"/>
                            <attachment id="12546460" name="hive.3276.8.patch" size="466975" author="namit" created="Tue, 25 Sep 2012 07:06:06 +0000"/>
                            <attachment id="12547118" name="hive.3276.9.patch" size="467130" author="namit" created="Sat, 29 Sep 2012 16:33:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>14.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 25 Jul 2012 19:23:53 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>242116</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 37 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02iuv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>12656</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3277] Enable Metastore audit logging for non-secure connections</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3277</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12599525">HIVE-3277</key>
            <summary>Enable Metastore audit logging for non-secure connections</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mackrorysd">Sean Mackrory</assignee>
                                    <reporter username="cwsteinbach">Carl Steinbach</reporter>
                        <labels>
                    </labels>
                <created>Thu, 19 Jul 2012 20:53:20 +0000</created>
                <updated>Thu, 2 May 2013 02:30:52 +0000</updated>
                            <resolved>Thu, 27 Sep 2012 21:40:37 +0000</resolved>
                                    <version>0.10.0</version>
                                    <fixVersion>0.10.0</fixVersion>
                                    <component>Logging</component>
                    <component>Metastore</component>
                    <component>Security</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13418664" author="cwsteinbach" created="Thu, 19 Jul 2012 20:54:35 +0000"  >&lt;p&gt;Audit logging for the metastore was added in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1948&quot; title=&quot;Have audit logging in the Metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1948&quot;&gt;&lt;del&gt;HIVE-1948&lt;/del&gt;&lt;/a&gt;, but it only gets invoked if the client connection is secure. We should also enable this for non-secure connections.&lt;/p&gt;</comment>
                            <comment id="13442241" author="qwertymaniac" created="Mon, 27 Aug 2012 02:06:05 +0000"  >&lt;p&gt;Hi Carl,&lt;/p&gt;

&lt;p&gt;We do get some audit logging in unsecure mode but it lacks info I think. Isn&apos;t this done already via &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2797&quot; title=&quot;Make the IP address of a Thrift client available to HMSHandler.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2797&quot;&gt;&lt;del&gt;HIVE-2797&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="13462091" author="mackrorysd" created="Mon, 24 Sep 2012 20:33:37 +0000"  >&lt;p&gt;This patch uses the alternative method of determining the IP address in the event that there is no SASL connection. I&apos;ve tested this out on a pseudo-distributed Hadoop cluster and audit logging worked.&lt;/p&gt;</comment>
                            <comment id="13462116" author="mackrorysd" created="Mon, 24 Sep 2012 20:57:28 +0000"  >&lt;p&gt;My apologies - original patch was malformed.&lt;/p&gt;</comment>
                            <comment id="13462121" author="mackrorysd" created="Mon, 24 Sep 2012 20:59:25 +0000"  >&lt;p&gt;Code review: &lt;a href=&quot;https://reviews.apache.org/r/7236/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/7236/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13462140" author="mackrorysd" created="Mon, 24 Sep 2012 21:10:22 +0000"  >&lt;p&gt;Second patch fixes a code style issue&lt;/p&gt;</comment>
                            <comment id="13462144" author="cwsteinbach" created="Mon, 24 Sep 2012 21:13:08 +0000"  >&lt;p&gt;+1. Will commit if tests pass.&lt;/p&gt;</comment>
                            <comment id="13463497" author="hudson" created="Wed, 26 Sep 2012 03:48:09 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1697 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1697/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1697/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3277&quot; title=&quot;Enable Metastore audit logging for non-secure connections&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3277&quot;&gt;&lt;del&gt;HIVE-3277&lt;/del&gt;&lt;/a&gt;. Enable Metastore audit logging for non-secure connections (Sean Mackrory via cws) (Revision 1390155)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
cws : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1390155&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1390155&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13465138" author="cwsteinbach" created="Thu, 27 Sep 2012 21:46:20 +0000"  >&lt;p&gt;@Sean: Thanks for marking this resolved.&lt;/p&gt;</comment>
                            <comment id="13548121" author="hudson" created="Wed, 9 Jan 2013 10:24:28 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #54 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3277&quot; title=&quot;Enable Metastore audit logging for non-secure connections&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3277&quot;&gt;&lt;del&gt;HIVE-3277&lt;/del&gt;&lt;/a&gt;. Enable Metastore audit logging for non-secure connections (Sean Mackrory via cws) (Revision 1390155)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
cws : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1390155&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1390155&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12497525">HIVE-1948</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12546377" name="HIVE-3277.patch.1" size="1119" author="mackrorysd" created="Mon, 24 Sep 2012 20:57:28 +0000"/>
                            <attachment id="12546386" name="HIVE-3277.patch.2" size="1112" author="mackrorysd" created="Mon, 24 Sep 2012 21:10:22 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 27 Aug 2012 02:06:05 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>242699</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 2 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02z9z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>15316</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3278] Create wrappers around Thrift Metastore objects for improved readability</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3278</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12599533">HIVE-3278</key>
            <summary>Create wrappers around Thrift Metastore objects for improved readability</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="cwsteinbach">Carl Steinbach</reporter>
                        <labels>
                    </labels>
                <created>Thu, 19 Jul 2012 21:26:33 +0000</created>
                <updated>Sat, 6 Dec 2014 05:23:26 +0000</updated>
                                                                            <component>Metastore</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13418733" author="traviscrawford" created="Thu, 19 Jul 2012 22:30:40 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cwsteinbach&quot; class=&quot;user-hover&quot; rel=&quot;cwsteinbach&quot;&gt;Carl Steinbach&lt;/a&gt; - can you clarify what you mean by wrappers? There are wrappers already (for example &lt;a href=&quot;https://github.com/apache/hive/blob/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hive/blob/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java&lt;/a&gt;) and I&apos;m curious what the distinction will be.&lt;/p&gt;

&lt;p&gt;FWIW, having two sets of identically named classes (stuff under metastore.api &amp;amp; ql.metadata) has already caused some confusion. Typically this confusion has been people using the metastore.api versions not realizing ql.metadata adds some business logic.&lt;/p&gt;</comment>
                            <comment id="13422106" author="ashutoshc" created="Wed, 25 Jul 2012 09:16:11 +0000"  >&lt;p&gt;Totally agree with Travis. We already have metastore objects represented via 2 different ways in: &lt;tt&gt;org.apache.hadoop.hive.ql.metadata&lt;/tt&gt; and &lt;tt&gt;org.apache.hadoop.hive.metastore.api&lt;/tt&gt; with logic spread across both the layers. Adding another set of wrapper objects will only increase the confusion.&lt;/p&gt;</comment>
                            <comment id="13425382" author="cwsteinbach" created="Mon, 30 Jul 2012 23:33:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;FWIW, having two sets of identically named classes (stuff under metastore.api &amp;amp; ql.metadata) has already caused some confusion. Typically this confusion has been people using the metastore.api versions not realizing ql.metadata adds some business logic.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is precisely the problem I&apos;m trying to solve. I&apos;m proposing that we extend each of the Thrift types with a lightweight wrapper where the subclass name is prefixed with a &quot;T&quot;, e.g. o.a.h.hive.metastore.api.Table would be extended by o.a.hive.metastore.api.thrift.TTable, etc, and then replace all of the references to o.a.h.hive.metastore.api.* classes with the corresponding o.a.hive.metastore.api.thrift.T* classes. It would have been nice if this had been done originally in the Thrift IDL, but that didn&apos;t happen, and we can&apos;t change it now without breaking backward compatibility. My goal in doing this is to make the code more readable (e.g. get rid of those awful canonical class name references), as well as to highlight the fact that we have Thrift types polluting the code.&lt;/p&gt;

&lt;p&gt;The Hive source should only reference Thrift types immediately above and below the Thrift interface layer. In all other places it should be decoupled from the Thrift interface and types, and should instead use types similar to the ones in ql.metadata.&lt;/p&gt;</comment>
                            <comment id="13425466" author="traviscrawford" created="Tue, 31 Jul 2012 02:02:12 +0000"  >&lt;p&gt;Totally agree with the sentiment. What are your thoughts on renaming &lt;tt&gt;org.apache.hadoop.hive.ql.metadata&lt;/tt&gt; classes something like &lt;tt&gt;MTable&lt;/tt&gt; (prefixed with M or some other letter) and using them in the code whenever possible. This would distinguish the two sets of classes without adding yet another set.&lt;/p&gt;</comment>
                            <comment id="13425476" author="cwsteinbach" created="Tue, 31 Jul 2012 02:41:16 +0000"  >&lt;p&gt;The &apos;M&apos; prefix is is already spoken for. We use it as the prefix for the Modeled objects that Datanucleus persists to the metastore, e.g. o.a.h.hive.metastore.model.MTable. I suppose we could prefix the stuff in ql.metadata with an &apos;H&apos;, but before we do that I&apos;d first like to move that code over to the metastore package and do some other cleanup work. Also, we should eventually wrap the HiveMetaStoreClient library with an improved version that uses the H* types instead of the raw Thrift types.&lt;/p&gt;</comment>
                            <comment id="13425931" author="traviscrawford" created="Tue, 31 Jul 2012 17:14:00 +0000"  >&lt;p&gt;SGTM&lt;/p&gt;</comment>
                            <comment id="13444593" author="traviscrawford" created="Thu, 30 Aug 2012 01:19:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HCATALOG-484&quot; title=&quot;HCatalog should use ql.metadata Table and Partition classes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HCATALOG-484&quot;&gt;&lt;del&gt;HCATALOG-484&lt;/del&gt;&lt;/a&gt; is an example where moving &lt;tt&gt;o.a.h.hive.ql.metadata.Table/Partition&lt;/tt&gt; into the metastore package would be helpful. In that issue we introduce a dependency on the &lt;tt&gt;ql&lt;/tt&gt; package, when really all we want is the extra business-logic applied to metastore responses. I totally agree with Carl it makes sense to refactor how these classes work.&lt;/p&gt;

&lt;p&gt;If everyone agrees this makes sense, I can make a patch that:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Moves Table/Partition from ql.metadata over to the metastore package.&lt;/li&gt;
	&lt;li&gt;Create wrapper classes in the existing locations for backwards compatibility, and mark them as deprecated.&lt;/li&gt;
	&lt;li&gt;Update hive code to use the new classes in the metastore package.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;If this sounds good let me know and I&apos;ll work on the patch.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12599538">HIVE-3280</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12605448">HCATALOG-484</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 19 Jul 2012 22:30:40 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>247664</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 21 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08nkn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>48418</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-3279] Table schema not being copied to Partitions with no columns</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3279</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Hive has a feature where &lt;tt&gt;Partition&lt;/tt&gt;&apos;s without any defined columns use the &lt;tt&gt;Table&lt;/tt&gt; schema. This happens in &lt;tt&gt;&lt;a href=&quot;https://github.com/apache/hive/blob/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java#L167&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Partition.initialize&lt;/a&gt;&lt;/tt&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-comment&quot;&gt;// set &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; columns are not set
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (tPartition.getSd().getCols() == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (table.getCols() != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
    tPartition.getSd().setCols(table.getCols());
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There&apos;s an issue though, because &lt;tt&gt;&lt;a href=&quot;https://github.com/apache/hive/blob/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java#L121&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Table.getEmptyTable&lt;/a&gt;&lt;/tt&gt; initializes cols to an empty array, which of course is not null, causing the above feature to not work as expected.&lt;/p&gt;

&lt;p&gt;I&apos;m not sure of the fix - is there a case where cols can indeed be null? I think the best thing to do here is:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;-        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (tPartition.getSd().getCols() == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
+        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (tPartition.getSd().getCols() == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; || tPartition.getSd().getCols().size() == 0) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599536">HIVE-3279</key>
            <summary>Table schema not being copied to Partitions with no columns</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="traviscrawford">Travis Crawford</assignee>
                                    <reporter username="traviscrawford">Travis Crawford</reporter>
                        <labels>
                    </labels>
                <created>Thu, 19 Jul 2012 21:33:59 +0000</created>
                <updated>Thu, 10 Jan 2013 19:52:58 +0000</updated>
                            <resolved>Thu, 26 Jul 2012 15:59:00 +0000</resolved>
                                                    <fixVersion>0.10.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13420289" author="ashutoshc" created="Sun, 22 Jul 2012 19:37:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;There&apos;s an issue though, because Table.getEmptyTable initializes cols to an empty array, which of course is not null, causing the above feature to not work as expected.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I am not sure if this really is the case.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;hive&amp;gt; create table tt (a string) partitioned by (b string);
OK
Time taken: 7.907 seconds
hive&amp;gt; describe tt ;                     
OK
a	string	
b	string	
Time taken: 0.073 seconds
hive&amp;gt; alter table tt add partition(b=&lt;span class=&quot;code-quote&quot;&gt;&apos;part1&apos;&lt;/span&gt;);
OK
Time taken: 0.848 seconds
hive&amp;gt; describe tt partition (b=&lt;span class=&quot;code-quote&quot;&gt;&apos;part1&apos;&lt;/span&gt;);          
OK
a	string	
b	string	
Time taken: 0.071 seconds
hive&amp;gt; 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Above suggests that partition did inherit the columns from table. If the bug as you described is present, then partition won&apos;t have column information?&lt;/p&gt;</comment>
                            <comment id="13420721" author="traviscrawford" created="Mon, 23 Jul 2012 15:37:54 +0000"  >&lt;p&gt;I believe the issue happens with serde-reported columns; it works correctly as you pointed out when explicit columns are sued.&lt;/p&gt;

&lt;p&gt;Consider the following. I believe the correct behavior is for part1 to inherit the table columns. Here we see part1 only has the partition key.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;hive&amp;gt; create external table int_string
  partitioned by (b string)
  row format serde &lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.hadoop.hive.serde2.thrift.ThriftDeserializer&quot;&lt;/span&gt;
  with serdeproperties (
    &lt;span class=&quot;code-quote&quot;&gt;&quot;serialization.class&quot;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.hadoop.hive.serde2.thrift.test.IntString&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;serialization.format&quot;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.thrift.protocol.TBinaryProtocol&quot;&lt;/span&gt;);
OK
Time taken: 0.203 seconds
hive&amp;gt; describe int_string;
OK
myint	&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;	from deserializer
mystring	string	from deserializer
underscore_int	&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;	from deserializer
b	string	
Time taken: 0.098 seconds
hive&amp;gt; alter table int_string add partition (b=&lt;span class=&quot;code-quote&quot;&gt;&apos;part1&apos;&lt;/span&gt;);
OK
Time taken: 0.154 seconds
hive&amp;gt; describe int_string partition (b=&lt;span class=&quot;code-quote&quot;&gt;&apos;part1&apos;&lt;/span&gt;);       
OK
b	string	
Time taken: 0.072 seconds
hive&amp;gt; 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13420724" author="traviscrawford" created="Mon, 23 Jul 2012 15:43:03 +0000"  >&lt;p&gt;Applying the above change and rerunning these statements causes the partition to have dynamically-reported columns:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;Proposed behavior: partition has correct columns with above change&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;hive&amp;gt; create external table int_string
    &amp;gt;   partitioned by (b string)
    &amp;gt;   row format serde &lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.hadoop.hive.serde2.thrift.ThriftDeserializer&quot;&lt;/span&gt;
    &amp;gt;   with serdeproperties (
    &amp;gt;     &lt;span class=&quot;code-quote&quot;&gt;&quot;serialization.class&quot;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.hadoop.hive.serde2.thrift.test.IntString&quot;&lt;/span&gt;,
    &amp;gt;     &lt;span class=&quot;code-quote&quot;&gt;&quot;serialization.format&quot;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.thrift.protocol.TBinaryProtocol&quot;&lt;/span&gt;);
OK
Time taken: 0.085 seconds
hive&amp;gt; alter table int_string add partition (b=&lt;span class=&quot;code-quote&quot;&gt;&apos;part1&apos;&lt;/span&gt;);
OK
Time taken: 0.128 seconds
hive&amp;gt; describe int_string partition (b=&lt;span class=&quot;code-quote&quot;&gt;&apos;part1&apos;&lt;/span&gt;);     
OK
myint	&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;	from deserializer
mystring	string	from deserializer
underscore_int	&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;	from deserializer
b	string	
Time taken: 0.09 seconds
hive&amp;gt; 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13420809" author="ashutoshc" created="Mon, 23 Jul 2012 17:37:44 +0000"  >&lt;p&gt;Interesting. There seems to be no code in &lt;tt&gt;ql.metadata&lt;/tt&gt; that can bring this kind of discrepancy, so wondering why difference in behavior for serde reported columns Vs regular code.&lt;/p&gt;</comment>
                            <comment id="13420819" author="traviscrawford" created="Mon, 23 Jul 2012 17:53:32 +0000"  >&lt;p&gt;Looking at &lt;a href=&quot;https://github.com/apache/hive/blob/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java#L121&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Table.getEmptyTable&lt;/a&gt; we see:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sd.setCols(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;FieldSchema&amp;gt;());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;What I believe happens is a new empty table is created, which initializes an empty list of columns. No columns are actually set, because the serde reports them at runtime.&lt;/p&gt;

&lt;p&gt;Later, when initializing a Partition we check if the storage descriptor has null for its columns. It actually has the empty list copied from the empty table (not null) and we do not copy the table schema into the partition.&lt;/p&gt;

&lt;p&gt;Typically tables/partitions have an explicitly defined schema so maybe this use-case just hasn&apos;t come up? If you explicitly define the schema things work as expected.&lt;/p&gt;</comment>
                            <comment id="13420840" author="ashutoshc" created="Mon, 23 Jul 2012 18:19:38 +0000"  >&lt;blockquote&gt;&lt;p&gt;Later, when initializing a Partition we check if the storage descriptor has null for its columns. It actually has the empty list copied from the empty table (not null) and we do not copy the table schema into the partition.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is true even for regular columns, not only for serde reported columns. How in non-serde case, partition gets the columns from table then ?&lt;/p&gt;</comment>
                            <comment id="13420880" author="traviscrawford" created="Mon, 23 Jul 2012 19:09:36 +0000"  >&lt;p&gt;In both the serde-reported &amp;amp; non-serde cases, the table schema is copied into the partition storage descriptor. If the schema was explicitly defined, there&apos;s no need to copy it from the table so things work correctly.&lt;/p&gt;

&lt;p&gt;I can&apos;t actually generate a test case where the partition storage descriptor cols are null &#8211;&#160;its either the list of explicitly defined fields, or an empty list when serde-reported.&lt;/p&gt;

&lt;p&gt;Any ideas how to explicitly define fields for the table, but not have them copied into the partition storage descriptor?&lt;/p&gt;

&lt;p&gt;To double-check - do you think the current serde-reported schema behavior is a bug? If so, I&apos;m very interested in helping figure this one out. It feels like a simple issue where perhaps the table cols should be initialized to null instead of an empty list, or the empty list should be accommodated when choosing to copy the table schema.&lt;/p&gt;</comment>
                            <comment id="13421823" author="traviscrawford" created="Tue, 24 Jul 2012 22:13:13 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt; - fixing this issue is pretty high priority for me, any thoughts on next steps?&lt;/p&gt;</comment>
                            <comment id="13422103" author="ashutoshc" created="Wed, 25 Jul 2012 09:09:25 +0000"  >&lt;p&gt;@Travis,&lt;br/&gt;
Yeah, this fix is required. Can you prepare a patch for it. Also, include the testcase which you have in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3279?focusedCommentId=13420724&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13420724&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-3279?focusedCommentId=13420724&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13420724&lt;/a&gt; in the patch&lt;/p&gt;</comment>
                            <comment id="13422385" author="traviscrawford" created="Wed, 25 Jul 2012 16:28:59 +0000"  >&lt;p&gt;Differential review: &lt;a href=&quot;https://reviews.facebook.net/D4329&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4329&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13422958" author="ashutoshc" created="Thu, 26 Jul 2012 08:22:42 +0000"  >&lt;p&gt;+1 running tests.&lt;/p&gt;</comment>
                            <comment id="13423170" author="ashutoshc" created="Thu, 26 Jul 2012 15:59:00 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Travis!&lt;/p&gt;</comment>
                            <comment id="13423663" author="hudson" created="Fri, 27 Jul 2012 04:21:51 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1569 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1569/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1569/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3279&quot; title=&quot;Table schema not being copied to Partitions with no columns&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3279&quot;&gt;&lt;del&gt;HIVE-3279&lt;/del&gt;&lt;/a&gt;: Table schema not being copied to Partitions with no columns (Travis Crawford via Ashutosh Chauhan) (Revision 1366058)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1366058&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1366058&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/serde_reported_schema.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/serde_reported_schema.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13548120" author="hudson" created="Wed, 9 Jan 2013 10:24:28 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #54 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3279&quot; title=&quot;Table schema not being copied to Partitions with no columns&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3279&quot;&gt;&lt;del&gt;HIVE-3279&lt;/del&gt;&lt;/a&gt;: Table schema not being copied to Partitions with no columns (Travis Crawford via Ashutosh Chauhan) (Revision 1366058)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1366058&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1366058&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/serde_reported_schema.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/serde_reported_schema.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13549995" author="ashutoshc" created="Thu, 10 Jan 2013 19:52:58 +0000"  >&lt;p&gt;This issue is fixed and released as part of 0.10.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12560824">HIVE-3144</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12537850" name="HIVE-3279_serde_reported_partition_schema.1.patch" size="3330" author="traviscrawford" created="Wed, 25 Jul 2012 16:27:47 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 22 Jul 2012 19:37:07 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>259159</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 2 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ln6n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>124406</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3280] Make HiveMetaStoreClient a public API</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3280</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12599538">HIVE-3280</key>
            <summary>Make HiveMetaStoreClient a public API</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="thejas">Thejas M Nair</assignee>
                                    <reporter username="cwsteinbach">Carl Steinbach</reporter>
                        <labels>
                            <label>api-addition</label>
                    </labels>
                <created>Thu, 19 Jul 2012 21:37:34 +0000</created>
                <updated>Thu, 19 Feb 2015 18:22:06 +0000</updated>
                            <resolved>Mon, 26 Jan 2015 19:05:35 +0000</resolved>
                                                    <fixVersion>1.0.0</fixVersion>
                                    <component>Metastore</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>10</watches>
                                                                <comments>
                            <comment id="13418693" author="cwsteinbach" created="Thu, 19 Jul 2012 21:39:24 +0000"  >&lt;p&gt;At the moment HiveMetaStoreClient is treated as a de-facto public API. We should make this official and provide better documentation.&lt;/p&gt;</comment>
                            <comment id="14281982" author="brocknoland" created="Sun, 18 Jan 2015 22:12:41 +0000"  >&lt;p&gt;Linking to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-9363&quot; title=&quot;Document the Public Hive API&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-9363&quot;&gt;HIVE-9363&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14290351" author="alangates" created="Sat, 24 Jan 2015 01:41:04 +0000"  >&lt;p&gt;+1, evolving makes sense for this since we seem to change it almost every release.&lt;/p&gt;</comment>
                            <comment id="14290518" author="hiveqa" created="Sat, 24 Jan 2015 09:57:21 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12694317/HIVE-3280.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12694317/HIVE-3280.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 6 failed/errored test(s), 7366 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hive.spark.client.TestSparkClient.testAddJarsAndFiles
org.apache.hive.spark.client.TestSparkClient.testCounters
org.apache.hive.spark.client.TestSparkClient.testErrorJob
org.apache.hive.spark.client.TestSparkClient.testJobSubmission
org.apache.hive.spark.client.TestSparkClient.testMetricsCollection
org.apache.hive.spark.client.TestSparkClient.testSimpleSparkJob
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2505/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2505/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2505/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/2505/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2505/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-2505/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 6 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12694317 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14291515" author="thejas" created="Mon, 26 Jan 2015 06:51:50 +0000"  >&lt;p&gt;The failures are unrelated and are seen in some other builds as well.&lt;/p&gt;</comment>
                            <comment id="14292244" author="thejas" created="Mon, 26 Jan 2015 19:05:35 +0000"  >&lt;p&gt;Patch committed to trunk, 0.14 and branch-1.&lt;/p&gt;</comment>
                            <comment id="14327540" author="thejas" created="Thu, 19 Feb 2015 14:44:54 +0000"  >&lt;p&gt;Updating release version for jiras resolved in 1.0.0 .&lt;/p&gt;</comment>
                            <comment id="14327890" author="thejas" created="Thu, 19 Feb 2015 18:22:06 +0000"  >&lt;p&gt;This issue has been fixed in Apache Hive 1.0.0. If there is any issue with the fix, please open a new jira to address it.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12767259">HIVE-9363</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12599533">HIVE-3278</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12694317" name="HIVE-3280.1.patch" size="7054" author="thejas" created="Sat, 24 Jan 2015 01:20:59 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 18 Jan 2015 22:12:41 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>247670</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 48 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08np3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>48438</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3281] Alter table ignores table/partition not existing in semantic analysis</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3281</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;In the method addInputsOutputsAlterTable in the DDLSemanticAnalyzer we get the table and partition being altered from the metastore.  Failures to get these are quietly ignored, even though they resurface during query execution.  We can throw a semantic exception here instead of ignoring them and save some time/resources.  Also, by doing it here we save on retrieving the table/partition from the metastore since we&apos;re doing it here already.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599550">HIVE-3281</key>
            <summary>Alter table ignores table/partition not existing in semantic analysis</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="kevinwilfong">Kevin Wilfong</assignee>
                                    <reporter username="kevinwilfong">Kevin Wilfong</reporter>
                        <labels>
                    </labels>
                <created>Thu, 19 Jul 2012 23:02:09 +0000</created>
                <updated>Thu, 19 Jul 2012 23:02:09 +0000</updated>
                                            <version>0.10.0</version>
                                                    <component>Logging</component>
                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>259160</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 27 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ln6v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>124407</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-3282] Convert runtime exceptions to semantic exceptions for missing partitions/tables in show/describe statements</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3282</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The SHOW PARTITIONS command in Hive does not check for valid table and partition names during query compilation. Calling this command with non-existent table causes a run-time exception.&lt;/p&gt;

&lt;p&gt;The DESC command also does not check for this in semantic analysis.&lt;/p&gt;

&lt;p&gt;hive&amp;gt; desc xxxyyy;&lt;br/&gt;
OK&lt;br/&gt;
Table xxxyyy does not exist&lt;br/&gt;
Time taken: 1.403 seconds&lt;/p&gt;

&lt;p&gt;hive&amp;gt; show partitions xxxyyy;&lt;br/&gt;
Table xxxyyy does not exist&lt;br/&gt;
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599551">HIVE-3282</key>
            <summary>Convert runtime exceptions to semantic exceptions for missing partitions/tables in show/describe statements</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sambavi">Sambavi Muthukrishnan</assignee>
                                    <reporter username="sambavi">Sambavi Muthukrishnan</reporter>
                        <labels>
                    </labels>
                <created>Thu, 19 Jul 2012 23:07:01 +0000</created>
                <updated>Wed, 6 Feb 2013 09:23:50 +0000</updated>
                            <resolved>Thu, 2 Aug 2012 05:09:37 +0000</resolved>
                                    <version>0.9.0</version>
                                    <fixVersion>0.10.0</fixVersion>
                                    <component>Query Processor</component>
                        <due>Mon, 23 Jul 2012 00:00:00 +0000</due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                    <timeoriginalestimate seconds="86400">24h</timeoriginalestimate>
                            <timeestimate seconds="86400">24h</timeestimate>
                                        <comments>
                            <comment id="13426348" author="sambavi" created="Wed, 1 Aug 2012 06:20:24 +0000"  >&lt;p&gt;Code review is at &lt;a href=&quot;https://reviews.facebook.net/D4467&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4467&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13427095" author="namit" created="Thu, 2 Aug 2012 03:50:49 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13427115" author="namit" created="Thu, 2 Aug 2012 05:09:37 +0000"  >&lt;p&gt;Committed. Thanks Sambavi&lt;/p&gt;</comment>
                            <comment id="13427305" author="hudson" created="Thu, 2 Aug 2012 13:24:29 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1586 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1586/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1586/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3282&quot; title=&quot;Convert runtime exceptions to semantic exceptions for missing partitions/tables in show/describe statements&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3282&quot;&gt;&lt;del&gt;HIVE-3282&lt;/del&gt;&lt;/a&gt; Convert runtime exceptions to semantic exceptions for missing partitions/tables&lt;br/&gt;
in show/describe statements (Sambavi Muthukrishnan via namit) (Revision 1368352)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
namit : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1368352&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1368352&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/desc_failure1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/desc_failure2.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/show_partitions1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/show_tableproperties1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/desc_non_existent_tbl.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/inputddl6.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/show_tblproperties.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/desc_failure1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/desc_failure2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/show_partitions1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/show_tableproperties1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/show_tables_bad_db1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/show_tables_bad_db2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/show_tablestatus.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/show_tablestatus_not_existing_part.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/desc_non_existent_tbl.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/inputddl6.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/show_tblproperties.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13427588" author="cwsteinbach" created="Thu, 2 Aug 2012 20:34:36 +0000"  >&lt;p&gt;Correcting the fixversion field.&lt;/p&gt;</comment>
                            <comment id="13548153" author="hudson" created="Wed, 9 Jan 2013 10:24:37 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #54 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3282&quot; title=&quot;Convert runtime exceptions to semantic exceptions for missing partitions/tables in show/describe statements&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3282&quot;&gt;&lt;del&gt;HIVE-3282&lt;/del&gt;&lt;/a&gt; Convert runtime exceptions to semantic exceptions for missing partitions/tables&lt;br/&gt;
in show/describe statements (Sambavi Muthukrishnan via namit) (Revision 1368352)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
namit : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1368352&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1368352&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/desc_failure1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/desc_failure2.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/show_partitions1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/show_tableproperties1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/desc_non_existent_tbl.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/inputddl6.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/show_tblproperties.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/desc_failure1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/desc_failure2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/show_partitions1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/show_tableproperties1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/show_tables_bad_db1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/show_tables_bad_db2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/show_tablestatus.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/show_tablestatus_not_existing_part.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/desc_non_existent_tbl.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/inputddl6.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/show_tblproperties.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13550129" author="ashutoshc" created="Thu, 10 Jan 2013 19:53:29 +0000"  >&lt;p&gt;This issue is fixed and released as part of 0.10.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12631027">HIVE-3991</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12538649" name="HIVE-3282.1.patch" size="12935" author="sambavi" created="Wed, 1 Aug 2012 06:22:15 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 2 Aug 2012 03:50:49 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>259161</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 2 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ln73:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>124408</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3283] bucket information should be used from the partition instead of the table</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3283</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently Hive uses the number of buckets from the table object.&lt;br/&gt;
Ideally, the number of buckets from the partition should be used&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599574">HIVE-3283</key>
            <summary>bucket information should be used from the partition instead of the table</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="kevinwilfong">Kevin Wilfong</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Fri, 20 Jul 2012 04:15:46 +0000</created>
                <updated>Thu, 10 Jan 2013 19:53:47 +0000</updated>
                            <resolved>Sat, 15 Sep 2012 15:27:03 +0000</resolved>
                                    <version>0.10.0</version>
                                    <fixVersion>0.10.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13449502" author="namit" created="Thu, 6 Sep 2012 07:51:17 +0000"  >&lt;p&gt;Once &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3171&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-3171&lt;/a&gt; is in, it would be useful to have the partition metadata be used for bucketing information.&lt;/p&gt;</comment>
                            <comment id="13452345" author="kevinwilfong" created="Mon, 10 Sep 2012 19:27:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.facebook.net/D5319&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D5319&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13452346" author="kevinwilfong" created="Mon, 10 Sep 2012 19:27:48 +0000"  >&lt;p&gt;With the recent improvements to bucketing and sorting made primarily by Namit and Navis recently, this already seems like it&apos;s supported, it&apos;s just a matter of making the switch to use partition metadata.&lt;/p&gt;

&lt;p&gt;I re-enabled allowing users to change the number of buckets/bucketed and sorted columns of a partitioned table containing data (otherwise this change won&apos;t provide much benefit).&lt;/p&gt;</comment>
                            <comment id="13452757" author="namit" created="Tue, 11 Sep 2012 06:17:47 +0000"  >&lt;p&gt;comments on phabricator&lt;/p&gt;</comment>
                            <comment id="13453392" author="kevinwilfong" created="Tue, 11 Sep 2012 20:42:50 +0000"  >&lt;p&gt;Updated according to comments on phabricator.&lt;/p&gt;</comment>
                            <comment id="13453702" author="namit" created="Wed, 12 Sep 2012 04:39:15 +0000"  >&lt;p&gt;comments on phabricator&lt;/p&gt;</comment>
                            <comment id="13455971" author="kevinwilfong" created="Fri, 14 Sep 2012 17:32:18 +0000"  >&lt;p&gt;Updated according to comments on phabricator.&lt;/p&gt;</comment>
                            <comment id="13456322" author="namit" created="Sat, 15 Sep 2012 05:07:40 +0000"  >&lt;p&gt;+1 &lt;br/&gt;
running tests&lt;/p&gt;</comment>
                            <comment id="13456428" author="namit" created="Sat, 15 Sep 2012 15:27:03 +0000"  >&lt;p&gt;Committed. Thanks Kevin&lt;/p&gt;</comment>
                            <comment id="13456499" author="hudson" created="Sat, 15 Sep 2012 22:24:01 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1671 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1671/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1671/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3283&quot; title=&quot;bucket information should be used from the partition instead of the table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3283&quot;&gt;&lt;del&gt;HIVE-3283&lt;/del&gt;&lt;/a&gt; bucket information should be used from the partition instead of the table&lt;br/&gt;
(Kevin Wilfong via namit) (Revision 1385084)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
namit : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1385084&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1385084&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/alter_numbuckets_partitioned_table.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/alter_numbuckets_partitioned_table.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/bucketmapjoin10.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/bucketmapjoin11.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/bucketmapjoin12.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/bucketmapjoin8.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/bucketmapjoin9.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/sort_merge_join_desc_5.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/sort_merge_join_desc_6.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/sort_merge_join_desc_7.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/alter_numbuckets_partitioned_table.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/alter_numbuckets_partitioned_table.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin10.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin11.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin12.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin8.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin9.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sort_merge_join_desc_5.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sort_merge_join_desc_6.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sort_merge_join_desc_7.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13548151" author="hudson" created="Wed, 9 Jan 2013 10:24:36 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #54 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3283&quot; title=&quot;bucket information should be used from the partition instead of the table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3283&quot;&gt;&lt;del&gt;HIVE-3283&lt;/del&gt;&lt;/a&gt; bucket information should be used from the partition instead of the table&lt;br/&gt;
(Kevin Wilfong via namit) (Revision 1385084)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
namit : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1385084&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1385084&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/alter_numbuckets_partitioned_table.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/alter_numbuckets_partitioned_table.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/bucketmapjoin10.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/bucketmapjoin11.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/bucketmapjoin12.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/bucketmapjoin8.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/bucketmapjoin9.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/sort_merge_join_desc_5.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/sort_merge_join_desc_6.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/sort_merge_join_desc_7.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/alter_numbuckets_partitioned_table.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/alter_numbuckets_partitioned_table.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin10.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin11.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin12.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin8.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin9.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sort_merge_join_desc_5.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sort_merge_join_desc_6.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sort_merge_join_desc_7.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13550206" author="ashutoshc" created="Thu, 10 Jan 2013 19:53:47 +0000"  >&lt;p&gt;This issue is fixed and released as part of 0.10.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12598937">HIVE-3261</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12604358">HIVE-3403</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12544512" name="HIVE-3283.1.patch.txt" size="155589" author="kevinwilfong" created="Mon, 10 Sep 2012 19:28:22 +0000"/>
                            <attachment id="12544703" name="HIVE-3283.2.patch.txt" size="205953" author="kevinwilfong" created="Tue, 11 Sep 2012 20:42:25 +0000"/>
                            <attachment id="12545178" name="HIVE-3283.3.patch.txt" size="213704" author="kevinwilfong" created="Fri, 14 Sep 2012 17:31:43 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 10 Sep 2012 19:27:35 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>259162</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 2 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ln7b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>124409</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3284] create ExecutionException(s)</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3284</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Hive currently contains SemanticExceptions for all compile time exceptions.&lt;br/&gt;
It might be a good idea to create ExecutionExceptions to get the list&lt;br/&gt;
of all execution exceptions.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599577">HIVE-3284</key>
            <summary>create ExecutionException(s)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Fri, 20 Jul 2012 05:04:52 +0000</created>
                <updated>Fri, 20 Jul 2012 15:54:54 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13419282" author="ashutoshc" created="Fri, 20 Jul 2012 15:54:54 +0000"  >&lt;p&gt;+1 Would immensely increase diagnosability. &lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 20 Jul 2012 15:54:54 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>259163</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 27 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ln7j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>124410</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-3285] Create self-contained fat JAR for JDBC driver</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3285</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12599586">HIVE-3285</key>
            <summary>Create self-contained fat JAR for JDBC driver</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="cwsteinbach">Carl Steinbach</reporter>
                        <labels>
                    </labels>
                <created>Fri, 20 Jul 2012 07:32:15 +0000</created>
                <updated>Fri, 20 Jul 2012 20:58:21 +0000</updated>
                            <resolved>Fri, 20 Jul 2012 19:42:16 +0000</resolved>
                                                                    <component>JDBC</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13418984" author="cwsteinbach" created="Fri, 20 Jul 2012 07:33:38 +0000"  >&lt;p&gt;The Hive JDBC driver JAR currently depends on most of the other Hive JARs. This is very inconvenient from a deployment standpoint. We should create a fat jar for the JDBC driver in order to simplify deployment.&lt;/p&gt;</comment>
                            <comment id="13419250" author="ashutoshc" created="Fri, 20 Jul 2012 15:23:08 +0000"  >&lt;p&gt;Dupe of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-538&quot; title=&quot;make hive_jdbc.jar self-containing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-538&quot;&gt;&lt;del&gt;HIVE-538&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="13419492" author="cwsteinbach" created="Fri, 20 Jul 2012 19:42:16 +0000"  >&lt;p&gt;@Ashutosh: Good catch.&lt;/p&gt;</comment>
                            <comment id="13419562" author="ashutoshc" created="Fri, 20 Jul 2012 20:58:21 +0000"  >&lt;p&gt;Now, would you consider &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-538&quot; title=&quot;make hive_jdbc.jar self-containing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-538&quot;&gt;&lt;del&gt;HIVE-538&lt;/del&gt;&lt;/a&gt; for commit, given that its open since 2009 : )&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12427046">HIVE-538</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 20 Jul 2012 15:23:08 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>259164</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 27 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ln7r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>124411</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3286] Explicit skew join on user provided condition</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3286</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Join operation on table with skewed data takes most of execution time handling the skewed keys. But mostly we already know about that and even know what is look like the skewed keys.&lt;/p&gt;

&lt;p&gt;If we can explicitly assign reducer slots for the skewed keys, total execution time could be greatly shortened.&lt;/p&gt;

&lt;p&gt;As for a start, I&apos;ve extended join grammar something like this.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;select * from src a join src b on a.key=b.key skew on (a.key+1 &amp;lt; 50, a.key+1 &amp;lt; 100, a.key &amp;lt; 150);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;which means if above query is executed by 20 reducers, one reducer for a.key+1 &amp;lt; 50, one reducer for 50 &amp;lt;= a.key+1 &amp;lt; 100, one reducer for 99 &amp;lt;= a.key &amp;lt; 150, and 17 reducers for others (could be extended to assign more than one reducer later)&lt;/p&gt;

&lt;p&gt;This can be only used with common-inner-equi joins. And skew condition should be composed of join keys only.&lt;/p&gt;

&lt;p&gt;Work till done now will be updated shortly after code cleanup.&lt;/p&gt;


&lt;p&gt;----------------------------&lt;/p&gt;


&lt;p&gt;All expressions in the clause &quot;SKEW ON (expr1, expr2, ...)&quot; are called skew condition and consist of skew expression*, which is simple boolean expression for the group and optional CLUSTER/DISTRIBUTED expression. Skew expressions will be evaluated sequentially at runtime, deciding skew group for a row. Each skew group has reserved partition slot(s), to which all rows in a group would be assigned. &lt;/p&gt;

&lt;p&gt;The number of partition slot reserved for each skew group is decided by cluster expression. Before submitting the MR job, hive calculates size of each skew groups. If a skew group is &quot;CLUSTER BY 20 PERCENT&quot; and total partition slot (=number of reducer) is, say, 20, the group will reserve 4 partition slots for it, etc.&lt;/p&gt;

&lt;p&gt;The optional &quot;DISTRIBUTE BY&quot; decides how the rows in a skew group is dispersed in the range of reserved slots (If there is only one slot for a group, this is meaningless). Currently, three distribution policies are available: RANDOM, KEYS, &amp;lt;expression&amp;gt;. &lt;br/&gt;
1. RANDOM : rows from driver alias** are dispersed by random and rows of other aliases are multicasted to all slots (default behavior)&lt;br/&gt;
2. KEYS : rows from driver alias are dispersed by hash of keys same for &lt;br/&gt;
3. expression : determined by evaluation result of user-provided expression&lt;/p&gt;

&lt;p&gt;Only possible with inner, equi, common-joins. Not yet supports join tree merging or vectorization.&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Might be used by other RS users like &quot;SORT BY&quot; or &quot;GROUP BY&quot; (not-yet)&lt;/li&gt;
	&lt;li&gt;If there are column statistics for the skewness of the key, it could be possible applied automatically (not-yet)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;For example, if 20 reducers are used for the query below,&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;select count(*) from src a join src b on a.key=b.key skew on (
   a.key = &lt;span class=&quot;code-quote&quot;&gt;&apos;0&apos;&lt;/span&gt; CLUSTER BY 10 PERCENT,
   b.key &amp;lt; &lt;span class=&quot;code-quote&quot;&gt;&apos;100&apos;&lt;/span&gt; CLUSTER BY 20 PERCENT DISTRIBUTE BY upper(b.key),
   &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(a.key as &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) &amp;gt; 300 CLUSTER BY 40 PERCENT DISTRIBUTE BY KEYS);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Skew group-0 would reserve 2 slots (#6~#7), for group-1, 4 slots (#8~#11), for group-2, 8 slots (#12~#19) and others will use remaining 6 slots (#0~#5).&lt;/p&gt;

&lt;p&gt;For key=&apos;0&apos; from alias a(driver alias), it will be assigned to a slot of group-0 : 6 or 7&lt;br/&gt;
For key=&apos;0&apos; from alias b(non-driver alias), it will be multicasted to all slots of group-0 : 6 and 7&lt;/p&gt;

&lt;p&gt;For key=&apos;50&apos; from alias a(non-driver alias), it will be multicasted to all slots of group-1 : 8 and 9 and 10 and 11&lt;br/&gt;
For key=&apos;50&apos; from alias b(driver alias), it will be assigned to a slot of group-1 : 8 or 9 or 10 or 11&lt;/p&gt;

&lt;p&gt;For key=&apos;500&apos; from alias a(driver alias), it will be assigned to a slot of group-2 by modulation of hashcode of DISTRIBUTE expression&lt;br/&gt;
For key=&apos;500&apos; from alias b(non-driver alias), it will be multicasted to all slots of group-2 : #12~#19&lt;/p&gt;

&lt;p&gt;For key=&apos;200&apos;, it&apos;s not belong to any skew group and will be processed normally in the range of partition slot 0~5.&lt;/p&gt;

&lt;p&gt;*skew expression : &lt;br/&gt;
1. all expressions should be made of expression in join condition, which means if join condition is &quot;a.key=b.key&quot;, user can make any expression with &quot;a.key&quot; or &quot;b.key&quot;. But if join condition is a.key+1=b.key, user cannot make expression with &quot;a.key&quot; solely (or make expression with &quot;a.key+1&quot;). &lt;br/&gt;
2. all expressions should reference one and only-one side of aliases. For example, simple constant expressions or expressions referencing both side of join condition (&quot;a.key+b.key&amp;lt;100&quot;) is not allowed.&lt;br/&gt;
3. all functions in expression should be deterministic and stateless.&lt;br/&gt;
4. DISTRIBUTED expression should have same alias with skew expression.&lt;/p&gt;

&lt;p&gt;**driver alias :&lt;br/&gt;
1. driver alias means the sole referenced alias from skew expression, which is important for RANDOM distribution. Rows from driver alias are assigned to one slot, but rows from other aliases will be multicasted to all slots of the group. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12599592">HIVE-3286</key>
            <summary>Explicit skew join on user provided condition</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png" description="A patch for this issue has been uploaded to JIRA by a contributor.">Patch Available</status>
                    <statusCategory id="4" key="indeterminate" colorName="yellow"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="navis">Navis</assignee>
                                    <reporter username="navis">Navis</reporter>
                        <labels>
                    </labels>
                <created>Fri, 20 Jul 2012 07:49:39 +0000</created>
                <updated>Mon, 6 Oct 2014 05:28:10 +0000</updated>
                                                                            <component>Query Processor</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>12</watches>
                                                                <comments>
                            <comment id="13419027" author="namit" created="Fri, 20 Jul 2012 09:49:10 +0000"  >&lt;p&gt;Navis, Nadeem is already working on this in a different approach&lt;br/&gt;
&lt;a href=&quot;https://cwiki.apache.org/Hive/skewed-join-optimization.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/Hive/skewed-join-optimization.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I am not sure if there is a jira, but I know he is pretty close to getting one out.&lt;/p&gt;</comment>
                            <comment id="13419040" author="navis" created="Fri, 20 Jul 2012 10:25:57 +0000"  >&lt;p&gt;The idea of this issue was conceived couple of months ago and I&apos;ve seen the document later. I love the systemic approach in it.&lt;/p&gt;

&lt;p&gt;I&apos;ve considered using that but decided to implement this cause this seemed to allow more freedom in schema(without list bucketing).&lt;br/&gt;
If this is not appropriate for hive, I can keep this only for internal use.&lt;/p&gt;</comment>
                            <comment id="13419378" author="nadeemoidu" created="Fri, 20 Jul 2012 17:41:55 +0000"  >&lt;p&gt;Here is the other JIRA &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3086&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-3086&lt;/a&gt; .&lt;br/&gt;
I&apos;m not sure if using the list bucketing schema constricts you (the phrase &quot;list bucketed by&quot; has been removed from it). List bucketing was anyway solving a problem caused by skew, so there was no point expecting the user to give the skew information more than once.&lt;/p&gt;

&lt;p&gt;This seems to be solving a slightly different problem, e.g. I don&apos;t allow ranges.&lt;/p&gt;</comment>
                            <comment id="13419711" author="navis" created="Sat, 21 Jul 2012 00:47:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.facebook.net/D4287&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4287&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Slightly upgraded grammar, for example&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;select * from src a join src b on a.key=b.key skew on
  (a.key+1 &amp;lt; 50 SKEWED BY 30 PERCENT DISTRIBUTE BY a.key-1,
   a.key+1 &amp;lt; 100 SKEWED BY 20 PERCENT,
   a.key &amp;lt; 150);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13420008" author="namit" created="Sun, 22 Jul 2012 00:48:03 +0000"  >&lt;p&gt;@Navis, can you explain the semantics of the above grammar ?&lt;br/&gt;
What doe SKEWED BY, DISTRIBUTE BY imply ?&lt;/p&gt;

&lt;p&gt;Also, in the base case:&lt;/p&gt;

&lt;p&gt;select * from src a join src b on a.key=b.key skew on (a.key+1 &amp;lt; 50, a.key+1 &amp;lt; 100, a.key &amp;lt; 150);&lt;/p&gt;

&lt;p&gt;are you expecting skewed keys for key &amp;lt;= 49.&lt;br/&gt;
Is it true that the skewed keys will only be handled by reducers ?&lt;br/&gt;
If yes, why would it reduce the execution time ? The main advantage should be that reducer wont get any other key, so&lt;br/&gt;
wont be burdened. Is that the idea ?&lt;/p&gt;</comment>
                            <comment id="13420100" author="navis" created="Sun, 22 Jul 2012 03:28:39 +0000"  >&lt;p&gt;This is for assigning some number of reducers exclusively for a key (or group of keys). &lt;/p&gt;

&lt;p&gt;&quot;SKEWED BY 30 PERCENT&quot; means if the total number of reducer for MR is 20, hive assign 20*0.3=6 reducers for the group. If not specified, one reducer is assigned for that group. For above example, resultant partition number of group 1 is distributed in the range of 12~17, group 2 is 18, group 3 is 19, and remaining keys are distributed in the range of 0~11.&lt;/p&gt;

&lt;p&gt;&quot;DISTRIBUTED BY a.key-1&quot; means if partition range is more than 1(like group 1), distribution in the range(12~17) is based on hash of evaluated value by the expression 1.key-1. I think this is not yet enough for real usage.&lt;/p&gt;</comment>
                            <comment id="13423734" author="namit" created="Fri, 27 Jul 2012 08:16:41 +0000"  >&lt;p&gt;  // distributes randomly, disperses non driving aliases to all partitions in the skew group	&lt;br/&gt;
  public static final int SKEW_RULE_RANDOM = 0;&lt;/p&gt;


&lt;p&gt;Why is this needed ?&lt;/p&gt;

&lt;p&gt;I mean, wont it be very expensive ?&lt;/p&gt;



&lt;p&gt;2. KEYS : determined by hash value of keys (same with previous)&lt;br/&gt;
3. expression : determined by hash of object evaluated by user-provided expression&lt;/p&gt;

&lt;p&gt;Wont the above 2 always lead to the same expression ?&lt;/p&gt;


&lt;p&gt;Basically, why is distribute by needed at all ? Cant we always use the KEYS semantics ?&lt;br/&gt;
This seems too confusing.&lt;/p&gt;</comment>
                            <comment id="13423735" author="namit" created="Fri, 27 Jul 2012 08:19:21 +0000"  >&lt;p&gt;Otherwise, I think this is generic and is useful for Hive.&lt;/p&gt;</comment>
                            <comment id="13423808" author="navis" created="Fri, 27 Jul 2012 11:33:07 +0000"  >&lt;p&gt;Most of our queries are driven by big table (500G~) joining small tables (~10G) and big table is heavily skewed with one or a few keys(more than 60%). In this case RANDOM distribution would be very useful in spite of additional cost of duplication. And for small tables, there is not that much for the keys, which minimizes overload of duplication. I&apos;ll post test results later if possible. &lt;/p&gt;

&lt;p&gt;KEYS is distribution by join keys. EXPRESSIONs can be different from that, though should be composed of join keys. I also think this is not so useful option and even removed once. But I added it in final version for just in case.&lt;/p&gt;</comment>
                            <comment id="13423825" author="namit" created="Fri, 27 Jul 2012 11:53:20 +0000"  >&lt;p&gt;But, if you know the skewed keys, cant you create a group for each of the skewed key ?&lt;/p&gt;</comment>
                            <comment id="13423856" author="navis" created="Fri, 27 Jul 2012 13:16:57 +0000"  >&lt;p&gt;I cannot understand exactly what you said &apos;create group for each key&apos;. If it&apos;s something described in &lt;a href=&quot;https://cwiki.apache.org/Hive/skewed-join-optimization.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/Hive/skewed-join-optimization.html&lt;/a&gt;, I should say it&apos;s too difficult for developers who would translate sqls for rdbms to hsql(that&apos;s what I&apos;m supporting).&lt;/p&gt;</comment>
                            <comment id="13424312" author="namit" created="Sat, 28 Jul 2012 10:05:31 +0000"  >&lt;p&gt;I am sorry, I was not clear, what I meant was the following:&lt;/p&gt;

&lt;p&gt;If you know keys 10, 25 and 40 are skewed, accounting for nearly 5%, 6% and 7% of data respectively,&lt;br/&gt;
can&apos;t you issue the following &lt;/p&gt;


&lt;p&gt;select count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; from src a join src b on a.key=b.key skew on (&lt;br/&gt;
   a.key = &apos;10&apos; CLUSTER BY 5 PERCENT,&lt;br/&gt;
   a.key = &apos;25&apos; CLUSTER BY 6 PERCENT,&lt;br/&gt;
   a.key = &apos;40&apos; CLUSTER BY 7 PERCENT);&lt;/p&gt;

&lt;p&gt;I am not clear on why do you need DISTRIBUTE BY ?&lt;/p&gt;

&lt;p&gt;KEYS and EXPRESSIONS should lead to the same distribution.&lt;br/&gt;
Isn&apos;t that right ?&lt;/p&gt;

&lt;p&gt;I am sorry, can you give a clear example of where you see the benefit of using DISTRIBUTE BY ?&lt;/p&gt;</comment>
                            <comment id="13424728" author="navis" created="Mon, 30 Jul 2012 07:35:39 +0000"  >&lt;p&gt;Default is random, which should duplicate rows of small tables.&lt;/p&gt;

&lt;p&gt;When skewing for each key is not so severe, distributing by join key can be enough without duplicating row. For example, logs of last two hour is multiple of others, user can make a group for them and distribute them again by join key.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;select ~~ from logs join errors on logs.hour=errors.hour AND logs.error_seq = errors.error_seq
    skew on (last_two_hour(logs.hour) cluster by 60 PERCENT DISTRIBUTE BY KEYS)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;DISTRIBUTE BY &amp;lt;expression&amp;gt; can provides more control on key distribution. In above case, &quot;DISTRIBUTE BY logs.error_seq&quot; can be used if it would result better distribution.&lt;/p&gt;

&lt;p&gt;After writing to here, I&apos;ve found it&apos;s not so useful. Should I remove it?&lt;/p&gt;</comment>
                            <comment id="13424768" author="namit" created="Mon, 30 Jul 2012 09:14:20 +0000"  >&lt;p&gt;Ya, why dont you remove it ?&lt;/p&gt;</comment>
                            <comment id="13425679" author="namit" created="Tue, 31 Jul 2012 11:21:13 +0000"  >&lt;p&gt;Comments on phabricator&lt;/p&gt;</comment>
                            <comment id="13526138" author="phabricator@reviews.facebook.net" created="Fri, 7 Dec 2012 04:37:19 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3286&quot; title=&quot;Explicit skew join on user provided condition&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3286&quot;&gt;HIVE-3286&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Explicit skew join on user provided condition&quot;.&lt;br/&gt;
Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;  Addressed comments&lt;/p&gt;


&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D4287&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4287&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/SkewedKeyPartitioner.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ReduceSinkDeDuplication.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/QBJoinTree.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/SkewContext.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/skewjoin_explict.q&lt;br/&gt;
  ql/src/test/results/clientpositive/skewjoin_explict.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13539819" author="phabricator@reviews.facebook.net" created="Thu, 27 Dec 2012 04:02:12 +0000"  >&lt;p&gt;njain has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3286&quot; title=&quot;Explicit skew join on user provided condition&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3286&quot;&gt;HIVE-3286&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Explicit skew join on user provided condition&quot;.&lt;/p&gt;

&lt;p&gt;  1. Shouldnt you give an error for outer joins ?&lt;br/&gt;
  2. I think there used to be an optimization in place, where group followed by join on the same key&lt;br/&gt;
      did not require an extra reducer (reduce.dedup - or something like that). Can you add a test for&lt;br/&gt;
      that and make sure it works in that case.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D4287&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4287&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13539871" author="namit" created="Thu, 27 Dec 2012 08:53:51 +0000"  >&lt;p&gt;Comments on phbaricator -&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt;, can you refresh. do some cleanups - address comments.&lt;br/&gt;
This would be really useful.&lt;/p&gt;

&lt;p&gt;remove the syntax:&lt;/p&gt;

&lt;p&gt;a.key = 0 CLUSTER BY 2 PARTITIONS,&lt;/p&gt;



&lt;p&gt;What does the above mean &amp;#8211; not clear.&lt;/p&gt;

&lt;p&gt;Also, can you restructure the code in such a way, that in future if histogram&lt;br/&gt;
data is available for a table (like skewed data), we should be able to convert the&lt;br/&gt;
join to use this ? I mean, this data instead of coming from the query, can come from&lt;br/&gt;
the table metadata.&lt;/p&gt;</comment>
                            <comment id="13539872" author="namit" created="Thu, 27 Dec 2012 08:54:42 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gangtimliu&quot; class=&quot;user-hover&quot; rel=&quot;gangtimliu&quot;&gt;Gang Tim Liu&lt;/a&gt;, it would be useful if you can come up with a way to store the histogram data for a table.&lt;br/&gt;
The skew join should be automatically able to use that.&lt;/p&gt;</comment>
                            <comment id="13540247" author="phabricator@reviews.facebook.net" created="Fri, 28 Dec 2012 00:54:12 +0000"  >&lt;p&gt;navis has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3286&quot; title=&quot;Explicit skew join on user provided condition&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3286&quot;&gt;HIVE-3286&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Explicit skew join on user provided condition&quot;.&lt;/p&gt;

&lt;p&gt;  1. I think this is a kind of join hint. So just disabled if it&apos;s not possible (outer join, invalid expression, etc.).&lt;br/&gt;
  2. RS dedup does not applied when child RS is for GBY or JOIN. Test for JOIN+SORTBY case will be added.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D4287&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4287&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13540252" author="phabricator@reviews.facebook.net" created="Fri, 28 Dec 2012 01:06:12 +0000"  >&lt;p&gt;navis has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3286&quot; title=&quot;Explicit skew join on user provided condition&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3286&quot;&gt;HIVE-3286&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Explicit skew join on user provided condition&quot;.&lt;/p&gt;

&lt;p&gt;  RS.dedup does not applied to JOIN-RS case either. Then, could it be enough to remove explicit assigning partition number (a.key = 0 CLUSTER BY 2 PARTITIONS, as you mentioned)?&lt;/p&gt;

&lt;p&gt;  And.. creating a optimizer for skew join would be a really good thing (and also had intent to do it). I think current code base could be simply copied to the optimizer and it seemed not so hard.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D4287&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4287&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13540260" author="phabricator@reviews.facebook.net" created="Fri, 28 Dec 2012 01:34:11 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3286&quot; title=&quot;Explicit skew join on user provided condition&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3286&quot;&gt;HIVE-3286&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Explicit skew join on user provided condition&quot;.&lt;br/&gt;
Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;  Rebased to trunk&lt;br/&gt;
  Removed explicit assigning&lt;/p&gt;


&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D4287&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4287&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/SkewedKeyPartitioner.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ReduceSinkDeDuplication.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/QBJoinTree.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/SkewContext.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/skewjoin_explict.q&lt;br/&gt;
  ql/src/test/results/clientpositive/skewjoin_explict.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13540294" author="phabricator@reviews.facebook.net" created="Fri, 28 Dec 2012 04:24:11 +0000"  >&lt;p&gt;njain has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3286&quot; title=&quot;Explicit skew join on user provided condition&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3286&quot;&gt;HIVE-3286&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Explicit skew join on user provided condition&quot;.&lt;/p&gt;

&lt;p&gt;  Cool, can you move it to a optimization step ?&lt;br/&gt;
  That way, we can also drive it from the table metadata.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/test/queries/clientpositive/skewjoin_explict.q:4 The user should not be setting the partitioner.&lt;/p&gt;

&lt;p&gt;  for SKEWED ON syntax, the partitioner should be automatically chosen&lt;br/&gt;
  ql/src/test/queries/clientpositive/skewjoin_explict.q:63 Add some sub-queries in the tests&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D4287&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4287&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13541204" author="phabricator@reviews.facebook.net" created="Mon, 31 Dec 2012 01:06:12 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3286&quot; title=&quot;Explicit skew join on user provided condition&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3286&quot;&gt;HIVE-3286&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Explicit skew join on user provided condition&quot;.&lt;br/&gt;
Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;  1. Added stub for optimizer (not completed cause I cannot imagine how the histogram look like)&lt;br/&gt;
  2. Skew partitioner is applied automatically&lt;br/&gt;
  3. Added test case&lt;/p&gt;


&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D4287&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4287&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/SkewedKeyPartitioner.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/InlineSkewJoinOptimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/JoinReorder.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ReduceSinkDeDuplication.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/QBJoinTree.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeDescUtils.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/MapredWork.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/SkewContext.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/skewjoin_explict.q&lt;br/&gt;
  ql/src/test/results/clientpositive/skewjoin_explict.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13541209" author="phabricator@reviews.facebook.net" created="Mon, 31 Dec 2012 01:16:12 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3286&quot; title=&quot;Explicit skew join on user provided condition&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3286&quot;&gt;HIVE-3286&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Explicit skew join on user provided condition&quot;.&lt;br/&gt;
Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;  fix mixed merge. my bad.&lt;/p&gt;


&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D4287&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4287&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/SkewedKeyPartitioner.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/InlineSkewJoinOptimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/JoinReorder.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ReduceSinkDeDuplication.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/QBJoinTree.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeDescUtils.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/MapredWork.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/SkewContext.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/skewjoin_explict.q&lt;br/&gt;
  ql/src/test/results/clientpositive/skewjoin_explict.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13545639" author="phabricator@reviews.facebook.net" created="Mon, 7 Jan 2013 05:16:11 +0000"  >&lt;p&gt;njain has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3286&quot; title=&quot;Explicit skew join on user provided condition&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3286&quot;&gt;HIVE-3286&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Explicit skew join on user provided condition&quot;.&lt;/p&gt;

&lt;p&gt;  1. Added stub for optimizer (not completed cause I cannot imagine how the histogram look like)&lt;/p&gt;

&lt;p&gt;  &amp;gt;&amp;gt; call the optimizer. Come up with any definition. This may change over time, but if you dont&lt;br/&gt;
  do this now, it will never get integrated with the table metadata.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/test/queries/clientpositive/skewjoin_explict.q:34 For all the negative stuff, it would be much simpler if an error is thrown instead of&lt;br/&gt;
  silently ignoring the hint. It becomes much easier to debug/enforce in production&lt;br/&gt;
  environment.&lt;br/&gt;
  ql/src/test/queries/clientpositive/skewjoin_explict.q:24 Can you add some tests which select some columns:&lt;/p&gt;

&lt;p&gt;  select .. from&lt;br/&gt;
  (subq1 involving skewed join) s1&lt;br/&gt;
  join&lt;br/&gt;
  (subq2 involving skewed join) s2&lt;br/&gt;
  on join;&lt;/p&gt;


&lt;p&gt;  Add some tests with auto-convert join to true (both where the map-join is picked and&lt;br/&gt;
  the map-join is not picked). Ideally, for map-join, the skew should matter.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/InlineSkewJoinOptimizer.java:51 Is this even being called ?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D4287&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4287&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13545640" author="namit" created="Mon, 7 Jan 2013 05:16:15 +0000"  >&lt;p&gt;comments&lt;/p&gt;</comment>
                            <comment id="13546817" author="phabricator@reviews.facebook.net" created="Tue, 8 Jan 2013 12:04:11 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3286&quot; title=&quot;Explicit skew join on user provided condition&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3286&quot;&gt;HIVE-3286&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Explicit skew join on user provided condition&quot;.&lt;br/&gt;
Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;  Addressed comments&lt;/p&gt;


&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D4287&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4287&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/SkewedKeyPartitioner.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/InlineSkewJoinOptimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/JoinReorder.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/ReduceSinkDeDuplication.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/QBJoinTree.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeDescUtils.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/MapredWork.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/SkewContext.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/NumericHistogram.java&lt;br/&gt;
  ql/src/test/queries/clientnegative/skewjoin_explicit_invalid1.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/skewjoin_explicit_invalid2.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/skewjoin_explicit_invalid3.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/skewjoin_explicit_invalid4.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/skewjoin_explict.q&lt;br/&gt;
  ql/src/test/results/clientnegative/skewjoin_explicit_invalid1.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/skewjoin_explicit_invalid2.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/skewjoin_explicit_invalid3.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/skewjoin_explicit_invalid4.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/skewjoin_explict.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13549151" author="shreepadma" created="Wed, 9 Jan 2013 22:59:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3526&quot; title=&quot;Column Statistics - Add support for equi-height histograms on numeric columns&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3526&quot;&gt;HIVE-3526&lt;/a&gt; covers the task of computing and persisting histograms on numeric columns in Hive tables and partitions. &lt;/p&gt;</comment>
                            <comment id="13745773" author="phabricator@reviews.facebook.net" created="Wed, 21 Aug 2013 04:30:52 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3286&quot; title=&quot;Explicit skew join on user provided condition&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3286&quot;&gt;HIVE-3286&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Explicit skew join on user provided condition&quot;.&lt;/p&gt;

&lt;p&gt;  Rebased to trunk&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D4287&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4287&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D4287?vs=25041&amp;amp;id=38511#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4287?vs=25041&amp;amp;id=38511#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/SkewedKeyPartitioner.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/InlineSkewJoinOptimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/JoinReorder.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/FromClauseParser.g&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/QBJoinTree.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/MapWork.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/MapredWork.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/SkewContext.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/NumericHistogram.java&lt;br/&gt;
  ql/src/test/queries/clientnegative/skewjoin_explicit_invalid1.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/skewjoin_explicit_invalid2.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/skewjoin_explicit_invalid3.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/skewjoin_explicit_invalid4.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/skewjoin_explict.q&lt;br/&gt;
  ql/src/test/results/clientnegative/skewjoin_explicit_invalid1.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/skewjoin_explicit_invalid2.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/skewjoin_explicit_invalid3.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/skewjoin_explicit_invalid4.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/skewjoin_explict.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13831204" author="phabricator@reviews.facebook.net" created="Mon, 25 Nov 2013 06:37:36 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3286&quot; title=&quot;Explicit skew join on user provided condition&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3286&quot;&gt;HIVE-3286&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Explicit skew join on user provided condition&quot;.&lt;/p&gt;

&lt;p&gt;  Rebased to trunk&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D4287&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4287&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D4287?vs=38511&amp;amp;id=44265#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4287?vs=38511&amp;amp;id=44265#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/SkewedKeyPartitioner.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/InlineSkewJoinOptimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/JoinReorder.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/FromClauseParser.g&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/QBJoinTree.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/MapWork.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/SkewContext.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/NumericHistogram.java&lt;br/&gt;
  ql/src/test/queries/clientnegative/skewjoin_explicit_invalid1.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/skewjoin_explicit_invalid2.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/skewjoin_explicit_invalid3.q&lt;br/&gt;
  ql/src/test/queries/clientnegative/skewjoin_explicit_invalid4.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/skewjoin_explicit.q&lt;br/&gt;
  ql/src/test/results/clientnegative/skewjoin_explicit_invalid1.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/skewjoin_explicit_invalid2.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/skewjoin_explicit_invalid3.q.out&lt;br/&gt;
  ql/src/test/results/clientnegative/skewjoin_explicit_invalid4.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/skewjoin_explicit.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: njain&lt;/p&gt;</comment>
                            <comment id="13831383" author="hiveqa" created="Mon, 25 Nov 2013 11:41:29 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12615542/D4287.11.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12615542/D4287.11.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/434/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/434/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/434/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/434/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-434/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&apos;
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20/target shims/assembly/target shims/0.20S/target shims/0.23/target shims/common/target shims/common-secure/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit/target itests/custom-serde/target itests/util/target hcatalog/target hcatalog/storage-handlers/hbase/target hcatalog/server-extensions/target hcatalog/core/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target hcatalog/hcatalog-pig-adapter/target hwi/target common/target common/src/gen common/src/test/org/apache/hadoop/hive/conf/TestHiveConfRestrictList.java service/target contrib/target serde/target beeline/target odbc/target cli/target ql/dependency-reduced-pom.xml ql/target
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1545233.

At revision 1545233.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
patching file ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/SkewedKeyPartitioner.java
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/InlineSkewJoinOptimizer.java
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/JoinReorder.java
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/FromClauseParser.g
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/QBJoinTree.java
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/MapWork.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/SkewContext.java
patching file ql/src/java/org/apache/hadoop/hive/ql/udf/generic/NumericHistogram.java
patching file ql/src/test/queries/clientnegative/skewjoin_explicit_invalid1.q
patching file ql/src/test/queries/clientnegative/skewjoin_explicit_invalid2.q
patching file ql/src/test/queries/clientnegative/skewjoin_explicit_invalid3.q
patching file ql/src/test/queries/clientnegative/skewjoin_explicit_invalid4.q
patching file ql/src/test/queries/clientpositive/skewjoin_explicit.q
patching file ql/src/test/results/clientnegative/skewjoin_explicit_invalid1.q.out
patching file ql/src/test/results/clientnegative/skewjoin_explicit_invalid2.q.out
patching file ql/src/test/results/clientnegative/skewjoin_explicit_invalid3.q.out
patching file ql/src/test/results/clientnegative/skewjoin_explicit_invalid4.q.out
patching file ql/src/test/results/clientpositive/skewjoin_explicit.q.out
+ [[ maven == \m\a\v\e\n ]]
+ rm -rf /data/hive-ptest/working/maven/org/apache/hive
+ mvn -B clean install -DskipTests -Dmaven.repo.local=/data/hive-ptest/working/maven
[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Hive
[INFO] Hive Ant Utilities
[INFO] Hive Shims Common
[INFO] Hive Shims 0.20
[INFO] Hive Shims Secure Common
[INFO] Hive Shims 0.20S
[INFO] Hive Shims 0.23
[INFO] Hive Shims
[INFO] Hive Common
[INFO] Hive Serde
[INFO] Hive Metastore
[INFO] Hive Query Language
[INFO] Hive Service
[INFO] Hive JDBC
[INFO] Hive Beeline
[INFO] Hive CLI
[INFO] Hive Contrib
[INFO] Hive HBase Handler
[INFO] Hive HCatalog
[INFO] Hive HCatalog Core
[INFO] Hive HCatalog Pig Adapter
[INFO] Hive HCatalog Server Extensions
[INFO] Hive HCatalog Webhcat Java Client
[INFO] Hive HCatalog Webhcat
[INFO] Hive HCatalog HBase Storage Handler
[INFO] Hive HWI
[INFO] Hive ODBC
[INFO] Hive Shims Aggregator
[INFO] Hive TestUtils
[INFO] Hive Packaging
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive/0.13.0-SNAPSHOT/hive-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Ant Utilities 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-ant ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/ant (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-ant ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-ant ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-ant ---
[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-svn-trunk-source/ant/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-ant ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-ant ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-ant ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-ant ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-ant ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/hive-ant-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-ant ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ant/target/hive-ant-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-ant/0.13.0-SNAPSHOT/hive-ant-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ant/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-ant/0.13.0-SNAPSHOT/hive-ant-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-common ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/common (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common ---
[INFO] Compiling 15 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-common ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-common ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common/0.13.0-SNAPSHOT/hive-shims-common-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common/0.13.0-SNAPSHOT/hive-shims-common-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.20 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.20 ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20 (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20 ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20 ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20 ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.20 ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.20 ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20/0.13.0-SNAPSHOT/hive-shims-0.20-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20/0.13.0-SNAPSHOT/hive-shims-0.20-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Secure Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-common-secure ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common-secure ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common-secure ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common-secure ---
[INFO] Compiling 12 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/main/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common-secure ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common-secure ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common-secure ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common-secure ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-common-secure ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-common-secure ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common-secure/0.13.0-SNAPSHOT/hive-shims-common-secure-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common-secure/0.13.0-SNAPSHOT/hive-shims-common-secure-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.20S 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.20S ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20S ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20S ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20S ---
[INFO] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/main/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20S ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20S ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20S ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20S ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.20S ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.20S ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20S/0.13.0-SNAPSHOT/hive-shims-0.20S-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20S/0.13.0-SNAPSHOT/hive-shims-0.20S-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.23 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.23 ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23 (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.23 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.23 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.23 ---
[INFO] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/main/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.23 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.23 ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.23 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.23 ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.23 ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.23 ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.23/0.13.0-SNAPSHOT/hive-shims-0.23-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.23/0.13.0-SNAPSHOT/hive-shims-0.23-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims ---
[WARNING] JAR will be empty - no content was marked for inclusion!
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-assembly-plugin:2.3:single (uberjar) @ hive-shims ---
[INFO] Reading assembly descriptor: src/assemble/uberjar.xml
[WARNING] Artifact: org.apache.hive:hive-shims:jar:0.13.0-SNAPSHOT references the same file as the assembly destination file. Moving it to a temporary location for inclusion.
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[WARNING] Configuration options: &apos;appendAssemblyId&apos; is set to false, and &apos;classifier&apos; is missing.
Instead of attaching the assembly file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar, it will become the file for main project artifact.
NOTE: If multiple descriptors or descriptor-formats are provided for this project, the value of this file will be non-deterministic!
[WARNING] Replacing pre-existing project main-artifact file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/archive-tmp/hive-shims-0.13.0-SNAPSHOT.jar
with assembly file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.13.0-SNAPSHOT/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.13.0-SNAPSHOT/hive-shims-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-common ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/common (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-version-annotation) @ hive-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-common ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/common/src/gen added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-common ---
[INFO] Compiling 31 source files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/common/src/java/org/apache/hadoop/hive/common/ObjectPair.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-common ---
[INFO] Compiling 8 source files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-common ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-common ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-common ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-common/0.13.0-SNAPSHOT/hive-common-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/common/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-common/0.13.0-SNAPSHOT/hive-common-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Serde 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-serde ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/serde (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-serde ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/protobuf/gen-java added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-serde ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-serde ---
[INFO] Compiling 351 source files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-serde ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-serde ---
[INFO] Compiling 41 source files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-serde ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-serde ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-serde ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-serde/0.13.0-SNAPSHOT/hive-serde-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/serde/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-serde/0.13.0-SNAPSHOT/hive-serde-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Metastore 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-metastore ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/metastore (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-metastore ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/model added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-metastore ---
[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java
ANTLR Parser Generator  Version 3.4
org/apache/hadoop/hive/metastore/parser/Filter.g
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-metastore ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-metastore ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-metastore ---
[INFO] Compiling 132 source files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- datanucleus-maven-plugin:3.3.0-release:enhance (default) @ hive-metastore ---
[INFO] DataNucleus Enhancer (version 3.2.2) for API &quot;JDO&quot; using JRE &quot;1.6&quot;
DataNucleus Enhancer : Classpath
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-maven-plugin/3.3.0-release/datanucleus-maven-plugin-3.3.0-release.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-utils/3.0.8/plexus-utils-3.0.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-component-annotations/1.5.5/plexus-component-annotations-1.5.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-inject-bean/2.3.0/sisu-inject-bean-2.3.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guice/3.1.0/sisu-guice-3.1.0-no_aop.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guava/0.9.9/sisu-guava-0.9.9.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/xbean/xbean-reflect/3.4/xbean-reflect-3.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/log4j/log4j/1.2.12/log4j-1.2.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-logging/commons-logging-api/1.1/commons-logging-api-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/collections/google-collections/1.0/google-collections-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/junit/junit/3.8.2/junit-3.8.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/tukaani/xz/1.0/xz-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-codec/commons-codec/1.4/commons-codec-1.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/avro/avro/1.7.5/avro-1.7.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-core-asl/1.9.2/jackson-core-asl-1.9.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/guava/guava/11.0.2/guava-11.0.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-lang/commons-lang/2.4/commons-lang-2.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/transaction/jta/1.1/jta-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/antlr/antlr/2.7.7/antlr-2.7.7.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/hadoop/hadoop-core/1.2.1/hadoop-core-1.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/xmlenc/xmlenc/0.52/xmlenc-0.52.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-json/1.14/jersey-json-1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/stax/stax-api/1.0.1/stax-api-1.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/activation/activation/1.1/activation-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/asm/asm/3.1/asm-3.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-io/commons-io/2.4/commons-io-2.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/commons/commons-math/2.1/commons-math-2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-digester/commons-digester/1.8/commons-digester-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/ant/ant/1.6.5/ant-1.6.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-el/commons-el/1.0/commons-el-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/oro/oro/2.0.8/oro-2.0.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-mapper-asl/1.9.2/jackson-mapper-asl-1.9.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/slf4j/slf4j-log4j12/1.7.5/slf4j-log4j12-1.7.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/log4j/log4j/1.2.16/log4j-1.2.16.jar
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDatabase
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFieldSchema
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MType
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTable
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MOrder
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStringList
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartition
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MIndex
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRole
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRoleMap
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MMasterKey
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDelegationToken
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MVersionTable
DataNucleus Enhancer completed with success for 25 classes. Timings : input=589 ms, enhance=931 ms, total=1520 ms. Consult the log for full details

[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-metastore ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-metastore ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-metastore ---
[INFO] Compiling 10 source files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-metastore ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-metastore ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-metastore ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-metastore ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Query Language 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-exec ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/ql (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-sources) @ hive-exec ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-test-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
Generating vector expression code
Generating vector expression test code
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-exec ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/protobuf/gen-java added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-sources/java added.
[INFO] 
[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-exec ---
[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java
ANTLR Parser Generator  Version 3.4
org/apache/hadoop/hive/ql/parse/HiveLexer.g
org/apache/hadoop/hive/ql/parse/HiveParser.g
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:874:5: 
Decision can match input such as &quot;Identifier KW_RENAME KW_TO&quot; using multiple alternatives: 1, 10

As a result, alternative(s) 10 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1179:5: 
Decision can match input such as &quot;KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1179:5: 
Decision can match input such as &quot;KW_ORCFILE&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1179:5: 
Decision can match input such as &quot;KW_TEXTFILE&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1179:5: 
Decision can match input such as &quot;KW_RCFILE&quot; using multiple alternatives: 3, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:23: 
Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:23: 
Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:23: 
Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1199:23: 
Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1199:23: 
Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1199:23: 
Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1217:29: 
Decision can match input such as &quot;KW_FORMATTED KW_PARTITION&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1217:29: 
Decision can match input such as &quot;KW_PRETTY KW_PARTITION&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1217:29: 
Decision can match input such as &quot;KW_PRETTY {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1217:29: 
Decision can match input such as &quot;KW_PRETTY Identifier&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1217:29: 
Decision can match input such as &quot;KW_FORMATTED Identifier&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1217:29: 
Decision can match input such as &quot;KW_FORMATTED {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:116: 
Decision can match input such as &quot;KW_STORED KW_AS KW_DIRECTORIES&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_TEXTFILE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_INPUTFORMAT&quot; using multiple alternatives: 5, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_RCFILE&quot; using multiple alternatives: 3, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_ORCFILE&quot; using multiple alternatives: 4, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): SelectClauseParser.g:149:5: 
Decision can match input such as &quot;KW_NULL DOT Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): SelectClauseParser.g:149:5: 
Decision can match input such as &quot;KW_NULL DOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:147:2: 
Decision can match input such as &quot;KW_LATERAL KW_VIEW KW_OUTER&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:25: 
Decision can match input such as &quot;LPAREN StringLiteral COMMA&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:25: 
Decision can match input such as &quot;LPAREN StringLiteral RPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:25: 
Decision can match input such as &quot;LPAREN StringLiteral EQUAL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_OR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_AND&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL {MINUS, PLUS}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL {DIV..DIVIDE, MOD, STAR}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_WHEN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL BITWISEOR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_EXISTS LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL DOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL RPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN CharSetName CharSetLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LSQUARE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CAST LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_IN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN StringLiteral StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_IS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_BETWEEN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL {KW_LIKE, KW_REGEXP, KW_RLIKE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL EQUAL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL EQUAL_NS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL NOTEQUAL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LESSTHANOREQUALTO&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL AMPERSAND&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL BITWISEXOR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LESSTHAN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_DATE StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL GREATERTHANOREQUALTO&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL GREATERTHAN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:108:5: 
Decision can match input such as &quot;KW_ORDER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:121:5: 
Decision can match input such as &quot;KW_CLUSTER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:133:5: 
Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:144:5: 
Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:155:5: 
Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:172:7: 
Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_DATE StringLiteral&quot; using multiple alternatives: 2, 3

As a result, alternative(s) 3 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:524:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-exec ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1398 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/plan/SkewContext.java:[118,49] cannot find symbol
symbol  : method getRandom()
location: class org.apache.hadoop.hive.ql.io.HiveKey
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [4.600s]
[INFO] Hive Ant Utilities ................................ SUCCESS [6.658s]
[INFO] Hive Shims Common ................................. SUCCESS [3.301s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [2.425s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [2.869s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [1.419s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [3.040s]
[INFO] Hive Shims ........................................ SUCCESS [3.607s]
[INFO] Hive Common ....................................... SUCCESS [6.736s]
[INFO] Hive Serde ........................................ SUCCESS [15.748s]
[INFO] Hive Metastore .................................... SUCCESS [25.108s]
[INFO] Hive Query Language ............................... FAILURE [28.689s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog HBase Storage Handler ............... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1:47.048s
[INFO] Finished at: Mon Nov 25 06:41:27 EST 2013
[INFO] Final Memory: 52M/379M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/plan/SkewContext.java:[118,49] cannot find symbol
[ERROR] symbol  : method getRandom()
[ERROR] location: class org.apache.hadoop.hive.ql.io.HiveKey
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12615542&lt;/p&gt;</comment>
                            <comment id="13832176" author="navis" created="Tue, 26 Nov 2013 01:42:19 +0000"  >&lt;p&gt;Resubmitting to run test.&lt;/p&gt;</comment>
                            <comment id="13832842" author="hiveqa" created="Tue, 26 Nov 2013 18:27:53 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12615766/HIVE-3286.12.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12615766/HIVE-3286.12.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/449/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/449/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/449/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/449/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-449/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf
+ svn update
A    common/src/test/org/apache/hadoop/hive/conf/TestHiveConfRestrictList.java
U    common/src/java/org/apache/hadoop/hive/conf/HiveConf.java

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
Updated external to revision 1545762.

Updated to revision 1545762.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
patching file ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorReduceSinkOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/HiveKey.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/SkewedKeyPartitioner.java
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/InlineSkewJoinOptimizer.java
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/JoinReorder.java
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/Optimizer.java
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/FromClauseParser.g
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/QBJoinTree.java
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/MapWork.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/ReduceSinkDesc.java
patching file ql/src/java/org/apache/hadoop/hive/ql/plan/SkewContext.java
patching file ql/src/java/org/apache/hadoop/hive/ql/udf/generic/NumericHistogram.java
patching file ql/src/test/queries/clientnegative/skewjoin_explicit_invalid1.q
patching file ql/src/test/queries/clientnegative/skewjoin_explicit_invalid2.q
patching file ql/src/test/queries/clientnegative/skewjoin_explicit_invalid3.q
patching file ql/src/test/queries/clientnegative/skewjoin_explicit_invalid4.q
patching file ql/src/test/queries/clientpositive/skewjoin_explicit.q
patching file ql/src/test/results/clientnegative/skewjoin_explicit_invalid1.q.out
patching file ql/src/test/results/clientnegative/skewjoin_explicit_invalid2.q.out
patching file ql/src/test/results/clientnegative/skewjoin_explicit_invalid3.q.out
patching file ql/src/test/results/clientnegative/skewjoin_explicit_invalid4.q.out
patching file ql/src/test/results/clientpositive/skewjoin_explicit.q.out
+ [[ maven == \m\a\v\e\n ]]
+ rm -rf /data/hive-ptest/working/maven/org/apache/hive
+ mvn -B clean install -DskipTests -Dmaven.repo.local=/data/hive-ptest/working/maven
[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Hive
[INFO] Hive Ant Utilities
[INFO] Hive Shims Common
[INFO] Hive Shims 0.20
[INFO] Hive Shims Secure Common
[INFO] Hive Shims 0.20S
[INFO] Hive Shims 0.23
[INFO] Hive Shims
[INFO] Hive Common
[INFO] Hive Serde
[INFO] Hive Metastore
[INFO] Hive Query Language
[INFO] Hive Service
[INFO] Hive JDBC
[INFO] Hive Beeline
[INFO] Hive CLI
[INFO] Hive Contrib
[INFO] Hive HBase Handler
[INFO] Hive HCatalog
[INFO] Hive HCatalog Core
[INFO] Hive HCatalog Pig Adapter
[INFO] Hive HCatalog Server Extensions
[INFO] Hive HCatalog Webhcat Java Client
[INFO] Hive HCatalog Webhcat
[INFO] Hive HCatalog HBase Storage Handler
[INFO] Hive HWI
[INFO] Hive ODBC
[INFO] Hive Shims Aggregator
[INFO] Hive TestUtils
[INFO] Hive Packaging
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive/0.13.0-SNAPSHOT/hive-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Ant Utilities 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-ant ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/ant (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-ant ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-ant ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-ant ---
[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-svn-trunk-source/ant/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-ant ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-ant ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-ant ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-ant ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-ant ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/hive-ant-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-ant ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ant/target/hive-ant-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-ant/0.13.0-SNAPSHOT/hive-ant-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ant/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-ant/0.13.0-SNAPSHOT/hive-ant-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-common ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/common (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common ---
[INFO] Compiling 15 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-common ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-common ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common/0.13.0-SNAPSHOT/hive-shims-common-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common/0.13.0-SNAPSHOT/hive-shims-common-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.20 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.20 ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20 (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20 ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20 ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20 ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.20 ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.20 ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20/0.13.0-SNAPSHOT/hive-shims-0.20-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20/0.13.0-SNAPSHOT/hive-shims-0.20-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Secure Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-common-secure ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common-secure ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common-secure ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common-secure ---
[INFO] Compiling 12 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/main/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common-secure ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common-secure ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common-secure ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common-secure ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-common-secure ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-common-secure ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common-secure/0.13.0-SNAPSHOT/hive-shims-common-secure-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common-secure/0.13.0-SNAPSHOT/hive-shims-common-secure-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.20S 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.20S ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20S ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20S ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20S ---
[INFO] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/main/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20S ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20S ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20S ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20S ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.20S ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.20S ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20S/0.13.0-SNAPSHOT/hive-shims-0.20S-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20S/0.13.0-SNAPSHOT/hive-shims-0.20S-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.23 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.23 ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23 (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.23 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.23 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.23 ---
[INFO] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/main/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.23 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.23 ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.23 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.23 ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.23 ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.23 ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.23/0.13.0-SNAPSHOT/hive-shims-0.23-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.23/0.13.0-SNAPSHOT/hive-shims-0.23-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims ---
[WARNING] JAR will be empty - no content was marked for inclusion!
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-assembly-plugin:2.3:single (uberjar) @ hive-shims ---
[INFO] Reading assembly descriptor: src/assemble/uberjar.xml
[WARNING] Artifact: org.apache.hive:hive-shims:jar:0.13.0-SNAPSHOT references the same file as the assembly destination file. Moving it to a temporary location for inclusion.
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[WARNING] Configuration options: &apos;appendAssemblyId&apos; is set to false, and &apos;classifier&apos; is missing.
Instead of attaching the assembly file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar, it will become the file for main project artifact.
NOTE: If multiple descriptors or descriptor-formats are provided for this project, the value of this file will be non-deterministic!
[WARNING] Replacing pre-existing project main-artifact file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/archive-tmp/hive-shims-0.13.0-SNAPSHOT.jar
with assembly file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.13.0-SNAPSHOT/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.13.0-SNAPSHOT/hive-shims-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-common ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/common (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-version-annotation) @ hive-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-common ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/common/src/gen added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-common ---
[INFO] Compiling 31 source files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/common/src/java/org/apache/hadoop/hive/common/ObjectPair.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-common ---
[INFO] Compiling 9 source files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-common ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-common ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-common ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-common/0.13.0-SNAPSHOT/hive-common-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/common/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-common/0.13.0-SNAPSHOT/hive-common-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Serde 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-serde ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/serde (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-serde ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/protobuf/gen-java added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-serde ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-serde ---
[INFO] Compiling 351 source files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-serde ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-serde ---
[INFO] Compiling 42 source files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-serde ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-serde ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-serde ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-serde/0.13.0-SNAPSHOT/hive-serde-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/serde/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-serde/0.13.0-SNAPSHOT/hive-serde-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Metastore 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-metastore ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/metastore (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-metastore ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/model added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-metastore ---
[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java
ANTLR Parser Generator  Version 3.4
org/apache/hadoop/hive/metastore/parser/Filter.g
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-metastore ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-metastore ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-metastore ---
[INFO] Compiling 132 source files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- datanucleus-maven-plugin:3.3.0-release:enhance (default) @ hive-metastore ---
[INFO] DataNucleus Enhancer (version 3.2.2) for API &quot;JDO&quot; using JRE &quot;1.6&quot;
DataNucleus Enhancer : Classpath
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-maven-plugin/3.3.0-release/datanucleus-maven-plugin-3.3.0-release.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-utils/3.0.8/plexus-utils-3.0.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-component-annotations/1.5.5/plexus-component-annotations-1.5.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-inject-bean/2.3.0/sisu-inject-bean-2.3.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guice/3.1.0/sisu-guice-3.1.0-no_aop.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guava/0.9.9/sisu-guava-0.9.9.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/xbean/xbean-reflect/3.4/xbean-reflect-3.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/log4j/log4j/1.2.12/log4j-1.2.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-logging/commons-logging-api/1.1/commons-logging-api-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/collections/google-collections/1.0/google-collections-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/junit/junit/3.8.2/junit-3.8.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/tukaani/xz/1.0/xz-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-codec/commons-codec/1.4/commons-codec-1.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/avro/avro/1.7.5/avro-1.7.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-core-asl/1.9.2/jackson-core-asl-1.9.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/guava/guava/11.0.2/guava-11.0.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-lang/commons-lang/2.4/commons-lang-2.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/transaction/jta/1.1/jta-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/antlr/antlr/2.7.7/antlr-2.7.7.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/hadoop/hadoop-core/1.2.1/hadoop-core-1.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/xmlenc/xmlenc/0.52/xmlenc-0.52.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-json/1.14/jersey-json-1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/stax/stax-api/1.0.1/stax-api-1.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/activation/activation/1.1/activation-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/asm/asm/3.1/asm-3.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-io/commons-io/2.4/commons-io-2.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/commons/commons-math/2.1/commons-math-2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-digester/commons-digester/1.8/commons-digester-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/ant/ant/1.6.5/ant-1.6.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-el/commons-el/1.0/commons-el-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/oro/oro/2.0.8/oro-2.0.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-mapper-asl/1.9.2/jackson-mapper-asl-1.9.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/slf4j/slf4j-log4j12/1.7.5/slf4j-log4j12-1.7.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/log4j/log4j/1.2.16/log4j-1.2.16.jar
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDatabase
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFieldSchema
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MType
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTable
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MOrder
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStringList
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartition
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MIndex
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRole
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRoleMap
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MMasterKey
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDelegationToken
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MVersionTable
DataNucleus Enhancer completed with success for 25 classes. Timings : input=642 ms, enhance=961 ms, total=1603 ms. Consult the log for full details

[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-metastore ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-metastore ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-metastore ---
[INFO] Compiling 10 source files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-metastore ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-metastore ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-metastore ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-metastore ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Query Language 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-exec ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/ql (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-sources) @ hive-exec ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-test-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
Generating vector expression code
Generating vector expression test code
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-exec ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/protobuf/gen-java added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-sources/java added.
[INFO] 
[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-exec ---
[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java
ANTLR Parser Generator  Version 3.4
org/apache/hadoop/hive/ql/parse/HiveLexer.g
org/apache/hadoop/hive/ql/parse/HiveParser.g
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:874:5: 
Decision can match input such as &quot;Identifier KW_RENAME KW_TO&quot; using multiple alternatives: 1, 10

As a result, alternative(s) 10 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1179:5: 
Decision can match input such as &quot;KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1179:5: 
Decision can match input such as &quot;KW_ORCFILE&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1179:5: 
Decision can match input such as &quot;KW_TEXTFILE&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1179:5: 
Decision can match input such as &quot;KW_RCFILE&quot; using multiple alternatives: 3, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:23: 
Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:23: 
Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:23: 
Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1199:23: 
Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1199:23: 
Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1199:23: 
Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1217:29: 
Decision can match input such as &quot;KW_FORMATTED KW_PARTITION&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1217:29: 
Decision can match input such as &quot;KW_PRETTY KW_PARTITION&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1217:29: 
Decision can match input such as &quot;KW_PRETTY {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1217:29: 
Decision can match input such as &quot;KW_PRETTY Identifier&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1217:29: 
Decision can match input such as &quot;KW_FORMATTED Identifier&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1217:29: 
Decision can match input such as &quot;KW_FORMATTED {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:116: 
Decision can match input such as &quot;KW_STORED KW_AS KW_DIRECTORIES&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_TEXTFILE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_INPUTFORMAT&quot; using multiple alternatives: 5, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_RCFILE&quot; using multiple alternatives: 3, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_ORCFILE&quot; using multiple alternatives: 4, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): SelectClauseParser.g:149:5: 
Decision can match input such as &quot;KW_NULL DOT Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): SelectClauseParser.g:149:5: 
Decision can match input such as &quot;KW_NULL DOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:147:2: 
Decision can match input such as &quot;KW_LATERAL KW_VIEW KW_OUTER&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:25: 
Decision can match input such as &quot;LPAREN StringLiteral COMMA&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:25: 
Decision can match input such as &quot;LPAREN StringLiteral RPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:25: 
Decision can match input such as &quot;LPAREN StringLiteral EQUAL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:199:68: 
Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:257:16: 
Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_OR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_AND&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL {MINUS, PLUS}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL {DIV..DIVIDE, MOD, STAR}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_WHEN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL BITWISEOR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_EXISTS LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL DOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL RPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN CharSetName CharSetLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LSQUARE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CAST LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_IN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN StringLiteral StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_IS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_BETWEEN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL {KW_LIKE, KW_REGEXP, KW_RLIKE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL EQUAL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL EQUAL_NS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL NOTEQUAL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LESSTHANOREQUALTO&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL AMPERSAND&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL BITWISEXOR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LESSTHAN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_DATE StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL GREATERTHANOREQUALTO&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL GREATERTHAN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:108:5: 
Decision can match input such as &quot;KW_ORDER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:121:5: 
Decision can match input such as &quot;KW_CLUSTER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:133:5: 
Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:144:5: 
Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:155:5: 
Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:172:7: 
Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_DATE StringLiteral&quot; using multiple alternatives: 2, 3

As a result, alternative(s) 3 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:524:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-exec ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1399 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/plan/SkewContext.java:[118,49] cannot find symbol
symbol  : method getRandom()
location: class org.apache.hadoop.hive.ql.io.HiveKey
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [4.754s]
[INFO] Hive Ant Utilities ................................ SUCCESS [7.617s]
[INFO] Hive Shims Common ................................. SUCCESS [3.455s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [2.263s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [2.832s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [1.630s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [4.482s]
[INFO] Hive Shims ........................................ SUCCESS [3.006s]
[INFO] Hive Common ....................................... SUCCESS [5.342s]
[INFO] Hive Serde ........................................ SUCCESS [11.590s]
[INFO] Hive Metastore .................................... SUCCESS [26.085s]
[INFO] Hive Query Language ............................... FAILURE [35.747s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog HBase Storage Handler ............... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1:51.912s
[INFO] Finished at: Tue Nov 26 13:27:52 EST 2013
[INFO] Final Memory: 53M/369M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/plan/SkewContext.java:[118,49] cannot find symbol
[ERROR] symbol  : method getRandom()
[ERROR] location: class org.apache.hadoop.hive.ql.io.HiveKey
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12615766&lt;/p&gt;</comment>
                            <comment id="13834380" author="navis" created="Thu, 28 Nov 2013 00:11:28 +0000"  >&lt;p&gt;Rebased to trunk. Running test.&lt;/p&gt;</comment>
                            <comment id="13834436" author="hiveqa" created="Thu, 28 Nov 2013 01:19:48 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12616156/HIVE-3286.13.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12616156/HIVE-3286.13.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/472/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/472/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/472/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/472/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL GREATERTHAN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:108:5: 
Decision can match input such as &quot;KW_ORDER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:121:5: 
Decision can match input such as &quot;KW_CLUSTER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:133:5: 
Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:144:5: 
Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:155:5: 
Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:172:7: 
Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_DATE StringLiteral&quot; using multiple alternatives: 2, 3

As a result, alternative(s) 3 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:524:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-exec ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1400 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/plan/SkewContext.java:[118,49] cannot find symbol
symbol  : method getRandom()
location: class org.apache.hadoop.hive.ql.io.HiveKey
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [2.846s]
[INFO] Hive Ant Utilities ................................ SUCCESS [9.072s]
[INFO] Hive Shims Common ................................. SUCCESS [3.459s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [2.210s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [2.711s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [1.397s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [3.679s]
[INFO] Hive Shims ........................................ SUCCESS [3.073s]
[INFO] Hive Common ....................................... SUCCESS [13.388s]
[INFO] Hive Serde ........................................ SUCCESS [11.713s]
[INFO] Hive Metastore .................................... SUCCESS [26.188s]
[INFO] Hive Query Language ............................... FAILURE [30.091s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog HBase Storage Handler ............... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1:52.444s
[INFO] Finished at: Wed Nov 27 20:19:46 EST 2013
[INFO] Final Memory: 51M/371M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/plan/SkewContext.java:[118,49] cannot find symbol
[ERROR] symbol  : method getRandom()
[ERROR] location: class org.apache.hadoop.hive.ql.io.HiveKey
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12616156&lt;/p&gt;</comment>
                            <comment id="13834515" author="navis" created="Thu, 28 Nov 2013 04:45:43 +0000"  >&lt;p&gt;Fix build fail.&lt;/p&gt;</comment>
                            <comment id="13834560" author="hiveqa" created="Thu, 28 Nov 2013 07:51:27 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12616193/HIVE-3286.14.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12616193/HIVE-3286.14.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 4745 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.ql.TestErrorMsg.testUniqueErrorCode
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/480/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/480/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/480/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/480/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12616193&lt;/p&gt;</comment>
                            <comment id="13834635" author="hiveqa" created="Thu, 28 Nov 2013 09:18:01 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12616208/HIVE-3286.15.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12616208/HIVE-3286.15.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 4745 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_skewjoin_explicit_invalid1
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_skewjoin_explicit_invalid2
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_skewjoin_explicit_invalid3
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_skewjoin_explicit_invalid4
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/482/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/482/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/482/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/482/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12616208&lt;/p&gt;</comment>
                            <comment id="13848896" author="navis" created="Mon, 16 Dec 2013 07:42:09 +0000"  >&lt;p&gt;Rebased &amp;amp; fixed test fails&lt;/p&gt;</comment>
                            <comment id="13849088" author="hiveqa" created="Mon, 16 Dec 2013 12:01:28 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12618867/HIVE-3286.16.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12618867/HIVE-3286.16.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 4790 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_skewjoin_explicit
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_skewjoin_explicit_invalid1
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_skewjoin_explicit_invalid2
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_skewjoin_explicit_invalid3
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/652/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/652/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/652/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/652/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12618867&lt;/p&gt;</comment>
                            <comment id="13851560" author="hiveqa" created="Wed, 18 Dec 2013 10:27:13 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12619277/HIVE-3286.17.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12619277/HIVE-3286.17.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4796 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/688/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/688/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/688/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/688/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12619277&lt;/p&gt;</comment>
                            <comment id="13921841" author="navis" created="Thu, 6 Mar 2014 01:28:10 +0000"  >&lt;p&gt;Rebased to trunk&lt;/p&gt;</comment>
                            <comment id="14160000" author="hiveqa" created="Mon, 6 Oct 2014 04:44:29 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12673046/HIVE-3286.19.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12673046/HIVE-3286.19.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 6529 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.ql.TestErrorMsg.testUniqueErrorCode
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1127/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1127/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1127/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/1127/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1127/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1127/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12673046&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12615542" name="D4287.11.patch" size="107712" author="phabricator@reviews.facebook.net" created="Mon, 25 Nov 2013 06:37:36 +0000"/>
                            <attachment id="12615766" name="HIVE-3286.12.patch.txt" size="110167" author="navis" created="Tue, 26 Nov 2013 01:42:19 +0000"/>
                            <attachment id="12616156" name="HIVE-3286.13.patch.txt" size="110167" author="navis" created="Thu, 28 Nov 2013 00:10:54 +0000"/>
                            <attachment id="12616193" name="HIVE-3286.14.patch.txt" size="110345" author="navis" created="Thu, 28 Nov 2013 04:45:43 +0000"/>
                            <attachment id="12616208" name="HIVE-3286.15.patch.txt" size="110345" author="navis" created="Thu, 28 Nov 2013 08:20:04 +0000"/>
                            <attachment id="12618867" name="HIVE-3286.16.patch.txt" size="110403" author="navis" created="Mon, 16 Dec 2013 07:42:02 +0000"/>
                            <attachment id="12619277" name="HIVE-3286.17.patch.txt" size="110333" author="navis" created="Wed, 18 Dec 2013 08:43:43 +0000"/>
                            <attachment id="12632994" name="HIVE-3286.18.patch.txt" size="103852" author="navis" created="Thu, 6 Mar 2014 01:28:10 +0000"/>
                            <attachment id="12673046" name="HIVE-3286.19.patch.txt" size="105654" author="navis" created="Mon, 6 Oct 2014 01:31:47 +0000"/>
                            <attachment id="12599104" name="HIVE-3286.D4287.10.patch" size="105785" author="phabricator@reviews.facebook.net" created="Wed, 21 Aug 2013 04:30:52 +0000"/>
                            <attachment id="12559807" name="HIVE-3286.D4287.5.patch" size="62328" author="phabricator@reviews.facebook.net" created="Fri, 7 Dec 2012 04:37:19 +0000"/>
                            <attachment id="12562541" name="HIVE-3286.D4287.6.patch" size="61935" author="phabricator@reviews.facebook.net" created="Fri, 28 Dec 2012 01:34:11 +0000"/>
                            <attachment id="12562741" name="HIVE-3286.D4287.7.patch" size="83918" author="phabricator@reviews.facebook.net" created="Mon, 31 Dec 2012 01:06:12 +0000"/>
                            <attachment id="12562742" name="HIVE-3286.D4287.8.patch" size="83069" author="phabricator@reviews.facebook.net" created="Mon, 31 Dec 2012 01:16:12 +0000"/>
                            <attachment id="12563739" name="HIVE-3286.D4287.9.patch" size="109391" author="phabricator@reviews.facebook.net" created="Tue, 8 Jan 2013 12:04:11 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>15.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 20 Jul 2012 09:49:10 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>247698</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 16 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08ozj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>48647</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-3287] In UDTF explains use toString() for function name not annotation</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3287</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;UDTF Operator&lt;br/&gt;
  function name: o.a.h.stack@34314&lt;/p&gt;

&lt;p&gt;Unless a toSTring is specified.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599723">HIVE-3287</key>
            <summary>In UDTF explains use toString() for function name not annotation</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="appodictic">Edward Capriolo</assignee>
                                    <reporter username="appodictic">Edward Capriolo</reporter>
                        <labels>
                    </labels>
                <created>Sat, 21 Jul 2012 12:35:26 +0000</created>
                <updated>Sat, 21 Jul 2012 12:35:26 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>259165</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 27 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ln7z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>124412</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-3288] Hive does not support select distinct *</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3288</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;select distinct * returns the below error in Hive while mysql supports this syntax.&lt;/p&gt;

&lt;p&gt;hive&amp;gt; select distinct * from src;&lt;br/&gt;
FAILED: Error in semantic analysis: Line 0:-1 Invalid function &apos;TOK_ALLCOLREF&apos;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599760">HIVE-3288</key>
            <summary>Hive does not support select distinct *</summary>
                <type id="3" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21148&amp;avatarType=issuetype">Task</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="sambavi">Sambavi Muthukrishnan</reporter>
                        <labels>
                    </labels>
                <created>Sun, 22 Jul 2012 14:49:19 +0000</created>
                <updated>Thu, 15 Jan 2015 00:59:52 +0000</updated>
                            <resolved>Tue, 2 Oct 2012 04:14:18 +0000</resolved>
                                    <version>0.9.0</version>
                                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                    <timeoriginalestimate seconds="259200">72h</timeoriginalestimate>
                            <timeestimate seconds="259200">72h</timeestimate>
                                        <comments>
                            <comment id="13420184" author="namit" created="Sun, 22 Jul 2012 14:52:31 +0000"  >&lt;p&gt;Atleast, Hive should give a better error message&lt;/p&gt;</comment>
                            <comment id="13467467" author="ashutoshc" created="Tue, 2 Oct 2012 04:14:18 +0000"  >&lt;p&gt;Dupe of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3199&quot; title=&quot;support select distinct *&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3199&quot;&gt;HIVE-3199&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12763334">HIVE-9194</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 22 Jul 2012 14:52:31 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>242118</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 17 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02ivb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>12658</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3289] sort merge join may not work silently</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3289</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The user does not know, if the sort-merge join is working or not.&lt;/p&gt;


&lt;p&gt;create table table_asc(key int, value string) CLUSTERED BY (key) SORTED BY (key asc) &lt;br/&gt;
INTO 1 BUCKETS STORED AS RCFILE; &lt;br/&gt;
create table table_desc(key int, value string) CLUSTERED BY (key) SORTED BY (key desc) &lt;br/&gt;
INTO 1 BUCKETS STORED AS RCFILE; &lt;/p&gt;

&lt;p&gt;set hive.enforce.sorting = true;&lt;/p&gt;

&lt;p&gt;insert overwrite table table_asc select key, value from src;    &lt;br/&gt;
insert overwrite table table_desc select key, value from src;&lt;/p&gt;

&lt;p&gt;set hive.optimize.bucketmapjoin = true;&lt;br/&gt;
set hive.optimize.bucketmapjoin.sortedmerge = true;&lt;br/&gt;
set hive.input.format = org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat;&lt;/p&gt;

&lt;p&gt;explain &lt;br/&gt;
select /&lt;b&gt;+mapjoin(a)&lt;/b&gt;/ * from table_asc a join table_desc b on a.key = b.key;&lt;br/&gt;
select /&lt;b&gt;+mapjoin(a)&lt;/b&gt;/ * from table_asc a join table_desc b on a.key = b.key;&lt;/p&gt;

&lt;p&gt;explain&lt;br/&gt;
select /&lt;b&gt;+mapjoin(b)&lt;/b&gt;/ * from table_asc a join table_desc b on a.key = b.key;&lt;br/&gt;
select /&lt;b&gt;+mapjoin(b)&lt;/b&gt;/ * from table_asc a join table_desc b on a.key = b.key;&lt;/p&gt;



&lt;p&gt;In the above test, the sort-merge join is not obeyed as expected.&lt;br/&gt;
If you user explicitly asked for sort-merge join, and it is not being&lt;br/&gt;
obeyed, the operation should fail.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599816">HIVE-3289</key>
            <summary>sort merge join may not work silently</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="namit">Namit Jain</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Mon, 23 Jul 2012 08:01:23 +0000</created>
                <updated>Thu, 2 May 2013 02:30:53 +0000</updated>
                            <resolved>Wed, 1 Aug 2012 16:53:11 +0000</resolved>
                                    <version>0.10.0</version>
                                    <fixVersion>0.10.0</fixVersion>
                                    <component>Configuration</component>
                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13422026" author="namit" created="Wed, 25 Jul 2012 06:08:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.facebook.net/D4179&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4179&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13422808" author="kevinwilfong" created="Thu, 26 Jul 2012 01:24:20 +0000"  >&lt;p&gt;+1 running tests&lt;/p&gt;</comment>
                            <comment id="13422812" author="cwsteinbach" created="Thu, 26 Jul 2012 01:31:01 +0000"  >&lt;p&gt;-1&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I also am not a fan of hive.mapred.mode  If you turn it off, you may unintentionally turn off other checks, and it uses strict/nonstrict instead of true/false which is easier to validate. That&apos;s, at best, a problem for another JIRA, though, as it&apos;s fairly well established.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree with Kevin, but I don&apos;t think this should be postponed for another JIRA. Please add a new configuration property now instead of further overloading what is an already ill-defined and poorly documented configuration property.&lt;/p&gt;</comment>
                            <comment id="13422819" author="cwsteinbach" created="Thu, 26 Jul 2012 01:37:53 +0000"  >&lt;p&gt;Two more points which are tangentially related:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;The patch is not attached to this ticket, and it looks like Phabricator stopped automatically attaching patches some time ago. Is anyone at Facebook looking into fixing this?&lt;/li&gt;
	&lt;li&gt;Part of the agreement when we started using Phabricator was that the tool would automatically copy review comments back to JIRA. This feature hasn&apos;t worked in months, and unless it starts working soon I think we should stop using Phabricator and switch back to ReviewBoard. Is anyone looking into fixing this? If not we should probably just switch back now.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13422988" author="namit" created="Thu, 26 Jul 2012 09:44:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.facebook.net/D4377&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4377&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Added a new conf. parameter&lt;/p&gt;</comment>
                            <comment id="13422992" author="namit" created="Thu, 26 Jul 2012 09:47:38 +0000"  >&lt;p&gt;I think, the discussion to use phabricator/review board/patch should be done on the dev mailing list, instead of this jira.&lt;/p&gt;</comment>
                            <comment id="13425330" author="kevinwilfong" created="Mon, 30 Jul 2012 22:33:03 +0000"  >&lt;p&gt;Regarding the diff, I&apos;m +1 on it, Carl?&lt;/p&gt;</comment>
                            <comment id="13425413" author="cwsteinbach" created="Tue, 31 Jul 2012 00:12:00 +0000"  >&lt;p&gt;+1. Thanks for making these changes.&lt;/p&gt;</comment>
                            <comment id="13426751" author="kevinwilfong" created="Wed, 1 Aug 2012 16:53:11 +0000"  >&lt;p&gt;Committed, thanks Namit.&lt;/p&gt;</comment>
                            <comment id="13427049" author="hudson" created="Thu, 2 Aug 2012 00:49:45 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1584 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1584/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1584/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3289&quot; title=&quot;sort merge join may not work silently&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3289&quot;&gt;&lt;del&gt;HIVE-3289&lt;/del&gt;&lt;/a&gt;. sort merge join may not work silently. (njain via kevinwilfong) (Revision 1368119)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
kevinwilfong : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1368119&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1368119&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SortedMergeBucketMapJoinOptimizer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/sortmerge_mapjoin_mismatch_1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/sortmerge_mapjoin_mismatch_1.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13548157" author="hudson" created="Wed, 9 Jan 2013 10:24:37 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #54 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3289&quot; title=&quot;sort merge join may not work silently&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3289&quot;&gt;&lt;del&gt;HIVE-3289&lt;/del&gt;&lt;/a&gt;. sort merge join may not work silently. (njain via kevinwilfong) (Revision 1368119)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
kevinwilfong : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1368119&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1368119&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SortedMergeBucketMapJoinOptimizer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientnegative/sortmerge_mapjoin_mismatch_1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientnegative/sortmerge_mapjoin_mismatch_1.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13550180" author="ashutoshc" created="Thu, 10 Jan 2013 19:53:41 +0000"  >&lt;p&gt;This issue is fixed and released as part of 0.10.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12600762">HIVE-3322</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12599242">HIVE-3270</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12537978" name="hive.3289.1.patch" size="14227" author="namit" created="Thu, 26 Jul 2012 09:46:13 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 26 Jul 2012 01:24:20 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>259166</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 2 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ln87:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>124413</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>This patch adds the configuration property &amp;#39;hive.enforce.sortmergebucketmapjoin&amp;#39;, which is set to false by default.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3290] BucketizedHiveInputFormat should support combining files having same bucket number</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3290</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Current BucketizedHiveInputFormat creates one split per one input file, which could result too many map tasks. If input files are not so big (make configurable threshold?), combining files with same bucket number and same input format could help reducing total execution time.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599817">HIVE-3290</key>
            <summary>BucketizedHiveInputFormat should support combining files having same bucket number</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="navis">Navis</assignee>
                                    <reporter username="navis">Navis</reporter>
                        <labels>
                    </labels>
                <created>Mon, 23 Jul 2012 08:01:52 +0000</created>
                <updated>Tue, 24 Jul 2012 07:25:44 +0000</updated>
                                            <version>0.10.0</version>
                                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                    <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12595463">HIVE-3171</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>247699</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 27 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08ozr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>48648</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-3291] fix fs resolvers </title>
                <link>https://issues.apache.org/jira/browse/HIVE-3291</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;shims module fails to compile when compiling hive against 1.0 using the fs resolvers as the force=true flag forces it to use the available version of hadoop.&lt;/p&gt;

&lt;p&gt;In a scenario where you want to build hadoop-1.0 and shims would still want to build against 20.2 and if you happen to use fs resolver ie -Dresolvers=true , fs resolvers would just use 1.0 of hadoop for shims and shims compilation will fail.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599897">HIVE-3291</key>
            <summary>fix fs resolvers </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ashishujjain">Ashish Singh</assignee>
                                    <reporter username="gkesavan">Giridharan Kesavan</reporter>
                        <labels>
                    </labels>
                <created>Mon, 23 Jul 2012 20:20:42 +0000</created>
                <updated>Thu, 10 Jan 2013 19:53:28 +0000</updated>
                            <resolved>Thu, 15 Nov 2012 16:15:24 +0000</resolved>
                                    <version>0.9.0</version>
                                    <fixVersion>0.10.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13423502" author="ashishujjain" created="Thu, 26 Jul 2012 22:11:16 +0000"  >&lt;p&gt;fs resolver has hardcoded group id. It should be based on regular expression matching.&lt;/p&gt;</comment>
                            <comment id="13496714" author="ashishujjain" created="Wed, 14 Nov 2012 00:46:03 +0000"  >&lt;p&gt;Revised patch for fs resolver.&lt;/p&gt;</comment>
                            <comment id="13497720" author="ashutoshc" created="Thu, 15 Nov 2012 02:49:51 +0000"  >&lt;p&gt;+1 will commit if tests pass.&lt;/p&gt;</comment>
                            <comment id="13498100" author="ashutoshc" created="Thu, 15 Nov 2012 16:15:24 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Ashish!&lt;/p&gt;</comment>
                            <comment id="13498536" author="hudson" created="Fri, 16 Nov 2012 02:01:16 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1799 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1799/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1799/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3291&quot; title=&quot;fix fs resolvers &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3291&quot;&gt;&lt;del&gt;HIVE-3291&lt;/del&gt;&lt;/a&gt; : fix fs resolvers (Ashish Singh via Ashutosh Chauhan) (Revision 1409862)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1409862&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1409862&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ivy/ivysettings.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13548197" author="hudson" created="Wed, 9 Jan 2013 10:24:47 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #54 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3291&quot; title=&quot;fix fs resolvers &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3291&quot;&gt;&lt;del&gt;HIVE-3291&lt;/del&gt;&lt;/a&gt; : fix fs resolvers (Ashish Singh via Ashutosh Chauhan) (Revision 1409862)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1409862&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1409862&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ivy/ivysettings.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13550125" author="ashutoshc" created="Thu, 10 Jan 2013 19:53:28 +0000"  >&lt;p&gt;This issue is fixed and released as part of 0.10.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12537613" name="HIVE-3291.patch" size="605" author="gkesavan" created="Mon, 23 Jul 2012 21:30:40 +0000"/>
                            <attachment id="12538090" name="HIVE-3291.patch1" size="925" author="ashishujjain" created="Thu, 26 Jul 2012 22:12:17 +0000"/>
                            <attachment id="12553414" name="HIVE-3291.patch2" size="893" author="ashishujjain" created="Wed, 14 Nov 2012 00:46:03 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 26 Jul 2012 22:11:16 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>257602</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 2 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0k3hj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>115382</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3292] Table Statistics </title>
                <link>https://issues.apache.org/jira/browse/HIVE-3292</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;There is a problem with table statistics:&lt;/p&gt;

&lt;p&gt;If 2 partitions of a table are being created/updated concurrently, &lt;br/&gt;
table level stats may not be correct.&lt;/p&gt;

&lt;p&gt;For eg. if a table T has 2 partitions P1 and P2 with number of rows 10 and 20&lt;br/&gt;
respectively, and both the partitions are being updated concurrently (via &lt;br/&gt;
insert overwrite ...), the table object is obtained in StatsTask and updated.&lt;br/&gt;
Even with concurrency turned on, the table is not locked, and the two table&lt;br/&gt;
statistics updates may lead to one to them being lost.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599968">HIVE-3292</key>
            <summary>Table Statistics </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Tue, 24 Jul 2012 09:50:28 +0000</created>
                <updated>Tue, 24 Jul 2012 09:50:28 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>259167</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 27 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ln8n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>124415</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-3293] Load file into a table does not update table statistics</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3293</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;create table smb_bucket_1(key int, value string);&lt;/p&gt;

&lt;p&gt;load data local inpath &apos;../data/files/smbbucket_1.rc&apos; overwrite into table smb_bucket_1;&lt;br/&gt;
load data local inpath &apos;../data/files/smbbucket_2.rc&apos; overwrite into table smb_bucket_2;&lt;/p&gt;


&lt;p&gt;does not update the stats for smb_bucket_1&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599969">HIVE-3293</key>
            <summary>Load file into a table does not update table statistics</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="namit">Namit Jain</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Tue, 24 Jul 2012 09:52:05 +0000</created>
                <updated>Thu, 10 Jan 2013 19:53:32 +0000</updated>
                            <resolved>Mon, 13 Aug 2012 04:11:46 +0000</resolved>
                                                    <fixVersion>0.10.0</fixVersion>
                                    <component>Statistics</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13425951" author="namit" created="Tue, 31 Jul 2012 17:37:02 +0000"  >&lt;p&gt;The number of rows need a complete scan.&lt;/p&gt;

&lt;p&gt;However, the number of files, size etc. should be fixed.&lt;/p&gt;</comment>
                            <comment id="13426529" author="namit" created="Wed, 1 Aug 2012 11:29:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.facebook.net/D4473&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4473&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13427094" author="namit" created="Thu, 2 Aug 2012 03:44:13 +0000"  >&lt;p&gt;updated results&lt;/p&gt;</comment>
                            <comment id="13427558" author="kevinwilfong" created="Thu, 2 Aug 2012 19:54:17 +0000"  >&lt;p&gt;Commented on the diff.&lt;/p&gt;</comment>
                            <comment id="13428806" author="namit" created="Sun, 5 Aug 2012 05:34:55 +0000"  >&lt;p&gt;comments addressed&lt;/p&gt;</comment>
                            <comment id="13429265" author="kevinwilfong" created="Mon, 6 Aug 2012 17:03:26 +0000"  >&lt;p&gt;One comment on the diff, otherwise looks good.&lt;/p&gt;</comment>
                            <comment id="13429280" author="namit" created="Mon, 6 Aug 2012 17:29:02 +0000"  >&lt;p&gt;that was when i was testing on my mac - addressed.&lt;/p&gt;</comment>
                            <comment id="13429283" author="kevinwilfong" created="Mon, 6 Aug 2012 17:35:25 +0000"  >&lt;p&gt;Thanks Namit.  +1&lt;/p&gt;</comment>
                            <comment id="13429385" author="cwsteinbach" created="Mon, 6 Aug 2012 20:00:48 +0000"  >&lt;p&gt;Please attach the most recent version of the patch to this ticket.&lt;/p&gt;</comment>
                            <comment id="13429913" author="namit" created="Tue, 7 Aug 2012 04:10:31 +0000"  >&lt;p&gt;Latest patch attached&lt;/p&gt;</comment>
                            <comment id="13429984" author="cwsteinbach" created="Tue, 7 Aug 2012 07:06:25 +0000"  >&lt;p&gt;Thanks. Looks good to me.&lt;/p&gt;</comment>
                            <comment id="13430909" author="namit" created="Wed, 8 Aug 2012 06:46:08 +0000"  >&lt;p&gt;updated more test results&lt;/p&gt;</comment>
                            <comment id="13432908" author="namit" created="Mon, 13 Aug 2012 04:11:46 +0000"  >&lt;p&gt;This was committed by Kevin last week, I think he could not update the&lt;br/&gt;
jira since it was down.&lt;/p&gt;</comment>
                            <comment id="13433300" author="kevinwilfong" created="Mon, 13 Aug 2012 17:05:27 +0000"  >&lt;p&gt;That&apos;s exactly what happened, thanks Namit.&lt;/p&gt;</comment>
                            <comment id="13548195" author="hudson" created="Wed, 9 Jan 2013 10:24:46 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #54 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3293&quot; title=&quot;Load file into a table does not update table statistics&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3293&quot;&gt;&lt;del&gt;HIVE-3293&lt;/del&gt;&lt;/a&gt;. Load file into a table does not update table statistics. (njain via kevinwilfong) (Revision 1371580)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
kevinwilfong : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1371580&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1371580&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/StatsWork.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/stats1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/stats11.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/stats13.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/stats15.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/stats18.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/stats2.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/stats3.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/stats4.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/stats5.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/stats6.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/stats9.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/binary_output_format.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucket1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucket2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucket3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucket4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucket_map_join_1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucket_map_join_2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketcontext_1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketcontext_2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketcontext_3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketcontext_4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin5.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ctas.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/describe_table.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/disable_merge_for_bucketing.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby_map_ppr.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby_map_ppr_multi_distinct.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby_ppr.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby_ppr_multi_distinct.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input23.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input42.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input_part1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input_part2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input_part7.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input_part9.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join17.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join26.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join32.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join33.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join34.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join35.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join9.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join_map_ppr.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/load_dyn_part8.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/louter_join_ppr.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/outer_join_ppr.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/pcr.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppr_allchildsarenull.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/rand_partitionpruner1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/rand_partitionpruner2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/reduce_deduplicate.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/regexp_extract.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/router_join_ppr.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample5.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample6.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample7.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample8.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample9.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/stats0.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/stats1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/stats11.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/stats13.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/stats18.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/stats2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/stats3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/stats4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/stats5.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/stats6.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/stats9.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/transform_ppr1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/transform_ppr2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/udf_explode.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/udf_java_method.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/udf_reflect.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/udtf_explode.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_ppr.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/case_sensitivity.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/cast1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input20.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input8.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input9.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_part1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testxpath.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testxpath2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join8.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/subq.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf_case.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf_when.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/union.q.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13550140" author="ashutoshc" created="Thu, 10 Jan 2013 19:53:32 +0000"  >&lt;p&gt;This issue is fixed and released as part of 0.10.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12538772" name="hive.3293.1.patch" size="164483" author="namit" created="Wed, 1 Aug 2012 11:29:48 +0000"/>
                            <attachment id="12539418" name="hive.3293.2.patch" size="406887" author="namit" created="Tue, 7 Aug 2012 04:10:31 +0000"/>
                            <attachment id="12539783" name="hive.3293.3.patch" size="771953" author="namit" created="Wed, 8 Aug 2012 06:46:08 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 2 Aug 2012 19:54:17 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>240093</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 2 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i00x3r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3295</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-3294] alter table add partition does not update the statistics of the partition or the table</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3294</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;This may be specially bad for external tables, whose partitions are being &lt;br/&gt;
created via alter table add partition&lt;/p&gt;</description>
                <environment></environment>
        <key id="12599971">HIVE-3294</key>
            <summary>alter table add partition does not update the statistics of the partition or the table</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Tue, 24 Jul 2012 09:53:35 +0000</created>
                <updated>Tue, 24 Jul 2012 09:53:35 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>259168</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 27 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0ln8v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>124416</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-3295] HIVE-3128 introduced bug causing dynamic partitioning to fail</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3295</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3128&quot; title=&quot;use commons-compress instead of forking tar process&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3128&quot;&gt;&lt;del&gt;HIVE-3128&lt;/del&gt;&lt;/a&gt; introduced a new commons-compress jar and imports classes from it in FileUtils.java  The FileUtils class is accessed by dynamic partitioning in the map reduce cluster where the jar is not available, causing the query to fail.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12600090">HIVE-3295</key>
            <summary>HIVE-3128 introduced bug causing dynamic partitioning to fail</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="kevinwilfong">Kevin Wilfong</assignee>
                                    <reporter username="kevinwilfong">Kevin Wilfong</reporter>
                        <labels>
                    </labels>
                <created>Tue, 24 Jul 2012 23:24:42 +0000</created>
                <updated>Thu, 10 Jan 2013 19:54:04 +0000</updated>
                            <resolved>Wed, 25 Jul 2012 06:26:24 +0000</resolved>
                                    <version>0.10.0</version>
                                    <fixVersion>0.10.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13421883" author="kevinwilfong" created="Wed, 25 Jul 2012 00:00:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.facebook.net/D4311&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D4311&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13421919" author="ashutoshc" created="Wed, 25 Jul 2012 01:21:44 +0000"  >&lt;p&gt;+1. Your solution of moving out that method from FileUtils to CompressionUtils is a good one. We definitely don&apos;t want to send unnecessary jars to cluster. Please commit if tests pass.&lt;/p&gt;</comment>
                            <comment id="13421926" author="cwsteinbach" created="Wed, 25 Jul 2012 01:26:11 +0000"  >&lt;p&gt;@Kevin: The new file is missing an ASF header.&lt;/p&gt;</comment>
                            <comment id="13422021" author="kevinwilfong" created="Wed, 25 Jul 2012 05:46:13 +0000"  >&lt;p&gt;Added the header.&lt;/p&gt;</comment>
                            <comment id="13422028" author="namit" created="Wed, 25 Jul 2012 06:14:43 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13422309" author="appodictic" created="Wed, 25 Jul 2012 14:30:54 +0000"  >&lt;p&gt;you live and you learn. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13422324" author="hudson" created="Wed, 25 Jul 2012 14:50:19 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1567 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1567/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1567/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3295&quot; title=&quot;HIVE-3128 introduced bug causing dynamic partitioning to fail&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3295&quot;&gt;&lt;del&gt;HIVE-3295&lt;/del&gt;&lt;/a&gt;. &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3128&quot; title=&quot;use commons-compress instead of forking tar process&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3128&quot;&gt;&lt;del&gt;HIVE-3128&lt;/del&gt;&lt;/a&gt; introduced bug causing dynamic partitioning to fail. (kevinwilfong reviewed by njain, ashutoshc) (Revision 1365460)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
kevinwilfong : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1365460&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1365460&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/common/CompressionUtils.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/common/FileUtils.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13548208" author="hudson" created="Wed, 9 Jan 2013 10:24:49 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #54 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3295&quot; title=&quot;HIVE-3128 introduced bug causing dynamic partitioning to fail&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3295&quot;&gt;&lt;del&gt;HIVE-3295&lt;/del&gt;&lt;/a&gt;. &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3128&quot; title=&quot;use commons-compress instead of forking tar process&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3128&quot;&gt;&lt;del&gt;HIVE-3128&lt;/del&gt;&lt;/a&gt; introduced bug causing dynamic partitioning to fail. (kevinwilfong reviewed by njain, ashutoshc) (Revision 1365460)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
kevinwilfong : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1365460&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1365460&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/common/CompressionUtils.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/common/FileUtils.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13550276" author="ashutoshc" created="Thu, 10 Jan 2013 19:54:04 +0000"  >&lt;p&gt;This issue is fixed and released as part of 0.10.0 release. If you find an issue which seems to be related to this one, please create a new jira and link this one with new jira.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12605832">HIVE-3423</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                                                <inwardlinks description="is broken by">
                                        <issuelink>
            <issuekey id="12560540">HIVE-3128</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12537771" name="HIVE-3295.1.patch.txt" size="5704" author="kevinwilfong" created="Wed, 25 Jul 2012 00:01:43 +0000"/>
                            <attachment id="12537808" name="HIVE-3295.2.patch.txt" size="6530" author="kevinwilfong" created="Wed, 25 Jul 2012 05:47:39 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 25 Jul 2012 01:21:44 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>242363</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 2 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02u47:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>14480</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>
</channel>
</rss>
