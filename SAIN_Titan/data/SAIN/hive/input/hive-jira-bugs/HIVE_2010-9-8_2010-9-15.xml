<!--
RSS generated by JIRA (7.6.3#76005-sha1:8a4e38d34af948780dbf52044e7aafb13a7cae58) at Tue Jan 22 15:16:37 UTC 2019

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<!-- If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
    <channel>
        <title>ASF JIRA</title>
        <link>https://issues.apache.org/jira/issues/?jql=project+%3D+HIVE+AND+created+%3E%3D+2010-9-8+AND+created+%3C%3D+2010-9-15+ORDER+BY+key+ASC</link>
        <description>An XML representation of a search request</description>
                <language>en-uk</language>
                        <issue start="0" end="17" total="17"/>
                <build-info>
            <version>7.6.3</version>
            <build-number>76005</build-number>
            <build-date>09-01-2018</build-date>
        </build-info>

<item>
            <title>[HIVE-1619] pipes not correctly being handled in transform</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1619</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Akhil had a testcase where he had a query like:&lt;/p&gt;


&lt;p&gt;select tranform&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; using &apos;ex1 | ex2&apos; from T;&lt;/p&gt;

&lt;p&gt;There was some problem with the pipe.&lt;/p&gt;

&lt;p&gt;The work-around is to move &apos;ex1 | ex2&apos; in a new executable&lt;/p&gt;</description>
                <environment></environment>
        <key id="12473515">HIVE-1619</key>
            <summary>pipes not correctly being handled in transform</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Wed, 8 Sep 2010 00:37:24 +0000</created>
                <updated>Mon, 14 Feb 2011 21:02:11 +0000</updated>
                                                                            <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42420</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 20 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lg1b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123248</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-1620] Patch to write directly to S3 from Hive</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1620</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;We want to submit a patch to Hive which allows user to write files directly to S3.&lt;/p&gt;

&lt;p&gt;This patch allow user to specify an S3 location as the table output location and hence eliminates the need  of copying data from HDFS to S3.&lt;br/&gt;
Users can run Hive queries directly over the data stored in S3.&lt;br/&gt;
This patch helps integrate hive with S3 better and quicker.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12473520">HIVE-1620</key>
            <summary>Patch to write directly to S3 from Hive</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="vaggarw">Vaibhav Aggarwal</assignee>
                                    <reporter username="vaggarw">Vaibhav Aggarwal</reporter>
                        <labels>
                    </labels>
                <created>Wed, 8 Sep 2010 02:12:12 +0000</created>
                <updated>Mon, 5 Mar 2018 15:16:30 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>17</watches>
                                                                <comments>
                            <comment id="12907093" author="namit" created="Wed, 8 Sep 2010 05:18:51 +0000"  >&lt;p&gt;How will this handle failures and speculative execution ?&lt;br/&gt;
If you are directly writing to a file, cant it lead to duplicate data ?&lt;/p&gt;</comment>
                            <comment id="12907349" author="vaggarw" created="Wed, 8 Sep 2010 18:25:25 +0000"  >&lt;p&gt;This is the reason the patch uses task id instead of attempt id to write to s3.&lt;br/&gt;
Each process writes to the same file. In case of s3 the last process to commit the file wins. &lt;br/&gt;
Hadoop tasks are supposed to be idempotent hence this should work.&lt;/p&gt;</comment>
                            <comment id="12908854" author="namit" created="Mon, 13 Sep 2010 16:34:02 +0000"  >&lt;p&gt;The approach looks good, but can you move all the checks to compile time instead.&lt;/p&gt;

&lt;p&gt;I mean, while generating a plan, create a S3FileSinkOperator instead of FileSinkOperator, if the&lt;br/&gt;
destination under consideration is on S3 FileSystem - there will be no move task etc.&lt;br/&gt;
The explain work will show the correct plan&lt;/p&gt;


&lt;p&gt;The commit for S3FileSystem will be a no-op. That way, FileSinkOperator does not change much&lt;/p&gt;</comment>
                            <comment id="12910886" author="vaggarw" created="Sat, 18 Sep 2010 01:19:37 +0000"  >&lt;p&gt;I think that is a good suggestion.&lt;br/&gt;
I will try to break down the functionality into a separate class and will resubmit the patch.&lt;/p&gt;</comment>
                            <comment id="12912828" author="vaggarw" created="Tue, 21 Sep 2010 03:46:00 +0000"  >&lt;p&gt;I tried to change create a new class S3FileSinkOperator but there seems to be a lot of complexity involved in extending the existing FileSinkOperator class.&lt;/p&gt;

&lt;p&gt;Most of the changes that are required are in createBucketFiles() method. Overriding that method will lead to a lot of repeated code which would be very hard to maintain. That method needs to be refactored into smaller methods in order to extend FileSinkOperator. I should be able to do it but that seemed to defeat the purpose of not changing FileSinkOperator  much. Please let me know if you are OK with refactoring the FileSinkOperator class into smaller methods.&lt;/p&gt;

&lt;p&gt;Based on my investigations I still feel that the current approach is better. You would notice that there are very few changes to the FileSinkOperator in the current patch.&lt;br/&gt;
I have just introduced a new variable &quot;fsSupportsMove&quot; which is always parallel to isNativeTable (an existing boolean variable).&lt;br/&gt;
The only reason I choose not to reuse isNativeTable variable is to allow the functionality of non-native tables to grow independent of the file systems not supporting move.&lt;/p&gt;

&lt;p&gt;Please review the patch one more time considering the above argument and let me know which approach do you think is best.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Vaibhav&lt;/p&gt;</comment>
                            <comment id="12912849" author="namit" created="Tue, 21 Sep 2010 05:55:18 +0000"  >&lt;p&gt;I will take a look and get back to you&lt;/p&gt;</comment>
                            <comment id="12915383" author="vaggarw" created="Mon, 27 Sep 2010 17:36:59 +0000"  >&lt;p&gt;Hey Namit&lt;/p&gt;

&lt;p&gt;Please let me know what you think of this.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Vaibhav&lt;/p&gt;</comment>
                            <comment id="12918611" author="jsensarma" created="Wed, 6 Oct 2010 17:52:29 +0000"  >&lt;p&gt;if we are overwriting a table (&apos;insert overwrite table&apos;) - do we make sure that if the query/job fails in between - then some of the files (from maps/reduces that did succeed) are not left in the table&apos;s directory?&lt;/p&gt;</comment>
                            <comment id="12920788" author="richcole" created="Wed, 13 Oct 2010 22:37:08 +0000"  >&lt;p&gt;Hi Joydeep,&lt;/p&gt;

&lt;p&gt;The patch as proposed makes no attempt to cleanup the output directory in the case that jobflow failed. &lt;/p&gt;

&lt;p&gt;If I write to a table or directory into Amazon S3 and the Hadoop job ultimately fails then the directory contents will have been modified. Previous results will have been removed. Concequently it is not easy to preserve the property that Hive statement failure implies to no change to the destination. Given that the destination may change even though the statement fails, how important do you consider it that the result be no records, rather than a partial set of records?&lt;/p&gt;

&lt;p&gt;I know that with HDFS you attempt to achieve atomicity by doing a directory move at the end of the job. However Amazon S3 doesn&apos;t have an atomic directory move so this isn&apos;t possible. Writing directly to S3 gives a large efficiency gain without making the situation worse than it is today. It is important to message recognise however the different semantics of the two file stores.&lt;/p&gt;

&lt;p&gt;If you think it is important to output empty results rather than partial results we can look into that. Where do you think is the best place in Hive to react to the failure of a job for example by cleaning up spurious output from successful task attempts?&lt;/p&gt;

&lt;p&gt;regards,&lt;/p&gt;

&lt;p&gt;Richard.&lt;/p&gt;</comment>
                            <comment id="12920808" author="jsensarma" created="Wed, 13 Oct 2010 23:38:23 +0000"  >&lt;p&gt;i agree that the speed efficiency may be worth the tradeoff in consistency. as you say - the messaging is critical. can we gate this feature on a new hive option that makes the user conscious of this tradeoff?&lt;/p&gt;

&lt;p&gt;regarding the cleanup - please look at jobClose method in FileSinkOperator (I think). if the hive client is still functioning at the time the job fails - we can make an attempt to clean things up there (assuming that the file names are unique - which i am not sure about right now because we made some changes to shorten file names (that might have to be undone for this feature)).&lt;/p&gt;

&lt;p&gt;one thing we have experienced in the past is that hadoop tasks continue to do stuff even after the job is technically &apos;complete&apos;. so i think while the cleanup can help the 99% use case - there will be marginal cases where the output directory gets written to when it shouldn&apos;t. so having this gated on an option would still be worthwhile IMHO (for users who cannot afford speed-accuracy tradeoff).&lt;/p&gt;</comment>
                            <comment id="15572539" author="stakiar" created="Thu, 13 Oct 2016 17:04:06 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=richcole&quot; class=&quot;user-hover&quot; rel=&quot;richcole&quot;&gt;Richard Cole&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vaggarw&quot; class=&quot;user-hover&quot; rel=&quot;vaggarw&quot;&gt;Vaibhav Aggarwal&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yalovyyi&quot; class=&quot;user-hover&quot; rel=&quot;yalovyyi&quot;&gt;Illya Yalovyy&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=poeppt&quot; class=&quot;user-hover&quot; rel=&quot;poeppt&quot;&gt;Thomas Poepping&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;As part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-14271&quot; title=&quot;FileSinkOperator should not rename files to final paths when S3 is the default destination&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-14271&quot;&gt;HIVE-14271&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-14269&quot; title=&quot;Performance optimizations for data on S3&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-14269&quot;&gt;HIVE-14269&lt;/a&gt;, we are considering implementing something very similar to what this patch did. However, we are still debating between a few different options. Any chance someone could comment on if this approach worked well in production? Were there issues with this approach that caused problems for any users?&lt;/p&gt;

&lt;p&gt;Some of the concerns we have with the Direct Write to S3 from Hive are that the failure semantics need to be improved when writing to S3. Hive needs to make sure that there aren&#8217;t any dangling files left in the final table location on S3. This isn&#8217;t really an issue for writing to HDFS because everything is written to a temp directory and only the successfully written files get renamed to their output location. The temp directory is then deleted at the end of the MR job (similar concerns were raised in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-14271&quot; title=&quot;FileSinkOperator should not rename files to final paths when S3 is the default destination&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-14271&quot;&gt;HIVE-14271&lt;/a&gt;). &lt;/p&gt;

&lt;p&gt;According to the AWS docs, EMR 4.x took the Direct Write approach, but EMR 5.x doesn&apos;t (ref: &lt;a href=&quot;http://docs.aws.amazon.com/ElasticMapReduce/latest/ReleaseGuide/emr-hive-differences.html#emr-hive-diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://docs.aws.amazon.com/ElasticMapReduce/latest/ReleaseGuide/emr-hive-differences.html#emr-hive-diff&lt;/a&gt;). The docs say that the Direct Write to S3 was eliminated and that EMR 5.x writes to a staging file on S3, and then copies the data to the final table location on S3. Any chance someone could comment on why the approach was changed? Were there fundamental issues with the approach that caused it to not work well in production.&lt;/p&gt;

&lt;p&gt;Any help / feedback on this would be greatly appreciated, since we probably shouldn&apos;t implement the Direct Write Approach if it doesn&apos;t work well.&lt;/p&gt;</comment>
                            <comment id="15767027" author="poeppt" created="Wed, 21 Dec 2016 13:12:32 +0000"  >&lt;p&gt;Hi Sahil,&lt;/p&gt;

&lt;p&gt;Yes, direct write works well in production. There are definitely some difficult design decisions to be made, and as you say, there is no great solution to clean up after failure. Some other issues are: self-referencing insert overwrite data loss, metadata loss in dynamic partitioning, no good visibility of partial results. There are workarounds / best practices for these, though. We are happy to engage in conversation about pros and cons.&lt;/p&gt;

&lt;p&gt;The biggest thing we would like to stress with these implementations is that they should be pluggable. The solution should be as generic as possible to avoid spaghetti code.&lt;/p&gt;

&lt;p&gt;We think the best solution is to make this a conversation about the best design. We are happy to participate in a community design and implementation, drawing on our experience with these types of issues.&lt;/p&gt;</comment>
                            <comment id="16386192" author="stevel@apache.org" created="Mon, 5 Mar 2018 15:16:30 +0000"  >&lt;p&gt;This is the wrong way to  handle variations in FS semantics; once we add the ability to query FS Capabilities (Hadoop 3.2?) then all filesystems could be probed for their semantics. Even so, I dont think this is correct. What we&apos;ve done in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-13786&quot; title=&quot;Add S3A committers for zero-rename commits to S3 endpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-13786&quot;&gt;&lt;del&gt;HADOOP-13786&lt;/del&gt;&lt;/a&gt; gives you atomic task commit and fast job-commit semantics without playing any rename games at all.&lt;/p&gt;

&lt;p&gt;I&apos;d recommend closing this as a WONTFIX, but reemphasise the underlying problem, &quot;how to commit work to a store with neither consistency nor O(1) atomic renames&quot; remains, at least for S3 &amp;amp; Openstack Swift.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12515458">HIVE-2308</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12990523">HIVE-14269</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12454066" name="HIVE-1620.patch" size="21144" author="vaggarw" created="Wed, 8 Sep 2010 02:14:32 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 8 Sep 2010 05:18:51 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42419</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            46 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lg1j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123249</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-1621] Disable join filters for outer joins.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1621</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;As suggested at &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1534?focusedCommentId=12907001&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12907001&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;comment &lt;/a&gt;, SemanticAnalyzer should give out error if join filter is specified for outer joins.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12473528">HIVE-1621</key>
            <summary>Disable join filters for outer joins.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="amareshwari">Amareshwari Sriramadasu</assignee>
                                    <reporter username="amareshwari">Amareshwari Sriramadasu</reporter>
                        <labels>
                    </labels>
                <created>Wed, 8 Sep 2010 05:21:41 +0000</created>
                <updated>Wed, 22 Sep 2010 03:51:50 +0000</updated>
                            <resolved>Wed, 22 Sep 2010 03:51:50 +0000</resolved>
                                                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12908859" author="namit" created="Mon, 13 Sep 2010 16:56:16 +0000"  >&lt;p&gt;See &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1534&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1534&lt;/a&gt; for the offending test case.&lt;/p&gt;</comment>
                            <comment id="12913375" author="amareshwari" created="Wed, 22 Sep 2010 03:51:50 +0000"  >&lt;p&gt;Since &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1534&quot; title=&quot;Join filters do not work correctly with outer joins&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1534&quot;&gt;&lt;del&gt;HIVE-1534&lt;/del&gt;&lt;/a&gt; is committed, resolving this as won&apos;t fix.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12471377">HIVE-1534</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12471377">HIVE-1534</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 13 Sep 2010 16:56:16 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72810</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 18 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lg1r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123250</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1622] Use CombineHiveInputFormat for the merge job if hive.merge.mapredfiles=true</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1622</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently map-only merge (using CombineHiveInputFormat) is only enabled for merging files generated by mappers. It should be used for files generated at readers as well.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12473610">HIVE-1622</key>
            <summary>Use CombineHiveInputFormat for the merge job if hive.merge.mapredfiles=true</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nzhang">Ning Zhang</assignee>
                                    <reporter username="nzhang">Ning Zhang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 8 Sep 2010 18:06:11 +0000</created>
                <updated>Fri, 16 Dec 2011 23:59:34 +0000</updated>
                            <resolved>Wed, 8 Sep 2010 22:46:31 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12907367" author="namit" created="Wed, 8 Sep 2010 19:19:34 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;looks good&lt;/p&gt;</comment>
                            <comment id="12907470" author="namit" created="Wed, 8 Sep 2010 22:46:31 +0000"  >&lt;p&gt;Committed. Thanks Ning&lt;/p&gt;</comment>
                            <comment id="12908616" author="nzhang" created="Mon, 13 Sep 2010 05:09:25 +0000"  >&lt;p&gt;oops, forgot the patch hadoop 0.17 logs. &lt;/p&gt;</comment>
                            <comment id="12908874" author="namit" created="Mon, 13 Sep 2010 17:39:30 +0000"  >&lt;p&gt;Committed the new log for 0.17&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12454139" name="HIVE-1622.patch" size="129238" author="nzhang" created="Wed, 8 Sep 2010 18:55:52 +0000"/>
                            <attachment id="12454424" name="HIVE-1622_0.17.patch" size="87202" author="nzhang" created="Mon, 13 Sep 2010 05:09:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 8 Sep 2010 19:19:34 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72809</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 20 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lg1z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123251</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1623] Factor out Hadoop version check logic in bin/hive scripts</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1623</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The same Hadoop version check logic is repeated in each of the following files:&lt;/p&gt;

&lt;p&gt;bin/ext/hiveserver.sh&lt;br/&gt;
bin/ext/hwi.sh&lt;br/&gt;
bin/ext/metastore.sh&lt;br/&gt;
bin/ext/util/execHiveCmd.sh&lt;/p&gt;

&lt;p&gt;This code should be refactored into a version check function.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12473622">HIVE-1623</key>
            <summary>Factor out Hadoop version check logic in bin/hive scripts</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="cwsteinbach">Carl Steinbach</reporter>
                        <labels>
                    </labels>
                <created>Wed, 8 Sep 2010 20:25:51 +0000</created>
                <updated>Sat, 25 Dec 2010 15:33:41 +0000</updated>
                            <resolved>Fri, 24 Dec 2010 23:25:59 +0000</resolved>
                                                                    <component>Clients</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12974758" author="appodictic" created="Thu, 23 Dec 2010 21:42:37 +0000"  >&lt;p&gt;I have an jira open to remove all pre-20 tweaks. This will be handled inside that issue.&lt;/p&gt;</comment>
                            <comment id="12974768" author="cwsteinbach" created="Thu, 23 Dec 2010 22:10:47 +0000"  >&lt;p&gt;@Ed: Please link a ticket to the duplicating ticket before resolving it as a duplicate.&lt;/p&gt;</comment>
                            <comment id="12975062" author="appodictic" created="Sat, 25 Dec 2010 15:33:41 +0000"  >&lt;p&gt;@Carl. Sorry I will try to do this when I can. We have a good number of dupe and invalid tickets. Closing them out is much easier then having to research the two or three dupes a ticket has or trying to figure out when the issue was resolved. Almost chicken and egg now, with 600 open  tickets people are very likely to not research and simply open another dupe.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12477189">HIVE-1705</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12473263">HIVE-1613</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12463824">HIVE-1338</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 23 Dec 2010 21:42:37 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72808</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 5 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lg27:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123252</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1624] Patch to allows scripts in S3 location</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1624</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;I want to submit a patch which allows user to run scripts located in S3.&lt;/p&gt;

&lt;p&gt;This patch enables Hive to download the hive scripts located in S3 buckets and execute them. This saves users the effort of copying scripts to HDFS before executing them.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Vaibhav&lt;/p&gt;</description>
                <environment></environment>
        <key id="12473631">HIVE-1624</key>
            <summary>Patch to allows scripts in S3 location</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vaggarw">Vaibhav Aggarwal</assignee>
                                    <reporter username="vaggarw">Vaibhav Aggarwal</reporter>
                        <labels>
                    </labels>
                <created>Wed, 8 Sep 2010 22:26:01 +0000</created>
                <updated>Fri, 16 Dec 2011 23:59:22 +0000</updated>
                            <resolved>Thu, 30 Sep 2010 21:35:05 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12908729" author="he yongqiang" created="Mon, 13 Sep 2010 11:38:48 +0000"  >&lt;p&gt;S3 -&amp;gt; client -&amp;gt; cluster maybe better than directly downloading the script from S3 to TaskTracker node.&lt;br/&gt;
There may be thousands of concurrent downloading request to S3 for downloading a script. (I agree that the script can be cached in local machine, but right now hive does not do any cache clean up).&lt;br/&gt;
S3 -&amp;gt; client -&amp;gt; cluster will be able to use hadoop distributed cache.&lt;/p&gt;</comment>
                            <comment id="12913124" author="vaggarw" created="Tue, 21 Sep 2010 17:57:45 +0000"  >&lt;p&gt;Thanks for looking at this. I will experiment with the suggested approach today.&lt;/p&gt;</comment>
                            <comment id="12913875" author="vaggarw" created="Thu, 23 Sep 2010 01:24:48 +0000"  >&lt;p&gt;Hi&lt;/p&gt;

&lt;p&gt;I have attached a new patch.&lt;br/&gt;
It uses the add_resource functionality to make the script available to all nodes instead of downloading the script on each node.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Vaibhav&lt;/p&gt;</comment>
                            <comment id="12913878" author="he yongqiang" created="Thu, 23 Sep 2010 01:47:37 +0000"  >&lt;p&gt;looks good basically. need to remove some unneeded logging information&lt;/p&gt;

&lt;p&gt;one main problem here is to determine when to download file. We can not simply try downloading file when can not be found in local. &lt;br/&gt;
Sometimes scripts exist in some remote dir that the hadoop cluster nodes can access but the client can not.&lt;/p&gt;</comment>
                            <comment id="12913881" author="vaggarw" created="Thu, 23 Sep 2010 02:12:18 +0000"  >&lt;p&gt;I will remove some of the unnecessary log statements.&lt;/p&gt;

&lt;p&gt;The patch consists of two parts:&lt;/p&gt;

&lt;p&gt;1. It extends the add file/jar functionality to download remote files. I think it makes sense as it is as the user is expected to have access to the file from the client location. In case that is not true, the patch will fail with an IOException which will notify the user of the problem appropriately.&lt;/p&gt;

&lt;p&gt;2. It eliminates the need for user to run an extra add file command. I think that the current norm in Hive is for the user to execute the &apos;add file ....&apos; command to add a resource before using it in the transform function. This patch allows user to directly specify a resource instead of doing it in two steps.&lt;/p&gt;

&lt;p&gt;The patch does not attempt to address the case when the script exists on a remote location not accessible to the client.&lt;/p&gt;

&lt;p&gt;Please let me know what you think.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Vaibhav&lt;/p&gt;</comment>
                            <comment id="12913895" author="he yongqiang" created="Thu, 23 Sep 2010 04:00:09 +0000"  >&lt;p&gt;For 2, sometimes it is actually a common case. For example, User can use php but no need to have php program in local. We can add some simple rule for downloading resource files, such as starts with s3 schema in this case.  &lt;/p&gt;</comment>
                            <comment id="12914149" author="vaggarw" created="Thu, 23 Sep 2010 18:34:18 +0000"  >&lt;p&gt;So current patch matches the &quot;&amp;lt;word&amp;gt;://&amp;lt;anything&amp;gt;&quot; in file path before downloading the file.&lt;br/&gt;
Should I modify it to be &quot;hdfs://&amp;lt;anything&amp;gt; || s3://&amp;lt;anything&amp;gt;&quot; like path?&lt;br/&gt;
The first one is a more generic case to match any file system.&lt;br/&gt;
I can implement it either ways.&lt;br/&gt;
Please let me know what you prefer.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Vaibhav&lt;/p&gt;</comment>
                            <comment id="12914176" author="he yongqiang" created="Thu, 23 Sep 2010 19:17:08 +0000"  >&lt;p&gt;&amp;gt;&amp;gt;Should I modify it to be &quot;hdfs://&amp;lt;anything&amp;gt; || s3://&amp;lt;anything&amp;gt;&quot; like path?&lt;br/&gt;
Yes. That will be a great start. We can add more if needed in future.&lt;/p&gt;

&lt;p&gt;Also please make sure if a program, neither hdfs nor s3 , can not be found locally, the query should not fail in semantic analyzer. Otherwise, it may break a lot of existing queries.&lt;/p&gt;</comment>
                            <comment id="12914314" author="vaggarw" created="Fri, 24 Sep 2010 01:53:44 +0000"  >&lt;p&gt;Hi&lt;/p&gt;

&lt;p&gt;I made the changes you had suggested.&lt;br/&gt;
Please review the patch.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Vaibhav&lt;/p&gt;</comment>
                            <comment id="12915391" author="he yongqiang" created="Mon, 27 Sep 2010 17:50:52 +0000"  >&lt;p&gt;Great. some nitpick, sorry for not posting them in the previous comment. &lt;br/&gt;
1) It seems there is still one logging code &quot;+    getConsole().printInfo(&quot;Testing &quot; + value);&quot;&lt;br/&gt;
2) Also can you add one junit test for DosToUnix?&lt;br/&gt;
3) Do you think it maybe better to move fetchFilesNotInLocalFilesystem to SessionState?&lt;/p&gt;</comment>
                            <comment id="12915926" author="vaggarw" created="Tue, 28 Sep 2010 21:16:15 +0000"  >&lt;p&gt;Hi&lt;/p&gt;

&lt;p&gt;I have attached a new patch.&lt;br/&gt;
I have added unit tests for DosToUnix and removede the logging code.&lt;br/&gt;
I still kept the fetchFilesNotInLocalFilesystem in SemanticAnalyzer as I felt that it was not shared code and also depended on calls to getScriptProgName(). I felt that SessionState calling into SemanticAnalyzer might not be a good idea.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Vaibhav&lt;/p&gt;</comment>
                            <comment id="12915942" author="he yongqiang" created="Tue, 28 Sep 2010 22:15:46 +0000"  >&lt;p&gt;Mostly look good. &lt;/p&gt;

&lt;p&gt;In your testcase, can you put the new script file in&lt;br/&gt;
new Path(System.getProperty(&quot;test.data.dir&quot;, &quot;.&quot;) + &quot;file name&quot;) ?&lt;/p&gt;

&lt;p&gt;By move fetchFilesNotInLocalFilesystem to SessionState, you can keep getScriptProgName() ect in SemanticAnalyer by changing fetchFilesNotInLocalFilesystem&apos;s arguments to pass in the command etc. I am also ok with current way.&lt;/p&gt;</comment>
                            <comment id="12915995" author="vaggarw" created="Wed, 29 Sep 2010 02:17:14 +0000"  >&lt;p&gt;Made the change.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Vaibhav&lt;/p&gt;</comment>
                            <comment id="12916242" author="he yongqiang" created="Wed, 29 Sep 2010 19:12:44 +0000"  >&lt;p&gt;+1 running tests&lt;/p&gt;</comment>
                            <comment id="12916688" author="he yongqiang" created="Thu, 30 Sep 2010 21:35:05 +0000"  >&lt;p&gt;I just committed! Thanks Vaibhav Aggarwal!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12455979">HIVE-1157</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12455337" name="HIVE-1624-2.patch" size="11185" author="vaggarw" created="Thu, 23 Sep 2010 01:22:53 +0000"/>
                            <attachment id="12455457" name="HIVE-1624-3.patch" size="11224" author="vaggarw" created="Fri, 24 Sep 2010 01:52:38 +0000"/>
                            <attachment id="12455874" name="HIVE-1624-4.patch" size="15046" author="vaggarw" created="Tue, 28 Sep 2010 21:14:12 +0000"/>
                            <attachment id="12455894" name="HIVE-1624-5.patch" size="15047" author="vaggarw" created="Wed, 29 Sep 2010 02:16:55 +0000"/>
                            <attachment id="12454167" name="HIVE-1624.patch" size="9956" author="vaggarw" created="Wed, 8 Sep 2010 22:28:02 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 13 Sep 2010 11:38:48 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 17 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lg2f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123253</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1625] Added implementation to HivePreparedStatement, HiveBaseResultSet and HiveQueryResultSet.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1625</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;We implemented several of the HivePreparedStatement set methods, such as setString(int, String) and the means to substitute place holders in the SQL with the values set.  &lt;br/&gt;
HiveQueryResultSet and HiveBaseResultSet were enhanced so that getStatement() could be implemented.&lt;/p&gt;

&lt;p&gt;See attached change log for details.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12473724">HIVE-1625</key>
            <summary>Added implementation to HivePreparedStatement, HiveBaseResultSet and HiveQueryResultSet.</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="sflatley@pentaho.com">Sean Flatley</assignee>
                                    <reporter username="sflatley@pentaho.com">Sean Flatley</reporter>
                        <labels>
                    </labels>
                <created>Thu, 9 Sep 2010 20:16:12 +0000</created>
                <updated>Tue, 5 Apr 2011 22:13:48 +0000</updated>
                                                                            <component>JDBC</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="12907764" author="sflatley@pentaho.com" created="Thu, 9 Sep 2010 20:18:14 +0000"  >&lt;p&gt;Change log and test log file.&lt;/p&gt;</comment>
                            <comment id="12907837" author="sflatley@pentaho.com" created="Fri, 10 Sep 2010 00:10:31 +0000"  >&lt;p&gt;Patch.&lt;/p&gt;</comment>
                            <comment id="12907843" author="sflatley@pentaho.com" created="Fri, 10 Sep 2010 00:17:09 +0000"  >&lt;p&gt;Requesting a contribution code review.&lt;/p&gt;

&lt;p&gt;Our unit tests check to see if the &quot;built&quot; sql from the parameter values are correct.  We have experienced problems with &quot;where&quot; clauses in prepared statements that are run against the standalone database used in the unit tests.  We have not experience this problem when running the JDBC driver with our products against our development Hive server.&lt;/p&gt;

&lt;p&gt;I will browse Jira for a case on this.  If not found I will create a reproduction path and create an issue.&lt;/p&gt;
</comment>
                            <comment id="12909040" author="jvs" created="Mon, 13 Sep 2010 23:16:09 +0000"  >&lt;p&gt;Added some initial comments at&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://review.cloudera.org/r/827/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://review.cloudera.org/r/827/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Will have more later.&lt;/p&gt;</comment>
                            <comment id="12909046" author="hbasereviewboard" created="Mon, 13 Sep 2010 23:38:17 +0000"  >&lt;p&gt;Message from: &quot;John Sichi&quot; &amp;lt;jsichi@facebook.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/827/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/827/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for Hive Developers.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;review by JVS&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1625&quot; title=&quot;Added implementation to HivePreparedStatement, HiveBaseResultSet and HiveQueryResultSet.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1625&quot;&gt;HIVE-1625&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/HIVE-1625&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HIVE-1625&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/data/files/pstmt.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/data/files/pstmt.txt&lt;/a&gt; PRE-CREATION &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveBaseResultSet.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveBaseResultSet.java&lt;/a&gt; 995557 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveCallableStatement.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveCallableStatement.java&lt;/a&gt; 995557 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveDatabaseMetaData.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveDatabaseMetaData.java&lt;/a&gt; 995557 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveParameterValue.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveParameterValue.java&lt;/a&gt; PRE-CREATION &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HivePreparedStatement.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HivePreparedStatement.java&lt;/a&gt; 995557 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveQueryResultSet.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveQueryResultSet.java&lt;/a&gt; 995557 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveStatement.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveStatement.java&lt;/a&gt; 995557 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/test/org/apache/hadoop/hive/jdbc/MockHiveConnection.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/test/org/apache/hadoop/hive/jdbc/MockHiveConnection.java&lt;/a&gt; PRE-CREATION &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/test/org/apache/hadoop/hive/jdbc/MockHivePreparedStatement.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/test/org/apache/hadoop/hive/jdbc/MockHivePreparedStatement.java&lt;/a&gt; PRE-CREATION &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/test/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/test/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java&lt;/a&gt; 995557 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.cloudera.org/r/827/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/827/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;John&lt;/p&gt;

</comment>
                            <comment id="12910263" author="hbasereviewboard" created="Thu, 16 Sep 2010 18:54:57 +0000"  >&lt;p&gt;Message from: &quot;John Sichi&quot; &amp;lt;jsichi@facebook.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/827/#review1246&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/827/#review1246&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;



&lt;p&gt;&lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveParameterValue.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveParameterValue.java&lt;/a&gt;&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/827/#comment4208&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/827/#comment4208&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    These data members should be private.&lt;/p&gt;



&lt;p&gt;&lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HivePreparedStatement.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HivePreparedStatement.java&lt;/a&gt;&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/827/#comment4209&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/827/#comment4209&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    What is the purpose of typeMatches?&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;John&lt;/li&gt;
&lt;/ul&gt;



</comment>
                    </comments>
                    <attachments>
                            <attachment id="12454258" name="HIVE-1625.patch" size="72944" author="sflatley@pentaho.com" created="Fri, 10 Sep 2010 00:10:31 +0000"/>
                            <attachment id="12454233" name="changelog.txt" size="1930" author="sflatley@pentaho.com" created="Thu, 9 Sep 2010 20:18:14 +0000"/>
                            <attachment id="12454234" name="testJdbcDriver.log" size="166344" author="sflatley@pentaho.com" created="Thu, 9 Sep 2010 20:18:14 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 13 Sep 2010 23:16:09 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42418</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 19 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08ndj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>48386</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>We implemented several HivePreparedStatement methods for setting parameters.  The class also builds sql based on the parameters.  The classes&amp;#39; setNull methods have been implemented as well.&lt;br/&gt;
</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            </customfields>
    </item>


<item>
            <title>[HIVE-1626] stop using java.util.Stack</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1626</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;We currently use Stack as part of the generic node walking library.  Stack should not be used for this since its inheritance from Vector incurs superfluous synchronization overhead.&lt;/p&gt;

&lt;p&gt;Most projects end up adding an ArrayStack implementation and using that instead.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12473736">HIVE-1626</key>
            <summary>stop using java.util.Stack</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png" description="A patch for this issue has been uploaded to JIRA by a contributor.">Patch Available</status>
                    <statusCategory id="4" key="indeterminate" colorName="yellow"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="teddy.choi">Teddy Choi</assignee>
                                    <reporter username="jvs">John Sichi</reporter>
                        <labels>
                    </labels>
                <created>Thu, 9 Sep 2010 21:57:48 +0000</created>
                <updated>Thu, 30 Mar 2017 21:33:42 +0000</updated>
                                            <version>0.7.0</version>
                                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13155610" author="jvs" created="Wed, 23 Nov 2011 01:20:04 +0000"  >&lt;p&gt;We can use ArrayDeque.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://docs.oracle.com/javase/6/docs/api/java/util/Deque.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://docs.oracle.com/javase/6/docs/api/java/util/Deque.html&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15876290" author="teddy.choi" created="Tue, 21 Feb 2017 17:03:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=appodictic&quot; class=&quot;user-hover&quot; rel=&quot;appodictic&quot;&gt;Edward Capriolo&lt;/a&gt;, if you don&apos;t mind, may I do this issue?&lt;/p&gt;

&lt;p&gt;Hive has many optimization rules, and low-latency workloads nowadays. So it became more critical. The node walking library should use Deque (or ArrayDeque) instead of Stack.&lt;/p&gt;</comment>
                            <comment id="15876298" author="appodictic" created="Tue, 21 Feb 2017 17:07:08 +0000"  >&lt;p&gt;IT is not as easy as it seems. Many usages for example are in antlr generated classes and such.&lt;/p&gt;</comment>
                            <comment id="15876301" author="teddy.choi" created="Tue, 21 Feb 2017 17:11:14 +0000"  >&lt;p&gt;I made a draft patch. &lt;a href=&quot;https://reviews.apache.org/r/56894/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/56894/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15876354" author="teddy.choi" created="Tue, 21 Feb 2017 17:39:54 +0000"  >&lt;p&gt;Thank you, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=appodictic&quot; class=&quot;user-hover&quot; rel=&quot;appodictic&quot;&gt;Edward Capriolo&lt;/a&gt;. My draft patch includes 130 changed files, including an ANTLR file. It&apos;s quite complex and huge.&lt;/p&gt;</comment>
                            <comment id="15877404" author="teddy.choi" created="Wed, 22 Feb 2017 03:34:51 +0000"  >&lt;p&gt;125 files are changed. Most of files are subclasses of NodeProcessor and Dispatcher. They now use Deque instead of Stack. However, there were dozens of Stack.get(int) calls, which is not in ArrayDeque. I implemented Utils.get(Deque, int) for it with Deque.decendingIterator(), which impacts GC.&lt;/p&gt;</comment>
                            <comment id="15877679" author="hiveqa" created="Wed, 22 Feb 2017 07:33:36 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12853867/HIVE-1626.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12853867/HIVE-1626.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/3686/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/3686/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/3686/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/3686/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-3686/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-3686/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
Apply anyway? [n] 
Skipping patch.
3 out of 3 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/SparkMapJoinResolver.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/Vectorizer.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
12 out of 12 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/Vectorizer.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/index/IndexWhereProcessor.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/index/IndexWhereProcessor.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/index/IndexWhereTaskDispatcher.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
3 out of 3 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/index/IndexWhereTaskDispatcher.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/CombineEquivalentWorkResolver.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/CombineEquivalentWorkResolver.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SetSparkReducerParallelism.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SetSparkReducerParallelism.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SparkJoinHintOptimizer.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SparkJoinHintOptimizer.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SparkJoinOptimizer.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SparkJoinOptimizer.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SparkMapJoinOptimizer.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SparkMapJoinOptimizer.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SparkReduceSinkMapJoinProc.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
6 out of 6 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SparkReduceSinkMapJoinProc.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SparkSMBJoinHintOptimizer.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SparkSMBJoinHintOptimizer.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SparkSkewJoinProcFactory.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SparkSkewJoinProcFactory.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SparkSkewJoinResolver.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SparkSkewJoinResolver.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SparkSortMergeJoinOptimizer.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
6 out of 6 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/optimizer/spark/SparkSortMergeJoinOptimizer.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/stats/annotation/StatsRulesProcFactory.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
9 out of 9 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/optimizer/stats/annotation/StatsRulesProcFactory.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/optimizer/unionproc/UnionProcFactory.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
13 out of 13 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/optimizer/unionproc/UnionProcFactory.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/AppMasterEventProcessor.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/AppMasterEventProcessor.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/FileSinkProcessor.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/FileSinkProcessor.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/GenTezUtils.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
1 out of 1 hunk ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/GenTezUtils.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/GenTezWork.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
3 out of 3 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/GenTezWork.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/MacroSemanticAnalyzer.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/MacroSemanticAnalyzer.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/PrintOpTreeProcessor.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/PrintOpTreeProcessor.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/ProcessAnalyzeTable.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/ProcessAnalyzeTable.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/QBSubQuery.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
3 out of 3 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/QBSubQuery.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
1 out of 1 hunk ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/TableAccessAnalyzer.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
4 out of 4 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/TableAccessAnalyzer.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/TezCompiler.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
6 out of 6 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/TezCompiler.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
13 out of 13 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/UnionProcessor.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/UnionProcessor.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/spark/GenSparkWork.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/spark/GenSparkWork.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SparkCompiler.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
5 out of 5 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SparkCompiler.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SparkFileSinkProcessor.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SparkFileSinkProcessor.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SparkProcessAnalyzeTable.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SparkProcessAnalyzeTable.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SplitOpTreeForDPP.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SplitOpTreeForDPP.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/ppd/ExprWalkerProcFactory.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
5 out of 5 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/ppd/ExprWalkerProcFactory.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
11 out of 11 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/ppd/PredicateTransitivePropagate.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
3 out of 3 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/ppd/PredicateTransitivePropagate.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/ppd/SyntheticJoinPredicate.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
3 out of 3 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/ppd/SyntheticJoinPredicate.java.rej
patching file ql/src/java/org/apache/hadoop/hive/ql/tools/LineageInfo.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
2 out of 2 hunks ignored -- saving rejects to file ql/src/java/org/apache/hadoop/hive/ql/tools/LineageInfo.java.rej
patching file ql/src/test/org/apache/hadoop/hive/ql/lib/TestRuleRegExp.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
5 out of 5 hunks ignored -- saving rejects to file ql/src/test/org/apache/hadoop/hive/ql/lib/TestRuleRegExp.java.rej
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12853867 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15877700" author="teddy.choi" created="Wed, 22 Feb 2017 07:47:18 +0000"  >&lt;p&gt;Re-uploading the patch.&lt;/p&gt;</comment>
                            <comment id="15878614" author="hiveqa" created="Wed, 22 Feb 2017 16:21:04 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12853906/HIVE-1626.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12853906/HIVE-1626.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/3693/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/3693/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/3693/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/3693/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-3693/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-3693/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Tests exited with: ExecutionException: java.util.concurrent.ExecutionException: org.apache.hive.ptest.execution.ssh.SSHExecutionException: RSyncResult [localFile=/data/hiveptest/logs/PreCommit-HIVE-Build-3693/failed/115-TestSparkCliDriver-escape_distributeby1.q-join9.q-groupby2.q-and-12-more, remoteFile=/home/hiveptest/35.184.41.238-hiveptest-0/logs/, getExitCode()=11, getException()=null, getUser()=hiveptest, getHost()=35.184.41.238, getInstance()=0]: &apos;Warning: Permanently added &apos;35.184.41.238&apos; (ECDSA) to the list of known hosts.
receiving incremental file list
./
maven-test.txt

              0   0%    0.00kB/s    0:00:00  
         42,159 100%   40.21MB/s    0:00:00 (xfr#1, to-chk=16/18)
logs/
logs/derby.log

              0   0%    0.00kB/s    0:00:00  
          1,011 100%  987.30kB/s    0:00:00 (xfr#2, to-chk=13/18)
logs/hive.log

              0   0%    0.00kB/s    0:00:00  
     40,370,176   0%   38.04MB/s    0:13:26  
     90,112,000   0%   42.71MB/s    0:11:57  
    145,358,848   0%   46.04MB/s    0:11:04  
    198,934,528   0%   47.30MB/s    0:10:45  
    254,345,216   0%   51.02MB/s    0:09:57  
    310,149,120   0%   52.46MB/s    0:09:39  
    362,283,008   1%   51.72MB/s    0:09:47  
    417,431,552   1%   52.07MB/s    0:09:42  
    473,530,368   1%   52.22MB/s    0:09:39  
    529,301,504   1%   52.22MB/s    0:09:38  
    584,482,816   1%   52.95MB/s    0:09:29  
    630,456,320   2%   50.76MB/s    0:09:53  
    683,409,408   2%   50.04MB/s    0:10:00  
    738,983,936   2%   49.90MB/s    0:10:01  
    794,951,680   2%   50.07MB/s    0:09:58  
    850,427,904   2%   52.34MB/s    0:09:31  
    895,549,440   2%   50.45MB/s    0:09:51  
    950,763,520   3%   50.43MB/s    0:09:50  
  1,006,731,264   3%   50.42MB/s    0:09:49  
  1,050,148,864   3%   47.46MB/s    0:10:25  
  1,075,838,976   3%   42.62MB/s    0:11:36  
  1,102,741,504   3%   35.95MB/s    0:13:44  
  1,131,937,792   3%   29.53MB/s    0:16:42  
  1,159,200,768   3%   25.67MB/s    0:19:12  
  1,187,250,176   3%   26.31MB/s    0:18:43  
  1,211,629,568   3%   25.62MB/s    0:19:12  
  1,235,484,672   3%   24.35MB/s    0:20:12  
  1,259,077,632   4%   23.44MB/s    0:20:58  
  1,281,622,016   4%   22.22MB/s    0:22:06  
  1,306,525,696   4%   22.36MB/s    0:21:56  
  1,330,642,944   4%   22.46MB/s    0:21:49  
  1,353,973,760   4%   22.50MB/s    0:21:46  
  1,377,042,432   4%   22.57MB/s    0:21:41  
  1,400,111,104   4%   22.14MB/s    0:22:06  
  1,423,704,064   4%   21.95MB/s    0:22:16  
  1,445,986,304   4%   21.70MB/s    0:22:30  
  1,465,909,248   4%   20.92MB/s    0:23:20  
  1,489,240,064   4%   21.02MB/s    0:23:12  
  1,510,211,584   4%   20.47MB/s    0:23:49  
  1,530,396,672   4%   19.97MB/s    0:24:23  
  1,553,465,344   4%   20.71MB/s    0:23:29  
  1,577,058,304   5%   20.73MB/s    0:23:27  
  1,600,389,120   5%   21.29MB/s    0:22:49  
  1,623,719,936   5%   22.04MB/s    0:22:02  
  1,647,312,896   5%   22.20MB/s    0:21:51  
  1,670,643,712   5%   22.14MB/s    0:21:53  
  1,693,974,528   5%   22.14MB/s    0:21:52  
  1,717,305,344   5%   22.14MB/s    0:21:52  
  1,740,898,304   5%   22.14MB/s    0:21:51  
  1,764,229,120   5%   22.14MB/s    0:21:50  
  1,788,608,512   5%   22.34MB/s    0:21:36  
  1,813,610,496   5%   22.78MB/s    0:21:10  
  1,839,464,448   5%   23.27MB/s    0:20:42  
  1,864,368,128   5%   23.67MB/s    0:20:21  
  1,890,058,240   6%   23.97MB/s    0:20:04  
  1,915,748,352   6%   24.06MB/s    0:19:58  
  1,941,962,752   6%   24.15MB/s    0:19:53  
  1,966,342,144   6%   24.03MB/s    0:19:58  
  1,991,507,968   6%   23.97MB/s    0:20:00  
  2,017,198,080   6%   23.97MB/s    0:19:59  
  2,042,626,048   6%   23.82MB/s    0:20:06  
  2,067,824,640   6%   24.02MB/s    0:19:55  
  2,093,481,984   6%   24.05MB/s    0:19:52  
  2,119,172,096   6%   24.00MB/s    0:19:53  
  2,144,600,064   6%   23.98MB/s    0:19:53  
  2,170,290,176   6%   23.99MB/s    0:19:52  
  2,196,504,576   6%   24.13MB/s    0:19:44  
  2,220,883,968   7%   23.92MB/s    0:19:53  
  2,246,574,080   7%   23.95MB/s    0:19:51  
  2,272,264,192   7%   23.95MB/s    0:19:50  
  2,297,954,304   7%   23.83MB/s    0:19:55  
  2,324,168,704   7%   24.21MB/s    0:19:35  
  2,348,548,096   7%   23.91MB/s    0:19:49  
  2,374,238,208   7%   23.94MB/s    0:19:46  
  2,399,141,888   7%   23.84MB/s    0:19:50  
  2,424,832,000   7%   23.67MB/s    0:19:57  
  2,450,522,112   7%   24.07MB/s    0:19:36  
  2,475,687,936   7%   23.92MB/s    0:19:43  
  2,501,115,904   7%   23.95MB/s    0:19:40  
  2,526,281,728   8%   23.90MB/s    0:19:42  
  2,551,971,840   8%   23.84MB/s    0:19:44  
  2,578,186,240   8%   24.13MB/s    0:19:28  
  2,602,565,632   8%   23.98MB/s    0:19:35  
  2,628,255,744   8%   24.05MB/s    0:19:30  
  2,653,945,856   8%   24.05MB/s    0:19:29  
  2,678,849,536   8%   23.77MB/s    0:19:42  
  2,705,063,936   8%   24.10MB/s    0:19:25  
  2,730,229,760   8%   24.02MB/s    0:19:27  
  2,755,133,440   8%   23.94MB/s    0:19:30  
  2,780,299,264   8%   24.00MB/s    0:19:27  
  2,805,989,376   8%   23.87MB/s    0:19:32  
  2,831,417,344   9%   23.92MB/s    0:19:28  
  2,857,107,456   9%   23.98MB/s    0:19:24  
  2,882,273,280   9%   24.02MB/s    0:19:21  
  2,907,963,392   9%   24.01MB/s    0:19:21  
  2,932,867,072   9%   23.92MB/s    0:19:24  
  2,959,081,472   9%   24.07MB/s    0:19:16  
  2,984,247,296   9%   23.98MB/s    0:19:19  
  3,009,150,976   9%   23.92MB/s    0:19:21  
  3,034,841,088   9%   24.02MB/s    0:19:15  
  3,060,531,200   9%   23.90MB/s    0:19:20  
  3,086,221,312   9%   24.02MB/s    0:19:13  
  3,111,124,992   9%   24.02MB/s    0:19:12  
  3,136,815,104   9%   24.00MB/s    0:19:12  
  3,162,505,216  10%   24.02MB/s    0:19:10  
  3,187,933,184  10%   23.99MB/s    0:19:10  
  3,213,623,296  10%   24.06MB/s    0:19:06  
  3,238,789,120  10%   24.02MB/s    0:19:07  
  3,263,692,800  10%   23.92MB/s    0:19:11  
  3,289,382,912  10%   23.95MB/s    0:19:08  
  3,314,548,736  10%   23.94MB/s    0:19:07  
  3,339,452,416  10%   23.82MB/s    0:19:13  
  3,365,142,528  10%   23.88MB/s    0:19:09  
  3,390,832,640  10%   23.88MB/s    0:19:07  
  3,416,522,752  10%   23.91MB/s    0:19:05  
  3,441,426,432  10%   23.98MB/s    0:19:01  
  3,466,592,256  11%   23.95MB/s    0:19:01  
  3,492,282,368  11%   23.97MB/s    0:18:59  
  3,517,186,048  11%   23.86MB/s    0:19:03  
  3,542,876,160  11%   23.97MB/s    0:18:57  
  3,568,041,984  11%   23.97MB/s    0:18:56  
  3,592,945,664  11%   23.79MB/s    0:19:03  
  3,618,635,776  11%   23.88MB/s    0:18:58  
  3,644,325,888  11%   23.88MB/s    0:18:57  
  3,670,016,000  11%   23.95MB/s    0:18:52  
  3,695,443,968  11%   24.05MB/s    0:18:47  
  3,721,134,080  11%   24.13MB/s    0:18:42  
  3,746,299,904  11%   24.05MB/s    0:18:45  
  3,771,203,584  11%   23.92MB/s    0:18:50  
  3,796,893,696  12%   23.97MB/s    0:18:46  
  3,822,059,520  12%   23.90MB/s    0:18:49  
  3,847,487,488  12%   23.90MB/s    0:18:48  
  3,873,177,600  12%   24.02MB/s    0:18:41  
  3,898,867,712  12%   23.99MB/s    0:18:41  
  3,924,557,824  12%   24.03MB/s    0:18:38  
  3,949,985,792  12%   24.06MB/s    0:18:36  
  3,975,151,616  12%   23.95MB/s    0:18:40  
  4,000,841,728  12%   23.98MB/s    0:18:38  
  4,026,531,840  12%   23.95MB/s    0:18:38  
  4,051,959,808  12%   24.00MB/s    0:18:35  
  4,077,125,632  12%   23.28MB/s    0:19:08  
  4,105,961,472  13%   24.01MB/s    0:18:32  
  4,131,127,296  13%   24.00MB/s    0:18:31  
  4,156,293,120  13%   23.96MB/s    0:18:32  
  4,181,721,088  13%   24.73MB/s    0:17:57  
  4,207,411,200  13%   24.07MB/s    0:18:25  
  4,233,101,312  13%   24.07MB/s    0:18:24  
  4,258,267,136  13%   24.00MB/s    0:18:26  
  4,283,170,816  13%   23.95MB/s    0:18:27  
  4,308,336,640  13%   23.78MB/s    0:18:35  
  4,334,026,752  13%   23.90MB/s    0:18:28  
  4,358,930,432  13%   23.91MB/s    0:18:26  
  4,384,620,544  13%   24.02MB/s    0:18:20  
  4,409,786,368  14%   24.07MB/s    0:18:17  
  4,434,690,048  14%   23.82MB/s    0:18:28  
  4,455,923,712  14%   22.56MB/s    0:19:28  
  4,487,643,136  14%   23.95MB/s    0:18:19  
  4,512,808,960  14%   23.85MB/s    0:18:23  
  4,537,712,640  14%   23.88MB/s    0:18:21  
  4,563,402,752  14%   25.25MB/s    0:17:20  
  4,585,684,992  14%   23.15MB/s    0:18:53  
  4,614,782,976  14%   24.07MB/s    0:18:09  
  4,640,210,944  14%   24.13MB/s    0:18:05  
  4,665,901,056  14%   24.12MB/s    0:18:04  
  4,691,066,880  14%   24.78MB/s    0:17:34  
  4,715,118,592  14%   23.59MB/s    0:18:27  
  4,746,117,120  15%   24.95MB/s    0:17:25  
  4,773,904,384  15%   25.55MB/s    0:16:59  
  4,801,953,792  15%   26.26MB/s    0:16:31  
  4,829,741,056  15%   27.25MB/s    0:15:54  
  4,854,415,360  15%   25.82MB/s    0:16:46  
  4,885,315,584  15%   26.56MB/s    0:16:16  
  4,913,364,992  15%   26.56MB/s    0:16:15  
  4,941,414,400  15%   26.62MB/s    0:16:12  
  4,969,463,808  15%   27.43MB/s    0:15:43  
  4,994,564,096  15%   25.93MB/s    0:16:36  
  5,029,494,784  15%   27.50MB/s    0:15:38  
  5,059,903,488  16%   28.03MB/s    0:15:19  
  5,092,147,200  16%   28.96MB/s    0:14:49  
  5,124,128,768  16%   30.64MB/s    0:13:59  
  5,152,505,856  16%   29.08MB/s    0:14:43  
  5,187,567,616  16%   30.20MB/s    0:14:09  
  5,218,238,464  16%   29.86MB/s    0:14:18  
  5,249,957,888  16%   29.83MB/s    0:14:18  
  5,281,939,456  16%   30.64MB/s    0:13:54  
  5,308,579,840  16%   28.57MB/s    0:14:53  
  5,347,475,456  16%   30.54MB/s    0:13:55  
  5,378,932,736  17%   30.54MB/s    0:13:53  
  5,410,652,160  17%   30.60MB/s    0:13:51  
  5,442,371,584  17%   31.90MB/s    0:13:16  
  5,468,061,696  17%   28.47MB/s    0:14:51  
  5,510,266,880  17%   30.91MB/s    0:13:39  
  5,542,510,592  17%   31.04MB/s    0:13:35  
  5,574,492,160  17%   31.10MB/s    0:13:32  
  5,606,735,872  17%   32.97MB/s    0:12:45  
  5,633,212,416  17%   29.31MB/s    0:14:20  
  5,670,961,152  18%   30.62MB/s    0:13:42  
  5,701,369,856  18%   30.10MB/s    0:13:55  
  5,728,370,688  18%   28.80MB/s    0:14:32  
  5,755,371,520  18%   28.87MB/s    0:14:29  
  5,779,488,768  18%   25.62MB/s    0:16:18  
  5,801,771,008  18%   23.78MB/s    0:17:33  
  5,823,528,960  18%   22.53MB/s    0:18:31  
  5,844,762,624  18%   21.17MB/s    0:19:41  
  5,865,209,856  18%   20.28MB/s    0:20:32  
  5,881,200,640  18%   18.68MB/s    0:22:17  
  5,905,580,032  18%   19.32MB/s    0:21:31  
  5,925,502,976  18%   19.02MB/s    0:21:50  
  5,946,474,496  18%   19.12MB/s    0:21:42  
  5,967,708,160  18%   20.49MB/s    0:20:15  
  5,986,058,240  19%   19.08MB/s    0:21:43  
  6,009,651,200  19%   19.87MB/s    0:20:50  
  6,030,622,720  19%   19.86MB/s    0:20:50  
  6,052,118,528  19%   19.85MB/s    0:20:49  
  6,073,090,048  19%   20.42MB/s    0:20:13  
  6,093,471,744  19%   19.77MB/s    0:20:52  
  6,115,033,088  19%   19.93MB/s    0:20:42  
  6,136,004,608  19%   19.86MB/s    0:20:45  
  6,154,878,976  19%   19.38MB/s    0:21:14  
  6,172,442,624  19%   18.71MB/s    0:21:59  
  6,188,236,800  19%   17.31MB/s    0:23:45  
  6,208,618,496  19%   17.18MB/s    0:23:55  
  6,226,706,432  19%   16.94MB/s    0:24:14  
  6,244,794,368  19%   17.03MB/s    0:24:05  
  6,263,930,880  19%   17.88MB/s    0:22:56  
  6,282,215,424  19%   17.41MB/s    0:23:32  
  6,302,990,336  20%   18.05MB/s    0:22:41  
  6,322,651,136  20%   18.42MB/s    0:22:12  
  6,342,311,936  20%   18.54MB/s    0:22:02  
  6,361,972,736  20%   18.83MB/s    0:21:41  
  6,381,633,536  20%   18.60MB/s    0:21:56  
  6,401,294,336  20%   18.60MB/s    0:21:55  
  6,420,692,992  20%   18.54MB/s    0:21:58  
  6,440,353,792  20%   18.54MB/s    0:21:57  
  6,460,014,592  20%   18.54MB/s    0:21:56  
  6,480,494,592  20%   18.78MB/s    0:21:38  
  6,501,695,488  20%   19.16MB/s    0:21:12  
  6,522,667,008  20%   19.51MB/s    0:20:48  
  6,543,638,528  20%   19.80MB/s    0:20:28  
  6,565,134,336  20%   19.99MB/s    0:20:15  
  6,586,892,288  20%   20.14MB/s    0:20:06  
  6,607,601,664  21%   20.01MB/s    0:20:12  
  6,628,573,184  21%   20.03MB/s    0:20:10  
  6,650,068,992  21%   20.00MB/s    0:20:11  
  6,671,040,512  21%   19.84MB/s    0:20:19  
  6,692,536,320  21%   20.07MB/s    0:20:04  
  6,712,721,408  21%   19.92MB/s    0:20:12  
  6,734,217,216  21%   19.98MB/s    0:20:08  
  6,755,975,168  21%   20.17MB/s    0:19:55  
  6,779,305,984  21%   20.63MB/s    0:19:28  
  6,802,636,800  21%   21.38MB/s    0:18:46  
  6,825,967,616  21%   21.84MB/s    0:18:21  
  6,849,560,576  21%   22.31MB/s    0:17:57  
  6,872,891,392  21%   22.30MB/s    0:17:56  
  6,896,484,352  21%   22.26MB/s    0:17:57  
  6,918,471,680  21%   21.94MB/s    0:18:12  
  6,943,408,128  22%   22.27MB/s    0:17:55  
  6,966,738,944  22%   22.28MB/s    0:17:53  
  6,990,069,760  22%   22.29MB/s    0:17:52  
  7,013,924,864  22%   22.64MB/s    0:17:34  
  7,037,255,680  22%   22.26MB/s    0:17:51  
  7,060,586,496  22%   22.26MB/s    0:17:50  
  7,084,179,456  22%   22.33MB/s    0:17:46  
  7,108,034,560  22%   22.33MB/s    0:17:44  
  7,131,627,520  22%   22.39MB/s    0:17:40  
  7,153,844,224  22%   22.09MB/s    0:17:54  
  7,180,124,160  22%   22.67MB/s    0:17:25  
  7,204,241,408  22%   22.82MB/s    0:17:18  
  7,228,653,568  22%   23.02MB/s    0:17:07  
  7,253,524,480  23%   23.69MB/s    0:16:37  
  7,275,184,128  23%   22.65MB/s    0:17:22  
  7,306,215,424  23%   24.20MB/s    0:16:14  
  7,331,643,392  23%   24.44MB/s    0:16:04  
  7,357,071,360  23%   24.57MB/s    0:15:57  
  7,382,761,472  23%   25.55MB/s    0:15:20  
  7,407,992,832  23%   24.27MB/s    0:16:07  
  7,433,879,552  23%   24.38MB/s    0:16:02  
  7,459,569,664  23%   24.44MB/s    0:15:59  
  7,485,521,920  23%   24.50MB/s    0:15:55  
  7,511,212,032  23%   24.61MB/s    0:15:50  
  7,534,051,328  23%   23.84MB/s    0:16:19  
  7,563,378,688  24%   24.62MB/s    0:15:47  
  7,589,134,336  24%   24.59MB/s    0:15:48  
  7,615,021,056  24%   24.63MB/s    0:15:45  
  7,640,711,168  24%   25.35MB/s    0:15:17  
  7,662,632,960  24%   23.68MB/s    0:16:21  
  7,692,353,536  24%   24.61MB/s    0:15:43  
  7,718,305,792  24%   24.62MB/s    0:15:41  
  7,743,995,904  24%   24.62MB/s    0:15:40  
  7,769,686,016  24%   25.52MB/s    0:15:06  
  7,791,968,256  24%   23.50MB/s    0:16:23  
  7,822,901,248  24%   24.58MB/s    0:15:39  
  7,848,853,504  24%   24.63MB/s    0:15:36  
  7,874,543,616  25%   24.63MB/s    0:15:35  
  7,900,495,872  25%   25.77MB/s    0:14:52  
  7,923,662,848  25%   23.99MB/s    0:15:57  
  7,951,876,096  25%   24.53MB/s    0:15:35  
  7,978,352,640  25%   24.63MB/s    0:15:31  
  8,004,042,752  25%   24.57MB/s    0:15:32  
  8,029,995,008  25%   25.26MB/s    0:15:05  
  8,050,966,528  25%   23.54MB/s    0:16:11  
  8,081,637,376  25%   24.62MB/s    0:15:27  
  8,107,327,488  25%   24.62MB/s    0:15:26  
  8,133,017,600  25%   24.56MB/s    0:15:27  
  8,158,969,856  25%   25.75MB/s    0:14:43  
  8,180,727,808  26%   23.33MB/s    0:16:14  
  8,212,185,088  26%   24.63MB/s    0:15:21  
  8,237,875,200  26%   24.63MB/s    0:15:20  
  8,263,827,456  26%   24.63MB/s    0:15:19  
  8,289,517,568  26%   25.88MB/s    0:14:34  
  8,310,751,232  26%   23.22MB/s    0:16:13  
  8,342,732,800  26%   24.61MB/s    0:15:17  
  8,368,422,912  26%   24.55MB/s    0:15:18  
  8,394,375,168  26%   24.61MB/s    0:15:15  
  8,419,540,992  26%   25.74MB/s    0:14:33  
  8,444,444,672  26%   24.13MB/s    0:15:31  
  8,469,610,496  26%   23.93MB/s    0:15:38  
  8,494,514,176  27%   23.62MB/s    0:15:49  
  8,519,155,712  27%   23.50MB/s    0:15:53  
  8,544,059,392  27%   23.52MB/s    0:15:51  
  8,567,324,672  27%   23.11MB/s    0:16:07  
  8,594,391,040  27%   23.63MB/s    0:15:44  
  8,619,819,008  27%   23.86MB/s    0:15:34  
  8,644,984,832  27%   23.88MB/s    0:15:33  
  8,670,412,800  27%   24.37MB/s    0:15:13  
  8,693,547,008  27%   23.49MB/s    0:15:46  
  8,721,006,592  27%   24.01MB/s    0:15:24  
  8,746,172,416  27%   23.99MB/s    0:15:24  
  8,771,600,384  27%   24.00MB/s    0:15:22  
  8,796,766,208  27%   24.44MB/s    0:15:05  
  8,820,097,024  28%   23.48MB/s    0:15:41  
  8,846,835,712  28%   23.88MB/s    0:15:24  
  8,872,263,680  28%   23.86MB/s    0:15:24  
  8,897,429,504  28%   23.84MB/s    0:15:24  
  8,922,857,472  28%   24.29MB/s    0:15:06  
  8,948,023,296  28%   23.93MB/s    0:15:18  
  8,973,451,264  28%   23.91MB/s    0:15:18  
  8,998,617,088  28%   23.96MB/s    0:15:15  
  9,023,782,912  28%   23.95MB/s    0:15:14  
  9,049,210,880  28%   23.98MB/s    0:15:12  
  9,074,475,008  28%   24.02MB/s    0:15:10  
  9,099,804,672  28%   24.01MB/s    0:15:09  
  9,124,970,496  29%   23.96MB/s    0:15:10  
  9,150,398,464  29%   23.98MB/s    0:15:08  
  9,175,564,288  29%   23.96MB/s    0:15:08  
  9,200,992,256  29%   24.03MB/s    0:15:04  
  9,225,633,792  29%   23.95MB/s    0:15:06  
  9,251,061,760  29%   23.97MB/s    0:15:04  
  9,276,227,584  29%   23.93MB/s    0:15:05  
  9,301,655,552  29%   23.93MB/s    0:15:04  
  9,326,821,376  29%   24.03MB/s    0:14:59  
  9,352,249,344  29%   23.97MB/s    0:15:00  
  9,377,415,168  29%   23.96MB/s    0:15:00  
  9,402,843,136  29%   23.96MB/s    0:14:59  
  9,428,008,960  29%   23.98MB/s    0:14:57  
  9,453,174,784  30%   24.00MB/s    0:14:55  
  9,478,602,752  30%   24.00MB/s    0:14:54  
  9,503,768,576  30%   23.95MB/s    0:14:55  
  9,529,196,544  30%   23.93MB/s    0:14:54  
  9,554,362,368  30%   23.93MB/s    0:14:53  
  9,577,562,112  30%   23.48MB/s    0:15:09  
  9,604,431,872  30%   23.90MB/s    0:14:52  
  9,629,859,840  30%   23.98MB/s    0:14:49  
  9,655,025,664  30%   23.90MB/s    0:14:50  
  9,680,453,632  30%   24.38MB/s    0:14:32  
  9,705,521,152  30%   23.96MB/s    0:14:46  
  9,731,047,424  30%   23.93MB/s    0:14:46  
  9,756,213,248  31%   23.96MB/s    0:14:44  
  9,781,641,216  31%   23.93MB/s    0:14:44  
  9,806,807,040  31%   23.93MB/s    0:14:43  
  9,829,253,120  31%   23.26MB/s    0:15:08  
  9,857,400,832  31%   23.91MB/s    0:14:42  
  9,882,566,656  31%   23.88MB/s    0:14:42  
  9,907,994,624  31%   23.89MB/s    0:14:41  
  9,933,160,448  31%   24.48MB/s    0:14:18  
  9,957,933,056  31%   23.78MB/s    0:14:42  
  9,983,754,240  31%   23.96MB/s    0:14:35  
 10,009,182,208  31%   23.96MB/s    0:14:34  
 10,034,348,032  31%   23.93MB/s    0:14:34  
 10,059,776,000  31%   24.06MB/s    0:14:28  
 10,084,941,824  32%   23.96MB/s    0:14:31  
 10,109,845,504  32%   23.91MB/s    0:14:31  
 10,135,011,328  32%   23.93MB/s    0:14:30  
 10,160,439,296  32%   23.90MB/s    0:14:30  
 10,186,129,408  32%   23.91MB/s    0:14:28  
 10,211,688,448  32%   24.05MB/s    0:14:22  
 10,236,723,200  32%   24.04MB/s    0:14:22  
 10,262,151,168  32%   24.03MB/s    0:14:21  
 10,287,316,992  32%   23.98MB/s    0:14:22  
 10,312,482,816  32%   23.86MB/s    0:14:25  
 10,337,910,784  32%   23.99MB/s    0:14:19  
 10,363,076,608  32%   23.95MB/s    0:14:20  
 10,388,504,576  33%   23.98MB/s    0:14:18  
 10,413,670,400  33%   24.03MB/s    0:14:15  
 10,439,098,368  33%   23.98MB/s    0:14:15  
 10,464,755,712  33%   24.13MB/s    0:14:09  
 10,489,692,160  33%   24.01MB/s    0:14:12  
 10,514,857,984  33%   23.96MB/s    0:14:13  
 10,540,285,952  33%   23.96MB/s    0:14:12  
 10,565,451,776  33%   23.77MB/s    0:14:18  
 10,590,879,744  33%   23.91MB/s    0:14:12  
 10,616,045,568  33%   23.91MB/s    0:14:11  
 10,641,473,536  33%   23.94MB/s    0:14:09  
 10,666,639,360  33%   24.00MB/s    0:14:05  
 10,691,805,184  33%   23.97MB/s    0:14:05  
 10,717,233,152  34%   24.03MB/s    0:14:02  
 10,742,398,976  34%   23.90MB/s    0:14:06  
 10,767,826,944  34%   23.93MB/s    0:14:04  
 10,792,992,768  34%   23.91MB/s    0:14:04  
 10,818,420,736  34%   23.89MB/s    0:14:03  
 10,843,586,560  34%   23.96MB/s    0:14:00  
 10,869,014,528  34%   23.96MB/s    0:13:59  
 10,894,180,352  34%   23.93MB/s    0:13:59  
 10,919,608,320  34%   23.98MB/s    0:13:56  
 10,944,774,144  34%   23.93MB/s    0:13:57  
 10,970,202,112  34%   23.93MB/s    0:13:55  
 10,995,367,936  34%   23.94MB/s    0:13:54  
 11,020,795,904  35%   23.93MB/s    0:13:53  
 11,045,961,728  35%   23.93MB/s    0:13:53  
 11,071,389,696  35%   23.90MB/s    0:13:52  
 11,097,079,808  35%   23.98MB/s    0:13:49  
 11,122,245,632  35%   23.88MB/s    0:13:51  
 11,147,673,600  35%   23.94MB/s    0:13:48  
 11,172,839,424  35%   23.88MB/s    0:13:49  
 11,198,267,392  35%   23.86MB/s    0:13:49  
 11,223,957,504  35%   23.99MB/s    0:13:43  
 11,249,385,472  35%   23.96MB/s    0:13:43  
 11,274,551,296  35%   23.96MB/s    0:13:42  
 11,299,979,264  35%   23.96MB/s    0:13:41  
 11,325,145,088  36%   23.87MB/s    0:13:43  
 11,351,097,344  36%   24.03MB/s    0:13:37  
 11,376,001,024  36%   24.03MB/s    0:13:36  
 11,401,166,848  36%   23.99MB/s    0:13:36  
 11,426,332,672  36%   24.00MB/s    0:13:34  
 11,451,498,496  36%   23.82MB/s    0:13:40  
 11,476,926,464  36%   23.92MB/s    0:13:35  
 11,502,092,288  36%   23.92MB/s    0:13:34  
 11,527,520,256  36%   23.98MB/s    0:13:31  
 11,552,686,080  36%   23.96MB/s    0:13:31  
 11,578,638,336  36%   24.11MB/s    0:13:25  
 11,604,328,448  36%   24.28MB/s    0:13:18  
 11,630,280,704  36%   24.43MB/s    0:13:12  
 11,655,970,816  37%   24.62MB/s    0:13:05  
 11,681,923,072  37%   24.62MB/s    0:13:04  
 11,707,613,184  37%   24.62MB/s    0:13:03  
 11,735,859,200  37%   25.17MB/s    0:12:45  
 11,767,119,872  37%   26.48MB/s    0:12:06  
 11,799,363,584  37%   27.90MB/s    0:11:28  
 11,829,772,288  37%   29.01MB/s    0:11:00  
 11,862,278,144  37%   29.93MB/s    0:10:39  
 11,894,259,712  37%   30.14MB/s    0:10:33  
 11,923,357,696  37%   29.47MB/s    0:10:47  
 11,954,814,976  38%   29.73MB/s    0:10:40  
 11,986,534,400  38%   29.54MB/s    0:10:43  
 12,017,991,680  38%   29.41MB/s    0:10:45  
 12,048,531,456  38%   29.76MB/s    0:10:36  
 12,081,168,384  38%   30.01MB/s    0:10:30  
 12,112,363,520  38%   29.97MB/s    0:10:30  
 12,143,820,800  38%   29.98MB/s    0:10:29  
 12,175,278,080  38%   30.12MB/s    0:10:25  
 12,209,356,800  38%   30.44MB/s    0:10:17  
 12,240,027,648  38%   30.32MB/s    0:10:18  
 12,274,892,800  39%   31.13MB/s    0:10:01  
 12,306,350,080  39%   31.20MB/s    0:09:59  
 12,337,807,360  39%   30.62MB/s    0:10:09  
 12,365,791,232  39%   29.98MB/s    0:10:21  
 12,400,721,920  39%   30.00MB/s    0:10:20  
 12,432,441,344  39%   30.06MB/s    0:10:18  
 12,464,160,768  39%   30.12MB/s    0:10:15  
 12,495,880,192  39%   31.02MB/s    0:09:57  
 12,525,010,944  39%   29.63MB/s    0:10:23  
 12,559,581,184  39%   30.31MB/s    0:10:08  
 12,591,300,608  40%   30.31MB/s    0:10:07  
 12,623,020,032  40%   30.31MB/s    0:10:06  
 12,654,739,456  40%   30.92MB/s    0:09:53  
 12,681,740,288  40%   29.12MB/s    0:10:29  
 12,718,178,304  40%   30.25MB/s    0:10:05  
 12,750,159,872  40%   30.31MB/s    0:10:02  
 12,782,141,440  40%   30.38MB/s    0:10:00  
 12,813,860,864  40%   31.50MB/s    0:09:38  
 12,840,534,016  40%   29.13MB/s    0:10:24  
 12,878,610,432  40%   30.47MB/s    0:09:55  
 12,910,329,856  41%   30.41MB/s    0:09:55  
 12,942,311,424  41%   30.47MB/s    0:09:53  
 12,974,292,992  41%   31.79MB/s    0:09:27  
 13,002,375,168  41%   29.43MB/s    0:10:12  
 13,038,780,416  41%   30.48MB/s    0:09:50  
 13,070,761,984  41%   30.47MB/s    0:09:49  
 13,102,743,552  41%   30.47MB/s    0:09:48  
 13,134,725,120  41%   31.49MB/s    0:09:28  
 13,167,493,120  41%   30.69MB/s    0:09:42  
 13,207,601,152  41%   32.50MB/s    0:09:08  
 13,249,282,048  42%   34.69MB/s    0:08:32  
 13,291,749,376  42%   37.10MB/s    0:07:58  
 13,333,954,560  42%   39.27MB/s    0:07:30  
 13,370,523,648  42%   38.59MB/s    0:07:37  
 13,412,892,672  42%   38.88MB/s    0:07:33  
 13,461,618,688  42%   40.35MB/s    0:07:15  
 13,503,266,816  42%   40.12MB/s    0:07:17  
 13,547,077,632  43%   41.75MB/s    0:06:58  
 13,589,544,960  43%   41.69MB/s    0:06:58  
 13,630,439,424  43%   39.86MB/s    0:07:16  
 13,670,023,168  43%   39.41MB/s    0:07:20  
 13,713,276,928  43%   39.36MB/s    0:07:20  
 13,755,482,112  43%   39.17MB/s    0:07:21  
 13,789,986,816  43%   37.72MB/s    0:07:37  
 13,843,628,032  44%   41.16MB/s    0:06:57  
 13,882,589,184  44%   40.15MB/s    0:07:07  
 13,924,532,224  44%   40.29MB/s    0:07:04  
 13,968,605,184  44%   42.58MB/s    0:06:41  
 14,006,255,616  44%   38.59MB/s    0:07:21  
 14,057,603,072  44%   41.54MB/s    0:06:49  
 14,101,577,728  44%   42.02MB/s    0:06:43  
 14,145,552,384  44%   41.98MB/s    0:06:42  
 14,189,854,720  45%   43.66MB/s    0:06:26  
 14,226,030,592  45%   39.95MB/s    0:07:01  
 14,278,721,536  45%   41.94MB/s    0:06:40  
 14,322,597,888  45%   41.86MB/s    0:06:39  
 14,367,555,584  45%   42.07MB/s    0:06:36  
 14,411,366,400  45%   44.00MB/s    0:06:18  
 14,450,098,176  45%   40.60MB/s    0:06:49  
 14,498,791,424  46%   41.85MB/s    0:06:35  
 14,544,404,480  46%   42.03MB/s    0:06:33  
 14,588,313,600  46%   41.99MB/s    0:06:32  
 14,632,648,704  46%   43.48MB/s    0:06:17  
 14,676,361,216  46%   42.25MB/s    0:06:27  
 14,720,729,088  46%   41.96MB/s    0:06:29  
 14,764,736,512  46%   41.99MB/s    0:06:28  
 14,808,776,704  47%   41.90MB/s    0:06:28  
 14,853,079,040  47%   42.04MB/s    0:06:25  
 14,890,565,632  47%   40.20MB/s    0:06:42  
 14,942,470,144  47%   42.04MB/s    0:06:23  
 14,986,772,480  47%   42.03MB/s    0:06:22  
 15,031,074,816  47%   41.98MB/s    0:06:22  
 15,075,639,296  47%   43.77MB/s    0:06:05  
 15,111,815,168  48%   39.89MB/s    0:06:40  
 15,159,296,000  48%   40.73MB/s    0:06:30  
 15,205,662,720  48%   41.22MB/s    0:06:25  
 15,249,440,768  48%   41.11MB/s    0:06:25  
 15,290,597,376  48%   42.56MB/s    0:06:10  
 15,324,413,952  48%   39.17MB/s    0:06:42  
 15,375,269,888  48%   40.24MB/s    0:06:30  
 15,415,902,208  49%   39.46MB/s    0:06:37  
 15,456,010,240  49%   39.12MB/s    0:06:39  
 15,497,691,136  49%   41.13MB/s    0:06:18  
 15,532,556,288  49%   37.05MB/s    0:06:59  
 15,583,412,224  49%   39.40MB/s    0:06:33  
 15,625,093,120  49%   39.80MB/s    0:06:28  
 15,667,298,304  49%   39.89MB/s    0:06:26  
 15,708,979,200  49%   41.79MB/s    0:06:08  
 15,743,320,064  50%   37.70MB/s    0:06:47  
 15,794,176,000  50%   39.87MB/s    0:06:23  
 15,836,381,184  50%   39.83MB/s    0:06:22  
 15,877,537,792  50%   39.76MB/s    0:06:22  
 15,921,053,696  50%   42.23MB/s    0:05:59  
 15,956,967,424  50%   38.59MB/s    0:06:32  
 16,008,347,648  50%   40.79MB/s    0:06:09  
 16,053,698,560  51%   41.75MB/s    0:06:00  
 16,098,263,040  51%   41.93MB/s    0:05:57  
 16,144,138,240  51%   44.31MB/s    0:05:37  
 16,190,472,192  51%   43.05MB/s    0:05:46  
 16,239,886,336  51%   44.01MB/s    0:05:37  
 16,294,936,576  51%   46.58MB/s    0:05:17  
 16,350,609,408  51%   49.01MB/s    0:05:01  
 16,406,085,632  52%   51.35MB/s    0:04:46  
 16,449,536,000  52%   50.00MB/s    0:04:53  
 16,502,947,840  52%   49.61MB/s    0:04:54  
 16,558,948,352  52%   49.68MB/s    0:04:52  
 16,614,850,560  52%   49.77MB/s    0:04:51  
 16,668,950,528  52%   52.33MB/s    0:04:36  
 16,722,395,136  53%   52.33MB/s    0:04:34  
 16,776,855,552  53%   51.95MB/s    0:04:35  
 16,830,398,464  53%   51.39MB/s    0:04:37  
 16,886,202,368  53%   51.81MB/s    0:04:34  
 16,941,744,128  53%   52.30MB/s    0:04:31  
 16,989,814,784  54%   50.55MB/s    0:04:39  
 17,041,326,080  54%   50.00MB/s    0:04:41  
 17,096,081,408  54%   49.70MB/s    0:04:42  
 17,149,329,408  54%   49.06MB/s    0:04:44  
 17,203,625,984  54%   50.80MB/s    0:04:34  
 17,255,104,512  54%   50.85MB/s    0:04:32  
 17,311,301,632  55%   51.22MB/s    0:04:29  
 17,359,994,880  55%   50.23MB/s    0:04:34  
 17,414,946,816  55%   50.38MB/s    0:04:32  
 17,464,557,568  55%   49.88MB/s    0:04:34  
 17,505,943,552  55%   46.37MB/s    0:04:53  
 17,548,083,200  55%   44.81MB/s    0:05:03  
 17,590,616,064  55%   41.83MB/s    0:05:23  
 17,631,903,744  56%   39.90MB/s    0:05:38  
 17,674,895,360  56%   40.27MB/s    0:05:34  
 17,718,345,728  56%   40.49MB/s    0:05:31  
 17,762,844,672  56%   40.96MB/s    0:05:26  
 17,807,343,616  56%   41.70MB/s    0:05:19  
 17,851,613,184  56%   42.03MB/s    0:05:16  
 17,895,456,768  56%   42.22MB/s    0:05:13  
 17,931,436,032  56%   38.40MB/s    0:05:44  
 17,978,556,416  57%   39.02MB/s    0:05:37  
 18,025,545,728  57%   39.60MB/s    0:05:31  
 18,072,567,808  57%   40.32MB/s    0:05:24  
 18,119,884,800  57%   44.91MB/s    0:04:50  
 18,164,645,888  57%   44.25MB/s    0:04:53  
 18,212,290,560  57%   44.45MB/s    0:04:51  
 18,260,525,056  58%   44.62MB/s    0:04:48  
 18,306,105,344  58%   44.19MB/s    0:04:50  
 18,354,733,056  58%   45.18MB/s    0:04:43  
 18,397,265,920  58%   43.07MB/s    0:04:56  
 18,447,302,656  58%   43.57MB/s    0:04:51  
 18,497,011,712  58%   44.59MB/s    0:04:43  
 18,547,146,752  58%   44.93MB/s    0:04:40  
 18,597,740,544  59%   47.80MB/s    0:04:22  
 18,645,417,984  59%   47.25MB/s    0:04:24  
 18,696,110,080  59%   47.46MB/s    0:04:22  
 18,748,178,432  59%   47.93MB/s    0:04:18  
 18,800,771,072  59%   48.37MB/s    0:04:15  
 18,852,511,744  59%   49.31MB/s    0:04:09  
 18,897,436,672  60%   47.12MB/s    0:04:20  
 18,949,472,256  60%   47.11MB/s    0:04:19  
 19,001,999,360  60%   47.14MB/s    0:04:18  
 19,055,935,488  60%   47.67MB/s    0:04:14  
 19,109,773,312  60%   50.64MB/s    0:03:58  
 19,154,862,080  60%   48.50MB/s    0:04:07  
 19,206,078,464  61%   48.10MB/s    0:04:08  
 19,257,982,976  61%   47.62MB/s    0:04:10  
 19,312,902,144  61%   47.66MB/s    0:04:08  
 19,368,214,528  61%   50.51MB/s    0:03:53  
 19,423,559,680  61%   51.59MB/s    0:03:47  
 19,475,890,176  61%   51.63MB/s    0:03:46  
 19,529,629,696  62%   51.56MB/s    0:03:45  
 19,582,615,552  62%   50.98MB/s    0:03:47  
 19,635,994,624  62%   50.50MB/s    0:03:48  
 19,689,897,984  62%   50.90MB/s    0:03:45  
 19,745,767,424  62%   51.45MB/s    0:03:42  
 19,795,312,640  62%   50.70MB/s    0:03:44  
 19,851,247,616  63%   51.31MB/s    0:03:40  
 19,903,971,328  63%   51.06MB/s    0:03:40  
 19,958,431,744  63%   50.73MB/s    0:03:41  
 20,013,285,376  63%   51.89MB/s    0:03:35  
 20,066,598,912  63%   51.28MB/s    0:03:36  
 20,121,321,472  63%   51.64MB/s    0:03:34  
 20,177,092,608  64%   51.94MB/s    0:03:32  
 20,226,146,304  64%   50.52MB/s    0:03:37  
 20,281,458,688  64%   51.00MB/s    0:03:34  
 20,328,251,392  64%   49.23MB/s    0:03:40  
 20,381,499,392  64%   48.61MB/s    0:03:42  
 20,435,238,912  64%   49.85MB/s    0:03:35  
 20,482,097,152  65%   47.69MB/s    0:03:44  
 20,521,975,808  65%   46.05MB/s    0:03:51  
 20,577,124,352  65%   46.43MB/s    0:03:48  
 20,632,666,112  65%   46.86MB/s    0:03:45  
 20,687,355,904  65%   48.89MB/s    0:03:35  
 20,732,706,816  65%   49.83MB/s    0:03:30  
 20,783,038,464  66%   48.75MB/s    0:03:33  
 20,838,645,760  66%   48.78MB/s    0:03:32  
 20,894,449,664  66%   49.04MB/s    0:03:30  
 20,943,962,112  66%   50.38MB/s    0:03:23  
 20,989,607,936  66%   48.69MB/s    0:03:29  
 21,042,888,704  66%   48.07MB/s    0:03:31  
 21,098,987,520  67%   48.14MB/s    0:03:30  
 21,154,496,512  67%   49.55MB/s    0:03:23  
 21,208,924,160  67%   52.13MB/s    0:03:12  
 21,252,538,368  67%   49.62MB/s    0:03:20  
 21,307,883,520  67%   49.43MB/s    0:03:20  
 21,361,721,344  67%   49.04MB/s    0:03:21  
 21,417,295,872  68%   49.33MB/s    0:03:18  
 21,471,559,680  68%   52.08MB/s    0:03:07  
 21,523,431,424  68%   51.22MB/s    0:03:09  
 21,578,514,432  68%   51.52MB/s    0:03:07  
 21,632,057,344  68%   50.85MB/s    0:03:08  
 21,685,010,432  68%   50.60MB/s    0:03:08  
 21,739,896,832  69%   51.30MB/s    0:03:05  
 21,783,904,256  69%   48.44MB/s    0:03:15  
 21,833,711,616  69%   47.84MB/s    0:03:16  
 21,888,794,624  69%   48.34MB/s    0:03:13  
 21,943,517,184  69%   48.34MB/s    0:03:12  
 21,998,403,584  69%   51.00MB/s    0:03:01  
 22,043,164,672  70%   49.43MB/s    0:03:06  
 22,097,166,336  70%   49.18MB/s    0:03:05  
 22,152,347,648  70%   49.31MB/s    0:03:04  
 22,198,910,976  70%   47.48MB/s    0:03:10  
 22,252,912,640  70%   50.03MB/s    0:02:59  
 22,308,618,240  70%   50.33MB/s    0:02:57  
 22,360,621,056  71%   49.57MB/s    0:02:59  
 22,410,985,472  71%   50.49MB/s    0:02:55  
 22,466,297,856  71%   50.80MB/s    0:02:52  
 22,518,792,192  71%   50.12MB/s    0:02:54  
 22,567,485,440  71%   49.10MB/s    0:02:56  
 22,622,732,288  71%   50.22MB/s    0:02:51  
 22,676,406,272  72%   49.83MB/s    0:02:52  
 22,731,390,976  72%   50.45MB/s    0:02:48  
 22,784,245,760  72%   51.64MB/s    0:02:44  
 22,840,213,504  72%   51.81MB/s    0:02:42  
 22,896,541,696  72%   52.41MB/s    0:02:39  
 22,949,855,232  72%   51.89MB/s    0:02:40  
 23,005,626,368  73%   52.61MB/s    0:02:36  
 23,061,299,200  73%   52.55MB/s    0:02:36  
 23,103,569,920  73%   48.92MB/s    0:02:46  
 23,155,179,520  73%   48.64MB/s    0:02:46  
 23,207,739,392  73%   47.89MB/s    0:02:48  
 23,261,052,928  73%   47.36MB/s    0:02:49  
 23,317,020,672  74%   50.93MB/s    0:02:36  
 23,372,398,592  74%   51.81MB/s    0:02:32  
 23,424,794,624  74%   51.78MB/s    0:02:31  
 23,479,549,952  74%   52.07MB/s    0:02:29  
 23,534,600,192  74%   51.85MB/s    0:02:29  
 23,589,617,664  74%   51.74MB/s    0:02:28  
 23,636,508,672  75%   50.34MB/s    0:02:31  
 23,685,955,584  75%   49.14MB/s    0:02:34  
 23,741,431,808  75%   49.24MB/s    0:02:33  
 23,796,121,600  75%   49.17MB/s    0:02:32  
 23,850,778,624  75%   50.98MB/s    0:02:25  
 23,907,827,712  75%   52.77MB/s    0:02:19  
 23,963,860,992  76%   52.83MB/s    0:02:18  
 24,019,959,808  76%   53.11MB/s    0:02:16  
 24,076,288,000  76%   53.63MB/s    0:02:14  
 24,132,059,136  76%   53.30MB/s    0:02:14  
 24,187,961,344  76%   53.30MB/s    0:02:13  
 24,243,044,352  77%   53.02MB/s    0:02:12  
 24,298,946,560  77%   52.90MB/s    0:02:12  
 24,354,652,160  77%   52.87MB/s    0:02:11  
 24,410,456,064  77%   52.85MB/s    0:02:10  
 24,458,002,432  77%   51.06MB/s    0:02:13  
 24,513,576,960  77%   51.03MB/s    0:02:12  
 24,569,544,704  78%   51.08MB/s    0:02:11  
 24,619,581,440  78%   49.72MB/s    0:02:14  
 24,675,319,808  78%   51.73MB/s    0:02:08  
 24,731,090,944  78%   51.77MB/s    0:02:06  
 24,786,829,312  78%   51.77MB/s    0:02:05  
 24,843,223,040  78%   53.24MB/s    0:02:01  
 24,899,158,016  79%   53.25MB/s    0:02:00  
 24,955,027,456  79%   53.23MB/s    0:01:59  
 24,999,985,152  79%   50.69MB/s    0:02:04  
 25,053,888,512  79%   50.16MB/s    0:02:04  
 25,109,200,896  79%   50.07MB/s    0:02:03  
 25,164,873,728  79%   50.06MB/s    0:02:02  
 25,220,710,400  80%   52.65MB/s    0:01:55  
 25,276,121,088  80%   53.01MB/s    0:01:53  
 25,331,138,560  80%   52.94MB/s    0:01:53  
rsync: write failed on &quot;/data/hiveptest/logs/PreCommit-HIVE-Build-3693/failed/115-TestSparkCliDriver-escape_distributeby1.q-join9.q-groupby2.q-and-12-more/logs/hive.log&quot;: No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
Warning: Permanently added &apos;35.184.41.238&apos; (ECDSA) to the list of known hosts.
receiving incremental file list
logs/
logs/hive.log

              0   0%    0.00kB/s    0:00:00  
rsync: write failed on &quot;/data/hiveptest/logs/PreCommit-HIVE-Build-3693/failed/115-TestSparkCliDriver-escape_distributeby1.q-join9.q-groupby2.q-and-12-more/logs/hive.log&quot;: No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
Warning: Permanently added &apos;35.184.41.238&apos; (ECDSA) to the list of known hosts.
receiving incremental file list
logs/
logs/hive.log

              0   0%    0.00kB/s    0:00:00  
rsync: write failed on &quot;/data/hiveptest/logs/PreCommit-HIVE-Build-3693/failed/115-TestSparkCliDriver-escape_distributeby1.q-join9.q-groupby2.q-and-12-more/logs/hive.log&quot;: No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
Warning: Permanently added &apos;35.184.41.238&apos; (ECDSA) to the list of known hosts.
receiving incremental file list
logs/
logs/hive.log

              0   0%    0.00kB/s    0:00:00  
rsync: write failed on &quot;/data/hiveptest/logs/PreCommit-HIVE-Build-3693/failed/115-TestSparkCliDriver-escape_distributeby1.q-join9.q-groupby2.q-and-12-more/logs/hive.log&quot;: No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
Warning: Permanently added &apos;35.184.41.238&apos; (ECDSA) to the list of known hosts.
receiving incremental file list
logs/
logs/hive.log

              0   0%    0.00kB/s    0:00:00  
rsync: write failed on &quot;/data/hiveptest/logs/PreCommit-HIVE-Build-3693/failed/115-TestSparkCliDriver-escape_distributeby1.q-join9.q-groupby2.q-and-12-more/logs/hive.log&quot;: No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12853906 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15884496" author="teddy.choi" created="Sun, 26 Feb 2017 02:37:12 +0000"  >&lt;p&gt;Resolved conflicts from changes in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-15955&quot; title=&quot;make explain formatted to include opId and etc&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-15955&quot;&gt;&lt;del&gt;HIVE-15955&lt;/del&gt;&lt;/a&gt; and others.&lt;/p&gt;</comment>
                            <comment id="15884572" author="hiveqa" created="Sun, 26 Feb 2017 06:32:35 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12854690/HIVE-1626.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12854690/HIVE-1626.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/3790/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/3790/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/3790/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/3790/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-3790/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-3790/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Tests exited with: ExecutionException: java.util.concurrent.ExecutionException: org.apache.hive.ptest.execution.ssh.SSHExecutionException: RSyncResult [localFile=/data/hiveptest/logs/PreCommit-HIVE-Build-3790/failed/126-TestSparkCliDriver-ptf_seqfile.q-union_remove_23.q-parallel_join0.q-and-12-more, remoteFile=/home/hiveptest/35.184.171.199-hiveptest-0/logs/, getExitCode()=11, getException()=null, getUser()=hiveptest, getHost()=35.184.171.199, getInstance()=0]: &apos;Warning: Permanently added &apos;35.184.171.199&apos; (ECDSA) to the list of known hosts.
receiving incremental file list
./
maven-test.txt

              0   0%    0.00kB/s    0:00:00  
         42,490 100%   40.52MB/s    0:00:00 (xfr#1, to-chk=22/24)
logs/
logs/derby.log

              0   0%    0.00kB/s    0:00:00  
          1,015 100%  991.21kB/s    0:00:00 (xfr#2, to-chk=19/24)
logs/hive.log

              0   0%    0.00kB/s    0:00:00  
     10,715,136   0%   10.04MB/s    0:50:45  
     21,200,896   0%    9.89MB/s    0:51:30  
     31,948,800   0%    9.92MB/s    0:51:17  
     41,648,128   0%    9.74MB/s    0:52:13  
     52,887,552   0%    9.88MB/s    0:51:30  
     63,668,224   0%    9.98MB/s    0:50:59  
     74,645,504   0%   10.09MB/s    0:50:24  
     83,820,544   0%    9.97MB/s    0:50:58  
     94,568,448   0%    9.86MB/s    0:51:33  
    105,775,104   0%   10.00MB/s    0:50:47  
    115,277,824   0%    9.62MB/s    0:52:48  
    126,844,928   0%   10.19MB/s    0:49:49  
    137,854,976   0%   10.26MB/s    0:49:26  
    148,865,024   0%   10.19MB/s    0:49:47  
    160,137,216   0%   10.61MB/s    0:47:47  
    167,477,248   0%    9.60MB/s    0:52:47  
    178,487,296   0%    9.62MB/s    0:52:40  
    190,283,776   0%    9.83MB/s    0:51:32  
    201,293,824   0%    9.79MB/s    0:51:43  
    212,828,160   0%   10.75MB/s    0:47:04  
    223,019,008   0%   10.55MB/s    0:47:58  
    233,537,536   0%   10.24MB/s    0:49:23  
    244,023,296   0%   10.12MB/s    0:49:56  
    253,984,768   0%    9.77MB/s    0:51:43  
    262,307,840   0%    9.35MB/s    0:54:04  
    274,169,856   0%    9.64MB/s    0:52:23  
    286,490,624   0%   10.06MB/s    0:50:12  
    298,811,392   0%   10.61MB/s    0:47:34  
    310,870,016   0%   11.46MB/s    0:44:02  
    323,452,928   1%   11.63MB/s    0:43:23  
    335,511,552   1%   11.56MB/s    0:43:36  
    347,570,176   1%   11.53MB/s    0:43:43  
    359,596,032   1%   11.51MB/s    0:43:47  
    369,065,984   1%   10.76MB/s    0:46:47  
    378,241,024   1%   10.04MB/s    0:50:08  
    387,678,208   1%    9.40MB/s    0:53:31  
    397,115,392   1%    8.79MB/s    0:57:13  
    406,814,720   1%    8.85MB/s    0:56:50  
    418,611,200   1%    9.51MB/s    0:52:51  
    429,096,960   1%    9.78MB/s    0:51:23  
    438,272,000   1%    9.72MB/s    0:51:42  
    448,233,472   1%    9.75MB/s    0:51:30  
    458,424,320   1%    9.36MB/s    0:53:37  
    468,680,704   1%    9.30MB/s    0:53:57  
    478,085,120   1%    9.40MB/s    0:53:24  
    487,817,216   1%    9.37MB/s    0:53:32  
    497,778,688   1%    9.33MB/s    0:53:44  
    507,215,872   1%    9.08MB/s    0:55:12  
    517,177,344   1%    9.18MB/s    0:54:34  
    526,843,904   1%    9.17MB/s    0:54:39  
    535,756,800   1%    8.93MB/s    0:56:07  
    544,931,840   1%    8.89MB/s    0:56:19  
    556,761,088   1%    9.36MB/s    0:53:30  
    566,951,936   1%    9.51MB/s    0:52:37  
    578,256,896   1%   10.07MB/s    0:49:41  
    588,972,032   1%   10.43MB/s    0:47:57  
    600,014,848   1%   10.21MB/s    0:48:57  
    610,762,752   1%   10.29MB/s    0:48:33  
    620,986,368   1%   10.00MB/s    0:49:58  
    631,209,984   2%    9.92MB/s    0:50:20  
    642,482,176   2%    9.93MB/s    0:50:15  
    652,443,648   2%    9.76MB/s    0:51:06  
    661,880,832   2%    9.58MB/s    0:52:03  
    673,415,168   2%    9.85MB/s    0:50:36  
    684,130,304   2%    9.77MB/s    0:51:01  
    695,435,264   2%   10.10MB/s    0:49:20  
    705,626,112   2%   10.33MB/s    0:48:13  
    715,096,064   2%    9.88MB/s    0:50:23  
    727,416,832   2%   10.27MB/s    0:48:27  
    739,475,456   2%   10.43MB/s    0:47:42  
    750,223,360   2%   10.56MB/s    0:47:05  
    760,971,264   2%   10.83MB/s    0:45:53  
    771,194,880   2%   10.33MB/s    0:48:08  
    782,991,360   2%   10.23MB/s    0:48:35  
    793,739,264   2%   10.20MB/s    0:48:40  
    804,487,168   2%   10.20MB/s    0:48:39  
    814,153,728   2%   10.09MB/s    0:49:12  
    824,934,400   2%    9.91MB/s    0:50:03  
    835,944,448   2%    9.99MB/s    0:49:39  
    848,330,752   2%   10.42MB/s    0:47:35  
    859,242,496   2%   10.71MB/s    0:46:16  
    869,761,024   2%   10.64MB/s    0:46:33  
    880,738,304   2%   10.64MB/s    0:46:33  
    890,699,776   2%   10.04MB/s    0:49:19  
    901,480,448   2%   10.01MB/s    0:49:26  
    910,360,576   2%    9.62MB/s    0:51:25  
    921,403,392   2%    9.64MB/s    0:51:20  
    931,856,384   2%    9.73MB/s    0:50:48  
    943,751,168   3%   10.01MB/s    0:49:23  
    955,744,256   3%   10.74MB/s    0:46:00  
    966,492,160   3%   10.68MB/s    0:46:15  
    978,288,640   3%   11.03MB/s    0:44:44  
    989,298,688   3%   10.81MB/s    0:45:39  
  1,001,357,312   3%   10.82MB/s    0:45:35  
  1,013,153,792   3%   11.06MB/s    0:44:35  
  1,024,950,272   3%   11.06MB/s    0:44:34  
  1,035,665,408   3%   10.98MB/s    0:44:54  
  1,046,216,704   3%   10.59MB/s    0:46:31  
  1,058,209,792   3%   10.61MB/s    0:46:25  
  1,069,252,608   3%   10.43MB/s    0:47:11  
  1,080,000,512   3%   10.44MB/s    0:47:06  
  1,091,272,704   3%   10.61MB/s    0:46:22  
  1,102,807,040   3%   10.52MB/s    0:46:44  
  1,113,817,088   3%   10.44MB/s    0:47:05  
  1,124,827,136   3%   10.51MB/s    0:46:45  
  1,136,099,328   3%   10.58MB/s    0:46:25  
  1,147,895,808   3%   10.59MB/s    0:46:22  
  1,158,381,568   3%   10.50MB/s    0:46:43  
  1,169,391,616   3%   10.47MB/s    0:46:52  
  1,180,925,952   3%   10.51MB/s    0:46:40  
  1,191,903,232   3%   10.37MB/s    0:47:15  
  1,201,602,560   3%   10.19MB/s    0:48:06  
  1,212,579,840   3%   10.23MB/s    0:47:54  
  1,224,441,856   3%   10.30MB/s    0:47:31  
  1,234,665,472   3%   10.09MB/s    0:48:32  
  1,246,724,096   3%   10.65MB/s    0:45:55  
  1,257,963,520   4%   10.68MB/s    0:45:48  
  1,268,449,280   4%   10.34MB/s    0:47:16  
  1,279,721,472   4%   10.60MB/s    0:46:05  
  1,291,026,432   4%   10.44MB/s    0:46:49  
  1,302,822,912   4%   10.59MB/s    0:46:06  
  1,313,800,192   4%   10.70MB/s    0:45:37  
  1,325,596,672   4%   10.85MB/s    0:44:58  
  1,337,425,920   4%   10.95MB/s    0:44:33  
  1,346,830,336   4%   10.37MB/s    0:47:01  
  1,357,611,008   4%   10.35MB/s    0:47:05  
  1,369,309,184   4%   10.34MB/s    0:47:06  
  1,379,598,336   4%    9.99MB/s    0:48:46  
  1,391,165,440   4%   10.50MB/s    0:46:21  
  1,401,880,576   4%   10.48MB/s    0:46:26  
  1,412,399,104   4%   10.16MB/s    0:47:53  
  1,424,982,016   4%   10.70MB/s    0:45:28  
  1,437,564,928   4%   10.87MB/s    0:44:42  
  1,448,312,832   4%   10.88MB/s    0:44:39  
  1,460,895,744   4%   11.37MB/s    0:42:44  
  1,472,954,368   4%   11.26MB/s    0:43:08  
  1,485,275,136   4%   11.27MB/s    0:43:05  
  1,497,333,760   4%   11.57MB/s    0:41:56  
  1,509,457,920   4%   11.51MB/s    0:42:09  
  1,521,942,528   4%   11.59MB/s    0:41:50  
  1,534,001,152   4%   11.54MB/s    0:42:00  
  1,546,092,544   4%   11.54MB/s    0:41:58  
  1,558,151,168   4%   11.49MB/s    0:42:07  
  1,569,947,648   5%   11.33MB/s    0:42:43  
  1,581,219,840   5%   11.15MB/s    0:43:23  
  1,591,967,744   5%   10.81MB/s    0:44:46  
  1,602,977,792   5%   10.57MB/s    0:45:43  
  1,614,249,984   5%   10.49MB/s    0:46:03  
  1,626,570,752   5%   10.72MB/s    0:45:03  
  1,637,842,944   5%   10.91MB/s    0:44:16  
  1,649,377,280   5%   11.03MB/s    0:43:46  
  1,660,911,616   5%   11.08MB/s    0:43:34  
  1,672,183,808   5%   10.81MB/s    0:44:37  
  1,683,718,144   5%   10.85MB/s    0:44:26  
  1,695,514,624   5%   10.88MB/s    0:44:17  
  1,707,048,960   5%   10.85MB/s    0:44:23  
  1,719,107,584   5%   11.07MB/s    0:43:30  
  1,730,904,064   5%   11.11MB/s    0:43:19  
  1,742,962,688   5%   11.16MB/s    0:43:08  
  1,754,202,112   5%   11.13MB/s    0:43:13  
  1,766,260,736   5%   11.10MB/s    0:43:18  
  1,778,089,984   5%   11.08MB/s    0:43:23  
  1,789,886,464   5%   11.05MB/s    0:43:29  
  1,802,010,624   5%   11.26MB/s    0:42:39  
  1,812,692,992   5%   10.94MB/s    0:43:52  
  1,824,489,472   5%   10.97MB/s    0:43:45  
  1,836,285,952   5%   10.93MB/s    0:43:52  
  1,847,033,856   5%   10.55MB/s    0:45:28  
  1,857,224,704   5%   10.44MB/s    0:45:56  
  1,868,267,520   5%   10.29MB/s    0:46:34  
  1,880,588,288   6%   10.46MB/s    0:45:48  
  1,891,041,280   6%   10.41MB/s    0:45:59  
  1,902,346,240   6%   10.66MB/s    0:44:55  
  1,914,929,152   6%   11.00MB/s    0:43:30  
  1,926,725,632   6%   10.85MB/s    0:44:05  
  1,938,489,344   6%   11.14MB/s    0:42:54  
  1,949,270,016   6%   11.03MB/s    0:43:20  
  1,960,247,296   6%   10.67MB/s    0:44:46  
  1,970,307,072   6%   10.30MB/s    0:46:21  
  1,981,906,944   6%   10.32MB/s    0:46:16  
  1,994,358,784   6%   10.71MB/s    0:44:33  
  2,006,941,696   6%   11.07MB/s    0:43:04  
  2,019,524,608   6%   11.63MB/s    0:40:59  
  2,032,107,520   6%   11.82MB/s    0:40:18  
  2,044,690,432   6%   11.84MB/s    0:40:13  
  2,057,273,344   6%   11.84MB/s    0:40:12  
  2,069,856,256   6%   11.84MB/s    0:40:12  
  2,082,439,168   6%   11.83MB/s    0:40:12  
  2,094,759,936   6%   11.80MB/s    0:40:18  
  2,107,342,848   6%   11.81MB/s    0:40:15  
  2,119,925,760   6%   11.81MB/s    0:40:14  
  2,132,508,672   6%   11.81MB/s    0:40:13  
  2,145,091,584   6%   11.84MB/s    0:40:05  
  2,157,674,496   6%   11.83MB/s    0:40:05  
  2,169,962,496   6%   11.75MB/s    0:40:22  
  2,181,758,976   6%   11.60MB/s    0:40:52  
  2,192,769,024   7%   11.26MB/s    0:42:05  
  2,203,287,552   7%   10.78MB/s    0:43:57  
  2,215,510,016   7%   10.81MB/s    0:43:47  
  2,225,537,024   7%   10.36MB/s    0:45:42  
  2,236,055,552   7%   10.24MB/s    0:46:12  
  2,246,803,456   7%   10.32MB/s    0:45:49  
  2,258,042,880   7%   10.06MB/s    0:47:01  
  2,269,609,984   7%   10.41MB/s    0:45:24  
  2,281,144,320   7%   10.64MB/s    0:44:25  
  2,293,202,944   7%   10.93MB/s    0:43:13  
  2,304,442,368   7%   10.93MB/s    0:43:10  
  2,315,452,416   7%   10.85MB/s    0:43:31  
  2,327,281,664   7%   10.93MB/s    0:43:09  
  2,339,340,288   7%   10.95MB/s    0:43:04  
  2,351,661,056   7%   11.22MB/s    0:42:01  
  2,361,622,528   7%   10.96MB/s    0:43:00  
  2,372,108,288   7%   10.57MB/s    0:44:34  
  2,382,299,136   7%   10.11MB/s    0:46:35  
  2,392,031,232   7%    9.48MB/s    0:49:39  
  2,402,779,136   7%    9.64MB/s    0:48:48  
  2,414,051,328   7%    9.89MB/s    0:47:32  
  2,425,847,808   7%   10.27MB/s    0:45:46  
  2,437,644,288   7%   10.78MB/s    0:43:36  
  2,448,359,424   7%   10.76MB/s    0:43:38  
  2,458,353,664   7%   10.45MB/s    0:44:55  
  2,469,625,856   7%   10.33MB/s    0:45:27  
  2,480,111,616   7%   10.03MB/s    0:46:45  
  2,490,859,520   7%   10.08MB/s    0:46:31  
  2,501,509,120   7%   10.25MB/s    0:45:44  
  2,512,093,184   8%   10.11MB/s    0:46:22  
  2,522,546,176   8%   10.09MB/s    0:46:25  
  2,533,294,080   8%   10.08MB/s    0:46:27  
  2,543,812,608   8%   10.05MB/s    0:46:36  
  2,554,560,512   8%   10.06MB/s    0:46:31  
  2,565,570,560   8%   10.16MB/s    0:46:02  
  2,576,056,320   8%   10.10MB/s    0:46:19  
  2,586,542,080   8%   10.07MB/s    0:46:26  
  2,597,388,288   8%   10.13MB/s    0:46:08  
  2,608,791,552   8%   10.23MB/s    0:45:41  
  2,620,063,744   8%   10.39MB/s    0:44:56  
  2,630,582,272   8%   10.41MB/s    0:44:50  
  2,640,773,120   8%   10.22MB/s    0:45:38  
  2,651,553,792   8%   10.11MB/s    0:46:08  
  2,662,006,784   8%    9.92MB/s    0:47:01  
  2,672,787,456   8%    9.98MB/s    0:46:41  
  2,683,273,216   8%   10.08MB/s    0:46:13  
  2,693,464,064   8%    9.94MB/s    0:46:50  
  2,703,982,592   8%    9.98MB/s    0:46:40  
  2,714,468,352   8%    9.86MB/s    0:47:11  
  2,725,216,256   8%    9.92MB/s    0:46:54  
  2,735,439,872   8%    9.89MB/s    0:47:02  
  2,745,925,632   8%    9.85MB/s    0:47:13  
  2,754,838,528   8%    9.51MB/s    0:48:52  
  2,765,815,808   8%    9.54MB/s    0:48:42  
  2,775,711,744   8%    9.50MB/s    0:48:53  
  2,786,000,896   8%    9.47MB/s    0:49:01  
  2,797,273,088   8%   10.00MB/s    0:46:24  
  2,808,020,992   8%    9.94MB/s    0:46:40  
  2,818,768,896   9%   10.12MB/s    0:45:49  
  2,828,992,512   9%   10.13MB/s    0:45:46  
  2,840,264,704   9%   10.13MB/s    0:45:45  
  2,851,045,376   9%   10.12MB/s    0:45:46  
  2,861,268,992   9%   10.00MB/s    0:46:19  
  2,870,935,552   9%    9.88MB/s    0:46:50  
  2,881,355,776   9%    9.72MB/s    0:47:36  
  2,891,382,784   9%    9.59MB/s    0:48:15  
  2,901,639,168   9%    9.60MB/s    0:48:09  
  2,911,043,584   9%    9.49MB/s    0:48:43  
  2,921,562,112   9%    9.47MB/s    0:48:47  
  2,932,342,784   9%    9.66MB/s    0:47:47  
  2,943,221,760   9%    9.83MB/s    0:46:59  
  2,953,805,824   9%   10.13MB/s    0:45:34  
  2,964,553,728   9%   10.17MB/s    0:45:23  
  2,975,268,864   9%   10.10MB/s    0:45:40  
  2,984,968,192   9%    9.81MB/s    0:46:59  
  2,995,224,576   9%    9.72MB/s    0:47:24  
  3,005,677,568   9%    9.67MB/s    0:47:39  
  3,015,475,200   9%    9.50MB/s    0:48:28  
  3,025,600,512   9%    9.60MB/s    0:47:57  
  3,036,119,040   9%    9.68MB/s    0:47:33  
  3,046,604,800   9%    9.69MB/s    0:47:27  
  3,057,123,328   9%    9.87MB/s    0:46:36  
  3,067,543,552   9%    9.90MB/s    0:46:27  
  3,078,029,312   9%    9.92MB/s    0:46:19  
  3,088,252,928   9%    9.88MB/s    0:46:31  
  3,098,771,456   9%    9.87MB/s    0:46:32  
  3,109,781,504   9%    9.98MB/s    0:45:59  
  3,119,710,208   9%    9.82MB/s    0:46:42  
  3,129,868,288   9%    9.82MB/s    0:46:42  
  3,140,190,208  10%    9.76MB/s    0:47:00  
  3,150,118,912  10%    9.55MB/s    0:48:01  
  3,160,080,384  10%    9.55MB/s    0:47:57  
  3,170,304,000  10%    9.55MB/s    0:47:56  
  3,180,789,760  10%    9.61MB/s    0:47:38  
  3,190,915,072  10%    9.69MB/s    0:47:14  
  3,201,236,992  10%    9.77MB/s    0:46:51  
  3,212,017,664  10%    9.87MB/s    0:46:20  
  3,220,930,560  10%    9.48MB/s    0:48:13  
  3,232,169,984  10%    9.74MB/s    0:46:55  
  3,241,607,168  10%    9.56MB/s    0:47:48  
  3,252,912,128  10%    9.68MB/s    0:47:11  
  3,263,922,176  10%   10.17MB/s    0:44:53  
  3,274,113,024  10%    9.88MB/s    0:46:10  
  3,285,155,840  10%   10.26MB/s    0:44:26  
  3,297,738,752  10%   10.57MB/s    0:43:09  
  3,310,321,664  10%   10.93MB/s    0:41:42  
  3,322,642,432  10%   11.44MB/s    0:39:49  
  3,332,833,280  10%   11.24MB/s    0:40:32  
  3,342,008,320  10%   10.47MB/s    0:43:29  
  3,352,133,632  10%    9.92MB/s    0:45:51  
  3,364,028,416  10%    9.85MB/s    0:46:10  
  3,376,611,328  10%   10.43MB/s    0:43:36  
  3,389,227,008  10%   11.26MB/s    0:40:22  
  3,401,318,400  10%   11.73MB/s    0:38:44  
  3,411,214,336  10%   11.22MB/s    0:40:27  
  3,422,126,080  10%   10.83MB/s    0:41:55  
  3,431,694,336  10%   10.04MB/s    0:45:10  
  3,441,917,952  10%    9.57MB/s    0:47:24  
  3,452,108,800  11%    9.65MB/s    0:46:59  
  3,461,808,128  11%    9.33MB/s    0:48:35  
  3,472,031,744  11%    9.52MB/s    0:47:34  
  3,482,550,272  11%    9.61MB/s    0:47:08  
  3,492,773,888  11%    9.62MB/s    0:47:04  
  3,503,783,936  11%    9.93MB/s    0:45:36  
  3,513,712,640  11%    9.84MB/s    0:45:58  
  3,523,706,880  11%    9.71MB/s    0:46:35  
  3,532,619,776  11%    9.37MB/s    0:48:14  
  3,542,843,392  11%    9.19MB/s    0:49:12  
  3,553,329,152  11%    9.32MB/s    0:48:28  
  3,563,290,624  11%    9.30MB/s    0:48:33  
  3,573,481,472  11%    9.56MB/s    0:47:12  
  3,583,475,712  11%    9.52MB/s    0:47:24  
  3,593,437,184  11%    9.41MB/s    0:47:56  
  3,604,414,464  11%    9.68MB/s    0:46:36  
  3,615,195,136  11%    9.88MB/s    0:45:38  
  3,625,123,840  11%    9.89MB/s    0:45:33  
  3,635,347,456  11%    9.71MB/s    0:46:24  
  3,645,341,696  11%    9.49MB/s    0:47:25  
  3,655,532,544  11%    9.31MB/s    0:48:19  
  3,665,756,160  11%    9.36MB/s    0:48:04  
  3,676,012,544  11%    9.60MB/s    0:46:51  
  3,686,498,304  11%    9.69MB/s    0:46:23  
  3,696,951,296  11%    9.78MB/s    0:45:57  
  3,706,945,536  11%    9.71MB/s    0:46:16  
  3,717,136,384  11%    9.68MB/s    0:46:25  
  3,726,868,480  11%    9.52MB/s    0:47:10  
  3,737,223,168  11%    9.53MB/s    0:47:06  
  3,747,282,944  11%    9.54MB/s    0:47:02  
  3,756,752,896  11%    9.38MB/s    0:47:47  
  3,767,762,944  12%    9.69MB/s    0:46:16  
  3,778,248,704  12%    9.62MB/s    0:46:36  
  3,789,783,040  12%   10.00MB/s    0:44:48  
  3,801,055,232  12%   10.43MB/s    0:42:54  
  3,812,294,656  12%   10.48MB/s    0:42:42  
  3,824,648,192  12%   10.99MB/s    0:40:42  
  3,835,920,384  12%   10.93MB/s    0:40:54  
  3,845,881,856  12%   10.63MB/s    0:42:04  
  3,855,941,632  12%   10.36MB/s    0:43:08  
  3,867,377,664  12%   10.17MB/s    0:43:54  
  3,877,371,904  12%    9.62MB/s    0:46:25  
  3,890,446,336  12%   10.30MB/s    0:43:21  
  3,901,358,080  12%   10.49MB/s    0:42:31  
  3,911,614,464  12%   10.23MB/s    0:43:35  
  3,922,427,904  12%   10.66MB/s    0:41:49  
  3,933,700,096  12%   10.25MB/s    0:43:28  
  3,946,119,168  12%   10.61MB/s    0:41:59  
  3,957,817,344  12%   10.92MB/s    0:40:46  
  3,968,565,248  12%   10.92MB/s    0:40:44  
  3,979,542,528  12%   10.85MB/s    0:41:01  
  3,990,061,056  12%   10.36MB/s    0:42:56  
  4,001,333,248  12%   10.28MB/s    0:43:15  
  4,013,031,424  12%   10.53MB/s    0:42:12  
  4,023,746,560  12%   10.50MB/s    0:42:16  
  4,034,887,680  12%   10.61MB/s    0:41:49  
  4,044,849,152  12%   10.30MB/s    0:43:05  
  4,056,383,488  12%   10.23MB/s    0:43:21  
  4,066,344,960  12%   10.03MB/s    0:44:13  
  4,077,846,528  13%   10.15MB/s    0:43:40  
  4,089,413,632  13%   10.54MB/s    0:42:02  
  4,099,899,392  13%   10.31MB/s    0:42:56  
  4,110,647,296  13%   10.48MB/s    0:42:14  
  4,121,624,576  13%   10.39MB/s    0:42:34  
  4,133,715,968  13%   10.51MB/s    0:42:06  
  4,143,677,440  13%   10.38MB/s    0:42:37  
  4,154,425,344  13%   10.36MB/s    0:42:39  
  4,164,648,960  13%   10.18MB/s    0:43:23  
  4,175,364,096  13%    9.85MB/s    0:44:51  
  4,186,669,056  13%   10.14MB/s    0:43:32  
  4,196,892,672  13%   10.06MB/s    0:43:51  
  4,208,164,864  13%   10.28MB/s    0:42:55  
  4,217,864,192  13%   10.05MB/s    0:43:53  
  4,228,349,952  13%    9.87MB/s    0:44:40  
  4,239,065,088  13%    9.99MB/s    0:44:06  
  4,249,845,760  13%    9.88MB/s    0:44:34  
  4,260,593,664  13%   10.14MB/s    0:43:26  
  4,271,603,712  13%   10.24MB/s    0:42:59  
  4,282,056,704  13%   10.16MB/s    0:43:19  
  4,292,804,608  13%   10.16MB/s    0:43:16  
  4,303,847,424  13%   10.20MB/s    0:43:05  
  4,315,906,048  13%   10.49MB/s    0:41:52  
  4,327,964,672  13%   10.85MB/s    0:40:28  
  4,339,761,152  13%   11.11MB/s    0:39:31  
  4,351,819,776  13%   11.39MB/s    0:38:30  
  4,364,140,544  13%   11.42MB/s    0:38:24  
  4,376,199,168  13%   11.43MB/s    0:38:21  
  4,388,782,080  14%   11.57MB/s    0:37:52  
  4,401,364,992  14%   11.70MB/s    0:37:27  
  4,412,375,040  14%   11.38MB/s    0:38:28  
  4,423,385,088  14%   11.14MB/s    0:39:16  
  4,434,132,992  14%   10.75MB/s    0:40:41  
  4,445,143,040  14%   10.31MB/s    0:42:25  
  4,455,104,512  14%   10.07MB/s    0:43:23  
  4,465,819,648  14%   10.00MB/s    0:43:41  
  4,476,600,320  14%   10.00MB/s    0:43:41  
  4,487,577,600  14%   10.04MB/s    0:43:28  
  4,498,620,416  14%   10.29MB/s    0:42:26  
  4,509,401,088  14%   10.33MB/s    0:42:14  
  4,520,116,224  14%   10.29MB/s    0:42:23  
  4,530,569,216  14%   10.17MB/s    0:42:52  
  4,541,317,120  14%   10.11MB/s    0:43:05  
  4,552,130,560  14%   10.12MB/s    0:43:03  
  4,562,288,640  14%   10.01MB/s    0:43:28  
  4,572,807,168  14%   10.00MB/s    0:43:30  
  4,583,686,144  14%   10.07MB/s    0:43:13  
  4,594,008,064  14%    9.92MB/s    0:43:49  
  4,604,264,448  14%    9.91MB/s    0:43:52  
  4,613,701,632  14%    9.68MB/s    0:44:53  
  4,626,251,776  14%   10.04MB/s    0:43:16  
  4,638,867,456  14%   10.58MB/s    0:41:01  
  4,649,058,304  14%   10.61MB/s    0:40:53  
  4,660,363,264  14%   11.06MB/s    0:39:14  
  4,671,078,400  14%   10.64MB/s    0:40:45  
  4,681,859,072  14%   10.15MB/s    0:42:42  
  4,693,360,640  14%   10.46MB/s    0:41:25  
  4,705,452,032  15%   10.59MB/s    0:40:53  
  4,716,429,312  15%   10.63MB/s    0:40:42  
  4,727,734,272  15%   10.83MB/s    0:39:56  
  4,739,235,840  15%   10.79MB/s    0:40:05  
  4,749,983,744  15%   10.43MB/s    0:41:26  
  4,760,207,360  15%   10.28MB/s    0:42:03  
  4,771,512,320  15%   10.26MB/s    0:42:05  
  4,782,784,512  15%   10.24MB/s    0:42:10  
  4,793,532,416  15%   10.31MB/s    0:41:52  
  4,803,723,264  15%   10.31MB/s    0:41:50  
  4,814,471,168  15%   10.18MB/s    0:42:21  
  4,824,989,696  15%   10.00MB/s    0:43:06  
  4,835,475,456  15%    9.94MB/s    0:43:22  
  4,845,666,304  15%    9.93MB/s    0:43:23  
  4,857,757,696  15%   10.20MB/s    0:42:12  
  4,868,734,976  15%   10.31MB/s    0:41:43  
  4,879,253,504  15%   10.33MB/s    0:41:37  
  4,891,279,360  15%   10.78MB/s    0:39:53  
  4,903,632,896  15%   10.86MB/s    0:39:33  
  4,915,691,520  15%   11.10MB/s    0:38:42  
  4,927,717,376  15%   11.39MB/s    0:37:42  
  4,939,546,624  15%   11.32MB/s    0:37:55  
  4,950,818,816  15%   11.09MB/s    0:38:40  
  4,962,582,528  15%   10.99MB/s    0:39:02  
  4,973,625,344  15%   10.83MB/s    0:39:35  
  4,985,126,912  15%   10.74MB/s    0:39:53  
  4,997,185,536  15%   10.89MB/s    0:39:19  
  5,008,457,728  15%   10.81MB/s    0:39:36  
  5,019,500,544  16%   10.79MB/s    0:39:39  
  5,030,772,736  16%   10.74MB/s    0:39:49  
  5,042,536,448  16%   10.71MB/s    0:39:54  
  5,051,482,112  16%    8.88MB/s    0:48:07  
  5,051,711,488  16%    5.34MB/s    1:20:05  
  5,062,492,160  16%    5.26MB/s    1:21:09  
  5,073,764,352  16%    5.18MB/s    1:22:23  
  5,083,463,680  16%    5.83MB/s    1:13:12  
  5,093,916,672  16%    9.85MB/s    0:43:18  
  5,104,795,648  16%    9.88MB/s    0:43:10  
  5,115,150,336  16%    9.65MB/s    0:44:11  
  5,125,898,240  16%   10.04MB/s    0:42:27  
  5,137,465,344  16%   10.29MB/s    0:41:23  
  5,148,737,536  16%   10.31MB/s    0:41:17  
  5,159,747,584  16%   10.40MB/s    0:40:54  
  5,170,462,720  16%   10.41MB/s    0:40:52  
  5,181,767,680  16%   10.35MB/s    0:41:05  
  5,191,729,152  16%   10.09MB/s    0:42:08  
  5,202,477,056  16%   10.07MB/s    0:42:11  
  5,214,535,680  16%   10.40MB/s    0:40:51  
  5,226,856,448  16%   10.64MB/s    0:39:54  
  5,238,915,072  16%   11.13MB/s    0:38:08  
  5,249,400,832  16%   11.06MB/s    0:38:21  
  5,260,935,168  16%   10.97MB/s    0:38:38  
  5,272,207,360  16%   10.75MB/s    0:39:26  
  5,284,003,840  16%   10.71MB/s    0:39:32  
  5,295,767,552  16%   11.04MB/s    0:38:20  
  5,308,121,088  16%   11.19MB/s    0:37:49  
  5,320,441,856  16%   11.40MB/s    0:37:06  
  5,332,238,336  17%   11.40MB/s    0:37:05  
  5,343,248,384  17%   11.23MB/s    0:37:37  
  5,354,258,432  17%   10.95MB/s    0:38:34  
  5,364,482,048  17%   10.46MB/s    0:40:23  
  5,376,016,384  17%   10.36MB/s    0:40:44  
  5,387,288,576  17%   10.39MB/s    0:40:37  
  5,398,036,480  17%   10.29MB/s    0:40:59  
  5,409,308,672  17%   10.53MB/s    0:40:01  
  5,420,843,008  17%   10.54MB/s    0:39:58  
  5,433,425,920  17%   10.85MB/s    0:38:48  
  5,444,173,824  17%   10.89MB/s    0:38:39  
  5,454,921,728  17%   10.75MB/s    0:39:08  
  5,465,833,472  17%   10.63MB/s    0:39:34  
  5,472,190,464  17%    8.88MB/s    0:47:23  
  5,481,398,272  17%    8.51MB/s    0:49:25  
  5,491,359,744  17%    8.36MB/s    0:50:15  
  5,502,369,792  17%    8.39MB/s    0:50:05  
  5,514,428,416  17%   10.02MB/s    0:41:54  
  5,524,914,176  17%   10.34MB/s    0:40:34  
  5,532,483,584  17%    9.76MB/s    0:42:59  
  5,543,788,544  17%    9.82MB/s    0:42:41  
  5,556,109,312  17%    9.89MB/s    0:42:24  
  5,568,692,224  17%   10.40MB/s    0:40:18  
  5,581,242,368  17%   11.60MB/s    0:36:05  
  5,591,990,272  17%   11.47MB/s    0:36:28  
  5,604,081,664  17%   11.41MB/s    0:36:40  
  5,616,664,576  17%   11.41MB/s    0:36:38  
  5,629,247,488  17%   11.42MB/s    0:36:36  
  5,641,830,400  18%   11.86MB/s    0:35:14  
  5,652,840,448  18%   11.60MB/s    0:35:59  
  5,665,423,360  18%   11.55MB/s    0:36:08  
  5,677,973,504  18%   11.55MB/s    0:36:08  
  5,690,556,416  18%   11.55MB/s    0:36:07  
  5,701,861,376  18%   11.21MB/s    0:37:10  
  5,714,051,072  18%   11.17MB/s    0:37:17  
  5,726,502,912  18%   11.12MB/s    0:37:27  
  5,739,085,824  18%   11.12MB/s    0:37:25  
  5,751,635,968  18%   11.84MB/s    0:35:08  
  5,763,727,360  18%   11.77MB/s    0:35:20  
  5,776,310,272  18%   11.83MB/s    0:35:07  
  5,788,860,416  18%   11.79MB/s    0:35:14  
  5,801,476,096  18%   11.81MB/s    0:35:10  
  5,813,796,864  18%   11.90MB/s    0:34:52  
  5,825,331,200  18%   11.65MB/s    0:35:36  
  5,837,914,112  18%   11.69MB/s    0:35:28  
  5,850,497,024  18%   11.65MB/s    0:35:35  
  5,863,047,168  18%   11.71MB/s    0:35:22  
  5,875,662,848  18%   11.97MB/s    0:34:35  
  5,886,148,608  18%    7.00MB/s    0:59:05  
  5,886,410,752  18%    4.82MB/s    1:25:46  
  5,886,672,896  18%    2.67MB/s    2:34:42  
  5,886,935,040  18%    1.24MB/s    5:33:22  
  5,891,915,776  18%  922.22kB/s    7:39:25  
  5,904,498,688  18%    3.10MB/s    2:13:24  
  5,917,114,368  18%    6.85MB/s    1:00:22  
  5,929,664,512  18%   10.18MB/s    0:40:35  
  5,942,247,424  18%   12.00MB/s    0:34:24  
  5,954,568,192  19%   11.94MB/s    0:34:34  
  5,967,151,104  19%   11.93MB/s    0:34:35  
  5,979,734,016  19%   11.93MB/s    0:34:33  
  5,992,316,928  19%   11.93MB/s    0:34:31  
  6,004,899,840  19%   12.00MB/s    0:34:19  
  6,017,220,608  19%   11.94MB/s    0:34:29  
  6,029,803,520  19%   11.94MB/s    0:34:28  
  6,042,386,432  19%   11.94MB/s    0:34:27  
  6,054,969,344  19%   11.94MB/s    0:34:26  
  6,067,552,256  19%   12.00MB/s    0:34:14  
  6,080,135,168  19%   11.98MB/s    0:34:17  
  6,092,718,080  19%   11.98MB/s    0:34:16  
  6,105,300,992  19%   11.98MB/s    0:34:15  
  6,117,883,904  19%   11.98MB/s    0:34:13  
  6,130,466,816  19%   12.00MB/s    0:34:09  
  6,143,049,728  19%   11.98MB/s    0:34:11  
  6,155,632,640  19%   11.98MB/s    0:34:10  
  6,168,215,552  19%   11.98MB/s    0:34:09  
  6,180,798,464  19%   11.98MB/s    0:34:08  
  6,193,381,376  19%   11.96MB/s    0:34:10  
  6,205,964,288  19%   11.94MB/s    0:34:13  
  6,218,547,200  19%   11.94MB/s    0:34:12  
  6,231,130,112  19%   11.94MB/s    0:34:11  
  6,243,713,024  19%   11.98MB/s    0:34:03  
  6,256,295,936  19%   12.00MB/s    0:33:59  
  6,268,092,416  20%   11.79MB/s    0:34:34  
  6,280,675,328  20%   11.79MB/s    0:34:33  
  6,293,258,240  20%   11.79MB/s    0:34:32  
  6,305,841,152  20%   11.79MB/s    0:34:31  
  6,318,424,064  20%   12.00MB/s    0:33:54  
  6,329,958,400  20%   11.75MB/s    0:34:36  
  6,342,279,168  20%   11.69MB/s    0:34:46  
  6,354,599,936  20%   11.62MB/s    0:34:56  
  6,366,920,704  20%   11.56MB/s    0:35:06  
  6,379,241,472  20%   11.75MB/s    0:34:32  
  6,391,529,472  20%   11.74MB/s    0:34:32  
  6,403,883,008  20%   11.75MB/s    0:34:29  
  6,416,203,776  20%   11.75MB/s    0:34:28  
  6,428,491,776  20%   11.75MB/s    0:34:29  
  6,440,845,312  20%   11.76MB/s    0:34:25  
  6,453,166,080  20%   11.75MB/s    0:34:25  
  6,465,486,848  20%   11.75MB/s    0:34:24  
  6,477,807,616  20%   11.76MB/s    0:34:22  
  6,490,161,152  20%   11.76MB/s    0:34:21  
  6,502,449,152  20%   11.75MB/s    0:34:21  
  6,514,769,920  20%   11.75MB/s    0:34:20  
  6,527,090,688  20%   11.76MB/s    0:34:18  
  6,539,411,456  20%   11.74MB/s    0:34:20  
  6,551,732,224  20%   11.74MB/s    0:34:18  
  6,564,020,224  20%   11.73MB/s    0:34:20  
  6,576,340,992  21%   11.73MB/s    0:34:19  
  6,588,694,528  21%   11.74MB/s    0:34:16  
  6,601,048,064  21%   11.76MB/s    0:34:12  
  6,613,565,440  21%   11.82MB/s    0:34:01  
  6,626,181,120  21%   11.89MB/s    0:33:48  
  6,638,764,032  21%   11.94MB/s    0:33:38  
  6,651,314,176  21%   11.98MB/s    0:33:29  
  6,663,929,856  21%   11.98MB/s    0:33:28  
  6,676,512,768  21%   11.98MB/s    0:33:28  
  6,689,095,680  21%   11.98MB/s    0:33:27  
  6,701,678,592  21%   11.94MB/s    0:33:33  
  6,714,228,736  21%   11.95MB/s    0:33:30  
  6,726,844,416  21%   11.93MB/s    0:33:32  
  6,739,427,328  21%   11.93MB/s    0:33:31  
  6,752,010,240  21%   11.98MB/s    0:33:22  
  6,764,331,008  21%   11.89MB/s    0:33:36  
  6,776,913,920  21%   11.90MB/s    0:33:33  
  6,789,496,832  21%   11.88MB/s    0:33:36  
  6,802,079,744  21%   11.88MB/s    0:33:35  
  6,814,662,656  21%   11.98MB/s    0:33:17  
  6,827,245,568  21%   11.98MB/s    0:33:16  
  6,839,795,712  21%   11.99MB/s    0:33:12  
  6,852,411,392  21%   11.98MB/s    0:33:14  
  6,864,994,304  21%   11.98MB/s    0:33:13  
  6,877,577,216  21%   11.98MB/s    0:33:12  
  6,890,160,128  22%   11.99MB/s    0:33:09  
  6,902,743,040  22%   12.00MB/s    0:33:06  
  6,915,325,952  22%   11.98MB/s    0:33:08  
  6,927,908,864  22%   11.98MB/s    0:33:07  
  6,940,491,776  22%   11.98MB/s    0:33:06  
  6,953,074,688  22%   11.98MB/s    0:33:05  
  6,965,657,600  22%   12.00MB/s    0:33:01  
  6,978,240,512  22%   11.98MB/s    0:33:03  
  6,990,790,656  22%   11.97MB/s    0:33:04  
  7,003,406,336  22%   11.98MB/s    0:33:01  
  7,015,170,048  22%   11.73MB/s    0:33:42  
  7,027,523,584  22%   11.70MB/s    0:33:46  
  7,039,811,584  22%   11.62MB/s    0:34:00  
  7,052,165,120  22%   11.56MB/s    0:34:10  
  7,064,485,888  22%   11.74MB/s    0:33:37  
  7,076,773,888  22%   11.67MB/s    0:33:47  
  7,089,127,424  22%   11.71MB/s    0:33:41  
  7,101,448,192  22%   11.70MB/s    0:33:41  
  7,113,768,960  22%   11.70MB/s    0:33:39  
  7,126,089,728  22%   11.76MB/s    0:33:28  
  7,138,410,496  22%   11.75MB/s    0:33:28  
  7,150,731,264  22%   11.75MB/s    0:33:28  
  7,163,052,032  22%   11.75MB/s    0:33:27  
  7,175,372,800  22%   11.75MB/s    0:33:26  
  7,187,660,800  22%   11.74MB/s    0:33:26  
  7,200,014,336  22%   11.75MB/s    0:33:24  
  7,212,335,104  23%   11.75MB/s    0:33:23  
  7,224,655,872  23%   11.75MB/s    0:33:22  
  7,236,943,872  23%   11.75MB/s    0:33:21  
  7,249,297,408  23%   11.75MB/s    0:33:19  
  7,261,356,032  23%   11.64MB/s    0:33:38  
  7,273,676,800  23%   11.64MB/s    0:33:37  
  7,285,997,568  23%   11.65MB/s    0:33:34  
  7,298,318,336  23%   11.64MB/s    0:33:34  
  7,310,606,336  23%   11.74MB/s    0:33:16  
  7,322,959,872  23%   11.75MB/s    0:33:13  
  7,335,280,640  23%   11.75MB/s    0:33:12  
  7,347,601,408  23%   11.75MB/s    0:33:11  
  7,359,922,176  23%   11.76MB/s    0:33:09  
  7,372,242,944  23%   11.75MB/s    0:33:09  
  7,384,563,712  23%   11.75MB/s    0:33:08  
  7,396,884,480  23%   11.75MB/s    0:33:07  
  7,409,205,248  23%   11.75MB/s    0:33:06  
  7,421,526,016  23%   11.75MB/s    0:33:06  
  7,433,879,552  23%   11.76MB/s    0:33:03  
  7,445,643,264  23%   11.62MB/s    0:33:24  
  7,457,964,032  23%   11.62MB/s    0:33:23  
  7,470,284,800  23%   11.62MB/s    0:33:22  
  7,482,605,568  23%   11.61MB/s    0:33:23  
  7,494,926,336  23%   11.74MB/s    0:33:00  
  7,506,952,192  23%   11.68MB/s    0:33:10  
  7,519,109,120  24%   11.64MB/s    0:33:16  
  7,531,364,352  24%   11.62MB/s    0:33:18  
  7,543,652,352  24%   11.61MB/s    0:33:18  
  7,556,005,888  24%   11.68MB/s    0:33:05  
  7,567,802,368  24%   11.60MB/s    0:33:19  
  7,580,090,368  24%   11.61MB/s    0:33:16  
  7,592,443,904  24%   11.62MB/s    0:33:12  
  7,604,764,672  24%   11.62MB/s    0:33:13  
  7,617,085,440  24%   11.74MB/s    0:32:51  
  7,628,881,920  24%   11.62MB/s    0:33:10  
  7,640,875,008  24%   11.54MB/s    0:33:23  
  7,653,261,312  24%   11.50MB/s    0:33:28  
  7,665,844,224  24%   11.55MB/s    0:33:18  
  7,678,197,760  24%   11.69MB/s    0:32:54  
  7,689,699,328  24%   11.53MB/s    0:33:20  
  7,702,020,096  24%   11.58MB/s    0:33:11  
  7,714,340,864  24%   11.53MB/s    0:33:18  
  7,726,661,632  24%   11.52MB/s    0:33:19  
  7,738,982,400  24%   11.75MB/s    0:32:38  
  7,750,778,880  24%   11.59MB/s    0:33:05  
  7,763,099,648  24%   11.59MB/s    0:33:04  
  7,775,420,416  24%   11.59MB/s    0:33:03  
  7,787,741,184  24%   11.59MB/s    0:33:02  
  7,800,061,952  24%   11.75MB/s    0:32:33  
  7,811,563,520  24%   11.51MB/s    0:33:13  
  7,823,654,912  24%   11.43MB/s    0:33:26  
  7,835,975,680  25%   11.42MB/s    0:33:27  
  7,848,296,448  25%   11.42MB/s    0:33:26  
  7,860,649,984  25%   11.68MB/s    0:32:41  
  7,872,937,984  25%   11.73MB/s    0:32:31  
  7,885,258,752  25%   11.73MB/s    0:32:30  
  7,897,579,520  25%   11.74MB/s    0:32:28  
  7,909,900,288  25%   11.72MB/s    0:32:29  
  7,922,221,056  25%   11.75MB/s    0:32:24  
  7,934,541,824  25%   11.75MB/s    0:32:23  
  7,946,862,592  25%   11.74MB/s    0:32:22  
  7,959,183,360  25%   11.74MB/s    0:32:21  
  7,971,504,128  25%   11.75MB/s    0:32:19  
  7,983,824,896  25%   11.75MB/s    0:32:18  
  7,996,112,896  25%   11.75MB/s    0:32:18  
  8,008,466,432  25%   11.75MB/s    0:32:16  
  8,020,787,200  25%   11.75MB/s    0:32:15  
  8,033,107,968  25%   11.75MB/s    0:32:14  
  8,045,395,968  25%   11.74MB/s    0:32:14  
  8,057,192,448  25%   11.61MB/s    0:32:35  
  8,069,283,840  25%   11.54MB/s    0:32:46  
  8,081,604,608  25%   11.55MB/s    0:32:44  
  8,093,925,376  25%   11.54MB/s    0:32:44  
  8,106,246,144  25%   11.67MB/s    0:32:22  
  8,118,566,912  25%   11.74MB/s    0:32:09  
  8,130,887,680  25%   11.74MB/s    0:32:09  
  8,143,208,448  26%   11.75MB/s    0:32:05  
  8,155,529,216  26%   11.75MB/s    0:32:05  
  8,167,849,984  26%   11.74MB/s    0:32:04  
  8,180,170,752  26%   11.70MB/s    0:32:10  
  8,192,491,520  26%   11.70MB/s    0:32:09  
  8,204,812,288  26%   11.70MB/s    0:32:08  
  8,217,133,056  26%   11.70MB/s    0:32:07  
  8,229,453,824  26%   11.75MB/s    0:31:59  
  8,241,774,592  26%   11.71MB/s    0:32:04  
  8,254,095,360  26%   11.70MB/s    0:32:04  
  8,266,416,128  26%   11.70MB/s    0:32:03  
  8,278,736,896  26%   11.70MB/s    0:32:02  
  8,291,057,664  26%   11.74MB/s    0:31:54  
  8,302,854,144  26%   11.60MB/s    0:32:17  
  8,314,912,768  26%   11.53MB/s    0:32:27  
  8,327,233,536  26%   11.52MB/s    0:32:28  
  8,339,554,304  26%   11.53MB/s    0:32:26  
  8,351,875,072  26%   11.68MB/s    0:32:00  
  8,364,457,984  26%   11.80MB/s    0:31:38  
  8,377,040,896  26%   11.88MB/s    0:31:26  
  8,389,623,808  26%   11.93MB/s    0:31:15  
  8,402,272,256  26%   12.02MB/s    0:31:02  
  8,414,789,632  26%   11.96MB/s    0:31:09  
  8,427,372,544  26%   11.96MB/s    0:31:08  
  8,439,955,456  26%   11.97MB/s    0:31:06  
  8,452,538,368  26%   11.95MB/s    0:31:07  
  8,465,121,280  27%   12.00MB/s    0:30:59  
  8,477,704,192  27%   11.98MB/s    0:31:01  
  8,489,762,816  27%   11.86MB/s    0:31:19  
  8,502,083,584  27%   11.79MB/s    0:31:28  
  8,514,404,352  27%   11.74MB/s    0:31:37  
  8,526,725,120  27%   11.69MB/s    0:31:42  
  8,539,045,888  27%   11.75MB/s    0:31:32  
  8,551,366,656  27%   11.73MB/s    0:31:35  
  8,563,687,424  27%   11.73MB/s    0:31:34  
  8,575,975,424  27%   11.72MB/s    0:31:34  
  8,588,328,960  27%   11.73MB/s    0:31:32  
  8,600,649,728  27%   11.75MB/s    0:31:27  
  8,612,085,760  27%   11.54MB/s    0:32:00  
  8,624,504,832  27%   11.57MB/s    0:31:54  
  8,637,087,744  27%   11.63MB/s    0:31:44  
  8,649,670,656  27%   11.69MB/s    0:31:33  
  8,662,253,568  27%   11.96MB/s    0:30:49  
  8,674,836,480  27%   12.00MB/s    0:30:42  
  8,687,419,392  27%   11.97MB/s    0:30:45  
  8,700,002,304  27%   11.97MB/s    0:30:45  
  8,712,585,216  27%   11.97MB/s    0:30:44  
  8,725,168,128  27%   11.93MB/s    0:30:48  
  8,737,751,040  27%   11.97MB/s    0:30:42  
  8,750,333,952  27%   11.97MB/s    0:30:41  
  8,762,916,864  27%   11.97MB/s    0:30:40  
  8,775,499,776  28%   12.00MB/s    0:30:34  
  8,787,820,544  28%   11.93MB/s    0:30:43  
  8,800,403,456  28%   11.93MB/s    0:30:42  
  8,812,986,368  28%   11.93MB/s    0:30:41  
  8,825,569,280  28%   11.93MB/s    0:30:40  
  8,838,152,192  28%   12.00MB/s    0:30:29  
  8,850,735,104  28%   11.97MB/s    0:30:33  
  8,863,318,016  28%   11.94MB/s    0:30:36  
  8,875,900,928  28%   11.94MB/s    0:30:35  
  8,888,483,840  28%   11.94MB/s    0:30:34  
  8,901,066,752  28%   11.97MB/s    0:30:28  
  8,913,649,664  28%   12.00MB/s    0:30:22  
  8,925,970,432  28%   11.94MB/s    0:30:31  
  8,938,520,576  28%   11.93MB/s    0:30:31  
  8,951,136,256  28%   11.94MB/s    0:30:29  
  8,963,719,168  28%   11.94MB/s    0:30:28  
  8,976,302,080  28%   12.00MB/s    0:30:17  
  8,988,098,560  28%   11.80MB/s    0:30:47  
  9,000,681,472  28%   11.79MB/s    0:30:48  
  9,013,264,384  28%   11.79MB/s    0:30:47  
  9,025,847,296  28%   11.79MB/s    0:30:46  
  9,038,430,208  28%   12.00MB/s    0:30:13  
  9,050,226,688  28%   11.79MB/s    0:30:44  
  9,062,809,600  28%   11.75MB/s    0:30:48  
  9,075,392,512  28%   11.75MB/s    0:30:47  
  9,087,975,424  29%   11.75MB/s    0:30:46  
  9,100,558,336  29%   11.97MB/s    0:30:12  
  9,113,141,248  29%   11.96MB/s    0:30:12  
  9,125,724,160  29%   11.96MB/s    0:30:11  
  9,138,307,072  29%   11.96MB/s    0:30:10  
  9,150,857,216  29%   11.96MB/s    0:30:10  
  9,163,472,896  29%   12.00MB/s    0:30:02  
  9,176,055,808  29%   11.96MB/s    0:30:07  
  9,188,638,720  29%   11.96MB/s    0:30:06  
  9,201,188,864  29%   11.96MB/s    0:30:05  
  9,213,771,776  29%   11.95MB/s    0:30:05  
  9,226,387,456  29%   12.00MB/s    0:29:57  
  9,238,970,368  29%   11.96MB/s    0:30:02  
  9,251,553,280  29%   11.97MB/s    0:30:00  
rsync: write failed on &quot;/data/hiveptest/logs/PreCommit-HIVE-Build-3790/failed/126-TestSparkCliDriver-ptf_seqfile.q-union_remove_23.q-parallel_join0.q-and-12-more/logs/hive.log&quot;: No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
Warning: Permanently added &apos;35.184.171.199&apos; (ECDSA) to the list of known hosts.
receiving incremental file list
logs/
logs/hive.log

              0   0%    0.00kB/s    0:00:00  
rsync: write failed on &quot;/data/hiveptest/logs/PreCommit-HIVE-Build-3790/failed/126-TestSparkCliDriver-ptf_seqfile.q-union_remove_23.q-parallel_join0.q-and-12-more/logs/hive.log&quot;: No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
Warning: Permanently added &apos;35.184.171.199&apos; (ECDSA) to the list of known hosts.
receiving incremental file list
logs/
logs/hive.log

              0   0%    0.00kB/s    0:00:00  
rsync: write failed on &quot;/data/hiveptest/logs/PreCommit-HIVE-Build-3790/failed/126-TestSparkCliDriver-ptf_seqfile.q-union_remove_23.q-parallel_join0.q-and-12-more/logs/hive.log&quot;: No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
Warning: Permanently added &apos;35.184.171.199&apos; (ECDSA) to the list of known hosts.
receiving incremental file list
logs/
logs/hive.log

              0   0%    0.00kB/s    0:00:00  
rsync: write failed on &quot;/data/hiveptest/logs/PreCommit-HIVE-Build-3790/failed/126-TestSparkCliDriver-ptf_seqfile.q-union_remove_23.q-parallel_join0.q-and-12-more/logs/hive.log&quot;: No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
Warning: Permanently added &apos;35.184.171.199&apos; (ECDSA) to the list of known hosts.
receiving incremental file list
logs/
logs/hive.log

              0   0%    0.00kB/s    0:00:00  
rsync: write failed on &quot;/data/hiveptest/logs/PreCommit-HIVE-Build-3790/failed/126-TestSparkCliDriver-ptf_seqfile.q-union_remove_23.q-parallel_join0.q-and-12-more/logs/hive.log&quot;: No space left on device (28)
rsync error: error in file IO (code 11) at receiver.c(393) [receiver=3.1.1]
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12854690 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15892855" author="sershe" created="Thu, 2 Mar 2017 19:38:10 +0000"  >&lt;p&gt;Does this need to be resubmitted again?&lt;/p&gt;</comment>
                            <comment id="15894395" author="hiveqa" created="Fri, 3 Mar 2017 13:54:30 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12855728/HIVE-1626.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12855728/HIVE-1626.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/3913/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/3913/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/3913/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/3913/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-3913/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-3913/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Tests exited with: ExecutionException: java.util.concurrent.ExecutionException: java.io.IOException: Could not create /data/hiveptest/logs/PreCommit-HIVE-Build-3913/failed/26-TestCliDriver-autogen_colalias.q-notable_alias3.q-avro_decimal_native.q-and-27-more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12855728 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15902419" author="hiveqa" created="Thu, 9 Mar 2017 03:30:40 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12856829/HIVE-1626.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12856829/HIVE-1626.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/4036/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/4036/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/4036/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/4036/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-4036/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-4036/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hiveptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-03-09 03:30:39.148
+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]
+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;MAVEN_OPTS=-Xmx1g &apos;
+ MAVEN_OPTS=&apos;-Xmx1g &apos;
+ cd /data/hiveptest/working/
+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-4036/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-03-09 03:30:39.151
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 348a592 HIVE-16114 : NullPointerException in TezSessionPoolManager when getting the session (Zhihua Deng, reviewed by Sergey Shelukhin)
+ git clean -f -d
+ git checkout master
Already on &apos;master&apos;
Your branch is up-to-date with &apos;origin/master&apos;.
+ git reset --hard origin/master
HEAD is now at 348a592 HIVE-16114 : NullPointerException in TezSessionPoolManager when getting the session (Zhihua Deng, reviewed by Sergey Shelukhin)
+ git merge --ff-only origin/master
Already up-to-date.
+ date &apos;+%Y-%m-%d %T.%3N&apos;
2017-03-09 03:30:40.027
+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hiveptest/working/scratch/build.patch
+ [[ -f /data/hiveptest/working/scratch/build.patch ]]
+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh
+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch
error: patch failed: ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/NullScanTaskDispatcher.java:37
error: ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/NullScanTaskDispatcher.java: patch does not apply
error: patch failed: ql/src/java/org/apache/hadoop/hive/ql/parse/ProcessAnalyzeTable.java:20
error: ql/src/java/org/apache/hadoop/hive/ql/parse/ProcessAnalyzeTable.java: patch does not apply
The patch does not appear to apply with p0, p1, or p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12856829 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15949894" author="ashutoshc" created="Thu, 30 Mar 2017 21:33:42 +0000"  >&lt;p&gt;Patch needs a rebase.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12853906" name="HIVE-1626.2.patch" size="243308" author="teddy.choi" created="Wed, 22 Feb 2017 07:47:18 +0000"/>
                            <attachment id="12853867" name="HIVE-1626.2.patch" size="495278" author="teddy.choi" created="Wed, 22 Feb 2017 03:34:51 +0000"/>
                            <attachment id="12856829" name="HIVE-1626.3.patch" size="244523" author="teddy.choi" created="Wed, 8 Mar 2017 16:14:28 +0000"/>
                            <attachment id="12855728" name="HIVE-1626.3.patch" size="244523" author="teddy.choi" created="Thu, 2 Mar 2017 23:41:04 +0000"/>
                            <attachment id="12854690" name="HIVE-1626.3.patch" size="244523" author="teddy.choi" created="Sun, 26 Feb 2017 02:37:12 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 21 Feb 2017 17:03:15 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42417</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 42 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08ndr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>48387</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-1627] Hive Join returns incorrect results if the join is (bigint = string)</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1627</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;I was running a query joining on bigint column with string column.&lt;/p&gt;

&lt;p&gt;And, result was incorrect because only &quot;16 bytes seemed to be compared&quot;. The length of value more than 16 bytes when represented as base-10. &lt;/p&gt;

&lt;p&gt;The problem was fixed once I changed the join to (bigint = cast (string as bigint))&lt;/p&gt;

&lt;p&gt;Is the bug because of type conversion on join keys?&lt;/p&gt;</description>
                <environment></environment>
        <key id="12473818">HIVE-1627</key>
            <summary>Hive Join returns incorrect results if the join is (bigint = string)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="kevy">kevy liu</assignee>
                                    <reporter username="agupta@rocketfuelinc.com">Abhinav Gupta</reporter>
                        <labels>
                    </labels>
                <created>Fri, 10 Sep 2010 15:57:34 +0000</created>
                <updated>Tue, 6 Jun 2017 13:38:54 +0000</updated>
                                            <version>0.5.0</version>
                                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="12913310" author="jvs" created="Tue, 21 Sep 2010 23:43:12 +0000"  >&lt;p&gt;To help verify this, could you provide a specific example?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 21 Sep 2010 23:43:12 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42416</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 18 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lg2n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123254</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-1628] Fix Base64TextInputFormat to be compatible with commons codec 1.4</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1628</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Commons-codec 1.4 made an incompatible change to the Base64 class that made line-wrapping default (boo!). This breaks the Base64TextInputFormat in contrib. This patch adds some simple reflection to use the new constructor that uses the old behavior.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12473838">HIVE-1628</key>
            <summary>Fix Base64TextInputFormat to be compatible with commons codec 1.4</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="tlipcon">Todd Lipcon</assignee>
                                    <reporter username="tlipcon">Todd Lipcon</reporter>
                        <labels>
                    </labels>
                <created>Fri, 10 Sep 2010 18:35:55 +0000</created>
                <updated>Sat, 17 Dec 2011 00:01:08 +0000</updated>
                            <resolved>Mon, 20 Sep 2010 21:41:07 +0000</resolved>
                                    <version>0.6.0</version>
                    <version>0.7.0</version>
                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Contrib</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12908141" author="tlipcon" created="Fri, 10 Sep 2010 18:58:11 +0000"  >&lt;p&gt;Oops, I just noticed I posted the wrong patch! sorry, one sec...&lt;/p&gt;</comment>
                            <comment id="12908145" author="tlipcon" created="Fri, 10 Sep 2010 19:04:41 +0000"  >&lt;p&gt;Here are the correct patches.&lt;/p&gt;</comment>
                            <comment id="12912634" author="jvs" created="Mon, 20 Sep 2010 18:40:17 +0000"  >&lt;p&gt;+1.  Will commit if tests pass.&lt;/p&gt;</comment>
                            <comment id="12912726" author="jvs" created="Mon, 20 Sep 2010 21:41:07 +0000"  >&lt;p&gt;Committed (trunk only).  Thanks Todd!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12454322" name="hive-1628-0.5.txt" size="3371" author="tlipcon" created="Fri, 10 Sep 2010 19:04:41 +0000"/>
                            <attachment id="12454318" name="hive-1628-0.5.txt" size="2570" author="tlipcon" created="Fri, 10 Sep 2010 18:56:09 +0000"/>
                            <attachment id="12454321" name="hive-1628.txt" size="3101" author="tlipcon" created="Fri, 10 Sep 2010 19:04:41 +0000"/>
                            <attachment id="12454317" name="hive-1628.txt" size="2300" author="tlipcon" created="Fri, 10 Sep 2010 18:56:09 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 20 Sep 2010 18:40:17 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72806</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 19 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lg2v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123255</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1629] Patch to fix hashCode method in DoubleWritable class</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1629</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;A patch to fix the hashCode() method of DoubleWritable class of Hive.&lt;br/&gt;
It prevents the HashMap (of type DoubleWritable) from behaving as LinkedList.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12473852">HIVE-1629</key>
            <summary>Patch to fix hashCode method in DoubleWritable class</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vaggarw">Vaibhav Aggarwal</assignee>
                                    <reporter username="vaggarw">Vaibhav Aggarwal</reporter>
                        <labels>
                    </labels>
                <created>Fri, 10 Sep 2010 20:17:24 +0000</created>
                <updated>Fri, 16 Dec 2011 23:59:46 +0000</updated>
                            <resolved>Mon, 13 Sep 2010 05:59:45 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Serializers/Deserializers</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12908194" author="nzhang" created="Fri, 10 Sep 2010 21:35:56 +0000"  >&lt;p&gt;+    long v = Double.doubleToLongBits(value);&lt;br/&gt;
+    return (int) (v ^ (v &amp;gt;&amp;gt;&amp;gt; 32));&lt;/p&gt;

&lt;p&gt;won&apos;t this return 0 for all long values less than 2^32?&lt;/p&gt;

&lt;p&gt;Search on the web and it seems the following 64 bit to 32 bit hash is a good one&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cris.com/~ttwang/tech/inthash.htm&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.cris.com/~ttwang/tech/inthash.htm&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12908210" author="vaggarw" created="Fri, 10 Sep 2010 22:08:21 +0000"  >&lt;p&gt;Hi&lt;/p&gt;

&lt;p&gt;The doubleToLongBits converts the double value into IEEE 754 floating-point &quot;double format&quot; bit layout.&lt;br/&gt;
Furthermore the XOR operator prevents returning 0 for values less than 2^32.&lt;/p&gt;

&lt;p&gt;This is the hashCode function used by standard java implementation.&lt;/p&gt;

&lt;p&gt;I was noticing unexpected delay in one of the operations related to double data types.&lt;br/&gt;
After some debugging I realized that the HashMap puts and gets were extremely slow.&lt;br/&gt;
That pointed me to the hashCode implementatoin in DoubleWritable which turned out to be the cause of slow HashMap IO.&lt;/p&gt;

&lt;p&gt;That is why I propose to use the standard java implmenetation of HashCode for double type.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Vaibhav&lt;/p&gt;</comment>
                            <comment id="12908599" author="nzhang" created="Mon, 13 Sep 2010 03:28:44 +0000"  >&lt;p&gt;+1 Will commit if tests pass.&lt;/p&gt;</comment>
                            <comment id="12908622" author="jvs" created="Mon, 13 Sep 2010 05:28:18 +0000"  >&lt;p&gt;Ning, does this change introduce incompatibility with any persistent storage (e.g. bucketing)?&lt;/p&gt;</comment>
                            <comment id="12908631" author="nzhang" created="Mon, 13 Sep 2010 05:59:45 +0000"  >&lt;p&gt;Committed. Thanks Vaibhav!&lt;/p&gt;</comment>
                            <comment id="12908639" author="nzhang" created="Mon, 13 Sep 2010 06:18:23 +0000"  >&lt;p&gt;Good question John. I think this patch doesn&apos;t affect bucketing, which is implemented using ObjectInspectorUtils.hashCode(). Actually the hash function used there for Double is the same as the one provided in this patch. But I&apos;ll double check with Zheng/Namit tomorrow. &lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12454329" name="HIVE-1629.patch" size="607" author="vaggarw" created="Fri, 10 Sep 2010 20:18:16 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 10 Sep 2010 21:35:56 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72805</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 20 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lg33:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123256</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1630] bug in NO_DROP</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1630</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;If the table is marked NO_DROP, we should still be able to drop old partitions.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12473878">HIVE-1630</key>
            <summary>bug in NO_DROP</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sdong">Siying Dong</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Fri, 10 Sep 2010 23:18:13 +0000</created>
                <updated>Sat, 17 Dec 2011 00:01:03 +0000</updated>
                            <resolved>Sun, 12 Sep 2010 21:00:43 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12908241" author="sdong" created="Fri, 10 Sep 2010 23:55:23 +0000"  >&lt;p&gt;I think it is a mistake when I design the semantic of no_drop. no_drop on table level should not block us from dropping partitions. I&apos;ll fix that.&lt;/p&gt;</comment>
                            <comment id="12908261" author="sdong" created="Sat, 11 Sep 2010 01:42:44 +0000"  >&lt;p&gt;table of &quot;NO_DROP&quot; doesn&apos;t block dropping partitions of it.&lt;/p&gt;</comment>
                            <comment id="12908483" author="namit" created="Sun, 12 Sep 2010 15:40:58 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;will commit if the tests pass&lt;/p&gt;</comment>
                            <comment id="12908558" author="namit" created="Sun, 12 Sep 2010 21:00:43 +0000"  >&lt;p&gt;Committed. Thanks Siying&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12454355" name="HIVE-1630.2.patch" size="28869" author="sdong" created="Sat, 11 Sep 2010 01:56:05 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 10 Sep 2010 23:55:23 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72804</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 20 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lg3b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123257</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1631] JDBC driver returns wrong precision, scale, or column size for some data types</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1631</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;For some data types, these methods return values that do not conform to the JDBC spec:&lt;/p&gt;

&lt;p&gt;org.apache.hadoop.hive.jdbc.HiveResultSetMetaData.getPrecision(int)&lt;br/&gt;
org.apache.hadoop.hive.jdbc.HiveResultSetMetaData.getScale(int)&lt;br/&gt;
org.apache.hadoop.hive.jdbc.HiveResultSetMetaData.getColumnDisplaySize(int)&lt;br/&gt;
org.apache.hadoop.hive.jdbc.JdbcColumn.getColumnSize()&lt;/p&gt;</description>
                <environment></environment>
        <key id="12473884">HIVE-1631</key>
            <summary>JDBC driver returns wrong precision, scale, or column size for some data types</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="phunt">Patrick Hunt</assignee>
                                    <reporter username="slider">Steven K. Wong</reporter>
                        <labels>
                    </labels>
                <created>Sat, 11 Sep 2010 00:44:19 +0000</created>
                <updated>Fri, 16 Dec 2011 23:55:38 +0000</updated>
                            <resolved>Mon, 8 Aug 2011 17:42:45 +0000</resolved>
                                    <version>0.7.0</version>
                                    <fixVersion>0.8.0</fixVersion>
                                    <component>JDBC</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13073054" author="phunt" created="Fri, 29 Jul 2011 22:40:26 +0000"  >&lt;p&gt;This patch addresses the specified methods based on my reading of the spec. It&apos;s not at all clear to me that I&apos;ve interpreted the spec correctly, so please do chime in if you think something is wrong - for example: in my update Hive string columns have a size of Integer.MAX_VALUE given Hive has no bounds on length.&lt;/p&gt;

&lt;p&gt;This patch also fixes a problem with the metadata returned by &lt;/p&gt;

&lt;p&gt;DatabaseMetaData.getColumns(...).getMetaData()&lt;/p&gt;

&lt;p&gt;I updated the tests and also viewed the result of these changes via Squirrel&lt;/p&gt;
</comment>
                            <comment id="13073060" author="jiraposter@reviews.apache.org" created="Fri, 29 Jul 2011 22:44:10 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/1226/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/1226/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for hive and Carl Steinbach.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;This patch addresses the specified methods based on my reading of the spec.&lt;/p&gt;

&lt;p&gt;It&apos;s not at all clear to me that I&apos;ve interpreted the spec correctly, so please do chime in if you think something is wrong - for example: in my update Hive string columns have a size of Integer.MAX_VALUE given Hive has no bounds on length. Also take a look at precision and size for float/double.&lt;/p&gt;

&lt;p&gt;This patch also fixes a problem with the metadata returned by DatabaseMetaData.getColumns(...).getMetaData()&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1631&quot; title=&quot;JDBC driver returns wrong precision, scale, or column size for some data types&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1631&quot;&gt;&lt;del&gt;HIVE-1631&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1631&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1631&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveDatabaseMetaData.java 0e106be &lt;br/&gt;
  jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveResultSetMetaData.java cf651b6 &lt;br/&gt;
  jdbc/src/java/org/apache/hadoop/hive/jdbc/JdbcColumn.java 9182744 &lt;br/&gt;
  jdbc/src/java/org/apache/hadoop/hive/jdbc/Utils.java PRE-CREATION &lt;br/&gt;
  jdbc/src/test/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java 91af351 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/1226/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/1226/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;I updated the tests and also viewed the result of these changes via Squirrel&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Patrick&lt;/p&gt;
</comment>
                            <comment id="13078424" author="cwsteinbach" created="Tue, 2 Aug 2011 20:50:39 +0000"  >&lt;p&gt;+1. Will commit if tests pass.&lt;/p&gt;</comment>
                            <comment id="13079297" author="cwsteinbach" created="Thu, 4 Aug 2011 09:35:23 +0000"  >&lt;p&gt;Committed to trunk. Thanks Patrick!&lt;/p&gt;</comment>
                            <comment id="13079385" author="hudson" created="Thu, 4 Aug 2011 14:10:22 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #873 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/873/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/873/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1631&quot; title=&quot;JDBC driver returns wrong precision, scale, or column size for some data types&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1631&quot;&gt;&lt;del&gt;HIVE-1631&lt;/del&gt;&lt;/a&gt;. JDBC driver returns wrong precision, scale, or column size for some data types (Patrick Hunt via cws)&lt;/p&gt;

&lt;p&gt;cws : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1153809&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1153809&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/Utils.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveDatabaseMetaData.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/test/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/JdbcColumn.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveResultSetMetaData.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13080816" author="mgk.424@gmail.com" created="Mon, 8 Aug 2011 08:36:21 +0000"  >&lt;p&gt;Just verified this fix and does not work correctly. Here are my findings on a FLOAT column&lt;/p&gt;

&lt;p&gt;Without Patch on a FLOAT Column&lt;br/&gt;
--------------------------------&lt;br/&gt;
DatabaseMetaData.getColumns () COLUMN_SIZE returns 12&lt;br/&gt;
DatabaseMetaData.getColumns () DECIMAL_DIGITS - returns 0&lt;/p&gt;

&lt;p&gt;ResultSetMetaData.getPrecision() returns 0&lt;br/&gt;
ResultSetMetaData.getScale() returns 0&lt;/p&gt;

&lt;p&gt;With Patch on a FLOAT Column&lt;br/&gt;
----------------------------&lt;br/&gt;
DatabaseMetaData.getColumns () COLUMN_SIZE returns 24&lt;br/&gt;
DatabaseMetaData.getColumns () DECIMAL_DIGITS - returns 0&lt;/p&gt;

&lt;p&gt;ResultSetMetaData.getPrecision() returns 0&lt;br/&gt;
ResultSetMetaData.getScale() returns 0&lt;/p&gt;

&lt;p&gt;Both DatabaseMetadata and ResultSet metadata must return the same information for Precision and Scale for FLOAT,DOUBLE types.&lt;/p&gt;

</comment>
                            <comment id="13080819" author="mgk.424@gmail.com" created="Mon, 8 Aug 2011 08:42:28 +0000"  >&lt;p&gt;Fixing some typos  from previous comment&lt;/p&gt;

&lt;p&gt;Just tested this fix and does NOT work correctly. Here are my findings on a FLOAT column&lt;/p&gt;

&lt;p&gt;Without Patch on a FLOAT Column&lt;br/&gt;
--------------------------------&lt;br/&gt;
DatabaseMetaData.getColumns () COLUMN_SIZE returns 12&lt;br/&gt;
DatabaseMetaData.getColumns () DECIMAL_DIGITS - returns 0&lt;/p&gt;

&lt;p&gt;ResultSetMetaData.getPrecision() returns 0&lt;br/&gt;
ResultSetMetaData.getScale() returns 0&lt;/p&gt;

&lt;p&gt;With Patch on a FLOAT Column&lt;br/&gt;
----------------------------&lt;br/&gt;
DatabaseMetaData.getColumns () COLUMN_SIZE returns 24&lt;br/&gt;
DatabaseMetaData.getColumns () DECIMAL_DIGITS - returns 0&lt;/p&gt;

&lt;p&gt;ResultSetMetaData.getPrecision() returns 7&lt;br/&gt;
ResultSetMetaData.getScale() returns 7&lt;/p&gt;

&lt;p&gt;Also both DatabaseMetadata and ResultSetMetaData must return the same information for Precision and Scale for FLOAT,DOUBLE types.&lt;/p&gt;</comment>
                            <comment id="13081060" author="phunt" created="Mon, 8 Aug 2011 17:02:44 +0000"  >&lt;p&gt;I&apos;ll create an additional patch (incl more testing) for this. Thanks Mythili.&lt;/p&gt;</comment>
                            <comment id="13081081" author="cwsteinbach" created="Mon, 8 Aug 2011 17:42:38 +0000"  >&lt;p&gt;Please open a separate ticket for this issue.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12518249">HIVE-2358</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12488258" name="HIVE-1631.patch" size="15515" author="phunt" created="Fri, 29 Jul 2011 22:40:26 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 29 Jul 2011 22:40:26 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>37475</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 25 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i05ilb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>30109</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1632] Column length not sufficient for large STRUCT definitions</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1632</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Can be reproduced by adding the following table:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;hive&amp;gt; CREATE TABLE test (big struct&amp;lt;prop1: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop2: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop3: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop4: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop5: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop6: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop7: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop8: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop9: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop10: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop10: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop11: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop12: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop13: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop14: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop15: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop16: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop17: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop18: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
                                    prop19: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;&amp;gt;);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Error:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;FAILED: Error in metadata: javax.jdo.JDODataStoreException: Add request failed : INSERT INTO COLUMNS (SD_ID,COMMENT,&quot;COLUMN_NAME&quot;,TYPE_NAME,INTEGER_IDX) VALUES (?,?,?,?,?) 
NestedThrowables:
java.sql.SQLDataException: A truncation error was encountered trying to shrink VARCHAR &apos;struct&amp;lt;prop1:int,prop2:int,prop3:int,prop4:int,prop5:int,pro&amp;amp;&apos; to length 128.
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Workaround:&lt;br/&gt;
Change column length in metastore. Derby example: &lt;tt&gt;ALTER TABLE columns ALTER type_name SET DATA TYPE VARCHAR(1000);&lt;/tt&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12473944">HIVE-1632</key>
            <summary>Column length not sufficient for large STRUCT definitions</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.svg">Trivial</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="wnagele">Wolfgang Nagele</reporter>
                        <labels>
                    </labels>
                <created>Sun, 12 Sep 2010 21:27:33 +0000</created>
                <updated>Thu, 2 May 2013 02:29:33 +0000</updated>
                            <resolved>Sat, 29 Oct 2011 09:18:20 +0000</resolved>
                                    <version>0.5.0</version>
                                    <fixVersion>0.6.0</fixVersion>
                                    <component>Metastore</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13139160" author="ashutoshc" created="Sat, 29 Oct 2011 09:18:20 +0000"  >&lt;p&gt;This got resolved as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1364&quot; title=&quot;Increase the maximum length of various metastore fields, and remove TYPE_NAME from COLUMNS primary key&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1364&quot;&gt;&lt;del&gt;HIVE-1364&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12465284">HIVE-1364</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 29 Oct 2011 09:18:20 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42415</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 13 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lg3j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123258</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1633] CombineHiveInputFormat fails with &quot;cannot find dir for emptyFile&quot;</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1633</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12473954">HIVE-1633</key>
            <summary>CombineHiveInputFormat fails with &quot;cannot find dir for emptyFile&quot;</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sreekanth">Sreekanth Ramakrishnan</assignee>
                                    <reporter username="amareshwari">Amareshwari Sriramadasu</reporter>
                        <labels>
                    </labels>
                <created>Mon, 13 Sep 2010 06:17:37 +0000</created>
                <updated>Tue, 19 Jan 2016 21:47:38 +0000</updated>
                            <resolved>Wed, 20 Oct 2010 19:33:39 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Clients</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="12908638" author="amareshwari" created="Mon, 13 Sep 2010 06:18:10 +0000"  >&lt;p&gt;Here is full exception trace:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.io.IOException: cannot find dir =
hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/emptyFile
in partToPartitionInfo:
[xxx......., xxx......., xxx......., ...............
 hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1,
hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/2]
        at
org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getPartitionDescFromPathRecursively(HiveFileFormatUtils.java:277)
        at
org.apache.hadoop.hive.ql.io.CombineHiveInputFormat$CombineHiveInputSplit.&amp;lt;init&amp;gt;(CombineHiveInputFormat.java:100)
        at org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getSplits(CombineHiveInputFormat.java:312)
        at org.apache.hadoop.mapred.JobClient.writeOldSplits(JobClient.java:929)
        at org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:921)
        at org.apache.hadoop.mapred.JobClient.access$500(JobClient.java:170)
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:838)
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:792)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1021)
        at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:792)
        at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:766)
        at org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:610)
        at org.apache.hadoop.hive.ql.exec.MapRedTask.execute(MapRedTask.java:120)
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:108)
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:55)
        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:900)
        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:770)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:647)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:140)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:199)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:353)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:156)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12908716" author="he yongqiang" created="Mon, 13 Sep 2010 10:59:50 +0000"  >&lt;p&gt;Amareshwari, more details about your example? From your example, i can not reproduce the problem.&lt;/p&gt;</comment>
                            <comment id="12909666" author="amareshwari" created="Wed, 15 Sep 2010 09:17:49 +0000"  >&lt;p&gt;Sorry for the delay. &lt;br/&gt;
The table has three partitions and 100 columns. It is stored as RCFile with compressed data.&lt;br/&gt;
The query we ran was &quot;select count(&amp;#42;) from &amp;lt;table&amp;gt;&quot; with CombineHiveInputFormat as the input format. We were trying to test &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-1597&quot; title=&quot;combinefileinputformat does not work with non-splittable files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-1597&quot;&gt;&lt;del&gt;MAPREDUCE-1597&lt;/del&gt;&lt;/a&gt; by setting hive.hadoop.supports.splittable.combineinputformat to true. Queries ran fine with Text files.&lt;/p&gt;</comment>
                            <comment id="12909711" author="he yongqiang" created="Wed, 15 Sep 2010 12:36:25 +0000"  >&lt;p&gt;@Amareshwari&lt;/p&gt;

&lt;p&gt;in your example:&lt;br/&gt;
hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/emptyFile&lt;br/&gt;
in partToPartitionInfo:&lt;br/&gt;
[xxx......., xxx......., xxx......., ...............&lt;br/&gt;
 hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1,&lt;br/&gt;
hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/2]&lt;/p&gt;

&lt;p&gt;If i put these into TestHiveFormatUtils, it can return correct value. Maybe there is some mismatch about &apos;xxx&apos;?&lt;/p&gt;</comment>
                            <comment id="12910001" author="amareshwari" created="Thu, 16 Sep 2010 03:51:59 +0000"  >&lt;p&gt;I replaced the actual file names of xxx, because actual file/host names are internal to our organization. But the problem is CombineHiveInputFormat is looking for PartitionDesc in &quot;hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/emptyFile&quot; . This dir is not part of the table input data. I think this dir is getting added by FileSinkOperator. &lt;/p&gt;</comment>
                            <comment id="12910002" author="amareshwari" created="Thu, 16 Sep 2010 03:56:38 +0000"  >&lt;blockquote&gt;&lt;p&gt;I replaced the actual file names of xxx.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I meant &quot; I replaced the actual file/host names with xxx&quot;&lt;/p&gt;</comment>
                            <comment id="12910255" author="he yongqiang" created="Thu, 16 Sep 2010 18:32:14 +0000"  >&lt;p&gt;Can you search &lt;br/&gt;
hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1 (replacing xxx with actual file/host names)?&lt;/p&gt;

&lt;p&gt;It should appear one time in partToPartitionInfo and another one time in &quot;hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/emptyFile&quot;.&lt;/p&gt;</comment>
                            <comment id="12910430" author="amareshwari" created="Fri, 17 Sep 2010 03:34:57 +0000"  >&lt;p&gt;It appears only once as &quot;hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/&quot;. there is no &quot;hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/emptyFile&quot;&lt;/p&gt;</comment>
                            <comment id="12910431" author="he yongqiang" created="Fri, 17 Sep 2010 03:37:52 +0000"  >&lt;p&gt;so &apos;xxx&apos; part is not the same in &quot;hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/&quot; and &quot;hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/emptyFile&quot;&lt;br/&gt;
?&lt;/p&gt;</comment>
                            <comment id="12910435" author="amareshwari" created="Fri, 17 Sep 2010 03:55:05 +0000"  >&lt;p&gt;Sorry If I misunderstood your comment. I looked for hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/ in partToPartitionInfo shown in the exception. Only hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/ appears. hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1/emptyFile does not appear in partToPartitionInfo. &lt;/p&gt;</comment>
                            <comment id="12912795" author="he yongqiang" created="Tue, 21 Sep 2010 01:02:14 +0000"  >&lt;p&gt;For a given path, CombineHiveInputFormat does recursive lookup in partToPartitionInfo. If no match found, will lookup for the parent dir (&quot;hdfs://xxx/.../hive_2010-09-07_12-15-00_299_4877141498303008976/-mr-10002/1&quot;) in partToPartitionInfo. In your case, it seems the parent dir exist in partToPartitionInfo. &lt;/p&gt;</comment>
                            <comment id="12913230" author="he yongqiang" created="Tue, 21 Sep 2010 20:29:21 +0000"  >&lt;p&gt;Amareshwari, by adding a testcase in TestHiveFileFormatUtils, you will be able to find out the underlying problem, and then can you post a patch for it?&lt;/p&gt;</comment>
                            <comment id="12918490" author="sreekanth" created="Wed, 6 Oct 2010 12:17:10 +0000"  >&lt;p&gt;I was taking a look at reproducing the issue. The core reason why the exception is present is due to following.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Input format is passed a set of input path.&lt;/li&gt;
	&lt;li&gt;These set of path contains two kind of files, table data files and scratch/tmp files which are created by hive in hdfs.&lt;/li&gt;
	&lt;li&gt;CombineHiveInputFormat tries to compute splits in these temp/scratch file, which causes the  getPartitionDescFromPathRecursively to fail. Causing the query to fail.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I hope this helps, I am still looking at the code, and trying to figure out where the actual addition to input paths are done. So basically I can back track from there. Any help on this would be great.&lt;/p&gt;
</comment>
                            <comment id="12920838" author="sreekanth" created="Thu, 14 Oct 2010 02:58:02 +0000"  >&lt;p&gt;This problem is caused in following scenario:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;tt&gt;NameNode&lt;/tt&gt; is running on default port &lt;tt&gt;8020&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;The data which is to be processed has atleast one empty partition.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The logic how empty partition is dealt is by creating an &lt;tt&gt;emptyFile&lt;/tt&gt; in the scratch directory.&lt;/p&gt;

&lt;p&gt;So when &lt;tt&gt;NameNode&lt;/tt&gt; runs on default port, the URI which &lt;tt&gt;NameNode&lt;/tt&gt; passes on does not contain the port information in authority part. Whereas typically the configuration for hive scratch directory contains the port information. This causes this issue.&lt;/p&gt;</comment>
                            <comment id="12921967" author="sreekanth" created="Mon, 18 Oct 2010 05:07:55 +0000"  >&lt;p&gt;Attaching the patch which fixes this issue. It just makes the temporary empty file to qualified. Not sure of how to add a unit test case for the same.&lt;/p&gt;
</comment>
                            <comment id="12922419" author="amareshwari" created="Tue, 19 Oct 2010 03:55:25 +0000"  >&lt;p&gt;Making it Patch available.&lt;/p&gt;</comment>
                            <comment id="12922644" author="namit" created="Tue, 19 Oct 2010 18:03:48 +0000"  >&lt;p&gt;Yongqiang, can you take a look ?&lt;/p&gt;</comment>
                            <comment id="12922650" author="he yongqiang" created="Tue, 19 Oct 2010 18:10:18 +0000"  >&lt;p&gt;+1 &lt;/p&gt;</comment>
                            <comment id="12923120" author="he yongqiang" created="Wed, 20 Oct 2010 19:33:39 +0000"  >&lt;p&gt;I just committed! Thanks Sreekanth Ramakrishnan!&lt;/p&gt;</comment>
                            <comment id="13598983" author="shuang" created="Mon, 11 Mar 2013 16:59:16 +0000"  >&lt;p&gt;This bug seems to also show up in hive local mode, the empty temporary file path is not qualified with &quot;file:/&quot;.&lt;/p&gt;

&lt;p&gt;2013-03-11 09:34:30,767 INFO  io.CombineHiveInputFormat (CombineHiveInputFormat.java:getSplits(363)) - CombineHiveInputSplit creating pool for &lt;a href=&quot;file:/var/folders/w7/fp4gml2n1xqg2434qdp799r00002cr/T/shuang/hive_2013-03-11_09-34-29_301_2567414763209147193/-mr-10000/1&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/var/folders/w7/fp4gml2n1xqg2434qdp799r00002cr/T/shuang/hive_2013-03-11_09-34-29_301_2567414763209147193/-mr-10000/1&lt;/a&gt;; using filter path &lt;a href=&quot;file:/var/folders/w7/fp4gml2n1xqg2434qdp799r00002cr/T/shuang/hive_2013-03-11_09-34-29_301_2567414763209147193/-mr-10000/1&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/var/folders/w7/fp4gml2n1xqg2434qdp799r00002cr/T/shuang/hive_2013-03-11_09-34-29_301_2567414763209147193/-mr-10000/1&lt;/a&gt;&lt;br/&gt;
2013-03-11 09:34:30,772 INFO  mapred.FileInputFormat (FileInputFormat.java:listStatus(196)) - Total input paths to process : 1&lt;br/&gt;
2013-03-11 09:34:30,778 INFO  mapred.JobClient (JobClient.java:run(919)) - Cleaning up the staging area &lt;a href=&quot;file:/data/hadoop/cache/analytics-mr.sv2/shuang/mapred/staging/shuang-1827099888/.staging/job_local_0001&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/data/hadoop/cache/analytics-mr.sv2/shuang/mapred/staging/shuang-1827099888/.staging/job_local_0001&lt;/a&gt;&lt;br/&gt;
2013-03-11 09:34:30,778 ERROR security.UserGroupInformation (UserGroupInformation.java:doAs(1180)) - PriviledgedActionException as:shuang (auth:SIMPLE) cause:java.io.FileNotFoundException: File does not exist: /var/folders/w7/fp4gml2n1xqg2434qdp799r00002cr/T/shuang/hive_2013-03-11_09-34-29_301_2567414763209147193/-mr-10000/1/emptyFile&lt;br/&gt;
2013-03-11 09:34:30,779 ERROR exec.ExecDriver (SessionState.java:printError(365)) - Job Submission failed with exception &apos;java.io.FileNotFoundException(File does not exist: /var/folders/w7/fp4gml2n1xqg2434qdp799r00002cr/T/shuang/hive_2013-03-11_09-34-29_301_2567414763209147193/-mr-10000/1/emptyFile)&apos;&lt;br/&gt;
java.io.FileNotFoundException: File does not exist: /var/folders/w7/fp4gml2n1xqg2434qdp799r00002cr/T/shuang/hive_2013-03-11_09-34-29_301_2567414763209147193/-mr-10000/1/emptyFile&lt;br/&gt;
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:562)&lt;br/&gt;
        at org.apache.hadoop.mapred.lib.CombineFileInputFormat$OneFileInfo.&amp;lt;init&amp;gt;(CombineFileInputFormat.java:462)&lt;br/&gt;
        at org.apache.hadoop.mapred.lib.CombineFileInputFormat.getMoreSplits(CombineFileInputFormat.java:256)&lt;br/&gt;
        at org.apache.hadoop.mapred.lib.CombineFileInputFormat.getSplits(CombineFileInputFormat.java:212)&lt;br/&gt;
        at org.apache.hadoop.hive.shims.Hadoop20SShims$CombineFileInputFormatShim.getSplits(Hadoop20SShims.java:347)&lt;br/&gt;
        at org.apache.hadoop.hive.shims.Hadoop20SShims$CombineFileInputFormatShim.getSplits(Hadoop20SShims.java:313)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getSplits(CombineHiveInputFormat.java:377)&lt;br/&gt;
        at org.apache.hadoop.mapred.JobClient.writeOldSplits(JobClient.java:977)&lt;br/&gt;
        at org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:969)&lt;br/&gt;
        at org.apache.hadoop.mapred.JobClient.access$500(JobClient.java:170)&lt;br/&gt;
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:880)&lt;br/&gt;
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:833)&lt;br/&gt;
        at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
        at javax.security.auth.Subject.doAs(Subject.java:396)&lt;br/&gt;
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)&lt;br/&gt;
        at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:833)&lt;br/&gt;
        at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:807)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:671)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.ExecDriver.main(ExecDriver.java:1092)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.util.RunJar.main(RunJar.java:197)&lt;/p&gt;</comment>
                            <comment id="15107521" author="ergin.demirel" created="Tue, 19 Jan 2016 21:47:38 +0000"  >&lt;p&gt;We are still getting error message when trying to load empty table/file running on local mode. &lt;br/&gt;
Tried adding &quot;file://&quot; in front of the path though it didn&apos;t help. Can someone please clarify the solution here? &lt;/p&gt;

&lt;p&gt;Hive Version: 0.10.0+121-1.cdh4.3.0.p0.16~precise-cdh4.3.0&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;java.io.FileNotFoundException: File does not exist: /tmp/hdfs/hive_2016-01-19_21-40-07_727_4067638808884572526/-mr-10000/1/emptyFile
    at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:807)
    at org.apache.hadoop.mapred.lib.CombineFileInputFormat$OneFileInfo.&amp;lt;init&amp;gt;(CombineFileInputFormat.java:462)
    at org.apache.hadoop.mapred.lib.CombineFileInputFormat.getMoreSplits(CombineFileInputFormat.java:256)
    at org.apache.hadoop.mapred.lib.CombineFileInputFormat.getSplits(CombineFileInputFormat.java:212)
    at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileInputFormatShim.getSplits(HadoopShimsSecure.java:411)
    at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileInputFormatShim.getSplits(HadoopShimsSecure.java:377)
    at org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getSplits(CombineHiveInputFormat.java:387)
    at org.apache.hadoop.mapred.JobClient.writeOldSplits(JobClient.java:1091)
    at org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:1083)
    at org.apache.hadoop.mapred.JobClient.access$600(JobClient.java:174)
    at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:993)
    at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:946)
    at java.security.AccessController.doPrivileged(Native Method)
    at javax.security.auth.Subject.doAs(Subject.java:396)
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1408)
    at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:946)
    at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:920)
    at org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:448)
    at org.apache.hadoop.hive.ql.exec.ExecDriver.main(ExecDriver.java:690)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.util.RunJar.main(RunJar.java:208)
Job Submission failed with exception &lt;span class=&quot;code-quote&quot;&gt;&apos;java.io.FileNotFoundException(File does not exist: /tmp/hdfs/hive_2016-01-19_21-40-07_727_4067638808884572526/-mr-10000/1/emptyFile)&apos;&lt;/span&gt;
Execution failed with exit status: 1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12658525">HIVE-4881</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12478376">HIVE-1753</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12457415" name="HIVE-1633.patch" size="829" author="sreekanth" created="Mon, 18 Oct 2010 05:07:55 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 13 Sep 2010 10:59:50 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72803</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lg3r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123259</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1634] Allow access to Primitive types stored in binary format in HBase</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1634</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;This addresses &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1245&quot; title=&quot;allow access to values stored as non-strings in HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1245&quot;&gt;HIVE-1245&lt;/a&gt; in part, for atomic or primitive types.&lt;/p&gt;

&lt;p&gt;The serde property &quot;hbase.columns.storage.types&quot; = &quot;&lt;del&gt;,b,b,b,b,b,b,b,b&quot; is a specification of the storage option for the corresponding column in the serde property &quot;hbase.columns.mapping&quot;. Allowed values are &apos;&lt;/del&gt;&apos; for table default, &apos;s&apos; for standard string storage, and &apos;b&apos; for binary storage as would be obtained from o.a.h.hbase.utils.Bytes. Map types for HBase column families use a colon separated pair such as &apos;s:b&apos; for the key and value part specifiers respectively. See the test cases and queries for HBase handler for additional examples.&lt;/p&gt;

&lt;p&gt;There is also a table property &quot;hbase.table.default.storage.type&quot; = &quot;string&quot; to specify a table level default storage type. The other valid specification is &quot;binary&quot;. The table level default is overridden by a column level specification.&lt;/p&gt;

&lt;p&gt;This control is available for the boolean, tinyint, smallint, int, bigint, float, and double primitive types. The attached patch also relaxes the mapping of map types to HBase column families to allow any primitive type to be the map key.&lt;/p&gt;

&lt;p&gt;Attached is a program for creating a table and populating it in HBase. The external table in Hive can access the data as shown in the example below.&lt;/p&gt;

&lt;p&gt;hive&amp;gt; create external table TestHiveHBaseExternalTable&lt;br/&gt;
    &amp;gt; (key string, c_bool boolean, c_byte tinyint, c_short smallint,&lt;br/&gt;
    &amp;gt;  c_int int, c_long bigint, c_string string, c_float float, c_double double)&lt;br/&gt;
    &amp;gt;  stored by &apos;org.apache.hadoop.hive.hbase.HBaseStorageHandler&apos;&lt;br/&gt;
    &amp;gt;  with serdeproperties (&quot;hbase.columns.mapping&quot; = &quot;:key,cf:boolean,cf:byte,cf:short,cf:int,cf:long,cf:string,cf:float,cf:double&quot;)&lt;br/&gt;
    &amp;gt;  tblproperties (&quot;hbase.table.name&quot; = &quot;TestHiveHBaseExternalTable&quot;);&lt;br/&gt;
OK&lt;br/&gt;
Time taken: 0.691 seconds&lt;br/&gt;
hive&amp;gt; select * from TestHiveHBaseExternalTable;&lt;br/&gt;
OK&lt;br/&gt;
key-1	NULL	NULL	NULL	NULL	NULL	Test-String	NULL	NULL&lt;br/&gt;
Time taken: 0.346 seconds&lt;br/&gt;
hive&amp;gt; drop table TestHiveHBaseExternalTable;&lt;br/&gt;
OK&lt;br/&gt;
Time taken: 0.139 seconds&lt;br/&gt;
hive&amp;gt; create external table TestHiveHBaseExternalTable&lt;br/&gt;
    &amp;gt; (key string, c_bool boolean, c_byte tinyint, c_short smallint,&lt;br/&gt;
    &amp;gt;  c_int int, c_long bigint, c_string string, c_float float, c_double double)&lt;br/&gt;
    &amp;gt;  stored by &apos;org.apache.hadoop.hive.hbase.HBaseStorageHandler&apos;&lt;br/&gt;
    &amp;gt;  with serdeproperties (&lt;br/&gt;
    &amp;gt;  &quot;hbase.columns.mapping&quot; = &quot;:key,cf:boolean,cf:byte,cf:short,cf:int,cf:long,cf:string,cf:float,cf:double&quot;,&lt;br/&gt;
    &amp;gt;  &quot;hbase.columns.storage.types&quot; = &quot;-,b,b,b,b,b,b,b,b&quot; )&lt;br/&gt;
    &amp;gt;  tblproperties (&lt;br/&gt;
    &amp;gt;  &quot;hbase.table.name&quot; = &quot;TestHiveHBaseExternalTable&quot;,&lt;br/&gt;
    &amp;gt;  &quot;hbase.table.default.storage.type&quot; = &quot;string&quot;);&lt;br/&gt;
OK&lt;br/&gt;
Time taken: 0.139 seconds&lt;br/&gt;
hive&amp;gt; select * from TestHiveHBaseExternalTable;&lt;br/&gt;
OK&lt;br/&gt;
key-1	true	-128	-32768	-2147483648	-9223372036854775808	Test-String	-2.1793132E-11	2.01345E291&lt;br/&gt;
Time taken: 0.151 seconds&lt;br/&gt;
hive&amp;gt; drop table TestHiveHBaseExternalTable;&lt;br/&gt;
OK&lt;br/&gt;
Time taken: 0.154 seconds&lt;br/&gt;
hive&amp;gt; create external table TestHiveHBaseExternalTable&lt;br/&gt;
    &amp;gt; (key string, c_bool boolean, c_byte tinyint, c_short smallint,&lt;br/&gt;
    &amp;gt;  c_int int, c_long bigint, c_string string, c_float float, c_double double)&lt;br/&gt;
    &amp;gt;  stored by &apos;org.apache.hadoop.hive.hbase.HBaseStorageHandler&apos;&lt;br/&gt;
    &amp;gt;  with serdeproperties (&lt;br/&gt;
    &amp;gt;  &quot;hbase.columns.mapping&quot; = &quot;:key,cf:boolean,cf:byte,cf:short,cf:int,cf:long,cf:string,cf:float,cf:double&quot;,&lt;br/&gt;
    &amp;gt;  &quot;hbase.columns.storage.types&quot; = &quot;&lt;del&gt;,b,b,b,b,b,&lt;/del&gt;,b,b&quot; )&lt;br/&gt;
    &amp;gt;  tblproperties (&quot;hbase.table.name&quot; = &quot;TestHiveHBaseExternalTable&quot;);&lt;br/&gt;
OK&lt;br/&gt;
Time taken: 0.347 seconds&lt;br/&gt;
hive&amp;gt; select * from TestHiveHBaseExternalTable;&lt;br/&gt;
OK&lt;br/&gt;
key-1	true	-128	-32768	-2147483648	-9223372036854775808	Test-String	-2.1793132E-11	2.01345E291&lt;br/&gt;
Time taken: 0.245 seconds&lt;br/&gt;
hive&amp;gt; &lt;/p&gt;</description>
                <environment></environment>
        <key id="12474000">HIVE-1634</key>
            <summary>Allow access to Primitive types stored in binary format in HBase</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ashutoshc">Ashutosh Chauhan</assignee>
                                    <reporter username="bkm">Basab Maulik</reporter>
                        <labels>
                    </labels>
                <created>Mon, 13 Sep 2010 20:27:17 +0000</created>
                <updated>Tue, 21 Jan 2014 00:29:58 +0000</updated>
                            <resolved>Fri, 9 Mar 2012 00:50:58 +0000</resolved>
                                    <version>0.7.0</version>
                    <version>0.8.0</version>
                    <version>0.9.0</version>
                                    <fixVersion>0.9.0</fixVersion>
                                    <component>HBase Handler</component>
                        <due></due>
                            <votes>3</votes>
                                    <watches>10</watches>
                                                                <comments>
                            <comment id="12908986" author="bkm" created="Mon, 13 Sep 2010 20:35:14 +0000"  >&lt;p&gt;Attached is a preliminary patch for this issue.&lt;/p&gt;

&lt;p&gt;A scan of the HBase table for the example above:&lt;/p&gt;

&lt;p&gt;hbase(main):004:0&amp;gt; scan &apos;TestHiveHBaseExternalTable&apos;&lt;br/&gt;
ROW                          COLUMN+CELL                                                                      &lt;br/&gt;
 key-1                       column=cf:boolean, timestamp=1284406847770, value=\xFF                           &lt;br/&gt;
 key-1                       column=cf:byte, timestamp=1284406847770, value=\x80                              &lt;br/&gt;
 key-1                       column=cf:double, timestamp=1284406847770, value=|i\xD3lwy\xDCb                  &lt;br/&gt;
 key-1                       column=cf:float, timestamp=1284406847770, value=\xAD\xBF\xB1\xC5                 &lt;br/&gt;
 key-1                       column=cf:int, timestamp=1284406847770, value=\x80\x00\x00\x00                   &lt;br/&gt;
 key-1                       column=cf:long, timestamp=1284406847770, value=\x80\x00\x00\x00\x00\x00\x00\x00  &lt;br/&gt;
 key-1                       column=cf:short, timestamp=1284406847770, value=\x80\x00                         &lt;br/&gt;
 key-1                       column=cf:string, timestamp=1284406847770, value=Test-String                     &lt;br/&gt;
1 row(s) in 0.3670 seconds&lt;/p&gt;</comment>
                            <comment id="12909003" author="hbasereviewboard" created="Mon, 13 Sep 2010 21:15:28 +0000"  >&lt;p&gt;Message from: bkm.hadoop@gmail.com&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/826/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/826/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for Hive Developers and John Sichi.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;This addresses &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1245&quot; title=&quot;allow access to values stored as non-strings in HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1245&quot;&gt;HIVE-1245&lt;/a&gt; in part, for atomic or primitive types.&lt;/p&gt;

&lt;p&gt;The serde property &quot;hbase.columns.storage.types&quot; = &quot;-,b,b,b,b,b,b,b,b&quot; is a specification of the storage option for the corresponding column in the serde property &quot;hbase.columns.mapping&quot;. Allowed values are &apos;&apos; for table default, &apos;s&apos; for standard string storage, and &apos;b&apos; for binary storage as would be obtained from o.a.h.hbase.utils.Bytes. Map types for HBase column families use a colon separated pair such as &apos;s:b&apos; for the key and value part specifiers respectively. See the test cases and queries for HBase handler for additional examples.&lt;/p&gt;

&lt;p&gt;There is also a table property &quot;hbase.table.default.storage.type&quot; = &quot;string&quot; to specify a table level default storage type. The other valid specification is &quot;binary&quot;. The table level default is overridden by a column level specification.&lt;/p&gt;

&lt;p&gt;This control is available for the boolean, tinyint, smallint, int, bigint, float, and double primitive types. The attached patch also relaxes the mapping of map types to HBase column families to allow any primitive type to be the map key.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1634&quot; title=&quot;Allow access to Primitive types stored in binary format in HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1634&quot;&gt;&lt;del&gt;HIVE-1634&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/HIVE-1634&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HIVE-1634&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDe.java 990439 &lt;br/&gt;
  trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/LazyHBaseCellMap.java 990439 &lt;br/&gt;
  trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/LazyHBaseRow.java 990439 &lt;br/&gt;
  trunk/hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestHBaseSerDe.java 990439 &lt;br/&gt;
  trunk/hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestLazyHBaseObject.java 990439 &lt;br/&gt;
  trunk/hbase-handler/src/test/queries/hbase_binary_map_queries.q PRE-CREATION &lt;br/&gt;
  trunk/hbase-handler/src/test/queries/hbase_binary_storage_queries.q PRE-CREATION &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyBooleanBinary.java PRE-CREATION &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyByteBinary.java PRE-CREATION &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyDoubleBinary.java PRE-CREATION &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java 990439 &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFloatBinary.java PRE-CREATION &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyIntegerBinary.java PRE-CREATION &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyLongBinary.java PRE-CREATION &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyShortBinary.java PRE-CREATION &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java 990439 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.cloudera.org/r/826/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/826/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;The HBase handler tests TestHBaseSerDe, TestLazyHBaseObject, TestHBaseCliDriver, and TestHBaseMinimrCliDriver pass.&lt;/p&gt;

&lt;p&gt;New tests have been added to TestHBaseSerDe and TestLazyHBaseObject to test this feature.&lt;/p&gt;

&lt;p&gt;New queries which exercise this feature have been added to query files hbase_binary_map_queries.q and hbase_binary_storage_queries.q.&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;bkm&lt;/p&gt;

</comment>
                            <comment id="12910305" author="jvs" created="Thu, 16 Sep 2010 20:40:10 +0000"  >&lt;p&gt;Hey Basab,&lt;/p&gt;

&lt;p&gt;This is a great start.  Beyond the review comments I added, I do have some higher-level suggestions:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;For the column mapping, the reason I suggested &quot;a:b:string&quot; in the original JIRA description is that it&apos;s a pain to keep everything lined up by column position.  It&apos;s already less than ideal that we do the column name mapping by position, so I don&apos;t think we should make it worse by having a separate property for type.  Using the s/b shorthand is fine, and if you think that we shouldn&apos;t overload the colon, we can use a different separator, e.g. &quot;cf:cq#s&quot;.  Since the existing property name is hbase.columns.mapping, I don&apos;t think it will be confusing to roll in the (optional) type info as well.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I&apos;m wondering whether we can just use the existing classes like LazyBinaryByte in package org.apache.hadoop.hive.serde2.lazybinary instead of creating new ones.  Or are these not compatible with hbase.utils.Bytes?&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;For the tests, I noticed that you have attached TestHiveHBaseExternalTable.  I think it would be a good idea if you can create and populate such a fixture table in HBaseTestSetup; that way it can be available (treated as read-only) to all of the HBase .q tests.  Otherwise, it&apos;s hard to verify that we&apos;re compatible with a table created directly through HBase API&apos;s rather than Hive.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Also for the tests, it would be good if you can filter it down to only a small number of representative rows when pulling the initial test data set from the Hive src table.  That way, we can keep the .q.out files smaller.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Once we get this one committed, be sure to update the wiki.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12910312" author="hbasereviewboard" created="Thu, 16 Sep 2010 20:46:13 +0000"  >&lt;p&gt;Message from: &quot;John Sichi&quot; &amp;lt;jsichi@facebook.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/826/#review1247&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/826/#review1247&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;



&lt;p&gt;trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDe.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/826/#comment4213&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/826/#comment4213&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    We keep adding new List data members.  Probably time to move to a single List&amp;lt;ColumnMapping&amp;gt;, with a new class ColumnMapping with fields for familyName, familyNameBytes, qualifierName, qualifierNameBytes, familyBinary, qualifierBinary.  That will be a lot cleaner and also allow you to avoid the boolean [] here, which is a little clumsy.&lt;/p&gt;



&lt;p&gt;trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDe.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/826/#comment4210&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/826/#comment4210&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Doesn&apos;t this error message need to change?&lt;/p&gt;



&lt;p&gt;trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDe.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/826/#comment4214&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/826/#comment4214&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    I don&apos;t understand these TODO&apos;s.&lt;/p&gt;



&lt;p&gt;trunk/hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestHBaseSerDe.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/826/#comment4215&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/826/#comment4215&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Why is this assertion commented out?&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;John&lt;/li&gt;
&lt;/ul&gt;



</comment>
                            <comment id="12923746" author="hbasereviewboard" created="Fri, 22 Oct 2010 03:12:05 +0000"  >&lt;p&gt;Message from: bkm.hadoop@gmail.com&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/826/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/826/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2010-10-21 20:11:06.837430)&lt;/p&gt;


&lt;p&gt;Review request for Hive Developers and John Sichi.&lt;/p&gt;


&lt;p&gt;Changes&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;The proposed serde property &quot;hbase.columns.storage.types&quot; = &quot;-,b,b,b,b,b,b,b,b&quot; as a specification of the storage option for the corresponding column in the serde property &quot;hbase.columns.mapping&quot; has been removed. Instead the storage option is an optional part of the &quot;hbase.columns.mapping&quot; and is specified for a column using &apos;#&apos; as a separator following the column family/qualifier. Allowed values are &apos;&apos; for table default, a prefix of &apos;string&apos; for standard string storage, and a prefix of &apos;binary&apos; for binary storage as would be obtained from o.a.h.hbase.utils.Bytes. Map types for HBase column families use a colon separated pair such as &apos;str:bin&apos; or &apos;s:b&apos; for the key and value part specifiers respectively.&lt;/p&gt;

&lt;p&gt;The tests TestHBaseSerDe, TestLazyHBaseObject, TestHBaseCliDriver, and TestHBaseMinimrCliDriver pass.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;This addresses &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1245&quot; title=&quot;allow access to values stored as non-strings in HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1245&quot;&gt;HIVE-1245&lt;/a&gt; in part, for atomic or primitive types.&lt;/p&gt;

&lt;p&gt;The serde property &quot;hbase.columns.storage.types&quot; = &quot;-,b,b,b,b,b,b,b,b&quot; is a specification of the storage option for the corresponding column in the serde property &quot;hbase.columns.mapping&quot;. Allowed values are &apos;&apos; for table default, &apos;s&apos; for standard string storage, and &apos;b&apos; for binary storage as would be obtained from o.a.h.hbase.utils.Bytes. Map types for HBase column families use a colon separated pair such as &apos;s:b&apos; for the key and value part specifiers respectively. See the test cases and queries for HBase handler for additional examples.&lt;/p&gt;

&lt;p&gt;There is also a table property &quot;hbase.table.default.storage.type&quot; = &quot;string&quot; to specify a table level default storage type. The other valid specification is &quot;binary&quot;. The table level default is overridden by a column level specification.&lt;/p&gt;

&lt;p&gt;This control is available for the boolean, tinyint, smallint, int, bigint, float, and double primitive types. The attached patch also relaxes the mapping of map types to HBase column families to allow any primitive type to be the map key.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1634&quot; title=&quot;Allow access to Primitive types stored in binary format in HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1634&quot;&gt;&lt;del&gt;HIVE-1634&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/HIVE-1634&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HIVE-1634&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDe.java 1023967 &lt;br/&gt;
  trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsAggregator.java 1023967 &lt;br/&gt;
  trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsPublisher.java 1023967 &lt;br/&gt;
  trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java 1023967 &lt;br/&gt;
  trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java 1023967 &lt;br/&gt;
  trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/LazyHBaseCellMap.java 1023967 &lt;br/&gt;
  trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/LazyHBaseRow.java 1023967 &lt;br/&gt;
  trunk/hbase-handler/src/test/org/apache/hadoop/hive/hbase/HBaseTestSetup.java 1023967 &lt;br/&gt;
  trunk/hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestHBaseSerDe.java 1023967 &lt;br/&gt;
  trunk/hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestLazyHBaseObject.java 1023967 &lt;br/&gt;
  trunk/hbase-handler/src/test/queries/hbase_binary_external_table_queries.q PRE-CREATION &lt;br/&gt;
  trunk/hbase-handler/src/test/queries/hbase_binary_map_queries.q PRE-CREATION &lt;br/&gt;
  trunk/hbase-handler/src/test/queries/hbase_binary_storage_queries.q PRE-CREATION &lt;br/&gt;
  trunk/hbase-handler/src/test/results/hbase_binary_external_table_queries.q.out PRE-CREATION &lt;br/&gt;
  trunk/hbase-handler/src/test/results/hbase_binary_map_queries.q.out PRE-CREATION &lt;br/&gt;
  trunk/hbase-handler/src/test/results/hbase_binary_storage_queries.q.out PRE-CREATION &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyBooleanBinary.java PRE-CREATION &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyByteBinary.java PRE-CREATION &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyDoubleBinary.java PRE-CREATION &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java 1023967 &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFloatBinary.java PRE-CREATION &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyIntegerBinary.java PRE-CREATION &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyLongBinary.java PRE-CREATION &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyShortBinary.java PRE-CREATION &lt;br/&gt;
  trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java 1023967 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.cloudera.org/r/826/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/826/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;The HBase handler tests TestHBaseSerDe, TestLazyHBaseObject, TestHBaseCliDriver, and TestHBaseMinimrCliDriver pass.&lt;/p&gt;

&lt;p&gt;New tests have been added to TestHBaseSerDe and TestLazyHBaseObject to test this feature.&lt;/p&gt;

&lt;p&gt;New queries which exercise this feature have been added to query files hbase_binary_map_queries.q and hbase_binary_storage_queries.q.&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;bkm&lt;/p&gt;

</comment>
                            <comment id="12923769" author="hbasereviewboard" created="Fri, 22 Oct 2010 06:08:11 +0000"  >&lt;p&gt;Message from: bkm.hadoop@gmail.com&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-09-16 13:28:48, John Sichi wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDe.java, line 499&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/826/diff/1/?file=11523#file11523line499&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/826/diff/1/?file=11523#file11523line499&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Doesn&apos;t this error message need to change?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Updated the comment to &quot;&apos; should be mapped to Map&amp;lt;? extends LazyPrimitive&amp;lt;?, ?&amp;gt;,?&amp;gt;, that is &quot; + &quot;the Key for the map should be of primitive type, but is ... &quot;&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-09-16 13:28:48, John Sichi wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDe.java, line 623&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/826/diff/1/?file=11523#file11523line623&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/826/diff/1/?file=11523#file11523line623&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     I don&apos;t understand these TODO&apos;s.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Removed/updated comment.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-09-16 13:28:48, John Sichi wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDe.java, line 76&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/826/diff/1/?file=11523#file11523line76&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/826/diff/1/?file=11523#file11523line76&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     We keep adding new List data members.  Probably time to move to a single List&amp;lt;ColumnMapping&amp;gt;, with a new class ColumnMapping with fields for familyName, familyNameBytes, qualifierName, qualifierNameBytes, familyBinary, qualifierBinary.  That will be a lot cleaner and also allow you to avoid the boolean [] here, which is a little clumsy.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I have changed the code to use List&amp;lt;ColumnMapping&amp;gt; with the fields of interest as members of this data class.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2010-09-16 13:28:48, John Sichi wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; trunk/hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestHBaseSerDe.java, line 480&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/826/diff/1/?file=11526#file11526line480&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/826/diff/1/?file=11526#file11526line480&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Why is this assertion commented out?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I have removed this test. We do have coverage from the .q files for this case. This was failing due to small differences in the byte arrays from DataOutputStream/DataInputStream vs o.a.h.hbase.utils.Bytes.&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;bkm&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/826/#review1247&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/826/#review1247&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


</comment>
                            <comment id="12923776" author="bkm" created="Fri, 22 Oct 2010 06:28:15 +0000"  >&lt;p&gt;Re: Beyond the review comments I added, I do have some higher-level suggestions:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;For the column mapping, the reason I suggested &quot;a:b:string&quot; in the original JIRA description is that it&apos;s a pain to keep everything lined up by column position. It&apos;s already less than ideal that we do the column name mapping by position, so I don&apos;t think we should make it worse by having a separate property for type. Using the s/b shorthand is fine, and if you think that we shouldn&apos;t overload the colon, we can use a different separator, e.g. &quot;cf:cq#s&quot;. Since the existing property name is hbase.columns.mapping, I don&apos;t think it will be confusing to roll in the (optional) type info as well.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I have adopted your suggestion of &apos;#&apos; as the separator to the storage information and use &apos;hbase.columns.mapping&apos; to carry the additional storage information optionally. I have made a small change to allow any prefix of &apos;string&apos; or of &apos;binary&apos; to be valid, i.e. s/b or str/bin or string/binary etc.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;I&apos;m wondering whether we can just use the existing classes like LazyBinaryByte in package org.apache.hadoop.hive.serde2.lazybinary instead of creating new ones. Or are these not compatible with hbase.utils.Bytes?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I think the incompatibility stems more from trying to stay within the serde2.lazy.Lazy family of objects which the HBaseSerDe, LazyHBaseRow, and LazyHBaseCellMap extend or depend on. It will be useful to have these two families of classes compatible (inherit from a common base class). Small differences in the object inspector classes which type parametrize these classes further complicates getting past the type system. Should be doable but perhaps as a separate patch?&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;For the tests, I noticed that you have attached TestHiveHBaseExternalTable. I think it would be a good idea if you can create and populate such a fixture table in HBaseTestSetup; that way it can be available (treated as read-only) to all of the HBase .q tests. Otherwise, it&apos;s hard to verify that we&apos;re compatible with a table created directly through HBase API&apos;s rather than Hive.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Done. Added tests to create a Hive external table associated with this HBase table and test queries.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Also for the tests, it would be good if you can filter it down to only a small number of representative rows when pulling the initial test data set from the Hive src table. That way, we can keep the .q.out files smaller.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Done, the .out files are a lot smaller than in the initial patch.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Once we get this one committed, be sure to update the wiki.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Will do once this is committed.&lt;/p&gt;</comment>
                            <comment id="12925915" author="jvs" created="Thu, 28 Oct 2010 19:05:28 +0000"  >&lt;p&gt;Thanks Basab, I&apos;m going to try to take a look at this one next week.&lt;/p&gt;</comment>
                            <comment id="12928334" author="jvs" created="Thu, 4 Nov 2010 20:29:54 +0000"  >&lt;p&gt;OK, I finally got some time to look into the Lazy* classes.  I see what you mean about the class hierarchy, and I agree that we can leave any refactoring of the existing classes for a followup patch.  Also, I was wrong to think that we could reuse the existing binary classes, since they do things such as VInt zero-compression, and that&apos;s incompatible with the HBase Bytes format.&lt;/p&gt;

&lt;p&gt;However, for this patch, I want to at least get the new classes into their final destination with respect to package name and class name (so that we don&apos;t have to move them later, even if we adjust their inheritance).  To this end, I suggest a new package serde2.lazydio, and name the classes on the pattern LazyDioInteger.  The &quot;Dio&quot; is to indicate DataInput/DataOutput format.  (I was thinking of lazybytes and LazyByteInteger, to indicate HBase Bytes format, but then I saw that Byte is also one of the datatypes, and LazyBytesByte would be puzzling.)&lt;/p&gt;

&lt;p&gt;Having both LazyIntegerBinary and LazyBinaryInteger, as in the current patch, would just be too confusing.&lt;/p&gt;

&lt;p&gt;Also, regarding the implementation of the new classes, most of the init method code is duplicated from class to class.  The only thing specific to each class is the actual read+set.  Should we factor out a LazyDioObject (similar to the existing pattern for LazyObject and LazyBinaryObject)?  Likewise for LazyDioPrimitive and LazyDioNonPrimitive.&lt;/p&gt;

&lt;p&gt;I will ask some others to chime in on this as well.&lt;/p&gt;</comment>
                            <comment id="12928356" author="jvs" created="Thu, 4 Nov 2010 21:06:50 +0000"  >&lt;p&gt;But looking into it further, is it true that the only difference in persistence format is for Long and Integer (due to the zero-compression)?  Or are any of the other formats different as well?  If it&apos;s only these, then adding a whole new set of classes seems like a bad idea, and we should instead do any necessary refactoring now to allow the existing binary classes to be used (and add a couple of new ones for uncompressed int/long).&lt;/p&gt;

&lt;p&gt;Considering the fact that we eventually want to be able to store map/struct/list as well (the rest of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1245&quot; title=&quot;allow access to values stored as non-strings in HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1245&quot;&gt;HIVE-1245&lt;/a&gt;), it&apos;s worth looking into the refactoring now, since the existing lazybinary covers those too (and we don&apos;t want to duplicate that).&lt;/p&gt;</comment>
                            <comment id="12977976" author="jvs" created="Wed, 5 Jan 2011 21:39:59 +0000"  >&lt;p&gt;Not sure what happened to the last patch I was reviewing, but here it is again.&lt;/p&gt;</comment>
                            <comment id="13190370" author="devthoughts.issues@gmail.com" created="Sat, 21 Jan 2012 11:17:21 +0000"  >&lt;p&gt;It&apos;s unclear from the last comment whether the issue is resolved or not.I tried with hive-hbase-handler-0.7.1.jar, but the issue still exists. Can you suggest work around for this.&lt;/p&gt;</comment>
                            <comment id="13191519" author="jvs" created="Mon, 23 Jan 2012 21:56:27 +0000"  >&lt;p&gt;This issue is not resolved; the patch has not been completed.&lt;/p&gt;</comment>
                            <comment id="13199273" author="phabricator@reviews.facebook.net" created="Thu, 2 Feb 2012 22:08:52 +0000"  >&lt;p&gt;ashutoshc requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1634&quot; title=&quot;Allow access to Primitive types stored in binary format in HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1634&quot;&gt;&lt;del&gt;HIVE-1634&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Allow access to Primitive types stored in binary format in HBase&quot;.&lt;br/&gt;
Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1634&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1634&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Rebased the patch to the trunk. This patch adds support binary storage support for HBase tables. What that means is if you have existing hbase tables (that is those not written through hive) you can use query them now using hbase-handler. Without this patch, you can only read hbase tables which were stored through hive.&lt;/p&gt;

&lt;p&gt;  Test Plan:&lt;br/&gt;
  3 new .q files&lt;br/&gt;
  hbase_binary_external_table_queries.q&lt;br/&gt;
  hbase_binary_map_queries.q&lt;br/&gt;
  hbase_binary_storage_queries.q&lt;br/&gt;
  which has new tests.&lt;/p&gt;

&lt;p&gt;  This addresses &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1245&quot; title=&quot;allow access to values stored as non-strings in HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1245&quot;&gt;HIVE-1245&lt;/a&gt; in part, for atomic or primitive types.&lt;/p&gt;

&lt;p&gt;  The serde property &quot;hbase.columns.storage.types&quot; = &quot;,b,b,b,b,b,b,b,b&quot; is a specification of the storage option for the corresponding column in the serde property &quot;hbase.columns.mapping&quot;. Allowed values are &apos;&apos; for table default, &apos;s&apos; for standard string storage, and &apos;b&apos; for binary storage as would be obtained from o.a.h.hbase.utils.Bytes. Map types for HBase column families use a colon separated pair such as &apos;s:b&apos; for the key and value part specifiers respectively. See the test cases and queries for HBase handler for additional examples.&lt;/p&gt;

&lt;p&gt;  There is also a table property &quot;hbase.table.default.storage.type&quot; = &quot;string&quot; to specify a table level default storage type. The other valid specification is &quot;binary&quot;. The table level default is overridden by a column level specification.&lt;/p&gt;

&lt;p&gt;  This control is available for the boolean, tinyint, smallint, int, bigint, float, and double primitive types. The attached patch also relaxes the mapping of map types to HBase column families to allow any primitive type to be the map key.&lt;/p&gt;

&lt;p&gt;  Attached is a program for creating a table and populating it in HBase. The external table in Hive can access the data as shown in the example below.&lt;/p&gt;

&lt;p&gt;  hive&amp;gt; create external table TestHiveHBaseExternalTable&lt;br/&gt;
      &amp;gt; (key string, c_bool boolean, c_byte tinyint, c_short smallint,&lt;br/&gt;
      &amp;gt;  c_int int, c_long bigint, c_string string, c_float float, c_double double)&lt;br/&gt;
      &amp;gt;  stored by &apos;org.apache.hadoop.hive.hbase.HBaseStorageHandler&apos;&lt;br/&gt;
      &amp;gt;  with serdeproperties (&quot;hbase.columns.mapping&quot; = &quot;:key,cf:boolean,cf:byte,cf:short,cf:int,cf:long,cf:string,cf:float,cf:double&quot;)&lt;br/&gt;
      &amp;gt;  tblproperties (&quot;hbase.table.name&quot; = &quot;TestHiveHBaseExternalTable&quot;);&lt;br/&gt;
  OK&lt;br/&gt;
  Time taken: 0.691 seconds&lt;br/&gt;
  hive&amp;gt; select * from TestHiveHBaseExternalTable;&lt;br/&gt;
  OK&lt;br/&gt;
  key-1	NULL	NULL	NULL	NULL	NULL	Test-String	NULL	NULL&lt;br/&gt;
  Time taken: 0.346 seconds&lt;br/&gt;
  hive&amp;gt; drop table TestHiveHBaseExternalTable;&lt;br/&gt;
  OK&lt;br/&gt;
  Time taken: 0.139 seconds&lt;br/&gt;
  hive&amp;gt; create external table TestHiveHBaseExternalTable&lt;br/&gt;
      &amp;gt; (key string, c_bool boolean, c_byte tinyint, c_short smallint,&lt;br/&gt;
      &amp;gt;  c_int int, c_long bigint, c_string string, c_float float, c_double double)&lt;br/&gt;
      &amp;gt;  stored by &apos;org.apache.hadoop.hive.hbase.HBaseStorageHandler&apos;&lt;br/&gt;
      &amp;gt;  with serdeproperties (&lt;br/&gt;
      &amp;gt;  &quot;hbase.columns.mapping&quot; = &quot;:key,cf:boolean,cf:byte,cf:short,cf:int,cf:long,cf:string,cf:float,cf:double&quot;,&lt;br/&gt;
      &amp;gt;  &quot;hbase.columns.storage.types&quot; = &quot;-,b,b,b,b,b,b,b,b&quot; )&lt;br/&gt;
      &amp;gt;  tblproperties (&lt;br/&gt;
      &amp;gt;  &quot;hbase.table.name&quot; = &quot;TestHiveHBaseExternalTable&quot;,&lt;br/&gt;
      &amp;gt;  &quot;hbase.table.default.storage.type&quot; = &quot;string&quot;);&lt;br/&gt;
  OK&lt;br/&gt;
  Time taken: 0.139 seconds&lt;br/&gt;
  hive&amp;gt; select * from TestHiveHBaseExternalTable;&lt;br/&gt;
  OK&lt;br/&gt;
  key-1	true	-128	-32768	-2147483648	-9223372036854775808	Test-String	-2.1793132E-11	2.01345E291&lt;br/&gt;
  Time taken: 0.151 seconds&lt;br/&gt;
  hive&amp;gt; drop table TestHiveHBaseExternalTable;&lt;br/&gt;
  OK&lt;br/&gt;
  Time taken: 0.154 seconds&lt;br/&gt;
  hive&amp;gt; create external table TestHiveHBaseExternalTable&lt;br/&gt;
      &amp;gt; (key string, c_bool boolean, c_byte tinyint, c_short smallint,&lt;br/&gt;
      &amp;gt;  c_int int, c_long bigint, c_string string, c_float float, c_double double)&lt;br/&gt;
      &amp;gt;  stored by &apos;org.apache.hadoop.hive.hbase.HBaseStorageHandler&apos;&lt;br/&gt;
      &amp;gt;  with serdeproperties (&lt;br/&gt;
      &amp;gt;  &quot;hbase.columns.mapping&quot; = &quot;:key,cf:boolean,cf:byte,cf:short,cf:int,cf:long,cf:string,cf:float,cf:double&quot;,&lt;br/&gt;
      &amp;gt;  &quot;hbase.columns.storage.types&quot; = &quot;,b,b,b,b,b,,b,b&quot; )&lt;br/&gt;
      &amp;gt;  tblproperties (&quot;hbase.table.name&quot; = &quot;TestHiveHBaseExternalTable&quot;);&lt;br/&gt;
  OK&lt;br/&gt;
  Time taken: 0.347 seconds&lt;br/&gt;
  hive&amp;gt; select * from TestHiveHBaseExternalTable;&lt;br/&gt;
  OK&lt;br/&gt;
  key-1	true	-128	-32768	-2147483648	-9223372036854775808	Test-String	-2.1793132E-11	2.01345E291&lt;br/&gt;
  Time taken: 0.245 seconds&lt;br/&gt;
  hive&amp;gt;&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1581&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1581&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  hbase-handler/src/test/results/hbase_binary_external_table_queries.q.out&lt;br/&gt;
  hbase-handler/src/test/results/hbase_binary_map_queries.q.out&lt;br/&gt;
  hbase-handler/src/test/results/hbase_binary_storage_queries.q.out&lt;br/&gt;
  hbase-handler/src/test/org/apache/hadoop/hive/hbase/HBaseTestSetup.java&lt;br/&gt;
  hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestHBaseSerDe.java&lt;br/&gt;
  hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestLazyHBaseObject.java&lt;br/&gt;
  hbase-handler/src/test/queries/hbase_binary_map_queries.q&lt;br/&gt;
  hbase-handler/src/test/queries/hbase_binary_storage_queries.q&lt;br/&gt;
  hbase-handler/src/test/queries/hbase_binary_external_table_queries.q&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsPublisher.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableOutputFormat.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/LazyHBaseCellMap.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsAggregator.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDe.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/LazyHBaseRow.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyIntegerBinary.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyShortBinary.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyLongBinary.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyByteBinary.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFloatBinary.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyDoubleBinary.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyBooleanBinary.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD DIFFERENTIAL RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/3321/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/3321/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Tip: use the X-Herald-Rules header to filter Herald messages in your client.&lt;/p&gt;</comment>
                            <comment id="13201931" author="ashutoshc" created="Tue, 7 Feb 2012 01:20:55 +0000"  >&lt;p&gt;This patch is ready for review.&lt;/p&gt;</comment>
                            <comment id="13201932" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 01:20:58 +0000"  >&lt;p&gt;ashutoshc updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1634&quot; title=&quot;Allow access to Primitive types stored in binary format in HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1634&quot;&gt;&lt;del&gt;HIVE-1634&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Allow access to Primitive types stored in binary format in HBase&quot;.&lt;br/&gt;
Reviewers: JIRA, jsichi&lt;/p&gt;

&lt;p&gt;  Fixed couple of bugs in testcases. Now all the tests pass.&lt;br/&gt;
  Refactored to move new introduced classes in their own package serde2.lazydio. Also named classes as LazyDioInteger and so on.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1581&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1581&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  hbase-handler/src/test/results/hbase_binary_external_table_queries.q.out&lt;br/&gt;
  hbase-handler/src/test/results/hbase_binary_map_queries.q.out&lt;br/&gt;
  hbase-handler/src/test/results/hbase_binary_storage_queries.q.out&lt;br/&gt;
  hbase-handler/src/test/org/apache/hadoop/hive/hbase/HBaseTestSetup.java&lt;br/&gt;
  hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestHBaseSerDe.java&lt;br/&gt;
  hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestLazyHBaseObject.java&lt;br/&gt;
  hbase-handler/src/test/queries/hbase_binary_map_queries.q&lt;br/&gt;
  hbase-handler/src/test/queries/hbase_binary_storage_queries.q&lt;br/&gt;
  hbase-handler/src/test/queries/hbase_binary_external_table_queries.q&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsPublisher.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableOutputFormat.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/LazyHBaseCellMap.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsAggregator.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDe.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/LazyHBaseRow.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyObject.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyPrimitive.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazydio&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioByte.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioFloat.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioDouble.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioInteger.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioBoolean.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioLong.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioShort.java&lt;/p&gt;</comment>
                            <comment id="13223674" author="phabricator@reviews.facebook.net" created="Tue, 6 Mar 2012 21:31:55 +0000"  >&lt;p&gt;cwsteinbach has accepted the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1634&quot; title=&quot;Allow access to Primitive types stored in binary format in HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1634&quot;&gt;&lt;del&gt;HIVE-1634&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Allow access to Primitive types stored in binary format in HBase&quot;.&lt;/p&gt;

&lt;p&gt;  Will commit if tests pass.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1581&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1581&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  svn&lt;/p&gt;</comment>
                            <comment id="13223679" author="phabricator@reviews.facebook.net" created="Tue, 6 Mar 2012 21:35:56 +0000"  >&lt;p&gt;cwsteinbach has requested changes to the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1634&quot; title=&quot;Allow access to Primitive types stored in binary format in HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1634&quot;&gt;&lt;del&gt;HIVE-1634&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Allow access to Primitive types stored in binary format in HBase&quot;.&lt;/p&gt;

&lt;p&gt;  Patch needs to be rebased against trunk.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1581&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1581&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  svn&lt;/p&gt;</comment>
                            <comment id="13223915" author="phabricator@reviews.facebook.net" created="Wed, 7 Mar 2012 02:21:56 +0000"  >&lt;p&gt;ashutoshc updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1634&quot; title=&quot;Allow access to Primitive types stored in binary format in HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1634&quot;&gt;&lt;del&gt;HIVE-1634&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Allow access to Primitive types stored in binary format in HBase&quot;.&lt;br/&gt;
Reviewers: JIRA, jsichi, cwsteinbach&lt;/p&gt;

&lt;p&gt;  Rebased to trunk.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D1581&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D1581&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  hbase-handler/src/test/results/hbase_binary_external_table_queries.q.out&lt;br/&gt;
  hbase-handler/src/test/results/hbase_binary_map_queries.q.out&lt;br/&gt;
  hbase-handler/src/test/results/hbase_binary_storage_queries.q.out&lt;br/&gt;
  hbase-handler/src/test/org/apache/hadoop/hive/hbase/HBaseTestSetup.java&lt;br/&gt;
  hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestHBaseSerDe.java&lt;br/&gt;
  hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestLazyHBaseObject.java&lt;br/&gt;
  hbase-handler/src/test/queries/hbase_binary_map_queries.q&lt;br/&gt;
  hbase-handler/src/test/queries/hbase_binary_storage_queries.q&lt;br/&gt;
  hbase-handler/src/test/queries/hbase_binary_external_table_queries.q&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsPublisher.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableOutputFormat.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/LazyHBaseCellMap.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsAggregator.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDe.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/LazyHBaseRow.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyObject.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyPrimitive.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazydio&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioByte.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioFloat.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioDouble.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioInteger.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioBoolean.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioLong.java&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioShort.java&lt;/p&gt;</comment>
                            <comment id="13223945" author="ashutoshc" created="Wed, 7 Mar 2012 03:46:32 +0000"  >&lt;p&gt;Patch with ASF perms.&lt;/p&gt;</comment>
                            <comment id="13223947" author="ashutoshc" created="Wed, 7 Mar 2012 03:47:39 +0000"  >&lt;p&gt;Patch Available&lt;/p&gt;</comment>
                            <comment id="13225064" author="ashutoshc" created="Thu, 8 Mar 2012 07:16:00 +0000"  >&lt;p&gt;All the tests passed with latest patch on latest trunk. &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;BUILD SUCCESSFUL
Total time: 323 minutes 29 seconds
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13225071" author="cwsteinbach" created="Thu, 8 Mar 2012 07:33:21 +0000"  >&lt;p&gt;+1.&lt;/p&gt;

&lt;p&gt;@Ashutosh: can you please commit this? Thanks.&lt;/p&gt;</comment>
                            <comment id="13225744" author="ashutoshc" created="Fri, 9 Mar 2012 00:50:32 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Carl for the review. &lt;/p&gt;

&lt;p&gt;Credit for this goes to Basab Maulik who did initial patch. I just rebased and took care of the comments by reviewers. Thanks, Basab!&lt;/p&gt;</comment>
                            <comment id="13225871" author="hudson" created="Fri, 9 Mar 2012 06:01:11 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1299 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1299/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1299/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1634&quot; title=&quot;Allow access to Primitive types stored in binary format in HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1634&quot;&gt;&lt;del&gt;HIVE-1634&lt;/del&gt;&lt;/a&gt;: Allow access to Primitive types stored in binary format in HBase (Basab Maulik, Ashutosh Chauhan via hashutosh) (Revision 1298673)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1298673&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1298673&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDe.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsAggregator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsPublisher.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableOutputFormat.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/LazyHBaseCellMap.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/LazyHBaseRow.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/org/apache/hadoop/hive/hbase/HBaseTestSetup.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestHBaseSerDe.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestLazyHBaseObject.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/queries/hbase_binary_external_table_queries.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/queries/hbase_binary_map_queries.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/queries/hbase_binary_storage_queries.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/results/hbase_binary_external_table_queries.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/results/hbase_binary_map_queries.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/results/hbase_binary_storage_queries.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyObject.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyPrimitive.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioBoolean.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioByte.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioDouble.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioFloat.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioInteger.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioLong.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioShort.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13230584" author="alangates" created="Thu, 15 Mar 2012 21:36:13 +0000"  >&lt;p&gt;Version of the patch that applies to branch 0.8 after applying &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2748&quot; title=&quot;Upgrade Hbase and ZK dependcies&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2748&quot;&gt;&lt;del&gt;HIVE-2748&lt;/del&gt;&lt;/a&gt; patch 3-1.&lt;/p&gt;</comment>
                            <comment id="13258036" author="hudson" created="Fri, 20 Apr 2012 06:00:14 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1384 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1384/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1384/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2958&quot; title=&quot;GROUP BY causing ClassCastException [LazyDioInteger cannot be cast LazyInteger]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2958&quot;&gt;&lt;del&gt;HIVE-2958&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; GROUP BY causing ClassCastException [LazyDioInteger cannot be&lt;br/&gt;
cast LazyInteger]&lt;br/&gt;
(Navis Ryu via Ashutosh Chauhan)&lt;/p&gt;

&lt;p&gt;Summary:&lt;br/&gt;
DPAL-1111 GROUP BY causing ClassCastException [LazyDioInteger cannot be cast&lt;br/&gt;
LazyInteger]&lt;/p&gt;

&lt;p&gt;This relates to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1634&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1634&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The following work fine:&lt;/p&gt;

&lt;p&gt;CREATE EXTERNAL TABLE tim_hbase_occurrence (&lt;br/&gt;
  id int,&lt;br/&gt;
  scientific_name string,&lt;br/&gt;
  data_resource_id int&lt;br/&gt;
) STORED BY &apos;org.apache.hadoop.hive.hbase.HBaseStorageHandler&apos; WITH&lt;br/&gt;
SERDEPROPERTIES (&lt;br/&gt;
  &quot;hbase.columns.mapping&quot; = &quot;:key#b,v:scientific_name#s,v:data_resource_id#b&quot;&lt;br/&gt;
) TBLPROPERTIES(&lt;br/&gt;
  &quot;hbase.table.name&quot; = &quot;mini_occurrences&quot;,&lt;br/&gt;
  &quot;hbase.table.default.storage.type&quot; = &quot;binary&quot;&lt;br/&gt;
);&lt;br/&gt;
SELECT * FROM tim_hbase_occurrence LIMIT 3;&lt;br/&gt;
SELECT * FROM tim_hbase_occurrence WHERE data_resource_id=1081 LIMIT 3;&lt;/p&gt;

&lt;p&gt;However, the following fails:&lt;/p&gt;

&lt;p&gt;SELECT data_resource_id, count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; FROM tim_hbase_occurrence GROUP BY&lt;br/&gt;
data_resource_id;&lt;/p&gt;

&lt;p&gt;The error given:&lt;/p&gt;

&lt;p&gt;0 TS&lt;br/&gt;
2012-04-17 16:58:45,693 INFO org.apache.hadoop.hive.ql.exec.MapOperator:&lt;br/&gt;
Initialization Done 7 MAP&lt;br/&gt;
2012-04-17 16:58:45,714 INFO org.apache.hadoop.hive.ql.exec.MapOperator:&lt;br/&gt;
Processing alias tim_hbase_occurrence for file&lt;br/&gt;
hdfs://c1n2.gbif.org/user/hive/warehouse/tim_hbase_occurrence&lt;br/&gt;
2012-04-17 16:58:45,714 INFO org.apache.hadoop.hive.ql.exec.MapOperator: 7&lt;br/&gt;
forwarding 1 rows&lt;br/&gt;
2012-04-17 16:58:45,714 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: 0&lt;br/&gt;
forwarding 1 rows&lt;br/&gt;
2012-04-17 16:58:45,716 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 1&lt;br/&gt;
forwarding 1 rows&lt;br/&gt;
2012-04-17 16:58:45,723 FATAL ExecMapper:&lt;br/&gt;
org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while&lt;br/&gt;
processing row &lt;/p&gt;
{&quot;id&quot;:1444,&quot;scientific_name&quot;:null,&quot;data_resource_id&quot;:1081}
&lt;p&gt;	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:548)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.ExecMapper.map(ExecMapper.java:143)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:391)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:325)&lt;br/&gt;
	at org.apache.hadoop.mapred.Child$4.run(Child.java:270)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:396)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1157)&lt;br/&gt;
	at org.apache.hadoop.mapred.Child.main(Child.java:264)&lt;br/&gt;
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException:&lt;br/&gt;
java.lang.ClassCastException:&lt;br/&gt;
org.apache.hadoop.hive.serde2.lazydio.LazyDioInteger cannot be cast to&lt;br/&gt;
org.apache.hadoop.hive.serde2.lazy.LazyInteger&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.ql.exec.GroupByOperator.processOp(GroupByOperator.java:737)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:471)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:762)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(SelectOperator.java:84)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:471)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:762)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:83)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:471)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:762)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:529)&lt;br/&gt;
	... 9 more&lt;br/&gt;
Caused by: java.lang.ClassCastException:&lt;br/&gt;
org.apache.hadoop.hive.serde2.lazydio.LazyDioInteger cannot be cast to&lt;br/&gt;
org.apache.hadoop.hive.serde2.lazy.LazyInteger&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyIntObjectInspector.copyObject(LazyIntObjectInspector.java:43)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.copyToStandardObject(ObjectInspectorUtils.java:239)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.ql.exec.KeyWrapperFactory$ListKeyWrapper.deepCopyElements(KeyWrapperFactory.java:150)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.ql.exec.KeyWrapperFactory$ListKeyWrapper.deepCopyElements(KeyWrapperFactory.java:142)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.ql.exec.KeyWrapperFactory$ListKeyWrapper.copyKey(KeyWrapperFactory.java:119)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.ql.exec.GroupByOperator.processHashAggr(GroupByOperator.java:750)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.ql.exec.GroupByOperator.processOp(GroupByOperator.java:722)&lt;br/&gt;
	... 18 more&lt;/p&gt;

&lt;p&gt;Test Plan: EMPTY&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA, ashutoshc&lt;/p&gt;

&lt;p&gt;Reviewed By: ashutoshc&lt;/p&gt;

&lt;p&gt;Differential Revision: &lt;a href=&quot;https://reviews.facebook.net/D2871&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D2871&lt;/a&gt; (Revision 1328157)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1328157&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1328157&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/queries/hbase_binary_external_table_queries.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/results/hbase_binary_external_table_queries.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioBoolean.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioByte.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioDouble.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioFloat.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioInteger.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioLong.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioShort.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13265305" author="ashutoshc" created="Mon, 30 Apr 2012 21:11:38 +0000"  >&lt;p&gt;This issue is closed now. It was released with the fix in 0.9.0. If there is a problem, please open a new jira and link this one with that.&lt;/p&gt;</comment>
                            <comment id="13547939" author="hudson" created="Wed, 9 Jan 2013 10:23:40 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #54 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2958&quot; title=&quot;GROUP BY causing ClassCastException [LazyDioInteger cannot be cast LazyInteger]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2958&quot;&gt;&lt;del&gt;HIVE-2958&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; GROUP BY causing ClassCastException [LazyDioInteger cannot be&lt;br/&gt;
cast LazyInteger]&lt;br/&gt;
(Navis Ryu via Ashutosh Chauhan)&lt;/p&gt;

&lt;p&gt;Summary:&lt;br/&gt;
DPAL-1111 GROUP BY causing ClassCastException [LazyDioInteger cannot be cast&lt;br/&gt;
LazyInteger]&lt;/p&gt;

&lt;p&gt;This relates to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1634&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1634&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The following work fine:&lt;/p&gt;

&lt;p&gt;CREATE EXTERNAL TABLE tim_hbase_occurrence (&lt;br/&gt;
  id int,&lt;br/&gt;
  scientific_name string,&lt;br/&gt;
  data_resource_id int&lt;br/&gt;
) STORED BY &apos;org.apache.hadoop.hive.hbase.HBaseStorageHandler&apos; WITH&lt;br/&gt;
SERDEPROPERTIES (&lt;br/&gt;
  &quot;hbase.columns.mapping&quot; = &quot;:key#b,v:scientific_name#s,v:data_resource_id#b&quot;&lt;br/&gt;
) TBLPROPERTIES(&lt;br/&gt;
  &quot;hbase.table.name&quot; = &quot;mini_occurrences&quot;,&lt;br/&gt;
  &quot;hbase.table.default.storage.type&quot; = &quot;binary&quot;&lt;br/&gt;
);&lt;br/&gt;
SELECT * FROM tim_hbase_occurrence LIMIT 3;&lt;br/&gt;
SELECT * FROM tim_hbase_occurrence WHERE data_resource_id=1081 LIMIT 3;&lt;/p&gt;

&lt;p&gt;However, the following fails:&lt;/p&gt;

&lt;p&gt;SELECT data_resource_id, count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; FROM tim_hbase_occurrence GROUP BY&lt;br/&gt;
data_resource_id;&lt;/p&gt;

&lt;p&gt;The error given:&lt;/p&gt;

&lt;p&gt;0 TS&lt;br/&gt;
2012-04-17 16:58:45,693 INFO org.apache.hadoop.hive.ql.exec.MapOperator:&lt;br/&gt;
Initialization Done 7 MAP&lt;br/&gt;
2012-04-17 16:58:45,714 INFO org.apache.hadoop.hive.ql.exec.MapOperator:&lt;br/&gt;
Processing alias tim_hbase_occurrence for file&lt;br/&gt;
hdfs://c1n2.gbif.org/user/hive/warehouse/tim_hbase_occurrence&lt;br/&gt;
2012-04-17 16:58:45,714 INFO org.apache.hadoop.hive.ql.exec.MapOperator: 7&lt;br/&gt;
forwarding 1 rows&lt;br/&gt;
2012-04-17 16:58:45,714 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: 0&lt;br/&gt;
forwarding 1 rows&lt;br/&gt;
2012-04-17 16:58:45,716 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 1&lt;br/&gt;
forwarding 1 rows&lt;br/&gt;
2012-04-17 16:58:45,723 FATAL ExecMapper:&lt;br/&gt;
org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while&lt;br/&gt;
processing row &lt;/p&gt;
{&quot;id&quot;:1444,&quot;scientific_name&quot;:null,&quot;data_resource_id&quot;:1081}
&lt;p&gt;	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:548)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.ExecMapper.map(ExecMapper.java:143)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:391)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:325)&lt;br/&gt;
	at org.apache.hadoop.mapred.Child$4.run(Child.java:270)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:396)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1157)&lt;br/&gt;
	at org.apache.hadoop.mapred.Child.main(Child.java:264)&lt;br/&gt;
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException:&lt;br/&gt;
java.lang.ClassCastException:&lt;br/&gt;
org.apache.hadoop.hive.serde2.lazydio.LazyDioInteger cannot be cast to&lt;br/&gt;
org.apache.hadoop.hive.serde2.lazy.LazyInteger&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.ql.exec.GroupByOperator.processOp(GroupByOperator.java:737)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:471)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:762)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(SelectOperator.java:84)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:471)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:762)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:83)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:471)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:762)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:529)&lt;br/&gt;
	... 9 more&lt;br/&gt;
Caused by: java.lang.ClassCastException:&lt;br/&gt;
org.apache.hadoop.hive.serde2.lazydio.LazyDioInteger cannot be cast to&lt;br/&gt;
org.apache.hadoop.hive.serde2.lazy.LazyInteger&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyIntObjectInspector.copyObject(LazyIntObjectInspector.java:43)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.copyToStandardObject(ObjectInspectorUtils.java:239)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.ql.exec.KeyWrapperFactory$ListKeyWrapper.deepCopyElements(KeyWrapperFactory.java:150)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.ql.exec.KeyWrapperFactory$ListKeyWrapper.deepCopyElements(KeyWrapperFactory.java:142)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.ql.exec.KeyWrapperFactory$ListKeyWrapper.copyKey(KeyWrapperFactory.java:119)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.ql.exec.GroupByOperator.processHashAggr(GroupByOperator.java:750)&lt;br/&gt;
	at&lt;br/&gt;
org.apache.hadoop.hive.ql.exec.GroupByOperator.processOp(GroupByOperator.java:722)&lt;br/&gt;
	... 18 more&lt;/p&gt;

&lt;p&gt;Test Plan: EMPTY&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA, ashutoshc&lt;/p&gt;

&lt;p&gt;Reviewed By: ashutoshc&lt;/p&gt;

&lt;p&gt;Differential Revision: &lt;a href=&quot;https://reviews.facebook.net/D2871&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D2871&lt;/a&gt; (Revision 1328157)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1634&quot; title=&quot;Allow access to Primitive types stored in binary format in HBase&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1634&quot;&gt;&lt;del&gt;HIVE-1634&lt;/del&gt;&lt;/a&gt;: Allow access to Primitive types stored in binary format in HBase (Basab Maulik, Ashutosh Chauhan via hashutosh) (Revision 1298673)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1328157&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1328157&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/queries/hbase_binary_external_table_queries.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/results/hbase_binary_external_table_queries.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioBoolean.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioByte.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioDouble.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioFloat.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioInteger.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioLong.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioShort.java&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1298673&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1298673&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDe.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsAggregator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsPublisher.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableOutputFormat.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/LazyHBaseCellMap.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/LazyHBaseRow.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/org/apache/hadoop/hive/hbase/HBaseTestSetup.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestHBaseSerDe.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/org/apache/hadoop/hive/hbase/TestLazyHBaseObject.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/queries/hbase_binary_external_table_queries.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/queries/hbase_binary_map_queries.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/queries/hbase_binary_storage_queries.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/results/hbase_binary_external_table_queries.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/results/hbase_binary_map_queries.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/results/hbase_binary_storage_queries.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyObject.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyPrimitive.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioBoolean.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioByte.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioDouble.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioFloat.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioInteger.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioLong.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazydio/LazyDioShort.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13876870" author="vkorukanti" created="Mon, 20 Jan 2014 21:33:46 +0000"  >&lt;p&gt;From the description it looks like binary storage support is only for few primitive types.&lt;br/&gt;
Quoting from description: &quot;This control is available for the boolean, tinyint, smallint, int, bigint, float, and double primitive types&quot;&lt;/p&gt;

&lt;p&gt;Is there any JIRA or requirement to support the rest of primitive types (like binary, timestamp, decimal) in binary storage format?&lt;/p&gt;</comment>
                            <comment id="13876889" author="ashutoshc" created="Mon, 20 Jan 2014 21:54:49 +0000"  >&lt;p&gt;I don&apos;t think there is any jira for new types or complex types. At the time, this work was done only those primitive types were supported in Hive.&lt;br/&gt;
Although, any new work in this direction should take into account addition of type support work in Hbase. cc: &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ndimiduk&quot; class=&quot;user-hover&quot; rel=&quot;ndimiduk&quot;&gt;Nick Dimiduk&lt;/a&gt; who is leading the effort in hbase land.&lt;/p&gt;</comment>
                            <comment id="13877027" author="ndimiduk" created="Tue, 21 Jan 2014 00:29:58 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vkorukanti&quot; class=&quot;user-hover&quot; rel=&quot;vkorukanti&quot;&gt;Venki Korukanti&lt;/a&gt;. The parent ticket for HBase types is &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8089&quot; title=&quot;Add type support&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8089&quot;&gt;HBASE-8089&lt;/a&gt;. The groundwork has been laid on the HBase side by way of a &lt;tt&gt;DataType&lt;/tt&gt; API and an order-preserving serialization format. The next step, as I see it, would be to implement &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10091&quot; title=&quot;Exposing HBase DataTypes to non-Java interfaces&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10091&quot;&gt;HBASE-10091&lt;/a&gt;, that way there&apos;s a common description language that can be used to declare HBase types. I&apos;d love your thoughts on that topic if you have some moments to spare.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12543736">HIVE-2815</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12459221">HIVE-1245</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12513042" name="ASF.LICENSE.NOT.GRANTED--HIVE-1634.D1581.1.patch" size="249111" author="phabricator@reviews.facebook.net" created="Thu, 2 Feb 2012 22:08:53 +0000"/>
                            <attachment id="12513545" name="ASF.LICENSE.NOT.GRANTED--HIVE-1634.D1581.2.patch" size="252762" author="phabricator@reviews.facebook.net" created="Tue, 7 Feb 2012 01:21:05 +0000"/>
                            <attachment id="12517355" name="ASF.LICENSE.NOT.GRANTED--HIVE-1634.D1581.3.patch" size="251597" author="phabricator@reviews.facebook.net" created="Wed, 7 Mar 2012 02:21:57 +0000"/>
                            <attachment id="12454484" name="HIVE-1634.0.patch" size="574865" author="bkm" created="Mon, 13 Sep 2010 20:35:14 +0000"/>
                            <attachment id="12467588" name="HIVE-1634.1.patch" size="254675" author="jvs" created="Wed, 5 Jan 2011 21:39:59 +0000"/>
                            <attachment id="12518546" name="HIVE-1634.branch08.patch" size="252422" author="alangates" created="Thu, 15 Mar 2012 21:36:13 +0000"/>
                            <attachment id="12454483" name="TestHiveHBaseExternalTable.java" size="1793" author="bkm" created="Mon, 13 Sep 2010 20:35:14 +0000"/>
                            <attachment id="12517360" name="hive-1634_3.patch" size="252917" author="ashutoshc" created="Wed, 7 Mar 2012 03:46:31 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 13 Sep 2010 21:15:28 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42414</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 1 week ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i09yqv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>56070</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1635] ability to check partition size for dynamic partiions</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1635</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;With dynamic partitions, it becomes very easy to create partitions.&lt;/p&gt;

&lt;p&gt;We have seen some scenarios, where a lot of partitions/files get created due to some corrupt data (1 corrupt row&lt;br/&gt;
can end up creating a partition and a lot of files (number of mappers, if merge is false)).&lt;/p&gt;

&lt;p&gt;This puts a lot of load on the cluster, and is a debugging nightmare.&lt;/p&gt;

&lt;p&gt;It would be good to have a configuration parameter, for the minimum number of rows for a partition.&lt;br/&gt;
If the number of rows is less than the threshold, the partition need not be created. The default value&lt;br/&gt;
of this parameter can be zero for backward compatibility&lt;/p&gt;</description>
                <environment></environment>
        <key id="12474104">HIVE-1635</key>
            <summary>ability to check partition size for dynamic partiions</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="nzhang">Ning Zhang</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Tue, 14 Sep 2010 18:40:37 +0000</created>
                <updated>Mon, 14 Feb 2011 21:02:07 +0000</updated>
                                                                            <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42413</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 19 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lg3z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123260</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>
