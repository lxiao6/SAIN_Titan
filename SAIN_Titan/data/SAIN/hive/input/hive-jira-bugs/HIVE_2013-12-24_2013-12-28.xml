<!--
RSS generated by JIRA (7.6.3#76005-sha1:8a4e38d34af948780dbf52044e7aafb13a7cae58) at Tue Jan 22 03:26:09 UTC 2019

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<!-- If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
    <channel>
        <title>ASF JIRA</title>
        <link>https://issues.apache.org/jira/issues/?jql=project+%3D+HIVE+AND+created+%3E%3D+2013-12-24+AND+created+%3C%3D+2013-12-28+ORDER+BY+key+ASC</link>
        <description>An XML representation of a search request</description>
                <language>en-uk</language>
                        <issue start="0" end="15" total="15"/>
                <build-info>
            <version>7.6.3</version>
            <build-number>76005</build-number>
            <build-date>09-01-2018</build-date>
        </build-info>

<item>
            <title>[HIVE-6104] Join-key logging in join operator</title>
                <link>https://issues.apache.org/jira/browse/HIVE-6104</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;JoinOperator.processOp logs lines like &quot;table 0 has x rows for join key [foo]&quot;. It is supposed to log after x rows for x = i, 2i, 4i, .... However, it has never worked completely:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;In 0.11.0 and before, it logs after i rows and not after &amp;gt;i rows, because nextSz is not properly updated.&lt;/li&gt;
	&lt;li&gt;In 0.12.0, &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4960&quot; title=&quot;lastAlias in CommonJoinOperator is not used&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4960&quot;&gt;&lt;del&gt;HIVE-4960&lt;/del&gt;&lt;/a&gt; partially fixed that but x fails to be reset when the alias (tag) changes.&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
        <key id="12686249">HIVE-6104</key>
            <summary>Join-key logging in join operator</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="slider">Steven K. Wong</assignee>
                                    <reporter username="slider">Steven K. Wong</reporter>
                        <labels>
                    </labels>
                <created>Tue, 24 Dec 2013 03:24:16 +0000</created>
                <updated>Thu, 30 Jan 2014 22:46:49 +0000</updated>
                            <resolved>Thu, 30 Jan 2014 22:43:34 +0000</resolved>
                                    <version>0.11.0</version>
                    <version>0.12.0</version>
                    <version>0.13.0</version>
                                    <fixVersion>0.13.0</fixVersion>
                                    <component>Diagnosability</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13856129" author="hiveqa" created="Tue, 24 Dec 2013 04:33:49 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12620298/HIVE-6104.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12620298/HIVE-6104.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 4811 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_bucket_num_reducers
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/737/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/737/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/737/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/737/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12620298&lt;/p&gt;</comment>
                            <comment id="13856171" author="slider" created="Tue, 24 Dec 2013 06:01:41 +0000"  >&lt;p&gt;I don&apos;t think the above test failure is related, because the test passed on my computer.&lt;/p&gt;</comment>
                            <comment id="13870098" author="ehans" created="Mon, 13 Jan 2014 23:04:20 +0000"  >&lt;p&gt;Even though it is short, if you put the patch on Review Board that&apos;ll make it easier to review.&lt;/p&gt;</comment>
                            <comment id="13870145" author="slider" created="Mon, 13 Jan 2014 23:54:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/16836/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/16836/&lt;/a&gt; (my bad for not having this sooner)&lt;/p&gt;</comment>
                            <comment id="13886996" author="slider" created="Thu, 30 Jan 2014 19:57:43 +0000"  >&lt;p&gt;Can someone please review and commit this bug fix? If I am not following the proper procedure, do let me know, don&apos;t ignore the jira. Thanks.&lt;/p&gt;</comment>
                            <comment id="13887106" author="vikram.dixit" created="Thu, 30 Jan 2014 21:44:08 +0000"  >&lt;p&gt;Hi Steven,&lt;/p&gt;

&lt;p&gt;I found your emails in my spam folder for some reason. Probably the reason for most people missing this. I will take a look.&lt;/p&gt;

&lt;p&gt;Regards&lt;br/&gt;
Vikram.&lt;/p&gt;</comment>
                            <comment id="13887144" author="vikram.dixit" created="Thu, 30 Jan 2014 22:00:11 +0000"  >&lt;p&gt;LGTM +1. I will commit this shortly.&lt;/p&gt;</comment>
                            <comment id="13887201" author="vikram.dixit" created="Thu, 30 Jan 2014 22:43:34 +0000"  >&lt;p&gt;Committed to trunk. Thanks Steven!&lt;/p&gt;</comment>
                            <comment id="13887208" author="slider" created="Thu, 30 Jan 2014 22:46:49 +0000"  >&lt;p&gt;Thanks, Vikram!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12620298" name="HIVE-6104.patch" size="1499" author="slider" created="Tue, 24 Dec 2013 03:28:22 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 24 Dec 2013 04:33:49 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365222</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 51 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1qy9z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365527</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-6105] LongWritable.compareTo needs shimming</title>
                <link>https://issues.apache.org/jira/browse/HIVE-6105</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Compiled hive against hadoop-2. Running tests on hadoop 1 gives:&lt;/p&gt;

&lt;p&gt;Caused by: java.lang.NoSuchMethodError: org.apache.hadoop.io.LongWritable.compareTo(Lorg/apache/hadoop/io/LongWritable;)I&lt;br/&gt;
	at org.apache.hadoop.hive.ql.udf.UDAFPercentile$MyComparator.compare(UDAFPercentile.java:62)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.udf.UDAFPercentile$MyComparator.compare(UDAFPercentile.java:58)&lt;br/&gt;
	at java.util.Arrays.mergeSort(Arrays.java:1270)&lt;br/&gt;
	at java.util.Arrays.sort(Arrays.java:1210)&lt;br/&gt;
	at java.util.Collections.sort(Collections.java:157)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.udf.UDAFPercentile$PercentileLongEvaluator.terminate(UDAFPercentile.java:194)&lt;br/&gt;
	... 20 more&lt;/p&gt;

&lt;p&gt;I think the problem is that the compareTo function has changed from using Object to using LongWritable as an argument. Seems this needs a shim. However, we should also make sure that this shim doesn&apos;t hit performance too hard.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12686366">HIVE-6105</key>
            <summary>LongWritable.compareTo needs shimming</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis</assignee>
                                    <reporter username="hagleitn">Gunther Hagleitner</reporter>
                        <labels>
                    </labels>
                <created>Wed, 25 Dec 2013 19:10:06 +0000</created>
                <updated>Mon, 20 Jan 2014 22:44:45 +0000</updated>
                            <resolved>Tue, 7 Jan 2014 18:44:37 +0000</resolved>
                                    <version>0.12.0</version>
                                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13860494" author="hagleitn" created="Thu, 2 Jan 2014 18:18:50 +0000"  >&lt;p&gt;LGTM +1, will commit once tests have run.&lt;/p&gt;</comment>
                            <comment id="13861198" author="hiveqa" created="Fri, 3 Jan 2014 04:36:49 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12621031/HIVE-6105.1.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12621031/HIVE-6105.1.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 4874 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_disable_merge_for_bucketing
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/786/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/786/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/786/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/786/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12621031&lt;/p&gt;</comment>
                            <comment id="13862708" author="navis" created="Mon, 6 Jan 2014 01:22:43 +0000"  >&lt;p&gt;Cannot reproduce the failure. Rerunning test.&lt;/p&gt;</comment>
                            <comment id="13862770" author="hagleitn" created="Mon, 6 Jan 2014 05:11:17 +0000"  >&lt;p&gt;Cannot reproduce either. Probably a fluke. Let&apos;s see what the new run brings.&lt;/p&gt;</comment>
                            <comment id="13863709" author="hagleitn" created="Tue, 7 Jan 2014 00:35:35 +0000"  >&lt;p&gt;Don&apos;t see it in the q. Reuploading...&lt;/p&gt;</comment>
                            <comment id="13864127" author="hiveqa" created="Tue, 7 Jan 2014 11:37:19 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12621723/HIVE-6105.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12621723/HIVE-6105.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4881 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/819/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/819/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/819/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/819/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12621723&lt;/p&gt;</comment>
                            <comment id="13864523" author="hagleitn" created="Tue, 7 Jan 2014 18:44:37 +0000"  >&lt;p&gt;Committed to trunk. Thanks Navis!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                            <outwardlinks description="breaks">
                                        <issuelink>
            <issuekey id="12689898">HIVE-6238</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12621723" name="HIVE-6105.1.patch" size="7944" author="hagleitn" created="Tue, 7 Jan 2014 00:35:35 +0000"/>
                            <attachment id="12621031" name="HIVE-6105.1.patch.txt" size="7944" author="navis" created="Thu, 2 Jan 2014 04:52:55 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 3 Jan 2014 04:36:49 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365351</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 2 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1qz1z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365653</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-6106] update golden files for tez</title>
                <link>https://issues.apache.org/jira/browse/HIVE-6106</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;there&apos;s two cases where we need update:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;the stage id is one off in one file. this isn&apos;t a functional problem.&lt;/li&gt;
	&lt;li&gt;in vectorization we codified a wrong result in a couple golden files&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
        <key id="12686370">HIVE-6106</key>
            <summary>update golden files for tez</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hagleitn">Gunther Hagleitner</assignee>
                                    <reporter username="hagleitn">Gunther Hagleitner</reporter>
                        <labels>
                    </labels>
                <created>Wed, 25 Dec 2013 22:43:29 +0000</created>
                <updated>Tue, 7 Jan 2014 18:46:23 +0000</updated>
                            <resolved>Tue, 7 Jan 2014 18:46:23 +0000</resolved>
                                                    <fixVersion>tez-branch</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13864526" author="hagleitn" created="Tue, 7 Jan 2014 18:46:23 +0000"  >&lt;p&gt;Committed to branch.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12651047">HIVE-4660</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12620450" name="HIVE-6106.1.patch" size="18475" author="hagleitn" created="Wed, 25 Dec 2013 22:49:15 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365355</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 2 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1qz2v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365657</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-6107] Introduce nvl2 UDF similar to Oracle</title>
                <link>https://issues.apache.org/jira/browse/HIVE-6107</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Introduce new UDF:&lt;br/&gt;
nvl2 : extends the functionality found in the NVL function. It lets you substitutes a value when a null value is encountered as well as when a non-null value is encountered.&lt;br/&gt;
NVL2( string1, value_if_NOT_null, value_if_null )&lt;/p&gt;</description>
                <environment></environment>
        <key id="12686403">HIVE-6107</key>
            <summary>Introduce nvl2 UDF similar to Oracle</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png" description="A patch for this issue has been uploaded to JIRA by a contributor.">Patch Available</status>
                    <statusCategory id="4" key="indeterminate" colorName="yellow"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="kostiantyn">Kostiantyn Kudriavtsev</reporter>
                        <labels>
                    </labels>
                <created>Thu, 26 Dec 2013 11:42:00 +0000</created>
                <updated>Fri, 27 Dec 2013 22:21:38 +0000</updated>
                                                                            <component>UDF</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13857724" author="brocknoland" created="Fri, 27 Dec 2013 20:56:30 +0000"  >&lt;p&gt;Considering the on-going patent discussions with teradata I think we should do or due diligence on this one before adding it.&lt;/p&gt;</comment>
                            <comment id="13857753" author="kostiantyn" created="Fri, 27 Dec 2013 21:29:56 +0000"  >&lt;p&gt;Brock, thank you for your comment! Do you mean Teradata has patent on nvl2 or this API? For sure, in this case adding process must be postponed &lt;/p&gt;</comment>
                            <comment id="13857760" author="brocknoland" created="Fri, 27 Dec 2013 21:38:06 +0000"  >&lt;p&gt;No, another UDF. See: &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5087?focusedCommentId=13749807&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13749807&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-5087?focusedCommentId=13749807&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13749807&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13857769" author="kostiantyn" created="Fri, 27 Dec 2013 21:45:21 +0000"  >&lt;p&gt;do you mean it can cause lawsuit against nvl2 name? In this case UDF can be simple rename to CheckIfNull&lt;/p&gt;</comment>
                            <comment id="13857789" author="brocknoland" created="Fri, 27 Dec 2013 22:00:27 +0000"  >&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;Sorry, I should have been more clear. The comment I left was meant for other Hive committers. Long story short there is a lot of context regarding teradata + the other UDF that is not public. &lt;/p&gt;

&lt;p&gt;Therefore when implementing UDFs based on a commercial system like Oracle, we should do some work to ensure the udf name and functionality are not Oracle IP before committing this change.&lt;/p&gt;</comment>
                            <comment id="13857795" author="hiveqa" created="Fri, 27 Dec 2013 22:21:38 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12620644/hive-6107.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12620644/hive-6107.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/757/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/757/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/757/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/757/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-757/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;hcatalog/core/src/test/java/org/apache/hcatalog/mapreduce/TestHCatMultiOutputFormat.java&apos;
Reverted &apos;hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/TestHCatMultiOutputFormat.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/optimizer/SimpleFetchOptimizer.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/SortMergeJoinTaskDispatcher.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/GenMRSkewJoinProcessor.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/plan/FetchWork.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/plan/LoadDesc.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/MapReduceCompiler.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/session/LineageState.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java&apos;
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20/target shims/0.20S/target shims/0.23/target shims/aggregator/target shims/common/target shims/common-secure/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit/target itests/custom-serde/target itests/util/target hcatalog/target hcatalog/storage-handlers/hbase/target hcatalog/server-extensions/target hcatalog/core/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target hcatalog/hcatalog-pig-adapter/target hwi/target common/target common/src/gen contrib/target service/target serde/target beeline/target odbc/target cli/target ql/dependency-reduced-pom.xml ql/target
+ svn update
U    hcatalog/src/test/e2e/templeton/tests/ddl.conf
U    hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HcatDelegator.java

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
Updated external to revision 1553753.

Updated to revision 1553753.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12620644&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12620644" name="hive-6107.patch" size="18076" author="kostiantyn" created="Fri, 27 Dec 2013 20:15:27 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 27 Dec 2013 20:56:30 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365391</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 4 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1qzav:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365693</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-6108] Introduce Cryptographic hash UDFs</title>
                <link>https://issues.apache.org/jira/browse/HIVE-6108</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Introduce new UDF to implement Cryptographic hash algorithms: MD5 and SHA-256 which is already available in Java:&lt;/p&gt;

&lt;p&gt;MD5(string) Calculates an MD5 checksum for the string, return HEX representation&lt;br/&gt;
SHA256(string) Calculates an SHA-256 checksum for the string, return HEX representation&lt;/p&gt;</description>
                <environment></environment>
        <key id="12686405">HIVE-6108</key>
            <summary>Introduce Cryptographic hash UDFs</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="kostiantyn">Kostiantyn Kudriavtsev</assignee>
                                    <reporter username="kostiantyn">Kostiantyn Kudriavtsev</reporter>
                        <labels>
                    </labels>
                <created>Thu, 26 Dec 2013 12:15:01 +0000</created>
                <updated>Thu, 9 Apr 2015 16:22:15 +0000</updated>
                                                                            <component>UDF</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13902495" author="kostiantyn" created="Sat, 15 Feb 2014 19:20:01 +0000"  >&lt;p&gt;This functionality must be very useful to hide PII data from inappropriate access. For example, for creation a view for untrusted employee or so on &lt;/p&gt;</comment>
                            <comment id="13904603" author="hiveqa" created="Tue, 18 Feb 2014 21:11:40 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12629234/Hive-6108.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12629234/Hive-6108.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 5140 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_show_functions
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_bucketizedhiveinputformat
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1388/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1388/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1388/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1388/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12629234&lt;/p&gt;</comment>
                            <comment id="14487603" author="alangates" created="Thu, 9 Apr 2015 16:22:04 +0000"  >&lt;p&gt;Ok, so this review is way overdue, but better late than never&lt;/p&gt;

&lt;p&gt;A few issues&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;You should consider using GenericUDF rather than UDF, see the comments in those classes on why.&lt;/li&gt;
	&lt;li&gt;When errors are encountered in the code it should write to the log rather than System.out.  See many places in the Hive code for examples.&lt;/li&gt;
	&lt;li&gt;We cannot have any System.exit calls in the code.  Some of this code runs in servers that cannot exit.  Exceptions should be thrown instead.&lt;/li&gt;
&lt;/ol&gt;

</comment>
                    </comments>
                    <attachments>
                            <attachment id="12629234" name="Hive-6108.patch" size="11173" author="kostiantyn" created="Sat, 15 Feb 2014 20:29:46 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 18 Feb 2014 21:11:40 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365394</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 41 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1qzbj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365696</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-6109] Support customized location for EXTERNAL tables created by Dynamic Partitioning</title>
                <link>https://issues.apache.org/jira/browse/HIVE-6109</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently when dynamic partitions are created by HCatalog, the underlying directories for the partitions are created in a fixed &apos;Hive-style&apos; format, i.e. root_dir/key1=value1/key2=value2/.... and so on. However in case of external table, user should be able to control the format of directories created for dynamic partitions.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12686412">HIVE-6109</key>
            <summary>Support customized location for EXTERNAL tables created by Dynamic Partitioning</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="satish.mittal">Satish Mittal</assignee>
                                    <reporter username="satish.mittal">Satish Mittal</reporter>
                        <labels>
                    </labels>
                <created>Thu, 26 Dec 2013 12:58:25 +0000</created>
                <updated>Mon, 15 Sep 2014 07:35:48 +0000</updated>
                            <resolved>Thu, 13 Feb 2014 19:02:37 +0000</resolved>
                                                    <fixVersion>0.13.0</fixVersion>
                                    <component>HCatalog</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                <comments>
                            <comment id="13856862" author="satish.mittal" created="Thu, 26 Dec 2013 13:08:39 +0000"  >&lt;p&gt;As an example, suppose a table user_logs is partitioned by (year, month, day, hour, minute, country) and stored at location &quot;hdfs://hcat/data/user_logs&quot;. &lt;/p&gt;

&lt;p&gt;Currently dynamic partitions for user_logs would get created at HDFS locations in the fixed format &quot;hdfs://hcat/data/user_logs/year=2013/month=12/hour=06/minute=10/country=US&quot;. However in our use-case this breaks other data pipeline applications which expect the data to arrive in a different format: &quot;hdfs://hcat/data/user_logs/2013/12/06/10/US&quot;. There could be similar other use-cases possible.&lt;/p&gt;</comment>
                            <comment id="13857216" author="lefty@hortonworks.com" created="Fri, 27 Dec 2013 00:53:04 +0000"  >&lt;p&gt;I updated HCatalog&apos;s wikidoc &quot;Dynamic Partitioning&quot; with information about this ticket, and elaborated on the information about &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5011&quot; title=&quot;Dynamic partitioning in HCatalog broken on external tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5011&quot;&gt;&lt;del&gt;HIVE-5011&lt;/del&gt;&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/HCatalog+DynamicPartitions#HCatalogDynamicPartitions-ExternalTables&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;External Tables&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Corrections &amp;amp; improvements are welcomed.&lt;/p&gt;</comment>
                            <comment id="13868665" author="satish.mittal" created="Sat, 11 Jan 2014 05:34:38 +0000"  >&lt;p&gt;Working on this issue. Can someone please assign it to me?&lt;/p&gt;</comment>
                            <comment id="13869440" author="satish.mittal" created="Mon, 13 Jan 2014 11:58:29 +0000"  >&lt;p&gt;Attaching the patch that implements the functionality to support custom location for external tables in dynamic partitioning.&lt;/p&gt;</comment>
                            <comment id="13869654" author="hiveqa" created="Mon, 13 Jan 2014 16:12:29 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12622613/HIVE-6109.1.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12622613/HIVE-6109.1.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/884/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/884/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/884/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/884/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-contrib ---
[INFO] Compiling 39 source files to /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/java/org/apache/hadoop/hive/contrib/udf/example/UDFExampleStructPrint.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-contrib ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-contrib ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp/conf
     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-contrib ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/test-classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/org/apache/hadoop/hive/contrib/serde2/TestRegexSerDe.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-contrib ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-contrib ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/hive-contrib-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-contrib ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/hive-contrib-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-contrib/0.13.0-SNAPSHOT/hive-contrib-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/contrib/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-contrib/0.13.0-SNAPSHOT/hive-contrib-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HBase Handler 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hbase-handler ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hbase-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hbase-handler ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hbase-handler ---
[INFO] Compiling 18 source files to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hbase-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hbase-handler ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp/conf
     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hbase-handler ---
[INFO] Compiling 4 source files to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hbase-handler ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hbase-handler ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/hive-hbase-handler-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hbase-handler ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/hive-hbase-handler-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hbase-handler/0.13.0-SNAPSHOT/hive-hbase-handler-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-hbase-handler/0.13.0-SNAPSHOT/hive-hbase-handler-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hcatalog ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp/conf
     [copy] Copying 5 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hcatalog ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog/0.13.0-SNAPSHOT/hive-hcatalog-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Core 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hcatalog-core ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hcatalog-core ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-core ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-core ---
[INFO] Compiling 145 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/classes
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatFileUtil.java:[91,4] reached end of file while parsing
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [4.738s]
[INFO] Hive Ant Utilities ................................ SUCCESS [6.895s]
[INFO] Hive Shims Common ................................. SUCCESS [3.341s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [2.394s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [2.530s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [1.434s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [3.179s]
[INFO] Hive Shims ........................................ SUCCESS [0.592s]
[INFO] Hive Common ....................................... SUCCESS [8.025s]
[INFO] Hive Serde ........................................ SUCCESS [10.046s]
[INFO] Hive Metastore .................................... SUCCESS [26.609s]
[INFO] Hive Query Language ............................... SUCCESS [1:01.971s]
[INFO] Hive Service ...................................... SUCCESS [5.632s]
[INFO] Hive JDBC ......................................... SUCCESS [1.650s]
[INFO] Hive Beeline ...................................... SUCCESS [0.985s]
[INFO] Hive CLI .......................................... SUCCESS [1.368s]
[INFO] Hive Contrib ...................................... SUCCESS [1.182s]
[INFO] Hive HBase Handler ................................ SUCCESS [2.151s]
[INFO] Hive HCatalog ..................................... SUCCESS [0.152s]
[INFO] Hive HCatalog Core ................................ FAILURE [0.627s]
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog HBase Storage Handler ............... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 2:28.394s
[INFO] Finished at: Mon Jan 13 11:12:15 EST 2014
[INFO] Final Memory: 53M/466M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-hcatalog-core: Compilation failure
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatFileUtil.java:[91,4] reached end of file while parsing
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-hcatalog-core
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12622613&lt;/p&gt;</comment>
                            <comment id="13869797" author="satish.mittal" created="Mon, 13 Jan 2014 18:28:57 +0000"  >&lt;p&gt;Updated patch.&lt;/p&gt;</comment>
                            <comment id="13869878" author="satish.mittal" created="Mon, 13 Jan 2014 19:41:53 +0000"  >&lt;p&gt;Attaching a document that describes the approach taken by the patch in designing/implementing the functionality.&lt;/p&gt;</comment>
                            <comment id="13869933" author="hiveqa" created="Mon, 13 Jan 2014 20:27:52 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12622673/HIVE-6109.2.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12622673/HIVE-6109.2.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 4919 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testNegativeCliDriver_mapreduce_stack_trace_hadoop20
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/886/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/886/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/886/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/886/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12622673&lt;/p&gt;</comment>
                            <comment id="13870929" author="satish.mittal" created="Tue, 14 Jan 2014 17:26:47 +0000"  >&lt;p&gt;This test has passed on my setup, with the following command:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;cd itests&lt;/li&gt;
	&lt;li&gt;mvn test -Phadoop-1&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Not sure if it is a random test failure (the test is not related to the patch).&lt;/p&gt;</comment>
                            <comment id="13873976" author="sushanth" created="Thu, 16 Jan 2014 21:30:32 +0000"  >&lt;p&gt;I like your approach, and the attached doc. Looking through the patch.&lt;/p&gt;</comment>
                            <comment id="13873977" author="sushanth" created="Thu, 16 Jan 2014 21:31:36 +0000"  >&lt;p&gt;(Also, I&apos;m not able to assign it to you, I guess you aren&apos;t marked in the hive jira as a contributor? &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt;, could you please add Satish to the list?)&lt;/p&gt;</comment>
                            <comment id="13874577" author="satish.mittal" created="Fri, 17 Jan 2014 08:51:51 +0000"  >&lt;p&gt;Created review request for the patch: &lt;a href=&quot;https://reviews.apache.org/r/16951&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/16951&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13878320" author="satish.mittal" created="Wed, 22 Jan 2014 06:22:37 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sushanth&quot; class=&quot;user-hover&quot; rel=&quot;sushanth&quot;&gt;Sushanth Sowmyan&lt;/a&gt;, did you get a chance to look at the changes?&lt;/p&gt;</comment>
                            <comment id="13880526" author="sushanth" created="Fri, 24 Jan 2014 00:04:38 +0000"  >&lt;p&gt;Apparently reviewboard is having a fair number of issues, so I&apos;m copy-pasting my comments from reviewboard on to here:&lt;/p&gt;

&lt;p&gt;hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java (Diff revision 1)&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;73	
  private static final String DYNTEMP_DIR_NAME = &quot;_DYN&quot;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&quot;_DYN&quot; is already defined in FosterStorageHandler, needs to have one place where it&apos;s defined. I&apos;m okay with it being defined here if the FosterStorageHandler constant is removed and references to that are changed to reference this.&lt;/p&gt;


&lt;p&gt;hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java (Diff revision 1)&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;public void commitJob(JobContext jobContext) throws IOException {
272	
    
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;whitespace errors - git refers to a bunch of these through the patch when we try to apply, please correct for final patch upload.&lt;/p&gt;

&lt;p&gt;hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java (Diff revision 1)&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;private void registerPartitions(JobContext context) throws IOException{
662	
720	
        if (customDynamicLocationUsed) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;A bit about code readability - if we add a special case, then it makes sense to add the special case as an else, rather than as an if - that way, the default behaviour is visible first, and then the special case - please swap this around so that this is a if (!customDynamicLocationUsed) structure.&lt;/p&gt;


&lt;p&gt;hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java (Diff revision 1)&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;private void registerPartitions(JobContext context) throws IOException{
764	
          if (customDynamicLocationUsed) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This is now significant amount of code repetition from line 720-741 above, please see if we can refactor this into a separate method.&lt;/p&gt;


&lt;p&gt;hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/OutputJobInfo.java (Diff revision 1)&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;public String getLocation() {
178	
  public void setCustomDynamicLocation(String customDynamicRoot, String customDynamicPath) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This becomes the primary API point with this change, wherein, a user that is using HCatOutputFormat will generate an OutputJobInfo, and then call setCustomDynamicLocation on it. This is fine for M/R users of HCat, but is something that will wind up having to be implemented for each M/R user. It might have been better to define a constant in HCatConstants, say &quot;hcat.dynamic.partitioning.custom.pattern&quot;, and to use that as a JobInfo parameter. That makes it easier for other tools to integrate with this feature. For example, with your patch, we still do not support the ability for the HCatStorer from pig to be able to write to custom dynamic partitions, while we do want to keep feature parity where possible between HCatOutputFormat and HCatStorer.&lt;/p&gt;

&lt;p&gt;In fact, as a design goal for HCat, we&apos;re trying to move away from letting(requiring) users explicitly muck around with OutputJobInfo and InputJobInfo, and stick to static calls to HCatInputFormat/HCatOutputFormat.&lt;/p&gt;

&lt;p&gt;I would like to see this call be something the HCatOutputFormat automatically calls if a jobConf parameter(as above) is set. That way, we can solve pig compatibility as well easily&lt;/p&gt;</comment>
                            <comment id="13893691" author="satish.mittal" created="Thu, 6 Feb 2014 19:24:34 +0000"  >&lt;p&gt;Copy-pasting my response to review comments from review-board:&lt;/p&gt;

&lt;p&gt;1)Sushanth:  &quot;_DYN&quot; is already defined in FosterStorageHandler, needs to have one place where it&apos;s defined. I&apos;m okay with it being defined here if the FosterStorageHandler constant is removed and references to that are changed to reference this.&lt;/p&gt;

&lt;p&gt;Satish Mittal: Will refactor it now. I didn&apos;t want to touch unrelated code in the first cut.&lt;/p&gt;

&lt;p&gt;2) Sushanth: whitespace errors - git refers to a bunch of these through the patch when we try to apply, please correct for final patch upload.&lt;/p&gt;

&lt;p&gt;Satish Mittal: Will do.&lt;/p&gt;

&lt;p&gt;3) Sushanth: A bit about code readability - if we add a special case, then it makes sense to add the special case as an else, rather than as an if - that way, the default behaviour is visible first, and then the special case - please swap this around so that this is a if (!customDynamicLocationUsed) structure.&lt;/p&gt;

&lt;p&gt;Satish Mittal: Fine, will do that.&lt;/p&gt;

&lt;p&gt;4) Sushanth: This is now significant amount of code repetition from line 720-741 above, please see if we can refactor this into a separate method.&lt;/p&gt;

&lt;p&gt;Satish Mittal: I will see if it can be easily refactored into a private method.&lt;/p&gt;

&lt;p&gt;5) Sushanth: This becomes the primary API point with this change, wherein, a user that is using HCatOutputFormat will generate an OutputJobInfo, and then call setCustomDynamicLocation on it. This is fine for M/R users of HCat, but is something that will wind up having to be implemented for each M/R user. It might have been better to define a constant in HCatConstants, say &quot;hcat.dynamic.partitioning.custom.pattern&quot;, and to use that as a JobInfo parameter. That makes it easier for other tools to integrate with this feature. For example, with your patch, we still do not support the ability for the HCatStorer from pig to be able to write to custom dynamic partitions, while we do want to keep feature parity where possible between HCatOutputFormat and HCatStorer.&lt;/p&gt;

&lt;p&gt;In fact, as a design goal for HCat, we&apos;re trying to move away from letting(requiring) users explicitly muck around with OutputJobInfo and InputJobInfo, and stick to static calls to HCatInputFormat/HCatOutputFormat.&lt;/p&gt;

&lt;p&gt;I would like to see this call be something the HCatOutputFormat automatically calls if a jobConf parameter(as above) is set. That way, we can solve pig compatibility as well easily.&lt;/p&gt;

&lt;p&gt;Satish Mittal: Thanks for this feedback Sushanth. I had realized that with the current patch, HCatStorer is still not covered (only M/R jobs are covered), and was thinking of exposing equivalent APIs in HCatStorer to achieve it. However your suggestion sounds cleaner to me. Will do that!&lt;/p&gt;</comment>
                            <comment id="13893694" author="satish.mittal" created="Thu, 6 Feb 2014 19:25:57 +0000"  >&lt;p&gt;Uploading patch that incorporates review comments.&lt;/p&gt;</comment>
                            <comment id="13893903" author="hiveqa" created="Thu, 6 Feb 2014 22:27:09 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12627396/HIVE-6109.3.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12627396/HIVE-6109.3.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 5036 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1225/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1225/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1225/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1225/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12627396&lt;/p&gt;</comment>
                            <comment id="13894263" author="satish.mittal" created="Fri, 7 Feb 2014 07:31:56 +0000"  >&lt;p&gt;The latest patch &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6109&quot; title=&quot;Support customized location for EXTERNAL tables created by Dynamic Partitioning&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6109&quot;&gt;&lt;del&gt;HIVE-6109&lt;/del&gt;&lt;/a&gt;.3.patch.txt introduces a new Job conf property &quot;hcat.dynamic.partitioning.custom.pattern&quot; that can be configured to provide custom path pattern in case of dynamic partitioning. E.g. &quot;${year}/${month}/${day}/${hour}/${minute}/${country}&quot; in the above example.&lt;/p&gt;</comment>
                            <comment id="13899410" author="sushanth" created="Wed, 12 Feb 2014 18:41:57 +0000"  >&lt;p&gt;+1 to the updated patch, looks good to me.&lt;/p&gt;</comment>
                            <comment id="13900498" author="sushanth" created="Thu, 13 Feb 2014 16:50:47 +0000"  >&lt;p&gt;Oh, just realized! You introduced a new HCatFileUtil.java in this patch that does not have the ASF license header. I can include it before committing if you&apos;d like.&lt;/p&gt;</comment>
                            <comment id="13900531" author="satish.mittal" created="Thu, 13 Feb 2014 17:29:59 +0000"  >&lt;p&gt;Oh OK. I missed it. You can include the license header. Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=susanths&quot; class=&quot;user-hover&quot; rel=&quot;susanths&quot;&gt;Sushanth&lt;/a&gt;!&lt;/p&gt;</comment>
                            <comment id="13900615" author="sushanth" created="Thu, 13 Feb 2014 19:01:53 +0000"  >&lt;p&gt;Included the ASF header, and committed.&lt;/p&gt;

&lt;p&gt;Thanks, Satish, this was a very useful contribution!&lt;/p&gt;</comment>
                            <comment id="13925683" author="satish.mittal" created="Mon, 10 Mar 2014 11:53:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=leftylev&quot; class=&quot;user-hover&quot; rel=&quot;leftylev&quot;&gt;Lefty Leverenz&lt;/a&gt;, can you please update the HCatalog wikidoc section on &apos;external tables&apos; in &apos;dynamic partitioning&apos; with release notes of this ticket?&lt;/p&gt;</comment>
                            <comment id="13926248" author="lefty@hortonworks.com" created="Mon, 10 Mar 2014 21:28:27 +0000"  >&lt;p&gt;Will do.  Is the example in the release note sufficient, or do you want more details?&lt;/p&gt;</comment>
                            <comment id="13929999" author="satish.mittal" created="Tue, 11 Mar 2014 06:08:55 +0000"  >&lt;p&gt;You could use the following details: &lt;/p&gt;

&lt;p&gt;A new Job conf property &quot;hcat.dynamic.partitioning.custom.pattern&quot; is introduced that can be configured to provide custom path pattern in case of dynamic partitioning. E.g. suppose a table user_logs is partitioned by (year, month, day, hour, minute, country). If user wants data for dynamic partitions to get generated in the following location format: &quot;hdfs://hcat/data/user_logs/2013/12/06/10/US&quot;, then this property can be set to:&lt;/p&gt;

&lt;p&gt;&quot;${year}/${month}/${day}/${hour}/${minute}/${country}&quot;.&lt;/p&gt;</comment>
                            <comment id="13959750" author="lefty@hortonworks.com" created="Fri, 4 Apr 2014 08:07:24 +0000"  >&lt;p&gt;Please review and correct the doc here: &lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/HCatalog+DynamicPartitions#HCatalogDynamicPartitions-ExternalTables&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HCatalog Dynamic Partitioning:  External Tables &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13959769" author="satish.mittal" created="Fri, 4 Apr 2014 08:42:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=leftylev&quot; class=&quot;user-hover&quot; rel=&quot;leftylev&quot;&gt;Lefty Leverenz&lt;/a&gt;, Very nicely documented, with detailed examples that explain the feature!&lt;/p&gt;

&lt;p&gt;A minor comment: the number of partitions is not consistent in the 1st example. The schema has 6 partitions (year, month, day, hour, minute, country), but examples have 4/5 partitions. A new user might get confused. Would be good to be consistent throughout.&lt;/p&gt;</comment>
                            <comment id="13960161" author="lefty@hortonworks.com" created="Fri, 4 Apr 2014 17:29:34 +0000"  >&lt;p&gt;Good catch, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=satish.mittal&quot; class=&quot;user-hover&quot; rel=&quot;satish.mittal&quot;&gt;Satish Mittal&lt;/a&gt;.  You get the eagle-eye award.&lt;/p&gt;</comment>
                            <comment id="14128873" author="karthiksrivasthava" created="Wed, 10 Sep 2014 18:25:03 +0000"  >&lt;p&gt;Satish Mittal,&lt;/p&gt;

&lt;p&gt;You participation is phenomenal in this forum and very helpful for new users like me.&lt;/p&gt;

&lt;p&gt;I need to use dynamic partitioning -Custom pattern and i am missing something very obvious.&lt;/p&gt;

&lt;p&gt;Do i need to set up  hcat.dynamic.partitioning.custom.pattern in Hive CLI as both Hcatalog and Hive are integrated together. ? My path for partition in external table is asusual like data/year=2013/month=jan/&lt;br/&gt;
But i need data/year/month.. Do i need to amend location for this external table.?&lt;/p&gt;

&lt;p&gt;Please accept apologies if i sound very basic. Thanks in advance&lt;/p&gt;</comment>
                            <comment id="14129843" author="satish.mittal" created="Thu, 11 Sep 2014 10:09:19 +0000"  >&lt;p&gt;Hi karthik,&lt;/p&gt;

&lt;p&gt;Currently this setting allows customizing path pattern when dynamic partitions are added through HCatalog APIs (HCatOutputFormat in case of MR job). It&apos;s not available when dynamic partitions get added through Hive query. I have created &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-8053&quot; title=&quot;Support custom path pattern when dynamic partitions are added in Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-8053&quot;&gt;HIVE-8053&lt;/a&gt; to track it.&lt;/p&gt;</comment>
                            <comment id="14133625" author="karthiksrivasthava" created="Mon, 15 Sep 2014 06:44:40 +0000"  >&lt;p&gt;Satish ,&lt;/p&gt;

&lt;p&gt;I used HCatalog API (HCatOutputFormat ) to set custom pattern in dynamic Partitioning .But as documentation say I cannot use setCustomDynamicLocation() through OutputJobInfo object as it is not a public method.&lt;/p&gt;

&lt;p&gt;  Please correct me if I am missing something Satish .&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Karthik&lt;/p&gt;
</comment>
                            <comment id="14133653" author="satish.mittal" created="Mon, 15 Sep 2014 07:35:48 +0000"  >&lt;p&gt;Karthik, refer to the release notes. You need to set it as a job conf property. E.g.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;job.getConfiguration().set(&quot;hcat.dynamic.partitioning.custom.pattern&quot;, &quot;${year}/${month}/${day}/${hour}/${minute}&quot;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12740737">HIVE-8053</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12662210">HIVE-5011</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12622613" name="HIVE-6109.1.patch.txt" size="29001" author="satish.mittal" created="Mon, 13 Jan 2014 11:58:29 +0000"/>
                            <attachment id="12622673" name="HIVE-6109.2.patch.txt" size="29001" author="satish.mittal" created="Mon, 13 Jan 2014 18:28:57 +0000"/>
                            <attachment id="12627396" name="HIVE-6109.3.patch.txt" size="31424" author="satish.mittal" created="Thu, 6 Feb 2014 19:25:57 +0000"/>
                            <attachment id="12622686" name="HIVE-6109.pdf" size="61522" author="satish.mittal" created="Mon, 13 Jan 2014 19:41:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 27 Dec 2013 00:53:04 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365401</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 19 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1qzd3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365703</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>A new Job conf property &amp;quot;hcat.dynamic.partitioning.custom.pattern&amp;quot; is introduced that can be configured to provide custom path pattern in case of dynamic partitioning. E.g. &amp;quot;${year}/${month}/${day}/${hour}/${minute}/${country}&amp;quot;</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-6110] schematool errors out when HIVE_OPTS is set</title>
                <link>https://issues.apache.org/jira/browse/HIVE-6110</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;If HIVE_OPTS is set schematool command fails to start. To repro this set HIVE_AUX_JARS_PATH&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;$ export HIVE_AUX_JARS_PATH=/path/lib.jar
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Above export adds a --hiveconf option to the commandline args to HiveSchemaTool which doesn&apos;t recognize it.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;$ hive-install-dir/bin/schematool -dbType derby -info
HiveSchemaTool:Parsing failed.  Reason: Unrecognized option: -hiveconf
usage: schemaTool
 -dbType &amp;lt;databaseType&amp;gt;             Metastore database type
 -dryRun                            list SQL scripts (no execute)
 -help                              print &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; message
 -info                              Show config and schema details
 -initSchema                        Schema initialization
 -initSchemaTo &amp;lt;initTo&amp;gt;             Schema initialization to a version
 -passWord &amp;lt;password&amp;gt;               Override config file password
 -upgradeSchema                     Schema upgrade
 -upgradeSchemaFrom &amp;lt;upgradeFrom&amp;gt;   Schema upgrade from a version
 -userName &amp;lt;user&amp;gt;                   Override config file user name
 -verbose                           only print SQL statements
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12686441">HIVE-6110</key>
            <summary>schematool errors out when HIVE_OPTS is set</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vkorukanti">Venki Korukanti</assignee>
                                    <reporter username="vkorukanti">Venki Korukanti</reporter>
                        <labels>
                    </labels>
                <created>Thu, 26 Dec 2013 18:13:13 +0000</created>
                <updated>Thu, 13 Mar 2014 22:54:50 +0000</updated>
                            <resolved>Thu, 13 Mar 2014 22:54:50 +0000</resolved>
                                    <version>0.12.0</version>
                                    <fixVersion>0.13.0</fixVersion>
                                    <component>Metastore</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13856979" author="vkorukanti" created="Thu, 26 Dec 2013 18:16:22 +0000"  >&lt;p&gt;Reset HIVE_OPTS before calling execHiveCmd&lt;/p&gt;</comment>
                            <comment id="13857021" author="hiveqa" created="Thu, 26 Dec 2013 19:28:13 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12620521/HIVE-6110.1.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12620521/HIVE-6110.1.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4818 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/743/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/743/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/743/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/743/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12620521&lt;/p&gt;</comment>
                            <comment id="13933388" author="ashutoshc" created="Thu, 13 Mar 2014 15:18:28 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13934258" author="ashutoshc" created="Thu, 13 Mar 2014 22:54:50 +0000"  >&lt;p&gt;Committed to trunk &amp;amp; 0.13. Thanks, Venki!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12676226">HIVE-5677</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12620521" name="HIVE-6110.1.patch.txt" size="470" author="vkorukanti" created="Thu, 26 Dec 2013 18:16:58 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 26 Dec 2013 19:28:13 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365431</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 45 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1qzjr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365733</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-6111] SQL std auth - support granted-by in grant statements</title>
                <link>https://issues.apache.org/jira/browse/HIVE-6111</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;sub-task includes parser changes&lt;/p&gt;</description>
                <environment></environment>
        <key id="12686484">HIVE-6111</key>
            <summary>SQL std auth - support granted-by in grant statements</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12679546">HIVE-5837</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="thejas">Thejas M Nair</reporter>
                        <labels>
                    </labels>
                <created>Fri, 27 Dec 2013 00:11:42 +0000</created>
                <updated>Mon, 15 Sep 2014 17:25:31 +0000</updated>
                            <resolved>Mon, 15 Sep 2014 17:25:31 +0000</resolved>
                                                                    <component>Authorization</component>
                    <component>SQLStandardAuthorization</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                    <timeoriginalestimate seconds="86400">24h</timeoriginalestimate>
                            <timeestimate seconds="86400">24h</timeestimate>
                                        <comments>
                            <comment id="13894310" author="thejas" created="Fri, 7 Feb 2014 08:38:46 +0000"  >&lt;p&gt;The Syntax is &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&amp;lt;grant privilege statement&amp;gt; ::=
GRANT &amp;lt;privileges&amp;gt; TO &amp;lt;grantee&amp;gt; [ { &amp;lt;comma&amp;gt; &amp;lt;grantee&amp;gt; }... ]
[ WITH HIERARCHY OPTION ]
[ WITH GRANT OPTION ]
[ GRANTED BY &amp;lt;grantor&amp;gt; ]

&amp;lt;grantor&amp;gt; ::=
CURRENT_USER
| CURRENT_ROLE

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365475</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 50 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1qztb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365776</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-6112] SQL std auth - support new privileges INSERT, DELETE</title>
                <link>https://issues.apache.org/jira/browse/HIVE-6112</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Includes  INSERT, DELETE privileges. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12686486">HIVE-6112</key>
            <summary>SQL std auth - support new privileges INSERT, DELETE</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12679546">HIVE-5837</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="thejas">Thejas M Nair</assignee>
                                    <reporter username="thejas">Thejas M Nair</reporter>
                        <labels>
                    </labels>
                <created>Fri, 27 Dec 2013 00:21:59 +0000</created>
                <updated>Sat, 1 Feb 2014 21:28:00 +0000</updated>
                            <resolved>Fri, 31 Jan 2014 22:48:42 +0000</resolved>
                                                    <fixVersion>0.13.0</fixVersion>
                                    <component>Authorization</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                    <timeoriginalestimate seconds="43200">12h</timeoriginalestimate>
                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="32400">9h</timespent>
                                <comments>
                            <comment id="13858946" author="brocknoland" created="Mon, 30 Dec 2013 17:31:44 +0000"  >&lt;p&gt;Looks like this patch misses the getPrivTypeByName() and the toString() method on Privilege. FIWW this class looks like a perfect candidate for a unit test and I think we could get ride of all those if/else and case statements by storing this stuff in a map.&lt;/p&gt;</comment>
                            <comment id="13884793" author="thejas" created="Tue, 28 Jan 2014 22:29:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6112&quot; title=&quot;SQL std auth - support new privileges INSERT, DELETE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6112&quot;&gt;&lt;del&gt;HIVE-6112&lt;/del&gt;&lt;/a&gt;.2.patch - minor cleanup on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6112&quot; title=&quot;SQL std auth - support new privileges INSERT, DELETE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6112&quot;&gt;&lt;del&gt;HIVE-6112&lt;/del&gt;&lt;/a&gt;.1.patch.&lt;/p&gt;

&lt;p&gt;The patches also includes use of maps instead of if-else statement in privilege as suggested by Brock. The enum constructor sets the name and token type which gets added to map.&lt;/p&gt;</comment>
                            <comment id="13884951" author="ashutoshc" created="Wed, 29 Jan 2014 03:07:46 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13886407" author="thejas" created="Thu, 30 Jan 2014 08:31:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6112&quot; title=&quot;SQL std auth - support new privileges INSERT, DELETE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6112&quot;&gt;&lt;del&gt;HIVE-6112&lt;/del&gt;&lt;/a&gt;.3.patch - updated .q.out file after rebasing with trunk&lt;/p&gt;</comment>
                            <comment id="13887312" author="hiveqa" created="Fri, 31 Jan 2014 00:35:46 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12626081/HIVE-6112.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12626081/HIVE-6112.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 4985 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_authorization_1_sql_std
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1120/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1120/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1120/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1120/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12626081&lt;/p&gt;</comment>
                            <comment id="13887393" author="thejas" created="Fri, 31 Jan 2014 02:24:30 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6112&quot; title=&quot;SQL std auth - support new privileges INSERT, DELETE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6112&quot;&gt;&lt;del&gt;HIVE-6112&lt;/del&gt;&lt;/a&gt;.4.patch - fixing the test failure&lt;/p&gt;</comment>
                            <comment id="13887454" author="ashutoshc" created="Fri, 31 Jan 2014 04:22:20 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13888234" author="hiveqa" created="Fri, 31 Jan 2014 22:16:18 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12626256/HIVE-6112.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12626256/HIVE-6112.5.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4986 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1134/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1134/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1134/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/1134/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12626256&lt;/p&gt;</comment>
                            <comment id="13888260" author="thejas" created="Fri, 31 Jan 2014 22:48:42 +0000"  >&lt;p&gt;Patch committed to trunk. &lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12682516">HIVE-5928</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12625682" name="HIVE-6112.1.patch" size="52036" author="thejas" created="Tue, 28 Jan 2014 22:08:44 +0000"/>
                            <attachment id="12625689" name="HIVE-6112.2.patch" size="52421" author="thejas" created="Tue, 28 Jan 2014 22:29:53 +0000"/>
                            <attachment id="12626081" name="HIVE-6112.3.patch" size="52421" author="thejas" created="Thu, 30 Jan 2014 08:31:26 +0000"/>
                            <attachment id="12626246" name="HIVE-6112.4.patch" size="52505" author="thejas" created="Fri, 31 Jan 2014 02:24:30 +0000"/>
                            <attachment id="12626256" name="HIVE-6112.5.patch" size="52484" author="thejas" created="Fri, 31 Jan 2014 04:06:25 +0000"/>
                            <attachment id="12620568" name="new-privs.patch" size="1672" author="thejas" created="Fri, 27 Dec 2013 00:27:09 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 30 Dec 2013 17:31:44 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365477</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 51 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1qztr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365778</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-6113] Upgrade DataNucleus [was: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient]</title>
                <link>https://issues.apache.org/jira/browse/HIVE-6113</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;CLEAR LIBRARY CACHE&lt;/p&gt;

&lt;p&gt;When I exccute SQL &quot;use fdm; desc formatted fdm.tableName;&quot;  in python, throw Error as followed.&lt;br/&gt;
but when I tryit again , It will success.&lt;/p&gt;

&lt;p&gt;2013-12-25 03:01:32,290 ERROR exec.DDLTask (DDLTask.java:execute(435)) - org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient&lt;br/&gt;
	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1143)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1128)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.DDLTask.switchDatabase(DDLTask.java:3479)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:237)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:151)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:65)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1414)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1192)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1020)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:888)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:260)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:217)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:507)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:875)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:769)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:708)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.util.RunJar.main(RunJar.java:197)&lt;br/&gt;
Caused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1217)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&amp;lt;init&amp;gt;(RetryingMetaStoreClient.java:62)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:72)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2372)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2383)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1139)&lt;br/&gt;
	... 20 more&lt;br/&gt;
Caused by: java.lang.reflect.InvocationTargetException&lt;br/&gt;
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)&lt;br/&gt;
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)&lt;br/&gt;
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1210)&lt;br/&gt;
	... 25 more&lt;br/&gt;
Caused by: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore&lt;br/&gt;
NestedThrowables:&lt;br/&gt;
java.sql.BatchUpdateException: Duplicate entry &apos;default&apos; for key &apos;UNIQUE_DATABASE&apos;&lt;br/&gt;
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:451)&lt;br/&gt;
	at org.datanucleus.api.jdo.JDOTransaction.commit(JDOTransaction.java:165)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.ObjectStore.commitTransaction(ObjectStore.java:358)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.ObjectStore.createDatabase(ObjectStore.java:404)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.RetryingRawStore.invoke(RetryingRawStore.java:124)&lt;br/&gt;
	at $Proxy9.createDatabase(Unknown Source)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB_core(HiveMetaStore.java:422)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:441)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:326)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.&amp;lt;init&amp;gt;(HiveMetaStore.java:286)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&amp;lt;init&amp;gt;(RetryingHMSHandler.java:54)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:59)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.HiveMetaStore.newHMSHandler(HiveMetaStore.java:4060)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&amp;lt;init&amp;gt;(HiveMetaStoreClient.java:121)&lt;br/&gt;
	... 30 more&lt;br/&gt;
Caused by: java.sql.BatchUpdateException: Duplicate entry &apos;default&apos; for key &apos;UNIQUE_DATABASE&apos;&lt;br/&gt;
	at com.mysql.jdbc.PreparedStatement.executeBatchSerially(PreparedStatement.java:2028)&lt;br/&gt;
	at com.mysql.jdbc.PreparedStatement.executeBatch(PreparedStatement.java:1451)&lt;br/&gt;
	at com.jolbox.bonecp.StatementHandle.executeBatch(StatementHandle.java:469)&lt;br/&gt;
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:372)&lt;br/&gt;
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:628)&lt;br/&gt;
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:596)&lt;br/&gt;
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:683)&lt;br/&gt;
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:86)&lt;br/&gt;
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:454)&lt;br/&gt;
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:199)&lt;br/&gt;
	at org.datanucleus.TransactionImpl.commit(TransactionImpl.java:263)&lt;br/&gt;
	at org.datanucleus.api.jdo.JDOTransaction.commit(JDOTransaction.java:98)&lt;br/&gt;
	... 46 more&lt;br/&gt;
Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry &apos;default&apos; for key &apos;UNIQUE_DATABASE&apos;&lt;br/&gt;
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)&lt;br/&gt;
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)&lt;br/&gt;
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)&lt;br/&gt;
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:411)&lt;br/&gt;
	at com.mysql.jdbc.Util.getInstance(Util.java:386)&lt;br/&gt;
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1039)&lt;br/&gt;
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3609)&lt;br/&gt;
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3541)&lt;br/&gt;
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2002)&lt;br/&gt;
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2163)&lt;br/&gt;
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2624)&lt;br/&gt;
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:2127)&lt;br/&gt;
	at com.mysql.jdbc.PreparedStatement.executeUpdate(PreparedStatement.java:2427)&lt;br/&gt;
	at com.mysql.jdbc.PreparedStatement.executeBatchSerially(PreparedStatement.java:1980)&lt;br/&gt;
	... 57 more&lt;/p&gt;
</description>
                <environment>&lt;p&gt;hadoop-0.20.2-cdh3u3,hive-0.12.0&lt;/p&gt;</environment>
        <key id="12686504">HIVE-6113</key>
            <summary>Upgrade DataNucleus [was: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient]</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="osayankin">Oleksiy Sayankin</assignee>
                                    <reporter username="shiw019">William Stone</reporter>
                        <labels>
                            <label>HiveMetaStoreClient</label>
                            <label>TODOC2.0</label>
                            <label>metastore</label>
                            <label>unable_instantiate</label>
                    </labels>
                <created>Fri, 27 Dec 2013 07:07:00 +0000</created>
                <updated>Fri, 17 Mar 2017 20:33:50 +0000</updated>
                            <resolved>Mon, 4 Jan 2016 20:57:05 +0000</resolved>
                                    <version>0.12.0</version>
                    <version>0.13.0</version>
                    <version>0.14.0</version>
                    <version>1.0.0</version>
                    <version>1.2.1</version>
                                    <fixVersion>2.0.0</fixVersion>
                                    <component>Database/Schema</component>
                        <due></due>
                            <votes>5</votes>
                                    <watches>14</watches>
                                                                <comments>
                            <comment id="13963055" author="eliac" created="Tue, 8 Apr 2014 14:54:29 +0000"  >&lt;p&gt;The exact same issue reproduces here. Hive 0.12 on MapR 3.1.0 with MySQL metastore. The exception appears when there are several processes working with Hive concurrently.&lt;/p&gt;

&lt;p&gt;From our analysis the problem seems related to the one described here: &lt;a href=&quot;http://mail-archives.apache.org/mod_mbox/hive-user/201107.mbox/%3C4F6B25AFFFCAFE44B6259A412D5F9B1033183876@ExchMBX104.netflix.com%3E&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://mail-archives.apache.org/mod_mbox/hive-user/201107.mbox/%3C4F6B25AFFFCAFE44B6259A412D5F9B1033183876@ExchMBX104.netflix.com%3E&lt;/a&gt;&lt;/p&gt;

&lt;h5&gt;&lt;a name=&quot;Analysis%3A&quot;&gt;&lt;/a&gt;Analysis:&lt;/h5&gt;
&lt;p&gt;At certain times, Hive&apos;s DataNucleus decides to create and then drop tables called &quot;DELETEME&quot;+timestamp in the metastore schema on MySQL (see &lt;a href=&quot;http://sourceforge.net/p/datanucleus/code/HEAD/tree/platform/store.rdbms/tags/datanucleus-rdbms-3.2.2/src/java/org/datanucleus/store/rdbms/table/ProbeTable.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;ProbleTable&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;During other flows, DataNucleus queries MySQL for the list of all the columns of all the tables (see &lt;a href=&quot;http://sourceforge.net/p/datanucleus/code/HEAD/tree/platform/store.rdbms/tags/datanucleus-rdbms-3.2.2/src/java/org/datanucleus/store/rdbms/schema/RDBMSSchemaHandler.java#l872&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;RDBMSSchemaHandler.refreshTableData&lt;/a&gt;). MySQL&apos;s JDBC driver implements the DatabaseMetaData.getColumns method by querying the DB for a list of all the tables, and then iterating over that list and querying for each table&apos;s columns (see &lt;a href=&quot;http://bazaar.launchpad.net/~mysql/connectorj/5.1/view/head:/src/com/mysql/jdbc/DatabaseMetaData.java#L2581&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;com.mysql.jdbc.DatabaseMetaData&lt;/a&gt;). If a table is deleted from the DB during this operation, DatabaseMetaData.getColumns will throw an exception.&lt;/p&gt;

&lt;p&gt;This exception is interpreted by Hive to mean that the &quot;default&quot; Hive database doesn&apos;t exist. Hive tries to create it, inserting a row into the metastore.DBS table in MySQL, which triggers the &quot;Duplicate entry &apos;default&apos; for key &apos;UNIQUE_DATABASE&apos;&quot; exception.&lt;/p&gt;

&lt;p&gt;I&apos;m not completely clear about the conditions for a) DataNucleus creating and dropping a &quot;DELETEME&quot; table, and b) DataNucleus calling DatabaseMetaData.getColumns, so unfortunately I can&apos;t yet provide a clear test case. But in our lab environment under load we were able to reproduce the exception once every few minutes.&lt;/p&gt;

&lt;h5&gt;&lt;a name=&quot;Workaround%3A&quot;&gt;&lt;/a&gt;Workaround:&lt;/h5&gt;
&lt;p&gt;As suggested by the link above, setting the &lt;b&gt;datanucleus.fixedDatastore&lt;/b&gt; property to &lt;b&gt;true&lt;/b&gt; (e.g. in hive-site.xml or elsewhere) seems to solve the problem. However, it means that the metastore schema is no longer automatically created on-demand, and requires using Hive&apos;s schematool command to manually create the metastore schema.&lt;/p&gt;</comment>
                            <comment id="15006600" author="osayankin" created="Mon, 16 Nov 2015 12:31:19 +0000"  >&lt;p&gt;ROOT-CAUSE:&lt;/p&gt;

&lt;p&gt;Bug &lt;a href=&quot;http://www.datanucleus.org/servlet/jira/browse/NUCRDBMS-755&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.datanucleus.org/servlet/jira/browse/NUCRDBMS-755&lt;/a&gt; in DataNucleus Store RDBMS of version 3.2.9&lt;/p&gt;

&lt;p&gt;SOLUTION:&lt;/p&gt;

&lt;p&gt;Use DataNucleus Store RDBMS of higher version where fix of NUCRDBMS-755 is provided. Version change summary:&lt;/p&gt;

&lt;p&gt;datanucleus-api-jdo 3.2.6  ---&amp;gt; 4.2.1&lt;br/&gt;
datanucleus-core    3.2.10 ---&amp;gt; 4.1.6&lt;br/&gt;
datanucleus-rdbms 3.2.9  ---&amp;gt; 4.1.7&lt;/p&gt;</comment>
                            <comment id="15006620" author="osayankin" created="Mon, 16 Nov 2015 12:45:39 +0000"  >&lt;p&gt;For review &lt;a href=&quot;https://reviews.apache.org/r/40344/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/40344/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15006993" author="sushanth" created="Mon, 16 Nov 2015 17:50:28 +0000"  >&lt;p&gt;@&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=osayankin&quot; class=&quot;user-hover&quot; rel=&quot;osayankin&quot;&gt;Oleksiy Sayankin&lt;/a&gt; : I know &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt; will be pleased with this proposal, he&apos;s been suggesting the same for other reasons. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  That said, whenever we do a major version bump of DN, we should do a verification to ensure that we continue to work correctly. Have you verified the elements in &lt;a href=&quot;http://www.datanucleus.org/products/accessplatform_4_2/migration.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.datanucleus.org/products/accessplatform_4_2/migration.html&lt;/a&gt; to see if we won&apos;t be affected adversely?&lt;/p&gt;

&lt;p&gt;@&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eliac&quot; class=&quot;user-hover&quot; rel=&quot;eliac&quot;&gt;Eli Acherkan&lt;/a&gt; : Very interesting analysis. Could you point me to where you see the following:&lt;/p&gt;

&lt;p&gt;&amp;gt; If a table is deleted from the DB during this operation, DatabaseMetaData.getColumns will throw an exception.&lt;br/&gt;
&amp;gt;This exception is interpreted by Hive to mean that the &quot;default&quot; Hive database doesn&apos;t exist. &lt;/p&gt;

&lt;p&gt;Because I do recollect similar sounding issues where DN would report a null return when we tried to do a getDatabase, which reads equivalently to a case of a NoSuchObjectException from us, rather than throwing a JDOException when there was an underlying db issue. If this is the same issue and we have a trace of where that happens, this solves a lot more for us, hopefully.&lt;/p&gt;</comment>
                            <comment id="15006999" author="sushanth" created="Mon, 16 Nov 2015 17:53:59 +0000"  >&lt;p&gt;A couple of other gardening notes:&lt;/p&gt;

&lt;p&gt;+cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt;/&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt; as they would also be interested in this issue.&lt;/p&gt;

&lt;p&gt;Also, I removed the fix-version of 1.2.1 from this bug, fix version is marked by a committer to denote what versions a patch has already been patched into. Target version is the field used to request what version the requestor wants the patch to go into, and for that, it must be unreleased versions. Thus, since 1.2.1 has already been released, I&apos;ve updated Target version to 1.2.2.&lt;/p&gt;</comment>
                            <comment id="15007081" author="sershe" created="Mon, 16 Nov 2015 18:37:04 +0000"  >&lt;p&gt;DN version should be upgraded in 2.0 and 1.3 too if upgrading in 1.2.2. Also the release note is needed. &lt;br/&gt;
Otherwise this makes sense to me.&lt;/p&gt;</comment>
                            <comment id="15007158" author="hiveqa" created="Mon, 16 Nov 2015 19:21:34 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12772479/HIVE-6113.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12772479/HIVE-6113.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to no test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 898 failed/errored test(s), 5641 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestFilterHooks - did not produce a TEST-*.xml file
TestHS2ImpersonationWithRemoteMS - did not produce a TEST-*.xml file
TestHWISessionManager - did not produce a TEST-*.xml file
TestMetastoreAuthorizationProvider - did not produce a TEST-*.xml file
TestPartitionNameWhitelistValidation - did not produce a TEST-*.xml file
TestRemoteHiveMetaStore - did not produce a TEST-*.xml file
TestSetUGIOnBothClientServer - did not produce a TEST-*.xml file
TestSetUGIOnOnlyClient - did not produce a TEST-*.xml file
TestSetUGIOnOnlyServer - did not produce a TEST-*.xml file
TestStorageBasedMetastoreAuthorizationDrops - did not produce a TEST-*.xml file
TestStorageBasedMetastoreAuthorizationReads - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.initializationError
org.apache.hadoop.hive.cli.TestCliDriverMethods.testProcessSelectDatabase
org.apache.hadoop.hive.cli.TestCliDriverMethods.testQuit
org.apache.hadoop.hive.cli.TestCliDriverMethods.testRun
org.apache.hadoop.hive.cli.TestCliDriverMethods.testprocessInitFiles
org.apache.hadoop.hive.cli.TestCliSessionState.testgetDbName
org.apache.hadoop.hive.cli.TestCompareCliDriver.initializationError
org.apache.hadoop.hive.cli.TestContribCliDriver.initializationError
org.apache.hadoop.hive.cli.TestContribNegativeCliDriver.initializationError
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.initializationError
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_external_table_ppd
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_binary_external_table_queries
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_binary_map_queries
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_binary_map_queries_prefix
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_binary_storage_queries
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_custom_key
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_custom_key2
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_custom_key3
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_handler_bulk
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_handler_snapshot
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_joins
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_null_first_col
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_ppd_join
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_ppd_key_range
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_pushdown
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_queries
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_scan_params
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_single_sourced_multi_insert
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_stats3
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_timestamp
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_timestamp_format
org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_ppd_key_ranges
org.apache.hadoop.hive.cli.TestHBaseMinimrCliDriver.testCliDriver_hbase_bulk
org.apache.hadoop.hive.cli.TestHBaseNegativeCliDriver.testCliDriver_cascade_dbdrop
org.apache.hadoop.hive.cli.TestHBaseNegativeCliDriver.testCliDriver_cascade_dbdrop_hadoop20
org.apache.hadoop.hive.cli.TestHBaseNegativeCliDriver.testCliDriver_generatehfiles_require_family_path
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.initializationError
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.initializationError
org.apache.hadoop.hive.cli.TestMinimrCliDriver.initializationError
org.apache.hadoop.hive.cli.TestNegativeCliDriver.initializationError
org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.initializationError
org.apache.hadoop.hive.cli.TestSparkCliDriver.initializationError
org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver.initializationError
org.apache.hadoop.hive.hooks.TestHs2Hooks.org.apache.hadoop.hive.hooks.TestHs2Hooks
org.apache.hadoop.hive.metastore.TestAdminUser.testCreateAdminNAddUser
org.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInEmbed.org.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInEmbed
org.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testCreateRole
org.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testDropRole
org.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testGetPrivSet
org.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testGrantPriv
org.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testGrantRole
org.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testListPriv
org.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testListRoles
org.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testRevokePriv
org.apache.hadoop.hive.metastore.TestAuthzApiEmbedAuthorizerInRemote.testRevokeRole
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testAlterPartition
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testAlterTable
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testAlterViewParititon
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testColumnStatistics
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testComplexTable
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testComplexTypeApi
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testConcurrentMetastores
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testDBOwner
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testDBOwnerChange
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testDatabase
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testDatabaseLocation
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testDatabaseLocationWithPermissionProblems
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testDropTable
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testFilterLastPartition
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testFilterSinglePartition
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testFunctionWithResources
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testGetConfigValue
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testGetTableObjects
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testListPartitionNames
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testListPartitions
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testNameMethods
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testPartition
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testPartitionFilter
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testRenamePartition
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testRetriableClientWithConnLifetime
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testSimpleFunction
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testSimpleTable
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testSimpleTypeApi
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testStatsFastTrivial
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testSynchronized
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testTableDatabase
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testTableFilter
org.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testValidateTableCols
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testAddPartitions
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testFetchingPartitionsWithDifferentSchemas
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testGetPartitionSpecs_WithAndWithoutPartitionGrouping
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTimeout.org.apache.hadoop.hive.metastore.TestHiveMetaStoreTimeout
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.stringifyValidTxns
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testLocks
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testLocksWithTxn
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testOpenTxnNotExcluded
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testTxnRange
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testTxns
org.apache.hadoop.hive.metastore.TestHiveMetaStoreWithEnvironmentContext.testEnvironmentContext
org.apache.hadoop.hive.metastore.TestHiveMetaTool.testExecuteJDOQL
org.apache.hadoop.hive.metastore.TestHiveMetaTool.testListFSRoot
org.apache.hadoop.hive.metastore.TestHiveMetaTool.testUpdateFSRootLocation
org.apache.hadoop.hive.metastore.TestMarkPartition.testMarkingPartitionSet
org.apache.hadoop.hive.metastore.TestMarkPartitionRemote.testMarkingPartitionSet
org.apache.hadoop.hive.metastore.TestMetaStoreAuthorization.testMetaStoreAuthorization
org.apache.hadoop.hive.metastore.TestMetaStoreEndFunctionListener.testEndFunctionListener
org.apache.hadoop.hive.metastore.TestMetaStoreEventListener.testListener
org.apache.hadoop.hive.metastore.TestMetaStoreEventListenerOnlyOnCommit.testEventStatus
org.apache.hadoop.hive.metastore.TestMetaStoreListenersError.testEventListenerException
org.apache.hadoop.hive.metastore.TestMetaStoreMetrics.testConnections
org.apache.hadoop.hive.metastore.TestMetaStoreMetrics.testMetricsFile
org.apache.hadoop.hive.metastore.TestMetastoreExpr.testPartitionExpr
org.apache.hadoop.hive.metastore.TestMetastoreVersion.testMetastoreVersion
org.apache.hadoop.hive.metastore.TestMetastoreVersion.testVersionMatching
org.apache.hadoop.hive.metastore.TestMetastoreVersion.testVersionMisMatch
org.apache.hadoop.hive.metastore.TestMetastoreVersion.testVersionRestriction
org.apache.hadoop.hive.metastore.TestObjectStore.testDatabaseOps
org.apache.hadoop.hive.metastore.TestObjectStore.testMasterKeyOps
org.apache.hadoop.hive.metastore.TestObjectStore.testPartitionOps
org.apache.hadoop.hive.metastore.TestObjectStore.testRoleOps
org.apache.hadoop.hive.metastore.TestObjectStore.testTableOps
org.apache.hadoop.hive.metastore.TestRemoteHiveMetaStoreIpAddress.testIpAddress
org.apache.hadoop.hive.metastore.TestRemoteUGIHiveMetaStoreIpAddress.testIpAddress
org.apache.hadoop.hive.metastore.TestRetryingHMSHandler.testRetryingHMSHandler
org.apache.hadoop.hive.metastore.hbase.TestHBaseImport.org.apache.hadoop.hive.metastore.hbase.TestHBaseImport
org.apache.hadoop.hive.metastore.txn.TestCompactionTxnHandler.testRevokeTimedOutWorkers
org.apache.hadoop.hive.ql.TestCreateUdfEntities.testUdfWithDfsResource
org.apache.hadoop.hive.ql.TestCreateUdfEntities.testUdfWithLocalResource
org.apache.hadoop.hive.ql.TestDDLWithRemoteMetastoreSecondNamenode.testCreateDatabaseWithTableNonDefaultNameNode
org.apache.hadoop.hive.ql.TestDDLWithRemoteMetastoreSecondNamenode.testCreateTableWithIndexAndPartitionsNonDefaultNameNode
org.apache.hadoop.hive.ql.TestLocationQueries.testAlterTablePartitionLocation_alter5
org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1
org.apache.hadoop.hive.ql.TestTxnCommands.exchangePartition
org.apache.hadoop.hive.ql.TestTxnCommands.testDelete
org.apache.hadoop.hive.ql.TestTxnCommands.testDeleteIn
org.apache.hadoop.hive.ql.TestTxnCommands.testErrors
org.apache.hadoop.hive.ql.TestTxnCommands.testExplicitRollback
org.apache.hadoop.hive.ql.TestTxnCommands.testImplicitRollback
org.apache.hadoop.hive.ql.TestTxnCommands.testInsertOverwrite
org.apache.hadoop.hive.ql.TestTxnCommands.testMultipleDelete
org.apache.hadoop.hive.ql.TestTxnCommands.testMultipleInserts
org.apache.hadoop.hive.ql.TestTxnCommands.testReadMyOwnInsert
org.apache.hadoop.hive.ql.TestTxnCommands.testSimpleAcidInsert
org.apache.hadoop.hive.ql.TestTxnCommands.testTimeOutReaper
org.apache.hadoop.hive.ql.TestTxnCommands.testUpdateDeleteOfInserts
org.apache.hadoop.hive.ql.TestTxnCommands.testUpdateOfInserts
org.apache.hadoop.hive.ql.TestTxnCommands2.testBucketizedInputFormat
org.apache.hadoop.hive.ql.TestTxnCommands2.testDeleteIn
org.apache.hadoop.hive.ql.TestTxnCommands2.testInsertOverwriteWithSelfJoin
org.apache.hadoop.hive.ql.TestTxnCommands2.testOrcNoPPD
org.apache.hadoop.hive.ql.TestTxnCommands2.testOrcPPD
org.apache.hadoop.hive.ql.TestTxnCommands2.testUpdateMixedCase
org.apache.hadoop.hive.ql.exec.TestExecDriver.initializationError
org.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testCommonClass
org.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testCommonClassComparison
org.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testCommonClassUnionAll
org.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testGetMethodInternal
org.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testGetTypeInfoForPrimitiveCategory
org.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testImplicitConversion
org.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testImpliesOrder
org.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testIsRankingFunction
org.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testPrintTypeCompatibility
org.apache.hadoop.hive.ql.exec.TestFunctionRegistry.testTypeAffinity
org.apache.hadoop.hive.ql.exec.TestOperators.testFetchOperatorContext
org.apache.hadoop.hive.ql.exec.TestOperators.testScriptOperator
org.apache.hadoop.hive.ql.exec.TestUtilities.testgetDbTableName
org.apache.hadoop.hive.ql.exec.tez.TestTezTask.testBuildDag
org.apache.hadoop.hive.ql.exec.tez.TestTezTask.testClose
org.apache.hadoop.hive.ql.exec.tez.TestTezTask.testEmptyWork
org.apache.hadoop.hive.ql.exec.tez.TestTezTask.testExistingSessionGetsStorageHandlerResources
org.apache.hadoop.hive.ql.exec.tez.TestTezTask.testExtraResourcesAddedToDag
org.apache.hadoop.hive.ql.exec.tez.TestTezTask.testGetExtraLocalResources
org.apache.hadoop.hive.ql.exec.tez.TestTezTask.testSubmit
org.apache.hadoop.hive.ql.history.TestHiveHistory.testHiveHistoryConfigDisabled
org.apache.hadoop.hive.ql.history.TestHiveHistory.testHiveHistoryConfigEnabled
org.apache.hadoop.hive.ql.history.TestHiveHistory.testQueryloglocParentDirNotExist
org.apache.hadoop.hive.ql.history.TestHiveHistory.testSimpleQuery
org.apache.hadoop.hive.ql.hooks.TestHooks.org.apache.hadoop.hive.ql.hooks.TestHooks
org.apache.hadoop.hive.ql.io.TestSymlinkTextInputFormat.testCombine
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.concurrencyFalse
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testDDLExclusive
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testDDLNoLock
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testDDLShared
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testDelete
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testExceptions
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testJoin
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testReadWrite
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testRollback
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testSingleReadMultiPartition
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testSingleReadPartition
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testSingleReadTable
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testSingleWritePartition
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testSingleWriteTable
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testUpdate
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager.testWriteDynamicPartition
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.basicBlocking
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.createTable
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.insertOverwriteCreate
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.insertOverwritePartitionedCreate
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.lockConflictDbTable
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.updateSelectUpdate
org.apache.hadoop.hive.ql.lockmgr.TestDummyTxnManager.testDedupLockObjects
org.apache.hadoop.hive.ql.lockmgr.TestDummyTxnManager.testSingleReadTable
org.apache.hadoop.hive.ql.metadata.TestHive.testAutoPurgeTablesAndPartitions
org.apache.hadoop.hive.ql.metadata.TestHive.testDropPartitionsWithPurge
org.apache.hadoop.hive.ql.metadata.TestHive.testDropTableTrash
org.apache.hadoop.hive.ql.metadata.TestHive.testGetAndDropTables
org.apache.hadoop.hive.ql.metadata.TestHive.testHiveCloseCurrent
org.apache.hadoop.hive.ql.metadata.TestHive.testHiveRefreshOnConfChange
org.apache.hadoop.hive.ql.metadata.TestHive.testIndex
org.apache.hadoop.hive.ql.metadata.TestHive.testMetaStoreApiTiming
org.apache.hadoop.hive.ql.metadata.TestHive.testPartition
org.apache.hadoop.hive.ql.metadata.TestHive.testTable
org.apache.hadoop.hive.ql.metadata.TestHive.testThriftTable
org.apache.hadoop.hive.ql.metadata.TestHiveMetaStoreChecker.testDataDeletion
org.apache.hadoop.hive.ql.metadata.TestHiveMetaStoreChecker.testPartitionsCheck
org.apache.hadoop.hive.ql.metadata.TestHiveMetaStoreChecker.testTableCheck
org.apache.hadoop.hive.ql.metadata.TestHiveRemote.testAutoPurgeTablesAndPartitions
org.apache.hadoop.hive.ql.metadata.TestHiveRemote.testDropPartitionsWithPurge
org.apache.hadoop.hive.ql.metadata.TestHiveRemote.testDropTableTrash
org.apache.hadoop.hive.ql.metadata.TestHiveRemote.testGetAndDropTables
org.apache.hadoop.hive.ql.metadata.TestHiveRemote.testHiveCloseCurrent
org.apache.hadoop.hive.ql.metadata.TestHiveRemote.testHiveRefreshOnConfChange
org.apache.hadoop.hive.ql.metadata.TestHiveRemote.testIndex
org.apache.hadoop.hive.ql.metadata.TestHiveRemote.testMetaStoreApiTiming
org.apache.hadoop.hive.ql.metadata.TestHiveRemote.testPartition
org.apache.hadoop.hive.ql.metadata.TestHiveRemote.testTable
org.apache.hadoop.hive.ql.metadata.TestHiveRemote.testThriftTable
org.apache.hadoop.hive.ql.metadata.TestSemanticAnalyzerHookLoading.testHookLoading
org.apache.hadoop.hive.ql.parse.TestColumnAccess.org.apache.hadoop.hive.ql.parse.TestColumnAccess
org.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType
org.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType1
org.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType2
org.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType3
org.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType4
org.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType5
org.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType6
org.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType7
org.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType8
org.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType9
org.apache.hadoop.hive.ql.parse.TestIUD.org.apache.hadoop.hive.ql.parse.TestIUD
org.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testCannotUseReservedWordAsName
org.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacro
org.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacroDoesNotExist
org.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacroExistsDoNotIgnoreErrors
org.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacroNonExistent
org.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacroNonExistentWithIfExists
org.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testDropMacroNonExistentWithIfExistsDoNotIgnoreNonExistent
org.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testNoBody
org.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testOneInputParamters
org.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testOneUnusedParameterName
org.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testThreeDuplicateParameters
org.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testThreeInputParamters
org.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testTwoDuplicateParameterNames
org.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testTwoInputParamters
org.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testTwoUnusedParameterNames
org.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testUnknownInputParameter
org.apache.hadoop.hive.ql.parse.TestMacroSemanticAnalyzer.testZeroInputParamters
org.apache.hadoop.hive.ql.parse.TestParseNegative.initializationError
org.apache.hadoop.hive.ql.parse.TestQBCompact.org.apache.hadoop.hive.ql.parse.TestQBCompact
org.apache.hadoop.hive.ql.parse.TestQBJoinTreeApplyPredicate.org.apache.hadoop.hive.ql.parse.TestQBJoinTreeApplyPredicate
org.apache.hadoop.hive.ql.parse.TestQBSubQuery.org.apache.hadoop.hive.ql.parse.TestQBSubQuery
org.apache.hadoop.hive.ql.parse.TestSQL11ReservedKeyWordsNegative.org.apache.hadoop.hive.ql.parse.TestSQL11ReservedKeyWordsNegative
org.apache.hadoop.hive.ql.parse.TestSQL11ReservedKeyWordsPositive.org.apache.hadoop.hive.ql.parse.TestSQL11ReservedKeyWordsPositive
org.apache.hadoop.hive.ql.parse.TestUnpermittedCharsInColumnNameCreateTableNegative.org.apache.hadoop.hive.ql.parse.TestUnpermittedCharsInColumnNameCreateTableNegative
org.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteAllNonPartitioned
org.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteAllPartitioned
org.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteAllWherePartitioned
org.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteOnePartition
org.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteOnePartitionWhere
org.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testDeleteWhereNoPartition
org.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testInsertSelect
org.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testInsertValues
org.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testInsertValuesPartitioned
org.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateAllNonPartitioned
org.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateAllNonPartitionedWhere
org.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateAllPartitioned
org.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateAllPartitionedWhere
org.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateOnePartition
org.apache.hadoop.hive.ql.parse.TestUpdateDeleteSemanticAnalyzer.testUpdateOnePartitionWhere
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testCreateRole
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testDropRole
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testGrantGroupTable
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testGrantRoleGroup
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testGrantRoleRole
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testGrantRoleTable
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testGrantRoleUser
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testGrantServer
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testGrantUri
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testGrantUserTable
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testRevokeGroupTable
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testRevokeRoleGroup
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testRevokeRoleRole
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testRevokeRoleTable
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testRevokeRoleUser
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testRevokeUserTable
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testShowGrantGroupOnTable
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testShowGrantRoleOnTable
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testShowGrantUserOnTable
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testShowRoleGrantGroup
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testShowRoleGrantRole
org.apache.hadoop.hive.ql.parse.authorization.TestHiveAuthorizationTaskFactory.testShowRoleGrantUser
org.apache.hadoop.hive.ql.parse.authorization.TestPrivilegesV1.testPrivInGrant
org.apache.hadoop.hive.ql.parse.authorization.TestPrivilegesV1.testPrivInGrantNotAccepted
org.apache.hadoop.hive.ql.parse.authorization.TestPrivilegesV2.testPrivInGrant
org.apache.hadoop.hive.ql.parse.positive.TestTransactionStatement.org.apache.hadoop.hive.ql.parse.positive.TestTransactionStatement
org.apache.hadoop.hive.ql.plan.TestReadEntityDirect.org.apache.hadoop.hive.ql.plan.TestReadEntityDirect
org.apache.hadoop.hive.ql.plan.TestViewEntity.org.apache.hadoop.hive.ql.plan.TestViewEntity
org.apache.hadoop.hive.ql.processors.TestCommandProcessorFactory.testAvailableCommands
org.apache.hadoop.hive.ql.processors.TestSetProcessor.testHiddenConfig
org.apache.hadoop.hive.ql.security.TestAuthorizationPreEventListener.testListener
org.apache.hadoop.hive.ql.security.TestClientSideAuthorizationProvider.testSimplePrivileges
org.apache.hadoop.hive.ql.security.TestExtendedAcls.org.apache.hadoop.hive.ql.security.TestExtendedAcls
org.apache.hadoop.hive.ql.security.TestFolderPermissions.org.apache.hadoop.hive.ql.security.TestFolderPermissions
org.apache.hadoop.hive.ql.security.TestMultiAuthorizationPreEventListener.testMultipleAuthorizationListners
org.apache.hadoop.hive.ql.security.TestStorageBasedClientSideAuthorizationProvider.testSimplePrivileges
org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProvider.testSimplePrivileges
org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProviderWithACL.testSimplePrivileges
org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerCheckInvocation.org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerCheckInvocation
org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters.org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerShowFilters
org.apache.hadoop.hive.ql.session.TestAddResource.testDeleteJar
org.apache.hadoop.hive.ql.session.TestAddResource.testDeleteJarMultiple
org.apache.hadoop.hive.ql.session.TestAddResource.testDuplicateAdds
org.apache.hadoop.hive.ql.session.TestAddResource.testSanity
org.apache.hadoop.hive.ql.session.TestAddResource.testUnion
org.apache.hadoop.hive.ql.session.TestSessionState.testClassLoaderEquality[0]
org.apache.hadoop.hive.ql.session.TestSessionState.testClassLoaderEquality[1]
org.apache.hadoop.hive.ql.session.TestSessionState.testClose[0]
org.apache.hadoop.hive.ql.session.TestSessionState.testClose[1]
org.apache.hadoop.hive.ql.session.TestSessionState.testReloadAuxJars2[0]
org.apache.hadoop.hive.ql.session.TestSessionState.testReloadAuxJars2[1]
org.apache.hadoop.hive.ql.session.TestSessionState.testReloadExistingAuxJars2[0]
org.apache.hadoop.hive.ql.session.TestSessionState.testReloadExistingAuxJars2[1]
org.apache.hadoop.hive.ql.session.TestSessionState.testgetDbName[0]
org.apache.hadoop.hive.ql.session.TestSessionState.testgetDbName[1]
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner.blockedByLockPartition
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner.blockedByLockTable
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner.cleanupAfterMajorPartitionCompaction
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner.cleanupAfterMajorPartitionCompactionNoBase
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner.cleanupAfterMajorTableCompaction
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner.cleanupAfterMinorPartitionCompaction
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner.cleanupAfterMinorTableCompaction
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner.droppedPartition
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner.droppedTable
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner.notBlockedBySubsequentLock
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner.nothing
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner.partitionNotBlockedBySubsequentLock
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.blockedByLockPartition
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.blockedByLockTable
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.cleanupAfterMajorPartitionCompaction
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.cleanupAfterMajorPartitionCompactionNoBase
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.cleanupAfterMajorTableCompaction
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.cleanupAfterMinorPartitionCompaction
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.cleanupAfterMinorTableCompaction
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.droppedPartition
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.droppedTable
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.notBlockedBySubsequentLock
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.nothing
org.apache.hadoop.hive.ql.txn.compactor.TestCleaner2.partitionNotBlockedBySubsequentLock
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningDelete
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningInsert
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.dynamicPartitioningUpdate
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactAfterAbort
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.majorCompactWhileStreaming
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactAfterAbort
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.minorCompactWhileStreaming
org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.testStatsAfterCompactionPartTbl
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.chooseMajorOverMinorWhenBothValid
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.cleanEmptyAbortedTxns
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.compactPartitionHighDeltaPct
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.compactPartitionTooManyDeltas
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.compactTableHighDeltaPct
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.compactTableTooManyDeltas
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.dropPartition
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.dropTable
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.enoughDeltasNoBase
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.majorCompactOnPartitionTooManyAborts
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.majorCompactOnTableTooManyAborts
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactOnManyDifferentPartitionAborts
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactTableDeltaPctNotHighEnough
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactTableDynamicPartitioning
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactTableNotEnoughDeltas
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactWhenCompactAlreadyScheduled
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactWhenNoCompactSet
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.noCompactWhenNoCompactSetLowerCase
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.nothing
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.recoverFailedLocalWorkers
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.recoverFailedRemoteWorkers
org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.twoTxnsOnSamePartitionGenerateOneCompactionRequest
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.droppedPartition
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.droppedTable
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.inputSplit
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.inputSplitNullBase
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorNoBaseLotsOfDeltas
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorPartitionWithBase
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorPartitionWithBaseMissingBuckets
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableLegacy
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableNoBase
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableWithBase
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorWithAborted
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorWithOpenInMiddle
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorNoBaseLotsOfDeltas
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorPartitionWithBase
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableLegacy
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableNoBase
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableWithBase
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorWithAborted
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorWithOpenInMiddle
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.nothing
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.sortedPartition
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.sortedTable
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.stringableList
org.apache.hadoop.hive.ql.txn.compactor.TestWorker.stringableMap
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.droppedPartition
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.droppedTable
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.inputSplit
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.inputSplitNullBase
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorNoBaseLotsOfDeltas
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorPartitionWithBase
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorPartitionWithBaseMissingBuckets
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorTableLegacy
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorTableNoBase
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorTableWithBase
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorWithAborted
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.majorWithOpenInMiddle
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorNoBaseLotsOfDeltas
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorPartitionWithBase
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorTableLegacy
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorTableNoBase
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorTableWithBase
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorWithAborted
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.minorWithOpenInMiddle
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.nothing
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.sortedPartition
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.sortedTable
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.stringableList
org.apache.hadoop.hive.ql.txn.compactor.TestWorker2.stringableMap
org.apache.hadoop.hive.thrift.TestDBTokenStore.testDBTokenStore
org.apache.hadoop.hive.thrift.TestHadoopAuthBridge23.testMetastoreProxyUser
org.apache.hadoop.hive.thrift.TestHadoopAuthBridge23.testSaslWithHiveMetaStore
org.apache.hive.beeline.TestBeeLineWithArgs.org.apache.hive.beeline.TestBeeLineWithArgs
org.apache.hive.beeline.cli.TestHiveCli.testCmd
org.apache.hive.beeline.cli.TestHiveCli.testDatabaseOptions
org.apache.hive.beeline.cli.TestHiveCli.testErrOutput
org.apache.hive.beeline.cli.TestHiveCli.testHelp
org.apache.hive.beeline.cli.TestHiveCli.testInValidCmd
org.apache.hive.beeline.cli.TestHiveCli.testInvalidDatabaseOptions
org.apache.hive.beeline.cli.TestHiveCli.testInvalidOptions
org.apache.hive.beeline.cli.TestHiveCli.testInvalidOptions2
org.apache.hive.beeline.cli.TestHiveCli.testNoErrorDB
org.apache.hive.beeline.cli.TestHiveCli.testSetHeaderValue
org.apache.hive.beeline.cli.TestHiveCli.testSetPromptValue
org.apache.hive.beeline.cli.TestHiveCli.testSourceCmd
org.apache.hive.beeline.cli.TestHiveCli.testSourceCmd2
org.apache.hive.beeline.cli.TestHiveCli.testSourceCmd3
org.apache.hive.beeline.cli.TestHiveCli.testSqlFromCmd
org.apache.hive.beeline.cli.TestHiveCli.testSqlFromCmdWithDBName
org.apache.hive.beeline.cli.TestHiveCli.testUseCurrentDB1
org.apache.hive.beeline.cli.TestHiveCli.testUseCurrentDB2
org.apache.hive.beeline.cli.TestHiveCli.testUseCurrentDB3
org.apache.hive.beeline.cli.TestHiveCli.testUseInvalidDB
org.apache.hive.beeline.cli.TestHiveCli.testVariables
org.apache.hive.beeline.cli.TestHiveCli.testVariablesForSource
org.apache.hive.hcatalog.api.TestHCatClient.testBasicDDLCommands
org.apache.hive.hcatalog.api.TestHCatClient.testCreateTableLike
org.apache.hive.hcatalog.api.TestHCatClient.testDatabaseLocation
org.apache.hive.hcatalog.api.TestHCatClient.testDropPartitionsWithPartialSpec
org.apache.hive.hcatalog.api.TestHCatClient.testDropTableException
org.apache.hive.hcatalog.api.TestHCatClient.testEmptyTableInstantiation
org.apache.hive.hcatalog.api.TestHCatClient.testGetMessageBusTopicName
org.apache.hive.hcatalog.api.TestHCatClient.testGetPartitionsWithPartialSpec
org.apache.hive.hcatalog.api.TestHCatClient.testObjectNotFoundException
org.apache.hive.hcatalog.api.TestHCatClient.testOtherFailure
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSchema
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionsHCatClientImpl
org.apache.hive.hcatalog.api.TestHCatClient.testRenameTable
org.apache.hive.hcatalog.api.TestHCatClient.testReplicationTaskIter
org.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation
org.apache.hive.hcatalog.api.TestHCatClient.testTransportFailure
org.apache.hive.hcatalog.api.TestHCatClient.testUpdateTableSchema
org.apache.hive.hcatalog.api.TestHCatClientNotification.org.apache.hive.hcatalog.api.TestHCatClientNotification
org.apache.hive.hcatalog.api.repl.TestReplicationTask.testCreate
org.apache.hive.hcatalog.api.repl.commands.TestCommands.testBasicReplEximCommands
org.apache.hive.hcatalog.api.repl.commands.TestCommands.testDropDatabaseCommand
org.apache.hive.hcatalog.api.repl.commands.TestCommands.testDropPartitionCommand
org.apache.hive.hcatalog.api.repl.commands.TestCommands.testDropTableCommand
org.apache.hive.hcatalog.api.repl.commands.TestCommands.testDropTableCommand2
org.apache.hive.hcatalog.api.repl.commands.TestCommands.testMetadataReplEximCommands
org.apache.hive.hcatalog.api.repl.commands.TestCommands.testNoopReplEximCommands
org.apache.hive.hcatalog.api.repl.exim.TestEximReplicationTasks.org.apache.hive.hcatalog.api.repl.exim.TestEximReplicationTasks
org.apache.hive.hcatalog.cli.SemanticAnalysis.TestHCatAuthUtil.authDisabled
org.apache.hive.hcatalog.cli.SemanticAnalysis.TestHCatAuthUtil.authEnabledV1Auth
org.apache.hive.hcatalog.cli.SemanticAnalysis.TestHCatAuthUtil.authEnabledV2Auth
org.apache.hive.hcatalog.cli.TestPermsGrp.testCustomPerms
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testAddDriverInfo
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testAddPartFail
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testAddPartPass
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testAddReplaceCols
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testAlterTableSetFF
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testAlterTblClusteredBy
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testAlterTblFFpart
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testAlterTblTouch
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testCTAS
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testCTLFail
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testCTLPass
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testChangeColumns
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testCreateTableIfNotExists
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testCreateTblWithLowerCasePartNames
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testDatabaseOperations
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testDescDB
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testInvalidateClusteredBy
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testInvalidateNonStringPartition
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testInvalidateSeqFileStoredAs
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testInvalidateTextFileStoredAs
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testStoredAs
org.apache.hive.hcatalog.cli.TestSemanticAnalysis.testUsNonExistentDB
org.apache.hive.hcatalog.cli.TestUseDatabase.testAlterTablePass
org.apache.hive.hcatalog.common.TestHiveClientCache.testCacheExpiry
org.apache.hive.hcatalog.common.TestHiveClientCache.testCacheHit
org.apache.hive.hcatalog.common.TestHiveClientCache.testCacheMiss
org.apache.hive.hcatalog.common.TestHiveClientCache.testCloseAllClients
org.apache.hive.hcatalog.common.TestHiveClientCache.testMultipleThreadAccess
org.apache.hive.hcatalog.data.TestReaderWriter.test
org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler.org.apache.hive.hcatalog.hbase.TestPigHBaseStorageHandler
org.apache.hive.hcatalog.listener.TestDbNotificationListener.org.apache.hive.hcatalog.listener.TestDbNotificationListener
org.apache.hive.hcatalog.listener.TestMsgBusConnection.testConnection
org.apache.hive.hcatalog.listener.TestNotificationListener.testAMQListener
org.apache.hive.hcatalog.mapreduce.TestHCatDynamicPartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatDynamicPartitioned
org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned
org.apache.hive.hcatalog.mapreduce.TestHCatExternalNonPartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatExternalNonPartitioned
org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned
org.apache.hive.hcatalog.mapreduce.TestHCatHiveCompatibility.testPartedRead
org.apache.hive.hcatalog.mapreduce.TestHCatHiveCompatibility.testUnpartedReadWrite
org.apache.hive.hcatalog.mapreduce.TestHCatHiveThriftCompatibility.testDynamicCols
org.apache.hive.hcatalog.mapreduce.TestHCatInputFormat.testBadRecordHandlingFails
org.apache.hive.hcatalog.mapreduce.TestHCatInputFormat.testBadRecordHandlingPasses
org.apache.hive.hcatalog.mapreduce.TestHCatInputFormatMethods.testGetPartitionAndDataColumns
org.apache.hive.hcatalog.mapreduce.TestHCatMultiOutputFormat.org.apache.hive.hcatalog.mapreduce.TestHCatMultiOutputFormat
org.apache.hive.hcatalog.mapreduce.TestHCatMutableDynamicPartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatMutableDynamicPartitioned
org.apache.hive.hcatalog.mapreduce.TestHCatMutableNonPartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatMutableNonPartitioned
org.apache.hive.hcatalog.mapreduce.TestHCatMutablePartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatMutablePartitioned
org.apache.hive.hcatalog.mapreduce.TestHCatNonPartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatNonPartitioned
org.apache.hive.hcatalog.mapreduce.TestHCatOutputFormat.testSetOutput
org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish.testPartitionPublish
org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned
org.apache.hive.hcatalog.mapreduce.TestInputJobInfo.test4ArgCreate
org.apache.hive.hcatalog.mapreduce.TestPassProperties.testSequenceTableWriteReadMR
org.apache.hive.hcatalog.mapreduce.TestSequenceFileReadWrite.testSequenceTableWriteRead
org.apache.hive.hcatalog.mapreduce.TestSequenceFileReadWrite.testSequenceTableWriteReadMR
org.apache.hive.hcatalog.mapreduce.TestSequenceFileReadWrite.testTextTableWriteRead
org.apache.hive.hcatalog.mapreduce.TestSequenceFileReadWrite.testTextTableWriteReadMR
org.apache.hive.hcatalog.pig.TestE2EScenarios.testReadOrcAndRCFromPig
org.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown2[0]
org.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown2[1]
org.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown2[2]
org.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown2[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown2[4]
org.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown2[5]
org.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown[0]
org.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown[1]
org.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown[2]
org.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown[4]
org.apache.hive.hcatalog.pig.TestHCatLoader.testColumnarStorePushdown[5]
org.apache.hive.hcatalog.pig.TestHCatLoader.testConvertBooleanToInt[0]
org.apache.hive.hcatalog.pig.TestHCatLoader.testConvertBooleanToInt[1]
org.apache.hive.hcatalog.pig.TestHCatLoader.testConvertBooleanToInt[2]
org.apache.hive.hcatalog.pig.TestHCatLoader.testConvertBooleanToInt[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testConvertBooleanToInt[4]
org.apache.hive.hcatalog.pig.TestHCatLoader.testConvertBooleanToInt[5]
org.apache.hive.hcatalog.pig.TestHCatLoader.testGetInputBytes[0]
org.apache.hive.hcatalog.pig.TestHCatLoader.testGetInputBytes[1]
org.apache.hive.hcatalog.pig.TestHCatLoader.testGetInputBytes[2]
org.apache.hive.hcatalog.pig.TestHCatLoader.testGetInputBytes[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testGetInputBytes[4]
org.apache.hive.hcatalog.pig.TestHCatLoader.testGetInputBytes[5]
org.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic[0]
org.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic[1]
org.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic[2]
org.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic[4]
org.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic[5]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataBasic[0]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataBasic[1]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataBasic[2]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataBasic[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataBasic[4]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataBasic[5]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataPrimitiveTypes[0]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataPrimitiveTypes[1]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataPrimitiveTypes[2]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataPrimitiveTypes[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataPrimitiveTypes[4]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadDataPrimitiveTypes[5]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic[0]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic[1]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic[2]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic[4]
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic[5]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadBasic[0]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadBasic[1]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadBasic[2]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadBasic[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadBasic[4]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadBasic[5]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadComplex[0]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadComplex[1]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadComplex[2]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadComplex[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadComplex[4]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadComplex[5]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadPrimitiveTypes[0]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadPrimitiveTypes[1]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadPrimitiveTypes[2]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadPrimitiveTypes[3]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadPrimitiveTypes[4]
org.apache.hive.hcatalog.pig.TestHCatLoader.testSchemaLoadPrimitiveTypes[5]
org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema
org.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByHCatMR[0]
org.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByHCatMR[1]
org.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByHCatMR[2]
org.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByHCatMR[3]
org.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByHCatMR[4]
org.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByHCatMR[5]
org.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByPig[0]
org.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByPig[1]
org.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByPig[2]
org.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByPig[3]
org.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByPig[4]
org.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.testReadDataFromEncryptedHiveTableByPig[5]
org.apache.hive.hcatalog.pig.TestHCatLoaderStorer.testReadWrite
org.apache.hive.hcatalog.pig.TestHCatLoaderStorer.testSmallTinyInt
org.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testBagNStruct[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDateCharTypes[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDateCharTypes[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDateCharTypes[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDateCharTypes[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDateCharTypes[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDateCharTypes[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataNoSpec[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataNoSpec[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataNoSpec[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataNoSpec[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataNoSpec[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataNoSpec[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataPartialSpec[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataPartialSpec[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataPartialSpec[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataPartialSpec[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataPartialSpec[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsInDataPartialSpec[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsNoDataInDataNoSpec[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsNoDataInDataNoSpec[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsNoDataInDataNoSpec[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsNoDataInDataNoSpec[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsNoDataInDataNoSpec[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testDynamicPartitioningMultiPartColsNoDataInDataNoSpec[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testEmptyStore[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testEmptyStore[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testEmptyStore[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testEmptyStore[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testEmptyStore[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testEmptyStore[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testMultiPartColsInData[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testMultiPartColsInData[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testMultiPartColsInData[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testMultiPartColsInData[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testMultiPartColsInData[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testMultiPartColsInData[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testNoAlias[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testNoAlias[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testNoAlias[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testNoAlias[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testNoAlias[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testNoAlias[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testPartColsInData[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testPartColsInData[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testPartColsInData[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testPartColsInData[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testPartColsInData[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testPartColsInData[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testPartitionPublish[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testPartitionPublish[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testPartitionPublish[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testPartitionPublish[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testPartitionPublish[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testPartitionPublish[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncAllSimpleTypes[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncAllSimpleTypes[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncAllSimpleTypes[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncAllSimpleTypes[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncAllSimpleTypes[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncAllSimpleTypes[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncSimple[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncSimple[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncSimple[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncSimple[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncSimple[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreFuncSimple[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreInPartiitonedTbl[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreInPartiitonedTbl[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreInPartiitonedTbl[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreInPartiitonedTbl[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreInPartiitonedTbl[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreInPartiitonedTbl[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreMultiTables[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreMultiTables[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreMultiTables[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreMultiTables[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreMultiTables[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreMultiTables[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoCtorArgs[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoCtorArgs[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoCtorArgs[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoCtorArgs[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoCtorArgs[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoCtorArgs[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoSchema[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoSchema[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoSchema[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoSchema[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoSchema[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testStoreWithNoSchema[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteChar[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteChar[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteChar[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteChar[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteChar[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteChar[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate2[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate2[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate2[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate2[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate2[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate2[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate3[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate3[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate3[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate3[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate3[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate3[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDate[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalXY[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalXY[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalXY[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalXY[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalXY[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalXY[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalX[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalX[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalX[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalX[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalX[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimalX[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimal[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimal[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimal[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimal[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimal[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteDecimal[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteSmallint[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteSmallint[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteSmallint[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteSmallint[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteSmallint[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteSmallint[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTimestamp[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTimestamp[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTimestamp[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTimestamp[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTimestamp[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTimestamp[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTinyint[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTinyint[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTinyint[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTinyint[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTinyint[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteTinyint[5]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteVarchar[0]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteVarchar[1]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteVarchar[2]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteVarchar[3]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteVarchar[4]
org.apache.hive.hcatalog.pig.TestHCatStorer.testWriteVarchar[5]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreBasicTable[0]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreBasicTable[1]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreBasicTable[2]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreBasicTable[3]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreBasicTable[5]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStorePartitionedTable[0]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStorePartitionedTable[1]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStorePartitionedTable[2]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStorePartitionedTable[3]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStorePartitionedTable[5]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreTableMulti[0]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreTableMulti[1]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreTableMulti[2]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreTableMulti[3]
org.apache.hive.hcatalog.pig.TestHCatStorerMulti.testStoreTableMulti[5]
org.apache.hive.hcatalog.pig.TestHCatStorerWrapper.testStoreExternalTableWithExternalDir
org.apache.hive.hcatalog.streaming.TestStreaming.testAddPartition
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketing
org.apache.hive.hcatalog.streaming.TestStreaming.testBucketingWhereBucketColIsNotFirstCol
org.apache.hive.hcatalog.streaming.TestStreaming.testConcurrentTransactionBatchCommits
org.apache.hive.hcatalog.streaming.TestStreaming.testEndpointConnection
org.apache.hive.hcatalog.streaming.TestStreaming.testHearbeat
org.apache.hive.hcatalog.streaming.TestStreaming.testInterleavedTransactionBatchCommits
org.apache.hive.hcatalog.streaming.TestStreaming.testMultipleTransactionBatchCommits
org.apache.hive.hcatalog.streaming.TestStreaming.testRemainingTransactions
org.apache.hive.hcatalog.streaming.TestStreaming.testStreamBucketingMatchesRegularBucketing
org.apache.hive.hcatalog.streaming.TestStreaming.testTableValidation
org.apache.hive.hcatalog.streaming.TestStreaming.testTimeOutReaper
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbort
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchAbortAndCommit
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Delimited
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchCommit_Json
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyAbort
org.apache.hive.hcatalog.streaming.TestStreaming.testTransactionBatchEmptyCommit
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testMulti
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchAbort
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitPartitioned
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchCommitUnpartitioned
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchEmptyAbortPartitioned
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchEmptyAbortUnartitioned
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchEmptyCommitPartitioned
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testTransactionBatchEmptyCommitUnpartitioned
org.apache.hive.hcatalog.streaming.mutate.TestMutations.testUpdatesAndDeletes
org.apache.hive.jdbc.TestJdbcDriver2.org.apache.hive.jdbc.TestJdbcDriver2
org.apache.hive.jdbc.TestJdbcWithLocalClusterSpark.org.apache.hive.jdbc.TestJdbcWithLocalClusterSpark
org.apache.hive.jdbc.TestJdbcWithMiniHS2.org.apache.hive.jdbc.TestJdbcWithMiniHS2
org.apache.hive.jdbc.TestJdbcWithMiniMr.org.apache.hive.jdbc.TestJdbcWithMiniMr
org.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.org.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark
org.apache.hive.jdbc.TestNoSaslAuth.org.apache.hive.jdbc.TestNoSaslAuth
org.apache.hive.jdbc.TestSSL.testConnectionMismatch
org.apache.hive.jdbc.TestSSL.testInvalidConfig
org.apache.hive.jdbc.TestSSL.testSSLConnectionWithProperty
org.apache.hive.jdbc.TestSSL.testSSLConnectionWithURL
org.apache.hive.jdbc.TestSSL.testSSLFetch
org.apache.hive.jdbc.TestSSL.testSSLFetchHttp
org.apache.hive.jdbc.TestSSL.testSSLVersion
org.apache.hive.jdbc.TestSchedulerQueue.testFairSchedulerPrimaryQueueMapping
org.apache.hive.jdbc.TestSchedulerQueue.testFairSchedulerQueueMapping
org.apache.hive.jdbc.TestSchedulerQueue.testFairSchedulerSecondaryQueueMapping
org.apache.hive.jdbc.TestSchedulerQueue.testQueueMappingCheckDisabled
org.apache.hive.jdbc.authorization.TestCLIAuthzSessionContext.org.apache.hive.jdbc.authorization.TestCLIAuthzSessionContext
org.apache.hive.jdbc.authorization.TestHS2AuthzContext.org.apache.hive.jdbc.authorization.TestHS2AuthzContext
org.apache.hive.jdbc.authorization.TestHS2AuthzSessionContext.org.apache.hive.jdbc.authorization.TestHS2AuthzSessionContext
org.apache.hive.jdbc.authorization.TestJdbcMetadataApiAuth.org.apache.hive.jdbc.authorization.TestJdbcMetadataApiAuth
org.apache.hive.jdbc.authorization.TestJdbcWithSQLAuthUDFBlacklist.testBlackListedUdfUsage
org.apache.hive.jdbc.authorization.TestJdbcWithSQLAuthorization.org.apache.hive.jdbc.authorization.TestJdbcWithSQLAuthorization
org.apache.hive.jdbc.miniHS2.TestHiveServer2.org.apache.hive.jdbc.miniHS2.TestHiveServer2
org.apache.hive.jdbc.miniHS2.TestHiveServer2SessionTimeout.testConnection
org.apache.hive.jdbc.miniHS2.TestMiniHS2.testConfInSession
org.apache.hive.minikdc.TestHiveAuthFactory.testStartTokenManagerForDBTokenStore
org.apache.hive.minikdc.TestHs2HooksWithMiniKdc.org.apache.hive.minikdc.TestHs2HooksWithMiniKdc
org.apache.hive.minikdc.TestJdbcWithMiniKdc.org.apache.hive.minikdc.TestJdbcWithMiniKdc
org.apache.hive.minikdc.TestJdbcWithMiniKdcCookie.org.apache.hive.minikdc.TestJdbcWithMiniKdcCookie
org.apache.hive.minikdc.TestJdbcWithMiniKdcSQLAuthBinary.org.apache.hive.minikdc.TestJdbcWithMiniKdcSQLAuthBinary
org.apache.hive.minikdc.TestJdbcWithMiniKdcSQLAuthHttp.org.apache.hive.minikdc.TestJdbcWithMiniKdcSQLAuthHttp
org.apache.hive.service.auth.TestCustomAuthentication.org.apache.hive.service.auth.TestCustomAuthentication
org.apache.hive.service.auth.TestPlainSaslHelper.testDoAsSetting
org.apache.hive.service.cli.TestEmbeddedThriftBinaryCLIService.org.apache.hive.service.cli.TestEmbeddedThriftBinaryCLIService
org.apache.hive.service.cli.TestRetryingThriftCLIServiceClient.testRetryBehaviour
org.apache.hive.service.cli.operation.TestOperationLoggingAPIWithMr.org.apache.hive.service.cli.operation.TestOperationLoggingAPIWithMr
org.apache.hive.service.cli.operation.TestOperationLoggingAPIWithTez.org.apache.hive.service.cli.operation.TestOperationLoggingAPIWithTez
org.apache.hive.service.cli.operation.TestOperationLoggingLayout.org.apache.hive.service.cli.operation.TestOperationLoggingLayout
org.apache.hive.service.cli.session.TestSessionGlobalInitFile.testSessionGlobalInitDir
org.apache.hive.service.cli.session.TestSessionGlobalInitFile.testSessionGlobalInitFile
org.apache.hive.service.cli.session.TestSessionGlobalInitFile.testSessionGlobalInitFileAndConfOverlay
org.apache.hive.service.cli.session.TestSessionGlobalInitFile.testSessionGlobalInitFileWithUser
org.apache.hive.service.cli.session.TestSessionHooks.testProxyUser
org.apache.hive.service.cli.session.TestSessionHooks.testSessionHook
org.apache.hive.service.cli.thrift.TestThriftBinaryCLIService.org.apache.hive.service.cli.thrift.TestThriftBinaryCLIService
org.apache.hive.service.cli.thrift.TestThriftHttpCLIService.org.apache.hive.service.cli.thrift.TestThriftHttpCLIService
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6049/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6049/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6049/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6049/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6049/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6049/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 898 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12772479 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="15007204" author="ashutoshc" created="Mon, 16 Nov 2015 19:48:37 +0000"  >&lt;p&gt;2.0 is a good time to do this. Lets try to get it in. Web page pointed out by Sushanth does list few items we need to be wary of.&lt;/p&gt;</comment>
                            <comment id="15008513" author="osayankin" created="Tue, 17 Nov 2015 11:27:57 +0000"  >&lt;p&gt;&amp;gt;  Have you verified the elements in &lt;a href=&quot;http://www.datanucleus.org/products/accessplatform_4_2/migration.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.datanucleus.org/products/accessplatform_4_2/migration.html&lt;/a&gt; to see if we won&apos;t be affected adversely?&lt;/p&gt;

&lt;p&gt;Yes. Added &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6113&quot; title=&quot;Upgrade DataNucleus [was: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6113&quot;&gt;&lt;del&gt;HIVE-6113&lt;/del&gt;&lt;/a&gt;-2.patch where applied all changes regarding DN version migration from 3.X.X to 4.X.X. See &lt;a href=&quot;https://reviews.apache.org/r/40344/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/40344/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Code change summary. &lt;br/&gt;
Renamed:&lt;br/&gt;
datanucleus.validateTables ---&amp;gt; datanucleus.schema.validateTables&lt;br/&gt;
datanucleus.validateColumns ---&amp;gt; datanucleus.schema.validateColumns&lt;br/&gt;
datanucleus.validateConstraints ---&amp;gt; datanucleus.schema.validateConstraints&lt;br/&gt;
datanucleus.autoCreateSchema ---&amp;gt; datanucleus.schema.autoCreateAll&lt;/p&gt;

&lt;p&gt;Deleted:&lt;br/&gt;
datanucleus.fixedDatastore&lt;/p&gt;</comment>
                            <comment id="15008558" author="eliac" created="Tue, 17 Nov 2015 12:09:54 +0000"  >&lt;p&gt;&amp;gt; @Eli Acherkan : Very interesting analysis. Could you point me to where you see the following:&lt;br/&gt;
&amp;gt;&amp;gt; If a table is deleted from the DB during this operation, DatabaseMetaData.getColumns will throw an exception.&lt;br/&gt;
&amp;gt;&amp;gt; This exception is interpreted by Hive to mean that the &quot;default&quot; Hive database doesn&apos;t exist.&lt;/p&gt;

&lt;p&gt;Sure, let me try to explain.&lt;/p&gt;

&lt;p&gt;#When DatabaseMetaData.getColumns throws an SQLException, it&apos;s caught by RDBMSSchemaHandler.refreshTableData and rethrown as a NucleusDataStoreException.&lt;br/&gt;
#This one is then caught by JDOQLQuery.compileQueryFull, which doesn&apos;t rethrow an exception - it simply returns an empty result.&lt;br/&gt;
#ObjectStore.getMDatabase then receives the empty result and throws a NoSuchObjectException.&lt;br/&gt;
#This exception is caught by HiveMetaStore.createDefaultDB_core, and taken to mean that the default DB doesn&apos;t exist.&lt;br/&gt;
#The createDefaultDB_core method then proceeds to try to create a DB, which fails because the DB actually _does_exist already.&lt;/p&gt;

&lt;p&gt;Please let me know if the above is unclear.&lt;/p&gt;</comment>
                            <comment id="15010696" author="osayankin" created="Wed, 18 Nov 2015 10:24:28 +0000"  >&lt;p&gt;Hi team!&lt;br/&gt;
Any updates regarding &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6113&quot; title=&quot;Upgrade DataNucleus [was: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6113&quot;&gt;&lt;del&gt;HIVE-6113&lt;/del&gt;&lt;/a&gt;-2.patch ?&lt;/p&gt;</comment>
                            <comment id="15011610" author="osayankin" created="Wed, 18 Nov 2015 18:33:03 +0000"  >&lt;p&gt;va/org/apache/hadoop/hive/conf/HiveConf.java&lt;/p&gt;

&lt;p&gt;     if (getBoolVar(ConfVars.METASTORE_SCHEMA_VERIFICATION)) &lt;/p&gt;
{
-      setBoolVar(ConfVars.METASTORE_AUTO_CREATE_SCHEMA, false);
-      setBoolVar(ConfVars.METASTORE_FIXED_DATASTORE, true);
+      setBoolVar(ConfVars.METASTORE_AUTO_CREATE_ALL, false);
     }

&lt;p&gt;I&apos;m not sure about this change. Do we really need to set  setBoolVar(ConfVars.METASTORE_AUTO_CREATE_ALL, false);? What about &apos;true&apos; value? Please advice.&lt;/p&gt;</comment>
                            <comment id="15014691" author="sershe" created="Thu, 19 Nov 2015 23:08:34 +0000"  >&lt;p&gt;Wrt the patch, it looks like all the tests have failed above.&lt;br/&gt;
Also given the code changes, I assume there&apos;s no way to downgrade to old DN jars on a running Hive build if some issue is discovered? I love it when people change public APIs to beautify some package name or whatever. Maybe we can try to find the classes by string name to be able to use both jars?&lt;/p&gt;</comment>
                            <comment id="15020277" author="hiveqa" created="Sat, 21 Nov 2015 06:41:06 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12773550/HIVE-6113.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12773550/HIVE-6113.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6089/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6089/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6089/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6089/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6089/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6089/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n /usr/java/jdk1.7.0_45-cloudera ]]
+ export JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ JAVA_HOME=/usr/java/jdk1.7.0_45-cloudera
+ export PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ PATH=/usr/java/jdk1.7.0_45-cloudera/bin/:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-maven-3.0.5/bin:/usr/local/apache-maven-3.0.5/bin:/usr/java/jdk1.7.0_45-cloudera/bin:/usr/local/apache-ant-1.9.1/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hiveptest/bin
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-TRUNK-Build-6089/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ git = \s\v\n ]]
+ [[ git = \g\i\t ]]
+ [[ -z master ]]
+ [[ -d apache-github-source-source ]]
+ [[ ! -d apache-github-source-source/.git ]]
+ [[ ! -d apache-github-source-source ]]
+ cd apache-github-source-source
+ git fetch origin
+ git reset --hard HEAD
HEAD is now at 8e9bae2 HIVE-12472: Add test case for HIVE-10592 (Prasanth Jayachandran reviewed by  Ashutosh Chauhan)
+ git clean -f -d
Removing data/files/TJOIN1
Removing data/files/TJOIN2
Removing data/files/TJOIN3
Removing data/files/TJOIN4
Removing ql/src/test/queries/clientpositive/vector_outer_join6.q
Removing ql/src/test/results/clientpositive/tez/vector_outer_join6.q.out
Removing ql/src/test/results/clientpositive/vector_outer_join6.q.out
+ git checkout master
Already on &apos;master&apos;
+ git reset --hard origin/master
HEAD is now at 8e9bae2 HIVE-12472: Add test case for HIVE-10592 (Prasanth Jayachandran reviewed by  Ashutosh Chauhan)
+ git merge --ff-only origin/master
Already up-to-date.
+ git gc
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12773550 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="15026135" author="hiveqa" created="Wed, 25 Nov 2015 04:04:50 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12773890/HIVE-6113.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12773890/HIVE-6113.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6120/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6120/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6120/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6120/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6120/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6120/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-util ---
[INFO] Compiling 51 source files to /data/hive-ptest/working/apache-github-source-source/itests/util/target/classes
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseQTestUtil.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseQTestUtil.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-it-util ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/util/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-util ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/util/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/util/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/util/target/tmp/conf
     [copy] Copying 14 files to /data/hive-ptest/working/apache-github-source-source/itests/util/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-util ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-it-util ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-it-util ---
[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/itests/util/target/hive-it-util-2.0.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-it-util ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it-util ---
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/util/target/hive-it-util-2.0.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-it-util/2.0.0-SNAPSHOT/hive-it-util-2.0.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/util/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-it-util/2.0.0-SNAPSHOT/hive-it-util-2.0.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Unit Tests 2.0.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-unit ---
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/hive-unit (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-it-unit ---
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (download-spark) @ hive-it-unit ---
[INFO] Executing tasks

main:
     [exec] + /bin/pwd
     [exec] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit
     [exec] + BASE_DIR=./target
     [exec] + HIVE_ROOT=./target/../../../
     [exec] + DOWNLOAD_DIR=./../thirdparty
     [exec] + mkdir -p ./../thirdparty
     [exec] + download http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-1.5.0-bin-hadoop2-without-hive.tgz spark
     [exec] + url=http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-1.5.0-bin-hadoop2-without-hive.tgz
     [exec] + finalName=spark
     [exec] ++ basename http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-1.5.0-bin-hadoop2-without-hive.tgz
     [exec] + tarName=spark-1.5.0-bin-hadoop2-without-hive.tgz
     [exec] + rm -rf ./target/spark
     [exec] + [[ ! -f ./../thirdparty/spark-1.5.0-bin-hadoop2-without-hive.tgz ]]
     [exec] + tar -zxf ./../thirdparty/spark-1.5.0-bin-hadoop2-without-hive.tgz -C ./target
     [exec] + mv ./target/spark-1.5.0-bin-hadoop2-without-hive ./target/spark
     [exec] + cp -f ./target/../../..//data/conf/spark/log4j2.xml ./target/spark/conf/
     [exec] + sed &apos;/package /d&apos; /data/hive-ptest/working/apache-github-source-source/itests/../contrib/src/java/org/apache/hadoop/hive/contrib/udf/example/UDFExampleAdd.java
     [exec] + javac -cp /data/hive-ptest/working/maven/org/apache/hive/hive-exec/2.0.0-SNAPSHOT/hive-exec-2.0.0-SNAPSHOT.jar /tmp/UDFExampleAdd.java -d /tmp
     [exec] + jar -cf /tmp/udfexampleadd-1.0.jar -C /tmp UDFExampleAdd.class
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-it-unit ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-it-unit ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-unit ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-unit ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-it-unit ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-unit ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/conf
     [copy] Copying 14 files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-metastore-scripts) @ hive-it-unit ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/scripts/metastore
     [copy] Copying 235 files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/scripts/metastore
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-unit ---
[INFO] Compiling 98 source files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/test-classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/authorization/plugin/TestHiveAuthorizerCheckInvocation.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/authorization/plugin/TestHiveAuthorizerCheckInvocation.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[54,41] cannot find symbol
  symbol:   variable METASTORE_AUTO_CREATE_SCHEMA
  location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[55,41] cannot find symbol
  symbol:   variable METASTORE_FIXED_DATASTORE
  location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[84,53] cannot find symbol
  symbol:   variable METASTORE_AUTO_CREATE_SCHEMA
  location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[85,54] cannot find symbol
  symbol:   variable METASTORE_FIXED_DATASTORE
  location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[96,54] cannot find symbol
  symbol:   variable METASTORE_AUTO_CREATE_SCHEMA
  location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[97,53] cannot find symbol
  symbol:   variable METASTORE_FIXED_DATASTORE
  location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars
[INFO] 6 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive Integration - Parent ......................... SUCCESS [7.774s]
[INFO] Hive Integration - Custom Serde ................... SUCCESS [14.734s]
[INFO] Hive Integration - HCatalog Unit Tests ............ SUCCESS [24.616s]
[INFO] Hive Integration - Testing Utilities .............. SUCCESS [18.257s]
[INFO] Hive Integration - Unit Tests ..................... FAILURE [28.255s]
[INFO] Hive Integration - Test Serde ..................... SKIPPED
[INFO] Hive Integration - QFile Tests .................... SKIPPED
[INFO] Hive Integration - QFile Accumulo Tests ........... SKIPPED
[INFO] JMH benchmark: Hive ............................... SKIPPED
[INFO] Hive Integration - Unit Tests - Hadoop 2 .......... SKIPPED
[INFO] Hive Integration - Unit Tests with miniKdc ........ SKIPPED
[INFO] Hive Integration - QFile Spark Tests .............. SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1:39.450s
[INFO] Finished at: Tue Nov 24 23:04:48 EST 2015
[INFO] Final Memory: 84M/327M
[INFO] ------------------------------------------------------------------------
[WARNING] The requested profile &quot;hadoop-2&quot; could not be activated because it does not exist.
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile (default-testCompile) on project hive-it-unit: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[54,41] cannot find symbol
[ERROR] symbol:   variable METASTORE_AUTO_CREATE_SCHEMA
[ERROR] location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[55,41] cannot find symbol
[ERROR] symbol:   variable METASTORE_FIXED_DATASTORE
[ERROR] location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[84,53] cannot find symbol
[ERROR] symbol:   variable METASTORE_AUTO_CREATE_SCHEMA
[ERROR] location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[85,54] cannot find symbol
[ERROR] symbol:   variable METASTORE_FIXED_DATASTORE
[ERROR] location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[96,54] cannot find symbol
[ERROR] symbol:   variable METASTORE_AUTO_CREATE_SCHEMA
[ERROR] location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetastoreVersion.java:[97,53] cannot find symbol
[ERROR] symbol:   variable METASTORE_FIXED_DATASTORE
[ERROR] location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-it-unit
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12773890 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="15026579" author="osayankin" created="Wed, 25 Nov 2015 10:35:44 +0000"  >&lt;p&gt;Fixed compilation error in TestMetastoreVersion.java&lt;/p&gt;</comment>
                            <comment id="15030421" author="hiveqa" created="Sat, 28 Nov 2015 08:08:35 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12774318/HIVE-6113.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12774318/HIVE-6113.5.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 2 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 8 failed/errored test(s), 9865 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestHWISessionManager - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testAddPartitions
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testFetchingPartitionsWithDifferentSchemas
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testGetPartitionSpecs_WithAndWithoutPartitionGrouping
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testAddJarDataNucleusUnCaching
org.apache.hive.jdbc.TestSSL.testSSLVersion
org.apache.hive.jdbc.miniHS2.TestHs2Metrics.testMetrics
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6152/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6152/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6152/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6152/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6152/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6152/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 8 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12774318 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="15032465" author="osayankin" created="Mon, 30 Nov 2015 21:10:00 +0000"  >&lt;p&gt;Fixed org.apache.hive.jdbc.TestJdbcWithMiniHS2.testAddJarDataNucleusUnCaching&lt;/p&gt;</comment>
                            <comment id="15032542" author="ashutoshc" created="Mon, 30 Nov 2015 21:47:53 +0000"  >&lt;p&gt;Since DN property names are changing, it will be good to have this one before 2.0 for backward compat reasons. Apart from the issue discussed on this jira, it will also help &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-11036&quot; title=&quot;Race condition in DataNucleus makes Metastore to hang&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-11036&quot;&gt;&lt;del&gt;HIVE-11036&lt;/del&gt;&lt;/a&gt; &lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sushanth&quot; class=&quot;user-hover&quot; rel=&quot;sushanth&quot;&gt;Sushanth Sowmyan&lt;/a&gt;  I think you guys are best equipped to review this.&lt;/p&gt;</comment>
                            <comment id="15036950" author="sershe" created="Thu, 3 Dec 2015 00:30:53 +0000"  >&lt;p&gt;Suggested patch with reflection to be able to downgrade the JAR just in case...&lt;/p&gt;</comment>
                            <comment id="15037907" author="osayankin" created="Thu, 3 Dec 2015 15:12:56 +0000"  >&lt;p&gt;Hi Sergey,&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;Utilities.java&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (DN_MAP_CLASS != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
      e.setPersistenceDelegate(DN_MAP_CLASS, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; MapDelegate());
    }
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (DN_LIST_CLASS != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
      e.setPersistenceDelegate(DN_LIST_CLASS, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ListDelegate());
    }
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (DN_MAP_CLASS == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; || DN_LIST_CLASS == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
      LOG.info(&lt;span class=&quot;code-quote&quot;&gt;&quot;DN map and/or list classes were not found; not adding persistence delegate&quot;&lt;/span&gt;);
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;1. Why not to throw Exception here or at least LOG.error() ?&lt;br/&gt;
2. Why not no move not null verification before class usage and thus skip double verification. I mean smth like this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;Utilities.java&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (DN_MAP_CLASS == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; || DN_LIST_CLASS == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
      &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ClassNotFoundException(&lt;span class=&quot;code-quote&quot;&gt;&quot;DN map and/or list classes were not found; not adding persistence delegate&quot;&lt;/span&gt;);
    }
      e.setPersistenceDelegate(DN_MAP_CLASS, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; MapDelegate());
      e.setPersistenceDelegate(DN_LIST_CLASS, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ListDelegate());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15043447" author="osayankin" created="Sat, 5 Dec 2015 18:57:20 +0000"  >&lt;p&gt;Added Sergey&apos;s reflection code that makes Hive to be able to downgrade the DN JAR.&lt;/p&gt;

&lt;p&gt;Reflection code is available in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6113&quot; title=&quot;Upgrade DataNucleus [was: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6113&quot;&gt;&lt;del&gt;HIVE-6113&lt;/del&gt;&lt;/a&gt;.7.patch &lt;/p&gt;</comment>
                            <comment id="15043734" author="hiveqa" created="Sun, 6 Dec 2015 06:43:23 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12775944/HIVE-6113.7.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12775944/HIVE-6113.7.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6263/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6263/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6263/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6263/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6263/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6263/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/target/hive-hcatalog-it-unit-2.1.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hcatalog-it-unit/2.1.0-SNAPSHOT/hive-hcatalog-it-unit-2.1.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-hcatalog-it-unit/2.1.0-SNAPSHOT/hive-hcatalog-it-unit-2.1.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/hcatalog-unit/target/hive-hcatalog-it-unit-2.1.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hcatalog-it-unit/2.1.0-SNAPSHOT/hive-hcatalog-it-unit-2.1.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Testing Utilities 2.1.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-util ---
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/util/target
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/util (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-it-util ---
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (download-spark) @ hive-it-util ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-it-util ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-it-util ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/util/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-util ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-util ---
[INFO] Compiling 51 source files to /data/hive-ptest/working/apache-github-source-source/itests/util/target/classes
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseQTestUtil.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/util/src/main/java/org/apache/hadoop/hive/hbase/HBaseQTestUtil.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-it-util ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/util/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-util ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/util/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/util/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/util/target/tmp/conf
     [copy] Copying 14 files to /data/hive-ptest/working/apache-github-source-source/itests/util/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-util ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-it-util ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-it-util ---
[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/itests/util/target/hive-it-util-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-it-util ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it-util ---
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/util/target/hive-it-util-2.1.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-it-util/2.1.0-SNAPSHOT/hive-it-util-2.1.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/itests/util/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-it-util/2.1.0-SNAPSHOT/hive-it-util-2.1.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Unit Tests 2.1.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-unit ---
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/itests/hive-unit (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-it-unit ---
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (download-spark) @ hive-it-unit ---
[INFO] Executing tasks

main:
     [exec] + /bin/pwd
     [exec] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit
     [exec] + BASE_DIR=./target
     [exec] + HIVE_ROOT=./target/../../../
     [exec] + DOWNLOAD_DIR=./../thirdparty
     [exec] + mkdir -p ./../thirdparty
     [exec] + download http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-1.5.0-bin-hadoop2-without-hive.tgz spark
     [exec] + url=http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-1.5.0-bin-hadoop2-without-hive.tgz
     [exec] + finalName=spark
     [exec] ++ basename http://d3jw87u4immizc.cloudfront.net/spark-tarball/spark-1.5.0-bin-hadoop2-without-hive.tgz
     [exec] + tarName=spark-1.5.0-bin-hadoop2-without-hive.tgz
     [exec] + rm -rf ./target/spark
     [exec] + [[ ! -f ./../thirdparty/spark-1.5.0-bin-hadoop2-without-hive.tgz ]]
     [exec] + tar -zxf ./../thirdparty/spark-1.5.0-bin-hadoop2-without-hive.tgz -C ./target
     [exec] + mv ./target/spark-1.5.0-bin-hadoop2-without-hive ./target/spark
     [exec] + cp -f ./target/../../..//data/conf/spark/log4j2.properties ./target/spark/conf/
     [exec] + sed &apos;/package /d&apos; /data/hive-ptest/working/apache-github-source-source/itests/../contrib/src/java/org/apache/hadoop/hive/contrib/udf/example/UDFExampleAdd.java
     [exec] + javac -cp /data/hive-ptest/working/maven/org/apache/hive/hive-exec/2.1.0-SNAPSHOT/hive-exec-2.1.0-SNAPSHOT.jar /tmp/UDFExampleAdd.java -d /tmp
     [exec] + jar -cf /tmp/udfexampleadd-1.0.jar -C /tmp UDFExampleAdd.class
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-it-unit ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-it-unit ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-unit ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-unit ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-it-unit ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-unit ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/conf
     [copy] Copying 14 files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-metastore-scripts) @ hive-it-unit ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/scripts/metastore
     [copy] Copying 245 files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/tmp/scripts/metastore
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-unit ---
[INFO] Compiling 98 source files to /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/target/test-classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java: Some input files use or override a deprecated API.
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestRetryingHMSHandler.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/authorization/plugin/TestHiveAuthorizerCheckInvocation.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/authorization/plugin/TestHiveAuthorizerCheckInvocation.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java:[798,34] cannot find symbol
  symbol:   class AbstractNucleusContext
  location: class org.apache.hive.jdbc.TestJdbcWithMiniHS2
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive Integration - Parent ......................... SUCCESS [7.133s]
[INFO] Hive Integration - Custom Serde ................... SUCCESS [16.180s]
[INFO] Hive Integration - HCatalog Unit Tests ............ SUCCESS [23.874s]
[INFO] Hive Integration - Testing Utilities .............. SUCCESS [16.164s]
[INFO] Hive Integration - Unit Tests ..................... FAILURE [28.503s]
[INFO] Hive Integration - Test Serde ..................... SKIPPED
[INFO] Hive Integration - QFile Tests .................... SKIPPED
[INFO] Hive Integration - QFile Accumulo Tests ........... SKIPPED
[INFO] JMH benchmark: Hive ............................... SKIPPED
[INFO] Hive Integration - Unit Tests - Hadoop 2 .......... SKIPPED
[INFO] Hive Integration - Unit Tests with miniKdc ........ SKIPPED
[INFO] Hive Integration - QFile Spark Tests .............. SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1:36.347s
[INFO] Finished at: Sun Dec 06 01:43:22 EST 2015
[INFO] Final Memory: 85M/244M
[INFO] ------------------------------------------------------------------------
[WARNING] The requested profile &quot;hadoop-2&quot; could not be activated because it does not exist.
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile (default-testCompile) on project hive-it-unit: Compilation failure
[ERROR] /data/hive-ptest/working/apache-github-source-source/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestJdbcWithMiniHS2.java:[798,34] cannot find symbol
[ERROR] symbol:   class AbstractNucleusContext
[ERROR] location: class org.apache.hive.jdbc.TestJdbcWithMiniHS2
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-it-unit
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12775944 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="15043764" author="osayankin" created="Sun, 6 Dec 2015 08:31:12 +0000"  >&lt;p&gt;Added import of AbstractNucleusContext;&lt;/p&gt;</comment>
                            <comment id="15043934" author="hiveqa" created="Sun, 6 Dec 2015 15:58:05 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12775977/HIVE-6113.8.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12775977/HIVE-6113.8.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 3 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 9 failed/errored test(s), 9897 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestHWISessionManager - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_udf_max
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vectorized_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mergejoin
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testGetPartitionSpecs_WithAndWithoutPartitionGrouping
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testAddJarDataNucleusUnCaching
org.apache.hive.jdbc.TestSSL.testSSLVersion
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6268/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6268/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6268/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6268/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6268/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6268/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 9 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12775977 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="15046839" author="osayankin" created="Tue, 8 Dec 2015 13:12:01 +0000"  >&lt;p&gt;I have applied &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6113&quot; title=&quot;Upgrade DataNucleus [was: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient]&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6113&quot;&gt;&lt;del&gt;HIVE-6113&lt;/del&gt;&lt;/a&gt;.with.reflection.patch, installed patched hive, replaced &lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;datanucleus-api-jdo-4.2.1.jar
datanucleus-core-4.1.6.jar
datanucleus-rdbms-4.1.7.jar
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;with&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;datanucleus-api-jdo-3.2.6.jar&apos;
datanucleus-core-3.2.10.jar&apos;
datanucleus-rdbms-3.2.9.jar&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;in hive/lib folder, and restarted hive-metsatore. Then I got an exception (see below). If I replace back datanucleus-*3.X*jar with datanucleus-*4.X*jar, then hive-metsatore starts fine.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.datanucleus.api.jdo.exceptions.ClassNotPersistenceCapableException: The class &quot;org.apache.hadoop.hive.metastore.model.MVersionTable&quot; is not persistable. This means that it either hasnt been enhanced, or that the enhanced version of the file is not in the CLASSPATH (or is hidden by an unenhanced version), or the Meta-Data/annotations for the class are not found.
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:380)
	at org.datanucleus.api.jdo.JDOPersistenceManager.jdoMakePersistent(JDOPersistenceManager.java:732)
	at org.datanucleus.api.jdo.JDOPersistenceManager.makePersistent(JDOPersistenceManager.java:752)
	at org.apache.hadoop.hive.metastore.ObjectStore.setMetaStoreSchemaVersion(ObjectStore.java:6776)
	at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6673)
	at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:6648)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:114)
	at com.sun.proxy.$Proxy4.verifySchema(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:572)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:624)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:461)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&amp;lt;init&amp;gt;(RetryingHMSHandler.java:66)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72)
	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5756)
	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5751)
	at org.apache.hadoop.hive.metastore.HiveMetaStore.startMetaStore(HiveMetaStore.java:5984)
	at org.apache.hadoop.hive.metastore.HiveMetaStore.main(HiveMetaStore.java:5909)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
NestedThrowablesStackTrace:
The class &quot;org.apache.hadoop.hive.metastore.model.MVersionTable&quot; is not persistable. This means that it either hasnt been enhanced, or that the enhanced version of the file is not in the CLASSPATH (or is hidden by an unenhanced version), or the Meta-Data/annotations for the class are not found.
org.datanucleus.exceptions.ClassNotPersistableException: The class &quot;org.apache.hadoop.hive.metastore.model.MVersionTable&quot; is not persistable. This means that it either hasnt been enhanced, or that the enhanced version of the file is not in the CLASSPATH (or is hidden by an unenhanced version), or the Meta-Data/annotations for the class are not found.
	at org.datanucleus.ExecutionContextImpl.assertClassPersistable(ExecutionContextImpl.java:5698)
	at org.datanucleus.ExecutionContextImpl.persistObjectInternal(ExecutionContextImpl.java:2123)
	at org.datanucleus.ExecutionContextImpl.persistObjectWork(ExecutionContextImpl.java:2065)
	at org.datanucleus.ExecutionContextImpl.persistObject(ExecutionContextImpl.java:1913)
	at org.datanucleus.ExecutionContextThreadedImpl.persistObject(ExecutionContextThreadedImpl.java:217)
	at org.datanucleus.api.jdo.JDOPersistenceManager.jdoMakePersistent(JDOPersistenceManager.java:727)
	at org.datanucleus.api.jdo.JDOPersistenceManager.makePersistent(JDOPersistenceManager.java:752)
	at org.apache.hadoop.hive.metastore.ObjectStore.setMetaStoreSchemaVersion(ObjectStore.java:6776)
	at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6673)
	at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:6648)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:114)
	at com.sun.proxy.$Proxy4.verifySchema(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:572)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:624)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:461)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&amp;lt;init&amp;gt;(RetryingHMSHandler.java:66)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72)
	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5756)
	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5751)
	at org.apache.hadoop.hive.metastore.HiveMetaStore.startMetaStore(HiveMetaStore.java:5984)
	at org.apache.hadoop.hive.metastore.HiveMetaStore.main(HiveMetaStore.java:5909)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15047608" author="sershe" created="Tue, 8 Dec 2015 22:37:51 +0000"  >&lt;p&gt;+0.99, TestJdbcWithMiniHS2 appears to be related&lt;/p&gt;</comment>
                            <comment id="15067277" author="sershe" created="Mon, 21 Dec 2015 23:52:40 +0000"  >&lt;p&gt;Rebased the patch (the code to add custom handlers was removed in some other JIRA); fixed the classloader map cleanup that broke the test.&lt;/p&gt;</comment>
                            <comment id="15068497" author="hiveqa" created="Tue, 22 Dec 2015 18:07:26 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12778935/HIVE-6113.9.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12778935/HIVE-6113.9.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 3 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 19 failed/errored test(s), 9899 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestHWISessionManager - did not produce a TEST-*.xml file
TestSparkCliDriver-timestamp_lazy.q-bucketsortoptimize_insert_4.q-date_udf.q-and-12-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join_stats2
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_dynamic
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_columnstats_partlvl_multiple_part_clause
org.apache.hadoop.hive.cli.TestPerfCliDriver.initializationError
org.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testMultiSessionMultipleUse
org.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testSingleSessionMultipleUse
org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveOperationType.checkHiveOperationTypeMatch
org.apache.hive.jdbc.TestSSL.testSSLVersion
org.apache.hive.spark.client.TestSparkClient.testAddJarsAndFiles
org.apache.hive.spark.client.TestSparkClient.testCounters
org.apache.hive.spark.client.TestSparkClient.testErrorJob
org.apache.hive.spark.client.TestSparkClient.testJobSubmission
org.apache.hive.spark.client.TestSparkClient.testMetricsCollection
org.apache.hive.spark.client.TestSparkClient.testRemoteClient
org.apache.hive.spark.client.TestSparkClient.testSimpleSparkJob
org.apache.hive.spark.client.TestSparkClient.testSyncRpc
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6444/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6444/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6444/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6444/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6444/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6444/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 19 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12778935 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="15068629" author="sershe" created="Tue, 22 Dec 2015 19:43:22 +0000"  >&lt;p&gt;Hmm. The test that failed works for me locally. Added the property just in case.&lt;/p&gt;</comment>
                            <comment id="15069683" author="hiveqa" created="Wed, 23 Dec 2015 14:43:20 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12779112/HIVE-6113.10.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12779112/HIVE-6113.10.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 3 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 18 failed/errored test(s), 9961 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestHWISessionManager - did not produce a TEST-*.xml file
TestSparkCliDriver-timestamp_lazy.q-bucketsortoptimize_insert_4.q-date_udf.q-and-12-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join_stats2
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_dynamic
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_columnstats_partlvl_multiple_part_clause
org.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testMultiSessionMultipleUse
org.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testSingleSessionMultipleUse
org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveOperationType.checkHiveOperationTypeMatch
org.apache.hive.jdbc.TestSSL.testSSLVersion
org.apache.hive.spark.client.TestSparkClient.testAddJarsAndFiles
org.apache.hive.spark.client.TestSparkClient.testCounters
org.apache.hive.spark.client.TestSparkClient.testErrorJob
org.apache.hive.spark.client.TestSparkClient.testJobSubmission
org.apache.hive.spark.client.TestSparkClient.testMetricsCollection
org.apache.hive.spark.client.TestSparkClient.testRemoteClient
org.apache.hive.spark.client.TestSparkClient.testSimpleSparkJob
org.apache.hive.spark.client.TestSparkClient.testSyncRpc
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6457/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6457/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6457/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6457/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6457/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6457/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 18 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12779112 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="15070171" author="sershe" created="Wed, 23 Dec 2015 20:43:33 +0000"  >&lt;p&gt;None of the tests have age 1. +1. Will commit later today unless there are objections&lt;/p&gt;</comment>
                            <comment id="15081793" author="sershe" created="Mon, 4 Jan 2016 20:57:05 +0000"  >&lt;p&gt;Committed to master and branch-2.0&lt;/p&gt;</comment>
                            <comment id="15093058" author="sladymon" created="Tue, 12 Jan 2016 01:15:28 +0000"  >&lt;p&gt;Doc note: This changes the name of four configuration parameters in HiveConf.java in 2.0.0. The new names are documented in the wiki in the Configuration Properties section here:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-datanucleus.schema.validateTables&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;datanucleus.schema.validateTables &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-datanucleus.schema.validateColumns&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;datanucleus.schema.validateColumns &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-datanucleus.schema.validateConstraints&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;datanucleus.schema.validateConstraints &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-datanucleus.schema.autoCreateAll&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;datanucleus.schema.autoCreateAll &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Additionally, &lt;b&gt;datanucleus.fixedDatastore&lt;/b&gt; was updated to show that it was removed and &lt;b&gt;hive.metastore.schema.verification&lt;/b&gt; was updated to note that it affects &lt;b&gt;datanucleus.schema.autoCreateAll&lt;/b&gt;:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-datanucleus.fixedDatastore&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;datanucleus.fixedDatastore &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.metastore.schema.verification&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;hive.metastore.schema.verification &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15093141" author="lefty@hortonworks.com" created="Tue, 12 Jan 2016 02:06:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=osayankin&quot; class=&quot;user-hover&quot; rel=&quot;osayankin&quot;&gt;Oleksiy Sayankin&lt;/a&gt;, are these two sentences from &quot;Metastore Schema Consistency and Upgrades&quot; and &quot;Metastore Schema Verification&quot; still valid?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;To suppress the schema check and allow the metastore to implicitly modify the schema, you need to set a configuration property hive.metastore.schema.verification to false in hive-site.xml.&lt;/p&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;
&lt;p&gt;By default the configuration property hive.metastore.schema.verification is false and metastore to implicitly write the schema version if it&apos;s not matching. To enable the strict schema verification, you need to set this property to true in hive-site.xml.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t understand why &lt;b&gt;hive.metastore.schema.verification&lt;/b&gt; would need to be set to false in hive-site.xml since it is already false by default in HiveConf.java.  I also don&apos;t know which hive-site.xml file(s) should be set, or whether the parameter could be set in HiveConf.java instead.  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-12841&quot; title=&quot;Document existence of multiple hive-site.xml files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-12841&quot;&gt;HIVE-12841&lt;/a&gt; asks for better documentation of hive-site.xml.&lt;/p&gt;

&lt;p&gt;Also, in the second sentence quoted above should &quot;... and metastore to implicitly write&quot; be changed to &quot;... will implicitly write&quot; (or &quot;... implicitly writes&quot;)?&lt;/p&gt;

&lt;p&gt;Finally, I don&apos;t understand what is meant by implicitly modifying the schema or implicitly writing the schema version &amp;#8211; are they the same thing, that is, &quot;modify the schema&quot; means &quot;modify the schema version&quot;?  If you&apos;re not the right people to ask, perhaps you could suggest someone else.  Thanks.&lt;/p&gt;

&lt;p&gt;Here are the quoted sections:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/AdminManual+MetastoreAdmin#AdminManualMetastoreAdmin-MetastoreSchemaConsistencyandUpgrades&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Admin Manual &amp;#8211; Metastore Admin &amp;#8211; Metastore Schema Consistency and Upgrades &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Hive+Schema+Tool#HiveSchemaTool-MetastoreSchemaVerification&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Hive Schema Tool &amp;#8211; Metastore Schema Verification &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15930671" author="vgumashta" created="Fri, 17 Mar 2017 20:33:50 +0000"  >&lt;p&gt;Removing target 1.2.2 as it&apos;s a minor upgrade and this change touches lots of parts.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12975304">HIVE-13931</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12838580">HIVE-11036</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12771671">HIVE-9543</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12986353">HIVE-14152</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12992074">HIVE-14322</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12618540">HIVE-3764</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12492754">HIVE-1841</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12913783">HIVE-12436</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12772722" name="HIVE-6113-2.patch" size="12643" author="osayankin" created="Tue, 17 Nov 2015 11:24:14 +0000"/>
                            <attachment id="12779112" name="HIVE-6113.10.patch" size="18268" author="sershe" created="Tue, 22 Dec 2015 19:43:22 +0000"/>
                            <attachment id="12773550" name="HIVE-6113.3.patch" size="12290" author="osayankin" created="Fri, 20 Nov 2015 17:36:34 +0000"/>
                            <attachment id="12773890" name="HIVE-6113.4.patch" size="14641" author="osayankin" created="Mon, 23 Nov 2015 20:05:11 +0000"/>
                            <attachment id="12774318" name="HIVE-6113.5.patch" size="16968" author="osayankin" created="Wed, 25 Nov 2015 10:35:44 +0000"/>
                            <attachment id="12774888" name="HIVE-6113.6.patch" size="17916" author="osayankin" created="Mon, 30 Nov 2015 21:09:04 +0000"/>
                            <attachment id="12775944" name="HIVE-6113.7.patch" size="18788" author="osayankin" created="Sat, 5 Dec 2015 18:57:20 +0000"/>
                            <attachment id="12775977" name="HIVE-6113.8.patch" size="19083" author="osayankin" created="Sun, 6 Dec 2015 08:31:12 +0000"/>
                            <attachment id="12778935" name="HIVE-6113.9.patch" size="17738" author="sershe" created="Mon, 21 Dec 2015 23:52:40 +0000"/>
                            <attachment id="12772479" name="HIVE-6113.patch" size="2358" author="osayankin" created="Mon, 16 Nov 2015 12:31:56 +0000"/>
                            <attachment id="12775440" name="HIVE-6113.with.reflection.patch" size="17266" author="sershe" created="Thu, 3 Dec 2015 00:30:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 8 Apr 2014 14:54:29 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365495</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 44 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1qzxr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365796</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12332154</customfieldvalue>
    <customfieldvalue>12332641</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-6114] NoSuchObjectException(message:bdm.tableName table not found)</title>
                <link>https://issues.apache.org/jira/browse/HIVE-6114</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;When executing an Query &quot;USE bdm;DESC FORMATTED bdm_las_waybill_revoke_run_car_task;&quot;&lt;br/&gt;
But when I try it again, It will success.&lt;br/&gt;
This is a random phenomenon.&lt;/p&gt;

&lt;p&gt;Throw Exceptions like this&lt;/p&gt;

&lt;p&gt;2013-12-26 04:20:38,849 ERROR metadata.Hive (Hive.java:getTable(953)) - NoSuchObjectException(message:bdm.bdm_las_waybill_revoke_run_car_task table not found)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1373)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:103)&lt;br/&gt;
	at $Proxy10.get_table(Unknown Source)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:854)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:89)&lt;br/&gt;
	at $Proxy11.getTable(Unknown Source)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:950)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:892)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$tableSpec.&amp;lt;init&amp;gt;(BaseSemanticAnalyzer.java:730)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$tableSpec.&amp;lt;init&amp;gt;(BaseSemanticAnalyzer.java:707)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.parse.LoadSemanticAnalyzer.analyzeInternal(LoadSemanticAnalyzer.java:196)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:284)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:441)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:342)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:977)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:888)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:260)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:217)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:507)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:442)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:825)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:769)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:708)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.util.RunJar.main(RunJar.java:197)&lt;/p&gt;

&lt;p&gt;2013-12-26 04:20:38,904 ERROR ql.Driver (SessionState.java:printError(419)) - FAILED: SemanticException &lt;span class=&quot;error&quot;&gt;&amp;#91;Error 10001&amp;#93;&lt;/span&gt;: Line 1:114 Table not found &apos;bdm_las_waybill_revoke_run_car_task&apos;&lt;br/&gt;
org.apache.hadoop.hive.ql.parse.SemanticException: Line 1:114 Table not found &apos;bdm_las_waybill_revoke_run_car_task&apos;&lt;br/&gt;
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$tableSpec.&amp;lt;init&amp;gt;(BaseSemanticAnalyzer.java:733)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$tableSpec.&amp;lt;init&amp;gt;(BaseSemanticAnalyzer.java:707)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.parse.LoadSemanticAnalyzer.analyzeInternal(LoadSemanticAnalyzer.java:196)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:284)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:441)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:342)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:977)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:888)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:260)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:217)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:507)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:442)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:825)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:769)&lt;br/&gt;
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:708)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.util.RunJar.main(RunJar.java:197)&lt;br/&gt;
Caused by: org.apache.hadoop.hive.ql.metadata.InvalidTableException: Table not found bdm_las_waybill_revoke_run_car_task&lt;br/&gt;
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:954)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:892)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$tableSpec.&amp;lt;init&amp;gt;(BaseSemanticAnalyzer.java:730)&lt;br/&gt;
	... 19 more&lt;/p&gt;</description>
                <environment>&lt;p&gt;hadoop-0.20.2-cdh3u3, hive-0.12.0&lt;/p&gt;</environment>
        <key id="12686505">HIVE-6114</key>
            <summary>NoSuchObjectException(message:bdm.tableName table not found)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="shiw019">William Stone</reporter>
                        <labels>
                            <label>gettable</label>
                            <label>metastore</label>
                            <label>table_not_found</label>
                    </labels>
                <created>Fri, 27 Dec 2013 07:26:56 +0000</created>
                <updated>Wed, 7 May 2014 20:38:29 +0000</updated>
                                            <version>0.12.0</version>
                                                    <component>Database/Schema</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13950164" author="rhbutani" created="Thu, 27 Mar 2014 23:50:23 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shiw019&quot; class=&quot;user-hover&quot; rel=&quot;shiw019&quot;&gt;William Stone&lt;/a&gt; can you provide details on how to reproduce?&lt;br/&gt;
Also can this be downgraded from Blocker priority&lt;/p&gt;</comment>
                            <comment id="13950180" author="thejas" created="Fri, 28 Mar 2014 00:05:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shiw019&quot; class=&quot;user-hover&quot; rel=&quot;shiw019&quot;&gt;William Stone&lt;/a&gt; Can you also check if you have any datanucleus caching parameters set in your hive configuration ?&lt;/p&gt;</comment>
                            <comment id="13992202" author="sershe" created="Wed, 7 May 2014 20:38:29 +0000"  >&lt;p&gt;Hi, is there any update on this issue?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 27 Mar 2014 23:50:23 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365496</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 37 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1qzxz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365797</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-6115] Remove redundant code in HiveHBaseStorageHandler</title>
                <link>https://issues.apache.org/jira/browse/HIVE-6115</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12686536">HIVE-6115</key>
            <summary>Remove redundant code in HiveHBaseStorageHandler</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="brocknoland">Brock Noland</assignee>
                                    <reporter username="brocknoland">Brock Noland</reporter>
                        <labels>
                    </labels>
                <created>Fri, 27 Dec 2013 16:38:27 +0000</created>
                <updated>Mon, 13 Jan 2014 14:39:44 +0000</updated>
                            <resolved>Mon, 13 Jan 2014 14:39:44 +0000</resolved>
                                    <version>0.12.0</version>
                                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="13857721" author="hiveqa" created="Fri, 27 Dec 2013 20:52:54 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12620620/HIVE-6115.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12620620/HIVE-6115.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4818 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/754/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/754/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/754/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/754/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12620620&lt;/p&gt;</comment>
                            <comment id="13857743" author="brocknoland" created="Fri, 27 Dec 2013 21:21:44 +0000"  >&lt;p&gt;I describe why the code is redundant here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5260?focusedCommentId=13857548&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13857548&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-5260?focusedCommentId=13857548&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13857548&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13857824" author="xuefuz" created="Fri, 27 Dec 2013 23:01:13 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13857853" author="ashutoshc" created="Sat, 28 Dec 2013 00:04:59 +0000"  >&lt;p&gt;There was a reason for this, but I forgot exactly what? Lets wait to hear from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sushanth&quot; class=&quot;user-hover&quot; rel=&quot;sushanth&quot;&gt;Sushanth Sowmyan&lt;/a&gt; on this.&lt;/p&gt;</comment>
                            <comment id="13858027" author="brocknoland" created="Sat, 28 Dec 2013 14:01:12 +0000"  >&lt;p&gt;OK it&apos;d be great to know so we can add comments clarifying the requirement.&lt;/p&gt;

&lt;p&gt;I should have clarified this in the description, but in regards to the first case, it&apos;s actually more worse than redundant since it causes any local overrides of hbase parameters to be overridden by hbase-default.xml.&lt;/p&gt;</comment>
                            <comment id="13859606" author="brocknoland" created="Tue, 31 Dec 2013 18:35:27 +0000"  >&lt;p&gt;Ashutosh, any idea when Sushanth will be around to weigh-in?&lt;/p&gt;</comment>
                            <comment id="13859629" author="ashutoshc" created="Tue, 31 Dec 2013 18:53:52 +0000"  >&lt;p&gt;I think he should be around later this week at latest. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=viraj&quot; class=&quot;user-hover&quot; rel=&quot;viraj&quot;&gt;Viraj Bhat&lt;/a&gt; may also have an idea for this piece of code.&lt;/p&gt;</comment>
                            <comment id="13863454" author="sushanth" created="Mon, 6 Jan 2014 21:36:22 +0000"  >&lt;p&gt;Hi guys,&lt;/p&gt;

&lt;p&gt;Looking through the code, there are two signatures for calls on addHbaseResources, one being addHBaseResources(Configuration,Map&amp;lt;String,String&amp;gt;) and the other being addHBaseResources(Configuration). The first function is implemented in the HiveHBaseStorageHandler itself, and the other is defined in HBaseConfiguration.&lt;/p&gt;

&lt;p&gt;The one in HBaseConfiguration does the following:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;adds resources (hbase config xmls) to the conf passed in to it&lt;/li&gt;
	&lt;li&gt;performs some checks.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The one in HiveHBaseStorageHandler does the following:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;instantiates a new conf, and runs HBaseConfiguration.addHBaseResources on it.&lt;/li&gt;
	&lt;li&gt;Then, iterates through its properties, and for all values in it that are null (i.e. not present - covers only adds, not updates) in jobconf, it copies them into the Map&amp;lt;String,String&amp;gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So, our code path is relevant for the input side, where if called from hcatalog, we should be updating jobconf itself as well, so the extra bit makes sense. On the output side, however, where we do a copy into a copyOfConf, that looks redundant.&lt;/p&gt;
</comment>
                            <comment id="13863459" author="sushanth" created="Mon, 6 Jan 2014 21:38:37 +0000"  >&lt;p&gt;I&apos;d love to have &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=viraj&quot; class=&quot;user-hover&quot; rel=&quot;viraj&quot;&gt;Viraj Bhat&lt;/a&gt; also comment - he might remember this refactor a bit better, I think the reason this redundancy was in is because we asked for a few other refactor changes that made the if-else structuring a bit more redundant than it used to be.&lt;/p&gt;</comment>
                            <comment id="13863466" author="brocknoland" created="Mon, 6 Jan 2014 21:46:42 +0000"  >&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;Thanks for this. The issue is that this code right here:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;     if (this.configureInputJobProps) {
       try {
        HBaseConfiguration.addHbaseResources(jobConf);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Adds hbase-default.xml as a resource to the jobConf and it does so after hbase configuration may already be added to the jobconf and thereby overrides any local configuration. Since HiveHBaseStorageHandler. addHBaseResources the relevant hbase configuration should already be present, my contention is that line should be removed.&lt;/p&gt;</comment>
                            <comment id="13863510" author="sushanth" created="Mon, 6 Jan 2014 22:23:11 +0000"  >&lt;p&gt;There are two purposes served - one, to check that hbase-default.xml and hbase-site.xml are accessible, which HiveHBaseStorageHandler.addHBaseResources achieves, and the other is to add those as requisite resources for the current job, which is achieved by the inner call directly to HBaseConfiguration on the jobconf.&lt;/p&gt;

&lt;p&gt;From a HCat perspective, if I remember correctly, the second is needed to setup and ship the job correctly, otherwise we&apos;d wind up fail with errors indicating that we&apos;re failing not being able to talk to zookeeper or the master.&lt;/p&gt;

&lt;p&gt;Per your contention, the problem is that if you do have a local override hbase-site.xml, it still winds up pulling in a default hbase-default.xml/hbase-site.xml and thus fails? I&apos;m a little confused as to how this might be a problem, since when those resources are added,  they&apos;re added by name, without any associated path, and thus, would need to be present as resolved in the classpath anyway.&lt;/p&gt;

&lt;p&gt;Or I was barking up the wrong tree with that interpretation, and the problem is the update semantic that HiveHBaseStorageHandler.addHBaseResources takes care of is abused, and we wind up nuking other conf values by replacing, rather than strictly updating only for values where the values do not exist. In which case it makes sense to have a segment there which goes something like this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;tundra:hive sush$ git diff hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java
diff --git a/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java b/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java
index fc63970..d76abe8 100644
--- a/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java
+++ b/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java
@@ -333,7 +333,11 @@ &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void configureTableJobProperties(
     &lt;span class=&quot;code-comment&quot;&gt;// check to see &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; an input job or an outputjob
&lt;/span&gt;     &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.configureInputJobProps) {
       &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
-        HBaseConfiguration.addHbaseResources(jobConf);
+        &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; k : jobProperties.keySet()){
+          jobConf.set(k, jobProperties.get(k));
+        }
+        jobConf.addResource(&lt;span class=&quot;code-quote&quot;&gt;&quot;hbase-&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.xml&quot;&lt;/span&gt;);
+        jobConf.addResource(&lt;span class=&quot;code-quote&quot;&gt;&quot;hbase-site.xml&quot;&lt;/span&gt;);
         addHBaseDelegationToken(jobConf);
       }&lt;span class=&quot;code-comment&quot;&gt;//&lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt;
&lt;/span&gt;       &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (IOException e) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This, then, would be functionally equivalent and satisfy the need for those resources to be present, and not pollute jobconf with the rest of the parameters?&lt;/p&gt;

&lt;p&gt;This would then, however, be forcing visibility of hbase&apos;s internals out onto here, and looks hacky. What parameters get overridden by hbase&apos;s resource import that should not be overridden? This might be something to fix on HBaseConfiguration.addHBaseResources&apos; end instead, then.&lt;/p&gt;</comment>
                            <comment id="13863563" author="brocknoland" created="Mon, 6 Jan 2014 22:46:44 +0000"  >&lt;p&gt;Do you know why the tests pass after removing this code? Shouldn&apos;t we have at least one test that exhibits the requirement for this behavior?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Per your contention, the problem is that if you do have a local override hbase-site.xml, it still winds up pulling in a default hbase-default.xml/hbase-site.xml and thus fails?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Users often set hbase configuration settings relating to hive in hive-site.xml. Since the Configuration object stores resources in a list, hbase-default.xml is added after hive-site.xml and therefore takes precedence over it.&lt;/p&gt;</comment>
                            <comment id="13863581" author="sushanth" created="Mon, 6 Jan 2014 22:58:37 +0000"  >&lt;p&gt;I think we have e2e tests that run on an actual cluster that have failed in the past without that, testing under a local minicluster where everything is available makes these tests succeed in the unit test runs. (Tagging &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ndimiduk&quot; class=&quot;user-hover&quot; rel=&quot;ndimiduk&quot;&gt;Nick Dimiduk&lt;/a&gt; as he might be interested as well)&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Users often set hbase configuration settings relating to hive in hive-site.xml. Since the Configuration object stores resources in a list, hbase-default.xml is added after hive-site.xml and therefore takes precedence over it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ouch, I can see how that&apos;s problematic, and essentially incompatible with the idea on how addHbaseResources is used, which is to defer to an installed hbase cluster.&lt;/p&gt;</comment>
                            <comment id="13863771" author="ndimiduk" created="Tue, 7 Jan 2014 01:25:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sushanth&quot; class=&quot;user-hover&quot; rel=&quot;sushanth&quot;&gt;Sushanth Sowmyan&lt;/a&gt;: &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;testing under a local minicluster where everything is available makes these tests succeed in the unit test runs. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t have enough context on how Hive tests are executed, but I have seen issues which are not caught by standard unit tests but do surface when run with a real cluster (see also &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5515&quot; title=&quot;Writing to an HBase table throws IllegalArgumentException, failing job submission&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5515&quot;&gt;&lt;del&gt;HIVE-5515&lt;/del&gt;&lt;/a&gt;). Over in HBaseLand, we have the IntegrationTest category which are designed to run on real clusters, not the miniclusters, for finding such issues (the most common being classpaths unrealistic on a distributed deployment). In my experience testing our MapReduce code, this additional test harness has been valuable.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Users often set hbase configuration settings relating to hive in hive-site.xml.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I just &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5659?focusedCommentId=13863752&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13863752&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;commented&lt;/a&gt; about this over on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5659&quot; title=&quot;HBaseStorageHandler overwrites Hive-set HBase properties with hbase-defaults&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5659&quot;&gt;&lt;del&gt;HIVE-5659&lt;/del&gt;&lt;/a&gt;. I might insert hive-site.xml between (2) and (3) in that list, but what if Hive and HBase might have conflicting values for some settings. Anything come to mind? What HBase configs are your Hive users setting in hive-site.xml ?&lt;/p&gt;</comment>
                            <comment id="13863806" author="sushanth" created="Tue, 7 Jan 2014 01:59:43 +0000"  >&lt;p&gt;I mentioned this on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5659&quot; title=&quot;HBaseStorageHandler overwrites Hive-set HBase properties with hbase-defaults&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5659&quot;&gt;&lt;del&gt;HIVE-5659&lt;/del&gt;&lt;/a&gt; as well, but want to add this here too - I agree with Nick&apos;s order-of-resolution need, and thus, the need to make sure that the addResources does not wind up clobbering already-set config parameters, but I would strongly advise any user from putting any hbase-specific config in hive-site.xml. That seems to be asking for errors arising from messy config keeping. It can lead up to two-sources of truth if hive treats hive&apos;s copy of hbase config as prime, and hbase server/etc that the handler talk to treat hbase config as prime truth.&lt;/p&gt;</comment>
                            <comment id="13863824" author="ndimiduk" created="Tue, 7 Jan 2014 02:18:00 +0000"  >&lt;p&gt;I agree with you, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sushanth&quot; class=&quot;user-hover&quot; rel=&quot;sushanth&quot;&gt;Sushanth Sowmyan&lt;/a&gt;, on principal, but I&apos;m curious to hear what configs &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt; is seeing his users override in hive-site.xml. Maybe HBase can do something smarter out of the box.&lt;/p&gt;</comment>
                            <comment id="13863909" author="swarnim" created="Tue, 7 Jan 2014 05:04:57 +0000"  >&lt;p&gt;My 0.02 but two of the properties that we use in hive-site.xml to override properties in hbase-site.xml are &quot;hbase.zookeeper.quorum&quot; and &quot;hbase.client.scanner.caching&quot;. Agree that &quot;hbase.zookeeper.quorum&quot; should actually come from hbase-site.xml but for some reason, hive refuses to read that property(bug maybe?) and hence has to be redefined in hive-site.xml.&lt;/p&gt;

&lt;p&gt;The scanner caching property is used to just give the users greater control over fine tuning the performance of their hive queries running on top of hbase. &lt;/p&gt;</comment>
                            <comment id="13864317" author="brocknoland" created="Tue, 7 Jan 2014 15:04:32 +0000"  >&lt;p&gt;Linking with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5659&quot; title=&quot;HBaseStorageHandler overwrites Hive-set HBase properties with hbase-defaults&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5659&quot;&gt;&lt;del&gt;HIVE-5659&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13866051" author="sushanth" created="Wed, 8 Jan 2014 23:29:59 +0000"  >&lt;p&gt;Having read through addResources order resolution a bit more, I believe the solution is to have the following change:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;     &lt;span class=&quot;code-comment&quot;&gt;// check to see &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; an input job or an outputjob
&lt;/span&gt;     &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.configureInputJobProps) {
       &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
-        HBaseConfiguration.addHbaseResources(jobConf);
+        &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; k : jobProperties.keySet()){
+          jobConf.set(k, jobProperties.get(k));
+        }
         addHBaseDelegationToken(jobConf);
       }&lt;span class=&quot;code-comment&quot;&gt;//&lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt;
&lt;/span&gt;       &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (IOException e) {
@@ -342,8 +341,6 @@ &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void configureTableJobProperties(
       } &lt;span class=&quot;code-comment&quot;&gt;//input job properties
&lt;/span&gt;     }
     &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
-      Configuration copyOfConf = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Configuration(jobConf);
-      HBaseConfiguration.addHbaseResources(copyOfConf);
       jobProperties.put(TableOutputFormat.OUTPUT_TABLE, tableName);
     } &lt;span class=&quot;code-comment&quot;&gt;// output job properties
&lt;/span&gt;   }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13866055" author="sushanth" created="Wed, 8 Jan 2014 23:32:00 +0000"  >&lt;p&gt;The above code will only pick up those config parameters from the newly added resources that aren&apos;t already defined in jobconf, and add them to the jobconf, which hcat needs, and satisfies the non-clobbering requirement as well.&lt;/p&gt;</comment>
                            <comment id="13866741" author="brocknoland" created="Thu, 9 Jan 2014 16:09:11 +0000"  >&lt;p&gt;Sounds good to me. Thank you for looking at this!!&lt;/p&gt;</comment>
                            <comment id="13866746" author="brocknoland" created="Thu, 9 Jan 2014 16:18:59 +0000"  >&lt;p&gt;Updated patch attached.&lt;/p&gt;</comment>
                            <comment id="13867382" author="hiveqa" created="Fri, 10 Jan 2014 01:11:10 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12622201/HIVE-6115.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12622201/HIVE-6115.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 4904 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_bucket_num_reducers
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/845/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/845/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/845/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/845/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12622201&lt;/p&gt;</comment>
                            <comment id="13867608" author="viraj" created="Fri, 10 Jan 2014 08:03:41 +0000"  >&lt;p&gt;Hi Brock,&lt;br/&gt;
 Thanks for creating this Jira. I am +1 with the patch. The tests for &lt;b&gt;TestPigHBaseStorageHandler&lt;/b&gt; run fine and also eliminates those duplicates calls.&lt;br/&gt;
Viraj&lt;/p&gt;</comment>
                            <comment id="13868504" author="sushanth" created="Sat, 11 Jan 2014 00:11:21 +0000"  >&lt;p&gt;I&apos;ve tested the latest patch, and I&apos;m +1 on it.&lt;/p&gt;</comment>
                            <comment id="13868510" author="xuefuz" created="Sat, 11 Jan 2014 00:15:03 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13869582" author="brocknoland" created="Mon, 13 Jan 2014 14:39:44 +0000"  >&lt;p&gt;Thank you everyone! I have committed this change to trunk!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12667867">HIVE-5260</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12675926">HIVE-5659</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12622201" name="HIVE-6115.patch" size="1196" author="brocknoland" created="Thu, 9 Jan 2014 16:18:59 +0000"/>
                            <attachment id="12620620" name="HIVE-6115.patch" size="1018" author="brocknoland" created="Fri, 27 Dec 2013 16:46:03 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 27 Dec 2013 20:52:54 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365527</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 2 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1r04n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365828</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-6116] Use Paths consistently III</title>
                <link>https://issues.apache.org/jira/browse/HIVE-6116</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Another one in patch series to make use of Paths consistently.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12686557">HIVE-6116</key>
            <summary>Use Paths consistently III</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ashutoshc">Ashutosh Chauhan</assignee>
                                    <reporter username="ashutoshc">Ashutosh Chauhan</reporter>
                        <labels>
                    </labels>
                <created>Fri, 27 Dec 2013 19:27:47 +0000</created>
                <updated>Tue, 31 Dec 2013 17:01:35 +0000</updated>
                            <resolved>Tue, 31 Dec 2013 17:01:34 +0000</resolved>
                                                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13857663" author="sershe" created="Fri, 27 Dec 2013 19:33:17 +0000"  >&lt;p&gt;lgtm&lt;/p&gt;</comment>
                            <comment id="13857794" author="hiveqa" created="Fri, 27 Dec 2013 22:20:23 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12620635/HIVE-6116.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12620635/HIVE-6116.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 118 failed/errored test(s), 4818 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join0
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join11
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join12
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join13
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join14_hadoop20
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join15
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join16
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join17
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join19
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join20
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join21
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join22
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join23
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join24
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join25
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join26
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join27
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join29
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join30
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join31
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join32
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join8
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join_filters
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join_nulls
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_smb_mapjoin_14
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_13
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_14
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_15
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_9
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucket_map_join_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucket_map_join_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketmapjoin1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketmapjoin4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketmapjoin5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_column_access_stats
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cp_mj_rc
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_explain_rearrange
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_infer_bucket_sort_convert_join
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join25
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join26
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join27
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join28
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join29
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join30
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join31
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join32
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join32_lessSize
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join33
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join34
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join35
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join36
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join37
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join38
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join39
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join40
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_empty
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_filters
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_filters_overlap
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_map_ppr
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_nulls
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_nullsafe
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_reorder4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_star
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_filter_on_outerjoin
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_hook
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_mapjoin
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_subquery
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_subquery2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_test_outer
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multiMapJoin1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multiMapJoin2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_nonblock_op_deduplicate
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_select_transform_hint
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_semijoin
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_skewjoin
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_13
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_14
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_15
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_16
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_17
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_25
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sort_merge_join_desc_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sort_merge_join_desc_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sort_merge_join_desc_3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sort_merge_join_desc_4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats11
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_table_access_keys_stats
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union34
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_left_outer_join
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorized_context
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorized_mapjoin
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_infer_bucket_sort_map_operators
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_smb_mapjoin_8
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/755/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/755/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/755/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/755/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 118 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12620635&lt;/p&gt;</comment>
                            <comment id="13857800" author="sershe" created="Fri, 27 Dec 2013 22:29:31 +0000"  >&lt;p&gt;well, as long as tests pass&lt;/p&gt;</comment>
                            <comment id="13858176" author="hiveqa" created="Sat, 28 Dec 2013 23:35:28 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12620715/HIVE-6116.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12620715/HIVE-6116.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 117 failed/errored test(s), 4818 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join0
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join11
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join12
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join13
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join14_hadoop20
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join15
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join16
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join17
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join19
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join20
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join21
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join22
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join23
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join24
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join25
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join26
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join27
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join29
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join30
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join31
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join32
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join8
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join_filters
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join_nulls
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_smb_mapjoin_14
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_10
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_13
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_14
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_15
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_sortmerge_join_9
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucket_map_join_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucket_map_join_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketcontext_6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketmapjoin1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketmapjoin4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_bucketmapjoin5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_column_access_stats
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cp_mj_rc
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_infer_bucket_sort_convert_join
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join25
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join26
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join27
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join28
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join29
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join30
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join31
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join32
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join32_lessSize
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join33
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join34
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join35
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join36
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join37
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join38
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join39
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join40
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_empty
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_filters
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_filters_overlap
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_map_ppr
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_nulls
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_nullsafe
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_reorder4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join_star
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_filter_on_outerjoin
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_hook
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_mapjoin
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_subquery
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_subquery2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_mapjoin_test_outer
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multiMapJoin1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_multiMapJoin2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_nonblock_op_deduplicate
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_select_transform_hint
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_semijoin
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_skewjoin
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_13
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_14
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_15
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_16
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_17
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_25
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_5
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_smb_mapjoin_7
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sort_merge_join_desc_1
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sort_merge_join_desc_2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sort_merge_join_desc_3
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_sort_merge_join_desc_4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_stats11
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_table_access_keys_stats
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union34
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_left_outer_join
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorized_context
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vectorized_mapjoin
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_infer_bucket_sort_map_operators
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_smb_mapjoin_8
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/761/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/761/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/761/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/761/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 117 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12620715&lt;/p&gt;</comment>
                            <comment id="13858244" author="hiveqa" created="Sun, 29 Dec 2013 04:12:26 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12620747/HIVE-6116.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12620747/HIVE-6116.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 4818 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_bucket_num_reducers
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/763/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/763/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/763/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/763/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12620747&lt;/p&gt;</comment>
                            <comment id="13858246" author="ashutoshc" created="Sun, 29 Dec 2013 04:23:42 +0000"  >&lt;p&gt;Above failed test is known to be flaky. This is ready for review. &lt;a href=&quot;https://reviews.apache.org/r/16502/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/16502/&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;Xuefu Zhang&lt;/a&gt; can you take a look?&lt;/p&gt;</comment>
                            <comment id="13858865" author="xuefuz" created="Mon, 30 Dec 2013 15:19:22 +0000"  >&lt;p&gt;Patch looks good. A minor comment on RB.&lt;/p&gt;</comment>
                            <comment id="13858971" author="ashutoshc" created="Mon, 30 Dec 2013 18:30:59 +0000"  >&lt;p&gt;Updated patch on RB with correct formatting. No code changes. Only whitespace changes.&lt;/p&gt;</comment>
                            <comment id="13859357" author="xuefuz" created="Tue, 31 Dec 2013 06:11:27 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13859573" author="ashutoshc" created="Tue, 31 Dec 2013 17:01:35 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Xuefu for review!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12620715" name="HIVE-6116.2.patch" size="21189" author="ashutoshc" created="Sat, 28 Dec 2013 07:06:24 +0000"/>
                            <attachment id="12620747" name="HIVE-6116.3.patch" size="21179" author="ashutoshc" created="Sun, 29 Dec 2013 01:47:10 +0000"/>
                            <attachment id="12620635" name="HIVE-6116.patch" size="19411" author="ashutoshc" created="Fri, 27 Dec 2013 19:28:23 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 27 Dec 2013 19:33:17 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365548</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 3 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1r0fb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365856</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-6117] mapreduce.RecordReader instance needs to be initialized</title>
                <link>https://issues.apache.org/jira/browse/HIVE-6117</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The HBase storage handler makes use of a mapreduce.RecordReader instance but does not initialize it when consumed from local context. This results in a NPE for some queries, for instance&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;create table hbase_1(key string, age int) stored by &apos;org.apache.hadoop.hive.hbase.HBaseStorageHandler&apos; with serdeproperties ( &quot;hbase.columns.mapping&quot; = &quot;info:age&quot;);
insert overwrite table hbase_1 select name, SUM(age) from studenttab10k group by name;
select * from hbase_1;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The select statement throws the following exception&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;13/12/18 01:30:32 ERROR CliDriver: Failed with exception java.io.IOException:java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:551)
at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:489)
at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:136)
at org.apache.hadoop.hive.ql.Driver.getResults(Driver.java:1494)
at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:271)
at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)
at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:413)
at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:348)
at org.apache.hadoop.hive.cli.CliDriver.processReader(CliDriver.java:446)
at org.apache.hadoop.hive.cli.CliDriver.processFile(CliDriver.java:456)
at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:737)
at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:675)
at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:614)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:601)
at org.apache.hadoop.util.RunJar.main(RunJar.java:212)
Caused by: java.lang.NullPointerException
at org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.nextKeyValue(TableRecordReaderImpl.java:196)
at org.apache.hadoop.hbase.mapreduce.TableRecordReader.nextKeyValue(TableRecordReader.java:138)
at org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat$1.next(HiveHBaseTableInputFormat.java:234)
at org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat$1.next(HiveHBaseTableInputFormat.java:193)
at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:521)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12686560">HIVE-6117</key>
            <summary>mapreduce.RecordReader instance needs to be initialized</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ndimiduk">Nick Dimiduk</assignee>
                                    <reporter username="ndimiduk">Nick Dimiduk</reporter>
                        <labels>
                    </labels>
                <created>Fri, 27 Dec 2013 19:46:24 +0000</created>
                <updated>Mon, 30 Dec 2013 17:47:41 +0000</updated>
                            <resolved>Mon, 30 Dec 2013 14:54:23 +0000</resolved>
                                                    <fixVersion>0.13.0</fixVersion>
                                    <component>HBase Handler</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13857681" author="ndimiduk" created="Fri, 27 Dec 2013 19:54:36 +0000"  >&lt;p&gt;Attaching patch for trunk.&lt;/p&gt;</comment>
                            <comment id="13857689" author="brocknoland" created="Fri, 27 Dec 2013 20:06:09 +0000"  >&lt;p&gt;Thanks Nick. Looks like this was caused by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9791&quot; title=&quot;MR initializes scanner twice&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9791&quot;&gt;&lt;del&gt;HBASE-9791&lt;/del&gt;&lt;/a&gt;. Was hive not correctly using the API or this an API change?&lt;/p&gt;</comment>
                            <comment id="13857697" author="ndimiduk" created="Fri, 27 Dec 2013 20:16:33 +0000"  >&lt;p&gt;Oh, good catch &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt;. I think the responsibility lies with Hive because, in this case, the RecordReader is being consumed outside of the MapReduce Framework context. I don&apos;t know &lt;b&gt;where&lt;/b&gt; Hive should initialize the RecordReader &amp;#8211; my patch may result in a double-initialize for the mapreduce case, but corrects the problem for the local query. I think, somehow, processLocalCmd needs to indicate to HiveHBaseTableInputFormat that its RecordReader is being consumed outside of MapReduce. Perhaps you can advise?&lt;/p&gt;</comment>
                            <comment id="13857735" author="brocknoland" created="Fri, 27 Dec 2013 21:05:53 +0000"  >&lt;p&gt;Hmm, does this same error not occur during a MR run?&lt;/p&gt;</comment>
                            <comment id="13857747" author="ndimiduk" created="Fri, 27 Dec 2013 21:25:47 +0000"  >&lt;p&gt;Not sure; can I force the SELECT statement to run as a job?&lt;/p&gt;</comment>
                            <comment id="13857749" author="brocknoland" created="Fri, 27 Dec 2013 21:28:27 +0000"  >&lt;p&gt;SELECT count(&amp;#42;) from table&lt;/p&gt;</comment>
                            <comment id="13857758" author="ndimiduk" created="Fri, 27 Dec 2013 21:35:43 +0000"  >&lt;p&gt;SELECT count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; FROM hbase_1; gave me a MR job. It ran without complaint.&lt;/p&gt;</comment>
                            <comment id="13857762" author="brocknoland" created="Fri, 27 Dec 2013 21:39:20 +0000"  >&lt;p&gt;It ran correctly with or without the patch?&lt;/p&gt;</comment>
                            <comment id="13857763" author="ndimiduk" created="Fri, 27 Dec 2013 21:41:25 +0000"  >&lt;p&gt;Ran correctly with the patch.&lt;/p&gt;

&lt;p&gt;BuildBot should verify as well, yes?&lt;/p&gt;</comment>
                            <comment id="13857784" author="brocknoland" created="Fri, 27 Dec 2013 21:56:33 +0000"  >&lt;p&gt;Thanks Nick!  I have seen this error with MR + HBase trunk.&lt;/p&gt;

&lt;p&gt;As fair as I can tell we have not yet answered the question &quot;Was hive not correctly using the API or this an API change?&quot; I am fine making the change to Hive, but we should know if hive was simply using HBase incorrectly or if HBase is changing the API.&lt;/p&gt;

&lt;p&gt;Brock&lt;/p&gt;</comment>
                            <comment id="13857818" author="ndimiduk" created="Fri, 27 Dec 2013 22:54:05 +0000"  >&lt;p&gt;Technically speaking, HBase changed the way it initializes this particular MapReduce component via a public API, thus HBase&apos;s API has changed. Hive is consuming that component without respecting its API &amp;#8211; that is, Hadoop&apos;s mapreduce.RecordReader says the framework will call initialize, so Hive should be calling initialize when consuming it outside of the MapReduce Framework context. I think the answer is &quot;both&quot;. Perhaps &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9791&quot; title=&quot;MR initializes scanner twice&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9791&quot;&gt;&lt;del&gt;HBASE-9791&lt;/del&gt;&lt;/a&gt; needs to add a release note.&lt;/p&gt;

&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;Jimmy Xiang&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13858024" author="brocknoland" created="Sat, 28 Dec 2013 13:55:02 +0000"  >&lt;p&gt;Reuploading the exact same patch with a new file name so HiveQA will pick it up.&lt;/p&gt;</comment>
                            <comment id="13858025" author="brocknoland" created="Sat, 28 Dec 2013 13:57:40 +0000"  >&lt;p&gt;Thank you for clarifying. I am +1 if the tests pass.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Hadoop&apos;s mapreduce.RecordReader says the framework will call initialize,&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What&apos;s interesting is I have seen this same error occur within an MR job. Additionally we are doing some weird wrapping of RR here. Therefore I think it&apos;s likely that Hive should be calling initialize itself even in the MR case. I think this patch will in fact do this.&lt;/p&gt;</comment>
                            <comment id="13858201" author="hiveqa" created="Sun, 29 Dec 2013 01:04:03 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12620732/HIVE-6117.0.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12620732/HIVE-6117.0.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4818 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/762/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/762/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/762/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/762/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12620732&lt;/p&gt;</comment>
                            <comment id="13858497" author="jxiang" created="Mon, 30 Dec 2013 00:47:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ndimiduk&quot; class=&quot;user-hover&quot; rel=&quot;ndimiduk&quot;&gt;Nick Dimiduk&lt;/a&gt;, I think &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9791&quot; title=&quot;MR initializes scanner twice&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9791&quot;&gt;&lt;del&gt;HBASE-9791&lt;/del&gt;&lt;/a&gt; fixed a bug in HBase that does initialization twice. If some subclass needs to call initialization again, does this mean the fix in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9791&quot; title=&quot;MR initializes scanner twice&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9791&quot;&gt;&lt;del&gt;HBASE-9791&lt;/del&gt;&lt;/a&gt; is not right?  If it is right, why should HIVE need to call init again?&lt;/p&gt;</comment>
                            <comment id="13858837" author="brocknoland" created="Mon, 30 Dec 2013 14:43:07 +0000"  >&lt;p&gt;Hey guys,&lt;/p&gt;

&lt;p&gt;I think I see the issue here. o.a.h.mapreduce.RecordReader has an initialize method which is called by the mapper. o.a.h.mapred.RecordReader does not have an initialize method. Hive uses the mapred API so you can see here: &lt;a href=&quot;https://github.com/apache/hive/blob/fb63a28cd5fddb5e5c974cab84cd9c3a4155e40d/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java#L178&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hive/blob/fb63a28cd5fddb5e5c974cab84cd9c3a4155e40d/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java#L178&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;that we wrap the mapreduce RR from HBase in a mapred RR. Therefore it&apos;s hive&apos;s responsibility to call initialize which we are not doing. Therefore the patch looks correct and I will commit.&lt;/p&gt;</comment>
                            <comment id="13858845" author="brocknoland" created="Mon, 30 Dec 2013 14:52:52 +0000"  >&lt;p&gt;I also verified that this patch fixes the NPE I was seeing with &lt;b&gt;both&lt;/b&gt; select &amp;#42; from table (no-MR job) and select count(&amp;#42;) from table (MR job).&lt;/p&gt;</comment>
                            <comment id="13858846" author="brocknoland" created="Mon, 30 Dec 2013 14:54:23 +0000"  >&lt;p&gt;Committed to trunk! Thank you Nick and Jimmy for your help on this one!&lt;/p&gt;</comment>
                            <comment id="13858955" author="ndimiduk" created="Mon, 30 Dec 2013 17:47:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;that we wrap the mapreduce RR from HBase in a mapred RR. Therefore it&apos;s hive&apos;s responsibility to call initialize which we are not doing. Therefore the patch looks correct and I will commit.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, that&apos;s my understanding too. Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;Jimmy Xiang&lt;/a&gt; for the context and quick response!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12674338">HBASE-9791</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12620641" name="6117.00.patch" size="807" author="ndimiduk" created="Fri, 27 Dec 2013 19:54:36 +0000"/>
                            <attachment id="12620732" name="HIVE-6117.0.patch" size="807" author="brocknoland" created="Sat, 28 Dec 2013 13:55:02 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 27 Dec 2013 20:06:09 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365551</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1r0fz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365859</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-6118] PTest2 is banned periodically by AWS because JClouds is too agressive</title>
                <link>https://issues.apache.org/jira/browse/HIVE-6118</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12686576">HIVE-6118</key>
            <summary>PTest2 is banned periodically by AWS because JClouds is too agressive</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="brocknoland">Brock Noland</assignee>
                                    <reporter username="brocknoland">Brock Noland</reporter>
                        <labels>
                    </labels>
                <created>Fri, 27 Dec 2013 22:22:48 +0000</created>
                <updated>Sat, 28 Dec 2013 07:01:13 +0000</updated>
                            <resolved>Sat, 28 Dec 2013 07:01:13 +0000</resolved>
                                                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13857797" author="brocknoland" created="Fri, 27 Dec 2013 22:24:03 +0000"  >&lt;p&gt;1) adds a few sleeps&lt;br/&gt;
2) Increases default sleep/retry times&lt;br/&gt;
3) adds a license header which was missing&lt;/p&gt;</comment>
                            <comment id="13857802" author="brocknoland" created="Fri, 27 Dec 2013 22:30:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt; same here...thx!!&lt;/p&gt;</comment>
                            <comment id="13857849" author="ashutoshc" created="Fri, 27 Dec 2013 23:59:39 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13857897" author="hiveqa" created="Sat, 28 Dec 2013 01:25:19 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12620668/HIVE-6118.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12620668/HIVE-6118.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4818 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/760/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/760/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/760/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/760/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12620668&lt;/p&gt;</comment>
                            <comment id="13857963" author="ashutoshc" created="Sat, 28 Dec 2013 07:01:13 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Brock!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12620668" name="HIVE-6118.patch" size="8450" author="brocknoland" created="Fri, 27 Dec 2013 22:23:10 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 27 Dec 2013 23:59:39 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365567</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 4 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1r0jj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365875</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>
</channel>
</rss>
