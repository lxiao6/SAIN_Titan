<!--
RSS generated by JIRA (7.6.3#76005-sha1:8a4e38d34af948780dbf52044e7aafb13a7cae58) at Tue Jan 22 03:23:06 UTC 2019

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<!-- If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
    <channel>
        <title>ASF JIRA</title>
        <link>https://issues.apache.org/jira/issues/?jql=project+%3D+HIVE+AND+created+%3E%3D+2013-5-1+AND+created+%3C%3D+2013-5-8+ORDER+BY+key+ASC</link>
        <description>An XML representation of a search request</description>
                <language>en-uk</language>
                        <issue start="0" end="57" total="57"/>
                <build-info>
            <version>7.6.3</version>
            <build-number>76005</build-number>
            <build-date>09-01-2018</build-date>
        </build-info>

<item>
            <title>[HIVE-4463] Add unit tests for vectorized IS NULL and IS NOT NULL filters</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4463</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Add junit tests for vectorized IS NULL and IS NOT NULL.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645569">HIVE-4463</key>
            <summary>Add unit tests for vectorized IS NULL and IS NOT NULL filters</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="jnp">Jitendra Nath Pandey</assignee>
                                    <reporter username="ehans">Eric Hanson</reporter>
                        <labels>
                    </labels>
                <created>Wed, 1 May 2013 00:57:31 +0000</created>
                <updated>Tue, 14 May 2013 21:11:02 +0000</updated>
                            <resolved>Tue, 14 May 2013 21:11:02 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                    <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12646926">HIVE-4534</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>325930</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 38 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1k8af:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326275</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4464] Hive&apos;s JDBC module doesn&apos;t compile under openjdk 7</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4464</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Hive currently fails to compile when compiled with openjdk 7.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645583">HIVE-4464</key>
            <summary>Hive&apos;s JDBC module doesn&apos;t compile under openjdk 7</summary>
                <type id="3" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21148&amp;avatarType=issuetype">Task</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="owen.omalley">Owen O&apos;Malley</assignee>
                                    <reporter username="owen.omalley">Owen O&apos;Malley</reporter>
                        <labels>
                    </labels>
                <created>Wed, 1 May 2013 02:30:22 +0000</created>
                <updated>Wed, 1 May 2013 02:30:22 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>325944</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 38 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1k8dj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326289</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4465] webhcat e2e tests succeed regardless of exitvalue</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4465</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently the webhcat tests that check job status for Pig, Hive, and MR do not check the exit value of the job.  So a job can fail and the test will succeed.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645586">HIVE-4465</key>
            <summary>webhcat e2e tests succeed regardless of exitvalue</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="alangates">Alan Gates</assignee>
                                    <reporter username="alangates">Alan Gates</reporter>
                        <labels>
                    </labels>
                <created>Wed, 1 May 2013 03:37:25 +0000</created>
                <updated>Tue, 15 Oct 2013 23:31:05 +0000</updated>
                            <resolved>Wed, 1 May 2013 16:19:42 +0000</resolved>
                                    <version>0.11.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13646346" author="alangates" created="Wed, 1 May 2013 03:39:23 +0000"  >&lt;p&gt;This patch changes the test tool to check the exitValue returned in the JSON.  It also updates the tests to specify the expected exit value.&lt;/p&gt;</comment>
                            <comment id="13646421" author="daijy" created="Wed, 1 May 2013 06:40:16 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13646686" author="alangates" created="Wed, 1 May 2013 16:19:42 +0000"  >&lt;p&gt;Patch checked in.  Thank you Daniel for the review.&lt;/p&gt;</comment>
                            <comment id="13647254" author="hudson" created="Thu, 2 May 2013 03:55:10 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2088 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2088/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2088/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4465&quot; title=&quot;webhcat e2e tests succeed regardless of exitvalue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4465&quot;&gt;&lt;del&gt;HIVE-4465&lt;/del&gt;&lt;/a&gt; webhcat e2e tests succeed regardless of exitvalue (Revision 1478073)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
gates : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1478073&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1478073&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/src/test/e2e/templeton/drivers/TestDriverCurl.pm&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/src/test/e2e/templeton/tests/jobsubmission.conf&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13796117" author="ashutoshc" created="Tue, 15 Oct 2013 23:31:05 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12581330" name="HIVE-4465.patch" size="6190" author="alangates" created="Wed, 1 May 2013 03:39:23 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 1 May 2013 06:40:16 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>325947</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1k8e7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326292</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4466] Fix continue.on.failure in unit tests to -well- continue on failure in unit tests</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4466</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;continue.on.failure is no longer hooked up to anything in the build scripts. more importantly, the only choice right now is to continue through a module and then fail.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645595">HIVE-4466</key>
            <summary>Fix continue.on.failure in unit tests to -well- continue on failure in unit tests</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hagleitn">Gunther Hagleitner</assignee>
                                    <reporter username="hagleitn">Gunther Hagleitner</reporter>
                        <labels>
                    </labels>
                <created>Wed, 1 May 2013 06:29:19 +0000</created>
                <updated>Tue, 15 Oct 2013 23:30:48 +0000</updated>
                            <resolved>Wed, 8 May 2013 05:53:53 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13647991" author="ashutoshc" created="Thu, 2 May 2013 22:43:50 +0000"  >&lt;p&gt;+1 will commit if tests pass.&lt;/p&gt;</comment>
                            <comment id="13651646" author="ashutoshc" created="Wed, 8 May 2013 05:53:53 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Gunther!&lt;/p&gt;</comment>
                            <comment id="13652450" author="hudson" created="Wed, 8 May 2013 22:43:53 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2092 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2092/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2092/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4466&quot; title=&quot;Fix continue.on.failure in unit tests to -well- continue on failure in unit tests&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4466&quot;&gt;&lt;del&gt;HIVE-4466&lt;/del&gt;&lt;/a&gt; : Fix continue.on.failure in unit tests to &lt;del&gt;well&lt;/del&gt; continue on failure in unit tests (Gunther Hagleitner via Ashutosh Chauhan) (Revision 1480164)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1480164&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1480164&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/build-common.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/build.properties&lt;/li&gt;
	&lt;li&gt;/hive/trunk/build.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13652670" author="hudson" created="Thu, 9 May 2013 02:10:15 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #188 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/188/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/188/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4466&quot; title=&quot;Fix continue.on.failure in unit tests to -well- continue on failure in unit tests&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4466&quot;&gt;&lt;del&gt;HIVE-4466&lt;/del&gt;&lt;/a&gt; : Fix continue.on.failure in unit tests to &lt;del&gt;well&lt;/del&gt; continue on failure in unit tests (Gunther Hagleitner via Ashutosh Chauhan) (Revision 1480164)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1480164&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1480164&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/build-common.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/build.properties&lt;/li&gt;
	&lt;li&gt;/hive/trunk/build.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13796076" author="ashutoshc" created="Tue, 15 Oct 2013 23:30:48 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12581338" name="HIVE-4466.1.patch" size="3505" author="hagleitn" created="Wed, 1 May 2013 06:30:28 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 2 May 2013 22:43:50 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>325956</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1k8g7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326301</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4467] HiveConnection does not handle failures correctly</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4467</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;HiveConnection uses Utils.verifySuccess* routines to check if there is any error from the server side. This is not handled well. In Utils.verifySuccess() when withInfo is &apos;false&apos;, the condition evaluates to &apos;false&apos; and no SQLexception is thrown even though there could be a problem on the server.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645622">HIVE-4467</key>
            <summary>HiveConnection does not handle failures correctly</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="thiruvel">Thiruvel Thirumoolan</assignee>
                                    <reporter username="thiruvel">Thiruvel Thirumoolan</reporter>
                        <labels>
                    </labels>
                <created>Wed, 1 May 2013 10:05:02 +0000</created>
                <updated>Sun, 2 Jun 2013 18:48:02 +0000</updated>
                                            <version>0.11.0</version>
                    <version>0.12.0</version>
                                                    <component>HiveServer2</component>
                    <component>JDBC</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13646494" author="thiruvel" created="Wed, 1 May 2013 10:26:36 +0000"  >&lt;p&gt;Attaching patch, I have made the functions straightforward and not preserved the boolean in the UtilsverifySuccess() methods. I am unsure where TStatusCode.SUCCESS_WITH_INFO_STATUS is set in the HS2 code and couldn&apos;t find any occurrences. Is there any reason/intention for checking for that status?&lt;/p&gt;</comment>
                            <comment id="13646996" author="thiruvel" created="Wed, 1 May 2013 22:09:16 +0000"  >&lt;p&gt;Uploaded patch to phabricator: &lt;a href=&quot;https://reviews.facebook.net/D10629&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10629&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13647003" author="cwsteinbach" created="Wed, 1 May 2013 22:20:35 +0000"  >&lt;p&gt;The HS2 API is modeled on the &lt;a href=&quot;http://en.wikipedia.org/wiki/SQL/CLI&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;SQL/CLI standard&lt;/a&gt;. In most cases SQL/CLI is interchangeable with ODBC, so most answers about why things are structured the way they are can be answered by consulting the ODBC API documentation. Here&apos;s the relevant page for SUCCESS_WITH_INFO: &lt;a href=&quot;http://msdn.microsoft.com/en-us/library/windows/desktop/ms716219(v=vs.85).aspx&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://msdn.microsoft.com/en-us/library/windows/desktop/ms716219(v=vs.85).aspx&lt;/a&gt;&lt;/p&gt;
</comment>
                            <comment id="13647025" author="cdrome" created="Wed, 1 May 2013 22:46:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cwsteinbach&quot; class=&quot;user-hover&quot; rel=&quot;cwsteinbach&quot;&gt;Carl Steinbach&lt;/a&gt;, the issue is with the condition in the verifySuccess method:&lt;/p&gt;

&lt;p&gt;if ((status.getStatusCode() != TStatusCode.SUCCESS_STATUS) &amp;amp;&amp;amp;&lt;br/&gt;
    (withInfo &amp;amp;&amp;amp; (status.getStatusCode() != TStatusCode.SUCCESS_WITH_INFO_STATUS)))&lt;/p&gt;

&lt;p&gt;when withInfo is false this condition will always be false. We have seen the case where the status code is an error and because withInfo is false there is no exception thrown.&lt;/p&gt;

&lt;p&gt;Thiruvel&apos;s patch addresses this case.&lt;/p&gt;</comment>
                            <comment id="13647026" author="cwsteinbach" created="Wed, 1 May 2013 22:48:57 +0000"  >&lt;p&gt;I found a more concise explanation here: &lt;a href=&quot;http://www.easysoft.com/developer/interfaces/odbc/diagnostics_error_status_codes.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.easysoft.com/developer/interfaces/odbc/diagnostics_error_status_codes.html&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Virtually all ODBC functions can return two values which indicate success&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;SQL_SUCCESS&lt;/li&gt;
	&lt;li&gt;SQL_SUCCESS_WITH_INFO&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Both of these returns cause the SQL_SUCCEEDED macro to result in 1.&lt;/p&gt;

&lt;p&gt;If a function returns SQL_SUCCESS_WITH_INFO it means that the call succeeded but an informational message was produced.&lt;/p&gt;

&lt;p&gt;e.g. with some drivers you might set the cursor type, prepare a statement and then execute it. When SQLExecute is called the statement is acted upon but the driver might change the cursor type to something else. In this case, SQLExecute would return SQL_SUCCESS_WITH_INFO and the driver would add a diagnostic indicating the cursor type had been changed.&lt;/p&gt;

&lt;p&gt;You should note that a few ODBC functions return a status which fails the SQL_SUCCEEDED macro but do not indicate an error as such.&lt;/p&gt;

&lt;p&gt;e.g. SQLFetch can return SQL_NO_DATA indicating there is no further rows in the result set, this is not necessarily an error.&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="13647029" author="cwsteinbach" created="Wed, 1 May 2013 22:54:30 +0000"  >&lt;p&gt;I added a comment on phabricator. Thanks.&lt;/p&gt;</comment>
                            <comment id="13647039" author="cwsteinbach" created="Wed, 1 May 2013 23:02:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cdrome&quot; class=&quot;user-hover&quot; rel=&quot;cdrome&quot;&gt;Chris Drome&lt;/a&gt; I understand that. I was trying to answer the question Thiruvel raised in his first comment. In short, I don&apos;t think any functions return SUCCESS_WITH_INFO_STATUS right now, but in the future we probably will want to do this, and it&apos;s a lot easier to support it at the outset than to add it in later.&lt;/p&gt;</comment>
                            <comment id="13647046" author="cdrome" created="Wed, 1 May 2013 23:06:54 +0000"  >&lt;p&gt;My bad. I misunderstood the context of your comment.&lt;/p&gt;</comment>
                            <comment id="13652813" author="thiruvel" created="Thu, 9 May 2013 08:27:56 +0000"  >&lt;p&gt;Updated patch on phabricator and &lt;a href=&quot;https://reviews.facebook.net/D10629&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10629&lt;/a&gt; and also uploaded here (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4467&quot; title=&quot;HiveConnection does not handle failures correctly&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4467&quot;&gt;HIVE-4467&lt;/a&gt;_1.patch).&lt;/p&gt;</comment>
                            <comment id="13659904" author="thiruvel" created="Thu, 16 May 2013 20:05:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cwsteinbach&quot; class=&quot;user-hover&quot; rel=&quot;cwsteinbach&quot;&gt;Carl Steinbach&lt;/a&gt; Does the updated patch look good?&lt;/p&gt;</comment>
                            <comment id="13659916" author="cwsteinbach" created="Thu, 16 May 2013 20:12:52 +0000"  >&lt;p&gt;Changes look good to me. +1.&lt;/p&gt;</comment>
                            <comment id="13672639" author="ashutoshc" created="Sun, 2 Jun 2013 18:48:02 +0000"  >&lt;p&gt; ant clean package &amp;amp;&amp;amp; ant test -Dtestcase=TestBeeLineWithArgs -Dmodule=beeline fails after applying this patch.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12581352" name="HIVE-4467.patch" size="4433" author="thiruvel" created="Wed, 1 May 2013 10:26:36 +0000"/>
                            <attachment id="12582431" name="HIVE-4467_1.patch" size="6402" author="thiruvel" created="Thu, 9 May 2013 08:27:56 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 1 May 2013 22:20:35 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>325983</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 34 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1k8m7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326328</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4468] Extend plan vectorization to cover GroupByOperator</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4468</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Extend the vectorization operation to support the GroupBy operator&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645643">HIVE-4468</key>
            <summary>Extend plan vectorization to cover GroupByOperator</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="8">Not A Problem</resolution>
                                        <assignee username="rusanu">Remus Rusanu</assignee>
                                    <reporter username="rusanu">Remus Rusanu</reporter>
                        <labels>
                    </labels>
                <created>Wed, 1 May 2013 16:01:10 +0000</created>
                <updated>Tue, 14 May 2013 21:08:43 +0000</updated>
                            <resolved>Tue, 14 May 2013 21:08:43 +0000</resolved>
                                    <version>vectorization-branch</version>
                                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13657511" author="rusanu" created="Tue, 14 May 2013 21:08:43 +0000"  >&lt;p&gt;The existing vectorization handles GroupBy&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326004</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 36 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1k8qv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326349</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4469] Tests in TestCliDriver fail on Windows caused by hard coded file size in .q.out file</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4469</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Several tests in TestCliDriver fail on Windows caused by hard coded file size in .q.out file. The reason is the newline character is different in Windows and Linux which cause the query result file has different file size and the test result on windows does not match expected result in .q.out file&lt;/p&gt;</description>
                <environment>&lt;p&gt;Windows&lt;/p&gt;</environment>
        <key id="12645695">HIVE-4469</key>
            <summary>Tests in TestCliDriver fail on Windows caused by hard coded file size in .q.out file</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png" description="A patch for this issue has been uploaded to JIRA by a contributor.">Patch Available</status>
                    <statusCategory id="4" key="indeterminate" colorName="yellow"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="shuainie">Shuaishuai Nie</assignee>
                                    <reporter username="shuainie">Shuaishuai Nie</reporter>
                        <labels>
                    </labels>
                <created>Wed, 1 May 2013 20:41:05 +0000</created>
                <updated>Thu, 2 May 2013 19:44:36 +0000</updated>
                                            <version>0.11.0</version>
                                                    <component>Testing Infrastructure</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13646912" author="shuainie" created="Wed, 1 May 2013 20:46:35 +0000"  >&lt;p&gt;The patch fix following unit tests on Windows:&lt;br/&gt;
1. columnstats_partlvl.q&lt;br/&gt;
2. columnstats_tbllvl.q&lt;br/&gt;
3. exim_01_nonpart.q&lt;br/&gt;
4. exim_02_part.q&lt;br/&gt;
5. exim_04_all_part.q&lt;br/&gt;
6. exim_05_some_part.q&lt;br/&gt;
7. exim_06_one_part.q&lt;br/&gt;
8. exim_16_part_external.q&lt;br/&gt;
9. exim_17_part_managed.q&lt;br/&gt;
10. exim_18_part_external.q&lt;br/&gt;
11. exim_19_00_part_external_location.q&lt;br/&gt;
12. exim_19_part_external_location.q&lt;br/&gt;
13. exim_20_part_managed_location.q&lt;/p&gt;</comment>
                            <comment id="13646918" author="shuainie" created="Wed, 1 May 2013 20:53:16 +0000"  >&lt;p&gt;The idea is to separate the logic for execute command only for the &#8220;diff&#8221; when comparing the test result on Windows. In this case, the execution of other command will not be affected and the logic for Linux remain the same. When running the &#8220;diff&#8221; command on Windows, the output of &#8220;diff&#8221; will be filtered by a set of pattern, and if all the output lines of &#8220;diff&#8221; fit the patterns, the return value of the execution of &#8220;diff&#8221; will set to normal instead of error.(the patterns are a set of regular expression which match the know output inconsistency between Windows and Linux) Also the output of the &#8220;diff&#8221; will still be printed to the output and log just in case. The advantage of the method is it provide a way to ignore any know inconsistency between the output of Windows and Linux. By adding patterns in the filter, similar problems in the future can be solved in the same way.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12553674">HIVE-2998</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12581412" name="HIVE-4469.1.patch" size="5418" author="shuainie" created="Wed, 1 May 2013 20:44:18 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326056</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 38 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1k92f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326401</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4470] HS2 should disable local query execution</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4470</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Hive can run queries in local mode (instead of using a cluster), if the size is small. This happens when &quot;hive.exec.mode.local.auto&quot; is set to true.&lt;/p&gt;

&lt;p&gt;This would affect the stability of the hive server2 node, if you have heavy query processing happening on it. Bugs in udfs triggered by a bad record can potentially add very heavy load making the server inaccessible. &lt;br/&gt;
By default, HS2 should set these parameters to disallow local execution or send and error message if user tries to set these.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645703">HIVE-4470</key>
            <summary>HS2 should disable local query execution</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="thejas">Thejas M Nair</reporter>
                        <labels>
                    </labels>
                <created>Wed, 1 May 2013 21:11:23 +0000</created>
                <updated>Wed, 14 Aug 2013 03:35:49 +0000</updated>
                                                                            <component>HiveServer2</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13720110" author="hagleitn" created="Thu, 25 Jul 2013 21:54:30 +0000"  >&lt;p&gt;Local mode means that the query will run with local job runner - not in the same process, right? So the argument that a udf can bring down HS2 isn&apos;t true, is it?&lt;/p&gt;
</comment>
                            <comment id="13720124" author="thejas" created="Thu, 25 Jul 2013 22:04:40 +0000"  >&lt;p&gt;I meant that heavy processing on same node can degrade the performance hive server2. Bugs in udfs can put additional load on the server, making it almost inaccessible. &lt;/p&gt;</comment>
                            <comment id="13720126" author="thejas" created="Thu, 25 Jul 2013 22:05:59 +0000"  >&lt;p&gt;Updated the description.&lt;/p&gt;</comment>
                            <comment id="13720172" author="hagleitn" created="Thu, 25 Jul 2013 22:49:32 +0000"  >&lt;p&gt;What about Map joins? They can use up a tremendous amount of memory and affect the stability if you have multiple concurrent queries, couldn&apos;t they? Map join local work can also contain UDFs. Disallowing map joins on hive server 2 seems bad because of the performance penalty.&lt;/p&gt;</comment>
                            <comment id="13720379" author="appodictic" created="Fri, 26 Jul 2013 03:56:36 +0000"  >&lt;blockquote&gt;
&lt;p&gt;By default, HS2 should set these parameters to disallow local execution or send and error message if user tries to set these.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I do not agree with this. I can understand the argument for making the default off, but explicitly disabling it is too extreme. &lt;/p&gt;</comment>
                            <comment id="13720392" author="thejas" created="Fri, 26 Jul 2013 04:27:49 +0000"  >&lt;blockquote&gt;&lt;p&gt;Disallowing map joins on hive server 2 seems bad because of the performance penalty.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;By performance penalty, do you mean the increased latency because of MR job launching? Yes, I agree this would be incurred. (Hopefully, the MR framework/Tez improvements will bring that down.)&lt;br/&gt;
 But on the other hand, if you have 10&apos;s or 100s of queries running concurrently, having them run locally will potentially slow things down, because of high resource utilization on HS2 machine. When we have something like MR framework that does a good job of resource allocation, we should use that. &lt;br/&gt;
That is why a config flag makes sense, so that admins can make this tradeoff.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I can understand the argument for making the default off, but explicitly disabling it is too extreme.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I did a poor job of describing what I meant. What I mean is this should be a HS2 admin flag, that users who connect using jdbc should not be allowed to override for their query. Admins themselves should be able to configure HS2 the way they want.&lt;/p&gt;
</comment>
                            <comment id="13720398" author="appodictic" created="Fri, 26 Jul 2013 04:44:47 +0000"  >&lt;blockquote&gt;
&lt;p&gt;But on the other hand, if you have 10&apos;s or 100s of queries running concurrently, having them run locally will potentially slow things down, because of high resource utilization on HS2 machine. When we have something like MR framework that does a good job of resource allocation, we should use that. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Does the user only have 1 HS2 machine? For redundancy you want 2, but technically you could run N HiveServers and put a load balancer in front of them. That is what we do with hive-server1. Users always do bad things, you can not stop them from shooting themselves &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I did a poor job of describing what I meant. What I mean is this should be a HS2 admin flag, that users who connect using jdbc should not be allowed to override for their query. Admins themselves should be able to configure HS2 the way they want.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This sounds good. Although there are plenty of potentially dangerous flags in there outside of this one. This starts getting into the same mess hive auth is in. Like who polices the police? with config options to stop other config options.&lt;/p&gt;</comment>
                            <comment id="13721070" author="hagleitn" created="Fri, 26 Jul 2013 18:58:59 +0000"  >&lt;p&gt;Admin flag sounds good to me too.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;By performance penalty, do you mean the increased latency because of MR job launching?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It&apos;s much worse than that. There&apos;s no way right now to run the local stage of a map join anywhere but on the &quot;client&quot; machine, which is the HS2 machine in this case. So, you could either disable map joins altogether for HS2 through admin flag (which means really expensive shuffle joins for everything), or do the work to be able to run the hash table gen in the cluster, which makes this ticket really huge.&lt;/p&gt;
</comment>
                            <comment id="13721117" author="appodictic" created="Fri, 26 Jul 2013 19:32:21 +0000"  >&lt;p&gt;Adding an option is nice, but I do not see how it is enforceable since HiveConf can be changed by the user.&lt;/p&gt;</comment>
                            <comment id="13721167" author="hagleitn" created="Fri, 26 Jul 2013 20:21:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=appodictic&quot; class=&quot;user-hover&quot; rel=&quot;appodictic&quot;&gt;Edward Capriolo&lt;/a&gt; Can you explain what you mean by that some more? You mean an admin can set defaults, but we can&apos;t make sure someone submitting a query doesn&apos;t overwrite it? HiveConf only exists on the server in this case, so does the rest of the planning/submission code. Why wouldn&apos;t be be able to limit the user in what they can do?&lt;/p&gt;</comment>
                            <comment id="13721179" author="appodictic" created="Fri, 26 Jul 2013 20:31:20 +0000"  >&lt;p&gt;In HiveThrift1 I can do:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;client.execute( &lt;span class=&quot;code-quote&quot;&gt;&quot;SET hive.security.authorization.enabled=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;);
client.execute( &lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT * FROM StuffIamNotSupposedtoSsee&quot;&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Is there some mechanism in hive thrift2 that prevents set commands?&lt;/p&gt;
</comment>
                            <comment id="13721192" author="hagleitn" created="Fri, 26 Jul 2013 20:43:04 +0000"  >&lt;p&gt;That is an awesome attack. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;/p&gt;

&lt;p&gt;I thought there&apos;s already some black list for certain vars in HiveConf for this case. I&apos;m hoping security enabled/disabled is in that list.&lt;/p&gt;</comment>
                            <comment id="13721208" author="thejas" created="Fri, 26 Jul 2013 21:04:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;I thought there&apos;s already some black list for certain vars in HiveConf for this case. I&apos;m hoping security enabled/disabled is in that list.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, you can configure that using hive.conf.restricted.list . But it is empty by default.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=appodictic&quot; class=&quot;user-hover&quot; rel=&quot;appodictic&quot;&gt;Edward Capriolo&lt;/a&gt; That is something that needs to go in the default restricted list ! &lt;/p&gt;</comment>
                            <comment id="13721246" author="hagleitn" created="Fri, 26 Jul 2013 21:32:55 +0000"  >&lt;p&gt;Hehe. Yeah, btw: hive.conf.restricted.list should probably also be in the restricted list.&lt;/p&gt;</comment>
                            <comment id="13726650" author="prasadm" created="Thu, 1 Aug 2013 17:43:21 +0000"  >&lt;p&gt;The restrict list parameter itself is part of the list implicitly.&lt;/p&gt;</comment>
                            <comment id="13739181" author="appodictic" created="Wed, 14 Aug 2013 03:35:49 +0000"  >&lt;p&gt;Have you seen &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5054&quot; title=&quot;Remove unused property submitviachild&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5054&quot;&gt;&lt;del&gt;HIVE-5054&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;

&lt;p&gt;It seems like there is a property that we are about to remove that could help you disable local execution. Lets try to determine if the tickets are conflicting.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12642171">HIVE-4343</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 25 Jul 2013 21:54:30 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326064</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 23 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1k947:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326409</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4471] Build fails with hcatalog checkstyle error</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4471</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;This is the output:&lt;/p&gt;

&lt;p&gt;checkstyle:&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;echo&amp;#93;&lt;/span&gt; hcatalog&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;checkstyle&amp;#93;&lt;/span&gt; Running Checkstyle 5.5 on 412 files&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;checkstyle&amp;#93;&lt;/span&gt; /home/jenkins/jenkins-slave/workspace/Hive-trunk-h0.21/hive/hcatalog/src/test/.gitignore:1: Missing a header - not enough lines in file.&lt;/p&gt;

&lt;p&gt;BUILD FAILED&lt;br/&gt;
/home/jenkins/jenkins-slave/workspace/Hive-trunk-h0.21/hive/build.xml:296: The following error occurred while executing this line:&lt;br/&gt;
/home/jenkins/jenkins-slave/workspace/Hive-trunk-h0.21/hive/build.xml:298: The following error occurred while executing this line:&lt;br/&gt;
/home/jenkins/jenkins-slave/workspace/Hive-trunk-h0.21/hive/hcatalog/build.xml:109: The following error occurred while executing this line:&lt;br/&gt;
/home/jenkins/jenkins-slave/workspace/Hive-trunk-h0.21/hive/hcatalog/build-support/ant/checkstyle.xml:32: Got 1 errors and 0 warnings.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645714">HIVE-4471</key>
            <summary>Build fails with hcatalog checkstyle error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hagleitn">Gunther Hagleitner</assignee>
                                    <reporter username="hagleitn">Gunther Hagleitner</reporter>
                        <labels>
                    </labels>
                <created>Wed, 1 May 2013 22:39:19 +0000</created>
                <updated>Tue, 15 Oct 2013 23:31:05 +0000</updated>
                            <resolved>Wed, 8 May 2013 05:40:28 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13647022" author="hagleitn" created="Wed, 1 May 2013 22:41:09 +0000"  >&lt;p&gt;Testing locally I am not seeing the exact same error message, but also failures in checkstyle. The patch seems to take care of it.&lt;/p&gt;</comment>
                            <comment id="13647044" author="hagleitn" created="Wed, 1 May 2013 23:05:33 +0000"  >&lt;p&gt;Seems like we can just remove the .gitignore file as well.&lt;/p&gt;</comment>
                            <comment id="13647646" author="ashutoshc" created="Thu, 2 May 2013 15:55:13 +0000"  >&lt;p&gt;+1. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=traviscrawford&quot; class=&quot;user-hover&quot; rel=&quot;traviscrawford&quot;&gt;Travis Crawford&lt;/a&gt; would you like to take a look?&lt;/p&gt;</comment>
                            <comment id="13651636" author="ashutoshc" created="Wed, 8 May 2013 05:40:28 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Gunther!&lt;/p&gt;</comment>
                            <comment id="13652451" author="hudson" created="Wed, 8 May 2013 22:43:53 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2092 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2092/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2092/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4471&quot; title=&quot;Build fails with hcatalog checkstyle error&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4471&quot;&gt;&lt;del&gt;HIVE-4471&lt;/del&gt;&lt;/a&gt; : Build fails with hcatalog checkstyle error (Gunther Hagleitner via Ashutosh Chauhan) (Revision 1480162)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1480162&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1480162&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/build-support/ant/checkstyle.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/src/test/.gitignore&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13652672" author="hudson" created="Thu, 9 May 2013 02:10:15 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #188 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/188/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/188/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4471&quot; title=&quot;Build fails with hcatalog checkstyle error&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4471&quot;&gt;&lt;del&gt;HIVE-4471&lt;/del&gt;&lt;/a&gt; : Build fails with hcatalog checkstyle error (Gunther Hagleitner via Ashutosh Chauhan) (Revision 1480162)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1480162&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1480162&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hcatalog/build-support/ant/checkstyle.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hcatalog/src/test/.gitignore&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13662472" author="amalakar" created="Mon, 20 May 2013 23:47:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt;/&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=traviscrawford&quot; class=&quot;user-hover&quot; rel=&quot;traviscrawford&quot;&gt;Travis Crawford&lt;/a&gt; I see that the checkstyle entry has many directories/file types to exclude. Instead of excluding the ones could we change it to include only *&lt;b&gt;/&lt;/b&gt;.java? &lt;/p&gt;</comment>
                            <comment id="13796118" author="ashutoshc" created="Tue, 15 Oct 2013 23:31:05 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12581432" name="HIVE-4471.1.patch" size="576" author="hagleitn" created="Wed, 1 May 2013 22:40:36 +0000"/>
                            <attachment id="12581436" name="HIVE-4471.2.patch" size="832" author="hagleitn" created="Wed, 1 May 2013 23:05:33 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 2 May 2013 15:55:13 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326073</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1k967:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326418</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4472] OR, NOT Filter logic can lose an array, and always takes time O(VectorizedRowBatch.DEFAULT_SIZE)</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4472</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The issue is in file FilterExprOrExpr.java and FilterNotExpr.java.&lt;/p&gt;

&lt;p&gt;I posted a review for you at &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/10752/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/10752/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I think there is a bug related to sharing of an array of integers. Also, one algorithm step takes O(DEFAULT_BATCH_SIZE) time always. If n&amp;lt;&amp;lt;DEFAULT_BATCH_SIZE then this is a performance issue. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12645720">HIVE-4472</key>
            <summary>OR, NOT Filter logic can lose an array, and always takes time O(VectorizedRowBatch.DEFAULT_SIZE)</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jnp">Jitendra Nath Pandey</assignee>
                                    <reporter username="ehans">Eric Hanson</reporter>
                        <labels>
                    </labels>
                <created>Wed, 1 May 2013 23:06:57 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:20 +0000</updated>
                            <resolved>Wed, 22 May 2013 21:06:45 +0000</resolved>
                                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13659004" author="jnp" created="Wed, 15 May 2013 23:23:05 +0000"  >&lt;p&gt;Updated patch with unit tests.&lt;/p&gt;</comment>
                            <comment id="13659029" author="jnp" created="Wed, 15 May 2013 23:39:08 +0000"  >&lt;p&gt;Review board entry: &lt;a href=&quot;https://reviews.apache.org/r/11190/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11190/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13659757" author="ehans" created="Thu, 16 May 2013 17:48:05 +0000"  >&lt;p&gt;I posted additional comments to review board. Patch is almost ready but not quite. Expect one more update from Jitendra.&lt;/p&gt;</comment>
                            <comment id="13662215" author="jnp" created="Mon, 20 May 2013 17:58:58 +0000"  >&lt;p&gt;New patch addressing the comments.&lt;/p&gt;</comment>
                            <comment id="13664275" author="jnp" created="Wed, 22 May 2013 17:21:20 +0000"  >&lt;p&gt;Same patch as previous one except that the fix to TestConstantVectorExpression is removed, because that is taken care of by &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4553&quot; title=&quot;Column Column, and Column Scalar vectorized execution tests&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4553&quot;&gt;&lt;del&gt;HIVE-4553&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13664526" author="owen.omalley" created="Wed, 22 May 2013 21:06:45 +0000"  >&lt;p&gt;I just committed this to the vectorization branch. Thanks, Jitendra!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12583213" name="HIVE-4472.1.patch" size="5825" author="jnp" created="Tue, 14 May 2013 21:17:54 +0000"/>
                            <attachment id="12583400" name="HIVE-4472.2.patch" size="15562" author="jnp" created="Wed, 15 May 2013 23:23:05 +0000"/>
                            <attachment id="12583406" name="HIVE-4472.3.patch" size="15837" author="jnp" created="Wed, 15 May 2013 23:39:08 +0000"/>
                            <attachment id="12583867" name="HIVE-4472.4.patch" size="31017" author="jnp" created="Mon, 20 May 2013 17:58:58 +0000"/>
                            <attachment id="12584343" name="HIVE-4472.5.patch" size="30143" author="jnp" created="Wed, 22 May 2013 17:21:20 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 15 May 2013 23:23:05 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326079</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 35 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1k97j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326424</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4473] Improvement in logical expressions and checkstyle fixes.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4473</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;1. Use System.arraycopy.&lt;br/&gt;
2. check-style issues.&lt;br/&gt;
3. Avoid scanning whole array if only partial is selected.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645721">HIVE-4473</key>
            <summary>Improvement in logical expressions and checkstyle fixes.</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="jnp">Jitendra Nath Pandey</assignee>
                                    <reporter username="jnp">Jitendra Nath Pandey</reporter>
                        <labels>
                    </labels>
                <created>Wed, 1 May 2013 23:13:50 +0000</created>
                <updated>Wed, 1 May 2013 23:15:07 +0000</updated>
                            <resolved>Wed, 1 May 2013 23:15:07 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13647055" author="jnp" created="Wed, 1 May 2013 23:15:07 +0000"  >&lt;p&gt;Duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4472&quot; title=&quot;OR, NOT Filter logic can lose an array, and always takes time O(VectorizedRowBatch.DEFAULT_SIZE)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4472&quot;&gt;&lt;del&gt;HIVE-4472&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326080</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 38 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1k97r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326425</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4474] Column access not tracked properly for partitioned tables</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4474</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The columns recorded as being accessed is incorrect for partitioned tables. The index of accessed columns is a position in the list of non-partition columns, but a list of all columns is being used right now to do the lookup.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645725">HIVE-4474</key>
            <summary>Column access not tracked properly for partitioned tables</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sxyuan">Samuel Yuan</assignee>
                                    <reporter username="sxyuan">Samuel Yuan</reporter>
                        <labels>
                    </labels>
                <created>Wed, 1 May 2013 23:53:11 +0000</created>
                <updated>Tue, 15 Oct 2013 23:31:04 +0000</updated>
                            <resolved>Mon, 6 May 2013 18:55:56 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13647206" author="gangtimliu" created="Thu, 2 May 2013 02:25:33 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13647763" author="gangtimliu" created="Thu, 2 May 2013 18:06:52 +0000"  >&lt;p&gt;running test.&lt;/p&gt;</comment>
                            <comment id="13648537" author="gangtimliu" created="Fri, 3 May 2013 16:14:26 +0000"  >&lt;p&gt;Committed. thank Samuel Yuan&lt;/p&gt;</comment>
                            <comment id="13650876" author="hudson" created="Tue, 7 May 2013 14:21:38 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2089 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2089/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2089/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4474&quot; title=&quot;Column access not tracked properly for partitioned tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4474&quot;&gt;&lt;del&gt;HIVE-4474&lt;/del&gt;&lt;/a&gt;: Column access not tracked properly for partitioned tables. Samuel Yuan via Gang Tim Liu (Revision 1478856)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
gangtimliu : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1478856&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1478856&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ColumnAccessAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/column_access_stats.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/column_access_stats.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13796114" author="ashutoshc" created="Tue, 15 Oct 2013 23:31:04 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12581447" name="HIVE-4474.1.patch.txt" size="2893" author="sxyuan" created="Thu, 2 May 2013 00:58:19 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 2 May 2013 02:25:33 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326084</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1k98n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326429</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4475] Switch RCFile default to LazyBinaryColumnarSerDe</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4475</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;For most workloads it seems LazyBinaryColumnarSerDe (binary) will perform better than ColumnarSerDe (text). Not sure why ColumnarSerDe is the default, but my guess is, that&apos;s for historical reasons. I suggest switching the default.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645758">HIVE-4475</key>
            <summary>Switch RCFile default to LazyBinaryColumnarSerDe</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hagleitn">Gunther Hagleitner</assignee>
                                    <reporter username="hagleitn">Gunther Hagleitner</reporter>
                        <labels>
                    </labels>
                <created>Thu, 2 May 2013 08:19:14 +0000</created>
                <updated>Tue, 15 Oct 2013 23:30:51 +0000</updated>
                            <resolved>Mon, 20 May 2013 23:49:51 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13656512" author="hagleitn" created="Mon, 13 May 2013 23:21:15 +0000"  >&lt;p&gt;review: &lt;a href=&quot;https://reviews.facebook.net/D10785&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10785&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13657663" author="owen.omalley" created="Tue, 14 May 2013 23:13:17 +0000"  >&lt;p&gt;I&apos;m concerned about changing the default behavior, especially without a mechanism to get the old behavior. There are some advantages to the current serde, such as being able to read the rcfile with a different schema, although you are right that the binary is better choice in general.&lt;/p&gt;

&lt;p&gt;Maybe the right answer is to make a config knob that sets the default rcfile serde. Thoughts?&lt;/p&gt;</comment>
                            <comment id="13657866" author="hagleitn" created="Wed, 15 May 2013 03:42:38 +0000"  >&lt;p&gt;I like the idea of the config knob for this &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;Owen O&apos;Malley&lt;/a&gt;. This is safer and more flexible. I do think most cases benefit from LazyBinary, but you make a good point for why ppl might want to choose otherwise. Also, it actually makes the patch simpler. &lt;/p&gt;</comment>
                            <comment id="13657867" author="hagleitn" created="Wed, 15 May 2013 03:44:30 +0000"  >&lt;p&gt;Updated review as well: &lt;a href=&quot;https://reviews.facebook.net/D10785&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10785&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13660805" author="owen.omalley" created="Fri, 17 May 2013 15:51:22 +0000"  >&lt;p&gt;+1 Gunther, can you please run unit tests?&lt;/p&gt;</comment>
                            <comment id="13660830" author="hagleitn" created="Fri, 17 May 2013 16:18:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;Owen O&apos;Malley&lt;/a&gt;: Ran tests over night. All test came back green.&lt;/p&gt;</comment>
                            <comment id="13662474" author="owen.omalley" created="Mon, 20 May 2013 23:49:51 +0000"  >&lt;p&gt;I just committed this. Thanks, Gunther!&lt;/p&gt;</comment>
                            <comment id="13663106" author="hudson" created="Tue, 21 May 2013 16:45:41 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2111 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2111/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2111/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4475&quot; title=&quot;Switch RCFile default to LazyBinaryColumnarSerDe&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4475&quot;&gt;&lt;del&gt;HIVE-4475&lt;/del&gt;&lt;/a&gt; Switch RCFile default to LazyBinaryColumnarSerDe. (Guther Hagleitner&lt;br/&gt;
via omalley) (Revision 1484626)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
omalley : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1484626&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1484626&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/data/conf/hive-site.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/rcfile_default_format.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/rcfile_default_format.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13663517" author="hudson" created="Tue, 21 May 2013 22:41:48 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #205 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/205/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/205/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4475&quot; title=&quot;Switch RCFile default to LazyBinaryColumnarSerDe&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4475&quot;&gt;&lt;del&gt;HIVE-4475&lt;/del&gt;&lt;/a&gt; Switch RCFile default to LazyBinaryColumnarSerDe. (Guther Hagleitner&lt;br/&gt;
via omalley) (Revision 1484626)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
omalley : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1484626&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1484626&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/data/conf/hive-site.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/rcfile_default_format.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/rcfile_default_format.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13796086" author="ashutoshc" created="Tue, 15 Oct 2013 23:30:51 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12581495" name="HIVE-4475.1.patch" size="260437" author="hagleitn" created="Thu, 2 May 2013 08:21:14 +0000"/>
                            <attachment id="12583274" name="HIVE-4475.2.patch" size="22688" author="hagleitn" created="Wed, 15 May 2013 03:42:38 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 14 May 2013 23:13:17 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326117</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10342"><![CDATA[Incompatible change]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1k9fz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326462</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>This changes the default serde of tables that are created based on RCFile.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4476] HiveMetaStore caches the creation of a default db in a static way</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4476</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently HiveMetaStore.HMSHandler has a static flag set to true if the JVM has ever created a default db:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/hive/blob/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java#L176&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hive/blob/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java#L176&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, when testing it&apos;s nice to be able to create multiple HiveMetastore instances in a single JVM. Perhaps we should add a flag &quot;hive.metastore.always.create.default.db&quot; or something similar.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645839">HIVE-4476</key>
            <summary>HiveMetaStore caches the creation of a default db in a static way</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="brocknoland">Brock Noland</reporter>
                        <labels>
                    </labels>
                <created>Thu, 2 May 2013 17:30:50 +0000</created>
                <updated>Thu, 2 May 2013 17:43:31 +0000</updated>
                                            <version>0.10.0</version>
                    <version>0.11.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13647744" author="brocknoland" created="Thu, 2 May 2013 17:43:31 +0000"  >&lt;p&gt;perhaps the use of checkForDefaultDb in that class just needs to be modified.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326198</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 38 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1k9xz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326543</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4477] remove redundant copy of arithmetic filter unit test testColOpScalarNumericFilterNullAndRepeatingLogic</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4477</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;same test got ported to 2 different files&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645859">HIVE-4477</key>
            <summary>remove redundant copy of arithmetic filter unit test testColOpScalarNumericFilterNullAndRepeatingLogic</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ehans">Eric Hanson</assignee>
                                    <reporter username="ehans">Eric Hanson</reporter>
                        <labels>
                    </labels>
                <created>Thu, 2 May 2013 19:15:49 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:25 +0000</updated>
                            <resolved>Fri, 3 May 2013 14:42:03 +0000</resolved>
                                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13647840" author="ehans" created="Thu, 2 May 2013 19:52:24 +0000"  >&lt;p&gt;Code review available at &lt;a href=&quot;https://reviews.apache.org/r/10906/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/10906/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13648458" author="ashutoshc" created="Fri, 3 May 2013 14:42:03 +0000"  >&lt;p&gt;Committed to branch. Thanks, Eric!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12581589" name="HIVE-4477.1.patch" size="3681" author="ehans" created="Thu, 2 May 2013 19:37:44 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 3 May 2013 14:42:03 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326218</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 38 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ka2f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326563</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4478] In ORC, add boolean noNulls flag to column stripe metadata</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4478</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently, the stripe metadata for ORC contains the min and max value for each column in the stripe. This will be used for stripe elimination. However, an additional bit of metadata for each column for each stripe, noNulls (true/false), is needed to help speed up vectorized query execution as much as 30%. &lt;/p&gt;

&lt;p&gt;The vectorized QE code has a Boolean flag for each column vector called noNulls. If this is true, all the null-checking logic is skipped for that column for a VectorizedRowBatch when an operation is performed on that column. For simple filters and arithmetic expressions, this can save on the order of 30% of the time.&lt;/p&gt;

&lt;p&gt;Once this noNulls stripe metadata is available, the vectorized iterator (reader) for ORC can be updated to avoid all expense to load the isNull bitmap, and efficiently set the noNulls flag for each column vector.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645876">HIVE-4478</key>
            <summary>In ORC, add boolean noNulls flag to column stripe metadata</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="prasanth_j">Prasanth Jayachandran</assignee>
                                    <reporter username="ehans">Eric Hanson</reporter>
                        <labels>
                    </labels>
                <created>Thu, 2 May 2013 21:24:29 +0000</created>
                <updated>Tue, 15 Oct 2013 23:28:58 +0000</updated>
                            <resolved>Fri, 28 Jun 2013 20:37:26 +0000</resolved>
                                    <version>0.12.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                    <component>File Formats</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13671588" author="owen.omalley" created="Fri, 31 May 2013 15:43:27 +0000"  >&lt;p&gt;I&apos;ve pushed this to Prasanth. I think the best approach is to suppress the isPresent bit stream in the case that the entire column is present for the stripe. The ORC reader already handles this correctly by assuming that all values are present.&lt;/p&gt;</comment>
                            <comment id="13671687" author="prasanth_j" created="Fri, 31 May 2013 17:55:45 +0000"  >&lt;p&gt;Adding the patch that uses the approach posted above by Owen (suppressing the isPresent stream when no nulls are found in the stream). All test cases related to ORC are passing.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;Owen O&apos;Malley&lt;/a&gt; Can you please review the patch? &lt;/p&gt;</comment>
                            <comment id="13694879" author="owen.omalley" created="Thu, 27 Jun 2013 17:13:33 +0000"  >&lt;p&gt;Prasanth, I don&apos;t think we should add the suppress information to the BitFieldWriter. Could you instead modify the StreamFactory.createStream from a PositionedOutputStream to OutStream? Then you can hold onto the present stream&apos;s OutWriter in the TreeWriter class. Then the TreeWriter.writeStream can suppress the underlying OutStream directly.&lt;/p&gt;
</comment>
                            <comment id="13694955" author="prasanth_j" created="Thu, 27 Jun 2013 19:02:40 +0000"  >&lt;p&gt;Earlier I tried this but then failed miserably as I returned &quot;OutputStream&quot; instead of &quot;OutStream&quot; from StreamFactory.createStream(). Thanks for pointing out the correct way. Updated the patch with TreeWriter holding &quot;OutStream&quot; reference. All unit tests related to ORC file are passing. &lt;/p&gt;</comment>
                            <comment id="13695763" author="owen.omalley" created="Fri, 28 Jun 2013 20:37:26 +0000"  >&lt;p&gt;I just committed this to trunk. Thanks, Prasanth!&lt;/p&gt;</comment>
                            <comment id="13696152" author="hudson" created="Sat, 29 Jun 2013 16:57:38 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2168 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2168/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2168/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4478&quot; title=&quot;In ORC, add boolean noNulls flag to column stripe metadata&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4478&quot;&gt;&lt;del&gt;HIVE-4478&lt;/del&gt;&lt;/a&gt;. In ORC remove ispresent stream from columns that contain no null &lt;br/&gt;
values in a stripe. (Prasanth Jayachandran via omalley) (Revision 1497912)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
omalley : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1497912&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1497912&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OutStream.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestFileDump.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcNullOptimization.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/resources/orc-file-dump.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13696167" author="hudson" created="Sat, 29 Jun 2013 18:01:34 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #263 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/263/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/263/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4478&quot; title=&quot;In ORC, add boolean noNulls flag to column stripe metadata&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4478&quot;&gt;&lt;del&gt;HIVE-4478&lt;/del&gt;&lt;/a&gt;. In ORC remove ispresent stream from columns that contain no null &lt;br/&gt;
values in a stripe. (Prasanth Jayachandran via omalley) (Revision 1497912)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
omalley : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1497912&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1497912&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OutStream.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestFileDump.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestOrcNullOptimization.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/resources/orc-file-dump.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13795833" author="ashutoshc" created="Tue, 15 Oct 2013 23:28:58 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12585645" name="HIVE-4478.1.patch.txt" size="31566" author="prasanth_j" created="Fri, 31 May 2013 17:51:21 +0000"/>
                            <attachment id="12589948" name="HIVE-4478.2.git.patch.txt" size="31090" author="prasanth_j" created="Thu, 27 Jun 2013 18:58:10 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 31 May 2013 15:43:27 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326235</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ka67:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326580</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4479] Child expressions are not being evaluated hierarchically in a few templates.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4479</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;FilterColumnCompareColumn.txt, FilterStringColumnCompareScalar.txt and ScalarArithmeticColumn.txt are not evaluating the child expressions.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645887">HIVE-4479</key>
            <summary>Child expressions are not being evaluated hierarchically in a few templates.</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jnp">Jitendra Nath Pandey</assignee>
                                    <reporter username="jnp">Jitendra Nath Pandey</reporter>
                        <labels>
                    </labels>
                <created>Thu, 2 May 2013 22:57:48 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:16 +0000</updated>
                            <resolved>Fri, 3 May 2013 14:36:57 +0000</resolved>
                                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13648034" author="jnp" created="Thu, 2 May 2013 23:45:29 +0000"  >&lt;p&gt;Review board entry: &lt;a href=&quot;https://reviews.apache.org/r/10908/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/10908/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13648452" author="ashutoshc" created="Fri, 3 May 2013 14:36:57 +0000"  >&lt;p&gt;Committed to branch. Thanks, Jitendra!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12581628" name="HIVE-4479.1.patch" size="52381" author="jnp" created="Thu, 2 May 2013 23:06:03 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 3 May 2013 14:36:57 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326246</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 38 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ka8n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326591</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4480] Implement partition support for vectorized query execution</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4480</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Add support for eager deserialization of row data using serde in the RecordReader layer. Also add support for partitions in this layer so that the vectorized batch is populated correctly.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645895">HIVE-4480</key>
            <summary>Implement partition support for vectorized query execution</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sarvesh.sn">Sarvesh Sakalanaga</assignee>
                                    <reporter username="sarvesh.sn">Sarvesh Sakalanaga</reporter>
                        <labels>
                    </labels>
                <created>Thu, 2 May 2013 23:35:01 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:25 +0000</updated>
                            <resolved>Fri, 3 May 2013 14:45:07 +0000</resolved>
                                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13648105" author="sarvesh.sn" created="Fri, 3 May 2013 01:43:34 +0000"  >&lt;p&gt;Patch uploaded&lt;/p&gt;</comment>
                            <comment id="13648465" author="ashutoshc" created="Fri, 3 May 2013 14:45:07 +0000"  >&lt;p&gt;Committed to branch. Thanks, Sarvesh!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12581651" name="Hive-4480.1.patch" size="27244" author="sarvesh.sn" created="Fri, 3 May 2013 01:38:20 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 3 May 2013 14:45:07 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326254</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 38 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kaaf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326599</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4481] Vectorized row batch should be initialized with additional columns to hold intermediate output.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4481</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Vectorized row batch should be initialized with additional columns to hold intermediate output.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645898">HIVE-4481</key>
            <summary>Vectorized row batch should be initialized with additional columns to hold intermediate output.</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jnp">Jitendra Nath Pandey</assignee>
                                    <reporter username="jnp">Jitendra Nath Pandey</reporter>
                        <labels>
                    </labels>
                <created>Thu, 2 May 2013 23:41:13 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:23 +0000</updated>
                            <resolved>Fri, 3 May 2013 14:39:49 +0000</resolved>
                                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13648455" author="ashutoshc" created="Fri, 3 May 2013 14:39:49 +0000"  >&lt;p&gt;Committed to branch. Thanks, Jitendra!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12581640" name="HIVE-4481.1.patch" size="37187" author="jnp" created="Thu, 2 May 2013 23:44:58 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 3 May 2013 14:39:49 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326257</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 38 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kab3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326602</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4482] Template file VectorUDAFAvg.txt missing from public branch; CodeGen.java fails</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4482</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;In vectorization branch, file&lt;br/&gt;
ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/templates/VectorUDAFAvg.txt&lt;br/&gt;
is missing. So CodeGen.java doesn&apos;t run to completion, because it references that file.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645900">HIVE-4482</key>
            <summary>Template file VectorUDAFAvg.txt missing from public branch; CodeGen.java fails</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="rusanu">Remus Rusanu</assignee>
                                    <reporter username="ehans">Eric Hanson</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 May 2013 00:14:31 +0000</created>
                <updated>Fri, 10 May 2013 20:22:44 +0000</updated>
                            <resolved>Fri, 10 May 2013 20:22:44 +0000</resolved>
                                                    <fixVersion>vectorization-branch</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13654797" author="rusanu" created="Fri, 10 May 2013 20:21:34 +0000"  >&lt;p&gt;The patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4450&quot; title=&quot;Extend Vector Aggregates to support GROUP BY&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4450&quot;&gt;&lt;del&gt;HIVE-4450&lt;/del&gt;&lt;/a&gt; contains the missing file&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12645434">HIVE-4450</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 10 May 2013 20:21:34 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326259</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 37 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kabj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326604</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4483] Input format to read vector data from RC file</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4483</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12645909">HIVE-4483</key>
            <summary>Input format to read vector data from RC file</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sarvesh.sn">Sarvesh Sakalanaga</assignee>
                                    <reporter username="sarvesh.sn">Sarvesh Sakalanaga</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 May 2013 01:44:21 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:21 +0000</updated>
                            <resolved>Sun, 12 May 2013 19:24:06 +0000</resolved>
                                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13654830" author="sarvesh.sn" created="Fri, 10 May 2013 21:05:13 +0000"  >&lt;p&gt;Patch available.&lt;/p&gt;</comment>
                            <comment id="13654836" author="sarvesh.sn" created="Fri, 10 May 2013 21:07:00 +0000"  >&lt;p&gt;The patch also contains implementation for VectorizedColumnarSerDe that can be used with CommonRCInputFormat to read vectorized data from RC file.&lt;/p&gt;</comment>
                            <comment id="13654846" author="sarvesh.sn" created="Fri, 10 May 2013 21:14:21 +0000"  >&lt;p&gt;Review available at: &lt;a href=&quot;https://reviews.apache.org/r/11059/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11059/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13655605" author="ashutoshc" created="Sun, 12 May 2013 18:53:41 +0000"  >&lt;p&gt;Seems like changes in ColumnarSerde &amp;amp; LazyUtils are unnecessary. If they are not required for this patch, can you plz revert them?&lt;/p&gt;</comment>
                            <comment id="13655613" author="sarvesh.sn" created="Sun, 12 May 2013 19:09:47 +0000"  >&lt;p&gt;The changes to these files are required. VectorizedColumnarSerde inherits from ColumnarSerde and as such I need access to ColumnarSerde&apos;s serdeParams member from subclass to serialize the string in bytes vector correctly. I also need to change LazyUtils as LazyUtils::writeEscaped visibility was set to private and VectorizedColumnarSerde needs to access this method to correctly serialize the string(VectorizedColumnarSerde::serializeVector). &lt;/p&gt;</comment>
                            <comment id="13655617" author="ashutoshc" created="Sun, 12 May 2013 19:24:06 +0000"  >&lt;p&gt;Thanks for explaination.&lt;br/&gt;
Committed to branch. Thanks, Sarvesh!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12582692" name="Hive-4483.0.patch" size="49495" author="sarvesh.sn" created="Fri, 10 May 2013 21:05:13 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 12 May 2013 18:53:41 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326268</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 37 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kadj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326613</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4484] Current hive is slower than previous versions</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4484</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Comparing logs for various patches, I&apos;ve found query execution become slower than before. For example, (picked not-changed tests)&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ppr_pushdown.q
135~140 sec : 2012-03-27 ~ 2012-07-17
140~160 sec : ~ 2012-11-28
160~220 sec : ~ 2013-03-30
220~250 src : ~ current (HIVE-4392)

join_nulls.q
295~310 sec : 2012-03-27 ~ 2012-07-17
310~330 sec : ~ 2012-11-28
330~370 sec : ~ 2013-03-30
400~460 src : ~ current (HIVE-4392)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This explains much on recent prolonged test time. It might be from changes on test framework. But still need investigation before adding more functionality into hive.&lt;/p&gt;</description>
                <environment>&lt;p&gt;ubuntu 10.10, 4G, i7-8core&lt;/p&gt;</environment>
        <key id="12645910">HIVE-4484</key>
            <summary>Current hive is slower than previous versions</summary>
                <type id="3" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21148&amp;avatarType=issuetype">Task</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="navis">Navis</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 May 2013 01:59:37 +0000</created>
                <updated>Fri, 3 May 2013 01:59:37 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326269</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 38 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kadr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326614</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4485] beeline prints null as empty strings</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4485</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt; beeline is printing nulls as emtpy strings.  There was no way to distinguish between an empty string an a null value. &lt;br/&gt;
This is inconsistent with hive cli and other databases, they print null as &quot;NULL&quot; string.&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12645916">HIVE-4485</key>
            <summary>beeline prints null as empty strings</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="thejas">Thejas M Nair</assignee>
                                    <reporter username="thejas">Thejas M Nair</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 May 2013 02:59:13 +0000</created>
                <updated>Thu, 28 Apr 2016 00:52:33 +0000</updated>
                            <resolved>Wed, 27 Nov 2013 21:29:11 +0000</resolved>
                                                    <fixVersion>0.13.0</fixVersion>
                                    <component>HiveServer2</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13648245" author="thejas" created="Fri, 3 May 2013 07:38:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4485&quot; title=&quot;beeline prints null as empty strings&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4485&quot;&gt;&lt;del&gt;HIVE-4485&lt;/del&gt;&lt;/a&gt;.1.patch - initial patch. Makes null string configurable. test needs fixing/improvement&lt;/p&gt;</comment>
                            <comment id="13648971" author="thejas" created="Sat, 4 May 2013 01:14:54 +0000"  >&lt;p&gt;Making null string configurable is probably over engineering at this point. &lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4485&quot; title=&quot;beeline prints null as empty strings&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4485&quot;&gt;&lt;del&gt;HIVE-4485&lt;/del&gt;&lt;/a&gt;.2.patch - Simpler patch that does not make it configurable.&lt;/p&gt;</comment>
                            <comment id="13668006" author="cwsteinbach" created="Tue, 28 May 2013 00:55:16 +0000"  >&lt;p&gt;Hive 0.11.0 was released with the current behavior (nulls printed as &quot;NULL&quot;), so any changes we make at this point need to be configurable (using Beeline&apos;s &apos;set!&apos; command), and should default to the current behavior.&lt;/p&gt;</comment>
                            <comment id="13830354" author="thejas" created="Fri, 22 Nov 2013 21:58:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;Hive 0.11.0 was released with the current behavior (nulls printed as &quot;NULL&quot;)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cwsteinbach&quot; class=&quot;user-hover&quot; rel=&quot;cwsteinbach&quot;&gt;Carl Steinbach&lt;/a&gt; I want to clarify that this is about beeline and beeline currently prints nulls as emtpy strings. I agree that switching this would be a backward incompatible change. But I think it is important to distinguish between empty strings and null for obvious reasons.&lt;/p&gt;

&lt;p&gt;I think this is a general problem - Hive has undesirable defaults in some cases and changing those would break backward compatibility. I think we should give the users (specially new users), the option of using the more sensible but backward incompatible configuration defaults. I will open a new jira for that.&lt;/p&gt;</comment>
                            <comment id="13830387" author="cwsteinbach" created="Fri, 22 Nov 2013 22:56:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; I&apos;m fine with changing the default behavior in the next release as long as we document the change in the release notes and provide a configuration option that allows users to revert back to the old behavior.&lt;/p&gt;</comment>
                            <comment id="13833134" author="thejas" created="Tue, 26 Nov 2013 22:06:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4485&quot; title=&quot;beeline prints null as empty strings&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4485&quot;&gt;&lt;del&gt;HIVE-4485&lt;/del&gt;&lt;/a&gt;.3.patch - patch with behavior in release notes&lt;/p&gt;</comment>
                            <comment id="13833171" author="thejas" created="Tue, 26 Nov 2013 22:41:11 +0000"  >&lt;p&gt;4.patch - fixes whilespace issues, adds missing BooleanCompletor.java file&lt;/p&gt;</comment>
                            <comment id="13833482" author="ashutoshc" created="Wed, 27 Nov 2013 05:32:52 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13834098" author="hiveqa" created="Wed, 27 Nov 2013 20:12:13 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12615928/HIVE-4485.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12615928/HIVE-4485.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4740 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/463/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/463/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/463/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/463/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12615928&lt;/p&gt;</comment>
                            <comment id="13834167" author="thejas" created="Wed, 27 Nov 2013 21:29:11 +0000"  >&lt;p&gt;Patch committed to trunk. Thanks for the review Ashutosh!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12581669" name="HIVE-4485.1.patch" size="9610" author="thejas" created="Fri, 3 May 2013 07:38:17 +0000"/>
                            <attachment id="12581784" name="HIVE-4485.2.patch" size="1439" author="thejas" created="Sat, 4 May 2013 01:14:54 +0000"/>
                            <attachment id="12615927" name="HIVE-4485.3.patch" size="13376" author="thejas" created="Tue, 26 Nov 2013 22:06:55 +0000"/>
                            <attachment id="12615928" name="HIVE-4485.4.patch" size="14791" author="thejas" created="Tue, 26 Nov 2013 22:41:11 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 28 May 2013 00:55:16 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326275</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10342"><![CDATA[Incompatible change]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 8 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kaf3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326620</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>This introduces a backward incompatible change.&lt;br/&gt;
Earlier, null was getting printed as an empty string. There was no way to distinguish between an empty string an a null value. &lt;br/&gt;
With this change null values will be printed as NULL. &lt;br/&gt;
To get the old behavior you can set the property nullemptystring to values.&lt;br/&gt;
This can be done via commandline argument : beeline --nullemptystring=true&lt;br/&gt;
Or within the beeline shell&lt;br/&gt;
&amp;gt; !set nullemptystring true&lt;br/&gt;
</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4486] FetchOperator slows down SMB map joins by 50% when there are many partitions</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4486</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;While looking at log files for SMB joins in hive, it was noticed that the actual join op didn&apos;t show up as a significant fraction of the time spent. Most of the time was spent parsing configuration files.&lt;/p&gt;

&lt;p&gt;To confirm, I put log lines in the HiveConf constructor and eventually made the following edit to the code&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;--- ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java
+++ ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java
@@ -648,8 +648,7 @@ &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; ObjectInspector getOutputObjectInspector() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; HiveException {
    * @&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; list of file status entries
    */
   &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; FileStatus[] listStatusUnderPath(FileSystem fs, Path p) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
-    HiveConf hiveConf = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HiveConf(job, FetchOperator.class);
-    &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; recursive = hiveConf.getBoolVar(HiveConf.ConfVars.HADOOPMAPREDINPUTDIRRECURSIVE);
+    &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; recursive = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
     &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!recursive) {
       &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; fs.listStatus(p);
     }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And re-ran my query to compare timings.&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&amp;nbsp;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Before&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;After&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Cumulative CPU&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 731.07 sec&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;386.0 sec&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Total time &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 347.66 seconds &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 218.855 seconds &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;The query used was &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;INSERT OVERWRITE LOCAL DIRECTORY
&lt;span class=&quot;code-quote&quot;&gt;&apos;/grid/0/smb/&apos;&lt;/span&gt;
select inv_item_sk
from
     inventory inv
     join store_sales ss on (ss.ss_item_sk = inv.inv_item_sk)
limit 100000
;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;On a scale=2 tpcds data-set, where both store_sales &amp;amp; inventory are bucketed into 4 buckets, with store_sales split into 7 partitions and inventory into 261 partitions.&lt;/p&gt;

&lt;p&gt;78% of all CPU time was spent within new HiveConf(). The yourkit profiler runs are attached.&lt;/p&gt;</description>
                <environment>&lt;p&gt;Ubuntu LXC 12.10&lt;/p&gt;</environment>
        <key id="12645966">HIVE-4486</key>
            <summary>FetchOperator slows down SMB map joins by 50% when there are many partitions</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gopalv">Gopal V</assignee>
                                    <reporter username="gopalv">Gopal V</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 May 2013 13:55:18 +0000</created>
                <updated>Tue, 15 Oct 2013 23:30:19 +0000</updated>
                            <resolved>Fri, 17 May 2013 15:45:16 +0000</resolved>
                                    <version>0.12.0</version>
                                    <fixVersion>0.11.1</fixVersion>
                    <fixVersion>0.12.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13648425" author="gopalv" created="Fri, 3 May 2013 14:03:27 +0000"  >&lt;p&gt;attach yourkit profile (HTML)&lt;/p&gt;</comment>
                            <comment id="13652262" author="gopalv" created="Wed, 8 May 2013 19:49:47 +0000"  >&lt;p&gt;Root caused to the following code in HiveConf&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; void initialize(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;&amp;lt;?&amp;gt; cls) {
    hiveJar = (&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; JobConf(cls)).getJar();

    &lt;span class=&quot;code-comment&quot;&gt;// preserve the original configuration
&lt;/span&gt;    origProp = getAllProperties();

    &lt;span class=&quot;code-comment&quot;&gt;// Overlay the ConfVars. Note that &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; ignores ConfVars with &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; values
&lt;/span&gt;    addResource(getConfVarInputStream());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;addResource() calls reloadConfiguration() eventually, causing each new HiveConf(job) to parse all the conf xml files again.&lt;/p&gt;</comment>
                            <comment id="13654367" author="navis" created="Fri, 10 May 2013 10:52:33 +0000"  >&lt;p&gt;In above, &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;HiveConf hiveConf = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HiveConf(job, FetchOperator.class);
&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; recursive = hiveConf.getBoolVar(HiveConf.ConfVars.HADOOPMAPREDINPUTDIRRECURSIVE);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;could be replaced by&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; recursive = HiveConf.getBoolVar(job, HiveConf.ConfVars.HADOOPMAPREDINPUTDIRRECURSIVE);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Could you make a patch for review?&lt;/p&gt;</comment>
                            <comment id="13654477" author="gopalv" created="Fri, 10 May 2013 14:00:54 +0000"  >&lt;p&gt;Running it through the benchmarks now.&lt;/p&gt;

&lt;p&gt;That looked like it did the trick. I will put up a patch for review &lt;/p&gt;</comment>
                            <comment id="13654653" author="gopalv" created="Fri, 10 May 2013 17:44:08 +0000"  >&lt;p&gt;Patch based on Navis&apos; suggestions.&lt;/p&gt;</comment>
                            <comment id="13654658" author="gopalv" created="Fri, 10 May 2013 17:48:24 +0000"  >&lt;p&gt;Opened &lt;a href=&quot;https://reviews.apache.org/r/11047/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11047/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13654668" author="gopalv" created="Fri, 10 May 2013 17:57:01 +0000"  >&lt;p&gt;Closed that (wrong diff), opened as &lt;a href=&quot;https://reviews.apache.org/r/11048/diff/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11048/diff/&lt;/a&gt; instead.&lt;/p&gt;</comment>
                            <comment id="13659762" author="owen.omalley" created="Thu, 16 May 2013 17:50:11 +0000"  >&lt;p&gt;+1 can you run the unit tests?&lt;/p&gt;</comment>
                            <comment id="13659785" author="gopalv" created="Thu, 16 May 2013 18:09:53 +0000"  >&lt;p&gt;I have already run all of tests in ql/ against svn (Wed May 8) already.&lt;/p&gt;

&lt;p&gt;Will run all tests in some time &amp;amp; report back.&lt;/p&gt;</comment>
                            <comment id="13660745" author="gopalv" created="Fri, 17 May 2013 14:24:44 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;Owen O&apos;Malley&lt;/a&gt; - all test pass on (bdd257f71bc0b65100dbd41425d7f8250ae27e57 + patch)&lt;/p&gt;</comment>
                            <comment id="13660801" author="owen.omalley" created="Fri, 17 May 2013 15:45:16 +0000"  >&lt;p&gt;I just committed this to branch-0.11 and trunk. Thanks, Gopal!&lt;/p&gt;</comment>
                            <comment id="13661271" author="hudson" created="Sat, 18 May 2013 04:28:26 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #201 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/201/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/201/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4486&quot; title=&quot;FetchOperator slows down SMB map joins by 50% when there are many partitions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4486&quot;&gt;&lt;del&gt;HIVE-4486&lt;/del&gt;&lt;/a&gt; FetchOperator slows down SMB map joins by 50% when there are many &lt;br/&gt;
partitions (Gopal V via omalley) (Revision 1483874)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
omalley : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1483874&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1483874&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13661276" author="gopalv" created="Sat, 18 May 2013 04:39:38 +0000"  >&lt;p&gt;HBase errors in trunk tests?&lt;/p&gt;

&lt;p&gt;Caused by: java.lang.RuntimeException: Master not initialized after 200 seconds&lt;br/&gt;
	at org.apache.hadoop.hbase.util.JVMClusterUtil.startup(JVMClusterUtil.java:206)&lt;br/&gt;
	at org.apache.hadoop.hbase.LocalHBaseCluster.startup(LocalHBaseCluster.java:420)&lt;br/&gt;
	at org.apache.hadoop.hbase.MiniHBaseCluster.init(MiniHBaseCluster.java:216)&lt;/p&gt;</comment>
                            <comment id="13661295" author="hudson" created="Sat, 18 May 2013 05:17:59 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2107 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2107/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2107/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4486&quot; title=&quot;FetchOperator slows down SMB map joins by 50% when there are many partitions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4486&quot;&gt;&lt;del&gt;HIVE-4486&lt;/del&gt;&lt;/a&gt; FetchOperator slows down SMB map joins by 50% when there are many &lt;br/&gt;
partitions (Gopal V via omalley) (Revision 1483874)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
omalley : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1483874&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1483874&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13796006" author="ashutoshc" created="Tue, 15 Oct 2013 23:30:19 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12648218">HADOOP-9570</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12582648" name="HIVE-4486.patch" size="849" author="gopalv" created="Fri, 10 May 2013 17:44:08 +0000"/>
                            <attachment id="12581692" name="smb-profile.html" size="281932" author="gopalv" created="Fri, 3 May 2013 14:03:27 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 10 May 2013 10:52:33 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326325</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kaq7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326670</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Avoid creating new HiveConf() within the FetchOperator loop</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4487] Hive does not set explicit permissions on hive.exec.scratchdir</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4487</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The hive.exec.scratchdir defaults to /tmp/hive-${user.name}, but when Hive creates this directory it doesn&apos;t set any explicit permission on it. This means if you have the default HDFS umask setting of 022, then these directories end up being world readable. These permissions also get applied to the staging directories and their files, thus leaving inter-stage data world readable.&lt;/p&gt;

&lt;p&gt;This can cause a potential leak of data especially when operating on a Kerberos enabled cluster. Hive should probably default these directories to only be readable by the owner.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12645967">HIVE-4487</key>
            <summary>Hive does not set explicit permissions on hive.exec.scratchdir</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ctang.ma">Chaoyu Tang</assignee>
                                    <reporter username="fwiffo">Joey Echeverria</reporter>
                        <labels>
                            <label>TODOC12</label>
                    </labels>
                <created>Fri, 3 May 2013 14:05:01 +0000</created>
                <updated>Tue, 24 Feb 2015 11:09:55 +0000</updated>
                            <resolved>Wed, 18 Sep 2013 18:07:25 +0000</resolved>
                                    <version>0.10.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13648435" author="fwiffo" created="Fri, 3 May 2013 14:12:59 +0000"  >&lt;p&gt;The current workaround is to set the umask in hive-site.xml:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-xml&quot;&gt;  &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;fs.permissions.umask-mode&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;077&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13659087" author="ctang.ma" created="Thu, 16 May 2013 00:40:30 +0000"  >&lt;p&gt;How about the hive.exec.local.scratchdir (/tmp/${user.name} in local system) if it is applicable, should not it be 700 as well?&lt;/p&gt;</comment>
                            <comment id="13691208" author="ctang.ma" created="Sat, 22 Jun 2013 18:38:43 +0000"  >&lt;p&gt;Please review the changes in &lt;a href=&quot;https://reviews.apache.org/r/12049/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/12049/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13769116" author="hiveqa" created="Tue, 17 Sep 2013 02:40:43 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12589262/HIVE-4487.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12589262/HIVE-4487.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 3125 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/770/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/770/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/770/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/770/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13769126" author="brocknoland" created="Tue, 17 Sep 2013 02:52:09 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13771025" author="brocknoland" created="Wed, 18 Sep 2013 18:07:25 +0000"  >&lt;p&gt;Thanks Chaoyu! I have committed this to trunk. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; you mind consider this one for 0.12 as well.&lt;/p&gt;</comment>
                            <comment id="13771045" author="thejas" created="Wed, 18 Sep 2013 18:22:19 +0000"  >&lt;p&gt;Yes, I will commit it to 0.12 branch.&lt;/p&gt;</comment>
                            <comment id="13771092" author="hudson" created="Wed, 18 Sep 2013 18:49:11 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #172 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/172/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/172/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4487&quot; title=&quot;Hive does not set explicit permissions on hive.exec.scratchdir&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4487&quot;&gt;&lt;del&gt;HIVE-4487&lt;/del&gt;&lt;/a&gt; - Hive does not set explicit permissions on hive.exec.scratchdir (Chaoyu Tang via Brock Noland) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524509&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524509&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Context.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13771106" author="hudson" created="Wed, 18 Sep 2013 18:55:03 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2 #438 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/438/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/438/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4487&quot; title=&quot;Hive does not set explicit permissions on hive.exec.scratchdir&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4487&quot;&gt;&lt;del&gt;HIVE-4487&lt;/del&gt;&lt;/a&gt; - Hive does not set explicit permissions on hive.exec.scratchdir (Chaoyu Tang via Brock Noland) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524509&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524509&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Context.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13771160" author="yhuai" created="Wed, 18 Sep 2013 19:55:12 +0000"  >&lt;p&gt;FsPermission(String mode) was not in hadoop 0.20.2.&lt;/p&gt;</comment>
                            <comment id="13771162" author="yhuai" created="Wed, 18 Sep 2013 19:56:37 +0000"  >&lt;p&gt;If we use &quot;ant clean package eclipse-files&quot;, we cannot build hive inside eclipse.&lt;/p&gt;</comment>
                            <comment id="13771165" author="brocknoland" created="Wed, 18 Sep 2013 20:00:44 +0000"  >&lt;p&gt;I created &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5313&quot; title=&quot;HIVE-4487 breaks build because 0.20.2 is missing FSPermission(string)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5313&quot;&gt;&lt;del&gt;HIVE-5313&lt;/del&gt;&lt;/a&gt; to fix this.&lt;/p&gt;</comment>
                            <comment id="13771336" author="hudson" created="Wed, 18 Sep 2013 22:38:33 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2 #439 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/439/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/439/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5313&quot; title=&quot;HIVE-4487 breaks build because 0.20.2 is missing FSPermission(string)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5313&quot;&gt;&lt;del&gt;HIVE-5313&lt;/del&gt;&lt;/a&gt; - &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4487&quot; title=&quot;Hive does not set explicit permissions on hive.exec.scratchdir&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4487&quot;&gt;&lt;del&gt;HIVE-4487&lt;/del&gt;&lt;/a&gt; breaks build because 0.20.2 is missing FSPermission(string) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524578&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524578&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Context.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13771535" author="thejas" created="Thu, 19 Sep 2013 02:29:31 +0000"  >&lt;p&gt;Patch committed to 0.12 branch&lt;/p&gt;</comment>
                            <comment id="13771678" author="thejas" created="Thu, 19 Sep 2013 07:55:06 +0000"  >&lt;p&gt;I am seeing several precommit intermittent test failures in last few builds, which seem to be caused by permission errors. I am wondering if it might be related to this change. I also saw this on my linux machine, but not in another run on my mac.&lt;/p&gt;

&lt;p&gt;The tests have errors like this -&lt;br/&gt;
Copying data from &lt;a href=&quot;file:/home/hiveptest/ip-10-74-50-170-hiveptest-2/apache-svn-trunk-source/data/files/kv1.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/home/hiveptest/ip-10-74-50-170-hiveptest-2/apache-svn-trunk-source/data/files/kv1.txt&lt;/a&gt;&lt;br/&gt;
Failed with exception Failed to set permissions of path: /home/hiveptest/ip-10-74-50-170-hiveptest-2/apache-svn-trunk-source/build/ql/scratchdir/hive_2013-09-18_19-22-30_852_799993877859563099-1/-ext-10000 to 0777&lt;/p&gt;

&lt;p&gt;For example in - &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/813/testReport/org.apache.hadoop.hive.ql.parse/TestParseNegative/testParseNegative_ambiguous_join_col/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/813/testReport/org.apache.hadoop.hive.ql.parse/TestParseNegative/testParseNegative_ambiguous_join_col/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13771713" author="hudson" created="Thu, 19 Sep 2013 09:02:43 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-h0.21 #2341 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2341/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2341/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5313&quot; title=&quot;HIVE-4487 breaks build because 0.20.2 is missing FSPermission(string)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5313&quot;&gt;&lt;del&gt;HIVE-5313&lt;/del&gt;&lt;/a&gt; - &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4487&quot; title=&quot;Hive does not set explicit permissions on hive.exec.scratchdir&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4487&quot;&gt;&lt;del&gt;HIVE-4487&lt;/del&gt;&lt;/a&gt; breaks build because 0.20.2 is missing FSPermission(string) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524578&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524578&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Context.java&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4487&quot; title=&quot;Hive does not set explicit permissions on hive.exec.scratchdir&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4487&quot;&gt;&lt;del&gt;HIVE-4487&lt;/del&gt;&lt;/a&gt; - Hive does not set explicit permissions on hive.exec.scratchdir (Chaoyu Tang via Brock Noland) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524509&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524509&lt;/a&gt;)&lt;/li&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Context.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13771952" author="brocknoland" created="Thu, 19 Sep 2013 14:58:37 +0000"  >&lt;p&gt;Very strange. I don&apos;t see why this would be occurring since the hiveptest owns everything in /home/hiveptest/. It&apos;s not a privileged user so cannot it cannot change ownership. The only way I can see that is if &quot;hive_2013-09-18_19-22-30_852_799993877859563099-1&quot; somehow got created with 000 (or anything but 700).&lt;/p&gt;</comment>
                            <comment id="13771954" author="brocknoland" created="Thu, 19 Sep 2013 15:00:09 +0000"  >&lt;p&gt;Full error message from: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-Build-813/failed/TestParseNegative/hive.log&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-Build-813/failed/TestParseNegative/hive.log&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;20_510_7475863120290716577-1/-ext-10000 to 0777
java.io.IOException: Failed to set permissions of path: /home/hiveptest/ip-10-74-50-170-hiveptest-2/apache-svn-trunk-source/build/ql/scratchdir/hive_2013-09-18_19-22-20_510_7475863120290716577-1/-ext-10000 to 0777
	at org.apache.hadoop.fs.FileUtil.checkReturnValue(FileUtil.java:689)
	at org.apache.hadoop.fs.FileUtil.setPermission(FileUtil.java:662)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:509)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:344)
	at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:189)
	at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:189)
	at org.apache.hadoop.fs.ProxyFileSystem.mkdirs(ProxyFileSystem.java:217)
	at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:189)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1126)
	at org.apache.hadoop.hive.ql.exec.CopyTask.execute(CopyTask.java:74)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:151)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:65)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1415)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1193)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1021)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:889)
	at org.apache.hadoop.hive.ql.QTestUtil.runLoadCmd(QTestUtil.java:539)
	at org.apache.hadoop.hive.ql.QTestUtil.createSources(QTestUtil.java:586)
	at org.apache.hadoop.hive.ql.QTestUtil.init(QTestUtil.java:678)
	at org.apache.hadoop.hive.ql.parse.TestParseNegative.runTest(TestParseNegative.java:248)
	at org.apache.hadoop.hive.ql.parse.TestParseNegative.testParseNegative_ambiguous_join_col(TestParseNegative.java:117)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13772066" author="hudson" created="Thu, 19 Sep 2013 17:24:23 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #106 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/106/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/106/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5313&quot; title=&quot;HIVE-4487 breaks build because 0.20.2 is missing FSPermission(string)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5313&quot;&gt;&lt;del&gt;HIVE-5313&lt;/del&gt;&lt;/a&gt; - &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4487&quot; title=&quot;Hive does not set explicit permissions on hive.exec.scratchdir&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4487&quot;&gt;&lt;del&gt;HIVE-4487&lt;/del&gt;&lt;/a&gt; breaks build because 0.20.2 is missing FSPermission(string) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524578&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524578&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Context.java&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4487&quot; title=&quot;Hive does not set explicit permissions on hive.exec.scratchdir&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4487&quot;&gt;&lt;del&gt;HIVE-4487&lt;/del&gt;&lt;/a&gt; - Hive does not set explicit permissions on hive.exec.scratchdir (Chaoyu Tang via Brock Noland) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524509&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524509&lt;/a&gt;)&lt;/li&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Context.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13772093" author="yhuai" created="Thu, 19 Sep 2013 17:44:00 +0000"  >&lt;p&gt;Here is my error log when I am launching hive cli through eclipse.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Caused by: java.io.FileNotFoundException: /tmp/yhuai/hive_2013-09-19_13-43-12_206_2528583202954923226-1/-local-10000 (Permission denied)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.&amp;lt;init&amp;gt;(FileOutputStream.java:209)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.&amp;lt;init&amp;gt;(RawLocalFileSystem.java:180)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.&amp;lt;init&amp;gt;(RawLocalFileSystem.java:176)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:234)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.&amp;lt;init&amp;gt;(ChecksumFileSystem.java:335)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:368)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:484)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:465)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:372)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:364)
	at org.apache.hadoop.hive.ql.exec.DDLTask.showTables(DDLTask.java:2252)
	... 13 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13772101" author="brocknoland" created="Thu, 19 Sep 2013 17:50:12 +0000"  >&lt;p&gt;Can you share the file permissions on each directory in the tree?&lt;/p&gt;</comment>
                            <comment id="13772103" author="yhuai" created="Thu, 19 Sep 2013 17:50:45 +0000"  >&lt;p&gt;i meant when I did &quot;show tables&quot; in hive cli launched in eclipse.&lt;/p&gt;</comment>
                            <comment id="13772106" author="yhuai" created="Thu, 19 Sep 2013 17:52:24 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;drwxrwxrwt  22 root     root      56K Sep 19 13:36 tmp
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;drwxrwxrwx 2 yhuai   yhuai   4.0K Sep 19 13:50 yhuai
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13772184" author="hudson" created="Thu, 19 Sep 2013 19:15:20 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #173 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/173/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/173/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5313&quot; title=&quot;HIVE-4487 breaks build because 0.20.2 is missing FSPermission(string)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5313&quot;&gt;&lt;del&gt;HIVE-5313&lt;/del&gt;&lt;/a&gt; - &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4487&quot; title=&quot;Hive does not set explicit permissions on hive.exec.scratchdir&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4487&quot;&gt;&lt;del&gt;HIVE-4487&lt;/del&gt;&lt;/a&gt; breaks build because 0.20.2 is missing FSPermission(string) (brock: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524578&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1524578&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Context.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13772186" author="ctang.ma" created="Thu, 19 Sep 2013 19:16:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yhuai&quot; class=&quot;user-hover&quot; rel=&quot;yhuai&quot;&gt;Yin Huai&lt;/a&gt; It works in my eclipse. The log tells that it failed in line outStream = fs.create(resFile) of DDLTask.&lt;br/&gt;
Could you debug and check before this line is executed, what permission and owner of the dir (e.g. /tmp/yhuai/hive_2013-09-19_xxxx/, one level up -local-10000) are? What Hadoop version you are using?&lt;/p&gt;</comment>
                            <comment id="13772258" author="thejas" created="Thu, 19 Sep 2013 20:25:42 +0000"  >&lt;p&gt;I think the problem might have to do with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5313&quot; title=&quot;HIVE-4487 breaks build because 0.20.2 is missing FSPermission(string)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5313&quot;&gt;&lt;del&gt;HIVE-5313&lt;/del&gt;&lt;/a&gt; change. It converts the octal string into short using Short.parseShort(scratchDirPermission) but that function expects decimal. So &quot;700&quot; gets converted to 700 instead of 448.&lt;/p&gt;</comment>
                            <comment id="13772278" author="thejas" created="Thu, 19 Sep 2013 20:35:35 +0000"  >&lt;p&gt;I have created &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5322&quot; title=&quot;FsPermission is initialized incorrectly in HIVE 5513&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5322&quot;&gt;&lt;del&gt;HIVE-5322&lt;/del&gt;&lt;/a&gt; to track the permission issue.&lt;/p&gt;</comment>
                            <comment id="13772351" author="ctang.ma" created="Thu, 19 Sep 2013 21:35:14 +0000"  >&lt;p&gt;Synced to the head of trunk and was able to reproduce the issue as Yin Huai saw. &lt;br/&gt;
The cause is, as Thejas said, in the conversion of octal permission to short. Changed the line 209 in Context.java to:&lt;br/&gt;
FsPermission fsPermission = new FsPermission(Short.parseShort(scratchDirPermission.trim(), 8)) &lt;br/&gt;
will solve the problem.&lt;/p&gt;</comment>
                            <comment id="13772355" author="ctang.ma" created="Thu, 19 Sep 2013 21:39:15 +0000"  >&lt;p&gt;Noticed that Mark has already provided a patch with the same changes in Hive-5322. Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mwagner&quot; class=&quot;user-hover&quot; rel=&quot;mwagner&quot;&gt;Mark Wagner&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13796132" author="ashutoshc" created="Tue, 15 Oct 2013 23:31:13 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                            <comment id="14334688" author="lefty@hortonworks.com" created="Tue, 24 Feb 2015 08:59:45 +0000"  >&lt;p&gt;Doc note:  This adds configuration parameter &lt;b&gt;hive.scratch.dir.permission&lt;/b&gt; to HiveConf.java, so it needs to be documented in the wiki (in two places):&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/AdminManual+Configuration#AdminManualConfiguration-ConfigurationVariables&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;AdminManual Configuration &amp;#8211; Configuration Variables &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.exec.scratchdir&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Configuration Properties &amp;#8211; put it after hive.exec.scratchdir &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6847&quot; title=&quot;Improve / fix bugs in Hive scratch dir setup&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6847&quot;&gt;&lt;del&gt;HIVE-6847&lt;/del&gt;&lt;/a&gt; adds a parameter description in release 0.14.0.&lt;/p&gt;</comment>
                            <comment id="14334776" author="lefty@hortonworks.com" created="Tue, 24 Feb 2015 11:09:55 +0000"  >&lt;p&gt;Doc done (please review):  &lt;b&gt;hive.scratch.dir.permission&lt;/b&gt; is documented in the wiki now.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/AdminManual+Configuration#AdminManualConfiguration-ConfigurationVariables&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;AdminManual Configuration &amp;#8211; Configuration Variables &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.scratch.dir.permission&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Configuration Properties &amp;#8211; hive.scratch.dir.permission &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;By the way, the parameter name omits &quot;.exec.&quot; so it doesn&apos;t match similar parameters.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12669541">HIVE-5322</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12706743">HIVE-6847</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12669321">HIVE-5313</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12589262" name="HIVE-4487.patch" size="2659" author="ctang.ma" created="Sat, 22 Jun 2013 19:27:15 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 16 May 2013 00:40:30 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326326</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 47 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kaqf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326671</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4488] BucketizedHiveInputFormat is pessimistic with SMB split generation</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4488</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;BucketizedHiveInputFormat generates fewer splits than possible when faced with a table structure where both tables are partitioned.&lt;/p&gt;

&lt;p&gt;When debugging query82 from the TPC-DS spec, there were 7 partitions in the lhs (store_sales) &amp;amp; 8 partitions in the rhs (inventory), with 1 bucket each.&lt;/p&gt;

&lt;p&gt;Only 7 splits are generated from the mapper, instead of a potential 56 mappers.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;13/05/01 07:08:22 INFO mapred.FileInputFormat: Total input paths to process : 1
13/05/01 07:08:22 INFO io.BucketizedHiveInputFormat: 7 bucketized splits generated from 344 original splits.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The loop that generates the splits is as follows&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;        InputSplit[] iss = inputFormat.getSplits(newjob, 0);
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (iss != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; iss.length &amp;gt; 0) {
          numOrigSplits += iss.length;
          result.add(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BucketizedHiveInputSplit(iss, inputFormatClass
              .getName()));
        }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As is clear from above, even though the more granular (per-file/per-partition) splits coming off the getSplits() is being added to a single bucket split.&lt;/p&gt;

&lt;p&gt;Logically, in our mapper we get &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;store_sales(2003)/000000_1)
join MergeQueue(
  inv(1998-01-01)/000000_0
  inv(1998-01-08)/000000_0
  inv(1998-01-15)/000000_0
  inv(1998-01-22)/000000_0
  inv(1998-01-29)/000000_0
  inv(1998-02-05)/000000_0
  inv(1998-02-12)/000000_0
  inv(1998-02-19)/000000_0
  inv(1998-02-26)/000000_0
  )
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Where ideally, we could&apos;ve used a CombineFileInputFormat to get node locality for the merge queue inputs (viz BucketizedHiveInputSplit).&lt;/p&gt;

&lt;p&gt;This would be far better in generating splits &amp;amp; in getting more out of short-circuit reads.&lt;/p&gt;</description>
                <environment>&lt;p&gt;Ubuntu LXC&lt;/p&gt;</environment>
        <key id="12645973">HIVE-4488</key>
            <summary>BucketizedHiveInputFormat is pessimistic with SMB split generation</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="gopalv">Gopal V</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 May 2013 14:20:57 +0000</created>
                <updated>Fri, 3 May 2013 14:20:57 +0000</updated>
                                            <version>0.12.0</version>
                                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326332</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 38 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1karr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326677</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4489] beeline always return the same error message twice</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4489</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Beeline always returns the same error message twice. for example, if I try to create a table a2 which already exists, it prints out two exact same messages and it is not quite user friendly.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;beeline&amp;gt; !connect jdbc:hive2:&lt;span class=&quot;code-comment&quot;&gt;//localhost:10000 scott tiger org.apache.hive.jdbc.HiveDriver
&lt;/span&gt;Connecting to jdbc:hive2:&lt;span class=&quot;code-comment&quot;&gt;//localhost:10000
&lt;/span&gt;Connected to: Hive (version 0.10.0)
Driver: Hive (version 0.10.0-cdh4.2.1)
Transaction isolation: TRANSACTION_REPEATABLE_READ
0: jdbc:hive2:&lt;span class=&quot;code-comment&quot;&gt;//localhost:10000&amp;gt; create table a2 (value &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;);
&lt;/span&gt;Error: Error &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; processing statement: FAILED: Execution Error, &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; code 1 from org.apache.hadoop.hive.ql.exec.DDLTask (state=08S01,code=1)
Error: Error &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; processing statement: FAILED: Execution Error, &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; code 1 from org.apache.hadoop.hive.ql.exec.DDLTask (state=08S01,code=1)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12645978">HIVE-4489</key>
            <summary>beeline always return the same error message twice</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ctang.ma">Chaoyu Tang</assignee>
                                    <reporter username="ctang.ma">Chaoyu Tang</reporter>
                        <labels>
                            <label>newbie</label>
                    </labels>
                <created>Fri, 3 May 2013 14:55:58 +0000</created>
                <updated>Tue, 15 Oct 2013 23:30:22 +0000</updated>
                            <resolved>Sun, 2 Jun 2013 16:58:35 +0000</resolved>
                                    <version>0.10.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Clients</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                    <timeoriginalestimate seconds="0">0h</timeoriginalestimate>
                            <timeestimate seconds="0">0h</timeestimate>
                                        <comments>
                            <comment id="13648488" author="ctang.ma" created="Fri, 3 May 2013 15:19:45 +0000"  >&lt;p&gt;removed duplicated error logging in the low level of exception catch block and only the top level catch block print out the error.&lt;/p&gt;</comment>
                            <comment id="13654547" author="ctang.ma" created="Fri, 10 May 2013 15:36:59 +0000"  >&lt;p&gt;Could someone review and commit it if it is a proper fix? Thanks. It is to fix the issue raised by some beeline users.&lt;/p&gt;</comment>
                            <comment id="13672201" author="ashutoshc" created="Sat, 1 Jun 2013 19:22:18 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13672596" author="ashutoshc" created="Sun, 2 Jun 2013 16:58:35 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Chaoyu!&lt;/p&gt;</comment>
                            <comment id="13673611" author="hudson" created="Mon, 3 Jun 2013 21:32:38 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #223 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/223/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/223/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4489&quot; title=&quot;beeline always return the same error message twice&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4489&quot;&gt;&lt;del&gt;HIVE-4489&lt;/del&gt;&lt;/a&gt; : beeline always return the same error message twice (Chaoyu Tang via Ashutosh Chauhan) (Revision 1488741)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1488741&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1488741&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/beeline/src/java/org/apache/hive/beeline/Commands.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13674015" author="hudson" created="Tue, 4 Jun 2013 04:08:09 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2126 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2126/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2126/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4489&quot; title=&quot;beeline always return the same error message twice&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4489&quot;&gt;&lt;del&gt;HIVE-4489&lt;/del&gt;&lt;/a&gt; : beeline always return the same error message twice (Chaoyu Tang via Ashutosh Chauhan) (Revision 1488741)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1488741&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1488741&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/beeline/src/java/org/apache/hive/beeline/Commands.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13796016" author="ashutoshc" created="Tue, 15 Oct 2013 23:30:22 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12581759" name="HIVE-4489.patch" size="633" author="ctang.ma" created="Fri, 3 May 2013 22:58:04 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 1 Jun 2013 19:22:18 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326337</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kasv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326682</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4490] HS2 - &apos;select null ..&apos; fails with NPE</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4490</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Eg, from beeline &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&amp;gt; select &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, i from t1 ;
Error: Error running query: java.lang.NullPointerException (state=,code=0)
Error: Error running query: java.lang.NullPointerException (state=,code=0)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In HS2 log&lt;br/&gt;
org.apache.hive.service.cli.HiveSQLException: Error running query: java.lang.NullPointerException&lt;br/&gt;
        at org.apache.hive.service.cli.operation.SQLOperation.run(SQLOperation.java:113)&lt;br/&gt;
        at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatement(HiveSessionImpl.java:169)&lt;br/&gt;
        at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:62)&lt;br/&gt;
        at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
        at javax.security.auth.Subject.doAs(Subject.java:396)&lt;br/&gt;
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1178)&lt;br/&gt;
        at org.apache.hadoop.hive.shims.HadoopShimsSecure.doAs(HadoopShimsSecure.java:524)&lt;br/&gt;
        at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:57)&lt;br/&gt;
        at $Proxy8.executeStatement(Unknown Source)&lt;br/&gt;
        at org.apache.hive.service.cli.CLIService.executeStatement(CLIService.java:148)&lt;br/&gt;
        at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:203)&lt;br/&gt;
        at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1133)&lt;br/&gt;
        at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1118)&lt;br/&gt;
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)&lt;br/&gt;
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)&lt;br/&gt;
        at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge20S.java:565)&lt;br/&gt;
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:662)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646022">HIVE-4490</key>
            <summary>HS2 - &apos;select null ..&apos; fails with NPE</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="thejas">Thejas M Nair</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 May 2013 18:44:20 +0000</created>
                <updated>Sat, 1 Nov 2014 10:11:29 +0000</updated>
                            <resolved>Thu, 16 May 2013 01:52:58 +0000</resolved>
                                                                    <component>HiveServer2</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13648673" author="prasadm" created="Fri, 3 May 2013 18:51:53 +0000"  >&lt;p&gt;Looks like duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4172&quot; title=&quot;JDBC2 does not support VOID type&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4172&quot;&gt;&lt;del&gt;HIVE-4172&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14193052" author="qiaohaijun" created="Sat, 1 Nov 2014 10:11:29 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12636967">HIVE-4172</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 3 May 2013 18:51:53 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326381</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 12 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kb2n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326726</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4491] Grouping by a struct throws an exception</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4491</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Queries that require a shuffle with a struct as the key result in an exception: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Caused by: java.lang.RuntimeException: Hash code on complex types not supported yet.
	at org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.hashCode(ObjectInspectorUtils.java:528)
	at org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.processOp(ReduceSinkOperator.java:226)
	at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:531)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:859)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.forward(GroupByOperator.java:1066)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.closeOp(GroupByOperator.java:1118)
	... 13 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12646023">HIVE-4491</key>
            <summary>Grouping by a struct throws an exception</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="mwagner">Mark Wagner</assignee>
                                    <reporter username="mwagner">Mark Wagner</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 May 2013 18:46:03 +0000</created>
                <updated>Fri, 3 May 2013 18:51:49 +0000</updated>
                            <resolved>Fri, 3 May 2013 18:51:49 +0000</resolved>
                                    <version>0.12.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13648671" author="mwagner" created="Fri, 3 May 2013 18:49:32 +0000"  >&lt;p&gt;A full demonstration, using the table created in the create_struct_table.q test.&lt;/p&gt;</comment>
                            <comment id="13648672" author="mwagner" created="Fri, 3 May 2013 18:51:49 +0000"  >&lt;p&gt;My mistake. This is a duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2517&quot; title=&quot;Support group by on struct type&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2517&quot;&gt;&lt;del&gt;HIVE-2517&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12527873">HIVE-2517</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12581726" name="demonstration.txt" size="4402" author="mwagner" created="Fri, 3 May 2013 18:49:32 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326382</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 38 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kb2v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326727</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4492] Revert HIVE-4322</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4492</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;See &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4432&quot; title=&quot;Follow-up to HIVE-4322 - make metastore API changes backwards compatible&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4432&quot;&gt;&lt;del&gt;HIVE-4432&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4433&quot; title=&quot;Fix C++ Thrift bindings broken in HIVE-4322&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4433&quot;&gt;&lt;del&gt;HIVE-4433&lt;/del&gt;&lt;/a&gt;. It&apos;s possible to work around these issues but a better solution is probably to roll back the &quot;fix&quot; and change the API to use a primitive type as the map key (in a backwards-compatible manner).&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646024">HIVE-4492</key>
            <summary>Revert HIVE-4322</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sxyuan">Samuel Yuan</assignee>
                                    <reporter username="sxyuan">Samuel Yuan</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 May 2013 18:59:13 +0000</created>
                <updated>Tue, 15 Oct 2013 23:31:33 +0000</updated>
                            <resolved>Mon, 9 Sep 2013 14:17:00 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Metastore</component>
                    <component>Thrift API</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13761215" author="ashutoshc" created="Sun, 8 Sep 2013 07:14:43 +0000"  >&lt;p&gt;Patch rebased on trunk.&lt;/p&gt;</comment>
                            <comment id="13761216" author="ashutoshc" created="Sun, 8 Sep 2013 07:15:21 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sxyuan&quot; class=&quot;user-hover&quot; rel=&quot;sxyuan&quot;&gt;Samuel Yuan&lt;/a&gt; Can you take a look?&lt;/p&gt;</comment>
                            <comment id="13761217" author="ashutoshc" created="Sun, 8 Sep 2013 07:28:04 +0000"  >&lt;p&gt;Phabricator link: &lt;a href=&quot;https://reviews.facebook.net/D12795&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D12795&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13761251" author="hiveqa" created="Sun, 8 Sep 2013 11:13:39 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12602038/HIVE-4492.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12602038/HIVE-4492.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 3086 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned.testHCatPartitionedTable
org.apache.hcatalog.pig.TestHCatLoaderComplexSchema.testSyntheticComplexSchema
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/660/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/660/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/660/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/660/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13761501" author="ashutoshc" created="Sun, 8 Sep 2013 18:32:10 +0000"  >&lt;p&gt;Tests passed. May I request a committer to review the patch?&lt;/p&gt;</comment>
                            <comment id="13761610" author="cwsteinbach" created="Mon, 9 Sep 2013 04:34:58 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13761874" author="ashutoshc" created="Mon, 9 Sep 2013 14:17:00 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Samuel for initial patch. Thanks, Carl for review!&lt;/p&gt;</comment>
                            <comment id="13761977" author="hudson" created="Mon, 9 Sep 2013 16:17:56 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #89 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/89/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/89/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4492&quot; title=&quot;Revert HIVE-4322&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4492&quot;&gt;&lt;del&gt;HIVE-4492&lt;/del&gt;&lt;/a&gt; : Revert HIVE4322 (Samuel Yuan and Ashutosh Chauhan via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521120&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521120&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/metastore/if/hive_metastore.thrift&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-cpp/hive_metastore_types.cpp&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-cpp/hive_metastore_types.h&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/SkewedInfo.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/SkewedValueList.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-php/metastore/Types.php&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-py/hive_metastore/ttypes.py&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-rb/hive_metastore_types.rb&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/formatting/MetaDataFormatUtils.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/listbucketingpruner/ListBucketingPruner.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13761996" author="hudson" created="Mon, 9 Sep 2013 16:31:13 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #157 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/157/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/157/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4492&quot; title=&quot;Revert HIVE-4322&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4492&quot;&gt;&lt;del&gt;HIVE-4492&lt;/del&gt;&lt;/a&gt; : Revert HIVE4322 (Samuel Yuan and Ashutosh Chauhan via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521120&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521120&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/metastore/if/hive_metastore.thrift&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-cpp/hive_metastore_types.cpp&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-cpp/hive_metastore_types.h&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/SkewedInfo.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/SkewedValueList.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-php/metastore/Types.php&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-py/hive_metastore/ttypes.py&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-rb/hive_metastore_types.rb&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/formatting/MetaDataFormatUtils.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/listbucketingpruner/ListBucketingPruner.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13763233" author="hudson" created="Tue, 10 Sep 2013 17:12:37 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-h0.21 #2322 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2322/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2322/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4492&quot; title=&quot;Revert HIVE-4322&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4492&quot;&gt;&lt;del&gt;HIVE-4492&lt;/del&gt;&lt;/a&gt; : Revert HIVE4322 (Samuel Yuan and Ashutosh Chauhan via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521120&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521120&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/metastore/if/hive_metastore.thrift&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-cpp/hive_metastore_types.cpp&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-cpp/hive_metastore_types.h&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/SkewedInfo.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/SkewedValueList.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-php/metastore/Types.php&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-py/hive_metastore/ttypes.py&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-rb/hive_metastore_types.rb&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/formatting/MetaDataFormatUtils.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/listbucketingpruner/ListBucketingPruner.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13763247" author="hudson" created="Tue, 10 Sep 2013 17:14:40 +0000"  >&lt;p&gt;ABORTED: Integrated in Hive-trunk-hadoop2 #419 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/419/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/419/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4492&quot; title=&quot;Revert HIVE-4322&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4492&quot;&gt;&lt;del&gt;HIVE-4492&lt;/del&gt;&lt;/a&gt; : Revert HIVE4322 (Samuel Yuan and Ashutosh Chauhan via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521120&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1521120&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/metastore/if/hive_metastore.thrift&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-cpp/hive_metastore_types.cpp&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-cpp/hive_metastore_types.h&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/SkewedInfo.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/SkewedValueList.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-php/metastore/Types.php&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-py/hive_metastore/ttypes.py&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/gen/thrift/gen-rb/hive_metastore_types.rb&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/formatting/MetaDataFormatUtils.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/optimizer/listbucketingpruner/ListBucketingPruner.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13766167" author="thejas" created="Fri, 13 Sep 2013 01:58:20 +0000"  >&lt;p&gt;This looks like an api backward compatibility fix that we should include in 0.12 . &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt; Do you agree ?&lt;/p&gt;</comment>
                            <comment id="13766214" author="ashutoshc" created="Fri, 13 Sep 2013 03:33:51 +0000"  >&lt;p&gt;Yup. Please apply to 0.12&lt;/p&gt;</comment>
                            <comment id="13767196" author="thejas" created="Fri, 13 Sep 2013 23:56:44 +0000"  >&lt;p&gt;Patch committed to 0.12 branch.&lt;/p&gt;</comment>
                            <comment id="13796172" author="ashutoshc" created="Tue, 15 Oct 2013 23:31:33 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12644987">HIVE-4432</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12644991">HIVE-4433</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12641743">HIVE-4322</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12581760" name="HIVE-4492.1.patch.txt" size="105936" author="sxyuan" created="Fri, 3 May 2013 23:03:56 +0000"/>
                            <attachment id="12602038" name="HIVE-4492.patch" size="93646" author="ashutoshc" created="Sun, 8 Sep 2013 07:14:43 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 8 Sep 2013 07:14:43 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326383</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kb33:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326728</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4493] Implement vectorized filter for string column compared to string column</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4493</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12646027">HIVE-4493</key>
            <summary>Implement vectorized filter for string column compared to string column</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ehans">Eric Hanson</assignee>
                                    <reporter username="ehans">Eric Hanson</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 May 2013 19:21:58 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:25 +0000</updated>
                            <resolved>Thu, 9 May 2013 04:44:52 +0000</resolved>
                                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13651036" author="ehans" created="Tue, 7 May 2013 16:45:36 +0000"  >&lt;p&gt;Code review available at &lt;a href=&quot;https://reviews.apache.org/r/10978/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/10978/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13652734" author="ashutoshc" created="Thu, 9 May 2013 04:44:52 +0000"  >&lt;p&gt;Committed to branch. Thanks, Eric!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12582118" name="HIVE-4493.1.patch" size="125534" author="ehans" created="Tue, 7 May 2013 16:39:49 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 9 May 2013 04:44:52 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326386</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 37 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kb3r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326731</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4494] ORC map columns get class cast exception in some context</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4494</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Setting up the test case like:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;create table map_text (&lt;br/&gt;
  name string,&lt;br/&gt;
  m map&amp;lt;string,string&amp;gt;&lt;br/&gt;
) row format delimited&lt;br/&gt;
    fields terminated by &apos;|&apos;&lt;br/&gt;
    collection items terminated by &apos;,&apos;&lt;br/&gt;
    map keys terminated by &apos;:&apos;;&lt;/p&gt;

&lt;p&gt;create table map_orc (&lt;br/&gt;
  name string,&lt;br/&gt;
  m map&amp;lt;string,string&amp;gt;&lt;br/&gt;
) stored as orc;&lt;/p&gt;

&lt;p&gt;cat map.txt&lt;br/&gt;
name1|key11:value11,key12:value12,key13:value13&lt;br/&gt;
name2|key21:value21,key22:value22,key23:value23&lt;br/&gt;
name3|key31:value31,key32:value32,key33:value33&lt;/p&gt;

&lt;p&gt;load data local	inpath &apos;map.txt&apos; into table map_text;&lt;/p&gt;

&lt;p&gt;insert overwrite table map_orc select * from map_text;&lt;/p&gt;&lt;/blockquote&gt;
</description>
                <environment></environment>
        <key id="12646049">HIVE-4494</key>
            <summary>ORC map columns get class cast exception in some context</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="owen.omalley">Owen O&apos;Malley</assignee>
                                    <reporter username="owen.omalley">Owen O&apos;Malley</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 May 2013 21:14:20 +0000</created>
                <updated>Thu, 16 May 2013 21:10:58 +0000</updated>
                            <resolved>Wed, 8 May 2013 21:10:35 +0000</resolved>
                                                    <fixVersion>0.11.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13649289" author="phabricator@reviews.facebook.net" created="Sun, 5 May 2013 07:06:15 +0000"  >&lt;p&gt;omalley requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4494&quot; title=&quot;ORC map columns get class cast exception in some context&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4494&quot;&gt;&lt;del&gt;HIVE-4494&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; ORC map columns get class cast exception in some context&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4494&quot; title=&quot;ORC map columns get class cast exception in some context&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4494&quot;&gt;&lt;del&gt;HIVE-4494&lt;/del&gt;&lt;/a&gt; fix class cast exception for some queries using complex types in ORC&lt;/p&gt;

&lt;p&gt;Setting up the test case like:&lt;/p&gt;

&lt;p&gt;create table map_text (&lt;br/&gt;
  name string,&lt;br/&gt;
  m map&amp;lt;string,string&amp;gt;&lt;br/&gt;
) row format delimited&lt;br/&gt;
    fields terminated by &apos;|&apos;&lt;br/&gt;
    collection items terminated by &apos;,&apos;&lt;br/&gt;
    map keys terminated by &apos;:&apos;;&lt;/p&gt;

&lt;p&gt;create table map_orc (&lt;br/&gt;
  name string,&lt;br/&gt;
  m map&amp;lt;string,string&amp;gt;&lt;br/&gt;
) stored as orc;&lt;/p&gt;

&lt;p&gt;cat map.txt&lt;br/&gt;
name1|key11:value11,key12:value12,key13:value13&lt;br/&gt;
name2|key21:value21,key22:value22,key23:value23&lt;br/&gt;
name3|key31:value31,key32:value32,key33:value33&lt;/p&gt;

&lt;p&gt;load data local	inpath &apos;map.txt&apos; into table map_text;&lt;/p&gt;

&lt;p&gt;insert overwrite table map_orc select * from map_text;&lt;/p&gt;

&lt;p&gt;Selecting the name column from orc_map will get the following exception:&lt;/p&gt;

&lt;p&gt;java.lang.RuntimeException: Error in configuring object&lt;br/&gt;
	at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:93)&lt;br/&gt;
	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:64)&lt;br/&gt;
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:431)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:371)&lt;br/&gt;
	at org.apache.hadoop.mapred.Child$4.run(Child.java:255)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:396)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1195)&lt;br/&gt;
	at org.apache.hadoop.mapred.Child.main(Child.java:249)&lt;br/&gt;
Caused by: java.lang.reflect.InvocationTargetException&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:88)&lt;br/&gt;
	... 9 more&lt;br/&gt;
Caused by: java.lang.RuntimeException: Error in configuring object&lt;br/&gt;
	at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:93)&lt;br/&gt;
	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:64)&lt;br/&gt;
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.configure(MapRunner.java:34)&lt;br/&gt;
	... 14 more&lt;br/&gt;
Caused by: java.lang.reflect.InvocationTargetException&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:88)&lt;br/&gt;
	... 17 more&lt;br/&gt;
Caused by: java.lang.RuntimeException: Map operator initialization failed&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.ExecMapper.configure(ExecMapper.java:121)&lt;br/&gt;
	... 22 more&lt;br/&gt;
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassCastException: org.apache.hadoop.hive.ql.io.orc.OrcStruct$OrcMapObjectInspector cannot be cast to org.apache.hadoop.hive.serde2.objectinspector.SettableMapObjectInspector&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.MapOperator.setChildren(MapOperator.java:522)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.ExecMapper.configure(ExecMapper.java:90)&lt;br/&gt;
	... 22 more&lt;br/&gt;
Caused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.io.orc.OrcStruct$OrcMapObjectInspector cannot be cast to org.apache.hadoop.hive.serde2.objectinspector.SettableMapObjectInspector&lt;br/&gt;
	at org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters.getConverter(ObjectInspectorConverters.java:144)&lt;br/&gt;
	at org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters$StructConverter.&amp;lt;init&amp;gt;(ObjectInspectorConverters.java:307)&lt;br/&gt;
	at org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters.getConverter(ObjectInspectorConverters.java:138)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.MapOperator.initObjectInspector(MapOperator.java:270)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.MapOperator.setChildren(MapOperator.java:482)&lt;br/&gt;
	... 23 more&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10653&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10653&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  data/files/orc_create.txt&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcStruct.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/orc_create.q&lt;br/&gt;
  ql/src/test/results/clientpositive/orc_create.q.out&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/25569/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/25569/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, omalley&lt;/p&gt;</comment>
                            <comment id="13650248" author="phabricator@reviews.facebook.net" created="Mon, 6 May 2013 23:48:14 +0000"  >&lt;p&gt;pamelavagata has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4494&quot; title=&quot;ORC map columns get class cast exception in some context&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4494&quot;&gt;&lt;del&gt;HIVE-4494&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; ORC map columns get class cast exception in some context&quot;.&lt;/p&gt;

&lt;p&gt;  Owen, I had previously investigated this issue and found that the reason for the ClassCastException was due to the following reason:&lt;/p&gt;

&lt;p&gt;  in ObjectInspectorConverters.getConverter(ObjectInspector inputOI, ObjectInspector outputOI),&lt;br/&gt;
  there&apos;s a referential equality check to see if the inputOI is the same as the outputOI and returns a new Identity Converter. When running the same query with RC, you&apos;ll find that ColumnarSerde caches the the object inspectors and reuses them, which is why the referential equality check will pass and return an IdentityConverter instead of trying to cast to a Settable*ObjectInspector.&lt;/p&gt;

&lt;p&gt;  If you cache the object inspectors in OrcStruct instead of having OrcList/OrcMap object inspectors inherit from Settable*ObjectInspector, it will fix the underlying issue. I hadn&apos;t gotten around to submitting a diff for this yet but would be happy to push one out in the next 2 days.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10653&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10653&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, omalley&lt;br/&gt;
Cc: pamelavagata&lt;/p&gt;</comment>
                            <comment id="13651993" author="phabricator@reviews.facebook.net" created="Wed, 8 May 2013 15:37:13 +0000"  >&lt;p&gt;omalley updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4494&quot; title=&quot;ORC map columns get class cast exception in some context&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4494&quot;&gt;&lt;del&gt;HIVE-4494&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; ORC map columns get class cast exception in some context&quot;.&lt;/p&gt;

&lt;p&gt;  Added the equals methods so that the schema conversion is handled better&lt;br/&gt;
  as suggested by Pamela.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10653&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10653&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10653?vs=33351&amp;amp;id=33387#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10653?vs=33351&amp;amp;id=33387#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  data/files/orc_create.txt&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcStruct.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcUnion.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/orc_create.q&lt;br/&gt;
  ql/src/test/results/clientpositive/orc_create.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, omalley&lt;br/&gt;
Cc: pamelavagata&lt;/p&gt;</comment>
                            <comment id="13652214" author="kevinwilfong" created="Wed, 8 May 2013 18:46:28 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;Go ahead and commit if tests pass.&lt;/p&gt;</comment>
                            <comment id="13652363" author="owen.omalley" created="Wed, 8 May 2013 21:10:35 +0000"  >&lt;p&gt;I just committed this. Thanks for the review, Kevin &amp;amp; Pamela!&lt;/p&gt;</comment>
                            <comment id="13652874" author="hudson" created="Thu, 9 May 2013 11:17:18 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2093 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2093/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2093/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4494&quot; title=&quot;ORC map columns get class cast exception in some context&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4494&quot;&gt;&lt;del&gt;HIVE-4494&lt;/del&gt;&lt;/a&gt; ORC map columns get class cast exception in some contexts (omalley) (Revision 1480460)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
omalley : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1480460&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1480460&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk&lt;/li&gt;
	&lt;li&gt;/hive/trunk/data/files/orc_create.txt&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcStruct.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcUnion.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/orc_create.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/orc_create.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13653222" author="hudson" created="Thu, 9 May 2013 21:15:44 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #189 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/189/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/189/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4494&quot; title=&quot;ORC map columns get class cast exception in some context&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4494&quot;&gt;&lt;del&gt;HIVE-4494&lt;/del&gt;&lt;/a&gt; ORC map columns get class cast exception in some contexts (omalley) (Revision 1480460)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
omalley : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1480460&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1480460&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk&lt;/li&gt;
	&lt;li&gt;/hive/trunk/data/files/orc_create.txt&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcStruct.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcUnion.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/orc_create.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/orc_create.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12581820" name="HIVE-4494.D10653.1.patch" size="21194" author="phabricator@reviews.facebook.net" created="Sun, 5 May 2013 07:06:15 +0000"/>
                            <attachment id="12582307" name="HIVE-4494.D10653.2.patch" size="23559" author="phabricator@reviews.facebook.net" created="Wed, 8 May 2013 15:37:13 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 5 May 2013 07:06:15 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326407</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 37 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kb8f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326752</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4495] Implement vectorized string substr</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4495</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12646050">HIVE-4495</key>
            <summary>Implement vectorized string substr</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="tnachen">Timothy Chen</assignee>
                                    <reporter username="tnachen">Timothy Chen</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 May 2013 21:22:39 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:11 +0000</updated>
                            <resolved>Mon, 1 Jul 2013 22:27:14 +0000</resolved>
                                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13652092" author="ehans" created="Wed, 8 May 2013 17:30:01 +0000"  >&lt;p&gt;Timothy Chen is working on this already. He&apos;s trying to get added as a Hive developer so we can assign it to him on the JIRA.&lt;/p&gt;

&lt;p&gt;Teddy, if you are interested in working on vectorized QE, please get in touch with me. Thanks! -Eric&lt;/p&gt;</comment>
                            <comment id="13652583" author="teddy.choi" created="Thu, 9 May 2013 00:27:32 +0000"  >&lt;p&gt;Hello &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ehans&quot; class=&quot;user-hover&quot; rel=&quot;ehans&quot;&gt;Eric Hanson&lt;/a&gt;. I thought that there&apos;s nobody assigned to. Please excuse me for misunderstanding. I&apos;m interested in working on vectorization and any chance of it will be great for me. Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ehans&quot; class=&quot;user-hover&quot; rel=&quot;ehans&quot;&gt;Eric Hanson&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13656578" author="ehans" created="Tue, 14 May 2013 00:22:08 +0000"  >&lt;p&gt;See my comments on the first version of the patch at &lt;a href=&quot;https://reviews.apache.org/r/11106/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11106/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13658642" author="ehans" created="Wed, 15 May 2013 18:34:36 +0000"  >&lt;p&gt;This is looking good. You&apos;re almost there. See my additional comments on the review board entry.&lt;/p&gt;</comment>
                            <comment id="13663551" author="ehans" created="Tue, 21 May 2013 22:56:54 +0000"  >&lt;p&gt;The latest patch appears functionally correct but has some minor performance issues, plus unit test needs some comments. Looking good. Please make the final changes and we can get this committed.&lt;/p&gt;</comment>
                            <comment id="13668409" author="ehans" created="Tue, 28 May 2013 16:25:49 +0000"  >&lt;p&gt;Tim, please attach the patch to this JIRA. The naming convention is HIVE-XXXX.n.patch where XXXX is the JIRA number and n is the version of the patch, starting at 1.&lt;/p&gt;</comment>
                            <comment id="13697273" author="ashutoshc" created="Mon, 1 Jul 2013 22:27:14 +0000"  >&lt;p&gt;Committed to branch. Thanks, Timothy!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12585090" name="HIVE-4495.4.patch" size="34576" author="tnachen" created="Tue, 28 May 2013 21:49:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 8 May 2013 17:30:01 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326408</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 30 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kb8n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326753</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4496] JDBC2 won&apos;t compile with JDK7</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4496</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;HiveServer2 related JDBC does not compile with JDK7. Related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3384&quot; title=&quot;HIVE JDBC module won&amp;#39;t compile under JDK1.7 as new methods added in JDBC specification&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3384&quot;&gt;&lt;del&gt;HIVE-3384&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646063">HIVE-4496</key>
            <summary>JDBC2 won&apos;t compile with JDK7</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cdrome">Chris Drome</assignee>
                                    <reporter username="cdrome">Chris Drome</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 May 2013 23:28:06 +0000</created>
                <updated>Thu, 19 Dec 2013 11:19:01 +0000</updated>
                            <resolved>Tue, 25 Jun 2013 01:42:04 +0000</resolved>
                                    <version>0.12.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                    <component>JDBC</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="13648952" author="cdrome" created="Sat, 4 May 2013 00:35:46 +0000"  >&lt;p&gt;Attached trunk patch.&lt;/p&gt;</comment>
                            <comment id="13648953" author="cdrome" created="Sat, 4 May 2013 00:36:38 +0000"  >&lt;p&gt;Phabricator ticket: &lt;a href=&quot;https://reviews.facebook.net/D10647&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10647&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13648954" author="cdrome" created="Sat, 4 May 2013 00:37:37 +0000"  >&lt;p&gt;Ported the &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3384&quot; title=&quot;HIVE JDBC module won&amp;#39;t compile under JDK1.7 as new methods added in JDBC specification&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3384&quot;&gt;&lt;del&gt;HIVE-3384&lt;/del&gt;&lt;/a&gt; patch to the HS2 JDBC code.&lt;/p&gt;</comment>
                            <comment id="13649113" author="wasperen" created="Sat, 4 May 2013 17:03:16 +0000"  >&lt;p&gt;I can confirm that applying this patch makes the jdbc part of the build work.&lt;/p&gt;</comment>
                            <comment id="13665808" author="xuefuz" created="Thu, 23 May 2013 23:00:35 +0000"  >&lt;p&gt;I think the code base has changed such that applying this patch doesn&apos;t compiler any more. There is a javadoc warning failing the build. The patch might need an update. Thanks.&lt;/p&gt;

&lt;p&gt;  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Standard Doclet version 1.7.0_21&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Building tree for all the packages and classes...&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; /home/xzhang/apache/hive-nochange/hcatalog/storage-handlers/hbase/src/java/org/apache/hcatalog/hbase/snapshot/RevisionManagerFactory.java:81: warning - @return tag has no arguments.&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Building index for all the packages and classes...&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Building index for all classes...&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Generating /home/xzhang/apache/hive-nochange/hcatalog/build/docs/api/help-doc.html...&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; 2 warnings&lt;/p&gt;

&lt;p&gt;BUILD FAILED&lt;br/&gt;
/home/xzhang/apache/hive-nochange/build.xml:520: The following error occurred while executing this line:&lt;br/&gt;
/home/xzhang/apache/hive-nochange/hcatalog/build.xml:246: Javadoc comments contain warnings.&lt;/p&gt;</comment>
                            <comment id="13665824" author="cdrome" created="Thu, 23 May 2013 23:22:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;Xuefu Zhang&lt;/a&gt; I don&apos;t think the problem is with the patch.&lt;/p&gt;

&lt;p&gt;RevisionManagerFactory.java:81 generates the javadoc warning.&lt;br/&gt;
This file is not part of this patch, it was imported as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4264&quot; title=&quot;Move HCatalog trunk code from trunk/hcatalog/historical to trunk/hcatalog&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4264&quot;&gt;&lt;del&gt;HIVE-4264&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;BTW, I just finished patching trunk and running ant tar, which completed successfully.&lt;/p&gt;</comment>
                            <comment id="13665864" author="xuefuz" created="Fri, 24 May 2013 00:11:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cdrome&quot; class=&quot;user-hover&quot; rel=&quot;cdrome&quot;&gt;Chris Drome&lt;/a&gt; I guess it&apos;s right: the warning has nothing to do with your patch. I did &quot;ant tar&quot;, but it also stopped due to the warning. Not sure why.&lt;/p&gt;

&lt;p&gt;Anyway, is there a plan to check this patch in?&lt;/p&gt;</comment>
                            <comment id="13691716" author="navis" created="Mon, 24 Jun 2013 05:56:30 +0000"  >&lt;p&gt;It&apos;s not applied to trunk cleanly. Could you update this?&lt;/p&gt;</comment>
                            <comment id="13692237" author="cdrome" created="Mon, 24 Jun 2013 18:44:44 +0000"  >&lt;p&gt;Rebased trunk patch.&lt;/p&gt;</comment>
                            <comment id="13692362" author="cdrome" created="Mon, 24 Jun 2013 20:49:06 +0000"  >&lt;p&gt;Restored the SQLException signature to include the original Exception in openSession.&lt;/p&gt;</comment>
                            <comment id="13692364" author="cdrome" created="Mon, 24 Jun 2013 20:49:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt;: Please try the latest patch. Thanks for your help on this patch.&lt;/p&gt;</comment>
                            <comment id="13692673" author="navis" created="Tue, 25 Jun 2013 01:42:04 +0000"  >&lt;p&gt;I think some methods can be implemented but would be better to do in following issue. Committed to trunk. Thanks Chris!&lt;/p&gt;</comment>
                            <comment id="13693583" author="hudson" created="Wed, 26 Jun 2013 02:20:48 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #257 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/257/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/257/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4496&quot; title=&quot;JDBC2 won&amp;#39;t compile with JDK7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4496&quot;&gt;&lt;del&gt;HIVE-4496&lt;/del&gt;&lt;/a&gt; : JDBC2 won&apos;t compile with JDK7 (Chris Drome via Navis) (Revision 1496332)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
navis : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1496332&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1496332&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveCallableStatement.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveDataSource.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveDriver.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HivePreparedStatement.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13702875" author="dvryaboy" created="Tue, 9 Jul 2013 04:18:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; looks like this didn&apos;t go in. Care to give it another go?&lt;/p&gt;</comment>
                            <comment id="13702887" author="navis" created="Tue, 9 Jul 2013 04:32:01 +0000"  >&lt;p&gt;It&apos;s in trunk.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;....
d9afa8f HIVE-4591: Making changes to webhcat-site.xml have no effect
3295a8e HIVE-4784:ant testreport doesn&apos;t include any HCatalog tests
f536c0b HIVE-4496 : JDBC2 won&apos;t compile with JDK7 (Chris Drome via Navis)
e3d3bdb HIVE-1402 Add parallel order by to hive (Navis Ryu and Jeff Zhang via egc)
d3afa30 HIVE-4767 : ObjectStore.getPMF has concurrency problems (Brock Noland via Ashutosh Chauhan)
58d001a HIVE-4743 : Improve test coverage of package org.apache.hadoop.hive.ql.io (Ivan Veselovsky via Ashutosh Chauhan)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13702917" author="dvryaboy" created="Tue, 9 Jul 2013 04:57:36 +0000"  >&lt;p&gt;Right, I&apos;m looking at the vectorization branch. Will post a patch to merge trunk into the branch. Thanks.&lt;/p&gt;</comment>
                            <comment id="13795999" author="ashutoshc" created="Tue, 15 Oct 2013 23:30:17 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                            <comment id="13852817" author="mantonov" created="Thu, 19 Dec 2013 11:19:01 +0000"  >&lt;p&gt;If it affects 0.11 (compilation for jdk 7), are there any plans/possibilities to port it back to 0.11? It seems 0.11 doesn&apos;t compile under jdk7 now.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12646238">HIVE-4507</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12603418">HIVE-3384</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12648611">HIVE-4583</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12589458" name="HIVE-4496-1.patch" size="10256" author="cdrome" created="Mon, 24 Jun 2013 18:44:44 +0000"/>
                            <attachment id="12589481" name="HIVE-4496-2.patch" size="10259" author="cdrome" created="Mon, 24 Jun 2013 20:49:06 +0000"/>
                            <attachment id="12581781" name="HIVE-4496.patch" size="10253" author="cdrome" created="Sat, 4 May 2013 00:35:46 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 4 May 2013 17:03:16 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326421</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 5 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kbbj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326766</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>jdbc jdk7</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4497] beeline module tests don&apos;t get run by default</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4497</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;beeline tests are not getting run by default . &lt;br/&gt;
See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/lastCompletedBuild/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/lastCompletedBuild/testReport/&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646068">HIVE-4497</key>
            <summary>beeline module tests don&apos;t get run by default</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="thejas">Thejas M Nair</assignee>
                                    <reporter username="thejas">Thejas M Nair</reporter>
                        <labels>
                    </labels>
                <created>Sat, 4 May 2013 00:25:47 +0000</created>
                <updated>Tue, 15 Oct 2013 23:30:36 +0000</updated>
                            <resolved>Mon, 6 May 2013 19:00:10 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                    <component>CLI</component>
                    <component>HiveServer2</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13648946" author="thejas" created="Sat, 4 May 2013 00:27:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4497&quot; title=&quot;beeline module tests don&amp;#39;t get run by default&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4497&quot;&gt;&lt;del&gt;HIVE-4497&lt;/del&gt;&lt;/a&gt;.1.patch - adds beeline to iterate.hive.tests in build.properties&lt;/p&gt;</comment>
                            <comment id="13648965" author="cwsteinbach" created="Sat, 4 May 2013 01:09:30 +0000"  >&lt;p&gt;This is a duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4357&quot; title=&quot;BeeLine tests are not getting executed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4357&quot;&gt;&lt;del&gt;HIVE-4357&lt;/del&gt;&lt;/a&gt; (which I never got around to testing), but that patch positions beeline after ql, and it makes more sense to run it after jdbc as is done here.&lt;/p&gt;

&lt;p&gt;+1 (someone else needs to test and commit since I don&apos;t have a build farm).&lt;/p&gt;</comment>
                            <comment id="13649003" author="robw" created="Sat, 4 May 2013 04:11:11 +0000"  >&lt;p&gt;Patch available at &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4357&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-4357&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13649989" author="cwsteinbach" created="Mon, 6 May 2013 19:00:11 +0000"  >&lt;p&gt;Committed to trunk. Thanks Thejas.&lt;/p&gt;</comment>
                            <comment id="13650877" author="hudson" created="Tue, 7 May 2013 14:21:39 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2089 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2089/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2089/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4497&quot; title=&quot;beeline module tests don&amp;#39;t get run by default&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4497&quot;&gt;&lt;del&gt;HIVE-4497&lt;/del&gt;&lt;/a&gt;. beeline module tests don&apos;t get run by default (Thejas Nair via cws) (Revision 1479677)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
cws : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1479677&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1479677&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/build.properties&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13796044" author="ashutoshc" created="Tue, 15 Oct 2013 23:30:36 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12642507">HIVE-4357</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12639913">HIVE-4268</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12581778" name="HIVE-4497.1.patch" size="780" author="thejas" created="Sat, 4 May 2013 00:27:54 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 4 May 2013 01:09:30 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326426</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kbcn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326771</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4498] TestBeeLineWithArgs.testPositiveScriptFile fails</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4498</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;TestBeeLineWithArgs.testPositiveScriptFile fails -&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;   [junit] 0: jdbc:hive2:&lt;span class=&quot;code-comment&quot;&gt;//localhost:10000&amp;gt; &amp;gt;&amp;gt;&amp;gt; STARTED testBreakOnErrorScriptFile
&lt;/span&gt;    [junit] Output: Connecting to jdbc:hive2:&lt;span class=&quot;code-comment&quot;&gt;//localhost:10000
&lt;/span&gt;    [junit] Connected to: Hive (version 0.12.0-SNAPSHOT)
    [junit] Driver: Hive (version 0.12.0-SNAPSHOT)
    [junit] Transaction isolation: TRANSACTION_REPEATABLE_READ
    [junit] Beeline version 0.12.0-SNAPSHOT by Apache Hive
    [junit] +----------------+
    [junit] | database_name  |
    [junit] +----------------+
    [junit] +----------------+
    [junit] No rows selected (0.899 seconds)
    [junit] Closing: org.apache.hive.jdbc.HiveConnection
    [junit]
    [junit] &amp;gt;&amp;gt;&amp;gt; FAILED testPositiveScriptFile (ERROR) (2s)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12646069">HIVE-4498</key>
            <summary>TestBeeLineWithArgs.testPositiveScriptFile fails</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="thejas">Thejas M Nair</assignee>
                                    <reporter username="thejas">Thejas M Nair</reporter>
                        <labels>
                    </labels>
                <created>Sat, 4 May 2013 00:52:38 +0000</created>
                <updated>Thu, 16 May 2013 21:10:16 +0000</updated>
                            <resolved>Sat, 11 May 2013 14:54:19 +0000</resolved>
                                                    <fixVersion>0.11.0</fixVersion>
                                    <component>CLI</component>
                    <component>HiveServer2</component>
                    <component>JDBC</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13648960" author="thejas" created="Sat, 4 May 2013 00:55:20 +0000"  >&lt;p&gt;This test was introduced in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4268&quot; title=&quot;Beeline should support the -f option&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4268&quot;&gt;&lt;del&gt;HIVE-4268&lt;/del&gt;&lt;/a&gt; .&lt;/p&gt;</comment>
                            <comment id="13652530" author="hagleitn" created="Wed, 8 May 2013 23:51:39 +0000"  >&lt;p&gt;Now that the build doesn&apos;t fail earlier anymore this problem is causing the build to fail. Since we&apos;ve disabled BeeLine tests I guess we can disable this one too?&lt;/p&gt;</comment>
                            <comment id="13652539" author="hagleitn" created="Wed, 8 May 2013 23:57:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=robw&quot; class=&quot;user-hover&quot; rel=&quot;robw&quot;&gt;Rob Weltman&lt;/a&gt; do you want to take a look?&lt;/p&gt;</comment>
                            <comment id="13652550" author="cwsteinbach" created="Thu, 9 May 2013 00:09:23 +0000"  >&lt;blockquote&gt;&lt;p&gt;Since we&apos;ve disabled BeeLine tests I guess we can disable this one too?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No, I think it would be better to fix TestBeeLineWithArgs (which isn&apos;t actually broken), and re-enable a comprehensive subset of the other HiveServer2 tests, unless of course the plan is to let HiveServer2 rot until it&apos;s completely broken.&lt;/p&gt;

&lt;p&gt;TestBeeLineWithArgs was committed in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4268&quot; title=&quot;Beeline should support the -f option&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4268&quot;&gt;&lt;del&gt;HIVE-4268&lt;/del&gt;&lt;/a&gt;, but it wasn&apos;t enabled until I committed &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4497&quot; title=&quot;beeline module tests don&amp;#39;t get run by default&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4497&quot;&gt;&lt;del&gt;HIVE-4497&lt;/del&gt;&lt;/a&gt; the other day. &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4356&quot; title=&quot;remove duplicate impersonation parameters for hiveserver2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4356&quot;&gt;&lt;del&gt;HIVE-4356&lt;/del&gt;&lt;/a&gt; was committed in between, and that&apos;s the actual source of the bug.&lt;/p&gt;

&lt;p&gt;Gunther, can you please take a look at this? Thanks.&lt;/p&gt;</comment>
                            <comment id="13652554" author="cwsteinbach" created="Thu, 9 May 2013 00:11:53 +0000"  >&lt;p&gt;This is a blocker for 0.11 since &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4356&quot; title=&quot;remove duplicate impersonation parameters for hiveserver2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4356&quot;&gt;&lt;del&gt;HIVE-4356&lt;/del&gt;&lt;/a&gt; is included on that branch.&lt;/p&gt;</comment>
                            <comment id="13652594" author="hagleitn" created="Thu, 9 May 2013 00:39:07 +0000"  >&lt;p&gt;I haven&apos;t actually touched &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4356&quot; title=&quot;remove duplicate impersonation parameters for hiveserver2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4356&quot;&gt;&lt;del&gt;HIVE-4356&lt;/del&gt;&lt;/a&gt;. That&apos;s Thejas&apos; work. I believe Ashutosh mistakenly put my name in the commit log. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; do you have any ideas?&lt;/p&gt;</comment>
                            <comment id="13652616" author="thejas" created="Thu, 9 May 2013 01:10:05 +0000"  >&lt;p&gt;Sure, looking into it.&lt;/p&gt;</comment>
                            <comment id="13652650" author="thejas" created="Thu, 9 May 2013 01:39:32 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4498&quot; title=&quot;TestBeeLineWithArgs.testPositiveScriptFile fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4498&quot;&gt;&lt;del&gt;HIVE-4498&lt;/del&gt;&lt;/a&gt;.1.patch - TUGIContainingProcessor calls  shim.closeAllForUGI() to free up entries from FileSystem.CACHE. But that ends resulting in the empty result being fetched in the next call.&lt;/p&gt;

&lt;p&gt;The best way to fix the memory leak, in my opinion is to just disable the FileSystem cache.  See &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4501&quot; title=&quot;HS2 memory leak - FileSystem objects in FileSystem.CACHE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4501&quot;&gt;&lt;del&gt;HIVE-4501&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;
</comment>
                            <comment id="13652652" author="thejas" created="Thu, 9 May 2013 01:44:03 +0000"  >&lt;p&gt;Review board link - &lt;a href=&quot;https://reviews.apache.org/r/11017/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11017/&lt;/a&gt; &lt;br/&gt;
I think we should also get &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4501&quot; title=&quot;HS2 memory leak - FileSystem objects in FileSystem.CACHE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4501&quot;&gt;&lt;del&gt;HIVE-4501&lt;/del&gt;&lt;/a&gt; into hive 0.11, ie disable cache by default, so that there is no memory leak with default configs.&lt;/p&gt;
</comment>
                            <comment id="13652802" author="cwsteinbach" created="Thu, 9 May 2013 07:40:03 +0000"  >&lt;p&gt;@Thejas: Thanks for providing a patch. I verified that it fixes the problem. I also took a look at &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4356&quot; title=&quot;remove duplicate impersonation parameters for hiveserver2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4356&quot;&gt;&lt;del&gt;HIVE-4356&lt;/del&gt;&lt;/a&gt; and left some comments on the original reviewboard request here: &lt;a href=&quot;https://reviews.apache.org/r/10554/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/10554/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I would really appreciate it if you take a look. Thanks.&lt;/p&gt;</comment>
                            <comment id="13652829" author="cwsteinbach" created="Thu, 9 May 2013 09:21:51 +0000"  >&lt;p&gt;+1. If someone else can test this that would be great.&lt;/p&gt;</comment>
                            <comment id="13654725" author="thejas" created="Fri, 10 May 2013 18:53:36 +0000"  >&lt;p&gt;Carl, Thanks for the review.&lt;br/&gt;
I will go through your comments on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4356&quot; title=&quot;remove duplicate impersonation parameters for hiveserver2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4356&quot;&gt;&lt;del&gt;HIVE-4356&lt;/del&gt;&lt;/a&gt;, but I don&apos;t think I will be able to get to it today.&lt;/p&gt;
</comment>
                            <comment id="13654746" author="cwsteinbach" created="Fri, 10 May 2013 19:07:02 +0000"  >&lt;p&gt;Thanks. My comments all fall into the nice-to-have category, so there&apos;s no need to worry about it now.&lt;/p&gt;</comment>
                            <comment id="13654810" author="owen.omalley" created="Fri, 10 May 2013 20:40:36 +0000"  >&lt;p&gt;I&apos;m starting up tests now and will commit it if they pass.&lt;/p&gt;</comment>
                            <comment id="13655292" author="owen.omalley" created="Sat, 11 May 2013 14:54:19 +0000"  >&lt;p&gt;I just committed this. Thanks, Thejas!&lt;/p&gt;</comment>
                            <comment id="13655333" author="hudson" created="Sat, 11 May 2013 18:18:37 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2098 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2098/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2098/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4498&quot; title=&quot;TestBeeLineWithArgs.testPositiveScriptFile fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4498&quot;&gt;&lt;del&gt;HIVE-4498&lt;/del&gt;&lt;/a&gt; TestBeeLineWithArgs.testPositiveScriptFile fails (Thejas Nair via omalley) (Revision 1481345)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
omalley : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1481345&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1481345&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/auth/TUGIContainingProcessor.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13655486" author="hudson" created="Sun, 12 May 2013 07:32:32 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #193 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/193/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/193/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4498&quot; title=&quot;TestBeeLineWithArgs.testPositiveScriptFile fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4498&quot;&gt;&lt;del&gt;HIVE-4498&lt;/del&gt;&lt;/a&gt; TestBeeLineWithArgs.testPositiveScriptFile fails (Thejas Nair via omalley) (Revision 1481345)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
omalley : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1481345&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1481345&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/auth/TUGIContainingProcessor.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12646502">HIVE-4517</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12639913">HIVE-4268</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                                                <inwardlinks description="is broken by">
                                        <issuelink>
            <issuekey id="12642486">HIVE-4356</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12582409" name="HIVE-4498.1.patch" size="752" author="thejas" created="Thu, 9 May 2013 01:39:32 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 8 May 2013 23:51:39 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326427</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 37 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kbcv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326772</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4499] Implement more versatile data type conversion in Hive JDBC ResultSet</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4499</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The Hive JDBC ResultSet cannot convert from Double to BigDecimal, as can be seen in this code extract here:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; BigDecimal getBigDecimal(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; columnIndex) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; SQLException {
    &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; obj = getObject(columnIndex);
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (obj == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
    }
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (obj &lt;span class=&quot;code-keyword&quot;&gt;instanceof&lt;/span&gt; BigDecimal) {
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; ((BigDecimal) obj);
    }
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (obj &lt;span class=&quot;code-keyword&quot;&gt;instanceof&lt;/span&gt; HiveDecimal) {
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; ((HiveDecimal) obj).bigDecimalValue();
    }
    &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SQLException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Cannot convert column &quot;&lt;/span&gt; + columnIndex
                           + &lt;span class=&quot;code-quote&quot;&gt;&quot; to BigDecimal. Found data of type: &quot;&lt;/span&gt;
                           + obj.getClass()+&lt;span class=&quot;code-quote&quot;&gt;&quot;, value: &quot;&lt;/span&gt; + obj.toString());
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Taken from:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/hive/blob/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveBaseResultSet.java#L107&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hive/blob/trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveBaseResultSet.java#L107&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This results in interoperability problems with other APIs, such as jOOQ, as can be seen in this issue here:&lt;br/&gt;
&lt;a href=&quot;https://github.com/jOOQ/jOOQ/issues/2442&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/jOOQ/jOOQ/issues/2442&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It would be nice if Hive could implement more versatile data type conversions in its ResultSet (not just for Double/BigDecimal). Some inspiration could be taken from&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Derby (&lt;a href=&quot;http://db.apache.org/derby&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://db.apache.org/derby&lt;/a&gt;)&lt;/li&gt;
	&lt;li&gt;H2 (&lt;a href=&quot;http://www.h2database.com&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.h2database.com&lt;/a&gt;)&lt;/li&gt;
	&lt;li&gt;HSQLDB (&lt;a href=&quot;http://hsqldb.org&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hsqldb.org&lt;/a&gt;)&lt;/li&gt;
	&lt;li&gt;jOOQ (&lt;a href=&quot;http://www.jooq.org&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.jooq.org&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;All of the above implement ResultSets with lots of data type conversion capabilities.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646126">HIVE-4499</key>
            <summary>Implement more versatile data type conversion in Hive JDBC ResultSet</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png" description="A patch for this issue has been uploaded to JIRA by a contributor.">Patch Available</status>
                    <statusCategory id="4" key="indeterminate" colorName="yellow"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="lukas.eder">Lukas Eder</reporter>
                        <labels>
                    </labels>
                <created>Sun, 5 May 2013 13:53:52 +0000</created>
                <updated>Tue, 7 May 2013 11:24:40 +0000</updated>
                                            <version>0.10.0</version>
                                                    <component>JDBC</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13650682" author="serega_sheypak" created="Tue, 7 May 2013 10:48:47 +0000"  >&lt;p&gt;I&apos;ve createad a patch, how can i submit it?&lt;/p&gt;</comment>
                            <comment id="13650701" author="serega_sheypak" created="Tue, 7 May 2013 10:49:21 +0000"  >&lt;p&gt;A patch&lt;/p&gt;</comment>
                            <comment id="13650704" author="lukas.eder" created="Tue, 7 May 2013 10:51:45 +0000"  >&lt;p&gt;The patch fixes the immediate issue encountered in the aforementioned third-party library, but I really think that data type conversion has to be implemented more generally, not just for the Double -&amp;gt; BigDecimal and Float -&amp;gt; BigDecimal conversions&lt;/p&gt;</comment>
                            <comment id="13650715" author="serega_sheypak" created="Tue, 7 May 2013 11:00:33 +0000"  >&lt;p&gt;I suppose that the whole class should be refactored.&lt;br/&gt;
We need to move away conversion logic, use some neutral lib/custom routines.&lt;br/&gt;
I&apos;ve made a first try. It&apos;s my first commit to open-source &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; If I get feedback from project holder, I can continue to rework this part of jdbc module. I&apos;ve interested in reliable integration JOOQ &amp;lt;-&amp;gt; Hive/Impala (in future...)&lt;/p&gt;</comment>
                            <comment id="13650723" author="lukas.eder" created="Tue, 7 May 2013 11:12:07 +0000"  >&lt;p&gt;Sure, I&apos;m just giving in hints, myself. The last word should be said by the Hive people, of course. I was hinting at an implementation like this one here, which is &quot;conversion-complete&quot;:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://code.google.com/p/h2database/source/browse/trunk/h2/src/main/org/h2/jdbc/JdbcResultSet.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://code.google.com/p/h2database/source/browse/trunk/h2/src/main/org/h2/jdbc/JdbcResultSet.java&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&apos;m sure you can find some more inspiration there.&lt;/p&gt;</comment>
                            <comment id="13650730" author="serega_sheypak" created="Tue, 7 May 2013 11:24:40 +0000"  >&lt;p&gt;Looks cool, thanks. It should take 2-3 days for refactoring and testing.&lt;/p&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12582071" name="HIVE-4499.patch" size="41661" author="serega_sheypak" created="Tue, 7 May 2013 10:49:21 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 7 May 2013 10:48:47 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326484</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 37 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kbpj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326829</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4500] HS2 holding too many file handles of hive_job_log_hive_*.txt files</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4500</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;In the hiveserver2 setup used for testing, we see that it has 2444 files open and of them 2152 are /tmp/hive/hive_job_log_hive_*.txt files&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646139">HIVE-4500</key>
            <summary>HS2 holding too many file handles of hive_job_log_hive_*.txt files</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="alangates">Alan Gates</assignee>
                                    <reporter username="alangates">Alan Gates</reporter>
                        <labels>
                    </labels>
                <created>Sun, 5 May 2013 22:14:36 +0000</created>
                <updated>Thu, 16 May 2013 21:11:00 +0000</updated>
                            <resolved>Wed, 8 May 2013 18:25:17 +0000</resolved>
                                    <version>0.11.0</version>
                                    <fixVersion>0.11.0</fixVersion>
                                    <component>HiveServer2</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="13649520" author="cwsteinbach" created="Mon, 6 May 2013 04:26:54 +0000"  >&lt;p&gt;@Alan: I have some comments. Can you please create a review request?&lt;/p&gt;</comment>
                            <comment id="13649888" author="alangates" created="Mon, 6 May 2013 17:27:16 +0000"  >&lt;p&gt;Review request at &lt;a href=&quot;https://reviews.apache.org/r/10954/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/10954/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13649959" author="cwsteinbach" created="Mon, 6 May 2013 18:32:18 +0000"  >&lt;p&gt;I left comments on rb. Thanks.&lt;/p&gt;</comment>
                            <comment id="13650453" author="alangates" created="Tue, 7 May 2013 03:10:03 +0000"  >&lt;p&gt;Addressed Carl&apos;s comments.&lt;/p&gt;</comment>
                            <comment id="13651175" author="cwsteinbach" created="Tue, 7 May 2013 18:52:08 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;@Alan: Changes look good. I forgot to mention that we also add new properties to conf/hive-default.xml.template with a short description for documentation purposes. It would be great if you&apos;re willing to update this, but I&apos;m fine with committing this as-is. Either way, can someone at HW test this on your build farm and let me know if it passes? Thanks.&lt;/p&gt;</comment>
                            <comment id="13651370" author="thejas" created="Tue, 7 May 2013 22:08:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4500&quot; title=&quot;HS2 holding too many file handles of hive_job_log_hive_*.txt files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4500&quot;&gt;&lt;del&gt;HIVE-4500&lt;/del&gt;&lt;/a&gt;-3.patch -&lt;br/&gt;
 Setting hive.session.history.enabled to false results in NPE in several places. This is because code calling SessionState.getHiveHistory() does not check for nulls.&lt;/p&gt;

&lt;p&gt;I am removing this config param change from the patch, so that we can go ahead with rest of the changes for hive 0.11 rc&lt;/p&gt;

&lt;p&gt;I will make the parameter part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4513&quot; title=&quot;disable hivehistory logs by default&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4513&quot;&gt;&lt;del&gt;HIVE-4513&lt;/del&gt;&lt;/a&gt; that I am working on.&lt;/p&gt;</comment>
                            <comment id="13651378" author="thejas" created="Tue, 7 May 2013 22:18:34 +0000"  >&lt;p&gt;I am unable to upload the new patch to RB link that Alan created, so I created a new one - &lt;a href=&quot;https://reviews.apache.org/r/10986/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/10986/&lt;/a&gt;&lt;br/&gt;
I have uploaded patch 1 and patch 3 to it so its easy to look at the changes between them. (RB was giving me trouble uploading patch2 for some reason!)&lt;/p&gt;
</comment>
                            <comment id="13651985" author="owen.omalley" created="Wed, 8 May 2013 15:23:26 +0000"  >&lt;p&gt;I started the tests on this last night and will commit it if they pass. &lt;/p&gt;

&lt;p&gt;I dislike the use of try finally in Java, because it either causes the code to ignore exceptions in the normal case or hide exceptions in the exception case. Obviously this patch is taking the ignore exceptions option. We should fix it, but not when the fix is on the critical path.&lt;/p&gt;</comment>
                            <comment id="13652001" author="thejas" created="Wed, 8 May 2013 15:47:19 +0000"  >&lt;blockquote&gt;&lt;p&gt;I dislike the use of try finally in Java&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Which part of the patch are you referring to ? Is it the change in HiveSessionImpl.java ?&lt;/p&gt;</comment>
                            <comment id="13652007" author="brocknoland" created="Wed, 8 May 2013 15:56:10 +0000"  >&lt;blockquote&gt;&lt;p&gt;I dislike the use of try finally in Java, because it either causes the code to ignore exceptions in the normal case or hide exceptions in the exception case.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is not true as long as the finally block does not throw an exception of it&apos;s own. Thus finally blocks should not throw an Exception.&lt;/p&gt;</comment>
                            <comment id="13652085" author="owen.omalley" created="Wed, 8 May 2013 17:25:35 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Which part of the patch are you referring to ? Is it the change in HiveSessionImpl.java ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m sorry, I was assuming that since you were calling IOUtils.cleanup, which throws away exceptions, that it was in a finally block outside of the patch.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This is not true as long as the finally block does not throw an exception of it&apos;s own. Thus finally blocks should not throw an Exception.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If the finally block calls a method like IOUtils.cleanup that discards exceptions it will miss exceptions on the close. For example, if the code looks like:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;OutputStream stream = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
&lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
  ...
} &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
  IOUtils.cleanup(stream);
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then in the case where the close, which likely includes the last write to the stream, fails that exception will be lost. The right code is:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;OutputStream stream = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
&lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
  ...
  stream.close();
} &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (Throwable th) {
  IOUtils.cleanup(stream);
  &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;code-quote&quot;&gt;&quot;something&quot;&lt;/span&gt;, th);
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13652177" author="owen.omalley" created="Wed, 8 May 2013 18:25:17 +0000"  >&lt;p&gt;I just committed this to branch-0.11 and trunk. Thanks, Alan!&lt;/p&gt;</comment>
                            <comment id="13652195" author="brocknoland" created="Wed, 8 May 2013 18:36:46 +0000"  >&lt;blockquote&gt;&lt;p&gt;If the finally block calls a method like IOUtils.cleanup that discards exceptions it will miss exceptions on the close. For example, if the code looks like:&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s an incorrect idiom and shouldn&apos;t damn all finally use.&lt;/p&gt;

&lt;p&gt;Regarding your example:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;OutputStream stream = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
&lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
  ...
  stream.close();
} &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (Throwable th) {
  IOUtils.cleanup(stream);
  &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;code-quote&quot;&gt;&quot;something&quot;&lt;/span&gt;, th);
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Granted that was an example but a Throwable should never be blindly converted to an IOException. Hadoop is too often guilty of this. I believe the following to be more correct as it doesn&apos;t convert all Throwables to IOException and only eats an exception on close if a previous exception as thrown, which is the same as your example.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;OutputStream stream = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
&lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
  ...
  stream.close();
  stream = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
} &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
  IOUtils.cleanup(stream);
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13652873" author="hudson" created="Thu, 9 May 2013 11:17:18 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2093 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2093/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2093/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4500&quot; title=&quot;HS2 holding too many file handles of hive_job_log_hive_*.txt files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4500&quot;&gt;&lt;del&gt;HIVE-4500&lt;/del&gt;&lt;/a&gt; Ensure that HiveServer 2 closes log files. (Alan Gates via omalley) (Revision 1480390)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
omalley : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1480390&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1480390&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/operation/HiveCommandOperation.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/operation/Operation.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/session/HiveSessionImpl.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13653221" author="hudson" created="Thu, 9 May 2013 21:15:44 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #189 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/189/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/189/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4500&quot; title=&quot;HS2 holding too many file handles of hive_job_log_hive_*.txt files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4500&quot;&gt;&lt;del&gt;HIVE-4500&lt;/del&gt;&lt;/a&gt; Ensure that HiveServer 2 closes log files. (Alan Gates via omalley) (Revision 1480390)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
omalley : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1480390&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1480390&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/operation/HiveCommandOperation.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/operation/Operation.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/session/HiveSessionImpl.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12646330">HIVE-4513</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12582026" name="HIVE-4500-2.patch" size="5589" author="alangates" created="Tue, 7 May 2013 03:09:43 +0000"/>
                            <attachment id="12582180" name="HIVE-4500-3.patch" size="5459" author="thejas" created="Tue, 7 May 2013 22:08:37 +0000"/>
                            <attachment id="12581837" name="HIVE-4500.patch" size="5279" author="alangates" created="Sun, 5 May 2013 22:18:00 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 6 May 2013 04:26:54 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326497</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 37 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kbsf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326842</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4501] HS2 memory leak - FileSystem objects in FileSystem.CACHE</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4501</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;org.apache.hadoop.fs.FileSystem objects are getting accumulated in FileSystem.CACHE, with HS2 in unsecure mode.&lt;/p&gt;

&lt;p&gt;As a workaround, it is possible to set fs.hdfs.impl.disable.cache and fs.file.impl.disable.cache to true.&lt;br/&gt;
Users should not have to bother with this extra configuration. &lt;/p&gt;

&lt;p&gt;As a workaround disable impersonation by setting hive.server2.enable.doAs to false.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646151">HIVE-4501</key>
            <summary>HS2 memory leak - FileSystem objects in FileSystem.CACHE</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="vgumashta">Vaibhav Gumashta</assignee>
                                    <reporter username="thejas">Thejas M Nair</reporter>
                        <labels>
                    </labels>
                <created>Mon, 6 May 2013 04:23:51 +0000</created>
                <updated>Tue, 30 Dec 2014 23:11:29 +0000</updated>
                            <resolved>Fri, 14 Mar 2014 18:17:31 +0000</resolved>
                                    <version>0.11.0</version>
                                    <fixVersion>0.13.0</fixVersion>
                                    <component>HiveServer2</component>
                        <due></due>
                            <votes>4</votes>
                                    <watches>17</watches>
                                                                <comments>
                            <comment id="13649519" author="thejas" created="Mon, 6 May 2013 04:26:27 +0000"  >&lt;p&gt; It would better to call shim.closeAllForUGI to free up the FileSystem objects, like it is done for the kerberos mode  from HiveSessionImplwithUGI.close().&lt;/p&gt;

&lt;p&gt;Calling shim.closeAllForUGI at end of  TUGIContainingProcessor.process is too early and ends up returning empty results for the queries.&lt;/p&gt;</comment>
                            <comment id="13649528" author="clarkyzl" created="Mon, 6 May 2013 05:17:13 +0000"  >&lt;p&gt;Is this issue related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3098&quot; title=&quot;Memory leak from large number of FileSystem instances in FileSystem.CACHE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3098&quot;&gt;&lt;del&gt;HIVE-3098&lt;/del&gt;&lt;/a&gt; or &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3155&quot; title=&quot;Memory leak in Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3155&quot;&gt;&lt;del&gt;HIVE-3155&lt;/del&gt;&lt;/a&gt; ?&lt;/p&gt;</comment>
                            <comment id="13649529" author="clarkyzl" created="Mon, 6 May 2013 05:22:19 +0000"  >&lt;p&gt;I think HS1 has similar problems...&lt;/p&gt;</comment>
                            <comment id="13649542" author="thejas" created="Mon, 6 May 2013 06:36:59 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=clarkyzl&quot; class=&quot;user-hover&quot; rel=&quot;clarkyzl&quot;&gt;Zhuoluo Yang&lt;/a&gt; Yes, &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3098&quot; title=&quot;Memory leak from large number of FileSystem instances in FileSystem.CACHE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3098&quot;&gt;&lt;del&gt;HIVE-3098&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3155&quot; title=&quot;Memory leak in Hive&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3155&quot;&gt;&lt;del&gt;HIVE-3155&lt;/del&gt;&lt;/a&gt; are related, as it is same kind of leak is seen, but with metastore and hive server1 instead.&lt;/p&gt;</comment>
                            <comment id="13649543" author="thejas" created="Mon, 6 May 2013 06:38:04 +0000"  >&lt;p&gt;I have updated hiveserver2 setup instructions to disable the fs caches - &lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Setting+up+HiveServer2&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/Setting+up+HiveServer2&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13652680" author="thejas" created="Thu, 9 May 2013 02:20:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4501&quot; title=&quot;HS2 memory leak - FileSystem objects in FileSystem.CACHE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4501&quot;&gt;&lt;del&gt;HIVE-4501&lt;/del&gt;&lt;/a&gt;.1.patch - disables fs cache by default, in non-kerberos mode with impersonation turned on. Makes hive work with default settings. &lt;/p&gt;</comment>
                            <comment id="13775756" author="apivovarov" created="Mon, 23 Sep 2013 23:00:34 +0000"  >&lt;p&gt;Thejas, I&apos;m confused&lt;br/&gt;
patch sets fs.hdfs.impl.disable.cache to false&lt;br/&gt;
but wiki says set it to true&lt;/p&gt;</comment>
                            <comment id="13775968" author="thejas" created="Tue, 24 Sep 2013 03:56:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apivovarov&quot; class=&quot;user-hover&quot; rel=&quot;apivovarov&quot;&gt;Alexander Pivovarov&lt;/a&gt;  Sorry about that, the patch should actually set it to true. (i wish we didn&apos;t use negative flags !) &lt;/p&gt;</comment>
                            <comment id="13776008" author="apivovarov" created="Tue, 24 Sep 2013 05:39:31 +0000"  >&lt;p&gt;After set them to false I see 4 Lease checker threads created on each query execution.&lt;/p&gt;</comment>
                            <comment id="13776963" author="sarutak" created="Wed, 25 Sep 2013 00:04:45 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt;&lt;br/&gt;
Now, I try to address the issue &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5296&quot; title=&quot;Memory leak: OOM Error after multiple open/closed JDBC connections. &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5296&quot;&gt;&lt;del&gt;HIVE-5296&lt;/del&gt;&lt;/a&gt;, which includes this issue.&lt;br/&gt;
I think, it&apos;s better to call FileSystem.closeAll at the end of the session than disable cache because a FileSystem object can be used more than 1 time in a statement.&lt;/p&gt;</comment>
                            <comment id="13777022" author="sarutak" created="Wed, 25 Sep 2013 01:02:52 +0000"  >&lt;p&gt;Sorry, I think that we use FileSystem.closeAll may be not good idea because a thread can block others threads by synchronizing. So, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; idea may be better.&lt;/p&gt;</comment>
                            <comment id="13777816" author="cos" created="Wed, 25 Sep 2013 18:01:25 +0000"  >&lt;p&gt;Provided patch doesn&apos;t solve the problem though, to my understanding. It makes it less pronounced for sure, but it doesn&apos;t go away.&lt;/p&gt;</comment>
                            <comment id="13777903" author="thejas" created="Wed, 25 Sep 2013 18:49:16 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cos&quot; class=&quot;user-hover&quot; rel=&quot;cos&quot;&gt;Konstantin Boudnik&lt;/a&gt; Can you please elaborate ? The problem is memory leak in HS2 caused by FileSystem objects being cached in FileSystem.CACHE. Why won&apos;t disabling the cache stop the leak ?&lt;/p&gt;</comment>
                            <comment id="13777991" author="apivovarov" created="Wed, 25 Sep 2013 19:48:54 +0000"  >&lt;p&gt;if cache is disabled then 4 lease checker threads are created for each query in hiveserver2 process.&lt;br/&gt;
These threads keep running even after client closes the connection.&lt;br/&gt;
I tested it in hive-0.11&lt;/p&gt;</comment>
                            <comment id="13778006" author="thejas" created="Wed, 25 Sep 2013 20:02:20 +0000"  >&lt;p&gt;I have corrected the description to say that these variables should be set to true to disable the cache.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apivovarov&quot; class=&quot;user-hover&quot; rel=&quot;apivovarov&quot;&gt;Alexander Pivovarov&lt;/a&gt;&lt;br/&gt;
I thought you saw lease checker threads when you set the variables to false (ie cache was not disabled). &lt;/p&gt;</comment>
                            <comment id="13778019" author="apivovarov" created="Wed, 25 Sep 2013 20:16:04 +0000"  >&lt;p&gt;if cache is enabled then only one FileSystem per query is not closed&lt;br/&gt;
But if cache is disabled then 4 FileSystems are not closed - as a result 4 lease checker threads leak per query&lt;/p&gt;

&lt;p&gt;How disabling FileSystem cache can help with closing FileSystem?&lt;br/&gt;
if we write smth to hdfs then Lease Checker thread is created. To stop the thread File System should be closed.&lt;br/&gt;
The only question is where.&lt;br/&gt;
As we already know calling close() at he end of TUGIContainingProcessor.process is too early.&lt;br/&gt;
So, where should it be called?&lt;/p&gt;</comment>
                            <comment id="13778060" author="sarutak" created="Wed, 25 Sep 2013 20:49:36 +0000"  >&lt;p&gt;I think we need to close FileSystem object properly, right?&lt;/p&gt;</comment>
                            <comment id="13778217" author="apivovarov" created="Wed, 25 Sep 2013 23:20:03 +0000"  >&lt;p&gt;Probably we can set ctx.setHDFSCleanup(false) in Driver   (lines 415, 1126)&lt;br/&gt;
after that the fix reverted here should work &lt;a href=&quot;https://github.com/apache/hive/commit/4de1b5acc0b0507787bc8e74259a15e414dcb49e&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hive/commit/4de1b5acc0b0507787bc8e74259a15e414dcb49e&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;set HDFScleanup to false is ok because clean of tmp files on exit did not work because fs was never closed.&lt;/p&gt;</comment>
                            <comment id="13778247" author="henry.wang" created="Wed, 25 Sep 2013 23:50:29 +0000"  >&lt;p&gt;Setting hive.server2.enable.doAs to false is a workaround.&lt;/p&gt;</comment>
                            <comment id="13778256" author="cos" created="Thu, 26 Sep 2013 00:03:43 +0000"  >&lt;p&gt;But it essentially prevents auth mechanism for HS2, right?&lt;/p&gt;</comment>
                            <comment id="13779135" author="apivovarov" created="Thu, 26 Sep 2013 19:32:41 +0000"  >&lt;p&gt;I did the fix which solves the problem with open FileSystems. (in case hive.server2.enable.doAs is true (which is default))&lt;/p&gt;

&lt;p&gt;I remember all UGIs created during Statement execution/fetch and then close FSs for all these UGIs on Statement.close() event  (Filesystem CACHE should be enabled)&lt;br/&gt;
I tested it - it looks good. Can you review the fix?&lt;br/&gt;
&lt;a href=&quot;https://github.com/WANdisco/amplab-hive/commit/ef7b4f618323796e730a0a4025455fa3a8fc66d6&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/WANdisco/amplab-hive/commit/ef7b4f618323796e730a0a4025455fa3a8fc66d6&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13779139" author="cos" created="Thu, 26 Sep 2013 19:37:26 +0000"  >&lt;p&gt;Posting the patch for his fix on JIRA.&lt;/p&gt;</comment>
                            <comment id="13780156" author="sarutak" created="Fri, 27 Sep 2013 17:52:37 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apivovarov&quot; class=&quot;user-hover&quot; rel=&quot;apivovarov&quot;&gt;Alexander Pivovarov&lt;/a&gt; I revased your patch and found that FileSystem.CACHE doesn&apos;t leak.&lt;/p&gt;</comment>
                            <comment id="13780343" author="cos" created="Fri, 27 Sep 2013 20:31:57 +0000"  >&lt;p&gt;So, shall we have committed it to the trunk and 0.12?&lt;/p&gt;</comment>
                            <comment id="13780368" author="thejas" created="Fri, 27 Sep 2013 20:52:22 +0000"  >&lt;p&gt;I will review it today.&lt;/p&gt;

&lt;p&gt;Closing the fs is certainly better than just disabling the cache. The benefit of explicitly closing the FS instead of just letting the GC collect it (by disabling the cache) seems to be that the deleteOnExit() calls will actually take effect. But I am not sure if hive code is relying on deleteOnExit() to happen on the client side. I haven&apos;t seen file/file handle leaks in long running HS2 . I believe the lease checker threads also go away when GC kicks in (based on my experience with long running HS2 with many queries).&lt;/p&gt;

</comment>
                            <comment id="13780369" author="thejas" created="Fri, 27 Sep 2013 20:52:43 +0000"  >&lt;p&gt;Making it patch available to kick off the tests.&lt;/p&gt;</comment>
                            <comment id="13780531" author="cos" created="Fri, 27 Sep 2013 22:51:35 +0000"  >&lt;blockquote&gt;&lt;p&gt;I believe the lease checker threads also go away when GC kicks in&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We haven&apos;t observed that behavior in our tests, not with explicit GC at least.&lt;/p&gt;</comment>
                            <comment id="13780649" author="hiveqa" created="Sat, 28 Sep 2013 01:48:02 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12605318/HIVE-4501.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12605318/HIVE-4501.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/942/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/942/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/942/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/942/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-942/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1527140.

At revision 1527140.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0 to p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13780676" author="cos" created="Sat, 28 Sep 2013 03:33:12 +0000"  >&lt;p&gt;Regenerating patch with -p0&lt;/p&gt;</comment>
                            <comment id="13780678" author="cos" created="Sat, 28 Sep 2013 03:33:52 +0000"  >&lt;p&gt;Wrong patch structure - needs to be regenerated with p0&lt;/p&gt;</comment>
                            <comment id="13780697" author="hiveqa" created="Sat, 28 Sep 2013 05:03:16 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12605629/HIVE-4501.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12605629/HIVE-4501.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/947/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/947/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/947/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/947/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-947/source-prep.txt
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1527150.

At revision 1527150.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0 to p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13780914" author="cos" created="Sat, 28 Sep 2013 18:17:10 +0000"  >&lt;p&gt;Here&apos;s the trunk patch. The original one wasn&apos;t applicable for the trunk version and should have been clearly marked as such. Apologies.&lt;/p&gt;</comment>
                            <comment id="13782587" author="thejas" created="Tue, 1 Oct 2013 03:18:17 +0000"  >&lt;p&gt;I reviewed the patch. The patch seems to make an assumption that same thread is used for whole session. This is not the case, same thread can get used for another session, once the call for a session has been serviced. This will close FileSystems associated with other sessions as well.&lt;/p&gt;

&lt;p&gt;A clean way to deal with this would be to use same way as its done for impersonation in kerberos mode, ie using HiveSessionImplwithUGI .&lt;/p&gt;</comment>
                            <comment id="13782632" author="cos" created="Tue, 1 Oct 2013 04:58:01 +0000"  >&lt;blockquote&gt;&lt;p&gt;This is not the case, same thread can get used for another session&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Are you saying that the same FS ref. can be used across UGIs? If so, It looks like a nice big hole to me &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; The call for the close of FS is done at the point where the particular UGI&apos;s session is getting finished and all its resources are let go, e.g. operation handlers, metastore, etc. I am not sure if I follow your comment. Could you please elaborate?&lt;/p&gt;</comment>
                            <comment id="13782668" author="thejas" created="Tue, 1 Oct 2013 06:47:35 +0000"  >&lt;blockquote&gt;&lt;p&gt;Are you saying that the same FS ref. can be used across UGIs? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;No, that is not happening in current code. But this patch will accumulate FS refs that belong to different sessions and when a session is closed it can end up closing FS objects that are associated with other sessions, and not closing the FS handles that belong to the session being closed. &lt;br/&gt;
The change in TUGIContainingProcessor will just accumulate FS handles to a thread local variable.  But that thread can be used by different hive sessions. There is no 1:1 mapping between hive server 2 threads and hive sessions. I hope this clarifies.&lt;/p&gt;
</comment>
                            <comment id="13782669" author="thejas" created="Tue, 1 Oct 2013 06:49:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;The change in TUGIContainingProcessor will just accumulate FS handles to a thread local variable.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Correction (i meant to say): The change in TUGIContainingProcessor will just accumulate UGI objects to a thread local variable. The UGI objects being accumulated in the thread local hashset can belong to different sessions.&lt;/p&gt;
</comment>
                            <comment id="13905687" author="ashahab" created="Wed, 19 Feb 2014 17:12:29 +0000"  >&lt;p&gt;What is the progress on this issue?&lt;/p&gt;</comment>
                            <comment id="13935377" author="thejas" created="Fri, 14 Mar 2014 18:17:03 +0000"  >&lt;p&gt;The changes in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6312&quot; title=&quot;doAs with plain sasl auth should be session aware&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6312&quot;&gt;&lt;del&gt;HIVE-6312&lt;/del&gt;&lt;/a&gt; (in 0.13) should fix this issue, as the unsecure mode now follows same code path as secure mode, which calls closeAllForUGI .&lt;br/&gt;
I haven&apos;t verified with large number of requests and cache enabled, but if there is still any leak its going to have a different root cause.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12691303">HIVE-6312</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12746265">HIVE-8369</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12595088">HDFS-3545</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12696679">HIVE-6484</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12667990">HIVE-5268</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12559587">HIVE-3098</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12668772">HIVE-5296</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12764307">HIVE-9234</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12605629" name="HIVE-4501.1.patch" size="4009" author="cos" created="Sat, 28 Sep 2013 03:33:12 +0000"/>
                            <attachment id="12605318" name="HIVE-4501.1.patch" size="4203" author="cos" created="Thu, 26 Sep 2013 19:37:26 +0000"/>
                            <attachment id="12582416" name="HIVE-4501.1.patch" size="2222" author="thejas" created="Thu, 9 May 2013 02:20:19 +0000"/>
                            <attachment id="12605665" name="HIVE-4501.trunk.patch" size="3596" author="cos" created="Sat, 28 Sep 2013 18:16:29 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 6 May 2013 05:17:13 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326509</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 45 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kbv3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326854</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4502] NPE - subquery smb joins fails</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4502</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Found this issue while running some SMB joins. Attaching test case that causes this error.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646157">HIVE-4502</key>
            <summary>NPE - subquery smb joins fails</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis</assignee>
                                    <reporter username="vikram.dixit">Vikram Dixit K</reporter>
                        <labels>
                    </labels>
                <created>Mon, 6 May 2013 05:48:35 +0000</created>
                <updated>Tue, 15 Oct 2013 23:29:30 +0000</updated>
                            <resolved>Tue, 23 Jul 2013 00:53:23 +0000</resolved>
                                    <version>0.11.0</version>
                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                <comments>
                            <comment id="13649536" author="vikram.dixit" created="Mon, 6 May 2013 06:05:36 +0000"  >&lt;p&gt;java.lang.NullPointerException&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.hadoop.hive.ql.exec.ExprNodeColumnEvaluator.initialize(ExprNodeColumnEvaluator.java:82)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.hadoop.hive.ql.exec.JoinUtil.getObjectInspectorsFromEvaluators(JoinUtil.java:68)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.hadoop.hive.ql.exec.CommonJoinOperator.initializeOp(CommonJoinOperator.java:224)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.hadoop.hive.ql.exec.JoinOperator.initializeOp(JoinOperator.java:61)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:375)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.hadoop.hive.ql.exec.ExecReducer.configure(ExecReducer.java:154)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:88)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:64)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:486)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:421)&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:262)&lt;/p&gt;</comment>
                            <comment id="13652880" author="phabricator@reviews.facebook.net" created="Thu, 9 May 2013 11:33:15 +0000"  >&lt;p&gt;navis requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; NPE - subquery smb joins fails&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt; NPE - subquery smb joins fails&lt;/p&gt;

&lt;p&gt;Found this issue while running some SMB joins. Attaching test case that causes this error.&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10695&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10695&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/lib/DefaultGraphWalker.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMROperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRProcContext.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRRedSink1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRRedSink2.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRRedSink3.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRTableScan1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRUnion1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinFactory.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/GenMapRedWalker.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/smb_mapjoin_25.q&lt;br/&gt;
  ql/src/test/results/clientpositive/auto_smb_mapjoin_14.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/auto_sortmerge_join_6.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/auto_sortmerge_join_9.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin1.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin2.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin3.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin4.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_2.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_4.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_5.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_6.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_7.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_8.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/mapjoin_distinct.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin9.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_11.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_12.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_14.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_25.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_6.q.out&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/25653/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/25653/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13655799" author="vikram.dixit" created="Mon, 13 May 2013 06:38:19 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My attached patch actually retains the SMB join and I feel it is a better plan over-all than converting all of the joins to reduce side joins. It would be great if you could take a look and let me know your opinion. All existing unit tests pass with this patch.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Vikram.&lt;/p&gt;</comment>
                            <comment id="13662539" author="vikram.dixit" created="Tue, 21 May 2013 01:02:46 +0000"  >&lt;p&gt;Review board request:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/11082/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11082/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13673578" author="ashutoshc" created="Mon, 3 Jun 2013 21:12:59 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; Would you like to take a look at Vikram&apos;s patch? I think if we can retain SMBJoin instead of converting them to reduce-side join, thats better.&lt;/p&gt;</comment>
                            <comment id="13673856" author="navis" created="Tue, 4 Jun 2013 00:28:36 +0000"  >&lt;p&gt;I&apos;ve not converted any SMBJoins to RS-joins and just changed creation order of those. The difference is that my patch adds a root task only when all of the join aliases are handled, which is contrary to trunk (add root whenever possible and remove if it&apos;s not afterwards). The patch I&apos;ve attached seemed easier but it is just my call.&lt;/p&gt;</comment>
                            <comment id="13673946" author="vikram.dixit" created="Tue, 4 Jun 2013 02:09:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; I misread the results of the test case from your patch. I was going through your patch more meticulously and found that a few of the tests have different results. Particularly those in auto_sortmerge_join_6.q. The count results seem to have changed.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3891&quot; title=&quot;physical optimizer changes for auto sort-merge join&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3891&quot;&gt;&lt;del&gt;HIVE-3891&lt;/del&gt;&lt;/a&gt; converts SMB joins to map-joins when possible. Although that seems orthogonal to this change, any idea as to why the join is still SMB?&lt;/p&gt;

&lt;p&gt;Also attached a few more tests for this. The plans seem valid after applying your patch. I will continue to review the patch.&lt;/p&gt;</comment>
                            <comment id="13678314" author="ashutoshc" created="Fri, 7 Jun 2013 19:00:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; Sorry earlier I didnt look at the patch closely. Now, I see you indeed are doing the right thing. We should move forward on this. Did you get a chance to see why results have changed for auto_sortmerge_join_6.q Perhaps, earlier results are wrong ? Also, it will be good to add &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vikram.dixit&quot; class=&quot;user-hover&quot; rel=&quot;vikram.dixit&quot;&gt;Vikram Dixit K&lt;/a&gt; &apos;s testcases (or some simplified version of it)in the patch, if its easy enough. &lt;/p&gt;</comment>
                            <comment id="13678926" author="brucenelson6655" created="Sun, 9 Jun 2013 03:44:04 +0000"  >&lt;p&gt;I verified that &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt;-1.patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4650&quot; title=&quot;Getting Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTask on auto convert to MapJoin after upgrade to Hive-0.11.0.x from hive-0.10.0.x&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4650&quot;&gt;&lt;del&gt;HIVE-4650&lt;/del&gt;&lt;/a&gt; has been applied to HWorx hive-0.11.0.1.3.0.0-170 and the MapJoin issue in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4650&quot; title=&quot;Getting Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTask on auto convert to MapJoin after upgrade to Hive-0.11.0.x from hive-0.10.0.x&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4650&quot;&gt;&lt;del&gt;HIVE-4650&lt;/del&gt;&lt;/a&gt; still exits. &lt;/p&gt;</comment>
                            <comment id="13678929" author="brucenelson6655" created="Sun, 9 Jun 2013 03:48:56 +0000"  >&lt;p&gt;Correction - typo on my part its hive-0.11.0.1.3.0.0-107 not *-170&lt;/p&gt;</comment>
                            <comment id="13679262" author="navis" created="Mon, 10 Jun 2013 02:28:08 +0000"  >&lt;p&gt;Sorry to all. I&apos;ve seen this assigned to Vikram days ago and completely forgot.&lt;/p&gt;

&lt;p&gt;It&apos;s my bad to have missed the changed result of auto_sortmerge_join_6.q. And I&apos;ve looked into this today. It seemed another bug in trunk which does not handle joining plan in some particular order. For example,&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;set hive.auto.convert.sortmerge.join=true;
set hive.optimize.bucketmapjoin = true;
set hive.optimize.bucketmapjoin.sortedmerge = true;
set hive.auto.convert.join=true;
set hive.auto.convert.join.noconditionaltask=true;
set hive.auto.convert.join.noconditionaltask.size=200;
set hive.auto.convert.sortmerge.join.to.mapjoin=false;

select * FROM tbl1 a JOIN tbl2 b ON a.key = b.key join src c on c.value = a.value;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The above query is from auto_sortmerge_join_6.q and works well. But if we change alias &apos;c&apos; to &apos;d&apos;, it will fail. The former makes MAPJOIN first and JOIN later but the latter makes JOIN first and MAPJOIN later, making strange plan which does not work. I should fix that, too.&lt;/p&gt;</comment>
                            <comment id="13679305" author="phabricator@reviews.facebook.net" created="Mon, 10 Jun 2013 04:52:20 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; NPE - subquery smb joins fails&quot;.&lt;/p&gt;

&lt;p&gt;  Fixed changed results &amp;amp; add test cases for that.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10695&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10695&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10695?vs=33447&amp;amp;id=34479#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10695?vs=33447&amp;amp;id=34479#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/QueryPlan.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/lib/DefaultGraphWalker.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMROperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRProcContext.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRRedSink1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRRedSink2.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRRedSink3.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRTableScan1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRUnion1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinFactory.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/GenMapRedWalker.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/MapredWork.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/auto_sortmerge_join_6.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/smb_mapjoin_25.q&lt;br/&gt;
  ql/src/test/results/clientpositive/auto_smb_mapjoin_14.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/auto_sortmerge_join_6.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/auto_sortmerge_join_9.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin1.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin2.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin3.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin4.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_2.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_4.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_5.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_6.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_7.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_8.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/mapjoin_distinct.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin9.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_11.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_12.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_14.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_25.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_6.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/stats11.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13679307" author="navis" created="Mon, 10 Jun 2013 04:58:10 +0000"  >&lt;p&gt;Running test&lt;/p&gt;</comment>
                            <comment id="13679315" author="phabricator@reviews.facebook.net" created="Mon, 10 Jun 2013 05:10:20 +0000"  >&lt;p&gt;brock has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; NPE - subquery smb joins fails&quot;.&lt;/p&gt;

&lt;p&gt;  One minor question&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java:265 What do you think of passing the exception into the constructor of the SemanticException instead of printing it to standard error?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10695&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10695&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: brock&lt;/p&gt;</comment>
                            <comment id="13679321" author="phabricator@reviews.facebook.net" created="Mon, 10 Jun 2013 05:16:22 +0000"  >&lt;p&gt;navis has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; NPE - subquery smb joins fails&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java:265 I prefer that way, too. But I&apos;ve just fixed typo because it&apos;s not related to this issue. Can I do that?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/QueryPlan.java:619 I should de-comment this. Sorry.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10695&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10695&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: brock&lt;/p&gt;</comment>
                            <comment id="13680090" author="navis" created="Tue, 11 Jun 2013 00:24:06 +0000"  >&lt;p&gt;passed all tests&lt;/p&gt;</comment>
                            <comment id="13707699" author="phabricator@reviews.facebook.net" created="Sat, 13 Jul 2013 08:49:46 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; NPE - subquery smb joins fails&quot;.&lt;/p&gt;

&lt;p&gt;  Rebased to trunk&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10695&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10695&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10695?vs=34479&amp;amp;id=35697#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10695?vs=34479&amp;amp;id=35697#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/QueryPlan.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/lib/DefaultGraphWalker.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMROperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRProcContext.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRRedSink1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRRedSink2.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRRedSink3.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRTableScan1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRUnion1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinFactory.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/GenMapRedWalker.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/MapReduceCompiler.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/MapredWork.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/auto_sortmerge_join_6.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/smb_mapjoin_25.q&lt;br/&gt;
  ql/src/test/results/clientpositive/auto_smb_mapjoin_14.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/auto_sortmerge_join_6.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/auto_sortmerge_join_9.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin1.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin2.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin3.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin4.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_2.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_4.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_5.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_6.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_7.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_8.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/mapjoin_distinct.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin9.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_11.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_12.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_14.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_25.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_6.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/stats11.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;br/&gt;
Cc: brock&lt;/p&gt;</comment>
                            <comment id="13709352" author="phabricator@reviews.facebook.net" created="Tue, 16 Jul 2013 01:52:48 +0000"  >&lt;p&gt;ashutoshc has requested changes to the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; NPE - subquery smb joins fails&quot;.&lt;/p&gt;

&lt;p&gt;  I dont like the idea of tracking operators in the task thereby tasks getting involved in plan manipulation but in absence of alternatives, this may be the way to move forward for now.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/QueryPlan.java:619 I guess this is unintentional.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java:72 I am little hesistant about task being aware of operators. Ideally if we have good demarkation of different layers, task (which is sort of a driver to execute a plan) need not be aware of operators contained in its plan. Planner shouldn&apos;t wait so late that it needs to track operators in task to generate plan correctly. I don&apos;t have a proposal on how to do this better though. At the very least, it will help to add comment explaining the purpose of this list.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRRedSink1.java:70 I think its better to do following:&lt;br/&gt;
  If (op.getNumChild() != 1)&lt;/p&gt;
{
    throw new IllegalStateException(&quot;Expecting operator &quot; + op + &quot;to have one child. Found: &quot; + op.getNumChild());
  }
&lt;p&gt;  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java:261 It will be good to add comments on what this method intends to do. Also, I guess you can make this protected, since all the callers of this method are in same package.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java:281 Does this method need to be public?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java:310 I didnt get this part. Can you add comments why old and curr tasks need to be of type ExecDriver. What about MapredLocalWork?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java:318 Does this method need to be public? Also, please add javadocs for the method.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java:851 throw IllegalStateException in case # of parents != 1&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java:949 I didnt get why did you remove this if check. We shall be needing tagging only for joins. Right? Removing this check implies we will tag always, is that needed?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java:942 Better name: hasBranchFinished() ?&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinFactory.java:228 Why is this function call needed here? Can you please add comment for it?&lt;br/&gt;
  ql/src/test/results/clientpositive/auto_smb_mapjoin_14.q.out:165 I see that there is no Stage-2 at all. What caused this? Its little weird that we have stages 0,1 and 3 in plan and no stage-2 at all.&lt;br/&gt;
  ql/src/test/results/clientpositive/auto_smb_mapjoin_14.q.out:349 No stage-2 here either. Probably the same cause?&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10695&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10695&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;br/&gt;
Cc: brock&lt;/p&gt;</comment>
                            <comment id="13710519" author="hiveqa" created="Wed, 17 Jul 2013 00:16:51 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12592133/HIVE-4502.D10695.3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12592133/HIVE-4502.D10695.3.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 all tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/8/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/8/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/8/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/8/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;br/&gt;
Executing org.apache.hive.ptest.execution.CleanupPhase&lt;br/&gt;
Executing org.apache.hive.ptest.execution.PrepPhase&lt;br/&gt;
Executing org.apache.hive.ptest.execution.ExecutionPhase&lt;br/&gt;
Executing org.apache.hive.ptest.execution.ReportingPhase&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13711534" author="phabricator@reviews.facebook.net" created="Wed, 17 Jul 2013 19:46:46 +0000"  >&lt;p&gt;vikram has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; NPE - subquery smb joins fails&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java:72 Maybe this can be moved to GenMRProcCtx and a hashmap used there can provide the same functionality.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10695&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10695&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;br/&gt;
Cc: brock, vikram&lt;/p&gt;</comment>
                            <comment id="13711560" author="vikram.dixit" created="Wed, 17 Jul 2013 20:16:37 +0000"  >&lt;p&gt;Left some comments on Phabricator. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; could you please take a look.&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Vikram.&lt;/p&gt;</comment>
                            <comment id="13711561" author="phabricator@reviews.facebook.net" created="Wed, 17 Jul 2013 20:16:47 +0000"  >&lt;p&gt;vikram has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; NPE - subquery smb joins fails&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java:72 You could have a hashmap from task to seenOp in the GenMRProCtx that maps a task to its corresponding operator(s). Map&amp;lt;Task, List&amp;lt;Operator&amp;lt;?&amp;gt;&amp;gt;&amp;gt; should do the trick. This should address Ashutosh&apos;s concern.&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10695&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10695&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;br/&gt;
Cc: brock, vikram&lt;/p&gt;</comment>
                            <comment id="13711935" author="navis" created="Thu, 18 Jul 2013 02:01:49 +0000"  >&lt;p&gt;Addressing comments&lt;/p&gt;</comment>
                            <comment id="13712016" author="phabricator@reviews.facebook.net" created="Thu, 18 Jul 2013 05:06:47 +0000"  >&lt;p&gt;navis has commented on the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; NPE - subquery smb joins fails&quot;.&lt;/p&gt;

&lt;p&gt;INLINE COMMENTS&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/QueryPlan.java:619 Ah sorry. This was throwing NPE when debugging.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java:72 Ok, sure.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRRedSink1.java:70 I think it&apos;s not possible to have 2 or more children for RS, but might be possible for Tez. I&apos;ll do that.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java:261 ok&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java:281 No. Will be changed to package local.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java:310 MapRedTask in fact. If any of MapRedTask need BucketizedInputFormat, use BucketizedInputFormat. It&apos;s fix for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502?focusedCommentId=13679262&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13679262&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-4502?focusedCommentId=13679262&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13679262&lt;/a&gt;&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java:851 ok.&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java:942 done&lt;br/&gt;
  ql/src/test/results/clientpositive/auto_smb_mapjoin_14.q.out:165 If Task-A is merged into Task-B, task-A will not be visible anywhere. I&apos;ve changed not to walk further when all parents are not walked, which changed stage-ids in result.&lt;/p&gt;

&lt;p&gt;  TS1  TS2&lt;br/&gt;
      SMB&lt;br/&gt;
       RS&lt;br/&gt;
      GBY&lt;br/&gt;
       RS&lt;br/&gt;
      GBY&lt;br/&gt;
       FS&lt;/p&gt;

&lt;p&gt;  before :&lt;br/&gt;
  TS1(stage-1)-SMB-RS-GBY&lt;span class=&quot;error&quot;&gt;&amp;#91;split&amp;#93;&lt;/span&gt;RS(stage-2)-GBY-FS&lt;br/&gt;
  TS2(stage-3)-SMB&lt;span class=&quot;error&quot;&gt;&amp;#91;merge into stage-1&amp;#93;&lt;/span&gt;-RS-GBY-RS-GBY-RS-FS&lt;/p&gt;

&lt;p&gt;  after :&lt;br/&gt;
  TS1(stage-1)-SMB&lt;br/&gt;
  TS2(stage-2)-SMB&lt;span class=&quot;error&quot;&gt;&amp;#91;merged into stage-1&amp;#93;&lt;/span&gt;-RS-GBY&lt;span class=&quot;error&quot;&gt;&amp;#91;split&amp;#93;&lt;/span&gt;RS(stage-3)-GBY-FS&lt;/p&gt;

&lt;p&gt;  I&apos;ll make a issue for rearranging Stage-IDs. (and order of explain output, too)&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinFactory.java:228 It&apos;s just a refactoring. setupBucketMapJoinInfo() was called both in initMapJoinPlan() and joinMapJoinPlan().&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java:318 ok&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java:949 It&apos;s called in join-checked block.&lt;br/&gt;
  if (reducer.getClass() == JoinOperator.class) &lt;/p&gt;
{
    ....
    cplan.setNeedsTagging(true);
  }

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10695&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10695&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;br/&gt;
Cc: brock, vikram&lt;/p&gt;</comment>
                            <comment id="13712017" author="phabricator@reviews.facebook.net" created="Thu, 18 Jul 2013 05:08:47 +0000"  >&lt;p&gt;navis updated the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; NPE - subquery smb joins fails&quot;.&lt;/p&gt;

&lt;p&gt;  Addressed comments&lt;/p&gt;

&lt;p&gt;Reviewers: ashutoshc, JIRA&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10695&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10695&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CHANGE SINCE LAST DIFF&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10695?vs=35697&amp;amp;id=35865#toc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10695?vs=35697&amp;amp;id=35865#toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/lib/DefaultGraphWalker.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMROperator.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRProcContext.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRRedSink1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRRedSink2.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRRedSink3.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRTableScan1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRUnion1.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinFactory.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/GenMapRedWalker.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/parse/MapReduceCompiler.java&lt;br/&gt;
  ql/src/java/org/apache/hadoop/hive/ql/plan/MapredWork.java&lt;br/&gt;
  ql/src/test/queries/clientpositive/auto_sortmerge_join_6.q&lt;br/&gt;
  ql/src/test/queries/clientpositive/smb_mapjoin_25.q&lt;br/&gt;
  ql/src/test/results/clientpositive/auto_smb_mapjoin_14.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/auto_sortmerge_join_6.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/auto_sortmerge_join_9.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin1.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin2.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin3.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin4.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_2.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_4.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_5.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_6.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_7.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/bucketsortoptimize_insert_8.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/mapjoin_distinct.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin9.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_11.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_12.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_14.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_25.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/smb_mapjoin_6.q.out&lt;br/&gt;
  ql/src/test/results/clientpositive/stats11.q.out&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;br/&gt;
Cc: brock, vikram&lt;/p&gt;</comment>
                            <comment id="13714573" author="phabricator@reviews.facebook.net" created="Sat, 20 Jul 2013 23:52:48 +0000"  >&lt;p&gt;ashutoshc has accepted the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; NPE - subquery smb joins fails&quot;.&lt;/p&gt;

&lt;p&gt;  +1&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10695&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10695&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;br/&gt;
Cc: brock, vikram&lt;/p&gt;</comment>
                            <comment id="13714575" author="ashutoshc" created="Sun, 21 Jul 2013 00:05:00 +0000"  >&lt;p&gt;Canceling patch to trigger pre-commit test.&lt;/p&gt;</comment>
                            <comment id="13714576" author="ashutoshc" created="Sun, 21 Jul 2013 00:06:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; I rebased your patch on trunk. Attaching here for reference.&lt;/p&gt;</comment>
                            <comment id="13714652" author="hiveqa" created="Sun, 21 Jul 2013 06:24:58 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12593370/HIVE-4502.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12593370/HIVE-4502.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 2647 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer6
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_correlationoptimizer3
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/117/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/117/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/117/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/117/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.CleanupPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13714656" author="yhuai" created="Sun, 21 Jul 2013 07:08:02 +0000"  >&lt;p&gt;I will take a look at these two failed tests.&lt;/p&gt;</comment>
                            <comment id="13714762" author="yhuai" created="Sun, 21 Jul 2013 18:07:14 +0000"  >&lt;p&gt;The failed query in correlationoptimizer3.q is ...&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-sql&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;set&lt;/span&gt; hive.&lt;span class=&quot;code-keyword&quot;&gt;optimize&lt;/span&gt;.correlation=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
&lt;span class=&quot;code-keyword&quot;&gt;set&lt;/span&gt; hive.auto.&lt;span class=&quot;code-keyword&quot;&gt;convert&lt;/span&gt;.&lt;span class=&quot;code-keyword&quot;&gt;join&lt;/span&gt;=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
&lt;span class=&quot;code-keyword&quot;&gt;set&lt;/span&gt; hive.&lt;span class=&quot;code-keyword&quot;&gt;optimize&lt;/span&gt;.mapjoin.mapreduce=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;

&lt;span class=&quot;code-keyword&quot;&gt;SELECT&lt;/span&gt; d.&lt;span class=&quot;code-keyword&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;key&lt;/span&gt;, d.cnt &lt;span class=&quot;code-keyword&quot;&gt;AS&lt;/span&gt; cnt, b.&lt;span class=&quot;code-keyword&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;value&lt;/span&gt;
&lt;span class=&quot;code-keyword&quot;&gt;FROM&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;SELECT&lt;/span&gt; x.&lt;span class=&quot;code-keyword&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;key&lt;/span&gt;, x.&lt;span class=&quot;code-keyword&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;FROM&lt;/span&gt; src1 x &lt;span class=&quot;code-keyword&quot;&gt;JOIN&lt;/span&gt; src y &lt;span class=&quot;code-keyword&quot;&gt;ON&lt;/span&gt; (x.&lt;span class=&quot;code-keyword&quot;&gt;key&lt;/span&gt; = y.&lt;span class=&quot;code-keyword&quot;&gt;key&lt;/span&gt;)) b
&lt;span class=&quot;code-keyword&quot;&gt;JOIN&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;SELECT&lt;/span&gt; x.&lt;span class=&quot;code-keyword&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;key&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;count&lt;/span&gt;(1) &lt;span class=&quot;code-keyword&quot;&gt;AS&lt;/span&gt; cnt &lt;span class=&quot;code-keyword&quot;&gt;FROM&lt;/span&gt; src1 x &lt;span class=&quot;code-keyword&quot;&gt;JOIN&lt;/span&gt; src y &lt;span class=&quot;code-keyword&quot;&gt;ON&lt;/span&gt; (x.&lt;span class=&quot;code-keyword&quot;&gt;key&lt;/span&gt; = y.&lt;span class=&quot;code-keyword&quot;&gt;key&lt;/span&gt;) &lt;span class=&quot;code-keyword&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;by&lt;/span&gt; x.&lt;span class=&quot;code-keyword&quot;&gt;key&lt;/span&gt;) d
&lt;span class=&quot;code-keyword&quot;&gt;ON&lt;/span&gt; (b.&lt;span class=&quot;code-keyword&quot;&gt;key&lt;/span&gt; = d.&lt;span class=&quot;code-keyword&quot;&gt;key&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and here is the stack trace ...&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2013-07-21 10:14:04,440 INFO  lazybinary.LazyBinaryStruct (LazyBinaryStruct.java:parse(172)) - Missing fields! Expected 1 fields but only got 0! Ignoring similar problems.
2013-07-21 10:14:04,444 FATAL ExecReducer (ExecReducer.java:reduce(269)) - org.apache.hadoop.hive.ql.metadata.HiveException: Hive &lt;span class=&quot;code-object&quot;&gt;Runtime&lt;/span&gt; Error &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; processing row (tag=0) {&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;:{&lt;span class=&quot;code-quote&quot;&gt;&quot;joinkey0&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;128&quot;&lt;/span&gt;},&lt;span class=&quot;code-quote&quot;&gt;&quot;value&quot;&lt;/span&gt;:{&lt;span class=&quot;code-quote&quot;&gt;&quot;_col1&quot;&lt;/span&gt;:&quot;&quot;}}
	at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:258)
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:520)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:421)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:262)
Caused by: java.lang.ArrayIndexOutOfBoundsException
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.arraycopy(Native Method)
	at org.apache.hadoop.io.Text.set(Text.java:205)
	at org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryString.init(LazyBinaryString.java:48)
	at org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryStruct.uncheckedGetField(LazyBinaryStruct.java:216)
	at org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryStruct.getField(LazyBinaryStruct.java:197)
	at org.apache.hadoop.hive.serde2.lazybinary.objectinspector.LazyBinaryStructObjectInspector.getStructFieldData(LazyBinaryStructObjectInspector.java:61)
	at org.apache.hadoop.hive.serde2.SerDeUtils.buildJSONString(SerDeUtils.java:371)
	at org.apache.hadoop.hive.serde2.SerDeUtils.buildJSONString(SerDeUtils.java:371)
	at org.apache.hadoop.hive.serde2.SerDeUtils.getJSONString(SerDeUtils.java:236)
	at org.apache.hadoop.hive.serde2.SerDeUtils.getJSONString(SerDeUtils.java:222)
	at org.apache.hadoop.hive.ql.exec.MuxOperator.processOp(MuxOperator.java:249)
	at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:504)
	at org.apache.hadoop.hive.ql.exec.DemuxOperator.processOp(DemuxOperator.java:245)
	at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:504)
	at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:249)
	... 3 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;At here, DemuxOperator only replaces the tag (the tag seems correct at here) and forward the row to MuxOperator. Then, MuxOperator will just forward the row to the JoinOperator. Seems we cannot get the value in this case... Still looking for the root cause... Seems related to MapJoin because the query with hive.optimize.correlation=true and hive.auto.convert.join=false is fine.&lt;/p&gt;</comment>
                            <comment id="13714791" author="yhuai" created="Sun, 21 Jul 2013 19:55:14 +0000"  >&lt;p&gt;Problem found. It&apos;s because in &apos;splitTasks&apos; the new patch (uploaded at 20/Jul/13 17:06) did not set needsTagging for the MR job which has DemuxOperator. Will upload a incremental patch later.&lt;/p&gt;</comment>
                            <comment id="13714800" author="yhuai" created="Sun, 21 Jul 2013 20:42:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt;.incremental.patch has extra changes I made based on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt;.patch (uploaded at 20/Jul/13 17:06). Since in GenMapRedUtils there are three places that we need to check if we need to need to do tagging, I add a utility method to check the class of the reducer. We will set needsTagging when the reducer is JoinOperator or DemuxOperator. Also, some small updates are needed for test results of those queries related to Correlation Optimizer. Those updates just replace &apos;#### A masked pattern was here ####&apos; with &apos;$INTNAME&apos;.&lt;/p&gt;</comment>
                            <comment id="13714802" author="yhuai" created="Sun, 21 Jul 2013 20:46:57 +0000"  >&lt;p&gt;I merged my incremental patch with Ashutosh&apos;s patch. Attaching it (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4502&quot; title=&quot;NPE - subquery smb joins fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4502&quot;&gt;&lt;del&gt;HIVE-4502&lt;/del&gt;&lt;/a&gt;.1.patch) at here as a reference.&lt;/p&gt;</comment>
                            <comment id="13714876" author="hiveqa" created="Mon, 22 Jul 2013 03:09:59 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12593432/HIVE-4502.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12593432/HIVE-4502.1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 2647 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/122/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/122/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/122/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/122/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.CleanupPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13715773" author="ashutoshc" created="Mon, 22 Jul 2013 22:17:57 +0000"  >&lt;p&gt;+1 Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yhuai&quot; class=&quot;user-hover&quot; rel=&quot;yhuai&quot;&gt;Yin Huai&lt;/a&gt; for taking a look.&lt;/p&gt;</comment>
                            <comment id="13715936" author="ashutoshc" created="Tue, 23 Jul 2013 00:53:23 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Navis for the fix! Thanks, Vikram for review and testcases. Thanks, Yin for fixing failing test cases.&lt;/p&gt;</comment>
                            <comment id="13795904" author="ashutoshc" created="Tue, 15 Oct 2013 23:29:30 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12650797">HIVE-4650</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12593432" name="HIVE-4502.1.patch" size="136314" author="yhuai" created="Sun, 21 Jul 2013 20:46:57 +0000"/>
                            <attachment id="12582449" name="HIVE-4502.D10695.1.patch" size="98851" author="phabricator@reviews.facebook.net" created="Thu, 9 May 2013 11:33:15 +0000"/>
                            <attachment id="12587021" name="HIVE-4502.D10695.2.patch" size="117284" author="phabricator@reviews.facebook.net" created="Mon, 10 Jun 2013 04:52:20 +0000"/>
                            <attachment id="12592133" name="HIVE-4502.D10695.3.patch" size="117808" author="phabricator@reviews.facebook.net" created="Sat, 13 Jul 2013 08:49:46 +0000"/>
                            <attachment id="12592916" name="HIVE-4502.D10695.4.patch" size="124619" author="phabricator@reviews.facebook.net" created="Thu, 18 Jul 2013 05:08:47 +0000"/>
                            <attachment id="12593431" name="HIVE-4502.incremental.patch" size="5622" author="yhuai" created="Sun, 21 Jul 2013 20:36:15 +0000"/>
                            <attachment id="12593370" name="HIVE-4502.patch" size="126467" author="ashutoshc" created="Sun, 21 Jul 2013 00:06:38 +0000"/>
                            <attachment id="12586024" name="smb_mapjoin_25.q" size="6437" author="vikram.dixit" created="Tue, 4 Jun 2013 02:07:31 +0000"/>
                            <attachment id="12581848" name="smb_mapjoin_25.q" size="2463" author="vikram.dixit" created="Mon, 6 May 2013 05:49:20 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 9 May 2013 11:33:15 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326515</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kbwf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326860</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4503] HiveServer have  too  many opened  fd</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4503</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;When i run hiveserver a while time it will occur error  &amp;gt;&amp;gt;&amp;gt; Caused by: java.io.FileNotFoundException: /opt/tmp/mapred/local/jobTracker/job_201301251143_76286.xml (Too many open files)&lt;/p&gt;

&lt;p&gt;more errors info : &lt;/p&gt;


&lt;p&gt;013-05-06 02:54:47,426 WARN  parse.SemanticAnalyzer (SemanticAnalyzer.java:genBodyPlan(5821)) - Common Gby keys:null&lt;br/&gt;
2013-05-06 02:54:50,386 WARN  mapred.JobClient (JobClient.java:copyAndConfigureFiles(659)) - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.&lt;br/&gt;
2013-05-06 02:54:52,565 ERROR exec.Task (SessionState.java:printError(380)) - Job Submission failed with exception &apos;org.apache.hadoop.ipc.RemoteException(java.io.IOException: java.io.FileNotFoundException: /opt/tmp/mapred/local/jobTracker/job_201301251143_76286.xml (Too many open files)&lt;br/&gt;
	at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:3943)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor1278.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:601)&lt;br/&gt;
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)&lt;br/&gt;
Caused by: java.io.FileNotFoundException: /opt/tmp/mapred/local/jobTracker/job_201301251143_76286.xml (Too many open files)&lt;br/&gt;
	at java.io.FileOutputStream.open(Native Method)&lt;br/&gt;
	at java.io.FileOutputStream.&amp;lt;init&amp;gt;(FileOutputStream.java:212)&lt;br/&gt;
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.&amp;lt;init&amp;gt;(RawLocalFileSystem.java:188)&lt;br/&gt;
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.&amp;lt;init&amp;gt;(RawLocalFileSystem.java:184)&lt;br/&gt;
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:242)&lt;br/&gt;
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.&amp;lt;init&amp;gt;(ChecksumFileSystem.java:335)&lt;br/&gt;
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:368)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:546)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:527)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:434)&lt;br/&gt;
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:229)&lt;br/&gt;
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:163)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:1164)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:1145)&lt;br/&gt;
	at org.apache.hadoop.mapred.JobInProgress.&amp;lt;init&amp;gt;(JobInProgress.java:415)&lt;br/&gt;
	at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:3941)&lt;br/&gt;
	... 10 more&lt;br/&gt;
)&apos;&lt;/p&gt;

&lt;p&gt;when i restart the hiveserver it will be ok .&lt;/p&gt;

&lt;p&gt;Thanks &lt;/p&gt;</description>
                <environment>&lt;p&gt;Hive: hive-0.8.1 &lt;br/&gt;
OS: Red Hat Enterprise Linux Server release 5.7 (Tikanga)&lt;br/&gt;
Hadoop: 0.20.205&lt;/p&gt;</environment>
        <key id="12646165">HIVE-4503</key>
            <summary>HiveServer have  too  many opened  fd</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="biansutao">sutao bian</reporter>
                        <labels>
                    </labels>
                <created>Mon, 6 May 2013 07:27:37 +0000</created>
                <updated>Fri, 7 Feb 2014 19:43:00 +0000</updated>
                                            <version>0.8.1</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13650106" author="alangates" created="Mon, 6 May 2013 20:59:46 +0000"  >&lt;p&gt;This looks like a duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4500&quot; title=&quot;HS2 holding too many file handles of hive_job_log_hive_*.txt files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4500&quot;&gt;&lt;del&gt;HIVE-4500&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13778474" author="wzc1989" created="Thu, 26 Sep 2013 04:42:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4500&quot; title=&quot;HS2 holding too many file handles of hive_job_log_hive_*.txt files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4500&quot;&gt;&lt;del&gt;HIVE-4500&lt;/del&gt;&lt;/a&gt; explicitly close history file and other resources in hiveserver2&apos;s close session methods, but hiveserver still depends on GC to release history file and SessionState&apos;s tmpOutputFile. There is a clean method in ThriftHive interface introduced in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-818&quot; title=&quot;Create a Hive CLI that connects to hive ThriftServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-818&quot;&gt;&lt;del&gt;HIVE-818&lt;/del&gt;&lt;/a&gt; and we can use it to explicitly close a session in hiveserver. We can also try to clean up old resource each time we initize a HiveServerHandler in HiveServer.java:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;@@ -134,10 +136,23 @@ &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; HiveServerHandler(HiveConf conf) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; MetaException {
|        isHiveQuery = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
|        driver = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
|        SessionState session = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SessionState(conf);
| +
| +      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (SessionState.get() != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
| +        SessionState oldSession = SessionState.get();
| +        tearDownSessionIO(oldSession);
| +      }
|        SessionState.start(session);
|        setupSessionIO(session);
|      }
|
| +    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; void tearDownSessionIO(SessionState session) {
| +      HiveHistory hiveHist = session.getHiveHistory();
| +      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; != hiveHist) {
| +        hiveHist.closeStream();
| +      }
| +      IOUtils.cleanup(LOG, session.out);
| +    }
| +
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Please correct me if I miss something.&lt;/p&gt;</comment>
                            <comment id="13894917" author="karen@cloudera.com" created="Fri, 7 Feb 2014 19:43:00 +0000"  >&lt;p&gt;Removed non-ascii character from Summary title.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 6 May 2013 20:59:46 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326523</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 50 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kby7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326868</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>hiveserver,too many open files </customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4504] HiveServer have  too  many opened  fd&#12290; </title>
                <link>https://issues.apache.org/jira/browse/HIVE-4504</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;When i run hiveserver a while time it will occur error  &amp;gt;&amp;gt;&amp;gt; Caused by: java.io.FileNotFoundException: /opt/tmp/mapred/local/jobTracker/job_201301251143_76286.xml (Too many open files)&lt;/p&gt;

&lt;p&gt;more errors info : &lt;/p&gt;


&lt;p&gt;013-05-06 02:54:47,426 WARN  parse.SemanticAnalyzer (SemanticAnalyzer.java:genBodyPlan(5821)) - Common Gby keys:null&lt;br/&gt;
2013-05-06 02:54:50,386 WARN  mapred.JobClient (JobClient.java:copyAndConfigureFiles(659)) - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.&lt;br/&gt;
2013-05-06 02:54:52,565 ERROR exec.Task (SessionState.java:printError(380)) - Job Submission failed with exception &apos;org.apache.hadoop.ipc.RemoteException(java.io.IOException: java.io.FileNotFoundException: /opt/tmp/mapred/local/jobTracker/job_201301251143_76286.xml (Too many open files)&lt;br/&gt;
	at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:3943)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor1278.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:601)&lt;br/&gt;
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)&lt;br/&gt;
Caused by: java.io.FileNotFoundException: /opt/tmp/mapred/local/jobTracker/job_201301251143_76286.xml (Too many open files)&lt;br/&gt;
	at java.io.FileOutputStream.open(Native Method)&lt;br/&gt;
	at java.io.FileOutputStream.&amp;lt;init&amp;gt;(FileOutputStream.java:212)&lt;br/&gt;
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.&amp;lt;init&amp;gt;(RawLocalFileSystem.java:188)&lt;br/&gt;
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.&amp;lt;init&amp;gt;(RawLocalFileSystem.java:184)&lt;br/&gt;
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:242)&lt;br/&gt;
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.&amp;lt;init&amp;gt;(ChecksumFileSystem.java:335)&lt;br/&gt;
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:368)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:546)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:527)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:434)&lt;br/&gt;
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:229)&lt;br/&gt;
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:163)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:1164)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:1145)&lt;br/&gt;
	at org.apache.hadoop.mapred.JobInProgress.&amp;lt;init&amp;gt;(JobInProgress.java:415)&lt;br/&gt;
	at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:3941)&lt;br/&gt;
	... 10 more&lt;br/&gt;
)&apos;&lt;/p&gt;

&lt;p&gt;when i restart the hiveserver it will be ok .&lt;/p&gt;

&lt;p&gt;Thanks &lt;/p&gt;</description>
                <environment>&lt;p&gt;Hive: hive-0.8.1 &lt;br/&gt;
OS: Red Hat Enterprise Linux Server release 5.7 (Tikanga)&lt;br/&gt;
Hadoop: 0.20.205&lt;/p&gt;</environment>
        <key id="12646166">HIVE-4504</key>
            <summary>HiveServer have  too  many opened  fd&#12290; </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="biansutao">sutao bian</reporter>
                        <labels>
                    </labels>
                <created>Mon, 6 May 2013 07:28:30 +0000</created>
                <updated>Mon, 6 May 2013 21:04:01 +0000</updated>
                            <resolved>Mon, 6 May 2013 21:04:01 +0000</resolved>
                                    <version>0.8.1</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13650110" author="alangates" created="Mon, 6 May 2013 21:04:01 +0000"  >&lt;p&gt;Duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4503&quot; title=&quot;HiveServer have  too  many opened  fd&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4503&quot;&gt;HIVE-4503&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 6 May 2013 21:04:01 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326524</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 38 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kbyf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326869</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>hiveserver,too many open files </customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4505] Hive can&apos;t load transforms added using &apos;ADD FILE&apos;</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4505</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;ADD FILE mangles name of the resource when copying to resource download directory. As a results following doesn&apos;t work:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-sql&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;ADD&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;FILE&lt;/span&gt; test.py;
&lt;span class=&quot;code-keyword&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;TRANSFORM&lt;/span&gt; (id) &lt;span class=&quot;code-keyword&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&apos;python test.py&apos;&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;AS&lt;/span&gt; b &lt;span class=&quot;code-keyword&quot;&gt;FROM&lt;/span&gt; tab1;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The resource gets added with a different name every time which makes it impossible to use transform in non-interactive mode.&lt;/p&gt;

&lt;p&gt;This seems to be due to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3431&quot; title=&quot;Avoid race conditions while downloading resources from non-local filesystem&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3431&quot;&gt;&lt;del&gt;HIVE-3431&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646178">HIVE-4505</key>
            <summary>Hive can&apos;t load transforms added using &apos;ADD FILE&apos;</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="prasadm">Prasad Mujumdar</assignee>
                                    <reporter username="prasadm">Prasad Mujumdar</reporter>
                        <labels>
                    </labels>
                <created>Mon, 6 May 2013 09:01:17 +0000</created>
                <updated>Thu, 16 May 2013 21:10:43 +0000</updated>
                            <resolved>Sat, 11 May 2013 15:05:45 +0000</resolved>
                                    <version>0.11.0</version>
                                    <fixVersion>0.11.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="13649606" author="prasadm" created="Mon, 6 May 2013 09:11:05 +0000"  >&lt;p&gt;Patch for 0.11 branch&lt;/p&gt;</comment>
                            <comment id="13649607" author="prasadm" created="Mon, 6 May 2013 09:11:19 +0000"  >&lt;p&gt;Review request on &lt;a href=&quot;https://reviews.apache.org/r/10945/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/10945/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13649973" author="prasadm" created="Mon, 6 May 2013 18:46:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;Owen O&apos;Malley&lt;/a&gt; This is a regression in 0.11 over 0.10 and hence created as a blocker for 0.11.&lt;/p&gt;</comment>
                            <comment id="13650205" author="owen.omalley" created="Mon, 6 May 2013 22:55:11 +0000"  >&lt;p&gt;Sorry, I did a bulk change of all of the 50 unfixed jiras to remove 0.11.0. If you read the message on dev, I included this one in the list for 0.11.0. &lt;/p&gt;</comment>
                            <comment id="13650229" author="owen.omalley" created="Mon, 6 May 2013 23:32:31 +0000"  >&lt;p&gt;This doesn&apos;t look like the right fix. It seems to mostly revert &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3431&quot; title=&quot;Avoid race conditions while downloading resources from non-local filesystem&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3431&quot;&gt;&lt;del&gt;HIVE-3431&lt;/del&gt;&lt;/a&gt; without fixing the original issue. There doesn&apos;t seem to be any code that uses the value in HIVE_SERVER2_SESSION.&lt;/p&gt;</comment>
                            <comment id="13650363" author="prasadm" created="Tue, 7 May 2013 01:56:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;Owen O&apos;Malley&lt;/a&gt; Thanks for taking a look. &lt;br/&gt;
yes, the fix is to essentially to revert &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3431&quot; title=&quot;Avoid race conditions while downloading resources from non-local filesystem&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3431&quot;&gt;&lt;del&gt;HIVE-3431&lt;/del&gt;&lt;/a&gt; and to provide configuration options. Hive already support ${user.name} and with this patch you can also use ${hive.server2.session} to have separate directory per session. The level of isolation that you need depends on the configuration (stand-alone vs Server) and this provides you options to tune it per the use case.&lt;/p&gt;</comment>
                            <comment id="13650903" author="owen.omalley" created="Tue, 7 May 2013 14:54:21 +0000"  >&lt;p&gt;I don&apos;t see how separating queries by user.name is sufficient. Most users don&apos;t go through Hive Server 2, so we need to ensure that we don&apos;t break their use case of using the cli. I see you setting the hive server 2 session name, but nothing seems to use the value you set. Why is deleting the directory necessary?&lt;/p&gt;</comment>
                            <comment id="13651086" author="prasadm" created="Tue, 7 May 2013 17:23:31 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;Owen O&apos;Malley&lt;/a&gt; yes, totally agree that we need to take care of both CLI and HiveServer2 cases.&lt;br/&gt;
Hive always supported user.name property in the config settings to that each multiple CLI users in the same environment will have separate resource directories. I believe the original &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3431&quot; title=&quot;Avoid race conditions while downloading resources from non-local filesystem&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3431&quot;&gt;&lt;del&gt;HIVE-3431&lt;/del&gt;&lt;/a&gt; patch was created to addresss HiveServer/HiveServer2 issue where the you could have multiple sessions with same user (eg when its not impersonating). In such case all the queries will be sharing the same resource directories resulting into conflicts.&lt;br/&gt;
The proposed patch restores the pre - &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3431&quot; title=&quot;Avoid race conditions while downloading resources from non-local filesystem&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3431&quot;&gt;&lt;del&gt;HIVE-3431&lt;/del&gt;&lt;/a&gt; behavior. The CLI users can continue to include user.name macro, there&apos;s already hive.session.id which can also be include if needed. For example,&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&amp;lt;name&amp;gt;hive.downloaded.resources.dir&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;/tmp/resource_dir/${user.name}/${hive.session.id}&amp;lt;/value&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Besides restoring the old behavior, the patch also enabled the hiveserver2 session handle for such isolation. Unlike hive.session.id (which is a timestamp), the hiveserver2 session handle is UUID which is a better option to avoid conflicts. If you are using HiveServe2 without impersonation, then you have an option to include this session handle in the directory path. &lt;br/&gt;
If you do use the session handles, then it will start creating a new directory per session. Hence there&apos;s an option (which is disabled by default) to remove that at the end of session.&lt;/p&gt;</comment>
                            <comment id="13651300" author="owen.omalley" created="Tue, 7 May 2013 20:55:32 +0000"  >&lt;p&gt;Ok, I see what you did now. &lt;b&gt;smile&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;How about pushing the change into cli to set a uuid as hive.session.id and changing the default value of hive.downloaded.resource.dir to use it also. Of course, you&apos;ll need to make the ql code do the delete instead of hive server 2.&lt;/p&gt;</comment>
                            <comment id="13654949" author="hagleitn" created="Fri, 10 May 2013 22:37:37 +0000"  >&lt;p&gt;I&apos;ve refactored &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasadm&quot; class=&quot;user-hover&quot; rel=&quot;prasadm&quot;&gt;Prasad Mujumdar&lt;/a&gt;&apos;s code slightly with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;Owen O&apos;Malley&lt;/a&gt;&apos;s recommendation. I think the added benefit is that it&apos;ll work for both CLI and HS2 with the default configuration.&lt;/p&gt;

&lt;p&gt;I also added a test case that exercises the code (TestMinimrCliDriver, fails before, passes after).&lt;/p&gt;

&lt;p&gt;Finally, I ran tests and it looks good.&lt;/p&gt;

&lt;p&gt;What do you guys think?&lt;/p&gt;</comment>
                            <comment id="13655001" author="owen.omalley" created="Fri, 10 May 2013 23:09:45 +0000"  >&lt;p&gt;+1 I&apos;ll commit it if the tests pass.&lt;/p&gt;</comment>
                            <comment id="13655163" author="prasadm" created="Sat, 11 May 2013 05:21:48 +0000"  >&lt;p&gt;sorry I could update the patch earlier as Owner&apos;s comment. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hagleitn&quot; class=&quot;user-hover&quot; rel=&quot;hagleitn&quot;&gt;Gunther Hagleitner&lt;/a&gt; Thanks for jumping in. Appreciate it. &lt;br/&gt;
The new patch is consolidating the session.id for both CLI and HiveServe. It mostly look fine. I have see  a few issues -&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The session now user+VM+date which could still result into conflicts for HiveServer2, eg. with impersonation turned off or same userid used in multiple sessions&lt;/li&gt;
	&lt;li&gt;The download directory is not getting cleaned up in case of hive -f &amp;lt;script&amp;gt;&lt;/li&gt;
	&lt;li&gt;A couple of corner error cases in HiveServer close() which could leave session&apos;s download directory behind.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I have an updated patch which addressed the issues. Please take a look at let me know.&lt;/p&gt;</comment>
                            <comment id="13655167" author="prasadm" created="Sat, 11 May 2013 05:23:35 +0000"  >&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Use UUID as the hive session id&lt;/li&gt;
	&lt;li&gt;Clean up the download dir in when CLI is invoked with -f option&lt;/li&gt;
	&lt;li&gt;Handle minor error cases&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13655187" author="owen.omalley" created="Sat, 11 May 2013 07:36:30 +0000"  >&lt;p&gt;Prasad, &lt;/p&gt;

&lt;p&gt;in Gunther&apos;s patch, Hive Server 2 will use the session handle for the handle identifier.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &lt;span class=&quot;code-comment&quot;&gt;// set an explicit session name to control the download directory name
&lt;/span&gt;    hiveConf.set(ConfVars.HIVESESSIONID.varname,
        sessionHandle.getHandleIdentifier().toString());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So there isn&apos;t an issue, right?&lt;/p&gt;

&lt;p&gt;The use of finally has bad properties with respect to debugability because any exceptions thrown out of the finally block (including ones like OOM or NPE) will hide the original exception. &lt;/p&gt;

&lt;p&gt;The -f case is certainly a bug, still an improvement over the current trunk (or Hive 0.10) behavior.&lt;/p&gt;

&lt;p&gt;My inclination is to wait for the test cases that I launched this afternoon to finish and roll the rc with Gunther&apos;s version of the patch tomorrow morning. We can file a follow up jira with a refactoring of the CliDriver.run that doesn&apos;t have so many return points. &lt;b&gt;smile&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Does that sounds reasonable?&lt;/p&gt;
</comment>
                            <comment id="13655194" author="prasadm" created="Sat, 11 May 2013 08:08:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;Owen O&apos;Malley&lt;/a&gt; My concern was that the way session handle is constructed (userid+VMid+date), there&apos;s still a possibility of running into conflict. But still what we have is better than what&apos;s on trunk before. I am fine with Gunther&apos;s patch for that case. &lt;br/&gt;
For CLI case, this might be a bit of problem to leave behind a new directory on each invocation. The users have a workaround of changing the configuration back to the old default. You might want to consider either restoring the default or just adding Sessionstate.close() for the -f case.&lt;/p&gt;

&lt;p&gt;Anyway, I am fine with keeping Gunther&apos;s patch in the RC. If are going to commit that patch, then I can log a follow up ticket for 0.12.&lt;/p&gt;

&lt;p&gt;Again, my apologies for not addressing the review comments sooner for the blocker issue.&lt;/p&gt;</comment>
                            <comment id="13655291" author="owen.omalley" created="Sat, 11 May 2013 14:48:40 +0000"  >&lt;p&gt;Thanks, Prasad.&lt;/p&gt;

&lt;p&gt;How can you explain how to run into conflict with username+process+host+date? It seems that would be a unique id (except in the Hive Server 2 case where username, process, and host are identical).&lt;/p&gt;

&lt;p&gt;This bug only happens in the case where the add file resource is on a non-local filesystem. By far the majority of users seem to use a local file system, so I think we can push fixing it to 0.11.1. &lt;b&gt;grin&lt;/b&gt;&lt;/p&gt;</comment>
                            <comment id="13655294" author="owen.omalley" created="Sat, 11 May 2013 15:05:45 +0000"  >&lt;p&gt;I just committed this. Thanks, Prasad and Gunther!&lt;/p&gt;</comment>
                            <comment id="13655332" author="hudson" created="Sat, 11 May 2013 18:18:37 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2098 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2098/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2098/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4505&quot; title=&quot;Hive can&amp;#39;t load transforms added using &amp;#39;ADD FILE&amp;#39;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4505&quot;&gt;&lt;del&gt;HIVE-4505&lt;/del&gt;&lt;/a&gt; Hive can&apos;t load transforms with remote scripts. (Prasad Majumdar and Gunther Hagleitner&lt;br/&gt;
via omalley) (Revision 1481347)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
omalley : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1481347&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1481347&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk&lt;/li&gt;
	&lt;li&gt;/hive/trunk/build-common.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/cli/src/java/org/apache/hadoop/hive/cli/CliSessionState.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/remote_script.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/remote_script.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/session/HiveSessionImpl.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13655485" author="hudson" created="Sun, 12 May 2013 07:32:32 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #193 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/193/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/193/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4505&quot; title=&quot;Hive can&amp;#39;t load transforms added using &amp;#39;ADD FILE&amp;#39;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4505&quot;&gt;&lt;del&gt;HIVE-4505&lt;/del&gt;&lt;/a&gt; Hive can&apos;t load transforms with remote scripts. (Prasad Majumdar and Gunther Hagleitner&lt;br/&gt;
via omalley) (Revision 1481347)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
omalley : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1481347&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1481347&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk&lt;/li&gt;
	&lt;li&gt;/hive/trunk/build-common.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/cli/src/java/org/apache/hadoop/hive/cli/CliSessionState.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/remote_script.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/remote_script.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/session/HiveSessionImpl.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12647264">HIVE-4546</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12581861" name="HIVE-4505-1.patch" size="6179" author="prasadm" created="Mon, 6 May 2013 09:11:05 +0000"/>
                            <attachment id="12582771" name="HIVE-4505-3.patch" size="16682" author="prasadm" created="Sat, 11 May 2013 05:23:35 +0000"/>
                            <attachment id="12582719" name="HIVE-4505.2.patch" size="15108" author="hagleitn" created="Fri, 10 May 2013 22:37:37 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 6 May 2013 22:55:11 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326536</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 37 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kc13:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326881</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4506] use one map reduce to join multiple small tables </title>
                <link>https://issues.apache.org/jira/browse/HIVE-4506</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;I know we can use map side join for small table.&lt;br/&gt;
by my test, if I use HQL like this&lt;br/&gt;
------&lt;br/&gt;
select /&lt;b&gt;+mapjoin(b,c)&lt;/b&gt;/...&lt;br/&gt;
from a&lt;br/&gt;
left join b&lt;br/&gt;
on ...&lt;br/&gt;
left join c&lt;br/&gt;
on ...&lt;br/&gt;
-------&lt;br/&gt;
b and c are both small tables, I expect do the join in one map reduce using map side join. Actually, it would generate two map-reduce jobs by sequence.&lt;/p&gt;


&lt;p&gt;Sorry, currently I am just a user of hive and not dig into the code, so this is what I expect but I have no idea about how to improve now. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12646195">HIVE-4506</key>
            <summary>use one map reduce to join multiple small tables </summary>
                <type id="5" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Wish</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="lou.kevinx@gmail.com">Fern</reporter>
                        <labels>
                    </labels>
                <created>Mon, 6 May 2013 11:37:58 +0000</created>
                <updated>Tue, 7 May 2013 02:34:54 +0000</updated>
                                            <version>0.10.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13650371" author="lianhuiwang" created="Tue, 7 May 2013 02:17:38 +0000"  >&lt;p&gt;Fern, can you provide your sql?&lt;br/&gt;
if these tables used the same column in join clause, it used one mr.&lt;br/&gt;
example:&lt;br/&gt;
explain&lt;br/&gt;
SELECT /&lt;b&gt;+mapjoin(src2,src3)&lt;/b&gt;/ src1.key, src3.value FROM src src1 JOIN src src2 ON (src1.key = src2.key) JOIN src src3 ON (src1.key = src3.key);&lt;/p&gt;
</comment>
                            <comment id="13650380" author="lianhuiwang" created="Tue, 7 May 2013 02:34:54 +0000"  >&lt;p&gt;if these have difference column, &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3784&quot; title=&quot;de-emphasize mapjoin hint&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3784&quot;&gt;&lt;del&gt;HIVE-3784&lt;/del&gt;&lt;/a&gt; resolved one big table with multiple small tables.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 7 May 2013 02:17:38 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326553</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 38 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kc4v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326898</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4507] Fix jdbc to compile under openjdk 7</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4507</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The newer Linux distros are shipping with just openjdk 7. Currently, the jdbc module doesn&apos;t compile because some new methods aren&apos;t implemented.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646238">HIVE-4507</key>
            <summary>Fix jdbc to compile under openjdk 7</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="owen.omalley">Owen O&apos;Malley</assignee>
                                    <reporter username="owen.omalley">Owen O&apos;Malley</reporter>
                        <labels>
                    </labels>
                <created>Mon, 6 May 2013 16:10:14 +0000</created>
                <updated>Mon, 6 May 2013 18:11:51 +0000</updated>
                            <resolved>Mon, 6 May 2013 18:11:51 +0000</resolved>
                                                                    <component>JDBC</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                    <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12646063">HIVE-4496</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326596</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 38 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kcef:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326941</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4508] Make minor changes to README and NOTICE files.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4508</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Various trivial changes to README files.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646240">HIVE-4508</key>
            <summary>Make minor changes to README and NOTICE files.</summary>
                <type id="3" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21148&amp;avatarType=issuetype">Task</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.svg">Trivial</priority>
                        <status id="4" iconUrl="https://issues.apache.org/jira/images/icons/statuses/reopened.png" description="This issue was once resolved, but the resolution was deemed incorrect. From here issues are either marked assigned or resolved.">Reopened</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="owen.omalley">Owen O&apos;Malley</reporter>
                        <labels>
                    </labels>
                <created>Mon, 6 May 2013 16:14:10 +0000</created>
                <updated>Sat, 6 Dec 2014 09:59:03 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13649934" author="cdrome" created="Mon, 6 May 2013 18:09:10 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4496&quot; title=&quot;JDBC2 won&amp;#39;t compile with JDK7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4496&quot;&gt;&lt;del&gt;HIVE-4496&lt;/del&gt;&lt;/a&gt; fixes the build issue with JDBC2 and JDK1.7.&lt;/p&gt;</comment>
                            <comment id="13649952" author="owen.omalley" created="Mon, 6 May 2013 18:25:00 +0000"  >&lt;p&gt;This fixes the issues that Carl identified.&lt;/p&gt;</comment>
                            <comment id="13650035" author="owen.omalley" created="Mon, 6 May 2013 19:47:16 +0000"  >&lt;p&gt;Removed paragraph about replacing hive-default.xml.&lt;/p&gt;</comment>
                            <comment id="13650946" author="owen.omalley" created="Tue, 7 May 2013 15:13:02 +0000"  >&lt;p&gt;I committed this to branch-11. (I assume that I don&apos;t need an explicit +1 from anyone since we don&apos;t normally file a jira for this stuff. I wanted to give the community to see the chance to see the changes before they were committed.) I&apos;ll regenerate the RELEASE_NOTES just before I make rc2 so that new jiras are reflected.&lt;/p&gt;</comment>
                            <comment id="13651257" author="cwsteinbach" created="Tue, 7 May 2013 20:22:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=owen.omalley&quot; class=&quot;user-hover&quot; rel=&quot;owen.omalley&quot;&gt;Owen O&apos;Malley&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I assume that I don&apos;t need an explicit +1 from anyone since we don&apos;t normally file a jira for this stuff.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not true. You need an explicit +1 from another committer, and we do usually file JIRAs for stuff like this. Also, most of the changes in this patch need to get committed to trunk as well.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I wanted to give the community to see the chance to see the changes before they were committed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s what reviewboard and phabricator are for. Please reopen this ticket and follow the process described here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/HowToCommit&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/HowToCommit&lt;/a&gt; (Note that I updated this page a minute ago in order to reconcile it with the Hive Bylaws).&lt;/p&gt;
</comment>
                            <comment id="13652478" author="owen.omalley" created="Wed, 8 May 2013 22:56:51 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Not true. You need an explicit +1 from another committer, and we do usually file JIRAs for stuff like this.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The HowToRelease wiki for Hive (&lt;a href=&quot;https://cwiki.apache.org/Hive/howtorelease.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/Hive/howtorelease.html&lt;/a&gt;) about editing the release notes: &quot;It&apos;s OK to do this with a direct commit rather than a patch.&quot;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Also, most of the changes in this patch need to get committed to trunk as well.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You&apos;re right about that.&lt;/p&gt;</comment>
                            <comment id="13652484" author="cwsteinbach" created="Wed, 8 May 2013 23:04:19 +0000"  >&lt;blockquote&gt;&lt;p&gt;The HowToRelease wiki for Hive (&lt;a href=&quot;https://cwiki.apache.org/Hive/howtorelease.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/Hive/howtorelease.html&lt;/a&gt;) about editing the release notes: &quot;It&apos;s OK to do this with a direct commit rather than a patch.&quot;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Owen, which files did you edit in this patch?&lt;/p&gt;</comment>
                            <comment id="13652549" author="owen.omalley" created="Thu, 9 May 2013 00:08:09 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Owen, which files did you edit in this patch?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The change is in the attached patch obviously. If you want to generate it from git:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;% git show --numstat 5364dd83cd6a0adb5b31e3275888e2cbd7608ed4
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The result shows that:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;commit 5364dd83cd6a0adb5b31e3275888e2cbd7608ed4
Author: Owen O&apos;Malley &amp;lt;omalley@apache.org&amp;gt;
Date:   Tue May 7 15:09:18 2013 +0000

    HIVE-4508 Update release notes &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Hive 0.11.0.
    
    
    git-svn-id: https:&lt;span class=&quot;code-comment&quot;&gt;//svn.apache.org/repos/asf/hive/branches/branch-0.11@1479935 13f79535-47bb-03
&lt;/span&gt;
1       1       NOTICE
4       8       README.txt
18      61      RELEASE_NOTES.txt
1       1       build.properties
1       1       docs/xdocs/index.xml
1       1       eclipse-templates/.classpath
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;which are precisely the set of changes that you asked for in the email thread.&lt;/p&gt;</comment>
                            <comment id="13652599" author="cwsteinbach" created="Thu, 9 May 2013 00:49:33 +0000"  >&lt;p&gt;Here&apos;s what the HowToRelease page says:&lt;/p&gt;

&lt;blockquote&gt;
&lt;ol&gt;
	&lt;li&gt;You probably also want to commit a patch (on both trunk and branch) which updates README.txt to bring it up to date (at a minimum, search+replacing references to the version number). Also check NOTICE to see if anything needs to be updated for recent library dependency changes or additions.
	&lt;ol&gt;
		&lt;li&gt;Select all of the JIRA&apos;s for the current release that aren&apos;t FIXED and do bulk update to clear the &apos;Fixed Version&apos; field.&lt;/li&gt;
		&lt;li&gt;Likewise, use JIRA&apos;s Release Notes link to generate content for the RELEASE_NOTES.txt file. Be sure to select &apos;Text&apos; format. (It&apos;s OK to do this with a direct commit rather than a patch.)&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;The narrow interpretation of this is that you are only allowed to commit changes to RELEASE_NOTES.txt without a +1, and I believe that is the actual intent since those changes are purely mechanical. I can understand how someone could read this and conclude that the policy also extends to README.txt, NOTICE, and build.properties, but it&apos;s easy to verify that this isn&apos;t the case by looking at the comments in the commit log. That still leaves two files that were modified in the patch which aren&apos;t mentioned anywhere on the HowToRelease page.&lt;/p&gt;

&lt;p&gt;Can you please post a review request for this patch? I noticed a couple other issues in the affected files that should be fixed before this patch is forward-ported to trunk. Thanks.&lt;/p&gt;</comment>
                            <comment id="13652683" author="owen.omalley" created="Thu, 9 May 2013 02:26:12 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Can you please post a review request for this patch?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No, there is no need for me to push it into arc. Just review either the patch or browse it from git:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/hive/commit/5364dd83cd6a0adb5b31e3275888e2cbd7608ed4&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hive/commit/5364dd83cd6a0adb5b31e3275888e2cbd7608ed4&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Fixing the release notes is the only important part of the patch. You requested a bunch of changes and I did the work. I don&apos;t understand why you are being so argumentative about work that you requested.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I noticed a couple other issues in the affected files that should be fixed before this patch is forward-ported to trunk&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Please file a new jira and include a patch. I&apos;ll review it promptly.&lt;/p&gt;</comment>
                            <comment id="13653081" author="cwsteinbach" created="Thu, 9 May 2013 19:31:41 +0000"  >&lt;p&gt;Review request: &lt;a href=&quot;https://reviews.apache.org/r/11030/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11030/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13654391" author="lefty@hortonworks.com" created="Fri, 10 May 2013 11:48:58 +0000"  >&lt;p&gt;Changes to docs/xdocs/index.xml won&apos;t have any effect, because the xdocs are dead (long live the wiki). The information is duplicated, more or less, on the wiki home page and in the tutorial.&lt;/p&gt;

&lt;p&gt;If you want to add the same information to the API docs, put an html file in an appropriate location such as ./docs/overview.html, and add a line to the javadoc target in build.xml, like so:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;lt;target name=&quot;javadoc&quot; depends=&quot;package&quot; description=&quot;Generate Javadoc&quot;&amp;gt;&lt;br/&gt;
&amp;lt;echo message=&quot;Project: ${ant.project.name}&quot;/&amp;gt;&lt;br/&gt;
&amp;lt;mkdir dir=&quot;${build.javadoc}&quot;/&amp;gt;&lt;br/&gt;
&amp;lt;javadoc&lt;br/&gt;
&lt;font color=&quot;red&quot;&gt;overview=&quot;${basedir}/docs/overview.html&quot;&lt;/font&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;... but without the backslashes that you&apos;ll probably see in email. I created an overview.html file including Carl&apos;s suggestions and a few editorial fixes (attached) so you just have to put it in ./docs and add the overview line to build.xml.&lt;/p&gt;
</comment>
                            <comment id="13654394" author="lefty@hortonworks.com" created="Fri, 10 May 2013 11:51:50 +0000"  >&lt;p&gt;Attaching an overview.html file that can be included in the API docs.&lt;/p&gt;</comment>
                            <comment id="13654656" author="owen.omalley" created="Fri, 10 May 2013 17:48:06 +0000"  >&lt;p&gt;I&apos;m splitting up this work into separate parts and will do the release notes separately.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12646755">HIVE-4527</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12581941" name="h-4508.patch" size="24657" author="owen.omalley" created="Mon, 6 May 2013 19:47:16 +0000"/>
                            <attachment id="12581923" name="h-4508.patch" size="24202" author="owen.omalley" created="Mon, 6 May 2013 18:25:00 +0000"/>
                            <attachment id="12582605" name="overview.html" size="4331" author="leftylev" created="Fri, 10 May 2013 11:51:50 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 6 May 2013 18:09:10 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326598</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 37 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kcev:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326943</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-4509] Integer division should be cast to double. </title>
                <link>https://issues.apache.org/jira/browse/HIVE-4509</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;In current hive, the division always returns a double. Also, division by zero returns infinity following java semantics.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646285">HIVE-4509</key>
            <summary>Integer division should be cast to double. </summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jnp">Jitendra Nath Pandey</assignee>
                                    <reporter username="jnp">Jitendra Nath Pandey</reporter>
                        <labels>
                    </labels>
                <created>Mon, 6 May 2013 20:23:30 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:20 +0000</updated>
                            <resolved>Sun, 12 May 2013 18:55:05 +0000</resolved>
                                    <version>vectorization-branch</version>
                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13655507" author="jnp" created="Sun, 12 May 2013 10:25:08 +0000"  >&lt;p&gt;Patch uploaded.&lt;br/&gt;
Review board entry: &lt;a href=&quot;https://reviews.apache.org/r/11075/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11075/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13655607" author="ashutoshc" created="Sun, 12 May 2013 18:55:05 +0000"  >&lt;p&gt;Committed to branch. Thanks, Jitendra!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12582833" name="HIVE-4509.1.patch" size="44683" author="jnp" created="Sun, 12 May 2013 10:18:03 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 12 May 2013 18:55:05 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326643</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 37 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kcov:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326988</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4510] HS2 doesn&apos;t nest exceptions properly (fun debug times)</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4510</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;In SQLOperation.java lines 97 + 113 for instance, we catch errors and throw a new HiveSQLException, but we don&apos;t wrap the original exception.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646304">HIVE-4510</key>
            <summary>HS2 doesn&apos;t nest exceptions properly (fun debug times)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="thejas">Thejas M Nair</assignee>
                                    <reporter username="hagleitn">Gunther Hagleitner</reporter>
                        <labels>
                    </labels>
                <created>Mon, 6 May 2013 21:50:55 +0000</created>
                <updated>Tue, 15 Oct 2013 23:28:55 +0000</updated>
                            <resolved>Sun, 2 Jun 2013 16:53:41 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                    <component>HiveServer2</component>
                    <component>JDBC</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13650342" author="thejas" created="Tue, 7 May 2013 01:18:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4510&quot; title=&quot;HS2 doesn&amp;#39;t nest exceptions properly (fun debug times)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4510&quot;&gt;&lt;del&gt;HIVE-4510&lt;/del&gt;&lt;/a&gt;.1.patch - Chains exception in SQLOperation and HS2 jdbc code.  Also adds exception details as part of Driver response object error string.&lt;/p&gt;</comment>
                            <comment id="13650350" author="cwsteinbach" created="Tue, 7 May 2013 01:29:17 +0000"  >&lt;p&gt;The same problem occurs in HiveCommandOperation.java, line 113.&lt;/p&gt;</comment>
                            <comment id="13651021" author="thejas" created="Tue, 7 May 2013 16:29:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4510&quot; title=&quot;HS2 doesn&amp;#39;t nest exceptions properly (fun debug times)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4510&quot;&gt;&lt;del&gt;HIVE-4510&lt;/del&gt;&lt;/a&gt;.2.patch- Making change for HiveCommandOperation as well.&lt;/p&gt;</comment>
                            <comment id="13651024" author="thejas" created="Tue, 7 May 2013 16:30:06 +0000"  >&lt;p&gt;Review board link - &lt;a href=&quot;https://reviews.apache.org/r/10977/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/10977/&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cwsteinbach&quot; class=&quot;user-hover&quot; rel=&quot;cwsteinbach&quot;&gt;Carl Steinbach&lt;/a&gt; This includes the changes to HiveCommandOperation&lt;/p&gt;</comment>
                            <comment id="13651151" author="cwsteinbach" created="Tue, 7 May 2013 18:32:09 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13651178" author="cwsteinbach" created="Tue, 7 May 2013 18:53:41 +0000"  >&lt;p&gt;I will commit this if someone else runs the tests and gives me a green light. Thanks.&lt;/p&gt;</comment>
                            <comment id="13656302" author="thejas" created="Mon, 13 May 2013 20:10:00 +0000"  >&lt;p&gt;I am running the full hive unit test suite on this patch. I will update when it is done.&lt;/p&gt;</comment>
                            <comment id="13661228" author="thejas" created="Sat, 18 May 2013 02:09:16 +0000"  >&lt;p&gt;I ran the full unit test suite, and it passed. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cwsteinbach&quot; class=&quot;user-hover&quot; rel=&quot;cwsteinbach&quot;&gt;Carl Steinbach&lt;/a&gt; can you please commit ?&lt;/p&gt;</comment>
                            <comment id="13661229" author="thejas" created="Sat, 18 May 2013 02:11:44 +0000"  >&lt;p&gt;Should we commit this to 0.11 branch as well? It really helps debug problems, and it is a unlikely to cause stability issues.&lt;/p&gt;</comment>
                            <comment id="13672595" author="ashutoshc" created="Sun, 2 Jun 2013 16:53:41 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Thejas!&lt;/p&gt;</comment>
                            <comment id="13673608" author="hudson" created="Mon, 3 Jun 2013 21:32:37 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #223 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/223/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/223/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4510&quot; title=&quot;HS2 doesn&amp;#39;t nest exceptions properly (fun debug times)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4510&quot;&gt;&lt;del&gt;HIVE-4510&lt;/del&gt;&lt;/a&gt; : HS2 doesn&apos;t nest exceptions properly (fun debug times) (Thejas Nair via Ashutosh Chauhan) (Revision 1488740)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1488740&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1488740&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveBaseResultSet.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/operation/HiveCommandOperation.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13674012" author="hudson" created="Tue, 4 Jun 2013 04:08:09 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2126 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2126/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2126/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4510&quot; title=&quot;HS2 doesn&amp;#39;t nest exceptions properly (fun debug times)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4510&quot;&gt;&lt;del&gt;HIVE-4510&lt;/del&gt;&lt;/a&gt; : HS2 doesn&apos;t nest exceptions properly (fun debug times) (Thejas Nair via Ashutosh Chauhan) (Revision 1488740)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1488740&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1488740&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveBaseResultSet.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/operation/HiveCommandOperation.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13795826" author="ashutoshc" created="Tue, 15 Oct 2013 23:28:55 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12582018" name="HIVE-4510.1.patch" size="11039" author="thejas" created="Tue, 7 May 2013 01:18:47 +0000"/>
                            <attachment id="12582115" name="HIVE-4510.2.patch" size="12188" author="thejas" created="Tue, 7 May 2013 16:29:13 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 7 May 2013 01:18:47 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326662</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kct3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>327007</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4511] Vectorized reader support for Byte Boolean and Timestamp.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4511</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Byte, boolean and timestamp support should be added to vectorized orc reader.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646312">HIVE-4511</key>
            <summary>Vectorized reader support for Byte Boolean and Timestamp.</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sarvesh.sn">Sarvesh Sakalanaga</assignee>
                                    <reporter username="jnp">Jitendra Nath Pandey</reporter>
                        <labels>
                    </labels>
                <created>Mon, 6 May 2013 22:10:32 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:21 +0000</updated>
                            <resolved>Thu, 30 May 2013 15:07:38 +0000</resolved>
                                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                    <component>File Formats</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13665545" author="sarvesh.sn" created="Thu, 23 May 2013 19:43:32 +0000"  >&lt;p&gt;Patch available.&lt;/p&gt;</comment>
                            <comment id="13665550" author="sarvesh.sn" created="Thu, 23 May 2013 19:47:50 +0000"  >&lt;p&gt;Review at : &lt;a href=&quot;https://reviews.apache.org/r/11350/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11350/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13669916" author="sarvesh.sn" created="Thu, 30 May 2013 00:22:56 +0000"  >&lt;p&gt;Added unit tests and Timestamp support.&lt;/p&gt;</comment>
                            <comment id="13670393" author="owen.omalley" created="Thu, 30 May 2013 15:07:38 +0000"  >&lt;p&gt;I just committed this to the vectorization branch. Thanks, Sarvesh!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12584561" name="Hive-4511.0.patch" size="12051" author="sarvesh.sn" created="Thu, 23 May 2013 19:43:32 +0000"/>
                            <attachment id="12585341" name="Hive-4511.1.patch" size="28484" author="sarvesh.sn" created="Thu, 30 May 2013 00:22:56 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 23 May 2013 19:43:32 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326670</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 34 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kcuv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>327015</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4512] The vectorized plan is not picking right expression class for string concatenation.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4512</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The vectorized plan is not picking right expression class for string concatenation.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646326">HIVE-4512</key>
            <summary>The vectorized plan is not picking right expression class for string concatenation.</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ehans">Eric Hanson</assignee>
                                    <reporter username="jnp">Jitendra Nath Pandey</reporter>
                        <labels>
                    </labels>
                <created>Mon, 6 May 2013 23:23:59 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:11 +0000</updated>
                            <resolved>Fri, 20 Sep 2013 17:14:16 +0000</resolved>
                                    <version>vectorization-branch</version>
                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="13717875" author="ehans" created="Wed, 24 Jul 2013 01:32:51 +0000"  >&lt;p&gt;Implemented support in VectorizationContext.java for concat(col, scalar). Still need to finish scalar-col and col-col support.&lt;/p&gt;</comment>
                            <comment id="13718945" author="ehans" created="Wed, 24 Jul 2013 22:34:40 +0000"  >&lt;p&gt;Code review available at:  &lt;a href=&quot;https://reviews.apache.org/r/12926/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/12926/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13719378" author="hiveqa" created="Thu, 25 Jul 2013 08:23:45 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12594047/HIVE-4512.1-vectorization.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12594047/HIVE-4512.1-vectorization.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 2 failed/errored test(s), 3410 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_bucket_num_reducers
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_view_cast
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/177/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/177/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/177/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/177/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.CleanupPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 2 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13720945" author="hiveqa" created="Fri, 26 Jul 2013 16:43:25 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12594218/HIVE-4512.2-vectorization.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12594218/HIVE-4512.2-vectorization.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/193/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/193/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/193/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/193/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.CleanupPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Tests failed with: IllegalStateException: Too many bad hosts: 0.6% (6 / 10) is greater than threshold of 50%
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13768628" author="ehans" created="Mon, 16 Sep 2013 19:02:58 +0000"  >&lt;p&gt;Based patch off the latest vectorization branch&lt;/p&gt;</comment>
                            <comment id="13769053" author="hiveqa" created="Tue, 17 Sep 2013 01:08:18 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12603399/HIVE-4512.3-vectorization.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12603399/HIVE-4512.3-vectorization.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 17 failed/errored test(s), 3951 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_input4
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_plan_json
org.apache.hadoop.hive.ql.io.orc.TestFileDump.testDictionaryThreshold
org.apache.hadoop.hive.ql.io.orc.TestFileDump.testDump
org.apache.hcatalog.api.TestHCatClient.testBasicDDLCommands
org.apache.hcatalog.api.TestHCatClient.testPartitionsHCatClientImpl
org.apache.hive.hcatalog.api.TestHCatClient.testBasicDDLCommands
org.apache.hive.hcatalog.api.TestHCatClient.testDatabaseLocation
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSchema
org.apache.hive.hcatalog.api.TestHCatClient.testPartitionsHCatClientImpl
org.apache.hive.hcatalog.fileformats.TestOrcDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask
org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatDynamicPartitionedTable
org.apache.hive.hcatalog.mapreduce.TestHCatExternalDynamicPartitioned.testHCatDynamicPartitionedTableMultipleTask
org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned.testHCatPartitionedTable
org.apache.hive.hcatalog.pig.TestHCatLoader.testGetInputBytes
org.apache.hive.hcatalog.pig.TestHCatLoader.testProjectionsBasic
org.apache.hive.hcatalog.pig.TestHCatLoader.testReadPartitionedBasic
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/768/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/768/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/768/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/768/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 17 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13769820" author="ehans" created="Tue, 17 Sep 2013 18:59:30 +0000"  >&lt;p&gt;These test failures are not related to this patch. See the discussion in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4961&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-4961&lt;/a&gt;. That applies here too.&lt;/p&gt;</comment>
                            <comment id="13770186" author="ehans" created="Tue, 17 Sep 2013 23:56:47 +0000"  >&lt;p&gt;I&apos;m re-basing the patch on the latest changes. Stay tuned.&lt;/p&gt;</comment>
                            <comment id="13770237" author="ehans" created="Wed, 18 Sep 2013 00:40:20 +0000"  >&lt;p&gt;Rebased patch off most recent changes to add vectorized UDF adaptor (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4961&quot; title=&quot;Create bridge for custom UDFs to operate in vectorized mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4961&quot;&gt;&lt;del&gt;HIVE-4961&lt;/del&gt;&lt;/a&gt;). Also updated Vectorizer to reference Concat class and tested Concat function in end-to-end query runs. Re-ran junit tests for concat and they pass.&lt;/p&gt;</comment>
                            <comment id="13773180" author="ehans" created="Fri, 20 Sep 2013 16:58:49 +0000"  >&lt;p&gt;Re-based patch after yesterday&apos;s merge from trunk to vectorization branch. Ran vectorized string function tests and ad-hoc end-to-end tests to verify operation of concat in vectorized mode.&lt;/p&gt;</comment>
                            <comment id="13773195" author="ashutoshc" created="Fri, 20 Sep 2013 17:14:16 +0000"  >&lt;p&gt;Committed to branch. Thanks, Eric!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12594047" name="HIVE-4512.1-vectorization.patch" size="7843" author="ehans" created="Wed, 24 Jul 2013 22:23:26 +0000"/>
                            <attachment id="12594218" name="HIVE-4512.2-vectorization.patch" size="7843" author="ehans" created="Thu, 25 Jul 2013 18:11:45 +0000"/>
                            <attachment id="12603399" name="HIVE-4512.3-vectorization.patch" size="7819" author="ehans" created="Mon, 16 Sep 2013 19:02:58 +0000"/>
                            <attachment id="12603728" name="HIVE-4512.4-vectorization.patch" size="8786" author="ehans" created="Wed, 18 Sep 2013 00:40:20 +0000"/>
                            <attachment id="12604267" name="HIVE-4512.5-vectorization.patch" size="9068" author="ehans" created="Fri, 20 Sep 2013 16:58:49 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 24 Jul 2013 01:32:51 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326684</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 18 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kcxr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>327029</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4513] disable hivehistory logs by default</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4513</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;HiveHistory log files (hive_job_log_hive_*.txt files) store information about hive query such as query string, plan , counters and MR job progress information.&lt;/p&gt;

&lt;p&gt;There is no mechanism to delete these files and as a result they get accumulated over time, using up lot of disk space. &lt;br/&gt;
I don&apos;t think this is used by most people, so I think it would better to turn this off by default. Jobtracker logs already capture most of this information, though it is not as structured as history logs.&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12646330">HIVE-4513</key>
            <summary>disable hivehistory logs by default</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="thejas">Thejas M Nair</assignee>
                                    <reporter username="thejas">Thejas M Nair</reporter>
                        <labels>
                            <label>TODOC12</label>
                    </labels>
                <created>Mon, 6 May 2013 23:39:02 +0000</created>
                <updated>Tue, 24 Jun 2014 07:54:05 +0000</updated>
                            <resolved>Tue, 13 Aug 2013 11:58:13 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                    <component>Configuration</component>
                    <component>Logging</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>10</watches>
                                                                <comments>
                            <comment id="13650235" author="thejas" created="Mon, 6 May 2013 23:39:58 +0000"  >&lt;p&gt;Blocked by &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4500&quot; title=&quot;HS2 holding too many file handles of hive_job_log_hive_*.txt files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4500&quot;&gt;&lt;del&gt;HIVE-4500&lt;/del&gt;&lt;/a&gt; as it relies on config parameter being introduced in that patch.&lt;/p&gt;</comment>
                            <comment id="13650245" author="thejas" created="Mon, 6 May 2013 23:44:30 +0000"  >&lt;p&gt;Having this on by default can cause problems if you have same machine and config being used for large number of queries. For example, while doing some stress tests on HiveServer2, the mount with /tmp became full because hive history files (around 20k of them) took 2.5 GB.&lt;/p&gt;</comment>
                            <comment id="13651562" author="thejas" created="Wed, 8 May 2013 02:21:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4513&quot; title=&quot;disable hivehistory logs by default&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4513&quot;&gt;&lt;del&gt;HIVE-4513&lt;/del&gt;&lt;/a&gt;.1.patch - Uses a proxy class that makes HiveHistory no-op, if hive history is disabled.&lt;/p&gt;</comment>
                            <comment id="13653041" author="thejas" created="Thu, 9 May 2013 16:19:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4513&quot; title=&quot;disable hivehistory logs by default&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4513&quot;&gt;&lt;del&gt;HIVE-4513&lt;/del&gt;&lt;/a&gt;.2.patch - &lt;br/&gt;
SessionState temp file gets created in same dir as hive history dir, but it was relying on hivehistory to create that dir. Now it independently does a -create-if-not-exist.&lt;/p&gt;</comment>
                            <comment id="13653047" author="thejas" created="Thu, 9 May 2013 16:28:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4513&quot; title=&quot;disable hivehistory logs by default&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4513&quot;&gt;&lt;del&gt;HIVE-4513&lt;/del&gt;&lt;/a&gt;.3.patch - additional comments&lt;/p&gt;</comment>
                            <comment id="13653050" author="thejas" created="Thu, 9 May 2013 16:30:47 +0000"  >&lt;p&gt;review board link with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4513&quot; title=&quot;disable hivehistory logs by default&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4513&quot;&gt;&lt;del&gt;HIVE-4513&lt;/del&gt;&lt;/a&gt;.3.patch - &lt;a href=&quot;https://reviews.apache.org/r/11029/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/11029/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13656430" author="thejas" created="Mon, 13 May 2013 21:50:44 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4513&quot; title=&quot;disable hivehistory logs by default&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4513&quot;&gt;&lt;del&gt;HIVE-4513&lt;/del&gt;&lt;/a&gt;.4.patch &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;add @Override to interface functions being implemented in HiveHistoryImpl&lt;/li&gt;
	&lt;li&gt;Removing javadoc duplication in HiveHistoryImpl. It will automatically inherit the documentation from interface.&lt;/li&gt;
	&lt;li&gt;Logging the exception in code unrelated to patch, to partly address Brock&apos;s concern. Since the code is not part of the patch, I don&apos;t want to increase the scope to address that concern.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13673559" author="ashutoshc" created="Mon, 3 Jun 2013 21:04:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt; Left some comments on RB.&lt;/p&gt;</comment>
                            <comment id="13673566" author="ashutoshc" created="Mon, 3 Jun 2013 21:06:20 +0000"  >&lt;p&gt;Canceling patch for now.&lt;/p&gt;</comment>
                            <comment id="13733021" author="thiruvel" created="Thu, 8 Aug 2013 01:08:42 +0000"  >&lt;p&gt;Hi Thejas, are you working on this patch?&lt;/p&gt;</comment>
                            <comment id="13733050" author="thejas" created="Thu, 8 Aug 2013 01:50:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thiruvel&quot; class=&quot;user-hover&quot; rel=&quot;thiruvel&quot;&gt;Thiruvel Thirumoolan&lt;/a&gt; Interesting that you asked me today, I am working on it right now! &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13734355" author="thejas" created="Fri, 9 Aug 2013 03:04:23 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4513&quot; title=&quot;disable hivehistory logs by default&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4513&quot;&gt;&lt;del&gt;HIVE-4513&lt;/del&gt;&lt;/a&gt;.5.patch - patch addressing review comments. &lt;br/&gt;
Also, removed use of hive history from TestCliDriver.vm and TestHBaseCliDriver.vm as it does not get used. When there is a failure that gets logged in hive history, it also results in client exit code being non zero. So the use of hivehistory there is redundant.  &lt;/p&gt;

&lt;p&gt;I will upload the updated patch to reviewboard once it is up again.&lt;/p&gt;</comment>
                            <comment id="13734356" author="appodictic" created="Fri, 9 Aug 2013 03:08:35 +0000"  >&lt;p&gt;+1 I never found them of much use.&lt;/p&gt;</comment>
                            <comment id="13734714" author="hiveqa" created="Fri, 9 Aug 2013 12:20:42 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12597018/HIVE-4513.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12597018/HIVE-4513.5.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 2775 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.service.TestHiveServerSessions.testSessionVars
org.apache.hcatalog.mapreduce.TestSequenceFileReadWrite.testSequenceTableWriteReadMR
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_infer_bucket_sort_bucketed_table
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_script_broken_pipe1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/359/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/359/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/359/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/359/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13735961" author="thejas" created="Sat, 10 Aug 2013 16:28:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4513&quot; title=&quot;disable hivehistory logs by default&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4513&quot;&gt;&lt;del&gt;HIVE-4513&lt;/del&gt;&lt;/a&gt;.6.patch - addresses review comments. &lt;/p&gt;

&lt;p&gt;Also fixes race condition the race condition that was causing the TestHiveServerSessions.testSessionVars test failure. This race condition gets exposed when hivehistory is disabled, because when hive history is enabled it attempts to create the same dir this way, but on failure it just logs a warning.&lt;/p&gt;</comment>
                            <comment id="13735964" author="thejas" created="Sat, 10 Aug 2013 16:36:14 +0000"  >&lt;p&gt;I found another issue while making these changes, - SessionState temp file gets created in history file directory, created  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5055&quot; title=&quot;SessionState temp file gets created in history file directory&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5055&quot;&gt;&lt;del&gt;HIVE-5055&lt;/del&gt;&lt;/a&gt; to track that.&lt;/p&gt;</comment>
                            <comment id="13736022" author="hiveqa" created="Sat, 10 Aug 2013 20:28:27 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12597289/HIVE-4513.6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12597289/HIVE-4513.6.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 2776 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testNegativeCliDriver_mapreduce_stack_trace_hadoop20
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/385/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/385/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/385/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/385/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13736661" author="thejas" created="Mon, 12 Aug 2013 07:31:14 +0000"  >&lt;p&gt;Regarding the pre-commit test result, testNegativeCliDriver_mapreduce_stack_trace_hadoop20 is a flaky test tracked in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4851&quot; title=&quot;Fix flaky tests&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4851&quot;&gt;&lt;del&gt;HIVE-4851&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
Reviewboard has the latest patch.&lt;/p&gt;</comment>
                            <comment id="13737535" author="ashutoshc" created="Mon, 12 Aug 2013 23:35:30 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13737711" author="thiruvel" created="Tue, 13 Aug 2013 01:59:03 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thejas&quot; class=&quot;user-hover&quot; rel=&quot;thejas&quot;&gt;Thejas M Nair&lt;/a&gt;. +1. I guess we can close the duplicates &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1708&quot; title=&quot;make hive history file configurable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1708&quot;&gt;&lt;del&gt;HIVE-1708&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3779&quot; title=&quot;An empty value to hive.logquery.location can&amp;#39;t disable the creation of hive history log files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3779&quot;&gt;&lt;del&gt;HIVE-3779&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We back-ported this to Hive10 and it works as expected. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cdrome&quot; class=&quot;user-hover&quot; rel=&quot;cdrome&quot;&gt;Chris Drome&lt;/a&gt; had some comments on the patch. These fall in the vicinity but should be addressed as a separate JIRA.&lt;/p&gt;

&lt;p&gt;1. HiveHistoryViewer.java: Its good as &quot;private void init()&quot;&lt;br/&gt;
2. HiveHistoryUtil.java: parseLine() method is not thread-safe. It uses parseBuffer which could be modified by multiple threads. Currently only HWA uses it.&lt;/p&gt;</comment>
                            <comment id="13737720" author="thiruvel" created="Tue, 13 Aug 2013 02:03:24 +0000"  >&lt;p&gt;&amp;gt; Chris Drome had some comments on the patch. These fall in the vicinity but should be addressed as a separate JIRA.&lt;/p&gt;

&lt;p&gt;Created &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5071&quot; title=&quot;Address thread safety issues with HiveHistoryUtil&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5071&quot;&gt;&lt;del&gt;HIVE-5071&lt;/del&gt;&lt;/a&gt; to address thread safety issues.&lt;/p&gt;</comment>
                            <comment id="13737922" author="thejas" created="Tue, 13 Aug 2013 06:49:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thiruvel&quot; class=&quot;user-hover&quot; rel=&quot;thiruvel&quot;&gt;Thiruvel Thirumoolan&lt;/a&gt; Thanks for the feedback and pointers to the duplicate jiras. Yes, I think it is better to address thread safety issue in another jira, as it is not a regression introduced by this patch, the issue was there when the function was in HiveHistory.java (but I should have noticed the bug!)&lt;/p&gt;
</comment>
                            <comment id="13737972" author="hiveqa" created="Tue, 13 Aug 2013 08:25:43 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12597289/HIVE-4513.6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12597289/HIVE-4513.6.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 2850 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/412/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/412/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/412/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/412/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13738115" author="ashutoshc" created="Tue, 13 Aug 2013 11:58:13 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Thejas!&lt;/p&gt;</comment>
                            <comment id="13738440" author="hudson" created="Tue, 13 Aug 2013 16:29:07 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-h0.21 #2265 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2265/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2265/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4513&quot; title=&quot;disable hivehistory logs by default&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4513&quot;&gt;&lt;del&gt;HIVE-4513&lt;/del&gt;&lt;/a&gt; : disable hivehistory logs by default (Thejas Nair via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1513445&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1513445&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/templates/TestHBaseCliDriver.vm&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistoryImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistoryProxyHandler.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistoryUtil.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistoryViewer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/history/TestHiveHistory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/templates/TestCliDriver.vm&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13738442" author="hudson" created="Tue, 13 Aug 2013 16:29:08 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2 #356 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/356/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/356/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4513&quot; title=&quot;disable hivehistory logs by default&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4513&quot;&gt;&lt;del&gt;HIVE-4513&lt;/del&gt;&lt;/a&gt; : disable hivehistory logs by default (Thejas Nair via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1513445&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1513445&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/templates/TestHBaseCliDriver.vm&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistoryImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistoryProxyHandler.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistoryUtil.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistoryViewer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/history/TestHiveHistory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/templates/TestCliDriver.vm&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13738447" author="hudson" created="Tue, 13 Aug 2013 16:29:09 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2-ptest #56 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/56/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/56/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4513&quot; title=&quot;disable hivehistory logs by default&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4513&quot;&gt;&lt;del&gt;HIVE-4513&lt;/del&gt;&lt;/a&gt; : disable hivehistory logs by default (Thejas Nair via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1513445&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1513445&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/templates/TestHBaseCliDriver.vm&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistoryImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistoryProxyHandler.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistoryUtil.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistoryViewer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/history/TestHiveHistory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/templates/TestCliDriver.vm&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13738636" author="hudson" created="Tue, 13 Aug 2013 18:37:01 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop1-ptest #126 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/126/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/126/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4513&quot; title=&quot;disable hivehistory logs by default&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4513&quot;&gt;&lt;del&gt;HIVE-4513&lt;/del&gt;&lt;/a&gt; : disable hivehistory logs by default (Thejas Nair via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1513445&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1513445&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/conf/hive-default.xml.template&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/templates/TestHBaseCliDriver.vm&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistoryImpl.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistoryProxyHandler.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistoryUtil.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/history/HiveHistoryViewer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/history/TestHiveHistory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/templates/TestCliDriver.vm&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13796115" author="ashutoshc" created="Tue, 15 Oct 2013 23:31:04 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                            <comment id="14041834" author="lefty@hortonworks.com" created="Tue, 24 Jun 2014 07:54:05 +0000"  >&lt;p&gt;This adds the configuration parameter &lt;b&gt;hive.session.history.enabled&lt;/b&gt; in HiveConf.java and hive-default.xml.template, so it needs to be documented in the wiki here:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Hive Configuration Properties &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12646139">HIVE-4500</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12622878">HIVE-3779</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12477261">HIVE-1708</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12643068">HIVE-4374</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12582241" name="HIVE-4513.1.patch" size="37620" author="thejas" created="Wed, 8 May 2013 02:21:04 +0000"/>
                            <attachment id="12582488" name="HIVE-4513.2.patch" size="38801" author="thejas" created="Thu, 9 May 2013 16:19:41 +0000"/>
                            <attachment id="12582489" name="HIVE-4513.3.patch" size="38824" author="thejas" created="Thu, 9 May 2013 16:28:27 +0000"/>
                            <attachment id="12583012" name="HIVE-4513.4.patch" size="38887" author="thejas" created="Mon, 13 May 2013 21:50:44 +0000"/>
                            <attachment id="12597018" name="HIVE-4513.5.patch" size="43414" author="thejas" created="Fri, 9 Aug 2013 03:04:23 +0000"/>
                            <attachment id="12597289" name="HIVE-4513.6.patch" size="43675" author="thejas" created="Sat, 10 Aug 2013 16:28:36 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 3 Jun 2013 21:04:01 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326688</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 30 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kcyn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>327033</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4514] Handle constants in projection</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4514</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Support for constants in the projections is required.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646331">HIVE-4514</key>
            <summary>Handle constants in projection</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21146&amp;avatarType=issuetype">Sub-task</type>
                            <parent id="12636846">HIVE-4160</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jnp">Jitendra Nath Pandey</assignee>
                                    <reporter username="jnp">Jitendra Nath Pandey</reporter>
                        <labels>
                    </labels>
                <created>Mon, 6 May 2013 23:47:36 +0000</created>
                <updated>Wed, 23 Oct 2013 21:59:15 +0000</updated>
                            <resolved>Fri, 10 May 2013 08:20:43 +0000</resolved>
                                                    <fixVersion>vectorization-branch</fixVersion>
                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13653631" author="ashutoshc" created="Fri, 10 May 2013 08:20:43 +0000"  >&lt;p&gt;Committed to branch. Thanks, Jitendra!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12582582" name="HIVE-4514.1.patch" size="16620" author="jnp" created="Fri, 10 May 2013 06:14:27 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 10 May 2013 08:20:43 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326689</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 37 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kcyv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>327034</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4515] &quot;select count(*) from table&quot; query on hive-0.10.0, hbase-0.94.7 integration throws exceptions</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4515</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;After integration hive-0.10.0+hbase-0.94.7, these commands could be executed successfully:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;create table
insert overwrite table
select * from table

However, when execute &quot;select count(*) from table&quot;, throws exception:
hive&amp;gt; select count(*) from test;         
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=&amp;lt;number&amp;gt;
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=&amp;lt;number&amp;gt;
In order to set a constant number of reducers:
  set mapred.reduce.tasks=&amp;lt;number&amp;gt;
Starting Job = job_201305061042_0028, Tracking URL = http://master0:50030/jobdetails.jsp?jobid=job_201305061042_0028
Kill Command = /opt/modules/hadoop/hadoop-1.0.4/libexec/../bin/hadoop job  -kill job_201305061042_0028
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2013-05-07 18:41:42,649 Stage-1 map = 0%,  reduce = 0%
2013-05-07 18:42:14,789 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201305061042_0028 with errors
Error during job, obtaining debugging information...
Job Tracking URL: http://master0:50030/jobdetails.jsp?jobid=job_201305061042_0028
Examining task ID: task_201305061042_0028_m_000002 (and more) from job job_201305061042_0028

Task with the most failures(4): 
-----
Task ID:
  task_201305061042_0028_m_000000

URL:
  http://master0:50030/taskdetails.jsp?jobid=job_201305061042_0028&amp;amp;tipid=task_201305061042_0028_m_000000
-----
Diagnostic Messages for this Task:
java.lang.NegativeArraySizeException: -1
	at org.apache.hadoop.hbase.util.Bytes.readByteArray(Bytes.java:148)
	at org.apache.hadoop.hbase.mapreduce.TableSplit.readFields(TableSplit.java:133)
	at org.apache.hadoop.hive.hbase.HBaseSplit.readFields(HBaseSplit.java:53)
	at org.apache.hadoop.hive.ql.io.HiveInputFormat$HiveInputSplit.readFields(HiveInputFormat.java:150)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:67)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:40)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:396)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:412)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:255)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.mapred.Child.main(Child.java:249)


FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTask
MapReduce Jobs Launched: 
Job 0: Map: 1  Reduce: 1   HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec

==================================================================
The log of tasktracker:

stderr logs

13/05/07 18:43:20 INFO util.NativeCodeLoader: Loaded the native-hadoop library
13/05/07 18:43:20 INFO mapred.TaskRunner: Creating symlink: /tmp/hadoop-hadoop/mapred/local/taskTracker/distcache/1073284782955556390_-1298160740_2123690974/master0/tmp/hive-hadoop/hive_2013-05-07_18-41-30_290_832140779606816147/-mr-10003/fd22448b-e923-498c-bc00-2164ca68447d &amp;lt;- /tmp/hadoop-hadoop/mapred/local/taskTracker/hadoop/jobcache/job_201305061042_0028/attempt_201305061042_0028_m_000000_0/work/HIVE_PLANfd22448b-e923-498c-bc00-2164ca68447d
13/05/07 18:43:20 INFO filecache.TrackerDistributedCacheManager: Creating symlink: /tmp/hadoop-hadoop/mapred/local/taskTracker/hadoop/jobcache/job_201305061042_0028/jars/javolution &amp;lt;- /tmp/hadoop-hadoop/mapred/local/taskTracker/hadoop/jobcache/job_201305061042_0028/attempt_201305061042_0028_m_000000_0/work/javolution
13/05/07 18:43:20 INFO filecache.TrackerDistributedCacheManager: Creating symlink: /tmp/hadoop-hadoop/mapred/local/taskTracker/hadoop/jobcache/job_201305061042_0028/jars/org &amp;lt;- /tmp/hadoop-hadoop/mapred/local/taskTracker/hadoop/jobcache/job_201305061042_0028/attempt_201305061042_0028_m_000000_0/work/org
13/05/07 18:43:20 INFO filecache.TrackerDistributedCacheManager: Creating symlink: /tmp/hadoop-hadoop/mapred/local/taskTracker/hadoop/jobcache/job_201305061042_0028/jars/hive-exec-log4j.properties &amp;lt;- /tmp/hadoop-hadoop/mapred/local/taskTracker/hadoop/jobcache/job_201305061042_0028/attempt_201305061042_0028_m_000000_0/work/hive-exec-log4j.properties
13/05/07 18:43:20 INFO filecache.TrackerDistributedCacheManager: Creating symlink: /tmp/hadoop-hadoop/mapred/local/taskTracker/hadoop/jobcache/job_201305061042_0028/jars/META-INF &amp;lt;- /tmp/hadoop-hadoop/mapred/local/taskTracker/hadoop/jobcache/job_201305061042_0028/attempt_201305061042_0028_m_000000_0/work/META-INF
13/05/07 18:43:20 INFO filecache.TrackerDistributedCacheManager: Creating symlink: /tmp/hadoop-hadoop/mapred/local/taskTracker/hadoop/jobcache/job_201305061042_0028/jars/.job.jar.crc &amp;lt;- /tmp/hadoop-hadoop/mapred/local/taskTracker/hadoop/jobcache/job_201305061042_0028/attempt_201305061042_0028_m_000000_0/work/.job.jar.crc
13/05/07 18:43:20 INFO filecache.TrackerDistributedCacheManager: Creating symlink: /tmp/hadoop-hadoop/mapred/local/taskTracker/hadoop/jobcache/job_201305061042_0028/jars/job.jar &amp;lt;- /tmp/hadoop-hadoop/mapred/local/taskTracker/hadoop/jobcache/job_201305061042_0028/attempt_201305061042_0028_m_000000_0/work/job.jar
13/05/07 18:43:20 INFO filecache.TrackerDistributedCacheManager: Creating symlink: /tmp/hadoop-hadoop/mapred/local/taskTracker/hadoop/jobcache/job_201305061042_0028/jars/javax &amp;lt;- /tmp/hadoop-hadoop/mapred/local/taskTracker/hadoop/jobcache/job_201305061042_0028/attempt_201305061042_0028_m_000000_0/work/javax
13/05/07 18:43:20 INFO filecache.TrackerDistributedCacheManager: Creating symlink: /tmp/hadoop-hadoop/mapred/local/taskTracker/hadoop/jobcache/job_201305061042_0028/jars/javaewah &amp;lt;- /tmp/hadoop-hadoop/mapred/local/taskTracker/hadoop/jobcache/job_201305061042_0028/attempt_201305061042_0028_m_000000_0/work/javaewah
13/05/07 18:43:20 INFO impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
13/05/07 18:43:21 INFO impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
13/05/07 18:43:21 INFO impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
13/05/07 18:43:21 INFO impl.MetricsSystemImpl: MapTask metrics system started
13/05/07 18:43:21 INFO impl.MetricsSourceAdapter: MBean for source ugi registered.
13/05/07 18:43:21 WARN impl.MetricsSystemImpl: Source name ugi already exists!
13/05/07 18:43:21 INFO impl.MetricsSourceAdapter: MBean for source jvm registered.
13/05/07 18:43:21 INFO util.ProcessTree: setsid exited with exit code 0
13/05/07 18:43:21 INFO mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@2d7aece8
13/05/07 18:43:21 INFO mapred.TaskLogsTruncater: Initializing logs&apos; truncater with mapRetainSize=-1 and reduceRetainSize=-1
13/05/07 18:43:21 INFO nativeio.NativeIO: Initialized cache for UID to User mapping with a cache timeout of 14400 seconds.
13/05/07 18:43:21 INFO nativeio.NativeIO: Got UserName hadoop for UID 1001 from the native implementation
13/05/07 18:43:21 WARN mapred.Child: Error running child
java.lang.NegativeArraySizeException: -1
	at org.apache.hadoop.hbase.util.Bytes.readByteArray(Bytes.java:148)
	at org.apache.hadoop.hbase.mapreduce.TableSplit.readFields(TableSplit.java:133)
	at org.apache.hadoop.hive.hbase.HBaseSplit.readFields(HBaseSplit.java:53)
	at org.apache.hadoop.hive.ql.io.HiveInputFormat$HiveInputSplit.readFields(HiveInputFormat.java:150)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:67)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:40)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:396)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:412)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:255)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.mapred.Child.main(Child.java:249)
13/05/07 18:43:21 INFO mapred.Task: Runnning cleanup for the task
13/05/07 18:43:21 INFO impl.MetricsSystemImpl: Stopping MapTask metrics system...
13/05/07 18:43:21 INFO impl.MetricsSystemImpl: Stopping metrics source ugi(org.apache.hadoop.security.UgiInstrumentation)
13/05/07 18:43:21 INFO impl.MetricsSystemImpl: Stopping metrics source jvm(org.apache.hadoop.metrics2.source.JvmMetricsSource)
13/05/07 18:43:21 INFO impl.MetricsSystemImpl: MapTask metrics system stopped.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment>&lt;p&gt;hive-0.10.0, hive-0.11.0&lt;br/&gt;
hbase-0.94.7, hbase-0.94.6.1&lt;br/&gt;
zookeeper-3.4.3&lt;br/&gt;
hadoop-1.0.4&lt;/p&gt;

&lt;p&gt;centos-5.7&lt;/p&gt;</environment>
        <key id="12646390">HIVE-4515</key>
            <summary>&quot;select count(*) from table&quot; query on hive-0.10.0, hbase-0.94.7 integration throws exceptions</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="6">Invalid</resolution>
                                        <assignee username="swarnim">Swarnim Kulkarni</assignee>
                                    <reporter username="mayanhui">Yanhui Ma</reporter>
                        <labels>
                    </labels>
                <created>Tue, 7 May 2013 10:44:27 +0000</created>
                <updated>Wed, 21 May 2014 15:25:50 +0000</updated>
                            <resolved>Wed, 21 May 2014 15:25:50 +0000</resolved>
                                    <version>0.10.0</version>
                    <version>0.11.0</version>
                                                    <component>HBase Handler</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13800541" author="yash360@gmail.com" created="Mon, 21 Oct 2013 10:46:41 +0000"  >&lt;p&gt;Is there any time line decided for this issue, or any other workaround for it. &lt;br/&gt;
I am stuck with it for a while.&lt;/p&gt;</comment>
                            <comment id="13914655" author="sridharpal" created="Thu, 27 Feb 2014 15:34:12 +0000"  >&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;We are using Hbase Avro tables and would like to access to data using Hive. So i modified the code in HBaseStorageHandler, LazyHBaseRow, LazyHBaseCellMap to provide support for Avro schema parsing. All works perfectly and able to see the data with basic query like; select * .... But when i query the hive table with any filter or select only some columns i see the same error that was reported above.&lt;br/&gt;
Also the exact same error is noticed when we access the data in hive using the original HBaseStorage Handler. So do not think this is something introduced by my changes to code.&lt;br/&gt;
So wanted check if there is any work around or fix available for this. We are using CDH 4.4.  &lt;br/&gt;
Any suggestions?&lt;/p&gt;</comment>
                            <comment id="13914673" author="swarnim" created="Thu, 27 Feb 2014 15:53:38 +0000"  >&lt;p&gt;I think this is more specific to CDH hive release, probably due to some incompatible dependencies. I wasn&apos;t able to reproduce this with apache stack.&lt;/p&gt;

&lt;p&gt;As a side note for your avro support of HBase, you might as well look into the patch on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6147&quot; title=&quot;Support avro data stored in HBase columns&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6147&quot;&gt;&lt;del&gt;HIVE-6147&lt;/del&gt;&lt;/a&gt;. It attempts to solve the sam problem.&lt;/p&gt;</comment>
                            <comment id="13914738" author="sridharpal" created="Thu, 27 Feb 2014 17:07:39 +0000"  >&lt;p&gt;Thank you Swarnim. I will follow up with the Cloudera and see if we have any resolution.&lt;/p&gt;</comment>
                            <comment id="14004763" author="ashutoshc" created="Wed, 21 May 2014 15:25:50 +0000"  >&lt;p&gt;Resolving this as invalid, per &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=swarnim&quot; class=&quot;user-hover&quot; rel=&quot;swarnim&quot;&gt;Swarnim Kulkarni&lt;/a&gt; previous comment. Feel free to reopen if you are able to repro this on trunk.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12646548">HIVE-4520</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12510557">HBASE-3996</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 21 Oct 2013 10:46:41 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326748</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 35 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kdbz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>327093</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4516] Fix concurrency bug in serde/src/java/org/apache/hadoop/hive/serde2/io/TimestampWritable.java</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4516</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;A patch for concurrent use of TimestampWritable which occurs in a multithreaded scenario (as found in AmpLab Shark).  A static SimpleDateFormat (not ThreadSafe) is used by TimestampWritable in CTAS DDL statements where it manifests as data corruption when used in a concurrent environment.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646446">HIVE-4516</key>
            <summary>Fix concurrency bug in serde/src/java/org/apache/hadoop/hive/serde2/io/TimestampWritable.java</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jhartlaub">Jon Hartlaub</assignee>
                                    <reporter username="jhartlaub">Jon Hartlaub</reporter>
                        <labels>
                    </labels>
                <created>Tue, 7 May 2013 16:51:10 +0000</created>
                <updated>Tue, 15 Oct 2013 23:30:01 +0000</updated>
                            <resolved>Wed, 5 Jun 2013 00:27:20 +0000</resolved>
                                                    <fixVersion>0.12.0</fixVersion>
                                        <due></due>
                            <votes>1</votes>
                                    <watches>7</watches>
                                                                <comments>
                            <comment id="13651557" author="teddy.choi" created="Wed, 8 May 2013 02:07:48 +0000"  >&lt;p&gt;It seems like &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4220&quot; title=&quot;TimestampWritable.toString throws array index exception sometimes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4220&quot;&gt;&lt;del&gt;HIVE-4220&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13651986" author="jhartlaub" created="Wed, 8 May 2013 15:26:58 +0000"  >&lt;p&gt;I agree - &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4220&quot; title=&quot;TimestampWritable.toString throws array index exception sometimes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4220&quot;&gt;&lt;del&gt;HIVE-4220&lt;/del&gt;&lt;/a&gt; may be a manifestation, although I think this ThreadLocal based patch or one using commons.lang FastDateFormat (which is thread-safe) would be preferable over the patch submitted in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4220&quot; title=&quot;TimestampWritable.toString throws array index exception sometimes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4220&quot;&gt;&lt;del&gt;HIVE-4220&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13664803" author="navis" created="Thu, 23 May 2013 02:32:20 +0000"  >&lt;p&gt;+1, running test&lt;/p&gt;</comment>
                            <comment id="13666205" author="navis" created="Fri, 24 May 2013 11:10:09 +0000"  >&lt;p&gt;passed all tests. But &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4220&quot; title=&quot;TimestampWritable.toString throws array index exception sometimes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4220&quot;&gt;&lt;del&gt;HIVE-4220&lt;/del&gt;&lt;/a&gt; has some minor optimization which removes unnecessary date.toString() call. It would be good to be merged with that.&lt;/p&gt;</comment>
                            <comment id="13666208" author="phabricator@reviews.facebook.net" created="Fri, 24 May 2013 11:14:20 +0000"  >&lt;p&gt;navis requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4516&quot; title=&quot;Fix concurrency bug in serde/src/java/org/apache/hadoop/hive/serde2/io/TimestampWritable.java&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4516&quot;&gt;&lt;del&gt;HIVE-4516&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Fix concurrency bug in serde/src/java/org/apache/hadoop/hive/serde2/io/TimestampWritable.java&quot;.&lt;/p&gt;

&lt;p&gt;Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4516&quot; title=&quot;Fix concurrency bug in serde/src/java/org/apache/hadoop/hive/serde2/io/TimestampWritable.java&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4516&quot;&gt;&lt;del&gt;HIVE-4516&lt;/del&gt;&lt;/a&gt; Fix concurrency bug in serde/src/java/org/apache/hadoop/hive/serde2/io/TimestampWritable.java&lt;/p&gt;

&lt;p&gt;A patch for concurrent use of TimestampWritable which occurs in a multithreaded scenario (as found in AmpLab Shark).  A static SimpleDateFormat (not ThreadSafe) is used by TimestampWritable in CTAS DDL statements where it manifests as data corruption when used in a concurrent environment.&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10929&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10929&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  serde/src/java/org/apache/hadoop/hive/serde2/io/TimestampWritable.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/26121/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/26121/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13674424" author="phabricator@reviews.facebook.net" created="Tue, 4 Jun 2013 14:09:23 +0000"  >&lt;p&gt;ashutoshc has accepted the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4516&quot; title=&quot;Fix concurrency bug in serde/src/java/org/apache/hadoop/hive/serde2/io/TimestampWritable.java&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4516&quot;&gt;&lt;del&gt;HIVE-4516&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Fix concurrency bug in serde/src/java/org/apache/hadoop/hive/serde2/io/TimestampWritable.java&quot;.&lt;/p&gt;

&lt;p&gt;  +1&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D10929&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10929&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4516&quot; title=&quot;Fix concurrency bug in serde/src/java/org/apache/hadoop/hive/serde2/io/TimestampWritable.java&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4516&quot;&gt;&lt;del&gt;HIVE-4516&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;/p&gt;</comment>
                            <comment id="13674504" author="brocknoland" created="Tue, 4 Jun 2013 15:38:44 +0000"  >&lt;p&gt;I hit this bug and this patch resolved the issue.&lt;/p&gt;</comment>
                            <comment id="13675468" author="ashutoshc" created="Wed, 5 Jun 2013 00:27:20 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Jon and Navis!&lt;/p&gt;</comment>
                            <comment id="13676300" author="hudson" created="Wed, 5 Jun 2013 20:17:59 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #2129 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2129/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2129/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4516&quot; title=&quot;Fix concurrency bug in serde/src/java/org/apache/hadoop/hive/serde2/io/TimestampWritable.java&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4516&quot;&gt;&lt;del&gt;HIVE-4516&lt;/del&gt;&lt;/a&gt; : Fix concurrency bug in serde/src/java/org/apache/hadoop/hive/serde2/io/TimestampWritable.java (Jon Hartlaub and Navis via Ashutosh Chauhan) (Revision 1489673)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1489673&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1489673&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/io/TimestampWritable.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13676476" author="hudson" created="Wed, 5 Jun 2013 23:24:21 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #226 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/226/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/226/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4516&quot; title=&quot;Fix concurrency bug in serde/src/java/org/apache/hadoop/hive/serde2/io/TimestampWritable.java&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4516&quot;&gt;&lt;del&gt;HIVE-4516&lt;/del&gt;&lt;/a&gt; : Fix concurrency bug in serde/src/java/org/apache/hadoop/hive/serde2/io/TimestampWritable.java (Jon Hartlaub and Navis via Ashutosh Chauhan) (Revision 1489673)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1489673&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1489673&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/io/TimestampWritable.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13795955" author="ashutoshc" created="Tue, 15 Oct 2013 23:30:01 +0000"  >&lt;p&gt;This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12638443">HIVE-4220</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12584681" name="HIVE-4516.D10929.1.patch" size="2201" author="phabricator@reviews.facebook.net" created="Fri, 24 May 2013 11:14:20 +0000"/>
                            <attachment id="12582122" name="TimestampWritable.java.patch" size="1660" author="jhartlaub" created="Tue, 7 May 2013 16:55:51 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 8 May 2013 02:07:48 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326804</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kdof:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>327149</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4517] Fix build broken in HIVE-4497</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4517</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12646502">HIVE-4517</key>
            <summary>Fix build broken in HIVE-4497</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="cwsteinbach">Carl Steinbach</assignee>
                                    <reporter username="cwsteinbach">Carl Steinbach</reporter>
                        <labels>
                    </labels>
                <created>Tue, 7 May 2013 21:18:27 +0000</created>
                <updated>Thu, 9 May 2013 00:14:08 +0000</updated>
                            <resolved>Thu, 9 May 2013 00:14:08 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="13651318" author="cwsteinbach" created="Tue, 7 May 2013 21:21:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2089/testReport/junit/org.apache.hive.beeline.src.test/TestBeeLineWithArgs/testPositiveScriptFile/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2089/testReport/junit/org.apache.hive.beeline.src.test/TestBeeLineWithArgs/testPositiveScriptFile/&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12646069">HIVE-4498</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326860</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 37 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ke0v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>327205</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4518] Counter Strike: Operation Operator</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4518</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Queries of the form:&lt;/p&gt;

&lt;p&gt;from foo&lt;br/&gt;
insert overwrite table bar partition (p) select ...&lt;br/&gt;
insert overwrite table bar partition (p) select ...&lt;br/&gt;
insert overwrite table bar partition (p) select ...&lt;/p&gt;

&lt;p&gt;Generate a huge amount of counters. The reason is that task.progress is turned on for dynamic partitioning queries.&lt;/p&gt;

&lt;p&gt;The counters not only make queries slower than necessary (up to 50%) you will also eventually run out. That&apos;s because we&apos;re wrapping them in enum values to comply with hadoop 0.17.&lt;/p&gt;

&lt;p&gt;The real reason we turn task.progress on is that we need CREATED_FILES and FATAL counters to ensure dynamic partitioning queries don&apos;t go haywire.&lt;/p&gt;

&lt;p&gt;The counters have counter-intuitive names like C1 through C1000 and don&apos;t seem really useful by themselves.&lt;/p&gt;

&lt;p&gt;With hadoop 20+ you don&apos;t need to wrap the counters anymore, each operator can simply create and increment counters. That should simplify the code a lot.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12646513">HIVE-4518</key>
            <summary>Counter Strike: Operation Operator</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hagleitn">Gunther Hagleitner</assignee>
                                    <reporter username="hagleitn">Gunther Hagleitner</reporter>
                        <labels>
                    </labels>
                <created>Tue, 7 May 2013 22:26:00 +0000</created>
                <updated>Mon, 13 Jan 2014 12:21:18 +0000</updated>
                            <resolved>Tue, 26 Nov 2013 01:07:40 +0000</resolved>
                                                    <fixVersion>0.13.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="13651411" author="hagleitn" created="Tue, 7 May 2013 23:01:15 +0000"  >&lt;p&gt;Review: &lt;a href=&quot;https://reviews.facebook.net/D10665&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10665&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13659092" author="hagleitn" created="Thu, 16 May 2013 00:51:10 +0000"  >&lt;p&gt;.2 is rebased to trunk&lt;/p&gt;</comment>
                            <comment id="13659145" author="appodictic" created="Thu, 16 May 2013 02:13:20 +0000"  >&lt;p&gt;We officially gave up support for 0.17 a LONG time ago so any 17 style counters can be replaced.&lt;/p&gt;</comment>
                            <comment id="13660803" author="hagleitn" created="Fri, 17 May 2013 15:48:09 +0000"  >&lt;p&gt;Ran all tests on patch .3. Passing.&lt;/p&gt;</comment>
                            <comment id="13660813" author="hagleitn" created="Fri, 17 May 2013 15:57:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=appodictic&quot; class=&quot;user-hover&quot; rel=&quot;appodictic&quot;&gt;Edward Capriolo&lt;/a&gt;, thanks for confirming, I had a sneaking suspicion that was the case. It does make the a lot code simpler, if we don&apos;t have to maintain that.&lt;/p&gt;</comment>
                            <comment id="13662087" author="appodictic" created="Mon, 20 May 2013 15:37:26 +0000"  >&lt;p&gt;Can you please deal with these two items:&lt;/p&gt;

&lt;p&gt;How many is too many? What is the limit and how many were there&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;fatalError = true;&lt;br/&gt;
           LOG.error(&quot;Fatal error was thrown due to exceeding number of dynamic partitions&quot;);&lt;br/&gt;
+          throw new HiveFatalException(&quot;Fatal Error: Too many partitions&quot;);&lt;br/&gt;
         }&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;Can this method be removed now?&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Override&lt;br/&gt;
   protected void localizeMRTmpFilesImpl(Context ctx) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {     // no op   }&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;</comment>
                            <comment id="13663448" author="hagleitn" created="Tue, 21 May 2013 21:49:12 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=appodictic&quot; class=&quot;user-hover&quot; rel=&quot;appodictic&quot;&gt;Edward Capriolo&lt;/a&gt;, I&apos;ve updated the fatal exception to include more information about the failure. (patch .4)&lt;/p&gt;

&lt;p&gt;Wrt the second question: localizeMRTmpFilesImpl - this is unrelated to this patch. I did some digging to understand what this is about. The code is supposed to enable full local execution of queries with small intermediate MR output. It&apos;s been in the code for 3 years and is currently disabled (commented out in SemanticAnalyzer). Given that the code hasn&apos;t been executed in that long it&apos;s probably ok to say folks aren&apos;t really interested and we can remove that code. I&apos;ll update &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1484&quot; title=&quot;use local file system for intermediate data when automatically inferring local mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1484&quot;&gt;HIVE-1484&lt;/a&gt; and see what other ppl think.&lt;/p&gt;</comment>
                            <comment id="13706596" author="appodictic" created="Fri, 12 Jul 2013 02:45:31 +0000"  >&lt;p&gt;Are you going to submit this patch.&lt;/p&gt;</comment>
                            <comment id="13707596" author="hagleitn" created="Sat, 13 Jul 2013 01:13:48 +0000"  >&lt;p&gt;Yes, thanks for the nudge. I&apos;ll rebase/run tests again on the weekend.&lt;/p&gt;</comment>
                            <comment id="13708274" author="hagleitn" created="Mon, 15 Jul 2013 07:01:51 +0000"  >&lt;p&gt;.5 is rebased to trunk. Running tests.&lt;/p&gt;</comment>
                            <comment id="13708275" author="hagleitn" created="Mon, 15 Jul 2013 07:03:43 +0000"  >&lt;p&gt;Updated: &lt;a href=&quot;https://reviews.facebook.net/D10665&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D10665&lt;/a&gt; as well with the latest patch&lt;/p&gt;</comment>
                            <comment id="13708758" author="appodictic" created="Mon, 15 Jul 2013 18:11:11 +0000"  >&lt;p&gt;I will check this out later tonight.&lt;/p&gt;</comment>
                            <comment id="13774777" author="appodictic" created="Mon, 23 Sep 2013 17:50:05 +0000"  >&lt;p&gt;My mistake I lost track of this one. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gunther&quot; class=&quot;user-hover&quot; rel=&quot;gunther&quot;&gt;Andrew Gunther&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; since you are both working on this code maybe you can review and commit. Otherwise if either of your are busy I will get back on top of this review.&lt;/p&gt;</comment>
                            <comment id="13814379" author="jdere" created="Tue, 5 Nov 2013 23:13:33 +0000"  >&lt;p&gt;~navis ~appodictic would one of you guys be able to give this one a look, if I rebase this with trunk?&lt;/p&gt;</comment>
                            <comment id="13816922" author="jdere" created="Fri, 8 Nov 2013 02:08:05 +0000"  >&lt;p&gt;Didn&apos;t do the usernames properly, trying again .. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=appodictic&quot; class=&quot;user-hover&quot; rel=&quot;appodictic&quot;&gt;Edward Capriolo&lt;/a&gt; would you guys be able to review if I rebase this one?&lt;/p&gt;</comment>
                            <comment id="13818778" author="navis" created="Mon, 11 Nov 2013 08:54:41 +0000"  >&lt;p&gt;Rebased to trunk. Let&apos;s see what&apos;s happening on test.&lt;/p&gt;</comment>
                            <comment id="13819262" author="jdere" created="Mon, 11 Nov 2013 19:26:42 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt;, took a look at this patch yesterday and was thinking that this patch could have been done without completely getting rid of hive.task.progress mode, looks like we could have made changes such that hive.task.progress wasn&apos;t required when doing dynamic partitioning.  Anyway, if you&apos;ve already gone through the trouble to rebase this patch we can go ahead with this as it is.&lt;/p&gt;</comment>
                            <comment id="13819418" author="hiveqa" created="Mon, 11 Nov 2013 21:28:41 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12613111/HIVE-4518.6.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12613111/HIVE-4518.6.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/242/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/242/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/242/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/242/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-242/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;ql/src/test/results/clientpositive/show_functions.q.out&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/RowSchema.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/io/OneNullRowInputFormat.java&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ awk &apos;{print $2}&apos;
++ svn status --no-ignore
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20/target shims/assembly/target shims/0.20S/target shims/0.23/target shims/common/target shims/common-secure/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit/target itests/custom-serde/target itests/util/target hcatalog/target hcatalog/storage-handlers/hbase/target hcatalog/server-extensions/target hcatalog/core/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target hcatalog/hcatalog-pig-adapter/target hwi/target common/target common/src/gen service/target contrib/target serde/target beeline/target odbc/target cli/target ql/dependency-reduced-pom.xml ql/target ql/src/test/results/clientpositive/select_dummy_source.q.out ql/src/test/results/clientpositive/udf_current_database.q.out ql/src/test/queries/clientpositive/udf_current_database.q ql/src/test/queries/clientpositive/select_dummy_source.q ql/src/java/org/apache/hadoop/hive/ql/io/NullRowsInputFormat.java ql/src/java/org/apache/hadoop/hive/ql/udf/generic/UDFCurrentDB.java
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1540846.

At revision 1540846.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
patching file conf/hive-default.xml.template
patching file data/conf/hive-site.xml
patching file ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java
patching file ql/src/java/org/apache/hadoop/hive/ql/QueryPlan.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/AbstractMapJoinOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/CommonJoinOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/DemuxOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/MuxOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/OperatorFactory.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecReducer.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHook.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorFileSinkOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/merge/BlockMergeTask.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/stats/PartialScanTask.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/truncate/ColumnTruncateTask.java
patching file ql/src/java/org/apache/hadoop/hive/ql/metadata/HiveFatalException.java
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/MapReduceCompiler.java
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
patching file ql/src/test/org/apache/hadoop/hive/ql/exec/TestOperators.java
patching file ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorGroupByOperator.java
patching file ql/src/test/org/apache/hadoop/hive/ql/testutil/OperatorTestUtils.java
patching file ql/src/test/queries/clientpositive/insert_into3.q
patching file ql/src/test/queries/clientpositive/optrstat_groupby.q
patching file ql/src/test/results/clientpositive/insert_into3.q.out
patching file ql/src/test/results/clientpositive/optrstat_groupby.q.out
patching file ql/src/test/results/compiler/plan/case_sensitivity.q.xml
patching file ql/src/test/results/compiler/plan/cast1.q.xml
patching file ql/src/test/results/compiler/plan/groupby1.q.xml
patching file ql/src/test/results/compiler/plan/groupby2.q.xml
patching file ql/src/test/results/compiler/plan/groupby3.q.xml
patching file ql/src/test/results/compiler/plan/groupby4.q.xml
patching file ql/src/test/results/compiler/plan/groupby5.q.xml
patching file ql/src/test/results/compiler/plan/groupby6.q.xml
patching file ql/src/test/results/compiler/plan/input1.q.xml
patching file ql/src/test/results/compiler/plan/input2.q.xml
patching file ql/src/test/results/compiler/plan/input20.q.xml
patching file ql/src/test/results/compiler/plan/input3.q.xml
patching file ql/src/test/results/compiler/plan/input4.q.xml
patching file ql/src/test/results/compiler/plan/input5.q.xml
patching file ql/src/test/results/compiler/plan/input6.q.xml
patching file ql/src/test/results/compiler/plan/input7.q.xml
patching file ql/src/test/results/compiler/plan/input8.q.xml
patching file ql/src/test/results/compiler/plan/input9.q.xml
patching file ql/src/test/results/compiler/plan/input_part1.q.xml
patching file ql/src/test/results/compiler/plan/input_testsequencefile.q.xml
patching file ql/src/test/results/compiler/plan/input_testxpath.q.xml
patching file ql/src/test/results/compiler/plan/input_testxpath2.q.xml
patching file ql/src/test/results/compiler/plan/join1.q.xml
patching file ql/src/test/results/compiler/plan/join2.q.xml
patching file ql/src/test/results/compiler/plan/join3.q.xml
patching file ql/src/test/results/compiler/plan/join4.q.xml
patching file ql/src/test/results/compiler/plan/join5.q.xml
patching file ql/src/test/results/compiler/plan/join6.q.xml
patching file ql/src/test/results/compiler/plan/join7.q.xml
patching file ql/src/test/results/compiler/plan/join8.q.xml
patching file ql/src/test/results/compiler/plan/sample1.q.xml
patching file ql/src/test/results/compiler/plan/sample2.q.xml
patching file ql/src/test/results/compiler/plan/sample3.q.xml
patching file ql/src/test/results/compiler/plan/sample4.q.xml
patching file ql/src/test/results/compiler/plan/sample5.q.xml
patching file ql/src/test/results/compiler/plan/sample6.q.xml
patching file ql/src/test/results/compiler/plan/sample7.q.xml
patching file ql/src/test/results/compiler/plan/subq.q.xml
patching file ql/src/test/results/compiler/plan/udf1.q.xml
patching file ql/src/test/results/compiler/plan/udf4.q.xml
patching file ql/src/test/results/compiler/plan/udf6.q.xml
patching file ql/src/test/results/compiler/plan/udf_case.q.xml
patching file ql/src/test/results/compiler/plan/udf_when.q.xml
patching file ql/src/test/results/compiler/plan/union.q.xml
+ [[ maven == \m\a\v\e\n ]]
+ rm -rf /data/hive-ptest/working/maven/org/apache/hive
+ mvn -B clean install -DskipTests -Dmaven.repo.local=/data/hive-ptest/working/maven
[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Hive
[INFO] Hive Ant Utilities
[INFO] Hive Shims Common
[INFO] Hive Shims 0.20
[INFO] Hive Shims Secure Common
[INFO] Hive Shims 0.20S
[INFO] Hive Shims 0.23
[INFO] Hive Shims
[INFO] Hive Common
[INFO] Hive Serde
[INFO] Hive Metastore
[INFO] Hive Query Language
[INFO] Hive Service
[INFO] Hive JDBC
[INFO] Hive Beeline
[INFO] Hive CLI
[INFO] Hive Contrib
[INFO] Hive HBase Handler
[INFO] Hive HCatalog
[INFO] Hive HCatalog Core
[INFO] Hive HCatalog Pig Adapter
[INFO] Hive HCatalog Server Extensions
[INFO] Hive HCatalog Webhcat Java Client
[INFO] Hive HCatalog Webhcat
[INFO] Hive HCatalog HBase Storage Handler
[INFO] Hive HWI
[INFO] Hive ODBC
[INFO] Hive Shims Aggregator
[INFO] Hive TestUtils
[INFO] Hive Packaging
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive/0.13.0-SNAPSHOT/hive-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Ant Utilities 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-ant ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/ant (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-ant ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-ant ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-ant ---
[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-svn-trunk-source/ant/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-ant ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-ant ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-ant ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-ant ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-ant ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/hive-ant-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-ant ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ant/target/hive-ant-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-ant/0.13.0-SNAPSHOT/hive-ant-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ant/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-ant/0.13.0-SNAPSHOT/hive-ant-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-common ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/common (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common ---
[INFO] Compiling 15 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-common ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-common ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common/0.13.0-SNAPSHOT/hive-shims-common-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common/0.13.0-SNAPSHOT/hive-shims-common-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.20 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.20 ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20 (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20 ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20 ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20 ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.20 ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.20 ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20/0.13.0-SNAPSHOT/hive-shims-0.20-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20/0.13.0-SNAPSHOT/hive-shims-0.20-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Secure Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-common-secure ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common-secure ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common-secure ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common-secure ---
[INFO] Compiling 12 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/main/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common-secure ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common-secure ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common-secure ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common-secure ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-common-secure ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-common-secure ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common-secure/0.13.0-SNAPSHOT/hive-shims-common-secure-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common-secure/0.13.0-SNAPSHOT/hive-shims-common-secure-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.20S 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.20S ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20S ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20S ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20S ---
[INFO] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/main/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20S ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20S ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20S ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20S ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.20S ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.20S ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20S/0.13.0-SNAPSHOT/hive-shims-0.20S-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20S/0.13.0-SNAPSHOT/hive-shims-0.20S-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.23 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.23 ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23 (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.23 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.23 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.23 ---
[INFO] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/main/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.23 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.23 ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.23 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.23 ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.23 ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.23 ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.23/0.13.0-SNAPSHOT/hive-shims-0.23-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.23/0.13.0-SNAPSHOT/hive-shims-0.23-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims ---
[WARNING] JAR will be empty - no content was marked for inclusion!
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-assembly-plugin:2.3:single (uberjar) @ hive-shims ---
[INFO] Reading assembly descriptor: src/assemble/uberjar.xml
[WARNING] Artifact: org.apache.hive:hive-shims:jar:0.13.0-SNAPSHOT references the same file as the assembly destination file. Moving it to a temporary location for inclusion.
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[WARNING] Configuration options: &apos;appendAssemblyId&apos; is set to false, and &apos;classifier&apos; is missing.
Instead of attaching the assembly file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar, it will become the file for main project artifact.
NOTE: If multiple descriptors or descriptor-formats are provided for this project, the value of this file will be non-deterministic!
[WARNING] Replacing pre-existing project main-artifact file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/archive-tmp/hive-shims-0.13.0-SNAPSHOT.jar
with assembly file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.13.0-SNAPSHOT/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.13.0-SNAPSHOT/hive-shims-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-common ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/common (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-version-annotation) @ hive-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-common ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/common/src/gen added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-common ---
[INFO] Compiling 31 source files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/common/src/java/org/apache/hadoop/hive/common/ObjectPair.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-common ---
[INFO] Compiling 8 source files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-common ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-common ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-common ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-common/0.13.0-SNAPSHOT/hive-common-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/common/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-common/0.13.0-SNAPSHOT/hive-common-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Serde 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-serde ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/serde (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-serde ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/protobuf/gen-java added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-serde ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-serde ---
[INFO] Compiling 351 source files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-serde ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-serde ---
[INFO] Compiling 41 source files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-serde ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-serde ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-serde ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-serde/0.13.0-SNAPSHOT/hive-serde-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/serde/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-serde/0.13.0-SNAPSHOT/hive-serde-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Metastore 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-metastore ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/metastore (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-metastore ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/model added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-metastore ---
[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java
ANTLR Parser Generator  Version 3.4
org/apache/hadoop/hive/metastore/parser/Filter.g
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-metastore ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-metastore ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-metastore ---
[INFO] Compiling 132 source files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- datanucleus-maven-plugin:3.3.0-release:enhance (default) @ hive-metastore ---
[INFO] DataNucleus Enhancer (version 3.2.2) for API &quot;JDO&quot; using JRE &quot;1.6&quot;
DataNucleus Enhancer : Classpath
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-maven-plugin/3.3.0-release/datanucleus-maven-plugin-3.3.0-release.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-utils/3.0.8/plexus-utils-3.0.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-component-annotations/1.5.5/plexus-component-annotations-1.5.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-inject-bean/2.3.0/sisu-inject-bean-2.3.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guice/3.1.0/sisu-guice-3.1.0-no_aop.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guava/0.9.9/sisu-guava-0.9.9.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/xbean/xbean-reflect/3.4/xbean-reflect-3.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/log4j/log4j/1.2.12/log4j-1.2.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-logging/commons-logging-api/1.1/commons-logging-api-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/collections/google-collections/1.0/google-collections-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/junit/junit/3.8.2/junit-3.8.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/tukaani/xz/1.0/xz-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-codec/commons-codec/1.4/commons-codec-1.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/avro/avro/1.7.1/avro-1.7.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/jline/jline/0.9.94/jline-0.9.94.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/guava/guava/11.0.2/guava-11.0.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-lang/commons-lang/2.4/commons-lang-2.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/transaction/jta/1.1/jta-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/antlr/antlr/2.7.7/antlr-2.7.7.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/hadoop/hadoop-core/1.2.1/hadoop-core-1.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/xmlenc/xmlenc/0.52/xmlenc-0.52.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/stax/stax-api/1.0.1/stax-api-1.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/activation/activation/1.1/activation-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-jaxrs/1.7.1/jackson-jaxrs-1.7.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/asm/asm/3.1/asm-3.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-io/commons-io/2.1/commons-io-2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/commons/commons-math/2.1/commons-math-2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-digester/commons-digester/1.8/commons-digester-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/ant/ant/1.6.5/ant-1.6.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-el/commons-el/1.0/commons-el-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/oro/oro/2.0.8/oro-2.0.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/log4j/log4j/1.2.16/log4j-1.2.16.jar
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDatabase
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFieldSchema
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MType
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTable
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MOrder
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStringList
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartition
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MIndex
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRole
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRoleMap
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MMasterKey
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDelegationToken
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MVersionTable
DataNucleus Enhancer completed with success for 25 classes. Timings : input=610 ms, enhance=920 ms, total=1530 ms. Consult the log for full details

[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-metastore ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-metastore ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-metastore ---
[INFO] Compiling 10 source files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-metastore ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-metastore ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-metastore ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-metastore ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Query Language 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-exec ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/ql (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-sources) @ hive-exec ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-test-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
Generating vector expression code
Generating vector expression test code
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-exec ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/protobuf/gen-java added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-sources/java added.
[INFO] 
[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-exec ---
[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java
ANTLR Parser Generator  Version 3.4
org/apache/hadoop/hive/ql/parse/HiveLexer.g
org/apache/hadoop/hive/ql/parse/HiveParser.g
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:872:5: 
Decision can match input such as &quot;Identifier KW_RENAME KW_TO&quot; using multiple alternatives: 1, 10

As a result, alternative(s) 10 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:5: 
Decision can match input such as &quot;KW_TEXTFILE&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:5: 
Decision can match input such as &quot;KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:5: 
Decision can match input such as &quot;KW_ORCFILE&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:5: 
Decision can match input such as &quot;KW_RCFILE&quot; using multiple alternatives: 3, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1190:23: 
Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1190:23: 
Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1190:23: 
Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1197:23: 
Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1197:23: 
Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1197:23: 
Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_PRETTY {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_FORMATTED {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_PRETTY Identifier&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_FORMATTED Identifier&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_PRETTY KW_PARTITION&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_FORMATTED KW_PARTITION&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1486:116: 
Decision can match input such as &quot;KW_STORED KW_AS KW_DIRECTORIES&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_RCFILE&quot; using multiple alternatives: 3, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_ORCFILE&quot; using multiple alternatives: 4, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_TEXTFILE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_INPUTFORMAT&quot; using multiple alternatives: 5, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): SelectClauseParser.g:149:5: 
Decision can match input such as &quot;KW_NULL DOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): SelectClauseParser.g:149:5: 
Decision can match input such as &quot;KW_NULL DOT Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:127:2: 
Decision can match input such as &quot;KW_LATERAL KW_VIEW KW_OUTER&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:25: 
Decision can match input such as &quot;LPAREN StringLiteral EQUAL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:25: 
Decision can match input such as &quot;LPAREN StringLiteral COMMA&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:25: 
Decision can match input such as &quot;LPAREN StringLiteral RPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL {KW_LIKE, KW_REGEXP, KW_RLIKE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL AMPERSAND&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_IS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL RPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN StringLiteral StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL BITWISEOR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL DOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL {DIV..DIVIDE, MOD, STAR}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL NOTEQUAL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL EQUAL_NS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_EXISTS LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LESSTHAN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LESSTHANOREQUALTO&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_OR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_DATE StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL EQUAL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CAST LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL GREATERTHAN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL GREATERTHANOREQUALTO&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_BETWEEN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL {MINUS, PLUS}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LSQUARE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL BITWISEXOR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN CharSetName CharSetLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_AND&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_IN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_WHEN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:108:5: 
Decision can match input such as &quot;KW_ORDER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:121:5: 
Decision can match input such as &quot;KW_CLUSTER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:133:5: 
Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:144:5: 
Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:155:5: 
Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:172:7: 
Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_DATE StringLiteral&quot; using multiple alternatives: 2, 3

As a result, alternative(s) 3 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:524:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-exec ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1388 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-test-source (add-test-sources) @ hive-exec ---
[INFO] Test Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-test-sources/java added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-exec ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-exec ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-exec ---
[INFO] Compiling 134 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-exec ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-exec ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-exec ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-shade-plugin:2.1:shade (build-exec-bundle) @ hive-exec ---
[INFO] Excluding org.apache.hive:hive-ant:jar:0.13.0-SNAPSHOT from the shaded jar.
[INFO] Excluding org.apache.velocity:velocity:jar:1.5 from the shaded jar.
[INFO] Excluding commons-collections:commons-collections:jar:3.1 from the shaded jar.
[INFO] Including org.apache.hive:hive-common:jar:0.13.0-SNAPSHOT in the shaded jar.
[INFO] Excluding commons-cli:commons-cli:jar:1.2 from the shaded jar.
[INFO] Excluding org.apache.hive:hive-metastore:jar:0.13.0-SNAPSHOT from the shaded jar.
[INFO] Excluding com.jolbox:bonecp:jar:0.7.1.RELEASE from the shaded jar.
[INFO] Excluding org.apache.derby:derby:jar:10.4.2.0 from the shaded jar.
[INFO] Excluding org.datanucleus:datanucleus-api-jdo:jar:3.2.1 from the shaded jar.
[INFO] Excluding org.datanucleus:datanucleus-rdbms:jar:3.2.1 from the shaded jar.
[INFO] Excluding javax.jdo:jdo-api:jar:3.0.1 from the shaded jar.
[INFO] Excluding javax.transaction:jta:jar:1.1 from the shaded jar.
[INFO] Including org.apache.hive:hive-serde:jar:0.13.0-SNAPSHOT in the shaded jar.
[INFO] Including org.apache.hive:hive-shims:jar:0.13.0-SNAPSHOT in the shaded jar.
[INFO] Excluding org.apache.hive.shims:hive-shims-common:jar:0.13.0-SNAPSHOT from the shaded jar.
[INFO] Excluding org.apache.hive.shims:hive-shims-0.20:jar:0.13.0-SNAPSHOT from the shaded jar.
[INFO] Excluding org.apache.hive.shims:hive-shims-common-secure:jar:0.13.0-SNAPSHOT from the shaded jar.
[INFO] Excluding org.apache.hive.shims:hive-shims-0.20S:jar:0.13.0-SNAPSHOT from the shaded jar.
[INFO] Excluding org.apache.hive.shims:hive-shims-0.23:jar:0.13.0-SNAPSHOT from the shaded jar.
[INFO] Including com.esotericsoftware.kryo:kryo:jar:2.22 in the shaded jar.
[INFO] Excluding commons-codec:commons-codec:jar:1.4 from the shaded jar.
[INFO] Excluding commons-httpclient:commons-httpclient:jar:3.0.1 from the shaded jar.
[INFO] Excluding commons-io:commons-io:jar:2.4 from the shaded jar.
[INFO] Including commons-lang:commons-lang:jar:2.4 in the shaded jar.
[INFO] Excluding commons-logging:commons-logging:jar:1.1.3 from the shaded jar.
[INFO] Including javolution:javolution:jar:5.5.1 in the shaded jar.
[INFO] Excluding log4j:log4j:jar:1.2.16 from the shaded jar.
[INFO] Excluding org.antlr:antlr-runtime:jar:3.4 from the shaded jar.
[INFO] Excluding org.antlr:stringtemplate:jar:3.2.1 from the shaded jar.
[INFO] Excluding antlr:antlr:jar:2.7.7 from the shaded jar.
[INFO] Excluding org.antlr:ST4:jar:4.0.4 from the shaded jar.
[INFO] Excluding org.apache.avro:avro:jar:1.7.1 from the shaded jar.
[INFO] Excluding com.thoughtworks.paranamer:paranamer:jar:2.3 from the shaded jar.
[INFO] Excluding org.xerial.snappy:snappy-java:jar:1.0.4.1 from the shaded jar.
[INFO] Excluding org.apache.avro:avro-mapred:jar:1.7.1 from the shaded jar.
[INFO] Excluding org.apache.avro:avro-ipc:jar:1.7.1 from the shaded jar.
[INFO] Excluding io.netty:netty:jar:3.4.0.Final from the shaded jar.
[INFO] Excluding org.mortbay.jetty:servlet-api:jar:2.5-20081211 from the shaded jar.
[INFO] Excluding org.apache.ant:ant:jar:1.9.1 from the shaded jar.
[INFO] Excluding org.apache.ant:ant-launcher:jar:1.9.1 from the shaded jar.
[INFO] Excluding org.apache.commons:commons-compress:jar:1.4.1 from the shaded jar.
[INFO] Excluding org.tukaani:xz:jar:1.0 from the shaded jar.
[INFO] Excluding org.apache.thrift:libfb303:jar:0.9.0 from the shaded jar.
[INFO] Including org.apache.thrift:libthrift:jar:0.9.0 in the shaded jar.
[INFO] Excluding org.apache.httpcomponents:httpclient:jar:4.1.3 from the shaded jar.
[INFO] Excluding org.apache.httpcomponents:httpcore:jar:4.1.3 from the shaded jar.
[INFO] Excluding org.apache.zookeeper:zookeeper:jar:3.4.3 from the shaded jar.
[INFO] Excluding jline:jline:jar:0.9.94 from the shaded jar.
[INFO] Excluding org.jboss.netty:netty:jar:3.2.2.Final from the shaded jar.
[INFO] Excluding org.codehaus.groovy:groovy-all:jar:2.1.6 from the shaded jar.
[INFO] Including org.codehaus.jackson:jackson-core-asl:jar:1.9.2 in the shaded jar.
[INFO] Including org.codehaus.jackson:jackson-mapper-asl:jar:1.9.2 in the shaded jar.
[INFO] Excluding org.datanucleus:datanucleus-core:jar:3.2.2 from the shaded jar.
[INFO] Including com.google.guava:guava:jar:11.0.2 in the shaded jar.
[INFO] Excluding com.google.code.findbugs:jsr305:jar:1.3.9 from the shaded jar.
[INFO] Including com.google.protobuf:protobuf-java:jar:2.5.0 in the shaded jar.
[INFO] Including com.googlecode.javaewah:JavaEWAH:jar:0.3.2 in the shaded jar.
[INFO] Including org.iq80.snappy:snappy:jar:0.2 in the shaded jar.
[INFO] Including org.json:json:jar:20090211 in the shaded jar.
[INFO] Excluding stax:stax-api:jar:1.0.1 from the shaded jar.
[INFO] Excluding org.apache.hadoop:hadoop-core:jar:1.2.1 from the shaded jar.
[INFO] Excluding xmlenc:xmlenc:jar:0.52 from the shaded jar.
[INFO] Excluding com.sun.jersey:jersey-core:jar:1.8 from the shaded jar.
[INFO] Excluding com.sun.jersey:jersey-json:jar:1.8 from the shaded jar.
[INFO] Excluding org.codehaus.jettison:jettison:jar:1.1 from the shaded jar.
[INFO] Excluding com.sun.xml.bind:jaxb-impl:jar:2.2.3-1 from the shaded jar.
[INFO] Excluding javax.xml.bind:jaxb-api:jar:2.2.2 from the shaded jar.
[INFO] Excluding javax.xml.stream:stax-api:jar:1.0-2 from the shaded jar.
[INFO] Excluding javax.activation:activation:jar:1.1 from the shaded jar.
[INFO] Excluding org.codehaus.jackson:jackson-jaxrs:jar:1.7.1 from the shaded jar.
[INFO] Excluding org.codehaus.jackson:jackson-xc:jar:1.7.1 from the shaded jar.
[INFO] Excluding com.sun.jersey:jersey-server:jar:1.8 from the shaded jar.
[INFO] Excluding asm:asm:jar:3.1 from the shaded jar.
[INFO] Excluding org.apache.commons:commons-math:jar:2.1 from the shaded jar.
[INFO] Excluding commons-configuration:commons-configuration:jar:1.6 from the shaded jar.
[INFO] Excluding commons-digester:commons-digester:jar:1.8 from the shaded jar.
[INFO] Excluding commons-beanutils:commons-beanutils:jar:1.7.0 from the shaded jar.
[INFO] Excluding commons-beanutils:commons-beanutils-core:jar:1.8.0 from the shaded jar.
[INFO] Excluding commons-net:commons-net:jar:1.4.1 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jetty:jar:6.1.26 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jetty-util:jar:6.1.26 from the shaded jar.
[INFO] Excluding tomcat:jasper-runtime:jar:5.5.12 from the shaded jar.
[INFO] Excluding tomcat:jasper-compiler:jar:5.5.12 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jsp-api-2.1:jar:6.1.14 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:servlet-api-2.5:jar:6.1.14 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jsp-2.1:jar:6.1.14 from the shaded jar.
[INFO] Excluding ant:ant:jar:1.6.5 from the shaded jar.
[INFO] Excluding commons-el:commons-el:jar:1.0 from the shaded jar.
[INFO] Excluding net.java.dev.jets3t:jets3t:jar:0.6.1 from the shaded jar.
[INFO] Excluding hsqldb:hsqldb:jar:1.8.0.10 from the shaded jar.
[INFO] Excluding oro:oro:jar:2.0.8 from the shaded jar.
[INFO] Excluding org.eclipse.jdt:core:jar:3.1.1 from the shaded jar.
[INFO] Excluding org.slf4j:slf4j-api:jar:1.6.1 from the shaded jar.
[INFO] Excluding org.slf4j:slf4j-log4j12:jar:1.6.1 from the shaded jar.
[INFO] Replacing original artifact with shaded artifact.
[INFO] Replacing /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT.jar with /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT-shaded.jar
[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-svn-trunk-source/ql/dependency-reduced-pom.xml
[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-svn-trunk-source/ql/dependency-reduced-pom.xml
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-exec ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-exec/0.13.0-SNAPSHOT/hive-exec-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ql/dependency-reduced-pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-exec/0.13.0-SNAPSHOT/hive-exec-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-exec/0.13.0-SNAPSHOT/hive-exec-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Service 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-service ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/service (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-service ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/service/src/model added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/service/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-service ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/service/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-service ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-service ---
[INFO] Compiling 153 source files to /data/hive-ptest/working/apache-svn-trunk-source/service/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-service ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-service ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-service ---
[INFO] Compiling 7 source files to /data/hive-ptest/working/apache-svn-trunk-source/service/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-service ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-service ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-service ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-service ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-service/0.13.0-SNAPSHOT/hive-service-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/service/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-service/0.13.0-SNAPSHOT/hive-service-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-service/0.13.0-SNAPSHOT/hive-service-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive JDBC 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-jdbc ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/jdbc (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-jdbc ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-jdbc ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-jdbc ---
[INFO] Compiling 30 source files to /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-jdbc ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-jdbc ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-jdbc ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-jdbc ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-jdbc ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/hive-jdbc-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-jdbc ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/hive-jdbc-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-jdbc/0.13.0-SNAPSHOT/hive-jdbc-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/jdbc/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-jdbc/0.13.0-SNAPSHOT/hive-jdbc-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Beeline 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-beeline ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/beeline (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-beeline ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-beeline ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-beeline ---
[INFO] Compiling 31 source files to /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/classes
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:[28,16] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:[29,16] warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:[31,64] warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:[44,23] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:[37,24] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/java/org/apache/hive/beeline/SunSignalHandler.java:[37,5] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-beeline ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-beeline ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-beeline ---
[INFO] Compiling 1 source file to /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-beeline ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-beeline ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/hive-beeline-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-beeline ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/hive-beeline-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-beeline/0.13.0-SNAPSHOT/hive-beeline-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/beeline/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-beeline/0.13.0-SNAPSHOT/hive-beeline-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive CLI 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-cli ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/cli (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-cli ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/cli/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-cli ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-cli ---
[INFO] Compiling 4 source files to /data/hive-ptest/working/apache-svn-trunk-source/cli/target/classes
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[74,16] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[75,16] warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[371,5] warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[372,5] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[377,27] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[378,52] warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[378,52] warning: sun.misc.SignalHandler is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[383,28] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[378,19] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java:[439,9] warning: sun.misc.Signal is Sun proprietary API and may be removed in a future release
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/RCFileCat.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-cli ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-cli ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/cli/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-cli ---
[INFO] Compiling 4 source files to /data/hive-ptest/working/apache-svn-trunk-source/cli/target/test-classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/org/apache/hadoop/hive/cli/TestCliDriverMethods.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-cli ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-cli ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/hive-cli-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-cli ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/cli/target/hive-cli-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-cli/0.13.0-SNAPSHOT/hive-cli-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/cli/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-cli/0.13.0-SNAPSHOT/hive-cli-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Contrib 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-contrib ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/contrib (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-contrib ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-contrib ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-contrib ---
[INFO] Compiling 39 source files to /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/java/org/apache/hadoop/hive/contrib/udf/example/UDFExampleStructPrint.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-contrib ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-contrib ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-contrib ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/test-classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/org/apache/hadoop/hive/contrib/serde2/TestRegexSerDe.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-contrib ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-contrib ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/hive-contrib-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-contrib ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/hive-contrib-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-contrib/0.13.0-SNAPSHOT/hive-contrib-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/contrib/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-contrib/0.13.0-SNAPSHOT/hive-contrib-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HBase Handler 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hbase-handler ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hbase-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hbase-handler ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hbase-handler ---
[INFO] Compiling 13 source files to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hbase-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hbase-handler ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hbase-handler ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hbase-handler ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hbase-handler ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/hive-hbase-handler-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hbase-handler ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/hive-hbase-handler-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hbase-handler/0.13.0-SNAPSHOT/hive-hbase-handler-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-hbase-handler/0.13.0-SNAPSHOT/hive-hbase-handler-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hcatalog ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hcatalog ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog/0.13.0-SNAPSHOT/hive-hcatalog-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Core 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hcatalog-core ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hcatalog-core ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-core ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-core ---
[INFO] Compiling 144 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hcatalog-core ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog-core ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hcatalog-core ---
[INFO] Compiling 67 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hcatalog-core ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hcatalog-core ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/hive-hcatalog-core-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-hcatalog-core ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/hive-hcatalog-core-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hcatalog-core ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/hive-hcatalog-core-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog-core/0.13.0-SNAPSHOT/hive-hcatalog-core-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog-core/0.13.0-SNAPSHOT/hive-hcatalog-core-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/hive-hcatalog-core-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog-core/0.13.0-SNAPSHOT/hive-hcatalog-core-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Pig Adapter 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hcatalog-pig-adapter ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hcatalog-pig-adapter ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-pig-adapter ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-pig-adapter ---
[INFO] Compiling 10 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hcatalog-pig-adapter ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog-pig-adapter ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hcatalog-pig-adapter ---
[INFO] Compiling 26 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hcatalog-pig-adapter ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hcatalog-pig-adapter ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/hive-hcatalog-pig-adapter-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hcatalog-pig-adapter ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/hive-hcatalog-pig-adapter-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog-pig-adapter/0.13.0-SNAPSHOT/hive-hcatalog-pig-adapter-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog-pig-adapter/0.13.0-SNAPSHOT/hive-hcatalog-pig-adapter-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Server Extensions 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hcatalog-server-extensions ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hcatalog-server-extensions ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-server-extensions ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-server-extensions ---
[INFO] Compiling 38 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hcatalog-server-extensions ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog-server-extensions ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hcatalog-server-extensions ---
[INFO] Compiling 4 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hcatalog-server-extensions ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hcatalog-server-extensions ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/hive-hcatalog-server-extensions-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hcatalog-server-extensions ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/hive-hcatalog-server-extensions-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog-server-extensions/0.13.0-SNAPSHOT/hive-hcatalog-server-extensions-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hcatalog-server-extensions/0.13.0-SNAPSHOT/hive-hcatalog-server-extensions-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Webhcat Java Client 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-webhcat-java-client ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-webhcat-java-client ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-webhcat-java-client ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-webhcat-java-client ---
[INFO] Compiling 20 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-webhcat-java-client ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-webhcat-java-client ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-webhcat-java-client ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-webhcat-java-client ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-webhcat-java-client ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/hive-webhcat-java-client-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-webhcat-java-client ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/hive-webhcat-java-client-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-webhcat-java-client/0.13.0-SNAPSHOT/hive-webhcat-java-client-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-webhcat-java-client/0.13.0-SNAPSHOT/hive-webhcat-java-client-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Webhcat 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-webhcat ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-webhcat ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-webhcat ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-webhcat ---
[INFO] Compiling 65 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-javadoc-plugin:2.4:javadoc (resourcesdoc.xml) @ hive-webhcat ---
[INFO] Setting property: classpath.resource.loader.class =&amp;gt; &apos;org.codehaus.plexus.velocity.ContextClassLoaderResourceLoader&apos;.
[INFO] Setting property: velocimacro.messages.on =&amp;gt; &apos;false&apos;.
[INFO] Setting property: resource.loader =&amp;gt; &apos;classpath&apos;.
[INFO] Setting property: resource.manager.logwhenfound =&amp;gt; &apos;false&apos;.
[INFO] ************************************************************** 
[INFO] Starting Jakarta Velocity v1.4
[INFO] RuntimeInstance initializing.
[INFO] Default Properties File: org/apache/velocity/runtime/defaults/velocity.properties
[INFO] Default ResourceManager initializing. (class org.apache.velocity.runtime.resource.ResourceManagerImpl)
[INFO] Resource Loader Instantiated: org.codehaus.plexus.velocity.ContextClassLoaderResourceLoader
[INFO] ClasspathResourceLoader : initialization starting.
[INFO] ClasspathResourceLoader : initialization complete.
[INFO] ResourceCache : initialized. (class org.apache.velocity.runtime.resource.ResourceCacheImpl)
[INFO] Default ResourceManager initialization complete.
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Literal
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Macro
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Parse
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Include
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Foreach
[INFO] Created: 20 parsers.
[INFO] Velocimacro : initialization starting.
[INFO] Velocimacro : adding VMs from VM library template : VM_global_library.vm
[ERROR] ResourceManager : unable to find resource &apos;VM_global_library.vm&apos; in any resource loader.
[INFO] Velocimacro : error using  VM library template VM_global_library.vm : org.apache.velocity.exception.ResourceNotFoundException: Unable to find resource &apos;VM_global_library.vm&apos;
[INFO] Velocimacro :  VM library template macro registration complete.
[INFO] Velocimacro : allowInline = true : VMs can be defined inline in templates
[INFO] Velocimacro : allowInlineToOverride = false : VMs defined inline may NOT replace previous VM definitions
[INFO] Velocimacro : allowInlineLocal = false : VMs defined inline will be  global in scope if allowed.
[INFO] Velocimacro : initialization complete.
[INFO] Velocity successfully started.
Loading source files for package org.apache.hive.hcatalog.templeton...
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/SimpleExceptionMapper.java]
[parsing completed 30ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JsonBuilder.java]
[parsing completed 8ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JobItemBean.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JarDelegator.java]
[parsing completed 11ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/LauncherDelegator.java]
[parsing completed 21ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ExecServiceImpl.java]
[parsing completed 20ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/DeleteDelegator.java]
[parsing completed 8ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ExecBean.java]
[parsing completed 5ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/PigDelegator.java]
[parsing completed 13ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/TempletonDelegator.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/StreamingDelegator.java]
[parsing completed 13ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/DatabaseDesc.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CompleteBean.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HiveDelegator.java]
[parsing completed 19ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/Server.java]
[parsing completed 130ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/BadParam.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ColumnDesc.java]
[parsing completed 2ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/PartitionDesc.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CatchallExceptionMapper.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HcatDelegator.java]
[parsing completed 52ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/StatusDelegator.java]
[parsing completed 3ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/QueueStatusBean.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CompleteDelegator.java]
[parsing completed 13ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/GroupPermissionsDesc.java]
[parsing completed 5ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/AppConfig.java]
[parsing completed 12ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HcatException.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/QueueException.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/TableLikeDesc.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/TableDesc.java]
[parsing completed 12ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/WadlConfig.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/BusyException.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ExecService.java]
[parsing completed 4ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/NotAuthorizedException.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/EnqueueBean.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/SimpleWebException.java]
[parsing completed 6ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ListDelegator.java]
[parsing completed 5ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/Main.java]
[parsing completed 18ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/SecureProxySupport.java]
[parsing completed 10ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/MaxByteArrayOutputStream.java]
[parsing completed 5ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ProxyUserSupport.java]
[parsing completed 13ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/UgiFactory.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CallbackFailedException.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/TablePropertyDesc.java]
[parsing completed 1ms]
Loading source files for package org.apache.hive.hcatalog.templeton.tool...
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/ZooKeeperStorage.java]
[parsing completed 22ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/NullRecordReader.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/PigJobIDParser.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonStorage.java]
[parsing completed 4ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JobIDParser.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JobState.java]
[parsing completed 12ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonUtils.java]
[parsing completed 18ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/HDFSStorage.java]
[parsing completed 25ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/DelegationTokenCache.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JarJobIDParser.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JobSubmissionConstants.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/ZooKeeperCleanup.java]
[parsing completed 6ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JobStateTracker.java]
[parsing completed 6ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/NotFoundException.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/SingleInputFormat.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/LogRetriever.java]
[parsing completed 9ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/NullSplit.java]
[parsing completed 2ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/HDFSCleanup.java]
[parsing completed 6ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java]
[parsing completed 6ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/HiveJobIDParser.java]
[parsing completed 3ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/LaunchMapper.java]
[parsing completed 9ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java]
[parsing completed 2ms]
Constructing Javadoc information...
[search path for source files: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java]
[search path for class files: /usr/java/jdk1.6.0_34/jre/lib/resources.jar,/usr/java/jdk1.6.0_34/jre/lib/rt.jar,/usr/java/jdk1.6.0_34/jre/lib/sunrsasign.jar,/usr/java/jdk1.6.0_34/jre/lib/jsse.jar,/usr/java/jdk1.6.0_34/jre/lib/jce.jar,/usr/java/jdk1.6.0_34/jre/lib/charsets.jar,/usr/java/jdk1.6.0_34/jre/lib/modules/jdk.boot.jar,/usr/java/jdk1.6.0_34/jre/classes,/usr/java/jdk1.6.0_34/jre/lib/ext/localedata.jar,/usr/java/jdk1.6.0_34/jre/lib/ext/sunpkcs11.jar,/usr/java/jdk1.6.0_34/jre/lib/ext/sunjce_provider.jar,/usr/java/jdk1.6.0_34/jre/lib/ext/dnsns.jar,/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes,/data/hive-ptest/working/maven/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar,/data/hive-ptest/working/maven/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar,/data/hive-ptest/working/maven/com/sun/jersey/jersey-json/1.14/jersey-json-1.14.jar,/data/hive-ptest/working/maven/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar,/data/hive-ptest/working/maven/javax/mail/mail/1.4.1/mail-1.4.1.jar,/data/hive-ptest/working/maven/javax/mail/mail/1.4.1/activation.jar,/data/hive-ptest/working/maven/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar,/data/hive-ptest/working/maven/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar,/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/hive-hcatalog-core-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/org/codehaus/jackson/jackson-core-asl/1.9.2/jackson-core-asl-1.9.2.jar,/data/hive-ptest/working/maven/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar,/data/hive-ptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar,/data/hive-ptest/working/maven/xerces/xercesImpl/2.6.1/xercesImpl-2.6.1.jar,/data/hive-ptest/working/maven/antlr/antlr/2.7.7/antlr-2.7.7.jar,/data/hive-ptest/working/maven/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.jar,/data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar,/data/hive-ptest/working/maven/com/sun/jdmk/jmxtools/1.2.1/jmxtools-1.2.1.jar,/data/hive-ptest/working/maven/org/apache/velocity/velocity/1.5/velocity-1.5.jar,/data/hive-ptest/working/maven/com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar,/data/hive-ptest/working/maven/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar,/data/hive-ptest/working/maven/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar,/data/hive-ptest/working/maven/javax/jms/jms/1.1/jms-1.1.jar,/data/hive-ptest/working/maven/commons-lang/commons-lang/2.4/commons-lang-2.4.jar,/data/hive-ptest/working/maven/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar,/data/hive-ptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar,/data/hive-ptest/working/maven/org/apache/commons/commons-math/2.1/commons-math-2.1.jar,/data/hive-ptest/working/maven/org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.jar,/data/hive-ptest/working/maven/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar,/data/hive-ptest/working/maven/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar,/data/hive-ptest/working/maven/org/antlr/ST4/4.0.4/ST4-4.0.4.jar,/data/hive-ptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar,/data/hive-ptest/working/maven/com/google/guava/guava/11.0.2/guava-11.0.2.jar,/data/hive-ptest/working/maven/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar,/data/hive-ptest/working/maven/org/apache/hadoop/hadoop-core/1.2.1/hadoop-core-1.2.1.jar,/data/hive-ptest/working/maven/org/tukaani/xz/1.0/xz-1.0.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar,/data/hive-ptest/working/maven/javax/activation/activation/1.1/activation-1.1.jar,/data/hive-ptest/working/maven/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar,/data/hive-ptest/working/maven/stax/stax-api/1.0.1/stax-api-1.0.1.jar,/data/hive-ptest/working/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar,/data/hive-ptest/working/maven/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar,/data/hive-ptest/working/maven/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar,/data/hive-ptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar,/usr/java/jdk1.6.0_34/jre/../lib/tools.jar,/data/hive-ptest/working/maven/org/apache/ant/ant/1.9.1/ant-1.9.1.jar,/data/hive-ptest/working/maven/io/netty/netty/3.4.0.Final/netty-3.4.0.Final.jar,/data/hive-ptest/working/maven/org/slf4j/jul-to-slf4j/1.6.1/jul-to-slf4j-1.6.1.jar,/data/hive-ptest/working/maven/com/sun/jersey/contribs/wadl-resourcedoc-doclet/1.4/wadl-resourcedoc-doclet-1.4.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar,/data/hive-ptest/working/maven/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar,/data/hive-ptest/working/maven/oro/oro/2.0.8/oro-2.0.8.jar,/data/hive-ptest/working/maven/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar,/data/hive-ptest/working/maven/javax/transaction/jta/1.1/jta-1.1.jar,/data/hive-ptest/working/maven/log4j/log4j/1.2.15/log4j-1.2.15.jar,/data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/org/apache/geronimo/specs/geronimo-annotation_1.0_spec/1.1.1/geronimo-annotation_1.0_spec-1.1.1.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar,/data/hive-ptest/working/maven/org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.jar,/data/hive-ptest/working/maven/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar,/data/hive-ptest/working/maven/com/sun/jersey/jersey-servlet/1.14/jersey-servlet-1.14.jar,/data/hive-ptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar,/data/hive-ptest/working/maven/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar,/data/hive-ptest/working/maven/xmlenc/xmlenc/0.52/xmlenc-0.52.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar,/data/hive-ptest/working/maven/commons-el/commons-el/1.0/commons-el-1.0.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/jline/jline/0.9.94/jline-0.9.94.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar,/data/hive-ptest/working/maven/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar,/data/hive-ptest/working/maven/org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.jar,/data/hive-ptest/working/maven/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar,/data/hive-ptest/working/maven/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar,/data/hive-ptest/working/maven/ant/ant/1.6.5/ant-1.6.5.jar,/data/hive-ptest/working/apache-svn-trunk-source/cli/target/hive-cli-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar,/data/hive-ptest/working/maven/org/codehaus/groovy/groovy-all/2.1.6/groovy-all-2.1.6.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_cs.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_de_DE.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_es.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_fr.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_hu.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_it.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_ja_JP.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_ko_KR.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_pl.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_pt_BR.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_ru.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_zh_CN.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_zh_TW.jar,/data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/asm/asm-commons/3.1/asm-commons-3.1.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-api.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/activation.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jsr173_1.0_api.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb1-impl.jar,/data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar,/data/hive-ptest/working/maven/org/apache/hadoop/hadoop-tools/1.2.1/hadoop-tools-1.2.1.jar,/data/hive-ptest/working/maven/asm/asm-tree/3.1/asm-tree-3.1.jar,/data/hive-ptest/working/maven/com/thoughtworks/paranamer/paranamer/2.2/paranamer-2.2.jar,/data/hive-ptest/working/maven/commons-io/commons-io/2.1/commons-io-2.1.jar,/data/hive-ptest/working/maven/org/codehaus/jackson/jackson-mapper-asl/1.9.2/jackson-mapper-asl-1.9.2.jar,/data/hive-ptest/working/maven/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar,/data/hive-ptest/working/maven/org/apache/avro/avro/1.7.1/avro-1.7.1.jar,/data/hive-ptest/working/maven/commons-digester/commons-digester/1.8/commons-digester-1.8.jar,/data/hive-ptest/working/maven/org/apache/geronimo/specs/geronimo-jaspic_1.0_spec/1.0/geronimo-jaspic_1.0_spec-1.0.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar,/data/hive-ptest/working/maven/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/org/apache/geronimo/specs/geronimo-jta_1.1_spec/1.1.1/geronimo-jta_1.1_spec-1.1.1.jar,/data/hive-ptest/working/maven/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar,/data/hive-ptest/working/maven/com/sun/jmx/jmxri/1.2.1/jmxri-1.2.1.jar,/data/hive-ptest/working/maven/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar,/data/hive-ptest/working/apache-svn-trunk-source/ant/target/hive-ant-0.13.0-SNAPSHOT.jar,/data/hive-ptest/working/maven/asm/asm/3.1/asm-3.1.jar,/data/hive-ptest/working/maven/commons-codec/commons-codec/1.4/commons-codec-1.4.jar]
[loading javax/ws/rs/core/Response.class(javax/ws/rs/core:Response.class)]
[loading javax/ws/rs/ext/ExceptionMapper.class(javax/ws/rs/ext:ExceptionMapper.class)]
[loading javax/ws/rs/ext/Provider.class(javax/ws/rs/ext:Provider.class)]
[loading java/io/IOException.class(java/io:IOException.class)]
[loading java/util/Map.class(java/util:Map.class)]
[loading java/util/HashMap.class(java/util:HashMap.class)]
[loading javax/ws/rs/core/MediaType.class(javax/ws/rs/core:MediaType.class)]
[loading org/codehaus/jackson/map/ObjectMapper.class(org/codehaus/jackson/map:ObjectMapper.class)]
[loading java/lang/Throwable.class(java/lang:Throwable.class)]
[loading java/io/Serializable.class(java/io:Serializable.class)]
[loading java/lang/Object.class(java/lang:Object.class)]
[loading java/lang/String.class(java/lang:String.class)]
[loading java/io/ByteArrayOutputStream.class(java/io:ByteArrayOutputStream.class)]
[loading org/apache/hadoop/hive/ql/ErrorMsg.class(org/apache/hadoop/hive/ql:ErrorMsg.class)]
[loading org/eclipse/jetty/http/HttpStatus.class(org/eclipse/jetty/http:HttpStatus.class)]
[loading java/lang/Integer.class(java/lang:Integer.class)]
[loading org/apache/hadoop/mapred/JobStatus.class(org/apache/hadoop/mapred:JobStatus.class)]
[loading org/apache/hadoop/mapred/JobProfile.class(org/apache/hadoop/mapred:JobProfile.class)]
[loading java/lang/Long.class(java/lang:Long.class)]
[loading java/util/ArrayList.class(java/util:ArrayList.class)]
[loading java/util/List.class(java/util:List.class)]
[loading org/apache/commons/logging/Log.class(org/apache/commons/logging:Log.class)]
[loading org/apache/commons/logging/LogFactory.class(org/apache/commons/logging:LogFactory.class)]
[loading org/apache/hadoop/conf/Configuration.class(org/apache/hadoop/conf:Configuration.class)]
[loading java/lang/Enum.class(java/lang:Enum.class)]
[loading java/lang/Comparable.class(java/lang:Comparable.class)]
[loading java/lang/Exception.class(java/lang:Exception.class)]
[loading java/io/FileNotFoundException.class(java/io:FileNotFoundException.class)]
[loading java/net/URISyntaxException.class(java/net:URISyntaxException.class)]
[loading org/apache/commons/exec/ExecuteException.class(org/apache/commons/exec:ExecuteException.class)]
[loading java/security/PrivilegedExceptionAction.class(java/security:PrivilegedExceptionAction.class)]
[loading org/apache/hadoop/fs/Path.class(org/apache/hadoop/fs:Path.class)]
[loading org/apache/hadoop/hive/conf/HiveConf.class(org/apache/hadoop/hive/conf:HiveConf.class)]
[loading org/apache/hadoop/security/UserGroupInformation.class(org/apache/hadoop/security:UserGroupInformation.class)]
[loading org/apache/hadoop/util/StringUtils.class(org/apache/hadoop/util:StringUtils.class)]
[loading org/apache/hadoop/util/ToolRunner.class(org/apache/hadoop/util:ToolRunner.class)]
[loading java/io/File.class(java/io:File.class)]
[loading java/net/URL.class(java/net:URL.class)]
[loading org/apache/hadoop/util/VersionInfo.class(org/apache/hadoop/util:VersionInfo.class)]
[loading java/lang/Iterable.class(java/lang:Iterable.class)]
[loading org/apache/hadoop/io/Writable.class(org/apache/hadoop/io:Writable.class)]
[loading java/lang/InterruptedException.class(java/lang:InterruptedException.class)]
[loading java/io/BufferedReader.class(java/io:BufferedReader.class)]
[loading java/io/InputStream.class(java/io:InputStream.class)]
[loading java/io/InputStreamReader.class(java/io:InputStreamReader.class)]
[loading java/io/OutputStream.class(java/io:OutputStream.class)]
[loading java/io/PrintWriter.class(java/io:PrintWriter.class)]
[loading java/util/Map$Entry.class(java/util:Map$Entry.class)]
[loading java/util/concurrent/Semaphore.class(java/util/concurrent:Semaphore.class)]
[loading org/apache/commons/exec/CommandLine.class(org/apache/commons/exec:CommandLine.class)]
[loading org/apache/commons/exec/DefaultExecutor.class(org/apache/commons/exec:DefaultExecutor.class)]
[loading org/apache/commons/exec/ExecuteWatchdog.class(org/apache/commons/exec:ExecuteWatchdog.class)]
[loading org/apache/commons/exec/PumpStreamHandler.class(org/apache/commons/exec:PumpStreamHandler.class)]
[loading org/apache/hadoop/util/Shell.class(org/apache/hadoop/util:Shell.class)]
[loading java/lang/Thread.class(java/lang:Thread.class)]
[loading java/lang/Runnable.class(java/lang:Runnable.class)]
[loading org/apache/hadoop/hive/shims/HadoopShims.class(org/apache/hadoop/hive/shims:HadoopShims.class)]
[loading org/apache/hadoop/hive/shims/HadoopShims$WebHCatJTShim.class(org/apache/hadoop/hive/shims:HadoopShims$WebHCatJTShim.class)]
[loading org/apache/hadoop/hive/shims/ShimLoader.class(org/apache/hadoop/hive/shims:ShimLoader.class)]
[loading org/apache/hadoop/mapred/JobID.class(org/apache/hadoop/mapred:JobID.class)]
[loading java/util/Arrays.class(java/util:Arrays.class)]
[loading javax/xml/bind/annotation/XmlRootElement.class(javax/xml/bind/annotation:XmlRootElement.class)]
[loading java/net/InetAddress.class(java/net:InetAddress.class)]
[loading java/net/UnknownHostException.class(java/net:UnknownHostException.class)]
[loading java/text/MessageFormat.class(java/text:MessageFormat.class)]
[loading java/util/Collections.class(java/util:Collections.class)]
[loading java/util/regex/Matcher.class(java/util/regex:Matcher.class)]
[loading java/util/regex/Pattern.class(java/util/regex:Pattern.class)]
[loading javax/servlet/http/HttpServletRequest.class(javax/servlet/http:HttpServletRequest.class)]
[loading javax/ws/rs/DELETE.class(javax/ws/rs:DELETE.class)]
[loading javax/ws/rs/FormParam.class(javax/ws/rs:FormParam.class)]
[loading javax/ws/rs/GET.class(javax/ws/rs:GET.class)]
[loading javax/ws/rs/POST.class(javax/ws/rs:POST.class)]
[loading javax/ws/rs/PUT.class(javax/ws/rs:PUT.class)]
[loading javax/ws/rs/Path.class(javax/ws/rs:Path.class)]
[loading javax/ws/rs/PathParam.class(javax/ws/rs:PathParam.class)]
[loading javax/ws/rs/Produces.class(javax/ws/rs:Produces.class)]
[loading javax/ws/rs/QueryParam.class(javax/ws/rs:QueryParam.class)]
[loading javax/ws/rs/core/Context.class(javax/ws/rs/core:Context.class)]
[loading javax/ws/rs/core/SecurityContext.class(javax/ws/rs/core:SecurityContext.class)]
[loading javax/ws/rs/core/UriInfo.class(javax/ws/rs/core:UriInfo.class)]
[loading org/apache/hadoop/security/authentication/client/PseudoAuthenticator.class(org/apache/hadoop/security/authentication/client:PseudoAuthenticator.class)]
[loading com/sun/jersey/api/NotFoundException.class(com/sun/jersey/api:NotFoundException.class)]
[loading java/net/URI.class(java/net:URI.class)]
[loading org/apache/commons/lang/StringUtils.class(org/apache/commons/lang:StringUtils.class)]
[loading org/apache/hadoop/fs/FileStatus.class(org/apache/hadoop/fs:FileStatus.class)]
[loading org/apache/hadoop/fs/FileSystem.class(org/apache/hadoop/fs:FileSystem.class)]
[loading java/util/Date.class(java/util:Date.class)]
[loading org/apache/hadoop/hive/common/classification/InterfaceAudience.class(org/apache/hadoop/hive/common/classification:InterfaceAudience.class)]
[loading org/apache/hadoop/hive/metastore/HiveMetaStoreClient.class(org/apache/hadoop/hive/metastore:HiveMetaStoreClient.class)]
[loading org/apache/hive/hcatalog/common/HCatUtil.class(org/apache/hive/hcatalog/common:HCatUtil.class)]
[loading org/apache/hadoop/hive/common/classification/InterfaceAudience$Private.class(org/apache/hadoop/hive/common/classification:InterfaceAudience$Private.class)]
[loading com/sun/jersey/api/wadl/config/WadlGeneratorConfig.class(com/sun/jersey/api/wadl/config:WadlGeneratorConfig.class)]
[loading com/sun/jersey/api/wadl/config/WadlGeneratorDescription.class(com/sun/jersey/api/wadl/config:WadlGeneratorDescription.class)]
[loading com/sun/jersey/server/wadl/generators/resourcedoc/WadlGeneratorResourceDocSupport.class(com/sun/jersey/server/wadl/generators/resourcedoc:WadlGeneratorResourceDocSupport.class)]
[loading com/sun/jersey/api/core/PackagesResourceConfig.class(com/sun/jersey/api/core:PackagesResourceConfig.class)]
[loading com/sun/jersey/spi/container/servlet/ServletContainer.class(com/sun/jersey/spi/container/servlet:ServletContainer.class)]
[loading org/apache/hadoop/hive/common/classification/InterfaceStability.class(org/apache/hadoop/hive/common/classification:InterfaceStability.class)]
[loading org/apache/hadoop/hdfs/web/AuthFilter.class(org/apache/hadoop/hdfs/web:AuthFilter.class)]
[loading org/apache/hadoop/util/GenericOptionsParser.class(org/apache/hadoop/util:GenericOptionsParser.class)]
[loading org/eclipse/jetty/rewrite/handler/RedirectPatternRule.class(org/eclipse/jetty/rewrite/handler:RedirectPatternRule.class)]
[loading org/eclipse/jetty/rewrite/handler/RewriteHandler.class(org/eclipse/jetty/rewrite/handler:RewriteHandler.class)]
[loading org/eclipse/jetty/server/Handler.class(org/eclipse/jetty/server:Handler.class)]
[loading org/eclipse/jetty/server/Server.class(org/eclipse/jetty/server:Server.class)]
[loading org/eclipse/jetty/server/handler/HandlerList.class(org/eclipse/jetty/server/handler:HandlerList.class)]
[loading org/eclipse/jetty/servlet/FilterHolder.class(org/eclipse/jetty/servlet:FilterHolder.class)]
[loading org/eclipse/jetty/servlet/FilterMapping.class(org/eclipse/jetty/servlet:FilterMapping.class)]
[loading org/eclipse/jetty/servlet/ServletContextHandler.class(org/eclipse/jetty/servlet:ServletContextHandler.class)]
[loading org/eclipse/jetty/servlet/ServletHolder.class(org/eclipse/jetty/servlet:ServletHolder.class)]
[loading org/slf4j/bridge/SLF4JBridgeHandler.class(org/slf4j/bridge:SLF4JBridgeHandler.class)]
[loading org/apache/hadoop/hive/common/classification/InterfaceAudience$LimitedPrivate.class(org/apache/hadoop/hive/common/classification:InterfaceAudience$LimitedPrivate.class)]
[loading org/apache/hadoop/hive/common/classification/InterfaceStability$Unstable.class(org/apache/hadoop/hive/common/classification:InterfaceStability$Unstable.class)]
[loading org/apache/hadoop/hive/metastore/api/MetaException.class(org/apache/hadoop/hive/metastore/api:MetaException.class)]
[loading org/apache/hadoop/io/Text.class(org/apache/hadoop/io:Text.class)]
[loading org/apache/hadoop/security/Credentials.class(org/apache/hadoop/security:Credentials.class)]
[loading org/apache/hadoop/security/token/Token.class(org/apache/hadoop/security/token:Token.class)]
[loading org/apache/thrift/TException.class(org/apache/thrift:TException.class)]
[loading java/io/Closeable.class(java/io:Closeable.class)]
[loading java/io/Flushable.class(java/io:Flushable.class)]
[loading org/apache/hadoop/security/Groups.class(org/apache/hadoop/security:Groups.class)]
[loading java/util/HashSet.class(java/util:HashSet.class)]
[loading java/util/Set.class(java/util:Set.class)]
[loading java/util/concurrent/ConcurrentHashMap.class(java/util/concurrent:ConcurrentHashMap.class)]
[loading java/io/UnsupportedEncodingException.class(java/io:UnsupportedEncodingException.class)]
[loading org/apache/zookeeper/CreateMode.class(org/apache/zookeeper:CreateMode.class)]
[loading org/apache/zookeeper/KeeperException.class(org/apache/zookeeper:KeeperException.class)]
[loading org/apache/zookeeper/WatchedEvent.class(org/apache/zookeeper:WatchedEvent.class)]
[loading org/apache/zookeeper/Watcher.class(org/apache/zookeeper:Watcher.class)]
[loading org/apache/zookeeper/ZooDefs.class(org/apache/zookeeper:ZooDefs.class)]
[loading org/apache/zookeeper/ZooDefs$Ids.class(org/apache/zookeeper:ZooDefs$Ids.class)]
[loading org/apache/zookeeper/ZooKeeper.class(org/apache/zookeeper:ZooKeeper.class)]
[loading org/apache/hadoop/io/NullWritable.class(org/apache/hadoop/io:NullWritable.class)]
[loading org/apache/hadoop/mapreduce/InputSplit.class(org/apache/hadoop/mapreduce:InputSplit.class)]
[loading org/apache/hadoop/mapreduce/RecordReader.class(org/apache/hadoop/mapreduce:RecordReader.class)]
[loading org/apache/hadoop/mapreduce/TaskAttemptContext.class(org/apache/hadoop/mapreduce:TaskAttemptContext.class)]
[loading java/net/URLConnection.class(java/net:URLConnection.class)]
[loading java/util/Collection.class(java/util:Collection.class)]
[loading javax/ws/rs/core/UriBuilder.class(javax/ws/rs/core:UriBuilder.class)]
[loading java/io/OutputStreamWriter.class(java/io:OutputStreamWriter.class)]
[loading org/apache/hadoop/hive/common/classification/InterfaceStability$Evolving.class(org/apache/hadoop/hive/common/classification:InterfaceStability$Evolving.class)]
[loading org/apache/zookeeper/data/Stat.class(org/apache/zookeeper/data:Stat.class)]
[loading org/apache/hadoop/mapreduce/InputFormat.class(org/apache/hadoop/mapreduce:InputFormat.class)]
[loading org/apache/hadoop/mapreduce/JobContext.class(org/apache/hadoop/mapreduce:JobContext.class)]
[loading org/apache/hadoop/mapred/JobClient.class(org/apache/hadoop/mapred:JobClient.class)]
[loading org/apache/hadoop/mapred/JobConf.class(org/apache/hadoop/mapred:JobConf.class)]
[loading org/apache/hadoop/mapred/RunningJob.class(org/apache/hadoop/mapred:RunningJob.class)]
[loading java/io/DataInput.class(java/io:DataInput.class)]
[loading java/io/DataOutput.class(java/io:DataOutput.class)]
[loading org/apache/hadoop/conf/Configured.class(org/apache/hadoop/conf:Configured.class)]
[loading org/apache/hadoop/fs/permission/FsPermission.class(org/apache/hadoop/fs/permission:FsPermission.class)]
[loading org/apache/hadoop/mapreduce/Job.class(org/apache/hadoop/mapreduce:Job.class)]
[loading org/apache/hadoop/mapreduce/JobID.class(org/apache/hadoop/mapreduce:JobID.class)]
[loading org/apache/hadoop/mapreduce/lib/output/NullOutputFormat.class(org/apache/hadoop/mapreduce/lib/output:NullOutputFormat.class)]
[loading org/apache/hadoop/mapreduce/security/token/delegation/DelegationTokenIdentifier.class(org/apache/hadoop/mapreduce/security/token/delegation:DelegationTokenIdentifier.class)]
[loading org/apache/hadoop/util/Tool.class(org/apache/hadoop/util:Tool.class)]
[loading org/apache/hadoop/conf/Configurable.class(org/apache/hadoop/conf:Configurable.class)]
[loading java/lang/ClassNotFoundException.class(java/lang:ClassNotFoundException.class)]
[loading org/apache/hadoop/mapreduce/Mapper.class(org/apache/hadoop/mapreduce:Mapper.class)]
[loading java/util/Iterator.class(java/util:Iterator.class)]
[loading java/util/LinkedList.class(java/util:LinkedList.class)]
[loading java/util/concurrent/ExecutorService.class(java/util/concurrent:ExecutorService.class)]
[loading java/util/concurrent/Executors.class(java/util/concurrent:Executors.class)]
[loading java/util/concurrent/TimeUnit.class(java/util/concurrent:TimeUnit.class)]
[loading org/apache/hadoop/mapreduce/Mapper$Context.class(org/apache/hadoop/mapreduce:Mapper$Context.class)]
[loading java/lang/Process.class(java/lang:Process.class)]
[loading java/lang/StringBuilder.class(java/lang:StringBuilder.class)]
[loading java/lang/ProcessBuilder.class(java/lang:ProcessBuilder.class)]
[loading java/lang/annotation/Target.class(java/lang/annotation:Target.class)]
[loading java/lang/annotation/ElementType.class(java/lang/annotation:ElementType.class)]
[loading java/lang/annotation/Retention.class(java/lang/annotation:Retention.class)]
[loading java/lang/annotation/RetentionPolicy.class(java/lang/annotation:RetentionPolicy.class)]
[loading java/lang/annotation/Annotation.class(java/lang/annotation:Annotation.class)]
[loading java/lang/SuppressWarnings.class(java/lang:SuppressWarnings.class)]
[loading java/lang/Override.class(java/lang:Override.class)]
[loading javax/ws/rs/HttpMethod.class(javax/ws/rs:HttpMethod.class)]
[loading java/lang/Deprecated.class(java/lang:Deprecated.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$3.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/HcatDelegator$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/LauncherDelegator$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$2.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/HcatException$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$2.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$2$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/ZooKeeperStorage$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/LogRetriever$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/ZooKeeperStorage$2.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonUtils$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/HDFSStorage$1.class]
[done in 7291 ms]
[WARNING] Javadoc Warnings
[WARNING] Nov 11, 2013 4:27:06 PM com.sun.jersey.wadl.resourcedoc.ResourceDoclet start
[WARNING] INFO: Wrote /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/resourcedoc.xml
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-webhcat ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-webhcat ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-webhcat ---
[INFO] Compiling 9 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/test-classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/test/java/org/apache/hive/hcatalog/templeton/TestDesc.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-webhcat ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-webhcat ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/hive-webhcat-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-webhcat ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/hive-webhcat-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-webhcat/0.13.0-SNAPSHOT/hive-webhcat-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-webhcat/0.13.0-SNAPSHOT/hive-webhcat-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog HBase Storage Handler 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hbase-storage-handler ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-hbase-storage-handler ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/src/gen-java added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hbase-storage-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hbase-storage-handler ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hbase-storage-handler ---
[INFO] Compiling 35 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hbase-storage-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hbase-storage-handler ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hbase-storage-handler ---
[INFO] Compiling 21 source files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hbase-storage-handler ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hbase-storage-handler ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/hive-hbase-storage-handler-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-hbase-storage-handler ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/hive-hbase-storage-handler-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hbase-storage-handler ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/hive-hbase-storage-handler-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hbase-storage-handler/0.13.0-SNAPSHOT/hive-hbase-storage-handler-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hbase-storage-handler/0.13.0-SNAPSHOT/hive-hbase-storage-handler-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/hive-hbase-storage-handler-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hcatalog/hive-hbase-storage-handler/0.13.0-SNAPSHOT/hive-hbase-storage-handler-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HWI 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-hwi ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/hwi (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hwi ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hwi ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hwi ---
[INFO] Compiling 6 source files to /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hwi ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hwi ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hwi ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hwi ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hwi ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/hive-hwi-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hwi ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/hive-hwi-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hwi/0.13.0-SNAPSHOT/hive-hwi-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/hwi/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-hwi/0.13.0-SNAPSHOT/hive-hwi-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive ODBC 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-odbc ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/odbc (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-odbc ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-odbc ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-odbc ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/odbc/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-odbc/0.13.0-SNAPSHOT/hive-odbc-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Aggregator 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-aggregator ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-aggregator ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-aggregator ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-aggregator ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-shims-aggregator/0.13.0-SNAPSHOT/hive-shims-aggregator-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive TestUtils 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-testutils ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/testutils (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-testutils ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-testutils ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-testutils ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-testutils ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-testutils ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-testutils ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-testutils ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-testutils ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/hive-testutils-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-testutils ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/hive-testutils-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-testutils/0.13.0-SNAPSHOT/hive-testutils-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/testutils/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-testutils/0.13.0-SNAPSHOT/hive-testutils-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Packaging 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-packaging ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/packaging (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-packaging ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-packaging ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-packaging ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/packaging/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-packaging/0.13.0-SNAPSHOT/hive-packaging-0.13.0-SNAPSHOT.pom
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [2.844s]
[INFO] Hive Ant Utilities ................................ SUCCESS [7.022s]
[INFO] Hive Shims Common ................................. SUCCESS [3.186s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [1.754s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [3.194s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [1.310s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [3.845s]
[INFO] Hive Shims ........................................ SUCCESS [3.250s]
[INFO] Hive Common ....................................... SUCCESS [8.878s]
[INFO] Hive Serde ........................................ SUCCESS [11.298s]
[INFO] Hive Metastore .................................... SUCCESS [22.615s]
[INFO] Hive Query Language ............................... SUCCESS [50.980s]
[INFO] Hive Service ...................................... SUCCESS [5.724s]
[INFO] Hive JDBC ......................................... SUCCESS [1.125s]
[INFO] Hive Beeline ...................................... SUCCESS [1.381s]
[INFO] Hive CLI .......................................... SUCCESS [1.730s]
[INFO] Hive Contrib ...................................... SUCCESS [1.698s]
[INFO] Hive HBase Handler ................................ SUCCESS [1.236s]
[INFO] Hive HCatalog ..................................... SUCCESS [0.222s]
[INFO] Hive HCatalog Core ................................ SUCCESS [2.758s]
[INFO] Hive HCatalog Pig Adapter ......................... SUCCESS [0.954s]
[INFO] Hive HCatalog Server Extensions ................... SUCCESS [0.828s]
[INFO] Hive HCatalog Webhcat Java Client ................. SUCCESS [0.646s]
[INFO] Hive HCatalog Webhcat ............................. SUCCESS [10.384s]
[INFO] Hive HCatalog HBase Storage Handler ............... SUCCESS [1.870s]
[INFO] Hive HWI .......................................... SUCCESS [0.761s]
[INFO] Hive ODBC ......................................... SUCCESS [0.330s]
[INFO] Hive Shims Aggregator ............................. SUCCESS [0.236s]
[INFO] Hive TestUtils .................................... SUCCESS [0.225s]
[INFO] Hive Packaging .................................... SUCCESS [0.379s]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 2:34.842s
[INFO] Finished at: Mon Nov 11 16:27:11 EST 2013
[INFO] Final Memory: 72M/425M
[INFO] ------------------------------------------------------------------------
+ mvn -B test -Dmaven.repo.local=/data/hive-ptest/working/maven -Dtest=TestDummy
[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Hive
[INFO] Hive Ant Utilities
[INFO] Hive Shims Common
[INFO] Hive Shims 0.20
[INFO] Hive Shims Secure Common
[INFO] Hive Shims 0.20S
[INFO] Hive Shims 0.23
[INFO] Hive Shims
[INFO] Hive Common
[INFO] Hive Serde
[INFO] Hive Metastore
[INFO] Hive Query Language
[INFO] Hive Service
[INFO] Hive JDBC
[INFO] Hive Beeline
[INFO] Hive CLI
[INFO] Hive Contrib
[INFO] Hive HBase Handler
[INFO] Hive HCatalog
[INFO] Hive HCatalog Core
[INFO] Hive HCatalog Pig Adapter
[INFO] Hive HCatalog Server Extensions
[INFO] Hive HCatalog Webhcat Java Client
[INFO] Hive HCatalog Webhcat
[INFO] Hive HCatalog HBase Storage Handler
[INFO] Hive HWI
[INFO] Hive ODBC
[INFO] Hive Shims Aggregator
[INFO] Hive TestUtils
[INFO] Hive Packaging
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf
[INFO] Executed tasks
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Ant Utilities 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-ant ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-ant ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-ant ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-ant ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-ant ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/ant/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-ant ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-ant ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.20 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20 ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20 ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20 ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Secure Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common-secure ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common-secure ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common-secure ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common-secure ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common-secure ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common-secure ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common-secure ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.20S 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20S ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20S ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20S ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20S ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20S ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20S ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20S ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.23 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.23 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.23 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.23 ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.23 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.23 ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.23 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.23 ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-version-annotation) @ hive-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-common ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/common/src/gen added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-common ---
[INFO] Compiling 1 source file to /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-common ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-common ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-common ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Serde 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-serde ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/protobuf/gen-java added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-serde ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-serde ---
[INFO] Compiling 1 source file to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-serde ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/serde/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-serde ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-serde ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Metastore 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-metastore ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/model added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-metastore ---
[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java
ANTLR Parser Generator  Version 3.4
Grammar /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java/org/apache/hadoop/hive/metastore/parser/Filter.g is up to date - build skipped
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-metastore ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-metastore ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-metastore ---
[INFO] Compiling 1 source file to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes
[INFO] 
[INFO] --- datanucleus-maven-plugin:3.3.0-release:enhance (default) @ hive-metastore ---
[INFO] DataNucleus Enhancer (version 3.2.2) for API &quot;JDO&quot; using JRE &quot;1.6&quot;
DataNucleus Enhancer : Classpath
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-maven-plugin/3.3.0-release/datanucleus-maven-plugin-3.3.0-release.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-utils/3.0.8/plexus-utils-3.0.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-component-annotations/1.5.5/plexus-component-annotations-1.5.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-inject-bean/2.3.0/sisu-inject-bean-2.3.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guice/3.1.0/sisu-guice-3.1.0-no_aop.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guava/0.9.9/sisu-guava-0.9.9.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/xbean/xbean-reflect/3.4/xbean-reflect-3.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/log4j/log4j/1.2.12/log4j-1.2.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-logging/commons-logging-api/1.1/commons-logging-api-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/collections/google-collections/1.0/google-collections-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/junit/junit/3.8.2/junit-3.8.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/serde/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/tukaani/xz/1.0/xz-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-codec/commons-codec/1.4/commons-codec-1.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/avro/avro/1.7.1/avro-1.7.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/jline/jline/0.9.94/jline-0.9.94.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/guava/guava/11.0.2/guava-11.0.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-lang/commons-lang/2.4/commons-lang-2.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/transaction/jta/1.1/jta-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/antlr/antlr/2.7.7/antlr-2.7.7.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/hadoop/hadoop-core/1.2.1/hadoop-core-1.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/xmlenc/xmlenc/0.52/xmlenc-0.52.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/stax/stax-api/1.0.1/stax-api-1.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/activation/activation/1.1/activation-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-jaxrs/1.7.1/jackson-jaxrs-1.7.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/asm/asm/3.1/asm-3.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-io/commons-io/2.1/commons-io-2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/commons/commons-math/2.1/commons-math-2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-digester/commons-digester/1.8/commons-digester-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/ant/ant/1.6.5/ant-1.6.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-el/commons-el/1.0/commons-el-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/oro/oro/2.0.8/oro-2.0.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/log4j/log4j/1.2.16/log4j-1.2.16.jar
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDatabase
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFieldSchema
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MType
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTable
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MOrder
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStringList
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartition
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MIndex
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRole
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRoleMap
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MMasterKey
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDelegationToken
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MVersionTable
DataNucleus Enhancer completed with success for 25 classes. Timings : input=728 ms, enhance=325 ms, total=1053 ms. Consult the log for full details

[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-metastore ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-metastore ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-metastore ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-metastore ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Query Language 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-sources) @ hive-exec ---
[INFO] Executing tasks

main:
Generating vector expression code
Generating vector expression test code
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-exec ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/protobuf/gen-java added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-sources/java added.
[INFO] 
[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-exec ---
[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java
ANTLR Parser Generator  Version 3.4
Grammar /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g is up to date - build skipped
Grammar /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g is up to date - build skipped
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-exec ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 6 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-test-source (add-test-sources) @ hive-exec ---
[INFO] Test Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-test-sources/java added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-exec ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-exec ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/ql/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/ql/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-exec ---
[INFO] Compiling 4 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-exec ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Service 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-service ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/service/src/model added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/service/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-service ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/service/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-service ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-service ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-service ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-service ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/service/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-service ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-service ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive JDBC 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-jdbc ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-jdbc ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-jdbc ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-jdbc ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-jdbc ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-jdbc ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-jdbc ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Beeline 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-beeline ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-beeline ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-beeline ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-beeline ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/beeline/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-beeline ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/beeline/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-beeline ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-beeline ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive CLI 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-cli ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/cli/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-cli ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-cli ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-cli ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/cli/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-cli ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/cli/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/cli/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/cli/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/cli/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-cli ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-cli ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Contrib 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-contrib ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-contrib ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-contrib ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-contrib ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/contrib/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-contrib ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/contrib/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-contrib ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-contrib ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HBase Handler 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hbase-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hbase-handler ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hbase-handler ---
[INFO] Compiling 1 source file to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hbase-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hbase-handler ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hbase-handler/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hbase-handler ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hbase-handler ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/target/tmp/conf
[INFO] Executed tasks
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Core 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hcatalog-core ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-core ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-core ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hcatalog-core ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog-core ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hcatalog-core ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hcatalog-core ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Pig Adapter 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hcatalog-pig-adapter ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-pig-adapter ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-pig-adapter ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hcatalog-pig-adapter ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog-pig-adapter ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/hcatalog-pig-adapter/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hcatalog-pig-adapter ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hcatalog-pig-adapter ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Server Extensions 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hcatalog-server-extensions ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hcatalog-server-extensions ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hcatalog-server-extensions ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hcatalog-server-extensions ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hcatalog-server-extensions ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/server-extensions/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hcatalog-server-extensions ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hcatalog-server-extensions ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Webhcat Java Client 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-webhcat-java-client ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-webhcat-java-client ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-webhcat-java-client ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-webhcat-java-client ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-webhcat-java-client ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/java-client/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-webhcat-java-client ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-webhcat-java-client ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog Webhcat 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-webhcat ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-webhcat ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-webhcat ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-javadoc-plugin:2.4:javadoc (resourcesdoc.xml) @ hive-webhcat ---
[INFO] Setting property: classpath.resource.loader.class =&amp;gt; &apos;org.codehaus.plexus.velocity.ContextClassLoaderResourceLoader&apos;.
[INFO] Setting property: velocimacro.messages.on =&amp;gt; &apos;false&apos;.
[INFO] Setting property: resource.loader =&amp;gt; &apos;classpath&apos;.
[INFO] Setting property: resource.manager.logwhenfound =&amp;gt; &apos;false&apos;.
[INFO] ************************************************************** 
[INFO] Starting Jakarta Velocity v1.4
[INFO] RuntimeInstance initializing.
[INFO] Default Properties File: org/apache/velocity/runtime/defaults/velocity.properties
[INFO] Default ResourceManager initializing. (class org.apache.velocity.runtime.resource.ResourceManagerImpl)
[INFO] Resource Loader Instantiated: org.codehaus.plexus.velocity.ContextClassLoaderResourceLoader
[INFO] ClasspathResourceLoader : initialization starting.
[INFO] ClasspathResourceLoader : initialization complete.
[INFO] ResourceCache : initialized. (class org.apache.velocity.runtime.resource.ResourceCacheImpl)
[INFO] Default ResourceManager initialization complete.
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Literal
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Macro
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Parse
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Include
[INFO] Loaded System Directive: org.apache.velocity.runtime.directive.Foreach
[INFO] Created: 20 parsers.
[INFO] Velocimacro : initialization starting.
[INFO] Velocimacro : adding VMs from VM library template : VM_global_library.vm
[ERROR] ResourceManager : unable to find resource &apos;VM_global_library.vm&apos; in any resource loader.
[INFO] Velocimacro : error using  VM library template VM_global_library.vm : org.apache.velocity.exception.ResourceNotFoundException: Unable to find resource &apos;VM_global_library.vm&apos;
[INFO] Velocimacro :  VM library template macro registration complete.
[INFO] Velocimacro : allowInline = true : VMs can be defined inline in templates
[INFO] Velocimacro : allowInlineToOverride = false : VMs defined inline may NOT replace previous VM definitions
[INFO] Velocimacro : allowInlineLocal = false : VMs defined inline will be  global in scope if allowed.
[INFO] Velocimacro : initialization complete.
[INFO] Velocity successfully started.
Loading source files for package org.apache.hive.hcatalog.templeton...
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/SimpleExceptionMapper.java]
[parsing completed 29ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JsonBuilder.java]
[parsing completed 7ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JobItemBean.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JarDelegator.java]
[parsing completed 11ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/LauncherDelegator.java]
[parsing completed 21ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ExecServiceImpl.java]
[parsing completed 20ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/DeleteDelegator.java]
[parsing completed 5ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ExecBean.java]
[parsing completed 9ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/PigDelegator.java]
[parsing completed 15ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/TempletonDelegator.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/StreamingDelegator.java]
[parsing completed 11ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/DatabaseDesc.java]
[parsing completed 5ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CompleteBean.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HiveDelegator.java]
[parsing completed 18ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/Server.java]
[parsing completed 125ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/BadParam.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ColumnDesc.java]
[parsing completed 4ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/PartitionDesc.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CatchallExceptionMapper.java]
[parsing completed 3ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HcatDelegator.java]
[parsing completed 42ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/StatusDelegator.java]
[parsing completed 13ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/QueueStatusBean.java]
[parsing completed 2ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CompleteDelegator.java]
[parsing completed 10ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/GroupPermissionsDesc.java]
[parsing completed 3ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/AppConfig.java]
[parsing completed 18ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HcatException.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/QueueException.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/TableLikeDesc.java]
[parsing completed 4ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/TableDesc.java]
[parsing completed 8ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/WadlConfig.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/BusyException.java]
[parsing completed 4ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ExecService.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/NotAuthorizedException.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/EnqueueBean.java]
[parsing completed 4ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/SimpleWebException.java]
[parsing completed 2ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ListDelegator.java]
[parsing completed 5ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/Main.java]
[parsing completed 13ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/SecureProxySupport.java]
[parsing completed 8ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/MaxByteArrayOutputStream.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ProxyUserSupport.java]
[parsing completed 7ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/UgiFactory.java]
[parsing completed 3ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/CallbackFailedException.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/TablePropertyDesc.java]
[parsing completed 0ms]
Loading source files for package org.apache.hive.hcatalog.templeton.tool...
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/ZooKeeperStorage.java]
[parsing completed 17ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/NullRecordReader.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/PigJobIDParser.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonStorage.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JobIDParser.java]
[parsing completed 4ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JobState.java]
[parsing completed 11ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonUtils.java]
[parsing completed 18ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/HDFSStorage.java]
[parsing completed 12ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/DelegationTokenCache.java]
[parsing completed 4ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JarJobIDParser.java]
[parsing completed 13ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JobSubmissionConstants.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/ZooKeeperCleanup.java]
[parsing completed 3ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JobStateTracker.java]
[parsing completed 3ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/NotFoundException.java]
[parsing completed 1ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/SingleInputFormat.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/LogRetriever.java]
[parsing completed 11ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/NullSplit.java]
[parsing completed 2ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/HDFSCleanup.java]
[parsing completed 7ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java]
[parsing completed 6ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/HiveJobIDParser.java]
[parsing completed 0ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/LaunchMapper.java]
[parsing completed 14ms]
[parsing started /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java]
[parsing completed 1ms]
Constructing Javadoc information...
[search path for source files: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/main/java]
[search path for class files: /usr/java/jdk1.6.0_34/jre/lib/resources.jar,/usr/java/jdk1.6.0_34/jre/lib/rt.jar,/usr/java/jdk1.6.0_34/jre/lib/sunrsasign.jar,/usr/java/jdk1.6.0_34/jre/lib/jsse.jar,/usr/java/jdk1.6.0_34/jre/lib/jce.jar,/usr/java/jdk1.6.0_34/jre/lib/charsets.jar,/usr/java/jdk1.6.0_34/jre/lib/modules/jdk.boot.jar,/usr/java/jdk1.6.0_34/jre/classes,/usr/java/jdk1.6.0_34/jre/lib/ext/localedata.jar,/usr/java/jdk1.6.0_34/jre/lib/ext/sunpkcs11.jar,/usr/java/jdk1.6.0_34/jre/lib/ext/sunjce_provider.jar,/usr/java/jdk1.6.0_34/jre/lib/ext/dnsns.jar,/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes,/data/hive-ptest/working/maven/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar,/data/hive-ptest/working/maven/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar,/data/hive-ptest/working/maven/com/sun/jersey/jersey-json/1.14/jersey-json-1.14.jar,/data/hive-ptest/working/maven/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar,/data/hive-ptest/working/maven/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/classes,/data/hive-ptest/working/maven/javax/mail/mail/1.4.1/mail-1.4.1.jar,/data/hive-ptest/working/maven/javax/mail/mail/1.4.1/activation.jar,/data/hive-ptest/working/maven/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar,/data/hive-ptest/working/maven/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar,/data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/classes,/data/hive-ptest/working/maven/org/codehaus/jackson/jackson-core-asl/1.9.2/jackson-core-asl-1.9.2.jar,/data/hive-ptest/working/maven/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar,/data/hive-ptest/working/maven/org/eclipse/jetty/aggregate/jetty-all-server/7.6.0.v20120127/jetty-all-server-7.6.0.v20120127.jar,/data/hive-ptest/working/maven/xerces/xercesImpl/2.6.1/xercesImpl-2.6.1.jar,/data/hive-ptest/working/maven/antlr/antlr/2.7.7/antlr-2.7.7.jar,/data/hive-ptest/working/maven/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar,/data/hive-ptest/working/maven/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/classes,/data/hive-ptest/working/maven/org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.jar,/data/hive-ptest/working/apache-svn-trunk-source/serde/target/classes,/data/hive-ptest/working/maven/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar,/data/hive-ptest/working/maven/com/sun/jdmk/jmxtools/1.2.1/jmxtools-1.2.1.jar,/data/hive-ptest/working/maven/org/apache/velocity/velocity/1.5/velocity-1.5.jar,/data/hive-ptest/working/maven/com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar,/data/hive-ptest/working/maven/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar,/data/hive-ptest/working/maven/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar,/data/hive-ptest/working/maven/javax/jms/jms/1.1/jms-1.1.jar,/data/hive-ptest/working/maven/commons-lang/commons-lang/2.4/commons-lang-2.4.jar,/data/hive-ptest/working/maven/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar,/data/hive-ptest/working/maven/com/sun/jersey/jersey-core/1.14/jersey-core-1.14.jar,/data/hive-ptest/working/maven/org/apache/commons/commons-math/2.1/commons-math-2.1.jar,/data/hive-ptest/working/maven/org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.jar,/data/hive-ptest/working/maven/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar,/data/hive-ptest/working/maven/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar,/data/hive-ptest/working/maven/org/antlr/ST4/4.0.4/ST4-4.0.4.jar,/data/hive-ptest/working/maven/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar,/data/hive-ptest/working/maven/com/google/guava/guava/11.0.2/guava-11.0.2.jar,/data/hive-ptest/working/maven/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar,/data/hive-ptest/working/maven/org/apache/hadoop/hadoop-core/1.2.1/hadoop-core-1.2.1.jar,/data/hive-ptest/working/maven/org/tukaani/xz/1.0/xz-1.0.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar,/data/hive-ptest/working/maven/javax/activation/activation/1.1/activation-1.1.jar,/data/hive-ptest/working/maven/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar,/data/hive-ptest/working/maven/stax/stax-api/1.0.1/stax-api-1.0.1.jar,/data/hive-ptest/working/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar,/data/hive-ptest/working/maven/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar,/data/hive-ptest/working/maven/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar,/data/hive-ptest/working/maven/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar,/data/hive-ptest/working/maven/com/sun/jersey/jersey-server/1.14/jersey-server-1.14.jar,/usr/java/jdk1.6.0_34/jre/../lib/tools.jar,/data/hive-ptest/working/maven/org/apache/ant/ant/1.9.1/ant-1.9.1.jar,/data/hive-ptest/working/maven/io/netty/netty/3.4.0.Final/netty-3.4.0.Final.jar,/data/hive-ptest/working/maven/org/slf4j/jul-to-slf4j/1.6.1/jul-to-slf4j-1.6.1.jar,/data/hive-ptest/working/maven/com/sun/jersey/contribs/wadl-resourcedoc-doclet/1.4/wadl-resourcedoc-doclet-1.4.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar,/data/hive-ptest/working/maven/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar,/data/hive-ptest/working/maven/oro/oro/2.0.8/oro-2.0.8.jar,/data/hive-ptest/working/maven/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/classes,/data/hive-ptest/working/maven/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar,/data/hive-ptest/working/maven/javax/transaction/jta/1.1/jta-1.1.jar,/data/hive-ptest/working/maven/log4j/log4j/1.2.15/log4j-1.2.15.jar,/data/hive-ptest/working/apache-svn-trunk-source/common/target/classes,/data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes,/data/hive-ptest/working/maven/org/apache/geronimo/specs/geronimo-annotation_1.0_spec/1.1.1/geronimo-annotation_1.0_spec-1.1.1.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar,/data/hive-ptest/working/maven/org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.jar,/data/hive-ptest/working/maven/javolution/javolution/5.5.1/javolution-5.5.1.jar,/data/hive-ptest/working/maven/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar,/data/hive-ptest/working/maven/com/sun/jersey/jersey-servlet/1.14/jersey-servlet-1.14.jar,/data/hive-ptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar,/data/hive-ptest/working/maven/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar,/data/hive-ptest/working/maven/xmlenc/xmlenc/0.52/xmlenc-0.52.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar,/data/hive-ptest/working/maven/commons-el/commons-el/1.0/commons-el-1.0.jar,/data/hive-ptest/working/maven/com/esotericsoftware/kryo/kryo/2.22/kryo-2.22.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/classes,/data/hive-ptest/working/maven/jline/jline/0.9.94/jline-0.9.94.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar,/data/hive-ptest/working/maven/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar,/data/hive-ptest/working/maven/org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.jar,/data/hive-ptest/working/maven/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar,/data/hive-ptest/working/maven/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar,/data/hive-ptest/working/maven/ant/ant/1.6.5/ant-1.6.5.jar,/data/hive-ptest/working/apache-svn-trunk-source/cli/target/classes,/data/hive-ptest/working/maven/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar,/data/hive-ptest/working/maven/org/codehaus/groovy/groovy-all/2.1.6/groovy-all-2.1.6.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_cs.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_de_DE.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_es.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_fr.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_hu.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_it.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_ja_JP.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_ko_KR.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_pl.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_pt_BR.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_ru.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_zh_CN.jar,/data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derbyLocale_zh_TW.jar,/data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes,/data/hive-ptest/working/maven/asm/asm-commons/3.1/asm-commons-3.1.jar,/data/hive-ptest/working/maven/org/iq80/snappy/snappy/0.2/snappy-0.2.jar,/data/hive-ptest/working/apache-svn-trunk-source/service/target/classes,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-api.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/activation.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jsr173_1.0_api.jar,/data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb1-impl.jar,/data/hive-ptest/working/maven/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar,/data/hive-ptest/working/maven/org/apache/hadoop/hadoop-tools/1.2.1/hadoop-tools-1.2.1.jar,/data/hive-ptest/working/maven/asm/asm-tree/3.1/asm-tree-3.1.jar,/data/hive-ptest/working/maven/com/thoughtworks/paranamer/paranamer/2.2/paranamer-2.2.jar,/data/hive-ptest/working/maven/commons-io/commons-io/2.1/commons-io-2.1.jar,/data/hive-ptest/working/maven/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar,/data/hive-ptest/working/maven/org/codehaus/jackson/jackson-mapper-asl/1.9.2/jackson-mapper-asl-1.9.2.jar,/data/hive-ptest/working/maven/org/apache/avro/avro/1.7.1/avro-1.7.1.jar,/data/hive-ptest/working/maven/commons-digester/commons-digester/1.8/commons-digester-1.8.jar,/data/hive-ptest/working/maven/org/apache/geronimo/specs/geronimo-jaspic_1.0_spec/1.0/geronimo-jaspic_1.0_spec-1.0.jar,/data/hive-ptest/working/maven/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar,/data/hive-ptest/working/maven/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/classes,/data/hive-ptest/working/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar,/data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/classes,/data/hive-ptest/working/maven/org/apache/geronimo/specs/geronimo-jta_1.1_spec/1.1.1/geronimo-jta_1.1_spec-1.1.1.jar,/data/hive-ptest/working/maven/org/json/json/20090211/json-20090211.jar,/data/hive-ptest/working/maven/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar,/data/hive-ptest/working/maven/com/sun/jmx/jmxri/1.2.1/jmxri-1.2.1.jar,/data/hive-ptest/working/maven/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar,/data/hive-ptest/working/apache-svn-trunk-source/ant/target/classes,/data/hive-ptest/working/maven/asm/asm/3.1/asm-3.1.jar,/data/hive-ptest/working/maven/commons-codec/commons-codec/1.4/commons-codec-1.4.jar]
[loading javax/ws/rs/core/Response.class(javax/ws/rs/core:Response.class)]
[loading javax/ws/rs/ext/ExceptionMapper.class(javax/ws/rs/ext:ExceptionMapper.class)]
[loading javax/ws/rs/ext/Provider.class(javax/ws/rs/ext:Provider.class)]
[loading java/io/IOException.class(java/io:IOException.class)]
[loading java/util/Map.class(java/util:Map.class)]
[loading java/util/HashMap.class(java/util:HashMap.class)]
[loading javax/ws/rs/core/MediaType.class(javax/ws/rs/core:MediaType.class)]
[loading org/codehaus/jackson/map/ObjectMapper.class(org/codehaus/jackson/map:ObjectMapper.class)]
[loading java/lang/Throwable.class(java/lang:Throwable.class)]
[loading java/io/Serializable.class(java/io:Serializable.class)]
[loading java/lang/Object.class(java/lang:Object.class)]
[loading java/lang/String.class(java/lang:String.class)]
[loading java/io/ByteArrayOutputStream.class(java/io:ByteArrayOutputStream.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes/org/apache/hadoop/hive/ql/ErrorMsg.class]
[loading org/eclipse/jetty/http/HttpStatus.class(org/eclipse/jetty/http:HttpStatus.class)]
[loading java/lang/Integer.class(java/lang:Integer.class)]
[loading org/apache/hadoop/mapred/JobStatus.class(org/apache/hadoop/mapred:JobStatus.class)]
[loading org/apache/hadoop/mapred/JobProfile.class(org/apache/hadoop/mapred:JobProfile.class)]
[loading java/lang/Long.class(java/lang:Long.class)]
[loading java/util/ArrayList.class(java/util:ArrayList.class)]
[loading java/util/List.class(java/util:List.class)]
[loading org/apache/commons/logging/Log.class(org/apache/commons/logging:Log.class)]
[loading org/apache/commons/logging/LogFactory.class(org/apache/commons/logging:LogFactory.class)]
[loading org/apache/hadoop/conf/Configuration.class(org/apache/hadoop/conf:Configuration.class)]
[loading java/lang/Enum.class(java/lang:Enum.class)]
[loading java/lang/Comparable.class(java/lang:Comparable.class)]
[loading java/lang/Exception.class(java/lang:Exception.class)]
[loading java/io/FileNotFoundException.class(java/io:FileNotFoundException.class)]
[loading java/net/URISyntaxException.class(java/net:URISyntaxException.class)]
[loading org/apache/commons/exec/ExecuteException.class(org/apache/commons/exec:ExecuteException.class)]
[loading java/security/PrivilegedExceptionAction.class(java/security:PrivilegedExceptionAction.class)]
[loading org/apache/hadoop/fs/Path.class(org/apache/hadoop/fs:Path.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes/org/apache/hadoop/hive/conf/HiveConf.class]
[loading org/apache/hadoop/security/UserGroupInformation.class(org/apache/hadoop/security:UserGroupInformation.class)]
[loading org/apache/hadoop/util/StringUtils.class(org/apache/hadoop/util:StringUtils.class)]
[loading org/apache/hadoop/util/ToolRunner.class(org/apache/hadoop/util:ToolRunner.class)]
[loading java/io/File.class(java/io:File.class)]
[loading java/net/URL.class(java/net:URL.class)]
[loading org/apache/hadoop/util/VersionInfo.class(org/apache/hadoop/util:VersionInfo.class)]
[loading java/lang/Iterable.class(java/lang:Iterable.class)]
[loading org/apache/hadoop/io/Writable.class(org/apache/hadoop/io:Writable.class)]
[loading java/lang/InterruptedException.class(java/lang:InterruptedException.class)]
[loading java/io/BufferedReader.class(java/io:BufferedReader.class)]
[loading java/io/InputStream.class(java/io:InputStream.class)]
[loading java/io/InputStreamReader.class(java/io:InputStreamReader.class)]
[loading java/io/OutputStream.class(java/io:OutputStream.class)]
[loading java/io/PrintWriter.class(java/io:PrintWriter.class)]
[loading java/util/Map$Entry.class(java/util:Map$Entry.class)]
[loading java/util/concurrent/Semaphore.class(java/util/concurrent:Semaphore.class)]
[loading org/apache/commons/exec/CommandLine.class(org/apache/commons/exec:CommandLine.class)]
[loading org/apache/commons/exec/DefaultExecutor.class(org/apache/commons/exec:DefaultExecutor.class)]
[loading org/apache/commons/exec/ExecuteWatchdog.class(org/apache/commons/exec:ExecuteWatchdog.class)]
[loading org/apache/commons/exec/PumpStreamHandler.class(org/apache/commons/exec:PumpStreamHandler.class)]
[loading org/apache/hadoop/util/Shell.class(org/apache/hadoop/util:Shell.class)]
[loading java/lang/Thread.class(java/lang:Thread.class)]
[loading java/lang/Runnable.class(java/lang:Runnable.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/classes/org/apache/hadoop/hive/shims/HadoopShims.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/classes/org/apache/hadoop/hive/shims/HadoopShims$WebHCatJTShim.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/classes/org/apache/hadoop/hive/shims/ShimLoader.class]
[loading org/apache/hadoop/mapred/JobID.class(org/apache/hadoop/mapred:JobID.class)]
[loading java/util/Arrays.class(java/util:Arrays.class)]
[loading javax/xml/bind/annotation/XmlRootElement.class(javax/xml/bind/annotation:XmlRootElement.class)]
[loading java/net/InetAddress.class(java/net:InetAddress.class)]
[loading java/net/UnknownHostException.class(java/net:UnknownHostException.class)]
[loading java/text/MessageFormat.class(java/text:MessageFormat.class)]
[loading java/util/Collections.class(java/util:Collections.class)]
[loading java/util/regex/Matcher.class(java/util/regex:Matcher.class)]
[loading java/util/regex/Pattern.class(java/util/regex:Pattern.class)]
[loading javax/servlet/http/HttpServletRequest.class(javax/servlet/http:HttpServletRequest.class)]
[loading javax/ws/rs/DELETE.class(javax/ws/rs:DELETE.class)]
[loading javax/ws/rs/FormParam.class(javax/ws/rs:FormParam.class)]
[loading javax/ws/rs/GET.class(javax/ws/rs:GET.class)]
[loading javax/ws/rs/POST.class(javax/ws/rs:POST.class)]
[loading javax/ws/rs/PUT.class(javax/ws/rs:PUT.class)]
[loading javax/ws/rs/Path.class(javax/ws/rs:Path.class)]
[loading javax/ws/rs/PathParam.class(javax/ws/rs:PathParam.class)]
[loading javax/ws/rs/Produces.class(javax/ws/rs:Produces.class)]
[loading javax/ws/rs/QueryParam.class(javax/ws/rs:QueryParam.class)]
[loading javax/ws/rs/core/Context.class(javax/ws/rs/core:Context.class)]
[loading javax/ws/rs/core/SecurityContext.class(javax/ws/rs/core:SecurityContext.class)]
[loading javax/ws/rs/core/UriInfo.class(javax/ws/rs/core:UriInfo.class)]
[loading org/apache/hadoop/security/authentication/client/PseudoAuthenticator.class(org/apache/hadoop/security/authentication/client:PseudoAuthenticator.class)]
[loading com/sun/jersey/api/NotFoundException.class(com/sun/jersey/api:NotFoundException.class)]
[loading java/net/URI.class(java/net:URI.class)]
[loading org/apache/commons/lang/StringUtils.class(org/apache/commons/lang:StringUtils.class)]
[loading org/apache/hadoop/fs/FileStatus.class(org/apache/hadoop/fs:FileStatus.class)]
[loading org/apache/hadoop/fs/FileSystem.class(org/apache/hadoop/fs:FileSystem.class)]
[loading java/util/Date.class(java/util:Date.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes/org/apache/hadoop/hive/common/classification/InterfaceAudience.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/core/target/classes/org/apache/hive/hcatalog/common/HCatUtil.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes/org/apache/hadoop/hive/common/classification/InterfaceAudience$Private.class]
[loading com/sun/jersey/api/wadl/config/WadlGeneratorConfig.class(com/sun/jersey/api/wadl/config:WadlGeneratorConfig.class)]
[loading com/sun/jersey/api/wadl/config/WadlGeneratorDescription.class(com/sun/jersey/api/wadl/config:WadlGeneratorDescription.class)]
[loading com/sun/jersey/server/wadl/generators/resourcedoc/WadlGeneratorResourceDocSupport.class(com/sun/jersey/server/wadl/generators/resourcedoc:WadlGeneratorResourceDocSupport.class)]
[loading com/sun/jersey/api/core/PackagesResourceConfig.class(com/sun/jersey/api/core:PackagesResourceConfig.class)]
[loading com/sun/jersey/spi/container/servlet/ServletContainer.class(com/sun/jersey/spi/container/servlet:ServletContainer.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes/org/apache/hadoop/hive/common/classification/InterfaceStability.class]
[loading org/apache/hadoop/hdfs/web/AuthFilter.class(org/apache/hadoop/hdfs/web:AuthFilter.class)]
[loading org/apache/hadoop/util/GenericOptionsParser.class(org/apache/hadoop/util:GenericOptionsParser.class)]
[loading org/eclipse/jetty/rewrite/handler/RedirectPatternRule.class(org/eclipse/jetty/rewrite/handler:RedirectPatternRule.class)]
[loading org/eclipse/jetty/rewrite/handler/RewriteHandler.class(org/eclipse/jetty/rewrite/handler:RewriteHandler.class)]
[loading org/eclipse/jetty/server/Handler.class(org/eclipse/jetty/server:Handler.class)]
[loading org/eclipse/jetty/server/Server.class(org/eclipse/jetty/server:Server.class)]
[loading org/eclipse/jetty/server/handler/HandlerList.class(org/eclipse/jetty/server/handler:HandlerList.class)]
[loading org/eclipse/jetty/servlet/FilterHolder.class(org/eclipse/jetty/servlet:FilterHolder.class)]
[loading org/eclipse/jetty/servlet/FilterMapping.class(org/eclipse/jetty/servlet:FilterMapping.class)]
[loading org/eclipse/jetty/servlet/ServletContextHandler.class(org/eclipse/jetty/servlet:ServletContextHandler.class)]
[loading org/eclipse/jetty/servlet/ServletHolder.class(org/eclipse/jetty/servlet:ServletHolder.class)]
[loading org/slf4j/bridge/SLF4JBridgeHandler.class(org/slf4j/bridge:SLF4JBridgeHandler.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes/org/apache/hadoop/hive/common/classification/InterfaceAudience$LimitedPrivate.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes/org/apache/hadoop/hive/common/classification/InterfaceStability$Unstable.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes/org/apache/hadoop/hive/metastore/api/MetaException.class]
[loading org/apache/hadoop/io/Text.class(org/apache/hadoop/io:Text.class)]
[loading org/apache/hadoop/security/Credentials.class(org/apache/hadoop/security:Credentials.class)]
[loading org/apache/hadoop/security/token/Token.class(org/apache/hadoop/security/token:Token.class)]
[loading org/apache/thrift/TException.class(org/apache/thrift:TException.class)]
[loading java/io/Closeable.class(java/io:Closeable.class)]
[loading java/io/Flushable.class(java/io:Flushable.class)]
[loading org/apache/hadoop/security/Groups.class(org/apache/hadoop/security:Groups.class)]
[loading java/util/HashSet.class(java/util:HashSet.class)]
[loading java/util/Set.class(java/util:Set.class)]
[loading java/util/concurrent/ConcurrentHashMap.class(java/util/concurrent:ConcurrentHashMap.class)]
[loading java/io/UnsupportedEncodingException.class(java/io:UnsupportedEncodingException.class)]
[loading org/apache/zookeeper/CreateMode.class(org/apache/zookeeper:CreateMode.class)]
[loading org/apache/zookeeper/KeeperException.class(org/apache/zookeeper:KeeperException.class)]
[loading org/apache/zookeeper/WatchedEvent.class(org/apache/zookeeper:WatchedEvent.class)]
[loading org/apache/zookeeper/Watcher.class(org/apache/zookeeper:Watcher.class)]
[loading org/apache/zookeeper/ZooDefs.class(org/apache/zookeeper:ZooDefs.class)]
[loading org/apache/zookeeper/ZooDefs$Ids.class(org/apache/zookeeper:ZooDefs$Ids.class)]
[loading org/apache/zookeeper/ZooKeeper.class(org/apache/zookeeper:ZooKeeper.class)]
[loading org/apache/hadoop/io/NullWritable.class(org/apache/hadoop/io:NullWritable.class)]
[loading org/apache/hadoop/mapreduce/InputSplit.class(org/apache/hadoop/mapreduce:InputSplit.class)]
[loading org/apache/hadoop/mapreduce/RecordReader.class(org/apache/hadoop/mapreduce:RecordReader.class)]
[loading org/apache/hadoop/mapreduce/TaskAttemptContext.class(org/apache/hadoop/mapreduce:TaskAttemptContext.class)]
[loading java/net/URLConnection.class(java/net:URLConnection.class)]
[loading java/util/Collection.class(java/util:Collection.class)]
[loading javax/ws/rs/core/UriBuilder.class(javax/ws/rs/core:UriBuilder.class)]
[loading java/io/OutputStreamWriter.class(java/io:OutputStreamWriter.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes/org/apache/hadoop/hive/common/classification/InterfaceStability$Evolving.class]
[loading org/apache/zookeeper/data/Stat.class(org/apache/zookeeper/data:Stat.class)]
[loading org/apache/hadoop/mapreduce/InputFormat.class(org/apache/hadoop/mapreduce:InputFormat.class)]
[loading org/apache/hadoop/mapreduce/JobContext.class(org/apache/hadoop/mapreduce:JobContext.class)]
[loading org/apache/hadoop/mapred/JobClient.class(org/apache/hadoop/mapred:JobClient.class)]
[loading org/apache/hadoop/mapred/JobConf.class(org/apache/hadoop/mapred:JobConf.class)]
[loading org/apache/hadoop/mapred/RunningJob.class(org/apache/hadoop/mapred:RunningJob.class)]
[loading java/io/DataInput.class(java/io:DataInput.class)]
[loading java/io/DataOutput.class(java/io:DataOutput.class)]
[loading org/apache/hadoop/conf/Configured.class(org/apache/hadoop/conf:Configured.class)]
[loading org/apache/hadoop/fs/permission/FsPermission.class(org/apache/hadoop/fs/permission:FsPermission.class)]
[loading org/apache/hadoop/mapreduce/Job.class(org/apache/hadoop/mapreduce:Job.class)]
[loading org/apache/hadoop/mapreduce/JobID.class(org/apache/hadoop/mapreduce:JobID.class)]
[loading org/apache/hadoop/mapreduce/lib/output/NullOutputFormat.class(org/apache/hadoop/mapreduce/lib/output:NullOutputFormat.class)]
[loading org/apache/hadoop/mapreduce/security/token/delegation/DelegationTokenIdentifier.class(org/apache/hadoop/mapreduce/security/token/delegation:DelegationTokenIdentifier.class)]
[loading org/apache/hadoop/util/Tool.class(org/apache/hadoop/util:Tool.class)]
[loading org/apache/hadoop/conf/Configurable.class(org/apache/hadoop/conf:Configurable.class)]
[loading java/lang/ClassNotFoundException.class(java/lang:ClassNotFoundException.class)]
[loading org/apache/hadoop/mapreduce/Mapper.class(org/apache/hadoop/mapreduce:Mapper.class)]
[loading java/util/Iterator.class(java/util:Iterator.class)]
[loading java/util/LinkedList.class(java/util:LinkedList.class)]
[loading java/util/concurrent/ExecutorService.class(java/util/concurrent:ExecutorService.class)]
[loading java/util/concurrent/Executors.class(java/util/concurrent:Executors.class)]
[loading java/util/concurrent/TimeUnit.class(java/util/concurrent:TimeUnit.class)]
[loading org/apache/hadoop/mapreduce/Mapper$Context.class(org/apache/hadoop/mapreduce:Mapper$Context.class)]
[loading java/lang/Process.class(java/lang:Process.class)]
[loading java/lang/StringBuilder.class(java/lang:StringBuilder.class)]
[loading java/lang/ProcessBuilder.class(java/lang:ProcessBuilder.class)]
[loading java/lang/annotation/Target.class(java/lang/annotation:Target.class)]
[loading java/lang/annotation/ElementType.class(java/lang/annotation:ElementType.class)]
[loading java/lang/annotation/Retention.class(java/lang/annotation:Retention.class)]
[loading java/lang/annotation/RetentionPolicy.class(java/lang/annotation:RetentionPolicy.class)]
[loading java/lang/annotation/Annotation.class(java/lang/annotation:Annotation.class)]
[loading java/lang/SuppressWarnings.class(java/lang:SuppressWarnings.class)]
[loading java/lang/Override.class(java/lang:Override.class)]
[loading javax/ws/rs/HttpMethod.class(javax/ws/rs:HttpMethod.class)]
[loading java/lang/Deprecated.class(java/lang:Deprecated.class)]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$3.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/HcatDelegator$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/LauncherDelegator$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/SecureProxySupport$2.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/HcatException$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$2.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$2$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/ZooKeeperStorage$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/LogRetriever$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/ZooKeeperStorage$2.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/TempletonUtils$1.class]
[loading /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/org/apache/hive/hcatalog/templeton/tool/HDFSStorage$1.class]
[done in 7970 ms]
[WARNING] Javadoc Warnings
[WARNING] Nov 11, 2013 4:28:05 PM com.sun.jersey.wadl.resourcedoc.ResourceDoclet start
[WARNING] INFO: Wrote /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/classes/resourcedoc.xml
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-webhcat ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-webhcat ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/webhcat/svr/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-webhcat ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-webhcat ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HCatalog HBase Storage Handler 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-hbase-storage-handler ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/src/gen-java added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hbase-storage-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hbase-storage-handler ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hbase-storage-handler ---
[INFO] Compiling 1 source file to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hbase-storage-handler ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hbase-storage-handler ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hcatalog/storage-handlers/hbase/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hbase-storage-handler ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hbase-storage-handler ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive HWI 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-hwi ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-hwi ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-hwi ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-hwi ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/hwi/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-hwi ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/hwi/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hwi ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hwi ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive ODBC 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-odbc ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-odbc ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/odbc/target/tmp/conf
[INFO] Executed tasks
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Aggregator 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-aggregator ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-aggregator ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/shims/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/target/tmp/conf
[INFO] Executed tasks
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive TestUtils 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-testutils ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-testutils ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-testutils ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-testutils ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/testutils/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-testutils ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/testutils/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-testutils ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-testutils ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Packaging 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-packaging ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-packaging ---
[INFO] Executing tasks

main:
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/tmp
   [delete] Deleting directory /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/packaging/target/tmp/conf
[INFO] Executed tasks
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [2.020s]
[INFO] Hive Ant Utilities ................................ SUCCESS [3.877s]
[INFO] Hive Shims Common ................................. SUCCESS [1.340s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [0.580s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [0.890s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [0.390s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [1.385s]
[INFO] Hive Shims ........................................ SUCCESS [0.250s]
[INFO] Hive Common ....................................... SUCCESS [3.676s]
[INFO] Hive Serde ........................................ SUCCESS [0.705s]
[INFO] Hive Metastore .................................... SUCCESS [5.853s]
[INFO] Hive Query Language ............................... SUCCESS [11.108s]
[INFO] Hive Service ...................................... SUCCESS [0.427s]
[INFO] Hive JDBC ......................................... SUCCESS [0.462s]
[INFO] Hive Beeline ...................................... SUCCESS [0.671s]
[INFO] Hive CLI .......................................... SUCCESS [0.912s]
[INFO] Hive Contrib ...................................... SUCCESS [0.830s]
[INFO] Hive HBase Handler ................................ SUCCESS [1.117s]
[INFO] Hive HCatalog ..................................... SUCCESS [0.452s]
[INFO] Hive HCatalog Core ................................ SUCCESS [0.780s]
[INFO] Hive HCatalog Pig Adapter ......................... SUCCESS [0.299s]
[INFO] Hive HCatalog Server Extensions ................... SUCCESS [0.391s]
[INFO] Hive HCatalog Webhcat Java Client ................. SUCCESS [0.555s]
[INFO] Hive HCatalog Webhcat ............................. SUCCESS [9.585s]
[INFO] Hive HCatalog HBase Storage Handler ............... SUCCESS [0.934s]
[INFO] Hive HWI .......................................... SUCCESS [0.510s]
[INFO] Hive ODBC ......................................... SUCCESS [0.372s]
[INFO] Hive Shims Aggregator ............................. SUCCESS [0.131s]
[INFO] Hive TestUtils .................................... SUCCESS [0.129s]
[INFO] Hive Packaging .................................... SUCCESS [0.215s]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 53.202s
[INFO] Finished at: Mon Nov 11 16:28:07 EST 2013
[INFO] Final Memory: 39M/104M
[INFO] ------------------------------------------------------------------------
+ cd itests
+ mvn -B clean install -DskipTests -Dmaven.repo.local=/data/hive-ptest/working/maven
[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Hive Integration - Parent
[INFO] Hive Integration - Custom Serde
[INFO] Hive Integration - Testing Utilities
[INFO] Hive Integration - Unit Tests
[INFO] Hive Integration - HCatalog Unit Tests
[INFO] Hive Integration - Test Serde
[INFO] Hive Integration - QFile Tests
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Parent 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/itests (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-it/0.13.0-SNAPSHOT/hive-it-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Custom Serde 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-custom-serde ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-it-custom-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-custom-serde ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-custom-serde ---
[INFO] Compiling 8 source files to /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-it-custom-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-it-custom-serde ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-it-custom-serde ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-it-custom-serde ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-it-custom-serde ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/hive-it-custom-serde-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-it-custom-serde ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/target/hive-it-custom-serde-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-it-custom-serde/0.13.0-SNAPSHOT/hive-it-custom-serde-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/itests/custom-serde/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-it-custom-serde/0.13.0-SNAPSHOT/hive-it-custom-serde-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Integration - Testing Utilities 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-it-util ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/itests/util (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-it-util ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-it-util ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-it-util ---
[INFO] Compiling 42 source files to /data/hive-ptest/working/apache-svn-trunk-source/itests/util/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 2 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/OptrStatGroupByHook.java:[45,73] cannot find symbol
symbol  : variable HIVEJOBPROGRESS
location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/OptrStatGroupByHook.java:[57,38] cannot find symbol
symbol  : method getCounters()
location: class org.apache.hadoop.hive.ql.exec.Operator&amp;lt;capture#459 of ? extends org.apache.hadoop.hive.ql.plan.OperatorDesc&amp;gt;
[INFO] 2 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive Integration - Parent ......................... SUCCESS [3.940s]
[INFO] Hive Integration - Custom Serde ................... SUCCESS [9.284s]
[INFO] Hive Integration - Testing Utilities .............. FAILURE [5.506s]
[INFO] Hive Integration - Unit Tests ..................... SKIPPED
[INFO] Hive Integration - HCatalog Unit Tests ............ SKIPPED
[INFO] Hive Integration - Test Serde ..................... SKIPPED
[INFO] Hive Integration - QFile Tests .................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 19.829s
[INFO] Finished at: Mon Nov 11 16:28:30 EST 2013
[INFO] Final Memory: 26M/63M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-it-util: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/OptrStatGroupByHook.java:[45,73] cannot find symbol
[ERROR] symbol  : variable HIVEJOBPROGRESS
[ERROR] location: class org.apache.hadoop.hive.conf.HiveConf.ConfVars
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/OptrStatGroupByHook.java:[57,38] cannot find symbol
[ERROR] symbol  : method getCounters()
[ERROR] location: class org.apache.hadoop.hive.ql.exec.Operator&amp;lt;capture#459 of ? extends org.apache.hadoop.hive.ql.plan.OperatorDesc&amp;gt;
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-it-util
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12613111&lt;/p&gt;</comment>
                            <comment id="13819627" author="jdere" created="Tue, 12 Nov 2013 00:09:23 +0000"  >&lt;p&gt;Looks like Gunther&apos;s original patch is also supposed to delete OptrStatGroupByHook.java.  Uploading the patch again.&lt;/p&gt;</comment>
                            <comment id="13819643" author="navis" created="Tue, 12 Nov 2013 00:24:49 +0000"  >&lt;p&gt;I just rebased and didn&apos;t look into thoroughly. Modify freely as you wish.&lt;/p&gt;</comment>
                            <comment id="13820683" author="jdere" created="Tue, 12 Nov 2013 23:53:30 +0000"  >&lt;p&gt;doesn&apos;t look like pre-commit tests ran from the last patch .. uploading patch again to run to kick off another test run.&lt;/p&gt;</comment>
                            <comment id="13821708" author="hiveqa" created="Wed, 13 Nov 2013 19:21:30 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12613468/HIVE-4518.8.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12613468/HIVE-4518.8.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/263/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/263/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/263/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/263/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests failed with: NonZeroExitCodeException: Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-263/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
Reverted &apos;common/src/test/org/apache/hadoop/hive/common/type/TestHiveDecimal.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoUtils.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/HiveDecimalUtils.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/PrimitiveObjectInspector.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/AbstractPrimitiveObjectInspector.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantShortObjectInspector.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantLongObjectInspector.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantByteObjectInspector.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveDecimalObjectInspector.java&apos;
Reverted &apos;serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantIntObjectInspector.java&apos;
Reverted &apos;ql/src/test/results/clientnegative/udf_assert_true2.q.out&apos;
Reverted &apos;ql/src/test/results/clientnegative/invalid_arithmetic_type.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/auto_join13.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/decimal_udf.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/rcfile_createas1.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/udf_pmod.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/orc_createas1.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/rcfile_merge2.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/ql_rewrite_gbtoidx.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/input8.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/vectorization_short_regress.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/decimal_6.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/rcfile_merge1.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/bucketmapjoin_negative3.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/windowing_expressions.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/vectorization_5.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/num_op_type_conv.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/skewjoin.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/vectorization_15.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/ppd_constant_expr.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/vectorized_math_funcs.q.out&apos;
Reverted &apos;ql/src/test/results/clientpositive/auto_join2.q.out&apos;
Reverted &apos;ql/src/test/results/compiler/plan/join2.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/input8.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/udf4.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/input20.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/sample1.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/sample2.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/sample3.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/sample4.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/sample5.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/sample6.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/sample7.q.xml&apos;
Reverted &apos;ql/src/test/results/compiler/plan/cast1.q.xml&apos;
Reverted &apos;ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorizationContext.java&apos;
Reverted &apos;ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorSelectOperator.java&apos;
Reverted &apos;ql/src/test/org/apache/hadoop/hive/ql/udf/TestUDFPosMod.java&apos;
Reverted &apos;ql/src/test/org/apache/hadoop/hive/ql/udf/TestUDFOPDivide.java&apos;
Reverted &apos;ql/src/test/org/apache/hadoop/hive/ql/udf/TestUDFOPMod.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/Vectorizer.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPMultiply.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/UDFBaseNumericOp.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/UDFPosMod.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPDivide.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPMod.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPPlus.java&apos;
Reverted &apos;ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPMinus.java&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ awk &apos;{print $2}&apos;
++ svn status --no-ignore
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20/target shims/assembly/target shims/0.20S/target shims/0.23/target shims/common/target shims/common-secure/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit/target itests/custom-serde/target itests/util/target hcatalog/target hcatalog/storage-handlers/hbase/target hcatalog/server-extensions/target hcatalog/core/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target hcatalog/hcatalog-pig-adapter/target hwi/target common/target common/src/gen service/target contrib/target serde/target beeline/target odbc/target cli/target ql/dependency-reduced-pom.xml ql/target ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFOPDivide.java ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFOPMinus.java ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFOPMultiply.java ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFOPMod.java ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFPosMod.java ql/src/test/org/apache/hadoop/hive/ql/udf/generic/TestGenericUDFOPPlus.java ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPPlus.java ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBaseNumeric.java ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPMod.java ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPMinus.java ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPosMod.java ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPDivide.java ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFOPMultiply.java
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1541663.

At revision 1541663.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
Going to apply patch with: patch -p0
patching file common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
patching file conf/hive-default.xml.template
patching file data/conf/hive-site.xml
patching file itests/util/src/main/java/org/apache/hadoop/hive/ql/hooks/OptrStatGroupByHook.java
patching file ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java
patching file ql/src/java/org/apache/hadoop/hive/ql/QueryPlan.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/AbstractMapJoinOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/CommonJoinOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/DemuxOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/MuxOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/OperatorFactory.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecReducer.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHook.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java
patching file ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorFileSinkOperator.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/merge/BlockMergeTask.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/stats/PartialScanTask.java
patching file ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/truncate/ColumnTruncateTask.java
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/MapReduceCompiler.java
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
Hunk #1 succeeded at 5229 (offset 63 lines).
patching file ql/src/test/org/apache/hadoop/hive/ql/exec/TestOperators.java
patching file ql/src/test/org/apache/hadoop/hive/ql/exec/vector/TestVectorGroupByOperator.java
patching file ql/src/test/org/apache/hadoop/hive/ql/testutil/OperatorTestUtils.java
patching file ql/src/test/queries/clientpositive/insert_into3.q
patching file ql/src/test/queries/clientpositive/optrstat_groupby.q
patching file ql/src/test/results/clientpositive/insert_into3.q.out
patching file ql/src/test/results/clientpositive/optrstat_groupby.q.out
patching file ql/src/test/results/compiler/plan/case_sensitivity.q.xml
patching file ql/src/test/results/compiler/plan/cast1.q.xml
patching file ql/src/test/results/compiler/plan/groupby1.q.xml
patching file ql/src/test/results/compiler/plan/groupby2.q.xml
patching file ql/src/test/results/compiler/plan/groupby3.q.xml
patching file ql/src/test/results/compiler/plan/groupby4.q.xml
patching file ql/src/test/results/compiler/plan/groupby5.q.xml
patching file ql/src/test/results/compiler/plan/groupby6.q.xml
patching file ql/src/test/results/compiler/plan/input1.q.xml
patching file ql/src/test/results/compiler/plan/input2.q.xml
patching file ql/src/test/results/compiler/plan/input20.q.xml
patching file ql/src/test/results/compiler/plan/input3.q.xml
patching file ql/src/test/results/compiler/plan/input4.q.xml
patching file ql/src/test/results/compiler/plan/input5.q.xml
patching file ql/src/test/results/compiler/plan/input6.q.xml
patching file ql/src/test/results/compiler/plan/input7.q.xml
patching file ql/src/test/results/compiler/plan/input8.q.xml
patching file ql/src/test/results/compiler/plan/input9.q.xml
patching file ql/src/test/results/compiler/plan/input_part1.q.xml
patching file ql/src/test/results/compiler/plan/input_testsequencefile.q.xml
patching file ql/src/test/results/compiler/plan/input_testxpath.q.xml
patching file ql/src/test/results/compiler/plan/input_testxpath2.q.xml
patching file ql/src/test/results/compiler/plan/join1.q.xml
patching file ql/src/test/results/compiler/plan/join2.q.xml
patching file ql/src/test/results/compiler/plan/join3.q.xml
patching file ql/src/test/results/compiler/plan/join4.q.xml
patching file ql/src/test/results/compiler/plan/join5.q.xml
patching file ql/src/test/results/compiler/plan/join6.q.xml
patching file ql/src/test/results/compiler/plan/join7.q.xml
patching file ql/src/test/results/compiler/plan/join8.q.xml
patching file ql/src/test/results/compiler/plan/sample1.q.xml
patching file ql/src/test/results/compiler/plan/sample2.q.xml
patching file ql/src/test/results/compiler/plan/sample3.q.xml
patching file ql/src/test/results/compiler/plan/sample4.q.xml
patching file ql/src/test/results/compiler/plan/sample5.q.xml
patching file ql/src/test/results/compiler/plan/sample6.q.xml
patching file ql/src/test/results/compiler/plan/sample7.q.xml
patching file ql/src/test/results/compiler/plan/subq.q.xml
patching file ql/src/test/results/compiler/plan/udf1.q.xml
patching file ql/src/test/results/compiler/plan/udf4.q.xml
patching file ql/src/test/results/compiler/plan/udf6.q.xml
patching file ql/src/test/results/compiler/plan/udf_case.q.xml
patching file ql/src/test/results/compiler/plan/udf_when.q.xml
patching file ql/src/test/results/compiler/plan/union.q.xml
+ [[ maven == \m\a\v\e\n ]]
+ rm -rf /data/hive-ptest/working/maven/org/apache/hive
+ mvn -B clean install -DskipTests -Dmaven.repo.local=/data/hive-ptest/working/maven
[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Hive
[INFO] Hive Ant Utilities
[INFO] Hive Shims Common
[INFO] Hive Shims 0.20
[INFO] Hive Shims Secure Common
[INFO] Hive Shims 0.20S
[INFO] Hive Shims 0.23
[INFO] Hive Shims
[INFO] Hive Common
[INFO] Hive Serde
[INFO] Hive Metastore
[INFO] Hive Query Language
[INFO] Hive Service
[INFO] Hive JDBC
[INFO] Hive Beeline
[INFO] Hive CLI
[INFO] Hive Contrib
[INFO] Hive HBase Handler
[INFO] Hive HCatalog
[INFO] Hive HCatalog Core
[INFO] Hive HCatalog Pig Adapter
[INFO] Hive HCatalog Server Extensions
[INFO] Hive HCatalog Webhcat Java Client
[INFO] Hive HCatalog Webhcat
[INFO] Hive HCatalog HBase Storage Handler
[INFO] Hive HWI
[INFO] Hive ODBC
[INFO] Hive Shims Aggregator
[INFO] Hive TestUtils
[INFO] Hive Packaging
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive/0.13.0-SNAPSHOT/hive-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Ant Utilities 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-ant ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/ant (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-ant ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-ant ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-ant ---
[INFO] Compiling 5 source files to /data/hive-ptest/working/apache-svn-trunk-source/ant/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/QTestGenTask.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/ant/src/org/apache/hadoop/hive/ant/DistinctElementsClassPath.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-ant ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/ant/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-ant ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/ant/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-ant ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-ant ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-ant ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/ant/target/hive-ant-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-ant ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ant/target/hive-ant-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-ant/0.13.0-SNAPSHOT/hive-ant-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ant/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-ant/0.13.0-SNAPSHOT/hive-ant-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-common ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/common (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common ---
[INFO] Compiling 15 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-common ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-common ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common/0.13.0-SNAPSHOT/hive-shims-common-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common/0.13.0-SNAPSHOT/hive-shims-common-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.20 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.20 ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20 (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20 ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/main/java/org/apache/hadoop/hive/shims/Hadoop20Shims.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20 ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20 ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.20 ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.20 ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20/0.13.0-SNAPSHOT/hive-shims-0.20-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20/0.13.0-SNAPSHOT/hive-shims-0.20-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims Secure Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-common-secure ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-common-secure ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-common-secure ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-common-secure ---
[INFO] Compiling 12 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/main/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-common-secure ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-common-secure ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-common-secure ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-common-secure ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-common-secure ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-common-secure ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common-secure/0.13.0-SNAPSHOT/hive-shims-common-secure-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-common-secure/0.13.0-SNAPSHOT/hive-shims-common-secure-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.20S 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.20S ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.20S ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.20S ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.20S ---
[INFO] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/main/java/org/apache/hadoop/hive/shims/Hadoop20SShims.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.20S ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.20S ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.20S ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.20S ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.20S ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.20S ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20S/0.13.0-SNAPSHOT/hive-shims-0.20S-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.20S/0.13.0-SNAPSHOT/hive-shims-0.20S-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.23 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims-0.23 ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23 (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims-0.23 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims-0.23 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims-0.23 ---
[INFO] Compiling 3 source files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/main/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims-0.23 ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims-0.23 ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims-0.23 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims-0.23 ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims-0.23 ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims-0.23 ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.23/0.13.0-SNAPSHOT/hive-shims-0.23-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/shims/hive-shims-0.23/0.13.0-SNAPSHOT/hive-shims-0.23-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Shims 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-shims ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-shims ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-shims ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-shims ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims ---
[WARNING] JAR will be empty - no content was marked for inclusion!
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-assembly-plugin:2.3:single (uberjar) @ hive-shims ---
[INFO] Reading assembly descriptor: src/assemble/uberjar.xml
[WARNING] Artifact: org.apache.hive:hive-shims:jar:0.13.0-SNAPSHOT references the same file as the assembly destination file. Moving it to a temporary location for inclusion.
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[INFO] META-INF/MANIFEST.MF already added, skipping
[WARNING] Configuration options: &apos;appendAssemblyId&apos; is set to false, and &apos;classifier&apos; is missing.
Instead of attaching the assembly file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar, it will become the file for main project artifact.
NOTE: If multiple descriptors or descriptor-formats are provided for this project, the value of this file will be non-deterministic!
[WARNING] Replacing pre-existing project main-artifact file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/archive-tmp/hive-shims-0.13.0-SNAPSHOT.jar
with assembly file: /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.13.0-SNAPSHOT/hive-shims-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-shims/0.13.0-SNAPSHOT/hive-shims-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Common 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-common ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/common (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-version-annotation) @ hive-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-common ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/common/src/gen added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-common ---
[INFO] Compiling 31 source files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/common/src/java/org/apache/hadoop/hive/common/ObjectPair.java uses unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-common ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-common ---
[INFO] Compiling 8 source files to /data/hive-ptest/working/apache-svn-trunk-source/common/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-common ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-common ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-common ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-common/0.13.0-SNAPSHOT/hive-common-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/common/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-common/0.13.0-SNAPSHOT/hive-common-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Serde 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-serde ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/serde (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-serde ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/protobuf/gen-java added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/serde/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-serde ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-serde ---
[INFO] Compiling 351 source files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-serde ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/serde/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-serde ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-serde ---
[INFO] Compiling 41 source files to /data/hive-ptest/working/apache-svn-trunk-source/serde/target/test-classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-serde ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-serde ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-serde ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-serde/0.13.0-SNAPSHOT/hive-serde-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/serde/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-serde/0.13.0-SNAPSHOT/hive-serde-0.13.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Metastore 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-metastore ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/metastore (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-metastore ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/model added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-metastore ---
[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/java
ANTLR Parser Generator  Version 3.4
org/apache/hadoop/hive/metastore/parser/Filter.g
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-metastore ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-metastore ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-metastore ---
[INFO] Compiling 132 source files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- datanucleus-maven-plugin:3.3.0-release:enhance (default) @ hive-metastore ---
[INFO] DataNucleus Enhancer (version 3.2.2) for API &quot;JDO&quot; using JRE &quot;1.6&quot;
DataNucleus Enhancer : Classpath
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-maven-plugin/3.3.0-release/datanucleus-maven-plugin-3.3.0-release.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-utils/3.0.8/plexus-utils-3.0.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/plexus/plexus-component-annotations/1.5.5/plexus-component-annotations-1.5.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-inject-bean/2.3.0/sisu-inject-bean-2.3.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guice/3.1.0/sisu-guice-3.1.0-no_aop.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/sonatype/sisu/sisu-guava/0.9.9/sisu-guava-0.9.9.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/xbean/xbean-reflect/3.4/xbean-reflect-3.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/log4j/log4j/1.2.12/log4j-1.2.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-logging/commons-logging-api/1.1/commons-logging-api-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/collections/google-collections/1.0/google-collections-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/junit/junit/3.8.2/junit-3.8.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/classes
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/serde/target/hive-serde-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/common/target/hive-common-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/tukaani/xz/1.0/xz-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-codec/commons-codec/1.4/commons-codec-1.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/avro/avro/1.7.1/avro-1.7.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/assembly/target/hive-shims-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/common/target/hive-shims-common-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20/target/hive-shims-0.20-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/common-secure/target/hive-shims-common-secure-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/zookeeper/zookeeper/3.4.3/zookeeper-3.4.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/jline/jline/0.9.94/jline-0.9.94.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/jboss/netty/netty/3.2.2.Final/netty-3.2.2.Final.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.20S/target/hive-shims-0.20S-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/apache-svn-trunk-source/shims/0.23/target/hive-shims-0.23-0.13.0-SNAPSHOT.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/guava/guava/11.0.2/guava-11.0.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-lang/commons-lang/2.4/commons-lang-2.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/transaction/jta/1.1/jta-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/antlr/antlr/2.7.7/antlr-2.7.7.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/hadoop/hadoop-core/1.2.1/hadoop-core-1.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/xmlenc/xmlenc/0.52/xmlenc-0.52.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/stax/stax-api/1.0.1/stax-api-1.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/javax/activation/activation/1.1/activation-1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-jaxrs/1.7.1/jackson-jaxrs-1.7.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/asm/asm/3.1/asm-3.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-io/commons-io/2.1/commons-io-2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/apache/commons/commons-math/2.1/commons-math-2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-digester/commons-digester/1.8/commons-digester-1.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/ant/ant/1.6.5/ant-1.6.5.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/commons-el/commons-el/1.0/commons-el-1.0.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/oro/oro/2.0.8/oro-2.0.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar
&amp;gt;&amp;gt;  /data/hive-ptest/working/maven/log4j/log4j/1.2.16/log4j-1.2.16.jar
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDatabase
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MFieldSchema
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MType
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTable
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MSerDeInfo
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MOrder
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MColumnDescriptor
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStringList
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MStorageDescriptor
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartition
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MIndex
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRole
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MRoleMap
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MGlobalPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDBPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTablePrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnPrivilege
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionEvent
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MMasterKey
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MDelegationToken
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MTableColumnStatistics
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics
ENHANCED (PersistenceCapable) : org.apache.hadoop.hive.metastore.model.MVersionTable
DataNucleus Enhancer completed with success for 25 classes. Timings : input=577 ms, enhance=922 ms, total=1499 ms. Consult the log for full details

[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-metastore ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/metastore/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-metastore ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-metastore ---
[INFO] Compiling 10 source files to /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-metastore ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-metastore ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-metastore ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-metastore ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/metastore/target/hive-metastore-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-metastore/0.13.0-SNAPSHOT/hive-metastore-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Query Language 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-exec ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/ql (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-sources) @ hive-exec ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/aggregates/gen
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-test-sources/java/org/apache/hadoop/hive/ql/exec/vector/expressions/gen
Generating vector expression code
Generating vector expression test code
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-exec ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/protobuf/gen-java added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/src/gen/thrift/gen-javabean added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/ql/target/generated-sources/java added.
[INFO] 
[INFO] --- antlr3-maven-plugin:3.4:antlr (default) @ hive-exec ---
[INFO] ANTLR: Processing source directory /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java
ANTLR Parser Generator  Version 3.4
org/apache/hadoop/hive/ql/parse/HiveLexer.g
org/apache/hadoop/hive/ql/parse/HiveParser.g
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:872:5: 
Decision can match input such as &quot;Identifier KW_RENAME KW_TO&quot; using multiple alternatives: 1, 10

As a result, alternative(s) 10 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:5: 
Decision can match input such as &quot;KW_TEXTFILE&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:5: 
Decision can match input such as &quot;KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:5: 
Decision can match input such as &quot;KW_ORCFILE&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:5: 
Decision can match input such as &quot;KW_RCFILE&quot; using multiple alternatives: 3, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1190:23: 
Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1190:23: 
Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1190:23: 
Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1197:23: 
Decision can match input such as &quot;KW_ELEM_TYPE&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1197:23: 
Decision can match input such as &quot;KW_VALUE_TYPE&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1197:23: 
Decision can match input such as &quot;KW_KEY_TYPE&quot; using multiple alternatives: 2, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_PRETTY {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_FORMATTED {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITIONED..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_PRETTY Identifier&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_FORMATTED Identifier&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_PRETTY KW_PARTITION&quot; using multiple alternatives: 3, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:29: 
Decision can match input such as &quot;KW_FORMATTED KW_PARTITION&quot; using multiple alternatives: 1, 4

As a result, alternative(s) 4 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1486:116: 
Decision can match input such as &quot;KW_STORED KW_AS KW_DIRECTORIES&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_RCFILE&quot; using multiple alternatives: 3, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_SEQUENCEFILE&quot; using multiple alternatives: 1, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_ORCFILE&quot; using multiple alternatives: 4, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_TEXTFILE&quot; using multiple alternatives: 2, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:5: 
Decision can match input such as &quot;KW_STORED KW_AS KW_INPUTFORMAT&quot; using multiple alternatives: 5, 7

As a result, alternative(s) 7 were disabled for that input
warning(200): SelectClauseParser.g:149:5: 
Decision can match input such as &quot;KW_NULL DOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE..KW_EXPORT, KW_EXTERNAL..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER..KW_UNARCHIVE, KW_UNDO..KW_UNIONTYPE, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): SelectClauseParser.g:149:5: 
Decision can match input such as &quot;KW_NULL DOT Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:127:2: 
Decision can match input such as &quot;KW_LATERAL KW_VIEW KW_OUTER&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:25: 
Decision can match input such as &quot;LPAREN StringLiteral EQUAL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:25: 
Decision can match input such as &quot;LPAREN StringLiteral COMMA&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:25: 
Decision can match input such as &quot;LPAREN StringLiteral RPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:179:68: 
Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): FromClauseParser.g:237:16: 
Decision can match input such as &quot;Identifier LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN CharSetName&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL {KW_LIKE, KW_REGEXP, KW_RLIKE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL AMPERSAND&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_IS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN {MINUS, PLUS, TILDE}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_MAP&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL RPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN StringLiteral StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_IF&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL BITWISEOR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL DOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL {DIV..DIVIDE, MOD, STAR}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL NOTEQUAL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL EQUAL_NS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_EXISTS LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LESSTHAN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LESSTHANOREQUALTO&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_OR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_DATE StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL EQUAL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CAST LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_STRUCT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_UNIONTYPE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL GREATERTHAN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_ARRAY&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_DATE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL GREATERTHANOREQUALTO&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_EXISTS&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_BETWEEN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL {MINUS, PLUS}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_NOT&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL LSQUARE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_FALSE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_NULL&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN {KW_ADD..KW_AFTER, KW_ALTER..KW_ANALYZE, KW_ARCHIVE, KW_AS..KW_CASCADE, KW_CHANGE, KW_CLUSTER..KW_COLLECTION, KW_COLUMNS..KW_CREATE, KW_CUBE, KW_CURSOR..KW_DATA, KW_DATABASES, KW_DATETIME..KW_DISABLE, KW_DISTRIBUTE..KW_ELEM_TYPE, KW_ENABLE, KW_ESCAPED, KW_EXCLUSIVE, KW_EXPLAIN..KW_EXPORT, KW_EXTERNAL, KW_FETCH..KW_FLOAT, KW_FOR..KW_FORMATTED, KW_FULL, KW_FUNCTIONS..KW_GROUPING, KW_HOLD_DDLTIME..KW_IDXPROPERTIES, KW_IGNORE..KW_ITEMS, KW_KEYS..KW_LEFT, KW_LIKE..KW_LONG, KW_MAPJOIN..KW_MINUS, KW_MSCK..KW_NOSCAN, KW_NO_DROP, KW_OF..KW_OFFLINE, KW_OPTION, KW_ORCFILE..KW_OUTPUTFORMAT, KW_OVERWRITE, KW_PARTITION..KW_PLUS, KW_PRETTY..KW_RECORDWRITER, KW_REGEXP..KW_SCHEMAS, KW_SEMI..KW_STRING, KW_TABLE..KW_TABLES, KW_TBLPROPERTIES..KW_TEXTFILE, KW_TIMESTAMP..KW_TOUCH, KW_TRIGGER, KW_TRUNCATE..KW_UNARCHIVE, KW_UNDO..KW_UNION, KW_UNLOCK..KW_VALUE_TYPE, KW_VIEW, KW_WHILE, KW_WITH}&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_TRUE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE Number&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL BITWISEXOR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT SmallintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN CharSetName CharSetLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_CAST&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT BigintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_AND&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NULL KW_IN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_CASE&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_NOT TinyintLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE KW_WHEN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN StringLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN LPAREN Identifier&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:68:4: 
Decision can match input such as &quot;LPAREN KW_CASE DecimalLiteral&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:108:5: 
Decision can match input such as &quot;KW_ORDER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:121:5: 
Decision can match input such as &quot;KW_CLUSTER KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:133:5: 
Decision can match input such as &quot;KW_PARTITION KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:144:5: 
Decision can match input such as &quot;KW_DISTRIBUTE KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:155:5: 
Decision can match input such as &quot;KW_SORT KW_BY LPAREN&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:172:7: 
Decision can match input such as &quot;STAR&quot; using multiple alternatives: 1, 2

As a result, alternative(s) 2 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_UNIONTYPE&quot; using multiple alternatives: 5, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_STRUCT&quot; using multiple alternatives: 4, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:185:5: 
Decision can match input such as &quot;KW_ARRAY&quot; using multiple alternatives: 2, 6

As a result, alternative(s) 6 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_TRUE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_DATE StringLiteral&quot; using multiple alternatives: 2, 3

As a result, alternative(s) 3 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_FALSE&quot; using multiple alternatives: 3, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:267:5: 
Decision can match input such as &quot;KW_NULL&quot; using multiple alternatives: 1, 8

As a result, alternative(s) 8 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_OVERWRITE&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_CLUSTER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_INSERT KW_INTO&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_ORDER KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_MAP LPAREN&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_SORT KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_LATERAL KW_VIEW&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;KW_BETWEEN KW_MAP LPAREN&quot; using multiple alternatives: 8, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_GROUP KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:399:5: 
Decision can match input such as &quot;{KW_LIKE, KW_REGEXP, KW_RLIKE} KW_DISTRIBUTE KW_BY&quot; using multiple alternatives: 2, 9

As a result, alternative(s) 9 were disabled for that input
warning(200): IdentifiersParser.g:524:5: 
Decision can match input such as &quot;{AMPERSAND..BITWISEXOR, DIV..DIVIDE, EQUAL..EQUAL_NS, GREATERTHAN..GREATERTHANOREQUALTO, KW_AND, KW_ARRAY, KW_BETWEEN..KW_BOOLEAN, KW_CASE, KW_DOUBLE, KW_FLOAT, KW_IF, KW_IN, KW_INT, KW_LIKE, KW_MAP, KW_NOT, KW_OR, KW_REGEXP, KW_RLIKE, KW_SMALLINT, KW_STRING..KW_STRUCT, KW_TINYINT, KW_UNIONTYPE, KW_WHEN, LESSTHAN..LESSTHANOREQUALTO, MINUS..NOTEQUAL, PLUS, STAR, TILDE}&quot; using multiple alternatives: 1, 3

As a result, alternative(s) 3 were disabled for that input
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-exec ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-exec ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec ---
[INFO] Compiling 1387 source files to /data/hive-ptest/working/apache-svn-trunk-source/ql/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java:[41,42] cannot find symbol
symbol  : class HiveFatalException
location: package org.apache.hadoop.hive.ql.metadata
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java:[770,21] cannot find symbol
symbol  : class HiveFatalException
location: class org.apache.hadoop.hive.ql.exec.FileSinkOperator
[INFO] 2 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [3.505s]
[INFO] Hive Ant Utilities ................................ SUCCESS [6.215s]
[INFO] Hive Shims Common ................................. SUCCESS [2.636s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [1.883s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [2.979s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [1.333s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [3.126s]
[INFO] Hive Shims ........................................ SUCCESS [3.527s]
[INFO] Hive Common ....................................... SUCCESS [5.317s]
[INFO] Hive Serde ........................................ SUCCESS [12.190s]
[INFO] Hive Metastore .................................... SUCCESS [24.201s]
[INFO] Hive Query Language ............................... FAILURE [29.831s]
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog HBase Storage Handler ............... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1:39.289s
[INFO] Finished at: Wed Nov 13 14:21:23 EST 2013
[INFO] Final Memory: 40M/436M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java:[41,42] cannot find symbol
[ERROR] symbol  : class HiveFatalException
[ERROR] location: package org.apache.hadoop.hive.ql.metadata
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java:[770,21] cannot find symbol
[ERROR] symbol  : class HiveFatalException
[ERROR] location: class org.apache.hadoop.hive.ql.exec.FileSinkOperator
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-exec
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12613468&lt;/p&gt;</comment>
                            <comment id="13821714" author="jdere" created="Wed, 13 Nov 2013 19:26:57 +0000"  >&lt;p&gt;Had not generated patch correctly, was missing file .. trying again with patch v9.&lt;/p&gt;</comment>
                            <comment id="13822688" author="hiveqa" created="Thu, 14 Nov 2013 18:02:25 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12613662/HIVE-4518.9.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12613662/HIVE-4518.9.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 3 failed/errored test(s), 4610 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_bucket_num_reducers
org.apache.hadoop.hive.ql.exec.vector.TestVectorFilterOperator.testBasicFilterLargeData
org.apache.hadoop.hive.ql.exec.vector.TestVectorFilterOperator.testBasicFilterOperator
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/277/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/277/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/277/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/277/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests failed with: TestsFailedException: 3 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12613662&lt;/p&gt;</comment>
                            <comment id="13824348" author="jdere" created="Sat, 16 Nov 2013 02:42:51 +0000"  >&lt;p&gt;patch v10. Removed the changes related to forwarding/setDone, which looked like the cause of the TestVectorFilterOperator failures. I don&apos;t think the bucket_num_reducers is related to these changes.&lt;/p&gt;</comment>
                            <comment id="13824733" author="hiveqa" created="Sun, 17 Nov 2013 04:40:20 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12614193/HIVE-4518.10.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12614193/HIVE-4518.10.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4613 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/332/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/332/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/332/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/332/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12614193&lt;/p&gt;</comment>
                            <comment id="13827379" author="navis" created="Wed, 20 Nov 2013 06:15:23 +0000"  >&lt;p&gt;Looks good. But lastly, would it be necessary to optionize the name of counter? (I mean HIVECOUNTERCREATEDFILES and HIVECOUNTERFATAL in HiveConf)&lt;/p&gt;</comment>
                            <comment id="13827439" author="jdere" created="Wed, 20 Nov 2013 08:38:03 +0000"  >&lt;p&gt;Do you mean we can just use fixed names rather than allowing configurable values for those counter names? You&apos;re probably right, no need for those names to be configurable, as long as we can configure the counter group for these counters.  Let me know if that is what you mean, I will make the change if so.&lt;/p&gt;</comment>
                            <comment id="13830245" author="jdere" created="Fri, 22 Nov 2013 19:20:24 +0000"  >&lt;p&gt;patch v11 - counter names don&apos;t need to be configurable. Also rebase with trunk&lt;/p&gt;</comment>
                            <comment id="13830497" author="hiveqa" created="Sat, 23 Nov 2013 01:35:13 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12615372/HIVE-4518.11.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12615372/HIVE-4518.11.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4679 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/404/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/404/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/404/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/404/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12615372&lt;/p&gt;</comment>
                            <comment id="13831131" author="navis" created="Mon, 25 Nov 2013 01:29:01 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13832152" author="navis" created="Tue, 26 Nov 2013 01:07:40 +0000"  >&lt;p&gt;Committed to trunk. Thanks Gunther and Jason!&lt;/p&gt;</comment>
                            <comment id="13848991" author="lefty@hortonworks.com" created="Mon, 16 Dec 2013 10:08:16 +0000"  >&lt;p&gt;This patch removed &lt;b&gt;hive.task.progress&lt;/b&gt; from HiveConf.java and hive-default.xml.template, so I revised the Configuration Properties wiki with a version note:  &quot;Removed in: Hive 0.13.0 with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-4518&quot; title=&quot;Counter Strike: Operation Operator&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-4518&quot;&gt;&lt;del&gt;HIVE-4518&lt;/del&gt;&lt;/a&gt;&#65279;&quot; (see &lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties&lt;/a&gt; and search for &quot;hive.task.progress&quot;).&lt;/p&gt;

&lt;p&gt;But the patch also added &lt;b&gt;hive.counters.group.name&lt;/b&gt; to HiveConf.java without defining it in hive-default.xml.template.  Would someone please put a definition in the release note for this ticket?  Then it can be added to hive-default.xml.template, either with the spelling fixes in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5879&quot; title=&quot;Fix spelling errors in hive-default.xml&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-5879&quot;&gt;&lt;del&gt;HIVE-5879&lt;/del&gt;&lt;/a&gt; or in a follow-up ticket when the Config Props wiki gets synchronized with hive-default.xml.template, and I&apos;ll add it to the wiki.&lt;/p&gt;</comment>
                            <comment id="13869447" author="lefty@hortonworks.com" created="Mon, 13 Jan 2014 12:21:18 +0000"  >&lt;p&gt;Someone already added &lt;b&gt;hive.counters.group.name&lt;/b&gt; to hive-default.xml.template with this description:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The name of counter group for internal Hive variables (CREATED_FILE, FATAL_ERROR, etc.)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;So I&apos;ve added it to the wiki with this merged description:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Counter group name for counters used during query execution. The counter group is used for internal Hive variables (CREATED_FILE, FATAL_ERROR, and so on).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;See &lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Configuration Properties&lt;/a&gt; &amp;#8211; it&apos;s listed in the Query Execution section right after &lt;b&gt;hive.task.progress&lt;/b&gt;.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12669989">HIVE-5342</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12510627">HIVE-2227</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12582189" name="HIVE-4518.1.patch" size="362284" author="hagleitn" created="Tue, 7 May 2013 22:53:45 +0000"/>
                            <attachment id="12614193" name="HIVE-4518.10.patch" size="383031" author="jdere" created="Sat, 16 Nov 2013 02:42:51 +0000"/>
                            <attachment id="12615372" name="HIVE-4518.11.patch" size="383372" author="jdere" created="Fri, 22 Nov 2013 19:20:24 +0000"/>
                            <attachment id="12583413" name="HIVE-4518.2.patch" size="368780" author="hagleitn" created="Thu, 16 May 2013 00:51:10 +0000"/>
                            <attachment id="12583419" name="HIVE-4518.3.patch" size="368945" author="hagleitn" created="Thu, 16 May 2013 01:09:21 +0000"/>
                            <attachment id="12584178" name="HIVE-4518.4.patch" size="375661" author="hagleitn" created="Tue, 21 May 2013 21:48:21 +0000"/>
                            <attachment id="12592288" name="HIVE-4518.5.patch" size="378037" author="hagleitn" created="Mon, 15 Jul 2013 07:01:33 +0000"/>
                            <attachment id="12613111" name="HIVE-4518.6.patch.txt" size="380674" author="navis" created="Mon, 11 Nov 2013 08:54:41 +0000"/>
                            <attachment id="12613268" name="HIVE-4518.7.patch" size="383484" author="jdere" created="Tue, 12 Nov 2013 00:09:23 +0000"/>
                            <attachment id="12613468" name="HIVE-4518.8.patch" size="383484" author="jdere" created="Tue, 12 Nov 2013 23:53:30 +0000"/>
                            <attachment id="12613662" name="HIVE-4518.9.patch" size="385010" author="jdere" created="Wed, 13 Nov 2013 19:26:57 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 16 May 2013 02:13:20 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326871</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 2 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ke3b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>327216</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Added config setting hive.counters.group.name: counter group name for counters used during query execution.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-4519] JDBC getColumnTypeName() should respond with the Hive-specifc type name for ARRAY, STRUCT and MAP</title>
                <link>https://issues.apache.org/jira/browse/HIVE-4519</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Per the Javadocs for ResultSetMetaData#getColumnTypeName():&lt;/p&gt;

&lt;p&gt;&quot;type name used by the database. If the column type is a user-defined type, then a fully-qualified type name is returned.&quot;&lt;/p&gt;

&lt;p&gt;Hive&apos;s type for array, struct and map is not String. It is array, struct or map, using a JSON string serialization. Returning the Hive type here will allow you to programmatically determine if you should parse the value in the ResultSet as JSON.&lt;/p&gt;

&lt;p&gt;ResultSetMetaData#getColumnType() should potentially return OTHER to indicate the column is a database-specific return type.&lt;/p&gt;

&lt;p&gt;This would replace the fix provided &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1378&quot; title=&quot;Return value for map, array, and struct needs to return a string &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1378&quot;&gt;&lt;del&gt;HIVE-1378&lt;/del&gt;&lt;/a&gt;. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12646525">HIVE-4519</key>
            <summary>JDBC getColumnTypeName() should respond with the Hive-specifc type name for ARRAY, STRUCT and MAP</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="robertroland">Robert Roland</assignee>
                                    <reporter username="robertroland">Robert Roland</reporter>
                        <labels>
                    </labels>
                <created>Tue, 7 May 2013 23:46:55 +0000</created>
                <updated>Thu, 16 Jan 2014 22:08:13 +0000</updated>
                            <resolved>Thu, 16 Jan 2014 22:08:13 +0000</resolved>
                                    <version>0.11.0</version>
                                    <fixVersion>0.13.0</fixVersion>
                                    <component>JDBC</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="13651449" author="robertroland" created="Tue, 7 May 2013 23:47:54 +0000"  >&lt;p&gt;Patch is based off trunk, r1479992&lt;/p&gt;</comment>
                            <comment id="13692598" author="robertroland" created="Tue, 25 Jun 2013 00:05:25 +0000"  >&lt;p&gt;Updating patch filename to match the submitter guidelines in the wiki&lt;/p&gt;</comment>
                            <comment id="13692600" author="robertroland" created="Tue, 25 Jun 2013 00:06:25 +0000"  >&lt;p&gt;Can I get a code review, please? Thanks!&lt;/p&gt;</comment>
                            <comment id="13696627" author="ashutoshc" created="Mon, 1 Jul 2013 07:34:45 +0000"  >&lt;p&gt;We should also update the corresponding java.sql.Types mapping in service/src/java/org/apache/hive/service/cli/Type.java. I think following makes sense:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;ARRAY =&amp;gt; java.sql.Types.ARRAY&lt;/li&gt;
	&lt;li&gt;MAP =&amp;gt; java.sql.Types.JAVA_OBJECT&lt;/li&gt;
	&lt;li&gt;STRUCT =&amp;gt; java.sql.Types.STRUCT&lt;/li&gt;
	&lt;li&gt;UNION =&amp;gt; java.sql.Types.OTHER&lt;/li&gt;
	&lt;li&gt;USER_DEFINED_TYPES =&amp;gt; java.sql.Types.OTHER&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13873016" author="navis" created="Thu, 16 Jan 2014 04:02:08 +0000"  >&lt;p&gt;Addressed comments. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt;, could you check this?&lt;/p&gt;</comment>
                            <comment id="13873039" author="navis" created="Thu, 16 Jan 2014 04:45:57 +0000"  >&lt;p&gt;Implemented &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3015&quot; title=&quot;org.apache.hadoop.hive.jdbc.HiveResultSetMetaData.getColumnClassName Method not supported&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3015&quot;&gt;&lt;del&gt;HIVE-3015&lt;/del&gt;&lt;/a&gt; also in this.&lt;/p&gt;</comment>
                            <comment id="13873653" author="ashutoshc" created="Thu, 16 Jan 2014 17:44:41 +0000"  >&lt;p&gt;+1 Looks like Hive QA didn&apos;t trigger.&lt;/p&gt;</comment>
                            <comment id="13873685" author="hiveqa" created="Thu, 16 Jan 2014 18:11:24 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12623308/HIVE-4519.3.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12623308/HIVE-4519.3.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4927 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/934/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/934/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/934/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/934/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12623308&lt;/p&gt;</comment>
                            <comment id="13874030" author="ashutoshc" created="Thu, 16 Jan 2014 22:08:13 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Robert &amp;amp; Navis!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12554873">HIVE-3015</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12589520" name="HIVE-4519.1.patch.txt" size="6066" author="robertroland" created="Tue, 25 Jun 2013 00:05:04 +0000"/>
                            <attachment id="12623302" name="HIVE-4519.2.patch.txt" size="9653" author="navis" created="Thu, 16 Jan 2014 04:00:58 +0000"/>
                            <attachment id="12623308" name="HIVE-4519.3.patch.txt" size="20993" author="navis" created="Thu, 16 Jan 2014 04:45:57 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 1 Jul 2013 07:34:45 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>326883</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 1 week, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ke5z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>327228</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>
</channel>
</rss>
