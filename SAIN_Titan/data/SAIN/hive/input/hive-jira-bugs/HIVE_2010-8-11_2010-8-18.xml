<!--
RSS generated by JIRA (7.6.3#76005-sha1:8a4e38d34af948780dbf52044e7aafb13a7cae58) at Tue Jan 22 15:16:24 UTC 2019

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<!-- If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
    <channel>
        <title>ASF JIRA</title>
        <link>https://issues.apache.org/jira/issues/?jql=project+%3D+HIVE+AND+created+%3E%3D+2010-8-11+AND+created+%3C%3D+2010-8-18+ORDER+BY+key+ASC</link>
        <description>An XML representation of a search request</description>
                <language>en-uk</language>
                        <issue start="0" end="25" total="25"/>
                <build-info>
            <version>7.6.3</version>
            <build-number>76005</build-number>
            <build-date>09-01-2018</build-date>
        </build-info>

<item>
            <title>[HIVE-1527] Remove Thrift generated code from version control</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1527</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;The current practice is to checkin code generated by the Thrift compiler.&lt;br/&gt;
This makes the development process slightly easier for some developers&lt;br/&gt;
(since you don&apos;t need to have the Thrift compiler installed in most cases),&lt;br/&gt;
but results noisy diffs when the thrift bindings are actually changed.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Remove the thrift generated code from version control&lt;/li&gt;
	&lt;li&gt;Make the &lt;tt&gt;thriftif&lt;/tt&gt; target part of the standard build.&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
        <key id="12471240">HIVE-1527</key>
            <summary>Remove Thrift generated code from version control</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="cwsteinbach">Carl Steinbach</reporter>
                        <labels>
                    </labels>
                <created>Wed, 11 Aug 2010 00:05:26 +0000</created>
                <updated>Tue, 21 Sep 2010 21:16:35 +0000</updated>
                                                                            <component>Build Infrastructure</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                    <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12471232">HIVE-1526</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42458</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 24 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08nm7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>48425</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-1528] Add json_tuple() UDTF function</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1528</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently the only way to evaluate a path expression on a JSON object is through get_json_object. If there are many fields in the JSON object need to be extract, we have to call this UDF multiple times. &lt;/p&gt;

&lt;p&gt;There are many use cases that get_json_object needs to be called many times in one query to convert the JSON object to a relational schema. It would be much desirable if we have a JSON UDTF that supports the following syntax:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;select a.id, b.*
from a lateral view json_tuple(a.json_str, &lt;span class=&quot;code-quote&quot;&gt;&apos;$.f1&apos;&lt;/span&gt;,  &lt;span class=&quot;code-quote&quot;&gt;&apos;$.f2&apos;&lt;/span&gt;, ..., &lt;span class=&quot;code-quote&quot;&gt;&apos;$.fn&apos;&lt;/span&gt;) b as f1, f2, ..., fn
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;where the json_table function only scans the json_object once and return a set of tuple of (f1, f2,..., fn). &lt;/p&gt;</description>
                <environment></environment>
        <key id="12471326">HIVE-1528</key>
            <summary>Add json_tuple() UDTF function</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nzhang">Ning Zhang</assignee>
                                    <reporter username="nzhang">Ning Zhang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 11 Aug 2010 17:44:44 +0000</created>
                <updated>Sat, 17 Dec 2011 00:01:08 +0000</updated>
                            <resolved>Fri, 13 Aug 2010 04:51:47 +0000</resolved>
                                    <version>0.7.0</version>
                                    <fixVersion>0.7.0</fixVersion>
                                    <component>UDF</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12898033" author="nzhang" created="Fri, 13 Aug 2010 01:22:41 +0000"  >&lt;p&gt;Based on offline discussion with Paul, added a new unit test of putting json_tuple in the select clause. Also removed temporary changes in UDFJson.java.&lt;/p&gt;</comment>
                            <comment id="12898034" author="pauly" created="Fri, 13 Aug 2010 01:24:55 +0000"  >&lt;p&gt;Looks good +1&lt;/p&gt;</comment>
                            <comment id="12898039" author="jvs" created="Fri, 13 Aug 2010 01:45:57 +0000"  >&lt;p&gt;Will commit if tests pass.&lt;/p&gt;</comment>
                            <comment id="12898076" author="jvs" created="Fri, 13 Aug 2010 04:51:47 +0000"  >&lt;p&gt;Committed.  Thanks Ning!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12451975" name="HIVE-1528.2.patch" size="31834" author="nzhang" created="Fri, 13 Aug 2010 01:22:41 +0000"/>
                            <attachment id="12451968" name="HIVE-1528.patch" size="33166" author="nzhang" created="Thu, 12 Aug 2010 23:01:57 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 13 Aug 2010 01:24:55 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72855</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 24 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfj3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123166</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1529] Add ANSI SQL covariance aggregate functions: covar_pop and covar_samp.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1529</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Create new built-in aggregate functions covar_pop and covar_samp, functions commonly used in statistical data analyses.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471341">HIVE-1529</key>
            <summary>Add ANSI SQL covariance aggregate functions: covar_pop and covar_samp.</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="p_huyn">Pierre Huyn</assignee>
                                    <reporter username="p_huyn">Pierre Huyn</reporter>
                        <labels>
                    </labels>
                <created>Wed, 11 Aug 2010 19:33:57 +0000</created>
                <updated>Sat, 17 Dec 2011 00:01:00 +0000</updated>
                            <resolved>Tue, 17 Aug 2010 01:02:15 +0000</resolved>
                                    <version>0.7.0</version>
                                    <fixVersion>0.7.0</fixVersion>
                                    <component>UDF</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                    <timeoriginalestimate seconds="345600">96h</timeoriginalestimate>
                            <timeestimate seconds="345600">96h</timeestimate>
                                        <comments>
                            <comment id="12897441" author="p_huyn" created="Wed, 11 Aug 2010 20:38:51 +0000"  >&lt;p&gt;Work is currently under way. Actually the code is done and tested. I am going doing the checklist, moving toward patch submit. Since this is my first assignment, I am not familiar with the process and it may take a little longer to get to the submission point.&lt;/p&gt;</comment>
                            <comment id="12897502" author="p_huyn" created="Wed, 11 Aug 2010 22:59:18 +0000"  >&lt;p&gt;Hi John,&lt;/p&gt;

&lt;p&gt;Now that I have created the .q test file, how do I generate the corresponding .q.out file? I assume the latter is needed by &quot;ant test&quot;. Thanks.&lt;/p&gt;

&lt;p&gt;Regards&lt;br/&gt;
&amp;#8212; Pierre&lt;/p&gt;

</comment>
                            <comment id="12897510" author="jvs" created="Wed, 11 Aug 2010 23:29:32 +0000"  >&lt;p&gt;Run ant test with -Doverwrite=true&lt;/p&gt;</comment>
                            <comment id="12897557" author="p_huyn" created="Thu, 12 Aug 2010 03:11:20 +0000"  >&lt;p&gt;Hi John,&lt;/p&gt;

&lt;p&gt;Thanks for your help. Now that I am getting further, is there a recommended way to create and populate the table used in my .q test file? I look at the other .q files and many of them use &quot;src&quot; without defining it. Also, I don&apos;t see where the &quot;src&quot; is populated. Help!&lt;br/&gt;
Regards&lt;br/&gt;
&amp;#8212; Pierre&lt;/p&gt;
</comment>
                            <comment id="12897921" author="jvs" created="Thu, 12 Aug 2010 19:48:02 +0000"  >&lt;p&gt;&quot;src&quot; is a test fixture (automatically created for use by all tests).&lt;/p&gt;

&lt;p&gt;For an example of how to add a test-specific dataset, see&lt;/p&gt;

&lt;p&gt;ql/src/test/queries/clientpositive/nullscript.q&lt;/p&gt;

&lt;p&gt;svn add your new file under hive-trunk/data/files.&lt;/p&gt;</comment>
                            <comment id="12897970" author="p_huyn" created="Thu, 12 Aug 2010 22:05:49 +0000"  >&lt;p&gt;This is the first release of 2 covariance generic UDAF: population covariance covar_pop(x,y) and sample covariance covar_samp(x,y).&lt;/p&gt;

&lt;p&gt;I am requesting a code review.&lt;/p&gt;</comment>
                            <comment id="12897973" author="p_huyn" created="Thu, 12 Aug 2010 22:08:38 +0000"  >&lt;p&gt;This is the initial release of the covariance generic UDAFs, covar_pop and covar_samp.&lt;/p&gt;</comment>
                            <comment id="12898003" author="mayanklahiri" created="Thu, 12 Aug 2010 23:39:13 +0000"  >&lt;p&gt;Hi Pierre,&lt;/p&gt;

&lt;p&gt;The numerical results appear to be accurate. A couple of comments about the code:&lt;/p&gt;

&lt;p&gt;(1) Run &quot;ant checkstyle&quot; and looks at the formatting errors for your file in the build/checkstyle/checkstyle-errors.html file. In particular, remove commented lines like #160 of GenericUDAFCovariance.java, and newline-elses like line #214, unnecessary wraps #210-211&lt;/p&gt;

&lt;p&gt;(2) Is there any reason for accepting string arguments in the Resolver class? If the user has a numeric value as a string, they can simply (CAST val AS double) in the query. As it stands right now, passing junk strings as one of the input expressions causes a return value of NULL and a silent exception that is only visible in the log file. It might be better to simply not accept STRING types in the resolver, as in GenericUDAFHistogramNumeric.java. This would also mean that you don&apos;t have to test for a NumberFormatException in the iterate() method &amp;#8211; line #263 of GenericUDAFCovariance.java.&lt;/p&gt;

&lt;p&gt;(3) Please add at least a little extended function info, line #59, see GenericUDAFHistogramNumeric.java or GenericUDAFnGrams.java for an example.&lt;/p&gt;</comment>
                            <comment id="12898022" author="p_huyn" created="Fri, 13 Aug 2010 00:39:12 +0000"  >&lt;p&gt;Hi Mayank,&lt;/p&gt;

&lt;p&gt;Thanks for reviewing. Please bear with me, as this is my first time. I am looking at the checkstyle-errors.html file but I cannot find the problems you reported. The only thing I found is &quot;File contains tab characters (this is the first instance).&quot; on line 177.&lt;/p&gt;

&lt;p&gt;Are there other log files I need to look at to find style errors? Are tab characters now allowed?&lt;/p&gt;

&lt;p&gt;Regards&lt;br/&gt;
&amp;#8212; Pierre&lt;/p&gt;
</comment>
                            <comment id="12898364" author="mayanklahiri" created="Fri, 13 Aug 2010 18:50:33 +0000"  >&lt;p&gt;Happy to help! It gets a lot easier after the first couple of UD(A)Fs...&lt;/p&gt;

&lt;p&gt;For the code conventions, Hive uses the Sun Java code conventions: &lt;a href=&quot;http://www.oracle.com/technetwork/java/codeconvtoc-136057.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.oracle.com/technetwork/java/codeconvtoc-136057.html&lt;/a&gt; (the example usage section is probably the most helpful, and I believe not all of them are checked by checkstyle.)&lt;/p&gt;</comment>
                            <comment id="12898415" author="p_huyn" created="Fri, 13 Aug 2010 20:51:41 +0000"  >&lt;p&gt;Implemented all feedback from reviewer.&lt;/p&gt;</comment>
                            <comment id="12898457" author="p_huyn" created="Fri, 13 Aug 2010 22:44:38 +0000"  >&lt;p&gt;Updated patch ready for review&lt;/p&gt;</comment>
                            <comment id="12899107" author="mayanklahiri" created="Mon, 16 Aug 2010 21:35:49 +0000"  >&lt;p&gt;+1 Looks good, passes tests.&lt;/p&gt;

&lt;p&gt;Note: there is a new data file to be added in data/files/covar_tab.txt &lt;/p&gt;</comment>
                            <comment id="12899113" author="jvs" created="Mon, 16 Aug 2010 21:54:01 +0000"  >&lt;p&gt;Will commit when tests pass.&lt;/p&gt;</comment>
                            <comment id="12899223" author="jvs" created="Tue, 17 Aug 2010 01:02:15 +0000"  >&lt;p&gt;Committed.  Thanks Pierre!&lt;/p&gt;</comment>
                            <comment id="12899460" author="p_huyn" created="Tue, 17 Aug 2010 16:38:38 +0000"  >&lt;p&gt;Hi John,&lt;/p&gt;

&lt;p&gt;Cool! Thanks for committing. I have a question for you about open source contributions. I would like to contribute more going forward and would like my company (Intuit) to allocate more resource (essentially my time) on open source contributions. What would people do commonly? How would my company be recognized for giving back?&lt;/p&gt;
</comment>
                            <comment id="12899542" author="jvs" created="Tue, 17 Aug 2010 19:35:28 +0000"  >&lt;p&gt;Hey Pierre,&lt;/p&gt;

&lt;p&gt;I don&apos;t know if we have one already, but we can certainly start a wiki page acknowledging the contributions from all of the companies and individuals who have helped with the development of Hive.&lt;/p&gt;

&lt;p&gt;Also, if you&apos;re in the Bay Area, come on by one of our contributor meetups so we can connect in person.&lt;/p&gt;</comment>
                            <comment id="12899546" author="p_huyn" created="Tue, 17 Aug 2010 19:45:20 +0000"  >&lt;p&gt;Hi John,&lt;/p&gt;

&lt;p&gt;That&apos;s cool. When and where will the next one be? I am in Mountain View/Palo Alto.&lt;br/&gt;
&amp;#8212; Pierre&lt;/p&gt;
</comment>
                            <comment id="12899629" author="jvs" created="Tue, 17 Aug 2010 22:37:24 +0000"  >&lt;p&gt;Next one will be at Cloudera, probably some time in September.  Join this meetup group to get notifications and RSVP:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.meetup.com/Hive-Contributors-Group/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.meetup.com/Hive-Contributors-Group/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12906081" author="jvs" created="Fri, 3 Sep 2010 20:48:48 +0000"  >&lt;p&gt;BTW, Pierre, I found this wiki page:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://wiki.apache.org/hadoop/Hive/PoweredBy&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Hive/PoweredBy&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Feel free to add Intuit there and note that the company is contributing resources to improve Hive.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12451958" name="HIVE-1529.1.patch" size="29722" author="p_huyn" created="Thu, 12 Aug 2010 22:05:49 +0000"/>
                            <attachment id="12452053" name="HIVE-1529.2.patch" size="30751" author="p_huyn" created="Fri, 13 Aug 2010 20:51:41 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 11 Aug 2010 23:29:32 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72854</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 21 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfjb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123167</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>New patch available for review.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>ANSI SQL covariance aggregation function</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1530] Include hive-default.xml and hive-log4j.properties in hive-common JAR</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1530</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;hive-common-*.jar should include hive-default.xml and hive-log4j.properties,&lt;br/&gt;
and similarly hive-exec-*.jar should include hive-exec-log4j.properties. The&lt;br/&gt;
hive-default.xml file that currently sits in the conf/ directory should be removed.&lt;/p&gt;

&lt;p&gt;Motivations for this change:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;We explicitly tell users that they should never modify hive-default.xml yet give them the opportunity to do so by placing the file in the conf dir.&lt;/li&gt;
	&lt;li&gt;Many users are familiar with the Hadoop configuration mechanism that does not require *-default.xml files to be present in the HADOOP_CONF_DIR, and assume that the same is true for HIVE_CONF_DIR.&lt;/li&gt;
&lt;/ul&gt;

</description>
                <environment></environment>
        <key id="12471357">HIVE-1530</key>
            <summary>Include hive-default.xml and hive-log4j.properties in hive-common JAR</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="6">Invalid</resolution>
                                        <assignee username="cwsteinbach">Carl Steinbach</assignee>
                                    <reporter username="cwsteinbach">Carl Steinbach</reporter>
                        <labels>
                    </labels>
                <created>Wed, 11 Aug 2010 21:44:28 +0000</created>
                <updated>Thu, 2 May 2013 02:28:56 +0000</updated>
                            <resolved>Wed, 4 Jan 2012 00:55:22 +0000</resolved>
                                                                    <component>Configuration</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>4</watches>
                                                                                                            <comments>
                            <comment id="12897993" author="jsensarma" created="Thu, 12 Aug 2010 23:03:27 +0000"  >&lt;p&gt;removing the .xml files makes sense.&lt;/p&gt;

&lt;p&gt;but users may want to modify the log4.properties files. how would do they do that in the new arrangement?&lt;/p&gt;</comment>
                            <comment id="12898030" author="appodictic" created="Fri, 13 Aug 2010 01:10:45 +0000"  >&lt;p&gt;I like the default xml. Hive has many undocumented options, new ones are being added often. Are end users going to know which jar the default.xml are in? Users want to extracting a jar just to get the conf out of it to read the description of the setting.&lt;/p&gt;

&lt;p&gt;As for what hadoop does...I personally find it annoying to have navigate to hadoop/src/mapred/mapred-default.xml or to hadoop/src/hdfs/hdfs-default.xml to figure out what options I have for settings. So i do not really thing we should just do it to be like hadoop it it makes peoples life harder.&lt;/p&gt;

&lt;p&gt;If anything please keep it as hive-site.xml.sample.&lt;/p&gt;</comment>
                            <comment id="12898038" author="cwsteinbach" created="Fri, 13 Aug 2010 01:41:33 +0000"  >&lt;blockquote&gt;&lt;p&gt;but users may want to modify the log4.properties files. how would do they do that in the new arrangement?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hive uses a classloader to get the hive-log4j and hive-exec-log4j property resources. If a user wants to override the log4j properties that are bundled with the JAR they only need to make sure that their copy appears first on the CLASSPATH.&lt;/p&gt;
</comment>
                            <comment id="12898040" author="cwsteinbach" created="Fri, 13 Aug 2010 01:47:26 +0000"  >&lt;p&gt;@Ed: In my opinion the ideal solution is to get rid of the hive-default.xml file entirely and rely on the default values that appear in HiveConf. We can add a &lt;tt&gt;describe property xxxx&lt;/tt&gt; command that prints out a description of the property, and also add checks that protect the &lt;tt&gt;hive.&lt;b&gt;&lt;/tt&gt; configuration property namespace (i.e. you can&apos;t set a &lt;tt&gt;hive.&lt;/b&gt;&lt;/tt&gt; property unless it is defined in HiveConf).  Another advantage of this approach is that we don&apos;t have to worry about hive-default.xml falling out of sync with HiveConf, e.g. a user upgrades to a new version of Hive but continues to use an older copy of hive-default.xml.&lt;/p&gt;</comment>
                            <comment id="12898080" author="jsensarma" created="Fri, 13 Aug 2010 05:00:50 +0000"  >&lt;p&gt;ok - that makes sense. leave a hive-site.xml.sample and hive-log4j.properties.example in the conf/. i agree with Ed&apos;s point about how difficult it is to figure out hadoop config variables now and hadoop is worse off for it. commands are nice - but having a template is better. it&apos;s easy to clone an example file and append/modify the default description to add site specific notes. and one can grep.&lt;/p&gt;

&lt;p&gt;we could autogenerate the hive-site.xml.sample from config variable metadata in the source code. that would keep us in sync with code.&lt;/p&gt;</comment>
                            <comment id="12898118" author="jsensarma" created="Fri, 13 Aug 2010 07:38:25 +0000"  >&lt;p&gt;don&apos;t dis-allow hive.* options not specified in HiveConf. reason is that hive is extensible at various points via custom code and those have access to config object and installs may want to set variables specific to their plugins etc. (we shouldn&apos;t be in the business of telling them what not to name them)&lt;/p&gt;</comment>
                            <comment id="12898266" author="appodictic" created="Fri, 13 Aug 2010 15:04:10 +0000"  >&lt;p&gt;@Joydeep +1 &lt;/p&gt;</comment>
                            <comment id="12914419" author="hbasereviewboard" created="Fri, 24 Sep 2010 11:25:30 +0000"  >&lt;p&gt;Message from: &quot;Carl Steinbach&quot; &amp;lt;carl@cloudera.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/902/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/902/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for Hive Developers.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1530&quot; title=&quot;Include hive-default.xml and hive-log4j.properties in hive-common JAR&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1530&quot;&gt;&lt;del&gt;HIVE-1530&lt;/del&gt;&lt;/a&gt;.1.patch.txt:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Move conf/hive-default.xml to common/resources/hive-default.xml and modify the build so that this gets included in hive-common-xxx.jar&lt;/li&gt;
	&lt;li&gt;Copy contents of conf/hive-default.xml to conf/hive-site.xml.template&lt;/li&gt;
	&lt;li&gt;Modify HiveConf so that it logs an INFO level message with the location of the hive-default.xml and hive-site.xml files which were loaded.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1530&quot; title=&quot;Include hive-default.xml and hive-log4j.properties in hive-common JAR&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1530&quot;&gt;&lt;del&gt;HIVE-1530&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/HIVE-1530&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HIVE-1530&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  build.xml 4b345b5 &lt;br/&gt;
  common/build.xml d9ac07e &lt;br/&gt;
  common/resources/hive-default.xml PRE-CREATION &lt;br/&gt;
  common/src/java/org/apache/hadoop/hive/conf/HiveConf.java 47b7518 &lt;br/&gt;
  conf/hive-default.xml 1465317 &lt;br/&gt;
  conf/hive-site.xml.template PRE-CREATION &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.cloudera.org/r/902/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/902/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Carl&lt;/p&gt;

</comment>
                            <comment id="12914528" author="philip" created="Fri, 24 Sep 2010 16:45:35 +0000"  >&lt;p&gt;+1.  I&apos;m a big fan of this change.&lt;/p&gt;

&lt;p&gt;We&apos;ve repeatedly had customers using an old or weird hive-default or non-existent hive-default, and that&apos;s caused quite tricky to debug issues.&lt;/p&gt;</comment>
                            <comment id="12923818" author="tucu00" created="Fri, 22 Oct 2010 11:05:27 +0000"  >&lt;p&gt;+1 for this change.&lt;/p&gt;

&lt;p&gt;The hive-default.xml can be provided in the distribution in a docs directory for documentation purposes for user.&lt;/p&gt;

&lt;p&gt;But the defaults used by the runtime should always come from the JAR.&lt;/p&gt;

&lt;p&gt;For log4j configuration, the JAR should include a default one, but the user should be able to provide an alternate one in the command line (like Pig). But this may be another issue.&lt;/p&gt;</comment>
                            <comment id="12983412" author="cwsteinbach" created="Tue, 18 Jan 2011 22:26:27 +0000"  >&lt;p&gt;I need to rebase the patch.&lt;/p&gt;</comment>
                            <comment id="13179184" author="cwsteinbach" created="Wed, 4 Jan 2012 00:55:22 +0000"  >&lt;p&gt;Resolving as INVALID since hive-default.xml no longer exists.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310051">
                    <name>Supercedes</name>
                                            <outwardlinks description="supercedes">
                                        <issuelink>
            <issuekey id="12506647">HIVE-2152</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12492754">HIVE-1841</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12455484" name="HIVE-1530.1.patch.txt" size="88135" author="cwsteinbach" created="Fri, 24 Sep 2010 11:00:51 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12498229">HIVE-1983</subtask>
                            <subtask id="12498241">HIVE-1984</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 12 Aug 2010 23:03:27 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>37491</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 3 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i05iov:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>30125</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1531] Make Hive build work with Ivy versions &lt; 2.1.0</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1531</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Many projects in the Hadoop ecosystem still use Ivy 2.0.0 (including Hadoop and Pig),&lt;br/&gt;
yet Hive requires version 2.1.0. Ordinarily this would not be a problem, but many users&lt;br/&gt;
have a copy of an older version of Ivy in their $ANT_HOME directory, and this copy will&lt;br/&gt;
always get picked up in preference to what the Hive build downloads for itself.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471364">HIVE-1531</key>
            <summary>Make Hive build work with Ivy versions &lt; 2.1.0</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cwsteinbach">Carl Steinbach</assignee>
                                    <reporter username="cwsteinbach">Carl Steinbach</reporter>
                        <labels>
                    </labels>
                <created>Thu, 12 Aug 2010 01:16:48 +0000</created>
                <updated>Sat, 17 Dec 2011 00:03:59 +0000</updated>
                            <resolved>Fri, 13 Aug 2010 20:29:03 +0000</resolved>
                                                    <fixVersion>0.6.0</fixVersion>
                                    <component>Build Infrastructure</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12897539" author="cwsteinbach" created="Thu, 12 Aug 2010 01:26:32 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1531&quot; title=&quot;Make Hive build work with Ivy versions &amp;lt; 2.1.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1531&quot;&gt;&lt;del&gt;HIVE-1531&lt;/del&gt;&lt;/a&gt;.patch.txt:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Changed Ivy offline defaultTTL from &quot;eternal&quot; to &quot;1000d&quot;&lt;/li&gt;
	&lt;li&gt;Verified that this change allows the Hive build to work with Ivy 2.0.0&lt;/li&gt;
&lt;/ul&gt;

</comment>
                            <comment id="12898032" author="jvs" created="Fri, 13 Aug 2010 01:18:25 +0000"  >&lt;p&gt;+1.  Will commit when tests pass.&lt;/p&gt;</comment>
                            <comment id="12898406" author="jvs" created="Fri, 13 Aug 2010 20:29:03 +0000"  >&lt;p&gt;Committed to branch and trunk.  Thanks Carl!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12447044">HIVE-1120</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12451852" name="HIVE-1531.patch.txt" size="654" author="cwsteinbach" created="Thu, 12 Aug 2010 01:26:32 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 13 Aug 2010 01:18:25 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72853</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 24 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfjj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123168</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1532] Replace globStatus with listStatus inside Hive.java&apos;s replaceFiles.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1532</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;globStatus expects a regular expression,  so if there is special characters (like &apos;{&apos; , &apos;[&apos;) in the filepath, this function will fail.&lt;/p&gt;

&lt;p&gt;We should be able to replace this call with listStatus easily since we are not passing regex to replaceFiles(). The only places replaceFiles is called is in loadPartition and Table&apos;s replaceFiles.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471366">HIVE-1532</key>
            <summary>Replace globStatus with listStatus inside Hive.java&apos;s replaceFiles.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="he yongqiang">He Yongqiang</assignee>
                                    <reporter username="he yongqiang">He Yongqiang</reporter>
                        <labels>
                    </labels>
                <created>Thu, 12 Aug 2010 02:42:33 +0000</created>
                <updated>Fri, 16 Dec 2011 23:59:36 +0000</updated>
                            <resolved>Sun, 15 Aug 2010 05:51:11 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12898653" author="namit" created="Sat, 14 Aug 2010 23:06:10 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;will commit if the tests pass&lt;/p&gt;</comment>
                            <comment id="12898663" author="namit" created="Sun, 15 Aug 2010 05:51:11 +0000"  >&lt;p&gt;Committed. Thanks yongqiang&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12452113" name="Hive-1532.1.patch" size="3440" author="he yongqiang" created="Sat, 14 Aug 2010 21:44:33 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 14 Aug 2010 23:06:10 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72852</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 24 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfjr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123169</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1533] Use ZooKeeper from maven</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1533</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Zookeeper is now available from maven. Maybe we should delete the one in hbase-handler/lib and get it via ivy instead of adding it in the top-level lib? The version we have checked in is 3.2.2, but the maven availability is 3.3.x, so we&apos;d need to test to make sure everything (including hbase-handler) still works with the newer version.&lt;br/&gt;
&lt;a href=&quot;http://mvnrepository.com/artifact/org.apache.hadoop/zookeeper&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://mvnrepository.com/artifact/org.apache.hadoop/zookeeper&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471373">HIVE-1533</key>
            <summary>Use ZooKeeper from maven</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Thu, 12 Aug 2010 04:51:28 +0000</created>
                <updated>Fri, 16 Dec 2011 23:59:24 +0000</updated>
                            <resolved>Tue, 1 Feb 2011 19:14:05 +0000</resolved>
                                    <version>0.6.0</version>
                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Testing Infrastructure</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12989341" author="jvs" created="Tue, 1 Feb 2011 19:14:05 +0000"  >&lt;p&gt;Fixed as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1235&quot; title=&quot;use Ivy for fetching HBase dependencies&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1235&quot;&gt;&lt;del&gt;HIVE-1235&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12458734">HIVE-1235</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 1 Feb 2011 19:14:05 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72851</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 51 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfjz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123170</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1534] Join filters do not work correctly with outer joins</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1534</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt; SELECT * FROM T1 LEFT OUTER JOIN T2 ON (T1.c1=T2.c2 AND T1.c1 &amp;lt; 10)&lt;br/&gt;
and  SELECT * FROM T1 RIGHT OUTER JOIN T2 ON (T1.c1=T2.c2 AND T2.c1 &amp;lt; 10)&lt;br/&gt;
do not give correct results.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471377">HIVE-1534</key>
            <summary>Join filters do not work correctly with outer joins</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="amareshwari">Amareshwari Sriramadasu</assignee>
                                    <reporter username="amareshwari">Amareshwari Sriramadasu</reporter>
                        <labels>
                    </labels>
                <created>Thu, 12 Aug 2010 06:05:13 +0000</created>
                <updated>Tue, 6 Sep 2016 23:39:01 +0000</updated>
                            <resolved>Tue, 21 Sep 2010 21:00:41 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="12897587" author="amareshwari" created="Thu, 12 Aug 2010 06:13:09 +0000"  >&lt;p&gt;For a table input3 with following data:&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;key &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; value &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NULL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   35 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;12 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;     NULL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;     1000 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;     100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;    100 &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;The queries&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; SELECT * FROM input3 a left &lt;span class=&quot;code-keyword&quot;&gt;outer&lt;/span&gt; JOIN input3 b ON (a.key=b.key AND a.key &amp;lt; 100);
and
 SELECT * FROM input3 a right &lt;span class=&quot;code-keyword&quot;&gt;outer&lt;/span&gt; JOIN input3 b ON (a.key=b.key AND b.key &amp;lt; 100);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 
&lt;p&gt;produce the output as &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;10      1000    10      100
10      1000    10      1000
10      100     10      100
10      100     10      1000
12      NULL    12      NULL
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Where as the expected output for &lt;br/&gt;
&quot;SELECT * FROM input3 a left outer JOIN input3 b ON (a.key=b.key AND a.key &amp;lt; 100);&quot; is&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; NULL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   35 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; NULL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; NULL &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1000 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1000 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1000 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  100 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; NULL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; NULL &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   12 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; NULL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   12 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; NULL &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1000 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  100 &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt; and expected output for &quot;SELECT * FROM input3 a right outer JOIN input3 b ON (a.key=b.key AND b.key &amp;lt; 100);&quot; is&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; NULL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; NULL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; NULL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   35 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1000 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1000 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1000 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; NULL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; NULL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  100 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   12 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; NULL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   12 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; NULL &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1000 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  100 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  100 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   10 &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  100 &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
</comment>
                            <comment id="12897909" author="jvs" created="Thu, 12 Aug 2010 19:26:52 +0000"  >&lt;p&gt;Definitely a bug.  It happens regardless of the setting of hive.optimize.ppd, so it probably has something to do with the way the join condition is decomposed rather than the predicate pushdown optimization.&lt;/p&gt;</comment>
                            <comment id="12897912" author="jvs" created="Thu, 12 Aug 2010 19:30:12 +0000"  >&lt;p&gt;Assigning this to you in case you want to take a look at it together with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-741&quot; title=&quot;NULL is not handled correctly in join&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-741&quot;&gt;&lt;del&gt;HIVE-741&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="12898124" author="amareshwari" created="Fri, 13 Aug 2010 08:01:24 +0000"  >&lt;p&gt;With ppd on or off, Mapper is filtering out table with alias a on the predicate a.key &amp;lt; 100 for the left outer join query. Similarly on alias b for right outer join query. This is mostly because of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1538&quot; title=&quot;FilterOperator is applied twice with ppd on.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1538&quot;&gt;&lt;del&gt;HIVE-1538&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="12906673" author="amareshwari" created="Tue, 7 Sep 2010 05:02:18 +0000"  >&lt;blockquote&gt;&lt;p&gt;Definitely a bug. It happens regardless of the setting of hive.optimize.ppd, so it probably has something to do with the way the join condition is decomposed rather than the predicate pushdown optimization.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes. This has nothing to do with predicate pushdown. After going through Join implementation, I see that after Join-tree is generated, join filters are pushed and then join operator is generated for the join condition. But for outer joins, filters should be part of the join condition i.e. if the condition is not obeyed (or the filter is not obeyed), the values should be joined with nulls.&lt;/p&gt;</comment>
                            <comment id="12907001" author="namit" created="Tue, 7 Sep 2010 22:32:45 +0000"  >&lt;p&gt;Definitely a bug, but not related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1538&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1538&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For outer joins, the filters should not be pushed above the join.&lt;/p&gt;


&lt;p&gt;For the query,&lt;/p&gt;

&lt;p&gt;SELECT * FROM input3 a left outer JOIN input3 b ON (a.key=b.key AND a.key &amp;lt; 100);&quot; &lt;/p&gt;


&lt;p&gt;the row: 100 100&lt;/p&gt;

&lt;p&gt;is being pruned even before it reaches the join.&lt;/p&gt;

&lt;p&gt;As you suggested above,  the correct solution is to have the filter as part of the join, which we dont support currently.&lt;/p&gt;

&lt;p&gt;For now, I would suggest not supporting filters in the join condition for outer joins, since we are returning wrong results,&lt;br/&gt;
and the correct fix will involve a big change&lt;/p&gt;</comment>
                            <comment id="12907094" author="amareshwari" created="Wed, 8 Sep 2010 05:22:46 +0000"  >&lt;blockquote&gt;&lt;p&gt;I would suggest not supporting filters in the join condition for outer joins, since we are returning wrong results.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Created &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1621&quot; title=&quot;Disable join filters for outer joins.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1621&quot;&gt;&lt;del&gt;HIVE-1621&lt;/del&gt;&lt;/a&gt; for this. Leaving this jira to do the correct fix.&lt;/p&gt;</comment>
                            <comment id="12907605" author="amareshwari" created="Thu, 9 Sep 2010 11:52:40 +0000"  >&lt;p&gt;I worked on separating filters for outer joins. &lt;br/&gt;
Here is a patch which does not push filters for outer joins and filters are applied in the join implementation.&lt;/p&gt;

&lt;p&gt;Patch would need some more work on SMBMapJoin. Please have look if the approach looks fine.&lt;/p&gt;</comment>
                            <comment id="12908657" author="amareshwari" created="Mon, 13 Sep 2010 07:38:11 +0000"  >&lt;p&gt;With the uploaded patch, there is bug with cartesian products and right outer joins, when there are filters. Looking into it.&lt;/p&gt;</comment>
                            <comment id="12908858" author="namit" created="Mon, 13 Sep 2010 16:54:19 +0000"  >&lt;p&gt;The approach looks OK - I will look into the code for more detailed comments.&lt;/p&gt;

&lt;p&gt;One general comment was that you also need to account for progress if the join filters filter all the rows.&lt;br/&gt;
The task tracker may be thought of an un-responsive. Look at the filter operator, we send a progress in&lt;br/&gt;
that case if there are &apos;n&apos; consecutive rows filtered out.&lt;/p&gt;</comment>
                            <comment id="12909182" author="amareshwari" created="Tue, 14 Sep 2010 10:43:04 +0000"  >&lt;p&gt;Thanks Namit for the feedback.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;One general comment was that you also need to account for progress if the join filters filter all the rows.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This shouldn&apos;t be a problem because, even if the row is filtered, the join will emit output by joining it with nulls. Am I sounding right?&lt;/p&gt;

&lt;p&gt;I&apos;m almost done with the next patch which fixes the bugs with right outer join, full outer join and nested joins in the earlier patch. Will upload it once all the tests pass.&lt;/p&gt;</comment>
                            <comment id="12909202" author="amareshwari" created="Tue, 14 Sep 2010 11:42:25 +0000"  >&lt;p&gt;Patch with bug fixes. Also takes care of SMBMapJoin.&lt;/p&gt;

&lt;p&gt;Patch does the following:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Moved the code which decides whether to push the filters or not from pushJoinFilters() to creation of filters (parseJoinCondition). Because, for nested joins, mergeJoinTree changes the join-tree structure.
	&lt;ul&gt;
		&lt;li&gt;Join filters are not pushed if
		&lt;ul&gt;
			&lt;li&gt;join is full outer join or&lt;/li&gt;
			&lt;li&gt;join is left outer join and filter is on left alias&lt;/li&gt;
			&lt;li&gt;join is right outer join and filter is on right alias&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Join impl changes:
	&lt;ul&gt;
		&lt;li&gt;When join values are computed from the row object, the row is evaluated to be filtered or not.&lt;/li&gt;
		&lt;li&gt;Depending on the row is filtered or not, joinObjects*OuterJoin methods put null arrays&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Fixed a minor bug in JoinDesc with noOuterJoin variable. The variable is not passed down properly and isNoOuterJoin looks for the join type and evaluates. Fixed it so that noOuterJoin variable contains correct value&lt;/li&gt;
&lt;/ul&gt;


</comment>
                            <comment id="12909388" author="namit" created="Tue, 14 Sep 2010 19:04:14 +0000"  >&lt;p&gt;Since we are still pushing filters for non-outer joins, the assumption that we will always output a row by the filters is true, and therefore &lt;br/&gt;
we dont need a progress.&lt;/p&gt;

&lt;p&gt;Cool, I will take a look at the patch again&lt;/p&gt;</comment>
                            <comment id="12909539" author="namit" created="Wed, 15 Sep 2010 00:33:03 +0000"  >&lt;p&gt;Did you run all the tests ? Some of the tests should break - minimally a change of explain plans.&lt;br/&gt;
What about semi joins ?&lt;/p&gt;

&lt;p&gt;Why did you add a genExprNode() ? Cant you re-use the one from SemanticAnalyzer ?&lt;/p&gt;</comment>
                            <comment id="12909604" author="amareshwari" created="Wed, 15 Sep 2010 06:02:49 +0000"  >&lt;blockquote&gt;&lt;p&gt;Did you run all the tests ? Some of the tests should break - minimally a change of explain plans.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I commented Explain annotation for filter predicates to skip test failures with explain plans for now; trying to figure out if filter predicates can be displayed only when they are present. Even then, all the tests did not pass. I&apos;m looking into the failures.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What about semi joins ? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I did not do anything for semi join. I will go through semi join and its expected output with filters. Will update the patch if any changes are needed and add tests.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Why did you add a genExprNode() ? Cant you re-use the one from SemanticAnalyzer ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;genExprNode() in SemanticAnalyzer is not a static method. It uses unparseTranslator while generating. Will change genExprNode() in SemanticAnalyzer to use the new static method introduced and remove duplicate code.&lt;/p&gt;</comment>
                            <comment id="12910503" author="amareshwari" created="Fri, 17 Sep 2010 08:11:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;What about semi joins ? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I did not find anything wrong with semijoin queries and filters. They can be pushed as they are now. I don&apos;t think any change is required for semi joins. What do you think?&lt;/p&gt;

&lt;p&gt;Uploading patch with following changes from earlier one:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;I think it makes sense to push the filters on partitioned columns and not output all the table for outer join. Patch pushes filters on partitioned columns, even for outer joins. Thoughts?&lt;/li&gt;
	&lt;li&gt;Removed duplicate code in genExprNode() in SemanticAnalyzer.&lt;/li&gt;
	&lt;li&gt;Fixed some minor bugs in SemanticAnalyzer and CommonJoinOperator, found in the test failures.&lt;/li&gt;
	&lt;li&gt;Updated the test results for clientpositive queries in join20.q.out, join21.q.out and join40.q.out, which involve filters on outer joins. Also, updated test results for TestParse join queries.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;All the tests passed with the uploaded patch.&lt;/p&gt;</comment>
                            <comment id="12910669" author="namit" created="Fri, 17 Sep 2010 17:15:46 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think it makes sense to push the filters on partitioned columns and not output all the table for outer join. Patch pushes filters on partitioned columns, even for outer joins. Thoughts?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I dont think it is a good idea to special case partitioned columns - can you treat them like any other column&lt;/p&gt;
</comment>
                            <comment id="12910723" author="jvs" created="Fri, 17 Sep 2010 18:40:38 +0000"  >&lt;p&gt;+1 to what Namit said about partitioned columns...although I have seen this mistake come up a lot, it&apos;s better to have consistent semantics and just educate users.&lt;/p&gt;</comment>
                            <comment id="12910763" author="namit" created="Fri, 17 Sep 2010 20:14:18 +0000"  >&lt;p&gt;You can cleanup the patch by not special-casing for partitioned columns. Otherwise, the patch looks good&lt;/p&gt;</comment>
                            <comment id="12912416" author="amareshwari" created="Mon, 20 Sep 2010 09:47:47 +0000"  >&lt;p&gt;Patch updated with following changes:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;removed the special casing for partitioned columns from SemanticAnalyzer&lt;/li&gt;
	&lt;li&gt;Updated ColumnPrunerProcFactory.pruneJoinOperator() to add columns from join-filters.&lt;/li&gt;
	&lt;li&gt;Updated test results for  queries: union22.q, louter_join_ppr.q, outer_join_ppr.q and router_join_ppr.q, which involve filters on partition predicates.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12912428" author="amareshwari" created="Mon, 20 Sep 2010 10:22:04 +0000"  >&lt;p&gt;All the tests passed with uploaded patch.&lt;/p&gt;</comment>
                            <comment id="12912590" author="namit" created="Mon, 20 Sep 2010 17:01:52 +0000"  >&lt;p&gt;I will take a look again&lt;/p&gt;</comment>
                            <comment id="12912741" author="namit" created="Mon, 20 Sep 2010 22:00:29 +0000"  >&lt;p&gt;The patch looks good - however, we have a deployment issue.&lt;/p&gt;

&lt;p&gt;This is a incompatible change, and will change/break existing queries. I cant think of a great way of getting this in.&lt;br/&gt;
One option is to cover it via a configurable parameter (it is ON by default). For internal deployments (like Facebook),&lt;br/&gt;
we can turn it off and find all the bad queries slowly and convert them, and only then enable this.&lt;/p&gt;</comment>
                            <comment id="12912831" author="amareshwari" created="Tue, 21 Sep 2010 04:01:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;This is a incompatible change, and will change/break existing queries.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The patch changes the query results to be different from what it was earlier. It does not give out any error, unlike &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1621&quot; title=&quot;Disable join filters for outer joins.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1621&quot;&gt;&lt;del&gt;HIVE-1621&lt;/del&gt;&lt;/a&gt;.  The effect is similar to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-741&quot; title=&quot;NULL is not handled correctly in join&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-741&quot;&gt;&lt;del&gt;HIVE-741&lt;/del&gt;&lt;/a&gt;.  I don&apos;t think this is incompatible change, because the current query results are wrong and the issue fixes the correctness.&lt;/p&gt;

&lt;p&gt;If you still think it is incompatible change, we can add a configuration like hive.outerjoin.supports.filters with following semantics:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;when it is off,  print a warning saying &quot;the results could be wrong. please turn on  hive.outerjoin.supports.filters&quot; and add it to filtersForPushing (same as old behavior).&lt;/li&gt;
	&lt;li&gt;When it is on, the filters are added to join filters.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="12912845" author="namit" created="Tue, 21 Sep 2010 05:50:20 +0000"  >&lt;p&gt;What I meant to say was the following:&lt;/p&gt;


&lt;p&gt;People are running queries in the warehouse with the expected wrong semantics - if we suddenly fix this, the queries will break.&lt;br/&gt;
We need to give some time to everyone to change their queries to use a sub-query if they want the filter to be pushed up.&lt;/p&gt;

&lt;p&gt;Adding the above config, parameter seems like the only choice - we can try to remove this parameter before 0.7 goes out &lt;br/&gt;
(if everyone agrees), but we need it right now for deployment&lt;/p&gt;</comment>
                            <comment id="12912912" author="amareshwari" created="Tue, 21 Sep 2010 09:54:58 +0000"  >&lt;p&gt;Added hive.outerjoin.supports.filter configuration with above semantics. Updated testcase to repeat the filter queries in join_filters.q with configuration turned off.&lt;/p&gt;</comment>
                            <comment id="12913105" author="namit" created="Tue, 21 Sep 2010 17:39:31 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="12913249" author="namit" created="Tue, 21 Sep 2010 21:00:41 +0000"  >&lt;p&gt;Committed. Thanks Amareshwari&lt;/p&gt;</comment>
                            <comment id="13772169" author="apivovarov" created="Thu, 19 Sep 2013 19:01:16 +0000"  >&lt;p&gt;I still see this issue in hive-0.11.0&lt;/p&gt;</comment>
                            <comment id="13772179" author="apivovarov" created="Thu, 19 Sep 2013 19:14:23 +0000"  >&lt;p&gt;to reproduce:&lt;/p&gt;

&lt;p&gt;hive&amp;gt; create table tt1 (c1 int);&lt;br/&gt;
hive&amp;gt; create table tt2 (c1 int);&lt;/p&gt;

&lt;p&gt;$ vi tt1&lt;br/&gt;
1&lt;br/&gt;
2&lt;br/&gt;
3&lt;br/&gt;
4&lt;/p&gt;

&lt;p&gt;$ vi tt2&lt;br/&gt;
1&lt;br/&gt;
2&lt;br/&gt;
8&lt;br/&gt;
9&lt;/p&gt;

&lt;p&gt;$ hadoop fs -put tt1 /user/hive/warehouse/tt1/&lt;br/&gt;
$ hadoop fs -put tt2 /user/hive/warehouse/tt2/&lt;/p&gt;

&lt;p&gt;wrong result:&lt;br/&gt;
hive&amp;gt; select * from tt1 left outer join tt2 on (tt1.c1 = tt2.c1 and tt1.c1 &amp;lt;= 2);&lt;br/&gt;
1	1&lt;br/&gt;
2	2&lt;br/&gt;
3	NULL&lt;br/&gt;
4	NULL&lt;/p&gt;

&lt;p&gt;correct result:&lt;br/&gt;
select * from tt1 left outer join tt2 on (tt1.c1 = tt2.c1) where tt1.c1 &amp;lt;= 2;&lt;br/&gt;
1	1&lt;br/&gt;
2	2&lt;/p&gt;


&lt;p&gt;alexp@t1:~/hive-0.11.0-bin$ head -1 RELEASE_NOTES.txt &lt;br/&gt;
Release Notes - Hive - Version 0.11.0&lt;/p&gt;</comment>
                            <comment id="13772576" author="apivovarov" created="Fri, 20 Sep 2013 02:36:56 +0000"  >&lt;p&gt;Actually the result below is correct - all tt1 filters in &quot;join on&quot; should be ignored&lt;br/&gt;
hive&amp;gt; select * from tt1 left outer join tt2 on (tt1.c1 = tt2.c1 and tt1.c1 &amp;lt;= 2);&lt;br/&gt;
1	1&lt;br/&gt;
2	2&lt;br/&gt;
3	NULL&lt;br/&gt;
4	NULL&lt;/p&gt;

&lt;p&gt;Please skip my prev 2 comments&lt;/p&gt;</comment>
                            <comment id="15468965" author="lefty@hortonworks.com" created="Tue, 6 Sep 2016 23:39:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sladymon&quot; class=&quot;user-hover&quot; rel=&quot;sladymon&quot;&gt;Shannon Ladymon&lt;/a&gt; documented the property &lt;b&gt;hive.outerjoin.supports.filters&lt;/b&gt; in the wiki:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.outerjoin.supports.filters&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Configuration Properties - hive.outerjoin.supports.filters &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Thanks, Shannon.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12669516">HIVE-5321</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12473528">HIVE-1621</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12996758">HIVE-14522</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12473528">HIVE-1621</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12454537" name="patch-1534-1.txt" size="93188" author="amareshwari" created="Tue, 14 Sep 2010 11:42:25 +0000"/>
                            <attachment id="12454831" name="patch-1534-2.txt" size="273829" author="amareshwari" created="Fri, 17 Sep 2010 08:11:01 +0000"/>
                            <attachment id="12455027" name="patch-1534-3.txt" size="297625" author="amareshwari" created="Mon, 20 Sep 2010 09:47:47 +0000"/>
                            <attachment id="12455128" name="patch-1534-4.txt" size="355090" author="amareshwari" created="Tue, 21 Sep 2010 09:54:58 +0000"/>
                            <attachment id="12454206" name="patch-1534.txt" size="52281" author="amareshwari" created="Thu, 9 Sep 2010 11:52:40 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 12 Aug 2010 19:26:52 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72850</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 19 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfk7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123171</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1535] alter partition should throw exception if the specified partition does not exist.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1535</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12471477">HIVE-1535</key>
            <summary>alter partition should throw exception if the specified partition does not exist.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="he yongqiang">He Yongqiang</assignee>
                                    <reporter username="he yongqiang">He Yongqiang</reporter>
                        <labels>
                    </labels>
                <created>Fri, 13 Aug 2010 01:12:23 +0000</created>
                <updated>Fri, 16 Dec 2011 23:59:54 +0000</updated>
                            <resolved>Fri, 13 Aug 2010 15:20:48 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Metastore</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12898050" author="he yongqiang" created="Fri, 13 Aug 2010 02:37:13 +0000"  >&lt;p&gt;No negative tests included because hive is using local meta store, and throw exception if the partition does not exist. So there is no problem when running with local meta store.&lt;/p&gt;</comment>
                            <comment id="12898272" author="namit" created="Fri, 13 Aug 2010 15:20:48 +0000"  >&lt;p&gt;Committed. Thanks Yongqiang&lt;/p&gt;</comment>
                            <comment id="12976684" author="cwsteinbach" created="Mon, 3 Jan 2011 10:46:07 +0000"  >&lt;p&gt;We could test this in TestRemoteHiveMetaStore, right?&lt;/p&gt;</comment>
                            <comment id="12999214" author="mosikri" created="Fri, 25 Feb 2011 04:35:42 +0000"  >&lt;p&gt;It seems some issue with my mailbox, could not able to send mail, so I&apos;m posting here :-&lt;/p&gt;

&lt;p&gt;As tested against latest Hive build and Hadoop 20.1.&lt;/p&gt;

&lt;p&gt;Kindly provide me the query or the list of queries for which this defect was tested against, as I see no test case in it and when I&apos;m running queries assuming which were being run by He Yongqiang while testing the scenarios, I&apos;m not able to re-produce the scenario.&lt;/p&gt;

&lt;p&gt;I&apos;m ran queries in below sequence :-&lt;/p&gt;

&lt;p&gt;1 . set hive.exec.drop.ignorenonexistent=false;&lt;/p&gt;

&lt;p&gt;2 . create table page_test(view INT, userid INT, page_url STRING) PARTITIONED BY(dt STRING, country STRING) STORED AS A TEXTFILE;&lt;/p&gt;

&lt;p&gt;3 . LOAD DATA LOCAL INPATH &apos;/home/test.txt&apos; OVERWRITE INTO TABLE page_test PARTITION(dt=&apos;10-10-2010&apos;,country=&apos;US&apos;);&lt;/p&gt;

&lt;p&gt;4 . LOAD DATA LOCAL INPATH &apos;/home/test.txt&apos; OVERWRITE INTO TABLE page_test PARTITION(dt=&apos;10-12-2010&apos;,country=&apos;IN&apos;);&lt;/p&gt;

&lt;p&gt;// This query fails during semantic analysis, since it is invalid partition and don&apos;t belong to partition spec of page_test.&lt;/p&gt;

&lt;p&gt;5 . ALTER TABLE page_test DROP PARTITION(invalid=&apos;23-02-2010&apos;,notexist=&apos;UK&apos;); &lt;br/&gt;
and when I turn ON the property hive.exec.drop.ignorenonexistent, hive is silent and OK.&lt;br/&gt;
So far good, and no issues.&lt;/p&gt;

&lt;p&gt;//However there is another case, in which partition is a valid spec but doesn&apos;t exists, as I have only &lt;span class=&quot;error&quot;&gt;&amp;#91;dt=&amp;#39;10-10-2010&amp;#39;,country=&amp;#39;US&amp;#39;&amp;#93;&lt;/span&gt; and &lt;span class=&quot;error&quot;&gt;&amp;#91;dt=&amp;#39;10-12-2010&amp;#39;,country=&amp;#39;IN&amp;#39;&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;6 . ALTER TABLE page_test DROP PARTITION (dt=&apos;23-02-2010&apos;,country=&apos;UK&apos;); &lt;br/&gt;
but it doesn&apos;t results in any exception, I&apos;m getting OK response on console.&lt;/p&gt;

&lt;p&gt;As per this defect  fix, it should actually fail with console error message &lt;br/&gt;
Partition : [&lt;/p&gt;
{dt=&apos;23-02-2010&apos;,country=&apos;UK&apos;}
&lt;p&gt;] does not exist.&lt;/p&gt;

&lt;p&gt;I may be wrong, or not aware of enough use cases covering the scope of this defect, kindly help me providing some insights.&lt;/p&gt;</comment>
                            <comment id="12999215" author="cwsteinbach" created="Fri, 25 Feb 2011 04:46:07 +0000"  >&lt;p&gt;@Mohit: Please file a new JIRA ticket against this issue. Thanks!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12451982" name="hive-1535.1.patch" size="674" author="he yongqiang" created="Fri, 13 Aug 2010 02:37:12 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 13 Aug 2010 15:20:48 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72849</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 48 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfkf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123172</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1536] Add support for JDBC PreparedStatements</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1536</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;As a result of a Sprint which had us using Pentaho Data Integration with the Hive database we have updated the driver.  Many PreparedStatement methods have been implemented.  A patch will be attached tomorrow with a summary of changes.&lt;/p&gt;


&lt;p&gt;Note:  A checkout of Hive/trunk was performed and the TestJdbcDriver test cased was run.  This was done before any modifications were made to the checked out project.  The testResultSetMetaData failed:&lt;/p&gt;

&lt;p&gt;java.sql.SQLException: Query returned non-zero code: 9, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.MapRedTask&lt;br/&gt;
	at org.apache.hadoop.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:189)&lt;br/&gt;
	at org.apache.hadoop.hive.jdbc.TestJdbcDriver.testResultSetMetaData(TestJdbcDriver.java:530)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at junit.framework.TestCase.runTest(TestCase.java:154)&lt;br/&gt;
	at junit.framework.TestCase.runBare(TestCase.java:127)&lt;br/&gt;
	at junit.framework.TestResult$1.protect(TestResult.java:106)&lt;br/&gt;
	at junit.framework.TestResult.runProtected(TestResult.java:124)&lt;br/&gt;
	at junit.framework.TestResult.run(TestResult.java:109)&lt;br/&gt;
	at junit.framework.TestCase.run(TestCase.java:118)&lt;br/&gt;
	at junit.framework.TestSuite.runTest(TestSuite.java:208)&lt;br/&gt;
	at junit.framework.TestSuite.run(TestSuite.java:203)&lt;br/&gt;
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)&lt;br/&gt;
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)&lt;br/&gt;
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)&lt;/p&gt;

&lt;p&gt;A co-worker did the same and the tests passed.  Both environments were Ubuntu and Hadoop version 0.20.2.&lt;/p&gt;

&lt;p&gt;Tests added to the TestJdbcDriver by us were successful.&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12471478">HIVE-1536</key>
            <summary>Add support for JDBC PreparedStatements</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sflatley@pentaho.com">Sean Flatley</assignee>
                                    <reporter username="sflatley@pentaho.com">Sean Flatley</reporter>
                        <labels>
                    </labels>
                <created>Fri, 13 Aug 2010 01:25:34 +0000</created>
                <updated>Fri, 16 Dec 2011 23:59:48 +0000</updated>
                            <resolved>Mon, 30 Aug 2010 03:38:33 +0000</resolved>
                                    <version>0.6.0</version>
                                    <fixVersion>0.7.0</fixVersion>
                                    <component>JDBC</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="12898381" author="jvs" created="Fri, 13 Aug 2010 19:29:32 +0000"  >&lt;p&gt;Sounds like an environmental problem, since I don&apos;t think I&apos;ve heard reports of failures on that test elsewhere.  Can you check hive-trunk/build/ql/tmp/hive.log after the test run to find the exception details?  (Search for the text of the select statement executed by that test.)&lt;/p&gt;</comment>
                            <comment id="12898655" author="sflatley@pentaho.com" created="Sun, 15 Aug 2010 00:43:19 +0000"  >&lt;p&gt;The log entries can be found at the end of this comment.  I did find in the Eclipse console an error entry reporting that JAVA_HOME is not set, so it does appear to be configuration:&lt;/p&gt;

&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; PREHOOK: query: select a,b,c,d,f as e,f*2 from testHiveJdbcDriverTable limit 1&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; PREHOOK: type: QUERY&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; PREHOOK: Input: default@testhivejdbcdrivertable&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; PREHOOK: Output: &lt;a href=&quot;file:/tmp/sean/hive_2010-08-14_17-32-24_783_1792704952460259887/-mr-10000&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/tmp/sean/hive_2010-08-14_17-32-24_783_1792704952460259887/-mr-10000&lt;/a&gt;&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Total MapReduce jobs = 1&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Launching Job 1 out of 1&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Number of reduce tasks is set to 0 since there&apos;s no reduce operator&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Error: JAVA_HOME is not set.&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.MapRedTask&lt;/p&gt;

&lt;p&gt;I do have JAVA_HOME set and exported in my .bashrc file.&lt;/p&gt;

&lt;p&gt;Here is the hive.log file entries.&lt;/p&gt;

&lt;p&gt;2010-08-14 17:32:24,929 INFO  ql.Driver (Driver.java:execute(425)) - Starting command: select a,b,c,d,f as e,f*2 from testHiveJdbcDriverTable limit 1&lt;br/&gt;
2010-08-14 17:32:24,935 ERROR SessionState (SessionState.java:printError(277)) - PREHOOK: query: select a,b,c,d,f as e,f*2 from testHiveJdbcDriverTable limit 1&lt;br/&gt;
2010-08-14 17:32:24,937 ERROR SessionState (SessionState.java:printError(277)) - PREHOOK: type: QUERY&lt;br/&gt;
2010-08-14 17:32:24,938 ERROR SessionState (SessionState.java:printError(277)) - PREHOOK: Input: default@testhivejdbcdrivertable&lt;br/&gt;
2010-08-14 17:32:24,939 ERROR SessionState (SessionState.java:printError(277)) - PREHOOK: Output: &lt;a href=&quot;file:/tmp/sean/hive_2010-08-14_17-32-24_783_1792704952460259887/-mr-10000&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/tmp/sean/hive_2010-08-14_17-32-24_783_1792704952460259887/-mr-10000&lt;/a&gt;&lt;br/&gt;
2010-08-14 17:32:24,940 INFO  ql.Driver (SessionState.java:printInfo(268)) - Total MapReduce jobs = 1&lt;br/&gt;
2010-08-14 17:32:24,942 INFO  ql.Driver (SessionState.java:printInfo(268)) - Launching Job 1 out of 1&lt;br/&gt;
2010-08-14 17:32:24,947 INFO  exec.MapRedTask (SessionState.java:printInfo(268)) - Number of reduce tasks is set to 0 since there&apos;s no reduce operator&lt;br/&gt;
2010-08-14 17:32:24,967 INFO  exec.MapRedTask (MapRedTask.java:execute(152)) - Generating plan file &lt;a href=&quot;file:/tmp/sean/hive_2010-08-14_17-32-24_783_1792704952460259887/-local-10002/plan.xml&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/tmp/sean/hive_2010-08-14_17-32-24_783_1792704952460259887/-local-10002/plan.xml&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2010-08-14 17:32:25,588 INFO  exec.MapRedTask (MapRedTask.java:execute(173)) - Executing: /home/sean/projects/hive/build/hadoopcore/hadoop-0.20.0/bin/hadoop jar /home/sean/projects/hive/build/ql/hive-exec-0.7.0.jar org.apache.hadoop.hive.ql.exec.ExecDriver &lt;del&gt;libjars &lt;a href=&quot;file:///home/sean/projects/hive/build/jdbc/test/test-udfs.jar&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:///home/sean/projects/hive/build/jdbc/test/test-udfs.jar&lt;/a&gt;  -plan &lt;a href=&quot;file:/tmp/sean/hive_2010-08-14_17-32-24_783_1792704952460259887/-local-10002/plan.xml&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/tmp/sean/hive_2010-08-14_17-32-24_783_1792704952460259887/-local-10002/plan.xml&lt;/a&gt; -nolog -jobconf datanucleus.connectionPoolingType=DBCP -jobconf hive.exec.script.allow.partial.consumption=false -jobconf hive.query.id=sean_20100814173232_f49d776c-7273-4995-8cc3-f7aceabdbde3 -jobconf hive.hwi.listen.port=9999 -jobconf hive.map.aggr=true -jobconf hive.map.aggr.hash.min.reduction=0.5 -jobconf datanucleus.plugin.pluginRegistryBundleCheck=LOG -jobconf hive.exec.reducers.bytes.per.reducer=1000000000 -jobconf hive.optimize.cp=true -jobconf hive.exec.dynamic.partition.mode=strict -jobconf hive.merge.size.smallfiles.avgsize=16000000 -jobconf datanucleus.cache.level2.type=SOFT -jobconf hive.exec.max.created.files=100000 -jobconf hive.script.serde=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe -jobconf hive.fileformat.check=true -jobconf hive.exec.max.dynamic.partitions.pernode=100 -jobconf hive.enforce.sorting=false -jobconf hive.optimize.ppd=true -jobconf hive.optimize.groupby=true -jobconf hive.enforce.bucketing=false -jobconf javax.jdo.option.ConnectionUserName=APP -jobconf hive.mapred.reduce.tasks.speculative.execution=true -jobconf mapred.job.name=select+a%2Cb%2Cc%2Cd%2Cf+as+e%2Cf*2+from+testHiveJ...1%28Stage-1%29 -jobconf javax.jdo.option.DetachAllOnCommit=true -jobconf hive.mapred.local.mem=0 -jobconf datanucleus.cache.level2=false -jobconf hive.session.id=sean_201008141732 -jobconf fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem -jobconf hive.script.operator.id.env.var=HIVE_SCRIPT_OPERATOR_ID -jobconf hive.archive.har.parentdir.settable=false -jobconf hadoop.job.ugi=sean%2Csean%2Cadm%2Cdialout%2Ccdrom%2Cplugdev%2Clpadmin%2Cadmin%2Csambashare -jobconf test.src.dir=file%3A%2F%2F%24%7Bbuild.dir%7D%2Fsrc%2Ftest -jobconf hive.metastore.server.max.threads=100000 -jobconf hive.udtf.auto.progress=false -jobconf hive.hwi.war.file=lib%2Fhive-hwi&lt;/del&gt;%40VERSION%40.war &lt;del&gt;jobconf datanucleus.validateTables=false -jobconf hive.exec.compress.output=false -jobconf hive.test.mode.prefix=test_ -jobconf hive.mapjoin.bucket.cache.size=100 -jobconf test.log.dir=%24%7Bbuild.dir%7D%2Ftest%2Flogs -jobconf test.data.files=%24%7Buser.dir%7D%2F..%2Fdata%2Ffiles -jobconf datanucleus.validateConstraints=false -jobconf hive.metastore.server.tcp.keepalive=true -jobconf mapred.reduce.tasks=-1 -jobconf hive.query.string=select+a%2Cb%2Cc%2Cd%2Cf+as+e%2Cf*2+from+testHiveJdbcDriverTable+limit+1 -jobconf hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat -jobconf hive.task.progress=false -jobconf hive.jar.path=%24%7Bbuild.dir.hive%7D%2Fql%2Fhive-exec&lt;/del&gt;%24%7Bversion%7D.jar &lt;del&gt;jobconf hive.metastore.ds.retry.interval=1000 -jobconf javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver -jobconf hive.skewjoin.mapjoin.map.tasks=10000 -jobconf hive.mapjoin.maxsize=100000 -jobconf hive.archive.enabled=false -jobconf hive.aux.jars.path=file%3A%2F%2F%2Fhome%2Fsean%2Fprojects%2Fhive%2Fbuild%2Fjdbc%2Ftest%2Ftest-udfs.jar -jobconf hive.exec.dynamic.partition=false -jobconf hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter%2C+org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables -jobconf hive.optimize.skewjoin=false -jobconf hive.groupby.mapaggr.checkinterval=100000 -jobconf hive.test.mode=false -jobconf hive.exec.parallel=false -jobconf hive.exec.counters.pull.interval=1000 -jobconf hive.default.fileformat=TextFile -jobconf hive.exec.max.dynamic.partitions=1000 -jobconf fs.har.impl=org.apache.hadoop.hive.shims.HiveHarFileSystem -jobconf hive.test.mode.samplefreq=32 -jobconf hive.metastore.ds.retry.attempts=1 -jobconf javax.jdo.option.NonTransactionalRead=true -jobconf hive.script.auto.progress=false -jobconf hive.merge.mapredfiles=false -jobconf javax.jdo.option.ConnectionURL=jdbc%3Aderby%3A%3BdatabaseName%3D..%2Fbuild%2Ftest%2Fjunit_metastore_db%3Bcreate%3Dtrue -jobconf hive.exec.compress.intermediate=false -jobconf hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore -jobconf hive.map.aggr.hash.percentmemory=0.5 -jobconf hive.hwi.listen.host=0.0.0.0 -jobconf datanucleus.transactionIsolation=read-committed -jobconf hive.merge.size.per.task=256000000 -jobconf datanucleus.autoCreateSchema=true -jobconf hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter -jobconf hive.groupby.skewindata=false -jobconf hive.metastore.local=true -jobconf hive.skewjoin.mapjoin.min.split=33554432 -jobconf hadoop.tmp.dir=%24%7Bbuild.dir.hive%7D%2Ftest%2Fhadoop&lt;/del&gt;%24%7Buser.name%7D -jobconf hive.mapred.mode=nonstrict -jobconf hive.optimize.pruner=true -jobconf hive.skewjoin.key=100000 -jobconf hive.default.partition.name=_&lt;em&gt;HIVE_DEFAULT_PARTITION&lt;/em&gt;_ -jobconf hive.hbase.wal.enabled=true -jobconf datanucleus.validateColumns=false -jobconf datanucleus.identifierFactory=datanucleus -jobconf hive.querylog.location=%24%7Bbuild.dir%7D%2Ftmp -jobconf hive.optimize.reducededuplication=true -jobconf hive.exec.reducers.max=999 -jobconf javax.jdo.PersistenceManagerFactoryClass=org.datanucleus.jdo.JDOPersistenceManagerFactory -jobconf hive.heartbeat.interval=1000 -jobconf hive.join.cache.size=25000 -jobconf hive.metastore.warehouse.dir=%24%7Btest.warehouse.dir%7D -jobconf datanucleus.autoStartMechanismMode=checked -jobconf javax.jdo.option.ConnectionPassword=mine -jobconf hive.metastore.connect.retries=5 -jobconf hive.exec.mode.local.auto=false -jobconf hive.mapjoin.cache.numrows=25000 -jobconf hive.exec.parallel.thread.number=8 -jobconf datanucleus.storeManagerType=rdbms -jobconf hive.script.recordreader=org.apache.hadoop.hive.ql.exec.TextRecordReader -jobconf hive.exec.scratchdir=%24%7Bbuild.dir%7D%2Fscratchdir -jobconf hive.metastore.metadb.dir=file%3A%2F%2F%24%7Bbuild.dir%7D%2Ftest%2Fdata%2Fmetadb%2F -jobconf hive.metastore.server.min.threads=200 -jobconf hive.script.recordwriter=org.apache.hadoop.hive.ql.exec.TextRecordWriter -jobconf hive.merge.mapfiles=true -jobconf hive.exec.script.maxerrsize=100000 -jobconf test.query.file1=file%3A%2F%2F%24%7Buser.dir%7D%2F..%2Fql%2Fsrc%2Ftest%2Forg%2Fapache%2Fhadoop%2Fhive%2Fql%2Finput2.q -jobconf hive.join.emit.interval=1000 -jobconf hive.added.jars.path= -jobconf mapred.system.dir=%2Fhome%2Fsean%2Fprojects%2Fhive%2Fbuild%2Ftest%2Fhadoop-sean%2Fmapred%2Fsystem%2F1753935500 -jobconf mapred.local.dir=%2Fhome%2Fsean%2Fprojects%2Fhive%2Fbuild%2Ftest%2Fhadoop-sean%2Fmapred%2Flocal%2F-2115807459&lt;/p&gt;

&lt;p&gt;2010-08-14 17:32:25,633 ERROR exec.MapRedTask (MapRedTask.java:execute(224)) - Execution failed with exit status: 1&lt;br/&gt;
2010-08-14 17:32:25,635 ERROR ql.Driver (SessionState.java:printError(277)) - FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.MapRedTask&lt;/p&gt;
</comment>
                            <comment id="12898704" author="sflatley@pentaho.com" created="Sun, 15 Aug 2010 16:45:20 +0000"  >&lt;p&gt;Change log.&lt;/p&gt;</comment>
                            <comment id="12898773" author="sflatley@pentaho.com" created="Mon, 16 Aug 2010 01:47:35 +0000"  >&lt;p&gt;Log file of:  ant clean test tar -logfile ant.log&lt;/p&gt;</comment>
                            <comment id="12898774" author="sflatley@pentaho.com" created="Mon, 16 Aug 2010 01:48:21 +0000"  >&lt;p&gt;Log file of:  ant clean test tar -Dtestcase=JdbcDriverTest -logfile JdbcDriverTest-ant.log&lt;/p&gt;</comment>
                            <comment id="12898775" author="sflatley@pentaho.com" created="Mon, 16 Aug 2010 01:49:09 +0000"  >&lt;p&gt;Patch.&lt;/p&gt;</comment>
                            <comment id="12898776" author="sflatley@pentaho.com" created="Mon, 16 Aug 2010 01:55:47 +0000"  >&lt;p&gt;The modified JdbcDriverTest test case succeeds.  I have attached two log files for the ant commands:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ant clean test tar -logfile all-tests-ant.log&lt;/li&gt;
	&lt;li&gt;ant clean test tar -Dtestcase=JdbcDriverTest -logfile JdbcDriverTest-ant.log&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The second command works.  Running the equivalent command in Eclipse using the &quot;ant&quot; interface results in the error where &quot;JAVA_HOME&quot; is not set.  &lt;/p&gt;

&lt;p&gt;This appears to be an environmental issue and I feel that it should not hold up the contribution process.  As out Sprint ends tomorrow I can circle back and take a look at my Linux environments. and nail down what is causing the existing tests to error.&lt;/p&gt;
</comment>
                            <comment id="12899131" author="hbasereviewboard" created="Mon, 16 Aug 2010 22:13:06 +0000"  >&lt;p&gt;Message from: &quot;Carl Steinbach&quot; &amp;lt;carl@cloudera.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/663/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/663/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for Hive Developers.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Submitted on behalf of Sean Flatley.&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1536&quot; title=&quot;Add support for JDBC PreparedStatements&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1536&quot;&gt;&lt;del&gt;HIVE-1536&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/HIVE-1536&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HIVE-1536&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/data/files/pstmt.txt PRE-CREATION &lt;br/&gt;
  trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveBaseResultSet.java 985606 &lt;br/&gt;
  trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveConnection.java 985606 &lt;br/&gt;
  trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveDatabaseMetaData.java 985606 &lt;br/&gt;
  trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HivePreparedStatement.java 985606 &lt;br/&gt;
  trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveResultSetMetaData.java 985606 &lt;br/&gt;
  trunk/jdbc/src/test/org/apache/hadoop/hive/jdbc/TestJdbcDriver.java 985606 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.cloudera.org/r/663/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/663/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Carl&lt;/p&gt;

</comment>
                            <comment id="12899232" author="jvs" created="Tue, 17 Aug 2010 01:39:15 +0000"  >&lt;p&gt;First pass of review comments added on Review Board.  I may have more in a second pass.&lt;/p&gt;</comment>
                            <comment id="12899234" author="hbasereviewboard" created="Tue, 17 Aug 2010 01:46:27 +0000"  >&lt;p&gt;Message from: &quot;John Sichi&quot; &amp;lt;jsichi@facebook.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/663/#review928&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/663/#review928&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;



&lt;p&gt;trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveBaseResultSet.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/663/#comment3025&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/663/#comment3025&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Looks like this got added back in by merge mistake.&lt;/p&gt;



&lt;p&gt;trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveConnection.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/663/#comment3026&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/663/#comment3026&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    I don&apos;t understand this if statement...we do the same thing anyway below?&lt;/p&gt;



&lt;p&gt;trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveConnection.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/663/#comment3027&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/663/#comment3027&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Shouldn&apos;t we prevent setAutoCommit(false) rather than setAutoCommit(true)?  Hive does not support user-level transactions.&lt;/p&gt;



&lt;p&gt;trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveDatabaseMetaData.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/663/#comment3028&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/663/#comment3028&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Where did the number 100 come from?&lt;/p&gt;



&lt;p&gt;trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveDatabaseMetaData.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/663/#comment3029&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/663/#comment3029&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    This should be a backtick, not an apostrophe.&lt;/p&gt;



&lt;p&gt;trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HiveDatabaseMetaData.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/663/#comment3030&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/663/#comment3030&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    This is inaccurate.  The database is read/write since you can issue INSERT statements etc.&lt;/p&gt;




&lt;p&gt;trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HivePreparedStatement.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/663/#comment3032&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/663/#comment3032&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    This should also close the resultSet (if there is one) before nullifying it.&lt;/p&gt;




&lt;p&gt;trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HivePreparedStatement.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/663/#comment3034&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/663/#comment3034&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    For PreparedStatement, public executeQuery(sql) and others inherited from vanilla Statement should throw, since they aren&apos;t supposed to take the SQL string as parameter (that&apos;s what prepare is for).&lt;/p&gt;

&lt;p&gt;    Instead, use a protected helper method with a different name (and share with HiveStatement so that excn handling code is reused).&lt;/p&gt;




&lt;p&gt;trunk/jdbc/src/java/org/apache/hadoop/hive/jdbc/HivePreparedStatement.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/663/#comment3035&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/663/#comment3035&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Where is the maxRows enforcement implemented?  I may have missed it.  Ideally we&apos;d like to turn this into a LIMIT clause for efficiency, but we can do a followup for that.&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;John&lt;/li&gt;
&lt;/ul&gt;



</comment>
                            <comment id="12901892" author="sflatley@pentaho.com" created="Tue, 24 Aug 2010 14:13:00 +0000"  >&lt;p&gt;JdbcDriverTest test case result for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1536&quot; title=&quot;Add support for JDBC PreparedStatements&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1536&quot;&gt;&lt;del&gt;HIVE-1536&lt;/del&gt;&lt;/a&gt;-2.patch.&lt;/p&gt;</comment>
                            <comment id="12901895" author="sflatley@pentaho.com" created="Tue, 24 Aug 2010 14:16:48 +0000"  >&lt;p&gt;Change log for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1536&quot; title=&quot;Add support for JDBC PreparedStatements&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1536&quot;&gt;&lt;del&gt;HIVE-1536&lt;/del&gt;&lt;/a&gt;-2.patch&lt;/p&gt;</comment>
                            <comment id="12901898" author="sflatley@pentaho.com" created="Tue, 24 Aug 2010 14:17:51 +0000"  >&lt;p&gt;Patch file #2.&lt;/p&gt;</comment>
                            <comment id="12901910" author="sflatley@pentaho.com" created="Tue, 24 Aug 2010 14:42:19 +0000"  >&lt;p&gt;In this second go around most of the code was reverted,  Please see the change log for details.&lt;/p&gt;

&lt;p&gt;Change log:   &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1536&quot; title=&quot;Add support for JDBC PreparedStatements&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1536&quot;&gt;&lt;del&gt;HIVE-1536&lt;/del&gt;&lt;/a&gt;-changes-2.txt &lt;br/&gt;
Junit log file :  JdbcDriverTest-ant-2.log&lt;br/&gt;
Patch:  &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1536&quot; title=&quot;Add support for JDBC PreparedStatements&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1536&quot;&gt;&lt;del&gt;HIVE-1536&lt;/del&gt;&lt;/a&gt;-2.patch&lt;/p&gt;</comment>
                            <comment id="12902102" author="jvs" created="Tue, 24 Aug 2010 22:13:33 +0000"  >&lt;p&gt;Thanks Sean.  I have two more items and then I think this one is ready for commit.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;for the column name length, we should use 128, since that&apos;s the length declared for MFieldSchema.FNAME in metastore/src/model/package.jdo&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;for PreparedStatement.execute, you can get rid of the TODO comment; the behavior is correct as is (the true/false return only discriminates between a query with a cursor vs DDL/DML; it&apos;s not related to whether any rows are actually returned by the query)&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12902923" author="sflatley@pentaho.com" created="Thu, 26 Aug 2010 16:42:21 +0000"  >&lt;p&gt;Revision 3 change log.&lt;/p&gt;</comment>
                            <comment id="12902925" author="sflatley@pentaho.com" created="Thu, 26 Aug 2010 16:48:11 +0000"  >&lt;p&gt;Unit test results for revision 3.&lt;/p&gt;</comment>
                            <comment id="12902926" author="sflatley@pentaho.com" created="Thu, 26 Aug 2010 16:48:41 +0000"  >&lt;p&gt;Revision 3 patch.&lt;/p&gt;</comment>
                            <comment id="12902929" author="sflatley@pentaho.com" created="Thu, 26 Aug 2010 16:50:35 +0000"  >&lt;p&gt;Please see the change log for details.&lt;/p&gt;

&lt;p&gt;Change log: &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1536&quot; title=&quot;Add support for JDBC PreparedStatements&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1536&quot;&gt;&lt;del&gt;HIVE-1536&lt;/del&gt;&lt;/a&gt;-changes-3.txt&lt;br/&gt;
Junit log file : TestJdbcDriver-ant-3.log&lt;br/&gt;
Patch: &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1536&quot; title=&quot;Add support for JDBC PreparedStatements&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1536&quot;&gt;&lt;del&gt;HIVE-1536&lt;/del&gt;&lt;/a&gt;-3.patch&lt;/p&gt;</comment>
                            <comment id="12902962" author="jvs" created="Thu, 26 Aug 2010 18:18:01 +0000"  >&lt;p&gt;+1.  Will commit when tests pass.&lt;/p&gt;</comment>
                            <comment id="12904073" author="jvs" created="Mon, 30 Aug 2010 03:38:33 +0000"  >&lt;p&gt;Committed.  Thanks Sean!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12403853">HIVE-48</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12452935" name="HIVE-1536-2.patch" size="18781" author="sflatley@pentaho.com" created="Tue, 24 Aug 2010 14:17:51 +0000"/>
                            <attachment id="12453144" name="HIVE-1536-3.patch" size="5130" author="sflatley@pentaho.com" created="Thu, 26 Aug 2010 16:48:41 +0000"/>
                            <attachment id="12452934" name="HIVE-1536-changes-2.txt" size="3194" author="sflatley@pentaho.com" created="Tue, 24 Aug 2010 14:16:48 +0000"/>
                            <attachment id="12453142" name="HIVE-1536-changes-3.txt" size="664" author="sflatley@pentaho.com" created="Thu, 26 Aug 2010 16:42:21 +0000"/>
                            <attachment id="12452121" name="HIVE-1536-changes.txt" size="2184" author="sflatley@pentaho.com" created="Sun, 15 Aug 2010 16:45:20 +0000"/>
                            <attachment id="12452137" name="HIVE-1536.patch" size="45565" author="sflatley@pentaho.com" created="Mon, 16 Aug 2010 01:49:09 +0000"/>
                            <attachment id="12452933" name="JdbcDriverTest-ant-2.log" size="196000" author="sflatley@pentaho.com" created="Tue, 24 Aug 2010 14:13:00 +0000"/>
                            <attachment id="12452136" name="JdbcDriverTest-ant.log" size="110902" author="sflatley@pentaho.com" created="Mon, 16 Aug 2010 01:48:21 +0000"/>
                            <attachment id="12453143" name="TestJdbcDriver-ant-3.log" size="197605" author="sflatley@pentaho.com" created="Thu, 26 Aug 2010 16:48:11 +0000"/>
                            <attachment id="12452135" name="all-tests-ant.log" size="54560" author="sflatley@pentaho.com" created="Mon, 16 Aug 2010 01:47:35 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>10.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 13 Aug 2010 19:29:32 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72848</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 22 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfkn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123173</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Many methods in HivePreparedStatement have been implemented.  This cases &amp;quot;change log&amp;quot; attachment summarizes all changes.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1537] Allow users to specify LOCATION in CREATE DATABASE statement</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1537</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12471484">HIVE-1537</key>
            <summary>Allow users to specify LOCATION in CREATE DATABASE statement</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="thiruvel">Thiruvel Thirumoolan</assignee>
                                    <reporter username="cwsteinbach">Carl Steinbach</reporter>
                        <labels>
                    </labels>
                <created>Fri, 13 Aug 2010 02:41:08 +0000</created>
                <updated>Fri, 16 Dec 2011 23:57:01 +0000</updated>
                            <resolved>Mon, 11 Jul 2011 07:35:53 +0000</resolved>
                                    <version>0.8.0</version>
                                    <fixVersion>0.8.0</fixVersion>
                                    <component>Metastore</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>11</watches>
                                                                <comments>
                            <comment id="13020220" author="devaraj" created="Fri, 15 Apr 2011 07:30:33 +0000"  >&lt;p&gt;Assuming that the location issue is solved, we need some checks in the create_database handler similar to what is there in the create_table handler. &lt;br/&gt;
This patch is an example patch. It introduces a check in HiveMetaStore.create_database_core for existence of database directory, and also checks for failure to create one. In either case, the create_database_core operation throws an exception and the DDL would fail.&lt;/p&gt;</comment>
                            <comment id="13047772" author="bliu@bobliu.com" created="Fri, 10 Jun 2011 23:42:35 +0000"  >&lt;p&gt;Any idea as to when this feature will get implemented?&lt;/p&gt;</comment>
                            <comment id="13048486" author="thiruvel" created="Mon, 13 Jun 2011 06:29:21 +0000"  >&lt;p&gt;@Bob will upload the patch sometime this week. Got busy with other stuff.&lt;/p&gt;</comment>
                            <comment id="13052736" author="thiruvel" created="Tue, 21 Jun 2011 18:19:51 +0000"  >&lt;p&gt;Usage:&lt;/p&gt;

&lt;p&gt;create database location &apos;path1&apos;;&lt;br/&gt;
alter database location &apos;path2&apos;;&lt;/p&gt;

&lt;p&gt;After &apos;alter&apos;, only newly created tables will be located under the new location. Tables created before &apos;alter&apos; will be under &apos;path1&apos;.&lt;/p&gt;</comment>
                            <comment id="13052739" author="thiruvel" created="Tue, 21 Jun 2011 18:26:46 +0000"  >&lt;p&gt;Notable changes:&lt;/p&gt;

&lt;p&gt;I have moved getDefaultDatabasePath() to HiveMetaStore and made it private. There should only be one API to obtain the location of a database and it has to accept &apos;Database&apos; as an arg and hence the new method in Warehouse &apos;getDatabasePath()&apos; and similarly &apos;getTablePath()&apos;. The usages of older API also has been changed. Hope that should be fine.&lt;/p&gt;</comment>
                            <comment id="13053764" author="jiraposter@reviews.apache.org" created="Thu, 23 Jun 2011 09:56:47 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/949/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for hive, Ning Zhang and Amareshwari Sriramadasu.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Usage:&lt;/p&gt;

&lt;p&gt;create database location &apos;path1&apos;;&lt;br/&gt;
alter database location &apos;path2&apos;;&lt;/p&gt;

&lt;p&gt;After &apos;alter&apos;, only newly created tables will be located under the new location. Tables created before &apos;alter&apos; will be under &apos;path1&apos;.&lt;/p&gt;

&lt;p&gt;Notes:&lt;br/&gt;
------&lt;br/&gt;
1. I have moved getDefaultDatabasePath() to HiveMetaStore and made it private. There should only be one API to obtain the location of a database and it has to accept &apos;Database&apos; as an arg and hence the new method in Warehouse &apos;getDatabasePath()&apos; and similarly &apos;getTablePath()&apos;. The usages of older API also has been changed. Hope that should be fine.&lt;br/&gt;
2. One could argue why have getDatabasePath() as location can be obtained by db.getLocationUri(). I wanted to retain this method to do any additional processing if necessary (getDns or whatever).&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; title=&quot;Allow users to specify LOCATION in CREATE DATABASE statement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1537&quot;&gt;&lt;del&gt;HIVE-1537&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1537&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java 1138011 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1138011 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java 1138011 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/Warehouse.java 1138011 &lt;br/&gt;
  trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java 1138011 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1138011 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java 1138011 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1138011 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1138011 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java 1138011 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java 1138011 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java 1138011 &lt;br/&gt;
  trunk/ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHive.java 1138011 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/database_location.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/database_location.q.out PRE-CREATION &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/949/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;1. Updated TestHiveMetaStore.java for testing the functionality - database creation, alteration and table&apos;s locations as TestCliDriver outputs ignore locations.&lt;br/&gt;
2. Added database_location.q for testing the grammar primarily.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Thiruvel&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Thiruvel&lt;/p&gt;
</comment>
                            <comment id="13053959" author="jiraposter@reviews.apache.org" created="Thu, 23 Jun 2011 16:51:47 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/949/#review898&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/#review898&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;



&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/949/#comment1938&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/#comment1938&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    This may not be always successful. You may fail to create dirs for number of reasons. So, this needs to be handled gracefully. Transaction needs to rollback in such case and create database ddl needs to fail. For more info, look the first comment of Devaraj and also his attached partial patch.&lt;/p&gt;



&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/949/#comment1941&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/#comment1941&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    As previously, mkdirs() can fail, so handle similarly as in createDatabase()&lt;/p&gt;



&lt;p&gt;trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/949/#comment1942&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/#comment1942&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Please also add a test when a create database fails because a FS operation fails. In such a case no metadata should get created. One way to simulate that is to make location unwritable then try to create database on that location.&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Ashutosh&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;On 2011-06-23 09:55:50, Thiruvel Thirumoolan wrote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This is an automatically generated e-mail. To reply, visit:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/949/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;(Updated 2011-06-23 09:55:50)&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Review request for hive, Ning Zhang and Amareshwari Sriramadasu.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Summary&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Usage:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;create database location &apos;path1&apos;;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;alter database location &apos;path2&apos;;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;After &apos;alter&apos;, only newly created tables will be located under the new location. Tables created before &apos;alter&apos; will be under &apos;path1&apos;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;1. I have moved getDefaultDatabasePath() to HiveMetaStore and made it private. There should only be one API to obtain the location of a database and it has to accept &apos;Database&apos; as an arg and hence the new method in Warehouse &apos;getDatabasePath()&apos; and similarly &apos;getTablePath()&apos;. The usages of older API also has been changed. Hope that should be fine.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;2. One could argue why have getDatabasePath() as location can be obtained by db.getLocationUri(). I wanted to retain this method to do any additional processing if necessary (getDns or whatever).&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; title=&quot;Allow users to specify LOCATION in CREATE DATABASE statement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1537&quot;&gt;&lt;del&gt;HIVE-1537&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1537&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diffs&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/Warehouse.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHive.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientpositive/database_location.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/database_location.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/949/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/diff&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Testing&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;1. Updated TestHiveMetaStore.java for testing the functionality - database creation, alteration and table&apos;s locations as TestCliDriver outputs ignore locations.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;2. Added database_location.q for testing the grammar primarily.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thiruvel&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thiruvel&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
</comment>
                            <comment id="13054259" author="jiraposter@reviews.apache.org" created="Fri, 24 Jun 2011 06:32:47 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/949/#review905&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/#review905&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;



&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/Warehouse.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/949/#comment1951&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/#comment1951&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    I don&apos;t think we can just remove these public apis. Shall we deprecate them now and remove in next version?&lt;/p&gt;



&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/Warehouse.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/949/#comment1953&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/#comment1953&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Again shall we deprecate this here?&lt;/p&gt;

&lt;p&gt;    I would also be interested in an api getTablePath(dbName, tableName) i.e. without Database object.&lt;/p&gt;




&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/Warehouse.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/949/#comment1954&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/#comment1954&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Same as getTablePath&lt;/p&gt;



&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/949/#comment1950&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/#comment1950&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Similar to TOK_ALTERTABLE_*, we can still have TOK_ALTERDATABASE_DBPROPERTIES for properties and TOK_ALTERDATABASE_LOCATION for location. What do you think?&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Amareshwari&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;On 2011-06-23 09:55:50, Thiruvel Thirumoolan wrote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This is an automatically generated e-mail. To reply, visit:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/949/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;(Updated 2011-06-23 09:55:50)&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Review request for hive, Ning Zhang and Amareshwari Sriramadasu.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Summary&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Usage:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;create database location &apos;path1&apos;;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;alter database location &apos;path2&apos;;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;After &apos;alter&apos;, only newly created tables will be located under the new location. Tables created before &apos;alter&apos; will be under &apos;path1&apos;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;1. I have moved getDefaultDatabasePath() to HiveMetaStore and made it private. There should only be one API to obtain the location of a database and it has to accept &apos;Database&apos; as an arg and hence the new method in Warehouse &apos;getDatabasePath()&apos; and similarly &apos;getTablePath()&apos;. The usages of older API also has been changed. Hope that should be fine.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;2. One could argue why have getDatabasePath() as location can be obtained by db.getLocationUri(). I wanted to retain this method to do any additional processing if necessary (getDns or whatever).&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; title=&quot;Allow users to specify LOCATION in CREATE DATABASE statement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1537&quot;&gt;&lt;del&gt;HIVE-1537&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1537&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diffs&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/Warehouse.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHive.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientpositive/database_location.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/database_location.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/949/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/diff&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Testing&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;1. Updated TestHiveMetaStore.java for testing the functionality - database creation, alteration and table&apos;s locations as TestCliDriver outputs ignore locations.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;2. Added database_location.q for testing the grammar primarily.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thiruvel&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thiruvel&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
</comment>
                            <comment id="13054292" author="jiraposter@reviews.apache.org" created="Fri, 24 Jun 2011 07:48:47 +0000"  >

&lt;blockquote&gt;&lt;p&gt;On 2011-06-23 16:49:59, Ashutosh Chauhan wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java, line 591&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/949/diff/1/?file=21560#file21560line591&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/diff/1/?file=21560#file21560line591&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     This may not be always successful. You may fail to create dirs for number of reasons. So, this needs to be handled gracefully. Transaction needs to rollback in such case and create database ddl needs to fail. For more info, look the first comment of Devaraj and also his attached partial patch.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I requested Devaraj offline to handle it in a separate JIRA. I am not sure about other methods having the same issue. That said, I introduced the same bug with alter_database. Will fix it for create and alter databases.&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Thiruvel&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/949/#review898&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/#review898&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


&lt;p&gt;On 2011-06-23 09:55:50, Thiruvel Thirumoolan wrote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This is an automatically generated e-mail. To reply, visit:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/949/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;(Updated 2011-06-23 09:55:50)&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Review request for hive, Ning Zhang and Amareshwari Sriramadasu.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Summary&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Usage:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;create database location &apos;path1&apos;;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;alter database location &apos;path2&apos;;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;After &apos;alter&apos;, only newly created tables will be located under the new location. Tables created before &apos;alter&apos; will be under &apos;path1&apos;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;1. I have moved getDefaultDatabasePath() to HiveMetaStore and made it private. There should only be one API to obtain the location of a database and it has to accept &apos;Database&apos; as an arg and hence the new method in Warehouse &apos;getDatabasePath()&apos; and similarly &apos;getTablePath()&apos;. The usages of older API also has been changed. Hope that should be fine.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;2. One could argue why have getDatabasePath() as location can be obtained by db.getLocationUri(). I wanted to retain this method to do any additional processing if necessary (getDns or whatever).&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; title=&quot;Allow users to specify LOCATION in CREATE DATABASE statement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1537&quot;&gt;&lt;del&gt;HIVE-1537&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1537&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diffs&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/Warehouse.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHive.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientpositive/database_location.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/database_location.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/949/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/diff&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Testing&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;1. Updated TestHiveMetaStore.java for testing the functionality - database creation, alteration and table&apos;s locations as TestCliDriver outputs ignore locations.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;2. Added database_location.q for testing the grammar primarily.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thiruvel&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thiruvel&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
</comment>
                            <comment id="13054293" author="jiraposter@reviews.apache.org" created="Fri, 24 Jun 2011 07:48:49 +0000"  >

&lt;blockquote&gt;&lt;p&gt;On 2011-06-24 06:32:41, Amareshwari Sriramadasu wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; trunk/metastore/src/java/org/apache/hadoop/hive/metastore/Warehouse.java, line 159&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/949/diff/1/?file=21562#file21562line159&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/diff/1/?file=21562#file21562line159&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     I don&apos;t think we can just remove these public apis. Shall we deprecate them now and remove in next version?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Dependence on dbname and not Database:&lt;/p&gt;

&lt;p&gt;If dbname is an arg, a Database object is required to get location and that will add a dependency to a RawStore instance (either creating it internally or as argument). The current separation of functionality seem to be breached and I did not want to do that. Let me know what you think.&lt;/p&gt;

&lt;p&gt;Making methods deprecated:&lt;/p&gt;

&lt;p&gt;0. I assumed this API is not used outside Hive and addressed internal usages. HCatalog will be inheriting this patch and that should work for them as well.&lt;br/&gt;
1. Retaining the API without change would return wrong results for databases created with a location.&lt;br/&gt;
2. Changing the API with change would add dependency to RawStore, which again I don&apos;t want.&lt;/p&gt;

&lt;p&gt;Considering all these, I removed it. Let me know if I am wrong.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;On 2011-06-24 06:32:41, Amareshwari Sriramadasu wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g, line 613&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/949/diff/1/?file=21567#file21567line613&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/diff/1/?file=21567#file21567line613&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     Similar to TOK_ALTERTABLE_*, we can still have TOK_ALTERDATABASE_DBPROPERTIES for properties and TOK_ALTERDATABASE_LOCATION for location. What do you think?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I thought about it, I intended to keep it compact. The amount of work being done for each ALTERTABLE_* is high but its pretty small for database (at-least for now). But it does not hurt to separate out.&lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Thiruvel&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/949/#review905&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/#review905&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


&lt;p&gt;On 2011-06-23 09:55:50, Thiruvel Thirumoolan wrote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This is an automatically generated e-mail. To reply, visit:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/949/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;(Updated 2011-06-23 09:55:50)&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Review request for hive, Ning Zhang and Amareshwari Sriramadasu.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Summary&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Usage:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;create database location &apos;path1&apos;;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;alter database location &apos;path2&apos;;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;After &apos;alter&apos;, only newly created tables will be located under the new location. Tables created before &apos;alter&apos; will be under &apos;path1&apos;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;1. I have moved getDefaultDatabasePath() to HiveMetaStore and made it private. There should only be one API to obtain the location of a database and it has to accept &apos;Database&apos; as an arg and hence the new method in Warehouse &apos;getDatabasePath()&apos; and similarly &apos;getTablePath()&apos;. The usages of older API also has been changed. Hope that should be fine.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;2. One could argue why have getDatabasePath() as location can be obtained by db.getLocationUri(). I wanted to retain this method to do any additional processing if necessary (getDns or whatever).&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; title=&quot;Allow users to specify LOCATION in CREATE DATABASE statement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1537&quot;&gt;&lt;del&gt;HIVE-1537&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1537&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diffs&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/Warehouse.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHive.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientpositive/database_location.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/database_location.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/949/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/diff&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Testing&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;1. Updated TestHiveMetaStore.java for testing the functionality - database creation, alteration and table&apos;s locations as TestCliDriver outputs ignore locations.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;2. Added database_location.q for testing the grammar primarily.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thiruvel&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thiruvel&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
</comment>
                            <comment id="13054523" author="jiraposter@reviews.apache.org" created="Fri, 24 Jun 2011 16:21:47 +0000"  >

&lt;blockquote&gt;&lt;p&gt;On 2011-06-23 16:49:59, Ashutosh Chauhan wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java, line 591&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt; &amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/949/diff/1/?file=21560#file21560line591&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/diff/1/?file=21560#file21560line591&lt;/a&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&amp;gt;     This may not be always successful. You may fail to create dirs for number of reasons. So, this needs to be handled gracefully. Transaction needs to rollback in such case and create database ddl needs to fail. For more info, look the first comment of Devaraj and also his attached partial patch.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thiruvel Thirumoolan wrote:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;I requested Devaraj offline to handle it in a separate JIRA. I am not sure about other methods having the same issue. That said, I introduced the same bug with alter_database. Will fix it for create and alter databases.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Actually, problem exists in create Database even now without your patch. So, you are not making it any worse. I am fine if you prefer to address it in a followup jira.  &lt;/p&gt;

&lt;p&gt;About alter database, I am not sure if there is any real usecase for it. Having a database spread across multiple locations is not a regular semantics. First concern is clean rollback semantics. Another is what about drop database in such scenarios, which directories are deleted when you drop a database, current one or all or one you specify in drop database ddl? You potentially need to persist all the locations of database in objectstore for deletion or for other purposes, which means a list of locationUri instead of a single string. Given all these, you might want to defer alter database to a new jira. Apart from better understanding of the usecases and semantics for alter database, doing it in two different jira will make this patch smaller and thus easier to get committed. &lt;/p&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Ashutosh&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/949/#review898&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/#review898&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


&lt;p&gt;On 2011-06-23 09:55:50, Thiruvel Thirumoolan wrote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This is an automatically generated e-mail. To reply, visit:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/949/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;(Updated 2011-06-23 09:55:50)&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Review request for hive, Ning Zhang and Amareshwari Sriramadasu.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Summary&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Usage:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;create database location &apos;path1&apos;;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;alter database location &apos;path2&apos;;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;After &apos;alter&apos;, only newly created tables will be located under the new location. Tables created before &apos;alter&apos; will be under &apos;path1&apos;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;1. I have moved getDefaultDatabasePath() to HiveMetaStore and made it private. There should only be one API to obtain the location of a database and it has to accept &apos;Database&apos; as an arg and hence the new method in Warehouse &apos;getDatabasePath()&apos; and similarly &apos;getTablePath()&apos;. The usages of older API also has been changed. Hope that should be fine.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;2. One could argue why have getDatabasePath() as location can be obtained by db.getLocationUri(). I wanted to retain this method to do any additional processing if necessary (getDns or whatever).&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; title=&quot;Allow users to specify LOCATION in CREATE DATABASE statement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1537&quot;&gt;&lt;del&gt;HIVE-1537&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1537&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diffs&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/Warehouse.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHive.java 1138011 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientpositive/database_location.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/database_location.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/949/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/diff&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Testing&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;1. Updated TestHiveMetaStore.java for testing the functionality - database creation, alteration and table&apos;s locations as TestCliDriver outputs ignore locations.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;2. Added database_location.q for testing the grammar primarily.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thiruvel&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thiruvel&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
</comment>
                            <comment id="13055389" author="thiruvel" created="Mon, 27 Jun 2011 08:13:37 +0000"  >&lt;p&gt;Will upload a revised patch without alter database.&lt;/p&gt;</comment>
                            <comment id="13056731" author="jiraposter@reviews.apache.org" created="Tue, 28 Jun 2011 20:08:17 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/973/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/973/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for hive, Ashutosh Chauhan, Ning Zhang, and Amareshwari Sriramadasu.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Removed alter database code from previous patch.&lt;/li&gt;
	&lt;li&gt;Updated create database to gracefully fail if database dir cannot be created (very close to Devaraj&apos;s patch)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; title=&quot;Allow users to specify LOCATION in CREATE DATABASE statement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1537&quot;&gt;&lt;del&gt;HIVE-1537&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1537&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java 1140495 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1140495 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/Warehouse.java 1140495 &lt;br/&gt;
  trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java 1140495 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java 1140495 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1140495 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1140495 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java 1140495 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java 1140495 &lt;br/&gt;
  trunk/ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHive.java 1140495 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/database_location.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/database_location.q.out PRE-CREATION &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/973/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/973/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Updated testDatabaseLocation() in TestHiveMetaStore() to test for negative case.&lt;/p&gt;

&lt;p&gt;Ran entire unit test and it went through fine for me.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Thiruvel&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Thiruvel&lt;/p&gt;
</comment>
                            <comment id="13057164" author="jiraposter@reviews.apache.org" created="Wed, 29 Jun 2011 11:19:28 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/949/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2011-06-29 11:17:50.481535)&lt;/p&gt;


&lt;p&gt;Review request for hive, Ning Zhang and Amareshwari Sriramadasu.&lt;/p&gt;


&lt;p&gt;Changes&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Updating old review request with the new patch, encountered an error yesterday and raised a new request.&lt;/p&gt;

&lt;p&gt;Changelog:&lt;/p&gt;

&lt;p&gt;1. Alter database has been removed.&lt;br/&gt;
2. create database will fail when database directory cannot be created. (Devaraj&apos;s patch)&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Thiruvel&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Usage:&lt;/p&gt;

&lt;p&gt;create database location &apos;path1&apos;;&lt;br/&gt;
alter database location &apos;path2&apos;;&lt;/p&gt;

&lt;p&gt;After &apos;alter&apos;, only newly created tables will be located under the new location. Tables created before &apos;alter&apos; will be under &apos;path1&apos;.&lt;/p&gt;

&lt;p&gt;Notes:&lt;br/&gt;
------&lt;br/&gt;
1. I have moved getDefaultDatabasePath() to HiveMetaStore and made it private. There should only be one API to obtain the location of a database and it has to accept &apos;Database&apos; as an arg and hence the new method in Warehouse &apos;getDatabasePath()&apos; and similarly &apos;getTablePath()&apos;. The usages of older API also has been changed. Hope that should be fine.&lt;br/&gt;
2. One could argue why have getDatabasePath() as location can be obtained by db.getLocationUri(). I wanted to retain this method to do any additional processing if necessary (getDns or whatever).&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; title=&quot;Allow users to specify LOCATION in CREATE DATABASE statement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1537&quot;&gt;&lt;del&gt;HIVE-1537&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1537&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java 1140495 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1140495 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/Warehouse.java 1140495 &lt;br/&gt;
  trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java 1140495 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java 1140495 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1140495 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1140495 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java 1140495 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java 1140495 &lt;br/&gt;
  trunk/ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHive.java 1140495 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/database_location.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/database_location.q.out PRE-CREATION &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/949/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;1. Updated TestHiveMetaStore.java for testing the functionality - database creation, alteration and table&apos;s locations as TestCliDriver outputs ignore locations.&lt;br/&gt;
2. Added database_location.q for testing the grammar primarily.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Thiruvel&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Thiruvel&lt;/p&gt;
</comment>
                            <comment id="13057177" author="jiraposter@reviews.apache.org" created="Wed, 29 Jun 2011 11:41:28 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/949/#review930&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/#review930&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;


&lt;p&gt;Changes look fine to me. &lt;br/&gt;
Ning, what do you think about removing the api in Warehouse.java vs deprecating them? &lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Amareshwari&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;On 2011-06-29 11:17:50, Thiruvel Thirumoolan wrote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This is an automatically generated e-mail. To reply, visit:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/949/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;(Updated 2011-06-29 11:17:50)&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Review request for hive, Ning Zhang and Amareshwari Sriramadasu.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Summary&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Usage:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;create database location &apos;path1&apos;;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;alter database location &apos;path2&apos;;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;After &apos;alter&apos;, only newly created tables will be located under the new location. Tables created before &apos;alter&apos; will be under &apos;path1&apos;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;1. I have moved getDefaultDatabasePath() to HiveMetaStore and made it private. There should only be one API to obtain the location of a database and it has to accept &apos;Database&apos; as an arg and hence the new method in Warehouse &apos;getDatabasePath()&apos; and similarly &apos;getTablePath()&apos;. The usages of older API also has been changed. Hope that should be fine.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;2. One could argue why have getDatabasePath() as location can be obtained by db.getLocationUri(). I wanted to retain this method to do any additional processing if necessary (getDns or whatever).&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; title=&quot;Allow users to specify LOCATION in CREATE DATABASE statement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1537&quot;&gt;&lt;del&gt;HIVE-1537&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1537&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diffs&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/Warehouse.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHive.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientpositive/database_location.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/database_location.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/949/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/diff&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Testing&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;1. Updated TestHiveMetaStore.java for testing the functionality - database creation, alteration and table&apos;s locations as TestCliDriver outputs ignore locations.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;2. Added database_location.q for testing the grammar primarily.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thiruvel&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thiruvel&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
</comment>
                            <comment id="13059175" author="jiraposter@reviews.apache.org" created="Sun, 3 Jul 2011 08:06:21 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/949/#review959&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/#review959&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;



&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java&lt;br/&gt;
&amp;lt;&lt;a href=&quot;https://reviews.apache.org/r/949/#comment2036&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/#comment2036&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    If location already exists then create db will fail. This differs from create table semantics, where if location already exists then create table succeeds. I think we should follow create table in both semantics as well as code-wise, which does as follows:&lt;br/&gt;
     if (!wh.isDir(tblPath)) {&lt;br/&gt;
                if (!wh.mkdirs(tblPath)) &lt;/p&gt;
{
                  throw new MetaException(tblPath
                      + &quot; is not a directory or unable to create one&quot;);
                }
&lt;p&gt;                madeDir = true;&lt;br/&gt;
              }&lt;/p&gt;

&lt;p&gt;    Also note that fs operations are done within transaction. &lt;/p&gt;


&lt;p&gt;w.r.t deprecation Vs deletion of path api, I agree with Thiruvel&apos;s analysis, that its best to delete the api, since the old one will be buggy with these changes and also then there will be multiple ways to get path which will be confusing.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Ashutosh&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;On 2011-06-29 11:17:50, Thiruvel Thirumoolan wrote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This is an automatically generated e-mail. To reply, visit:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/949/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;(Updated 2011-06-29 11:17:50)&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Review request for hive, Ning Zhang and Amareshwari Sriramadasu.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Summary&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Usage:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;create database location &apos;path1&apos;;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;alter database location &apos;path2&apos;;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;After &apos;alter&apos;, only newly created tables will be located under the new location. Tables created before &apos;alter&apos; will be under &apos;path1&apos;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;1. I have moved getDefaultDatabasePath() to HiveMetaStore and made it private. There should only be one API to obtain the location of a database and it has to accept &apos;Database&apos; as an arg and hence the new method in Warehouse &apos;getDatabasePath()&apos; and similarly &apos;getTablePath()&apos;. The usages of older API also has been changed. Hope that should be fine.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;2. One could argue why have getDatabasePath() as location can be obtained by db.getLocationUri(). I wanted to retain this method to do any additional processing if necessary (getDns or whatever).&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; title=&quot;Allow users to specify LOCATION in CREATE DATABASE statement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1537&quot;&gt;&lt;del&gt;HIVE-1537&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1537&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diffs&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/Warehouse.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHive.java 1140495 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientpositive/database_location.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/database_location.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/949/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/diff&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Testing&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;1. Updated TestHiveMetaStore.java for testing the functionality - database creation, alteration and table&apos;s locations as TestCliDriver outputs ignore locations.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;2. Added database_location.q for testing the grammar primarily.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thiruvel&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thiruvel&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
</comment>
                            <comment id="13059176" author="devaraj" created="Sun, 3 Jul 2011 08:08:22 +0000"  >&lt;p&gt;I&apos;m no longer at Yahoo!.  My new email address is ddas@hortonworks.com.  Please update your address book and resend your message.&lt;/p&gt;</comment>
                            <comment id="13060523" author="jiraposter@reviews.apache.org" created="Wed, 6 Jul 2011 12:15:17 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/949/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2011-07-06 12:14:34.148278)&lt;/p&gt;


&lt;p&gt;Review request for hive, Ning Zhang and Amareshwari Sriramadasu.&lt;/p&gt;


&lt;p&gt;Changes&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Thanks Ashutosh, updated patch with your comments. Not sure whats the benefit of embedding the whole chunk inside transactions, so have not done it.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;br/&gt;
Thiruvel&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Usage:&lt;/p&gt;

&lt;p&gt;create database location &apos;path1&apos;;&lt;br/&gt;
alter database location &apos;path2&apos;;&lt;/p&gt;

&lt;p&gt;After &apos;alter&apos;, only newly created tables will be located under the new location. Tables created before &apos;alter&apos; will be under &apos;path1&apos;.&lt;/p&gt;

&lt;p&gt;Notes:&lt;br/&gt;
------&lt;br/&gt;
1. I have moved getDefaultDatabasePath() to HiveMetaStore and made it private. There should only be one API to obtain the location of a database and it has to accept &apos;Database&apos; as an arg and hence the new method in Warehouse &apos;getDatabasePath()&apos; and similarly &apos;getTablePath()&apos;. The usages of older API also has been changed. Hope that should be fine.&lt;br/&gt;
2. One could argue why have getDatabasePath() as location can be obtained by db.getLocationUri(). I wanted to retain this method to do any additional processing if necessary (getDns or whatever).&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; title=&quot;Allow users to specify LOCATION in CREATE DATABASE statement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1537&quot;&gt;&lt;del&gt;HIVE-1537&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1537&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java 1143322 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1143322 &lt;br/&gt;
  trunk/metastore/src/java/org/apache/hadoop/hive/metastore/Warehouse.java 1143322 &lt;br/&gt;
  trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java 1143322 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java 1143322 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1143322 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1143322 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java 1143322 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java 1143322 &lt;br/&gt;
  trunk/ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHive.java 1143322 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/database_location.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/database_location.q.out PRE-CREATION &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/949/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;1. Updated TestHiveMetaStore.java for testing the functionality - database creation, alteration and table&apos;s locations as TestCliDriver outputs ignore locations.&lt;br/&gt;
2. Added database_location.q for testing the grammar primarily.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Thiruvel&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Thiruvel&lt;/p&gt;
</comment>
                            <comment id="13060652" author="jiraposter@reviews.apache.org" created="Wed, 6 Jul 2011 15:57:16 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/949/#review966&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/#review966&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Ship it!&lt;/p&gt;


&lt;p&gt;+1 &lt;br/&gt;
Looks good to me.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Ashutosh&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;On 2011-07-06 12:14:34, Thiruvel Thirumoolan wrote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This is an automatically generated e-mail. To reply, visit:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/949/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----------------------------------------------------------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;(Updated 2011-07-06 12:14:34)&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Review request for hive, Ning Zhang and Amareshwari Sriramadasu.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Summary&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Usage:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;create database location &apos;path1&apos;;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;alter database location &apos;path2&apos;;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;After &apos;alter&apos;, only newly created tables will be located under the new location. Tables created before &apos;alter&apos; will be under &apos;path1&apos;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;1. I have moved getDefaultDatabasePath() to HiveMetaStore and made it private. There should only be one API to obtain the location of a database and it has to accept &apos;Database&apos; as an arg and hence the new method in Warehouse &apos;getDatabasePath()&apos; and similarly &apos;getTablePath()&apos;. The usages of older API also has been changed. Hope that should be fine.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;2. One could argue why have getDatabasePath() as location can be obtained by db.getLocationUri(). I wanted to retain this method to do any additional processing if necessary (getDns or whatever).&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; title=&quot;Allow users to specify LOCATION in CREATE DATABASE statement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1537&quot;&gt;&lt;del&gt;HIVE-1537&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1537&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diffs&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-----&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java 1143322 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java 1143322 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/java/org/apache/hadoop/hive/metastore/Warehouse.java 1143322 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java 1143322 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java 1143322 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 1143322 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 1143322 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java 1143322 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java 1143322 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHive.java 1143322 &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/queries/clientpositive/database_location.q PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;trunk/ql/src/test/results/clientpositive/database_location.q.out PRE-CREATION &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/949/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/diff&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Testing&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;-------&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;1. Updated TestHiveMetaStore.java for testing the functionality - database creation, alteration and table&apos;s locations as TestCliDriver outputs ignore locations.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;2. Added database_location.q for testing the grammar primarily.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thiruvel&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thanks,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Thiruvel&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;
</comment>
                            <comment id="13061848" author="thiruvel" created="Fri, 8 Jul 2011 08:52:22 +0000"  >&lt;p&gt;Uploading patch that was reviewed.&lt;/p&gt;</comment>
                            <comment id="13061851" author="thiruvel" created="Fri, 8 Jul 2011 08:57:13 +0000"  >&lt;p&gt;Patch reviewed @ &lt;a href=&quot;https://reviews.apache.org/r/949/diff/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/949/diff/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13061852" author="amareshwari" created="Fri, 8 Jul 2011 08:59:21 +0000"  >&lt;p&gt;+1&lt;br/&gt;
Running tests.&lt;/p&gt;</comment>
                            <comment id="13062888" author="amareshwari" created="Mon, 11 Jul 2011 07:29:30 +0000"  >&lt;p&gt;The tests drop_multi_partitions.q, escape1.q failed. The tests failed without the patch also. Will commit it now.&lt;/p&gt;</comment>
                            <comment id="13062894" author="amareshwari" created="Mon, 11 Jul 2011 07:35:53 +0000"  >&lt;p&gt;I just committed this. Thanks Thiruvel !&lt;/p&gt;</comment>
                            <comment id="13063323" author="hudson" created="Mon, 11 Jul 2011 13:03:29 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #820 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/820/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/820/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1537&quot; title=&quot;Allow users to specify LOCATION in CREATE DATABASE statement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1537&quot;&gt;&lt;del&gt;HIVE-1537&lt;/del&gt;&lt;/a&gt;. Allow users to specify LOCATION in CREATE DATABASE statement. Contributed by Thiruvel Thirumoolan&lt;/p&gt;

&lt;p&gt;amareshwari : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1145053&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1145053&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHive.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/test/org/apache/hadoop/hive/metastore/TestHiveMetaStore.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/database_location.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/database_location.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/Warehouse.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12514719">HIVE-2292</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12431185">HIVE-675</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12483321" name="HIVE-1537.patch" size="36100" author="thiruvel" created="Tue, 21 Jun 2011 18:26:46 +0000"/>
                            <attachment id="12485711" name="HIVE-1537_3.patch" size="30363" author="thiruvel" created="Fri, 8 Jul 2011 08:52:22 +0000"/>
                            <attachment id="12476425" name="hive-1537.metastore.part.patch" size="2129" author="devaraj" created="Fri, 15 Apr 2011 07:30:33 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 15 Apr 2011 07:30:33 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>67453</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10342"><![CDATA[Incompatible change]]></customfieldvalue>
    <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 29 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfkv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123174</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Allow users to create database at a specific location. All tables created with that database will have their table-directory under the location.&lt;br/&gt;
&lt;br/&gt;
Usage:&lt;br/&gt;
create database &amp;lt;dbname&amp;gt; location &amp;lt;path&amp;gt;;</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>database</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1538] FilterOperator is applied twice with ppd on.</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1538</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;With hive.optimize.ppd set to true, FilterOperator is applied twice. And it seems second operator is always filtering zero rows.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471503">HIVE-1538</key>
            <summary>FilterOperator is applied twice with ppd on.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="amareshwari">Amareshwari Sriramadasu</assignee>
                                    <reporter username="amareshwari">Amareshwari Sriramadasu</reporter>
                        <labels>
                    </labels>
                <created>Fri, 13 Aug 2010 07:44:46 +0000</created>
                <updated>Thu, 28 Jan 2016 03:01:02 +0000</updated>
                            <resolved>Wed, 13 Jul 2011 16:50:31 +0000</resolved>
                                                    <fixVersion>0.8.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="12898120" author="amareshwari" created="Fri, 13 Aug 2010 07:53:30 +0000"  >&lt;p&gt;I see that if a query has where clause, the FilterOperator is applied twice.&lt;/p&gt;

&lt;p&gt;Explain on a query with where clause :&lt;br/&gt;
hive&amp;gt; explain select * from input1 where input1.key != 10;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;OK
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF input1)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_WHERE (!= (. (TOK_TABLE_OR_COL input1) key) 10))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -&amp;gt; Map Operator Tree:
        input1
          TableScan
            alias: input1
            Filter Operator
              predicate:
                  expr: (key &amp;lt;&amp;gt; 10)
                  type: boolean
              Filter Operator
                predicate:
                    expr: (key &amp;lt;&amp;gt; 10)
                    type: boolean
                Select Operator
                  expressions:
                        expr: key
                        type: int
                        expr: value
                        type: int
                  outputColumnNames: _col0, _col1
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

  Stage: Stage-0
    Fetch Operator
      limit: -1
Time taken: 0.099 seconds
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I see the same from the Mapper logs also. The first FilterOperator does the&lt;br/&gt;
filtering and second operator always filters zero rows.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;....
2010-08-13 13:20:21,451 INFO ExecMapper: 
&amp;lt;MAP&amp;gt;Id =5
  &amp;lt;Children&amp;gt;
    &amp;lt;TS&amp;gt;Id =0
      &amp;lt;Children&amp;gt;
        &amp;lt;FIL&amp;gt;Id =1
          &amp;lt;Children&amp;gt;
            &amp;lt;FIL&amp;gt;Id =2
              &amp;lt;Children&amp;gt;
                &amp;lt;SEL&amp;gt;Id =3
                  &amp;lt;Children&amp;gt;
                    &amp;lt;FS&amp;gt;Id =4
                      &amp;lt;Parent&amp;gt;Id = 3 null&amp;lt;\Parent&amp;gt;
                    &amp;lt;\FS&amp;gt;
                  &amp;lt;\Children&amp;gt;
                  &amp;lt;Parent&amp;gt;Id = 2 null&amp;lt;\Parent&amp;gt;
                &amp;lt;\SEL&amp;gt;
              &amp;lt;\Children&amp;gt;
              &amp;lt;Parent&amp;gt;Id = 1 null&amp;lt;\Parent&amp;gt;
            &amp;lt;\FIL&amp;gt;
          &amp;lt;\Children&amp;gt;
          &amp;lt;Parent&amp;gt;Id = 0 null&amp;lt;\Parent&amp;gt;
        &amp;lt;\FIL&amp;gt;
      &amp;lt;\Children&amp;gt;
      &amp;lt;Parent&amp;gt;Id = 5 null&amp;lt;\Parent&amp;gt;
    &amp;lt;\TS&amp;gt;
  &amp;lt;\Children&amp;gt;
&amp;lt;\MAP&amp;gt;
...
2010-08-13 13:20:21,489 INFO org.apache.hadoop.hive.ql.exec.MapOperator: 5 forwarding 1 rows
2010-08-13 13:20:21,489 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: 0 forwarding 1 rows
2010-08-13 13:20:21,600 INFO ExecMapper: ExecMapper: processing 1 rows: used memory = 10765360
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.MapOperator: 5 finished. closing... 
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.MapOperator: 5 forwarded 1 rows
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.MapOperator: DESERIALIZE_ERRORS:0
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: 0 finished. closing... 
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: 0 forwarded 1 rows
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.FilterOperator: 1 finished. closing... 
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.FilterOperator: 1 forwarded 0 rows
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.FilterOperator: PASSED:0
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.FilterOperator: FILTERED:1
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.FilterOperator: 2 finished. closing... 
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.FilterOperator: 2 forwarded 0 rows
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.FilterOperator: PASSED:0
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.FilterOperator: FILTERED:0
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 3 finished. closing... 
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 3 forwarded 0 rows
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: 4 finished. closing... 
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: 4 forwarded 0 rows
2010-08-13 13:20:21,600 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Final Path: FS hdfs://localhost:19000/tmp/hive-amarsri/hive_2010-08-13_13-20-11_483_2065579562420016208/_tmp.-ext-10001/000000_0
2010-08-13 13:20:21,601 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: Writing to temp file: FS hdfs://localhost:19000/tmp/hive-amarsri/hive_2010-08-13_13-20-11_483_2065579562420016208/_tmp.-ext-10001/_tmp.000000_0
2010-08-13 13:20:21,604 INFO org.apache.hadoop.hive.ql.exec.FileSinkOperator: New Final Path: FS hdfs://localhost:19000/tmp/hive-amarsri/hive_2010-08-13_13-20-11_483_2065579562420016208/_tmp.-ext-10001/000000_0
2010-08-13 13:20:21,629 INFO org.apache.hadoop.hive.ql.exec.SelectOperator: 3 Close done
2010-08-13 13:20:21,629 INFO org.apache.hadoop.hive.ql.exec.FilterOperator: 2 Close done
2010-08-13 13:20:21,629 INFO org.apache.hadoop.hive.ql.exec.FilterOperator: 1 Close done
2010-08-13 13:20:21,629 INFO org.apache.hadoop.hive.ql.exec.TableScanOperator: 0 Close done
2010-08-13 13:20:21,629 INFO org.apache.hadoop.hive.ql.exec.MapOperator: 5 Close done
2010-08-13 13:20:21,629 INFO ExecMapper: ExecMapper: processed 1 rows: used memory = 11454224
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12898122" author="amareshwari" created="Fri, 13 Aug 2010 07:55:22 +0000"  >&lt;p&gt;With hive.optimize.ppd set to false, I see that the FilterOperator is applied only once.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;hive&amp;gt; SET hive.optimize.ppd=false;
hive&amp;gt; explain select * from input1 where input1.key != 10;
OK
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF input1)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_WHERE (!= (. (TOK_TABLE_OR_COL input1) key) 10))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -&amp;gt; Map Operator Tree:
        input1
          TableScan
            alias: input1
            Filter Operator
              predicate:
                  expr: (key &amp;lt;&amp;gt; 10)
                  type: boolean
              Select Operator
                expressions:
                      expr: key
                      type: int
                      expr: value
                      type: int
                outputColumnNames: _col0, _col1
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

  Stage: Stage-0
    Fetch Operator
      limit: -1

Time taken: 0.022 seconds
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12898144" author="amareshwari" created="Fri, 13 Aug 2010 09:23:23 +0000"  >&lt;p&gt;Also, I observed that Select Operator is applied twice for a MapJoin query. Is it related to this?&lt;/p&gt;</comment>
                            <comment id="12906428" author="amareshwari" created="Mon, 6 Sep 2010 04:15:28 +0000"  >&lt;p&gt;With predicate pushdown on, the final candidates for predicate pushdown are collected for the top operator. &lt;br/&gt;
And a FilterOperator is created, with the final candidates, as a child of TableScanOperator (topOp). But the operators (FilterOperators) whose predicates are pushed down, are not removed.&lt;br/&gt;
I think the solution is to collect the operators who are contributing the predicates for &quot;final candidates of predicare pushdown&quot; and remove them from the final operator graph.&lt;br/&gt;
Thoughts?&lt;/p&gt;</comment>
                            <comment id="12906666" author="namit" created="Tue, 7 Sep 2010 04:18:54 +0000"  >&lt;p&gt;That is right - this has nothing to do with map join.&lt;br/&gt;
Whenever, a predicate is pushed down, it is also retained, thereby having 2 identical filters.&lt;/p&gt;

&lt;p&gt;Is this creating a performance problem ? It can definitely be optimized.&lt;br/&gt;
I totally agree with your proposed solution.&lt;/p&gt;</comment>
                            <comment id="12913354" author="jvs" created="Wed, 22 Sep 2010 02:16:07 +0000"  >&lt;p&gt;It would be cool to get this fixed; without it the predicate decomposition I added for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1226&quot; title=&quot;support filter pushdown against non-native tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1226&quot;&gt;&lt;del&gt;HIVE-1226&lt;/del&gt;&lt;/a&gt; is pointless.&lt;/p&gt;</comment>
                            <comment id="12921603" author="namit" created="Sat, 16 Oct 2010 00:24:42 +0000"  >&lt;p&gt;Amareshwari, are you planning to work on this ?&lt;/p&gt;

&lt;p&gt;We are trying to improve the performance, and some profiling showed that can lead to lot of improvements&lt;/p&gt;</comment>
                            <comment id="12921964" author="amareshwari" created="Mon, 18 Oct 2010 04:48:23 +0000"  >&lt;p&gt;Namit, I can take this up once I&apos;m done with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-474&quot; title=&quot;Support for distinct selection on two or more columns&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-474&quot;&gt;&lt;del&gt;HIVE-474&lt;/del&gt;&lt;/a&gt; i.e. mostly after a week.&lt;/p&gt;</comment>
                            <comment id="12921966" author="namit" created="Mon, 18 Oct 2010 04:50:54 +0000"  >&lt;p&gt;Thanks, That will be great. It can lead to substantial improvement (10-15%) on the map-side &lt;br/&gt;
for a large range of queries&lt;/p&gt;</comment>
                            <comment id="12925777" author="amareshwari" created="Thu, 28 Oct 2010 11:20:47 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think the solution is to collect the operators who are contributing the predicates for &quot;final candidates of predicare pushdown&quot; and remove them from the final operator graph.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This does not work as I thought earlier, because all the predicates in the FilterOperator may not be pushed. We might have to reconstruct the FilterOperator with un-pushed predicates.&lt;/p&gt;</comment>
                            <comment id="12929976" author="amareshwari" created="Tue, 9 Nov 2010 06:11:12 +0000"  >&lt;p&gt;There are a couple of issues in removing the original filter operator.&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;All the expressions in the filter predicate may not be pushed.
	&lt;ul&gt;
		&lt;li&gt;I&apos;m planning to create a filter operator with non-final candidates as a child of the original filter op and mark the original filter op for deletion.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;The candidate predicates may not pushed past some operators. For ex. Outer Join operator does not allow candidates for all aliases; LIMIT/SCRIPT/UDTF operators do not push any predicates.
	&lt;ul&gt;
		&lt;li&gt;I&apos;m planning to create a filter operator with unpushed predicates, as a child of the operator through which the predicates could not be pushed.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Finally, remove the original filter operators which are marked for deletion.&lt;/p&gt;

&lt;p&gt;Thoughts? Any suggestions?&lt;/p&gt;</comment>
                            <comment id="12930247" author="jvs" created="Tue, 9 Nov 2010 19:34:14 +0000"  >&lt;p&gt;You might want to look into &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1342&quot; title=&quot;Predicate push down get error result when sub-queries have the same alias name &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1342&quot;&gt;&lt;del&gt;HIVE-1342&lt;/del&gt;&lt;/a&gt; while you are working on this one.&lt;/p&gt;</comment>
                            <comment id="12931447" author="namit" created="Fri, 12 Nov 2010 17:23:27 +0000"  >&lt;p&gt;Talked to Amareshwari offline - the proposal looks good.&lt;br/&gt;
As a follow-up, we can merge consecutive filters in a follow-up task&lt;/p&gt;</comment>
                            <comment id="12935206" author="amareshwari" created="Wed, 24 Nov 2010 04:58:35 +0000"  >&lt;p&gt;Patch with following changes:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;creates a filter operator with unpushed predicates, as a child of the operator through which the predicates could not be pushed.&lt;/li&gt;
	&lt;li&gt;removes original filter operator if it does not have any non-final candidates.&lt;br/&gt;
With creating a child filter operator with the non-final candidates and removing the original one, I&apos;m seeing some problems. So, would like to do that in a followup jira.&lt;/li&gt;
	&lt;li&gt;Updates all the tests with new explain plans.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12965391" author="he yongqiang" created="Tue, 30 Nov 2010 19:54:23 +0000"  >&lt;p&gt;will take a look.&lt;/p&gt;</comment>
                            <comment id="12965508" author="he yongqiang" created="Wed, 1 Dec 2010 00:42:20 +0000"  >&lt;p&gt;I am not familiar with the ppd code, just a few questions:&lt;br/&gt;
In ExprWalkerProcFactory.java line 291,&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; } else if (!FunctionRegistry.isOpAnd(expr)) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;why this is needed? For example, what will happen if it is a OpNot?&lt;/p&gt;

&lt;p&gt;In OpProcFactory, why there is a createFilter in ScriptPPD, JoinPPD, and DefaultPPD?&lt;/p&gt;
</comment>
                            <comment id="12965509" author="he yongqiang" created="Wed, 1 Dec 2010 00:43:40 +0000"  >&lt;p&gt;also in OpProcFactory&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;if (!((FilterOperator)op).getConf().getIsSamplingPred()) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;can we just look at the parent to see if it is a tso?&lt;/p&gt;</comment>
                            <comment id="12965567" author="amareshwari" created="Wed, 1 Dec 2010 04:03:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;In ExprWalkerProcFactory.java line 291,&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;} else if (!FunctionRegistry.isOpAnd(expr)) {&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;why this is needed? For example, what will happen if it is a OpNot?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If it is an opAnd, we determine if its children are final predicates and add them accordingly, so I&apos;m not adding an opAnd to non-final candidates. The exceptional behavior is only for opAnd. opNot is like anyother predicate.&lt;/p&gt;


&lt;blockquote&gt;&lt;p&gt;In OpProcFactory, why there is a createFilter in ScriptPPD, JoinPPD, and DefaultPPD?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;There is createFilter for the unpushed predicates because, ScriptPPD does not allow any predicates to be pushed through it; JoinPPD does not allow predicates on some aliases to be pushed; DefaultPPD might have unpushed predicates because they were not candidates (for ex, ExtractOperator does not allow all predicates) .&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;also in OpProcFactory &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;if (!((FilterOperator)op).getConf().getIsSamplingPred()) {&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;can we just look at the parent to see if it is a tso?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The method createFilter() always creates filter with samplingPred as false. So right now, we cannot push a filter with sampling predicate, unless we make more changes. May be I should change the comment there. &lt;/p&gt;</comment>
                            <comment id="12965951" author="he yongqiang" created="Thu, 2 Dec 2010 01:24:28 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="12965953" author="he yongqiang" created="Thu, 2 Dec 2010 01:25:15 +0000"  >&lt;p&gt;i will still take a more detailed look before i do tests and commit.&lt;/p&gt;</comment>
                            <comment id="12992886" author="cwsteinbach" created="Thu, 10 Feb 2011 07:02:54 +0000"  >&lt;p&gt;Posted a review request here: &lt;a href=&quot;https://reviews.apache.org/r/415/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/415/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Looks like the test diffs need to be regenerated, but the code changes apply cleanly.&lt;/p&gt;

&lt;p&gt;@Yongqiang: Do you have time to finish this review?&lt;/p&gt;</comment>
                            <comment id="13006347" author="amareshwari" created="Mon, 14 Mar 2011 08:04:15 +0000"  >&lt;p&gt;Yongqiang, Can you have a look at the patch before i update it to trunk? Thanks&lt;/p&gt;</comment>
                            <comment id="13007110" author="he yongqiang" created="Tue, 15 Mar 2011 19:14:54 +0000"  >&lt;p&gt;Amareshwari, welcome back. The patch looks good to me. Please go ahead update the patch to trunk (with Carl&apos;s comments).&lt;/p&gt;</comment>
                            <comment id="13009031" author="amareshwari" created="Mon, 21 Mar 2011 06:08:07 +0000"  >&lt;p&gt;Patch is updated to trunk with regenerated outputs.&lt;/p&gt;</comment>
                            <comment id="13009032" author="amareshwari" created="Mon, 21 Mar 2011 06:10:20 +0000"  >&lt;p&gt;All tests passed on my machine.&lt;br/&gt;
@Yongqiang,Can you have a look at the patch and commit asap, because it is more likely to conflict again if delayed ? Thanks&lt;/p&gt;</comment>
                            <comment id="13009483" author="namit" created="Tue, 22 Mar 2011 00:18:30 +0000"  >&lt;p&gt;@Amareshwari, would it be possible to add a configuration variable to turn this off ?&lt;br/&gt;
Just a fallback, in case we missed something&lt;/p&gt;</comment>
                            <comment id="13009642" author="amareshwari" created="Tue, 22 Mar 2011 13:43:37 +0000"  >&lt;p&gt;Added configuration hive.ppd.remove.duplicatefilters, with default value of true. Updated ppd tests to run with both configuration off and on.&lt;/p&gt;</comment>
                            <comment id="13015943" author="jiraposter@reviews.apache.org" created="Tue, 5 Apr 2011 15:00:06 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/550/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/550/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for hive, Yongqiang He and namit jain.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Patch updated to trunk with newly added configuration var hive.ppd.remove.duplicatefilters&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1538&quot; title=&quot;FilterOperator is applied twice with ppd on.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1538&quot;&gt;&lt;del&gt;HIVE-1538&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1538&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1538&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java 1088944 &lt;br/&gt;
  trunk/contrib/src/test/results/clientpositive/dboutput.q.out 1088944 &lt;br/&gt;
  trunk/contrib/src/test/results/clientpositive/serde_typedbytes4.q.out 1088944 &lt;br/&gt;
  trunk/hbase-handler/src/test/results/hbase_pushdown.q.out 1088944 &lt;br/&gt;
  trunk/hbase-handler/src/test/results/hbase_queries.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java 1088944 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/ExprWalkerInfo.java 1088944 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/ExprWalkerProcFactory.java 1088944 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java 1088944 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/OpWalkerInfo.java 1088944 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/PredicatePushDown.java 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd1.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_clusterby.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_constant_expr.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_gby.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_gby2.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_gby_join.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_join.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_join2.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_join3.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_multi_insert.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_outer_join1.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_outer_join2.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_outer_join3.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_outer_join4.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_random.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_transform.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_udf_case.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_union.q 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join0.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join11.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join12.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join13.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join14.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join16.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join19.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join20.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join21.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join23.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join27.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join4.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join5.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join6.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join7.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join8.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join9.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/bucket2.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/bucket3.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/bucket4.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/bucket_groupby.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/bucketmapjoin1.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/bucketmapjoin2.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/bucketmapjoin3.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/case_sensitivity.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/cast1.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/cluster.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/combine2.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/create_view.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/disable_merge_for_bucketing.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/filter_join_breaktask.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/groupby_map_ppr.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/groupby_map_ppr_multi_distinct.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/groupby_ppr.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/groupby_ppr_multi_distinct.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/having.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/implicit_cast1.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input11.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input11_limit.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input14.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input18.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input23.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input24.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input25.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input26.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input2_limit.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input31.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input39.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input42.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input6.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input9.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input_part1.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input_part5.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input_part6.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input_part7.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input_part9.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input_testxpath2.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input_testxpath4.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join0.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join11.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join12.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join13.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join14.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join16.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join19.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join20.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join21.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join23.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join26.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join28.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join32.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join33.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join34.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join35.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join38.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join39.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join4.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join40.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join5.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join6.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join7.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join8.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join9.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join_map_ppr.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/lateral_view_ppd.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/load_dyn_part10.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/load_dyn_part13.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/load_dyn_part2.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/load_dyn_part3.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/load_dyn_part4.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/load_dyn_part9.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/louter_join_ppr.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/mapjoin_distinct.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/mapjoin_subquery.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/merge3.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/merge4.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/merge_dynamic_partition.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/merge_dynamic_partition2.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/merge_dynamic_partition3.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/no_hooks.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/noalias_subq1.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/notable_alias1.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/notable_alias2.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/nullgroup.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/nullgroup2.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/nullgroup4.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/nullgroup4_multi_distinct.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/nullgroup5.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/outer_join_ppr.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/pcr.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd1.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_clusterby.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_constant_expr.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_gby.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_gby2.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_gby_join.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_join.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_join2.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_join3.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_multi_insert.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_outer_join1.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_outer_join2.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_outer_join3.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_outer_join4.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_random.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_transform.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_udf_case.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_union.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/query_result_fileformat.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/quote1.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/rcfile_null_value.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/reduce_deduplicate.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/regex_col.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/regexp_extract.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/router_join_ppr.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample1.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample10.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample2.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample3.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample4.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample5.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample6.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample7.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample8.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample9.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/semijoin.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/set_processor_namespaces.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/skewjoin.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/smb_mapjoin9.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/smb_mapjoin_6.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/stats11.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/stats2.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/subq.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/subq2.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/transform_ppr1.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/transform_ppr2.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf1.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf9.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_10_trims.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_hour.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_isnull_isnotnull.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_like.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_lower.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_minute.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_notequal.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_parse_url.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_second.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_size.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/union.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/union20.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/union22.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/union_ppr.q.out 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/case_sensitivity.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/cast1.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/groupby1.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/groupby2.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/groupby3.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/groupby4.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/groupby5.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/groupby6.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input1.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input2.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input20.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input3.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input4.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input5.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input6.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input7.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input8.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input9.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input_part1.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input_testxpath.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input_testxpath2.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/join1.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/join2.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/join3.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/join4.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/join5.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/join6.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/join7.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/join8.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/sample1.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/sample2.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/sample3.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/sample4.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/sample5.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/sample6.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/sample7.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/subq.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/udf1.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/udf4.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/udf6.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/udf_case.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/udf_when.q.xml 1088944 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/union.q.xml 1088944 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/550/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/550/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;All unit tests passed&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Amareshwari&lt;/p&gt;
</comment>
                            <comment id="13015946" author="amareshwari" created="Tue, 5 Apr 2011 15:02:35 +0000"  >&lt;p&gt;Patch updated to trunk&lt;/p&gt;</comment>
                            <comment id="13061647" author="jvs" created="Thu, 7 Jul 2011 22:57:27 +0000"  >&lt;p&gt;Sorry, this one has gone stale.  Can you rebase against trunk?&lt;/p&gt;</comment>
                            <comment id="13061648" author="jvs" created="Thu, 7 Jul 2011 22:58:18 +0000"  >&lt;p&gt;Sorry for the repeated rebase requests; we&apos;ll make sure the next attempt gets committed!&lt;/p&gt;</comment>
                            <comment id="13064340" author="amareshwari" created="Wed, 13 Jul 2011 04:15:50 +0000"  >&lt;p&gt;Patch rebased to trunk. I would like this patch gets committed asap, because it touches almost all test output files and would go stale fast.&lt;/p&gt;</comment>
                            <comment id="13064355" author="jiraposter@reviews.apache.org" created="Wed, 13 Jul 2011 04:41:00 +0000"  >
&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;https://reviews.apache.org/r/550/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/550/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2011-07-13 04:40:26.685437)&lt;/p&gt;


&lt;p&gt;Review request for hive, Yongqiang He and namit jain.&lt;/p&gt;


&lt;p&gt;Changes&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Patch re-based to trunk&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Patch updated to trunk with newly added configuration var hive.ppd.remove.duplicatefilters&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1538&quot; title=&quot;FilterOperator is applied twice with ppd on.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1538&quot;&gt;&lt;del&gt;HIVE-1538&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1538&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-1538&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/ql/src/test/results/clientpositive/sample7.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample9.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample8.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/semijoin.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/set_processor_namespaces.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/skewjoin.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/smb_mapjoin9.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/smb_mapjoin_6.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/split_sample.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/stats11.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/stats2.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/subq.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/subq2.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/transform_ppr1.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/transform_ppr2.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf1.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf9.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_10_trims.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_hour.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_isnull_isnotnull.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_like.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_lower.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_minute.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_notequal.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_parse_url.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_second.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/udf_size.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/union.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/union20.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/union22.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/union_ppr.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/case_sensitivity.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/cast1.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample6.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample5.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample3.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample4.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample2.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/router_join_ppr.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample1.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/sample10.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/regexp_extract.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/regex_col.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/reduce_deduplicate.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/rcfile_null_value.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/query_result_fileformat.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/quote1.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_udf_case.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_union.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppr_pushdown3.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/bucketmapjoin1.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/bucketmapjoin2.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/bucketmapjoin3.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/case_sensitivity.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/cast1.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/cluster.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/combine2.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/create_view.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/disable_merge_for_bucketing.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/filter_join_breaktask.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/groupby_map_ppr.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/groupby_map_ppr_multi_distinct.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/groupby_ppr.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/groupby_ppr_multi_distinct.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/having.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/implicit_cast1.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/index_auto.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/index_auto_file_format.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/index_auto_multiple.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/index_auto_partitioned.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/index_auto_unused.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/index_bitmap3.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/index_bitmap_auto.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/index_bitmap_auto_partitioned.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input11.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input11_limit.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input14.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input18.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input23.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input24.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input25.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input26.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input2_limit.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input31.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input39.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input42.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input6.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input9.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input_part1.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input_part5.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input_part6.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input_part7.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input_part9.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input_testxpath2.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/input_testxpath4.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join0.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join11.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join12.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join13.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join14.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join16.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join19.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join20.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join21.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join23.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join26.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join28.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join32.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join33.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join34.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join35.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join38.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join39.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join4.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join40.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join5.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join6.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join7.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join8.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join9.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/join_map_ppr.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/lateral_view_ppd.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/load_dyn_part10.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/load_dyn_part13.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/load_dyn_part2.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/load_dyn_part3.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/load_dyn_part4.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/load_dyn_part9.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/louter_join_ppr.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/mapjoin_distinct.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/mapjoin_subquery.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/merge3.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/merge4.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/merge_dynamic_partition.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/merge_dynamic_partition2.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/merge_dynamic_partition3.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/no_hooks.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/noalias_subq1.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/notable_alias1.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/notable_alias2.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/nullgroup.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/nullgroup2.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/nullgroup4.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/nullgroup4_multi_distinct.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/nullgroup5.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/outer_join_ppr.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/pcr.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd1.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_clusterby.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_constant_expr.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_gby.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_gby2.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_gby_join.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_join.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_join2.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_join3.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_multi_insert.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_outer_join1.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_outer_join2.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_outer_join3.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_outer_join4.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_random.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/ppd_transform.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/groupby1.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/groupby2.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/groupby3.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/groupby4.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/join5.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/join4.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/join3.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/join2.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input_testxpath2.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/join1.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input_testxpath.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input_part1.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input9.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input8.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input7.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input6.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input5.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input3.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input4.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input20.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input2.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/input1.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/groupby6.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/groupby5.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/sample5.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/sample4.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/sample3.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/sample2.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/sample1.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/join8.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/join7.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/join6.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/udf4.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/udf6.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/udf_case.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/udf_when.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/union.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/udf1.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/subq.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/sample7.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/compiler/plan/sample6.q.xml 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/bucket_groupby.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/bucket4.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/bucket2.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/bucket3.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join9.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join8.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join7.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join6.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join5.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join4.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join27.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join28.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join29.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join20.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join21.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join23.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join19.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join14.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join16.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join13.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join11.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join12.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_transform.q 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_udf_case.q 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_union.q 1145463 &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/auto_join0.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_outer_join4.q 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_random.q 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_multi_insert.q 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_outer_join1.q 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_outer_join2.q 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_outer_join3.q 1145463 &lt;br/&gt;
  trunk/hbase-handler/src/test/results/hbase_pushdown.q.out 1145463 &lt;br/&gt;
  trunk/hbase-handler/src/test/results/hbase_queries.q.out 1145463 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java 1145463 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/ExprWalkerInfo.java 1145463 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/ExprWalkerProcFactory.java 1145463 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java 1145463 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/OpWalkerInfo.java 1145463 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/PredicatePushDown.java 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd1.q 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_clusterby.q 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_constant_expr.q 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_gby.q 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_gby2.q 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_gby_join.q 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_join.q 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_join2.q 1145463 &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/ppd_join3.q 1145463 &lt;br/&gt;
  trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java 1145463 &lt;br/&gt;
  trunk/contrib/src/test/results/clientpositive/dboutput.q.out 1145463 &lt;br/&gt;
  trunk/contrib/src/test/results/clientpositive/serde_typedbytes4.q.out 1145463 &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;https://reviews.apache.org/r/550/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/550/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;All unit tests passed&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;Amareshwari&lt;/p&gt;
</comment>
                            <comment id="13064384" author="jvs" created="Wed, 13 Jul 2011 06:37:15 +0000"  >&lt;p&gt;Since Yongqiang already reviewed this one, I can commit it assuming there were no new functional changes after his last review.&lt;/p&gt;

&lt;p&gt;One question though; I see a bunch of the new SELECT statements in the unit tests do not have ORDER BY.  Are those all guaranteed to return at most one row?  If not, they need to have an ORDER BY on a complete key to guarantee test determinism.&lt;/p&gt;</comment>
                            <comment id="13064395" author="amareshwari" created="Wed, 13 Jul 2011 07:07:44 +0000"  >&lt;p&gt;John, I modified the existing ppd_* tests to run with new configuration on and off. I copied the queries as they are and did not modify the the statements at all. If you are keen adding order by to the queries, Will do. I&apos;d like to do in a follow up and not stop this patch. &lt;/p&gt;</comment>
                            <comment id="13064396" author="jvs" created="Wed, 13 Jul 2011 07:10:44 +0000"  >&lt;p&gt;Oh, OK, if you copied the existing queries, they are probably OK without ORDER BY since they haven&apos;t been causing trouble.  +1, will commit when tests pass.&lt;/p&gt;</comment>
                            <comment id="13064693" author="jvs" created="Wed, 13 Jul 2011 16:50:31 +0000"  >&lt;p&gt;Committed.  Thanks Amareshwari!&lt;/p&gt;</comment>
                            <comment id="13064933" author="hudson" created="Wed, 13 Jul 2011 23:01:30 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #825 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/825/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/825/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1538&quot; title=&quot;FilterOperator is applied twice with ppd on.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1538&quot;&gt;&lt;del&gt;HIVE-1538&lt;/del&gt;&lt;/a&gt;. FilterOperator is applied twice with ppd on.&lt;br/&gt;
(Amareshwari Sriramadasu via jvs)&lt;/p&gt;

&lt;p&gt;jvs : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1146129&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1146129&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/smb_mapjoin_6.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucket3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample6.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/nullgroup4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join9.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/router_join_ppr.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/load_dyn_part13.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/having.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/index_bitmap_auto_partitioned.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join13.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_join2.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join26.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_gby2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/merge_dynamic_partition2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input9.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/split_sample.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/transform_ppr1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/notable_alias1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input11_limit.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/udf_10_trims.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_outer_join4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby_map_ppr_multi_distinct.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/udf_second.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/ExprWalkerInfo.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/index_auto_unused.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/udf_size.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join12.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_transform.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/lateral_view_ppd.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join6.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input26.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/load_dyn_part10.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/cast1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_gby.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input2_limit.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/filter_join_breaktask.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join40.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/case_sensitivity.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join23.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input6.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/pcr.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/subq2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/results/hbase_queries.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join0.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_outer_join1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join_map_ppr.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/merge3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_join2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input_part7.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join8.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/test/results/hbase_pushdown.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/index_auto_multiple.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/load_dyn_part4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join21.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join34.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join29.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/case_sensitivity.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input23.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample8.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_transform.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join20.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/rand_partitionpruner3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join28.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby_map_ppr.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join7.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/implicit_cast1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join5.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testxpath.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_gby2.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input9.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/load_dyn_part9.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join14.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join39.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join0.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucket2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby_ppr.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample5.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union20.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join8.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/nullgroup.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_outer_join4.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join12.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/query_result_fileformat.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_union.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/disable_merge_for_bucketing.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/stats2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_udf_case.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input31.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input_part1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_outer_join3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input14.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input39.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input_part9.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join23.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join11.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/smb_mapjoin9.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/stats11.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf_case.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union_ppr.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join19.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input42.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/regex_col.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/semijoin.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join5.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input25.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/louter_join_ppr.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/noalias_subq1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/outer_join_ppr.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_outer_join3.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/udf_parse_url.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testxpath2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/quote1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/contrib/src/test/results/clientpositive/dboutput.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input11.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/index_auto.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input_part6.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join7.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/load_dyn_part3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_clusterby.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/index_bitmap3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join20.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/udf_lower.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/ExprWalkerProcFactory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join33.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join28.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join16.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_part1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/mapjoin_distinct.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucket4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/rcfile_null_value.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample7.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input_testxpath2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/union22.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/nullgroup5.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/udf_like.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_outer_join2.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/udf_isnull_isnotnull.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join14.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/merge_dynamic_partition3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/subq.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/transform_ppr2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/notable_alias2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join6.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_clusterby.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_join.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_multi_insert.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/cast1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input_testsequencefile.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_udf_case.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input8.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/index_auto_partitioned.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_multi_insert.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/contrib/src/test/results/clientpositive/serde_typedbytes4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join13.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join38.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/OpWalkerInfo.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_constant_expr.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/nullgroup2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf_when.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join7.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/PredicatePushDown.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_outer_join1.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join11.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join19.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input20.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_gby.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join3.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/merge_dynamic_partition.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/no_hooks.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/skewjoin.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_outer_join2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/union.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/groupby_ppr_multi_distinct.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/merge4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_join3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_random.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join9.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucket_groupby.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_union.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input5.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_gby_join.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/cluster.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/subq.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/regexp_extract.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join35.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_random.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/reduce_deduplicate.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/nullgroup4_multi_distinct.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/create_view.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_gby_join.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/bucketmapjoin3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/index_auto_file_format.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/udf1.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input24.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/udf_minute.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample9.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input_testxpath4.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/index_bitmap_auto.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/mapjoin_subquery.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/udf9.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_constant_expr.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_join.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join21.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_join3.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/udf_hour.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join16.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/sample2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/groupby1.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/udf4.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/join8.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppr_pushdown3.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input_part5.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join6.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/input18.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/load_dyn_part2.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/compiler/plan/input2.q.xml&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/set_processor_namespaces.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/sample10.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/join32.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/udf_notequal.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/auto_join27.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/combine2.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13083847" author="hudson" created="Fri, 12 Aug 2011 00:42:56 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #889 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/889/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/889/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1538&quot; title=&quot;FilterOperator is applied twice with ppd on.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1538&quot;&gt;&lt;del&gt;HIVE-1538&lt;/del&gt;&lt;/a&gt;. filter is removed due to regression of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1538&quot; title=&quot;FilterOperator is applied twice with ppd on.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1538&quot;&gt;&lt;del&gt;HIVE-1538&lt;/del&gt;&lt;/a&gt;&lt;br/&gt;
(Amareshwari Sriramadasu via jvs)&lt;/p&gt;

&lt;p&gt;jvs : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1156787&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1156787&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/ExprWalkerProcFactory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd_udf_col.q.out&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd_udf_col.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13212987" author="hudson" created="Tue, 21 Feb 2012 21:42:02 +0000"  >&lt;p&gt;Integrated in Hive-trunk-h0.21 #1268 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/1268/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/1268/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2791&quot; title=&quot;filter is still removed due to regression of HIVE-1538 althougth HIVE-2344&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2791&quot;&gt;&lt;del&gt;HIVE-2791&lt;/del&gt;&lt;/a&gt;: filter is still removed due to regression of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1538&quot; title=&quot;FilterOperator is applied twice with ppd on.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1538&quot;&gt;&lt;del&gt;HIVE-1538&lt;/del&gt;&lt;/a&gt; althougth &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2344&quot; title=&quot;filter is removed due to regression of HIVE-1538&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2344&quot;&gt;&lt;del&gt;HIVE-2344&lt;/del&gt;&lt;/a&gt; (binlijin via hashutosh) (Revision 1291916)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1291916&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1291916&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd2.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd2.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13547940" author="hudson" created="Wed, 9 Jan 2013 10:23:40 +0000"  >&lt;p&gt;Integrated in Hive-trunk-hadoop2 #54 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/54/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2791&quot; title=&quot;filter is still removed due to regression of HIVE-1538 althougth HIVE-2344&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2791&quot;&gt;&lt;del&gt;HIVE-2791&lt;/del&gt;&lt;/a&gt;: filter is still removed due to regression of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1538&quot; title=&quot;FilterOperator is applied twice with ppd on.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1538&quot;&gt;&lt;del&gt;HIVE-1538&lt;/del&gt;&lt;/a&gt; althougth &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-2344&quot; title=&quot;filter is removed due to regression of HIVE-1538&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-2344&quot;&gt;&lt;del&gt;HIVE-2344&lt;/del&gt;&lt;/a&gt; (binlijin via hashutosh) (Revision 1291916)&lt;/p&gt;

&lt;p&gt;     Result = ABORTED&lt;br/&gt;
hashutosh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1291916&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1291916&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/queries/clientpositive/ppd2.q&lt;/li&gt;
	&lt;li&gt;/hive/trunk/ql/src/test/results/clientpositive/ppd2.q.out&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14568180" author="lefty@hortonworks.com" created="Mon, 1 Jun 2015 22:50:47 +0000"  >&lt;p&gt;Doc note:  This added &lt;b&gt;hive.ppd.remove.duplicatefilters&lt;/b&gt; to HiveConf.java.  It needs to be documented in the wiki.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Configuration Properties &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;It also needs an appropriate description, as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apivovarov&quot; class=&quot;user-hover&quot; rel=&quot;apivovarov&quot;&gt;Alexander Pivovarov&lt;/a&gt; pointed out in a message to the dev@hive mailing list:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;http://mail-archives.apache.org/mod_mbox/hive-dev/201506.mbox/%3cCAKKt98Q-cOrDBeQD+9Bbsy1+t9b60SzwA7XFgsYQPSp1MRScqA@mail.gmail.com%3e&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;&quot;hive.ppd.remove.duplicatefilters description is incorrect. What is the correct one?&quot; &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15116394" author="sladymon" created="Tue, 26 Jan 2016 00:46:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt;, can you confirm what description should be used for &lt;b&gt;hive.ppd.remove.duplicatefilters&lt;/b&gt; in the wiki? In HiveConf.java, the description is: &quot;Whether to push predicates down into storage handlers.  Ignored when hive.optimize.ppd is false&quot; which seems to be an incorrect description for this property.&lt;/p&gt;

&lt;p&gt;Would something like &quot;When hive.optimize.ppd is true, removes duplicate filters from the query plan.  Set this to false if it filters too aggressively.&quot; be more accurate?&lt;/p&gt;</comment>
                            <comment id="15118669" author="ashutoshc" created="Wed, 27 Jan 2016 05:11:49 +0000"  >&lt;p&gt;More like: &quot;During query optimization filters may be pushed down in operator tree. If this config is false, original filter is also left in operator tree at original place. If config is true, only pushed down filters remain in operator tree, original filter is removed. This optimization is always valid and useful, thus there is no reason to set this config to false, other than implementation bug, which may remove filter from both places.&quot;&lt;/p&gt;</comment>
                            <comment id="15120551" author="sladymon" created="Thu, 28 Jan 2016 01:05:00 +0000"  >&lt;p&gt;Thanks for the new description, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt;.  Also, thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apivovarov&quot; class=&quot;user-hover&quot; rel=&quot;apivovarov&quot;&gt;Alexander Pivovarov&lt;/a&gt; for pointing out the mismatched description.&lt;/p&gt;

&lt;p&gt;Doc done: The property &lt;b&gt;hive.ppd.remove.duplicatefilters&lt;/b&gt; is now documented in the wiki with a short version of the updated description:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.ppd.remove.duplicatefilters&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Configuration Properties - hive.ppd.remove.duplicatefilters &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&apos;ll also create a new JIRA and patch to update the HiveConf.java file with an updated description.&lt;/p&gt;</comment>
                            <comment id="15120659" author="sladymon" created="Thu, 28 Jan 2016 03:01:02 +0000"  >&lt;p&gt;New JIRA for updating the description created:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-12953&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HIVE-12953 &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12478296">HIVE-1752</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12934661">HIVE-12953</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12517852">HIVE-2344</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12541746">HIVE-2791</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12625501">HIVE-3847</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12474155" name="patch-1538-1.txt" size="2342711" author="amareshwari" created="Mon, 21 Mar 2011 06:08:07 +0000"/>
                            <attachment id="12474293" name="patch-1538-2.txt" size="2533702" author="amareshwari" created="Tue, 22 Mar 2011 13:43:37 +0000"/>
                            <attachment id="12475489" name="patch-1538-3.txt" size="3051306" author="amareshwari" created="Tue, 5 Apr 2011 15:02:35 +0000"/>
                            <attachment id="12486264" name="patch-1538-4.txt" size="2939664" author="amareshwari" created="Wed, 13 Jul 2011 04:15:50 +0000"/>
                            <attachment id="12460333" name="patch-1538.txt" size="2335375" author="amareshwari" created="Wed, 24 Nov 2010 04:58:35 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 7 Sep 2010 04:18:54 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>65234</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 51 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfl3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123175</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1539] Concurrent metastore threading problem </title>
                <link>https://issues.apache.org/jira/browse/HIVE-1539</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;When running hive as a service and running a high number of queries concurrently I end up with multiple threads running at 100% cpu without any progress.&lt;/p&gt;

&lt;p&gt;Looking at these threads I notice this thread(484e):&lt;br/&gt;
at org.apache.hadoop.hive.metastore.ObjectStore.getMTable(ObjectStore.java:598)&lt;/p&gt;

&lt;p&gt;But on a different thread(63a2):&lt;br/&gt;
at org.apache.hadoop.hive.metastore.model.MStorageDescriptor.jdoReplaceField(MStorageDescriptor.java)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471563">HIVE-1539</key>
            <summary>Concurrent metastore threading problem </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="bennies">Bennie Schut</assignee>
                                    <reporter username="bennies">Bennie Schut</reporter>
                        <labels>
                    </labels>
                <created>Fri, 13 Aug 2010 15:36:00 +0000</created>
                <updated>Wed, 28 Sep 2016 18:58:10 +0000</updated>
                            <resolved>Thu, 5 Jun 2014 07:55:11 +0000</resolved>
                                    <version>0.7.0</version>
                                                    <component>Metastore</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>10</watches>
                                                                <comments>
                            <comment id="12898279" author="bennies" created="Fri, 13 Aug 2010 15:38:26 +0000"  >&lt;p&gt;Thread dump.&lt;/p&gt;</comment>
                            <comment id="12898808" author="bennies" created="Mon, 16 Aug 2010 07:01:40 +0000"  >&lt;p&gt;This is starting to look more and more like a similar problem we have on the jdbc driver (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1428&quot; title=&quot;ALTER TABLE ADD PARTITION fails with a remote Thrift metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1428&quot;&gt;&lt;del&gt;HIVE-1428&lt;/del&gt;&lt;/a&gt;). the HiveMetatStoreClient is doing calls on the thrift client but the thrift client isn&apos;t threadsafe (probably by design). So when the HiveMetaStoreClient is used it should be synchronized or a new HiveMetaStoreClient object should be created for each thread.&lt;/p&gt;

&lt;p&gt;From the &quot;Hive&quot; class:&lt;/p&gt;

&lt;p&gt;  private IMetaStoreClient getMSC() throws MetaException {&lt;br/&gt;
    if (metaStoreClient == null) &lt;/p&gt;
{
      metaStoreClient = createMetaStoreClient();
    }
&lt;p&gt;    return metaStoreClient;&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;I could make the sync factory we use on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1428&quot; title=&quot;ALTER TABLE ADD PARTITION fails with a remote Thrift metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1428&quot;&gt;&lt;del&gt;HIVE-1428&lt;/del&gt;&lt;/a&gt; a common thing and reuse it here. Any objections?&lt;/p&gt;</comment>
                            <comment id="12898810" author="bennies" created="Mon, 16 Aug 2010 07:07:57 +0000"  >&lt;p&gt;That would be &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1482&quot; title=&quot;Not all jdbc calls are threadsafe.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1482&quot;&gt;HIVE-1482&lt;/a&gt; not 28 &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12899157" author="pauly" created="Mon, 16 Aug 2010 22:46:16 +0000"  >&lt;p&gt;From looking at the Hive class, we are creating a ThreadLocal instance of Hive when we call get(). Since the HiveMetaStoreClient is a member of Hive, shouldn&apos;t the client be accessed by only 1 thread at a time?&lt;/p&gt;</comment>
                            <comment id="12901356" author="bennies" created="Mon, 23 Aug 2010 11:36:24 +0000"  >&lt;p&gt;thanks Paul, I didn&apos;t notice that yet so in theory it shouldn&apos;t be the cause. However after synchronizing the metastore client I never saw this problem again where I used to see this problem every day.&lt;br/&gt;
Strange issue. I&apos;ll see if I can create something reproducible but that might be tricky for this type of problem.&lt;/p&gt;</comment>
                            <comment id="12904093" author="bennies" created="Mon, 30 Aug 2010 07:09:49 +0000"  >&lt;p&gt;Ok, I just had another few instances of hanging threads. Last time I used a SynchronizedFactory to eliminate any threading issues in the metastore client but that doesn&apos;t solve it like Paul correctly saw.&lt;/p&gt;

&lt;p&gt;&quot;pool-1-thread-224&quot; prio=10 tid=0x00007f717d62c800 nid=0x7b4d runnable &lt;span class=&quot;error&quot;&gt;&amp;#91;0x000000004557c000&amp;#93;&lt;/span&gt;&lt;br/&gt;
   java.lang.Thread.State: RUNNABLE&lt;br/&gt;
        at java.util.HashMap.get(HashMap.java:303)&lt;br/&gt;
        at org.datanucleus.util.ReferenceValueMap.get(ReferenceValueMap.java:186)&lt;br/&gt;
        at org.datanucleus.JDOClassLoaderResolver.classForName(JDOClassLoaderResolver.java:185)&lt;br/&gt;
        at org.datanucleus.JDOClassLoaderResolver.classForName(JDOClassLoaderResolver.java:415)&lt;br/&gt;
        at org.datanucleus.store.mapped.MappedTypeManager.isSupportedMappedType(MappedTypeManager.java:84)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.AbstractIteratorStatement.&amp;lt;init&amp;gt;(AbstractIteratorStatement.java:83)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.UnionIteratorStatement.&amp;lt;init&amp;gt;(UnionIteratorStatement.java:147)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.ClassTableExtent.newQueryStatement(ClassTableExtent.java:204)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.QueryCompiler.executionCompile(QueryCompiler.java:323)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQueryCompiler.compile(JDOQLQueryCompiler.java:225)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQuery.compileInternal(JDOQLQuery.java:175)&lt;br/&gt;
        at org.datanucleus.store.query.Query.executeQuery(Query.java:1628)&lt;br/&gt;
        at org.datanucleus.store.rdbms.query.legacy.JDOQLQuery.executeQuery(JDOQLQuery.java:245)&lt;br/&gt;
        at org.datanucleus.store.query.Query.executeWithArray(Query.java:1499)&lt;br/&gt;
        at org.datanucleus.jdo.JDOQuery.execute(JDOQuery.java:243)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.ObjectStore.getMDatabase(ObjectStore.java:323)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.ObjectStore.convertToMTable(ObjectStore.java:640)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.ObjectStore.alterTable(ObjectStore.java:946)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.HiveAlterHandler.alterTable(HiveAlterHandler.java:177)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$23.run(HiveMetaStore.java:1329)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler$23.run(HiveMetaStore.java:1326)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.executeWithRetry(HiveMetaStore.java:229)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.alter_table(HiveMetaStore.java:1326)&lt;br/&gt;
        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.alter_table(HiveMetaStoreClient.java:143)&lt;br/&gt;
        at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.hive.common.SynchronizedFactory$Handler.invoke(SynchronizedFactory.java:46)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;locked &amp;lt;0x00000007ffc6fd00&amp;gt; (a org.apache.hadoop.hive.metastore.HiveMetaStoreClient)&lt;br/&gt;
        at $Proxy8.alter_table(Unknown Source)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.metadata.Hive.alterTable(Hive.java:267)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.metadata.Hive.loadTable(Hive.java:875)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.MoveTask.execute(MoveTask.java:174)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:108)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:55)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:609)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:478)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:356)&lt;br/&gt;
        at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:114)&lt;br/&gt;
        at org.apache.hadoop.hive.service.ThriftHive$Processor$execute.process(ThriftHive.java:378)&lt;br/&gt;
        at org.apache.hadoop.hive.service.ThriftHive$Processor.process(ThriftHive.java:366)&lt;br/&gt;
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:252)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:619)&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12905455" author="bennies" created="Thu, 2 Sep 2010 08:58:37 +0000"  >&lt;p&gt;JDOClassLoaderResolver doesn&apos;t seem thread safe. That&apos;s a bit of a surprise. I filed a bug with datanucleus: &lt;br/&gt;
&lt;a href=&quot;http://www.datanucleus.org/servlet/jira/browse/NUCCORE-559&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.datanucleus.org/servlet/jira/browse/NUCCORE-559&lt;/a&gt;&lt;br/&gt;
I just made my own threadsafe version of the JDOClassLoaderResolver and am loading it to see if that fixes it. Will probably take a few days to be sure it got fixed.&lt;/p&gt;</comment>
                            <comment id="12905463" author="bennies" created="Thu, 2 Sep 2010 09:35:57 +0000"  >&lt;p&gt;Ok still testing it but this is a temporary fix we add our own sync. version of the classloader:&lt;/p&gt;

&lt;p&gt;Just make sure you add these properties and it should work:&lt;br/&gt;
&amp;lt;property&amp;gt;&lt;br/&gt;
  &amp;lt;name&amp;gt;datanucleus.classLoaderResolverName&amp;lt;/name&amp;gt;&lt;br/&gt;
  &amp;lt;value&amp;gt;syncloader&amp;lt;/value&amp;gt;&lt;br/&gt;
&amp;lt;/property&amp;gt;&lt;/p&gt;
</comment>
                            <comment id="12908472" author="bennies" created="Sun, 12 Sep 2010 14:12:15 +0000"  >&lt;p&gt;Patch got comitted on datanucleus 2.2.0.m2&lt;br/&gt;
We could consider moving from 2.0 to 2.2&lt;br/&gt;
The temporary fix of loading your own classloader also wroked nicely.&lt;/p&gt;</comment>
                            <comment id="12930974" author="bennies" created="Thu, 11 Nov 2010 10:21:14 +0000"  >&lt;p&gt;2.2.0-m2 can now be found on maven so the previous patch can be discarded and you can simple update the ivy/libraries/properties file to use datanucleus 2.2.0-m2.&lt;/p&gt;

&lt;p&gt;since -m2 is a milestone release I&apos;m not sure if we would want to include this or wait for 2.2.0 release.&lt;/p&gt;</comment>
                            <comment id="12965515" author="jvs" created="Wed, 1 Dec 2010 01:01:43 +0000"  >&lt;p&gt;According to the datanucleus website, 2.2.0 is scheduled for 10-Dec, so let&apos;s wait for it.&lt;/p&gt;</comment>
                            <comment id="12978521" author="bennies" created="Thu, 6 Jan 2011 21:50:01 +0000"  >&lt;p&gt;patch to go from datanucleus 2.0 to 2.2.0-release. I had to make a small change to the Utilities class since some package names changed. I also had to add some extra excludes on the metastore/ivy.xml&lt;/p&gt;</comment>
                            <comment id="12978538" author="ashutoshc" created="Thu, 6 Jan 2011 22:17:02 +0000"  >&lt;p&gt;@Bennie,&lt;/p&gt;

&lt;p&gt;Since this bug was filed, we upgraded from 2.0.3 to 2.1.1 (in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1609&quot; title=&quot;Support partition filtering in metastore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1609&quot;&gt;&lt;del&gt;HIVE-1609&lt;/del&gt;&lt;/a&gt;) Some bugs then showed up which were attributed to that jdo lib upgrade (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1853&quot; title=&quot;downgrade JDO version&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1853&quot;&gt;&lt;del&gt;HIVE-1853&lt;/del&gt;&lt;/a&gt;) so it was rolled back to 2.0.3 Investigation is still on for them in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1862&quot; title=&quot;Revive partition filtering in the Hive MetaStore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1862&quot;&gt;&lt;del&gt;HIVE-1862&lt;/del&gt;&lt;/a&gt; So, before committing to still higher version of jdo 2.2.0 we need to make sure it doesn&apos;t result in test case failure listed in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1862&quot; title=&quot;Revive partition filtering in the Hive MetaStore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1862&quot;&gt;&lt;del&gt;HIVE-1862&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="12978665" author="bennies" created="Fri, 7 Jan 2011 07:45:39 +0000"  >&lt;p&gt;Thanks Ashutosh, I was waiting for the test result and as you predicted just got a build failed. &lt;/p&gt;</comment>
                            <comment id="12978698" author="bennies" created="Fri, 7 Jan 2011 09:10:58 +0000"  >&lt;p&gt;Are we getting errors like these on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1862&quot; title=&quot;Revive partition filtering in the Hive MetaStore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1862&quot;&gt;&lt;del&gt;HIVE-1862&lt;/del&gt;&lt;/a&gt; ? :&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Exception: java.lang.RuntimeException: The table default_&lt;em&gt;show_idx_full_idx_comment&lt;/em&gt;_ is an index table. Please do drop index instead.&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: The table default_&lt;em&gt;show_idx_full_idx_comment&lt;/em&gt;_ is an index table. Please do drop index instead.&lt;/p&gt;

&lt;p&gt;Or is this something else?&lt;/p&gt;</comment>
                            <comment id="15530543" author="sharathmk99" created="Wed, 28 Sep 2016 18:58:10 +0000"  >&lt;p&gt;I&apos;m facing the same problem. &lt;br/&gt;
I&apos;m not able to run concurrent query using JDBC java program.&lt;br/&gt;
If any one solved, please direct me to some example java program.&lt;br/&gt;
Thanks&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12493928">HIVE-1862</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12494920">HIVE-1899</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12493399">HIVE-1853</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12472999">HIVE-1609</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12453671" name="ClassLoaderResolver.patch" size="26623" author="bennies" created="Thu, 2 Sep 2010 09:35:57 +0000"/>
                            <attachment id="12467673" name="HIVE-1539-1.patch" size="2952" author="bennies" created="Thu, 6 Jan 2011 21:50:01 +0000"/>
                            <attachment id="12459337" name="HIVE-1539.patch" size="563" author="bennies" created="Thu, 11 Nov 2010 10:21:14 +0000"/>
                            <attachment id="12452031" name="thread_dump_hanging.txt" size="30986" author="bennies" created="Fri, 13 Aug 2010 15:38:26 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 16 Aug 2010 22:46:16 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42457</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 16 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lflb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123176</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>We switched to a datanucleus version &amp;gt;= 2.2 a long time ago so this is fixed.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1540] Read-only, columnar data file for nested data structures</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1540</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;RCFile is a great start on an optimized layout for working with structured data with Hive. Given that Hive&apos;s data model supports nested lists and maps, and taking inspiration from the recent work by Google on Dremel, it may be useful for the Hive community to think about how to improve the RCFile format for nested data structures.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471626">HIVE-1540</key>
            <summary>Read-only, columnar data file for nested data structures</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="hammer">Jeff Hammerbacher</reporter>
                        <labels>
                    </labels>
                <created>Sat, 14 Aug 2010 23:45:32 +0000</created>
                <updated>Tue, 17 Aug 2010 02:48:57 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>16</watches>
                                                                <comments>
                            <comment id="12899199" author="jsensarma" created="Tue, 17 Aug 2010 00:14:15 +0000"  >&lt;p&gt;are there a lot of use cases for nested data structures? Google&apos;s approach is motivated by widespread use of Protocol Buffers. At Facebook - thrift serialized data sets (that motivated the initial support for nested data types) hasn&apos;t taken off.&lt;/p&gt;

&lt;p&gt;I think what&apos;s much more common is json serialized data (or map types more restrictively). it would be much more worthwhile, to begin with, to have optimized codecs and deserializers for map types.&lt;/p&gt;</comment>
                            <comment id="12899255" author="hammer" created="Tue, 17 Aug 2010 02:48:57 +0000"  >&lt;p&gt;We&apos;ve got an increasing number of customers using Avro&apos;s serialization format for working with data in Hadoop, and that&apos;s where our nested data structures come from. Any design which could incorporate a serialization framework like Avro would be of interest to me.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 17 Aug 2010 00:14:15 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42456</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 24 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lflj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123177</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-1541] More general dataflow execution backend</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1541</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;With the recent open source release of Mesos (&lt;a href=&quot;http://github.com/mesos/mesos&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://github.com/mesos/mesos&lt;/a&gt;), experimentation at the query execution layer has become more feasible. Inspired by more general-purpose dataflow systems like Volcano, Dryad, and Dremel, it would be interesting to explore a more general-purpose dataflow execution system for Hive queries. One potential backend is the Hyracks project from UCI: &lt;a href=&quot;http://code.google.com/p/hyracks&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://code.google.com/p/hyracks&lt;/a&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471627">HIVE-1541</key>
            <summary>More general dataflow execution backend</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="hammer">Jeff Hammerbacher</reporter>
                        <labels>
                    </labels>
                <created>Sat, 14 Aug 2010 23:48:37 +0000</created>
                <updated>Tue, 17 Aug 2010 05:45:24 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>20</watches>
                                                                <comments>
                            <comment id="12898654" author="hammer" created="Sat, 14 Aug 2010 23:49:22 +0000"  >&lt;p&gt;In particular, it would be nice to avoid the startup overhead of Hadoop MapReduce with this backend.&lt;/p&gt;</comment>
                            <comment id="12898812" author="svenkat" created="Mon, 16 Aug 2010 07:15:14 +0000"  >&lt;p&gt;Oozie should be a good candidate as well.&lt;/p&gt;</comment>
                            <comment id="12899290" author="hammer" created="Tue, 17 Aug 2010 05:45:24 +0000"  >&lt;p&gt;Hey Venkatesh,&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1107&quot; title=&quot;Generic parallel execution framework for Hive (and Pig, and ...)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1107&quot;&gt;HIVE-1107&lt;/a&gt; is aimed at getting Hive and Pig to express their sequence of MapReduce jobs as an Oozie workflow. For this JIRA, I meant an entirely different initialization routine and set of physical operators, similar to those used by an MPP relational database or Dremel, Whether Oozie is used to describe the workflow tying together these new physical operators is less of a concern to me.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Jeff&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 16 Aug 2010 07:15:14 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42455</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 24 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lflr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123178</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-1542] DROP TABLE &lt;tablename&gt; should raise an error when &lt;tablename&gt; does not exist</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1542</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;See &lt;a href=&quot;http://dev.mysql.com/doc/refman/5.1/en/drop-table.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://dev.mysql.com/doc/refman/5.1/en/drop-table.html&lt;/a&gt;&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12471722">HIVE-1542</key>
            <summary>DROP TABLE &lt;tablename&gt; should raise an error when &lt;tablename&gt; does not exist</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="cwsteinbach">Carl Steinbach</reporter>
                        <labels>
                    </labels>
                <created>Mon, 16 Aug 2010 17:27:06 +0000</created>
                <updated>Sun, 14 May 2017 20:08:12 +0000</updated>
                                                                            <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="12899039" author="jvs" created="Mon, 16 Aug 2010 19:09:53 +0000"  >&lt;p&gt;There are probably a lot of dependencies on the current (non-standard) behavior, so as part of implementing this, we also need to&lt;/p&gt;

&lt;p&gt;(a) add a configuration option to let the old behavior be re-enabled (but we can set the default to the standard behavior)&lt;/p&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;p&gt;(b) add support for the IF EXISTS clause (i.e. do this together with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1165&quot; title=&quot;Support `DROP TABLE XXX IF EXISTS`&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1165&quot;&gt;&lt;del&gt;HIVE-1165&lt;/del&gt;&lt;/a&gt;)&lt;/p&gt;
</comment>
                            <comment id="12972269" author="jvs" created="Thu, 16 Dec 2010 22:51:20 +0000"  >&lt;p&gt;Hi Marcel &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12972289" author="marcelk" created="Thu, 16 Dec 2010 23:32:15 +0000"  >&lt;p&gt;hey there &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12456202">HIVE-1165</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12471836">HIVE-1551</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12493708">HIVE-1856</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 16 Aug 2010 19:09:53 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42454</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 6 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lflz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123179</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-1543] set abort in ExecMapper when Hive&apos;s record reader got an IOException</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1543</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;When RecordReader got an IOException, ExecMapper does not know and will close the operators as if there is not error. We should catch this exception and avoid writing partial results to HDFS which will be removed later anyways.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471745">HIVE-1543</key>
            <summary>set abort in ExecMapper when Hive&apos;s record reader got an IOException</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nzhang">Ning Zhang</assignee>
                                    <reporter username="nzhang">Ning Zhang</reporter>
                        <labels>
                    </labels>
                <created>Mon, 16 Aug 2010 20:08:28 +0000</created>
                <updated>Sat, 17 Dec 2011 00:03:57 +0000</updated>
                            <resolved>Tue, 17 Aug 2010 05:40:00 +0000</resolved>
                                                    <fixVersion>0.6.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12899093" author="nzhang" created="Mon, 16 Aug 2010 21:12:56 +0000"  >&lt;p&gt;passed all hadoop 0.20 tests.&lt;/p&gt;</comment>
                            <comment id="12899098" author="he yongqiang" created="Mon, 16 Aug 2010 21:23:34 +0000"  >&lt;p&gt;let&apos;s do it in HiveContextAwareRecordReader. And maybe store the var in IOContext?&lt;/p&gt;</comment>
                            <comment id="12899158" author="nzhang" created="Mon, 16 Aug 2010 22:46:41 +0000"  >&lt;p&gt;@yongqiang, HiveContextAwareRecordReader is only available in 0.7 (trunk) but not 0.6. I think this should be back ported to 0.6 as well (as we did for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1492&quot; title=&quot;FileSinkOperator should remove duplicated files from the same task based on file sizes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1492&quot;&gt;&lt;del&gt;HIVE-1492&lt;/del&gt;&lt;/a&gt;)?&lt;/p&gt;</comment>
                            <comment id="12899165" author="namit" created="Mon, 16 Aug 2010 23:02:46 +0000"  >&lt;p&gt;What about BucketizedHiveRecordReader ?&lt;/p&gt;</comment>
                            <comment id="12899169" author="he yongqiang" created="Mon, 16 Aug 2010 23:04:47 +0000"  >&lt;p&gt;we can do two different patches for trunk and 0.6.&lt;/p&gt;

&lt;p&gt;I think BucketizedHiveRecordReader also extends HiveContextAwareRecordReader.&lt;/p&gt;</comment>
                            <comment id="12899203" author="nzhang" created="Tue, 17 Aug 2010 00:15:37 +0000"  >&lt;p&gt;Uploading 2 patches for trunk and 0.6 respectively. &lt;/p&gt;</comment>
                            <comment id="12899207" author="namit" created="Tue, 17 Aug 2010 00:28:54 +0000"  >&lt;p&gt;can you reload the patch for 0.6 - i got some merge conflicts&lt;/p&gt;</comment>
                            <comment id="12899209" author="namit" created="Tue, 17 Aug 2010 00:37:10 +0000"  >&lt;p&gt;+1 for trunk&lt;/p&gt;</comment>
                            <comment id="12899222" author="nzhang" created="Tue, 17 Aug 2010 01:02:00 +0000"  >&lt;p&gt;Uploading a new patch for branch 0.6.&lt;/p&gt;</comment>
                            <comment id="12899225" author="namit" created="Tue, 17 Aug 2010 01:05:53 +0000"  >&lt;p&gt;+1 for 0.6 also&lt;/p&gt;

&lt;p&gt;Will commit in both once the tests pass&lt;/p&gt;</comment>
                            <comment id="12899288" author="namit" created="Tue, 17 Aug 2010 05:40:00 +0000"  >&lt;p&gt;Committed. Thanks Ning&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12452233" name="HIVE-1543.1.patch" size="5220" author="nzhang" created="Tue, 17 Aug 2010 00:15:37 +0000"/>
                            <attachment id="12452240" name="HIVE-1543.2_branch0.6.patch" size="3961" author="nzhang" created="Tue, 17 Aug 2010 01:02:00 +0000"/>
                            <attachment id="12452213" name="HIVE-1543.patch" size="3470" author="nzhang" created="Mon, 16 Aug 2010 21:12:56 +0000"/>
                            <attachment id="12452234" name="HIVE-1543_branch0.6.patch" size="5107" author="nzhang" created="Tue, 17 Aug 2010 00:15:37 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 16 Aug 2010 21:23:34 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72847</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 24 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfm7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123180</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1544] Filtering out NULL-keyed rows in ReduceSinkOperator when no outer join involved</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1544</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;As discussed in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-741&quot; title=&quot;NULL is not handled correctly in join&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-741&quot;&gt;&lt;del&gt;HIVE-741&lt;/del&gt;&lt;/a&gt;, if a plan indicates that a non-outer join is the first operator in the reducer, the ReduceSinkOperator should filter out (not sending) rows with NULL as keys since they will not generate any results anyways. This should save both bandwidth and processing power. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12471750">HIVE-1544</key>
            <summary>Filtering out NULL-keyed rows in ReduceSinkOperator when no outer join involved</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="nzhang">Ning Zhang</reporter>
                        <labels>
                    </labels>
                <created>Mon, 16 Aug 2010 21:19:19 +0000</created>
                <updated>Wed, 18 Aug 2010 09:43:03 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12899096" author="nzhang" created="Mon, 16 Aug 2010 21:21:23 +0000"  >&lt;p&gt;The JoinDesc already has a flag noOuterJoin to keep track if there are outer joins involved in the join operator. Based on that we should set a flag in the ReduceSinkDesc to indicate whether NULL-keyed rows will be filtered out.&lt;/p&gt;</comment>
                            <comment id="12899805" author="amareshwari" created="Wed, 18 Aug 2010 09:43:03 +0000"  >&lt;p&gt;Also,see Namit&apos;s &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-741?focusedCommentId=12899177&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12899177&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;comment&lt;/a&gt; on &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-741&quot; title=&quot;NULL is not handled correctly in join&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-741&quot;&gt;&lt;del&gt;HIVE-741&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12432589">HIVE-741</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 18 Aug 2010 09:43:03 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42453</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 23 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i08ncn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>48382</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-1545] Add a bunch of UDFs and UDAFs</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1545</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Here some UD(A)Fs which can be incorporated into the Hive distribution:&lt;/p&gt;

&lt;p&gt;UDFArgMax - Find the 0-indexed index of the largest argument. e.g., ARGMAX(4, 5, 3) returns 1.&lt;br/&gt;
UDFBucket - Find the bucket in which the first argument belongs. e.g., BUCKET(x, b_1, b_2, b_3, ...), will return the smallest i such that x &amp;gt; b_&lt;/p&gt;
{i}
&lt;p&gt; but &amp;lt;= b_&lt;/p&gt;
{i+1}
&lt;p&gt;. Returns 0 if x is smaller than all the buckets.&lt;br/&gt;
UDFFindInArray - Finds the 1-index of the first element in the array given as the second argument. Returns 0 if not found. Returns NULL if either argument is NULL. E.g., FIND_IN_ARRAY(5, array(1,2,5)) will return 3. FIND_IN_ARRAY(5, array(1,2,3)) will return 0.&lt;br/&gt;
UDFGreatCircleDist - Finds the great circle distance (in km) between two lat/long coordinates (in degrees).&lt;br/&gt;
UDFLDA - Performs LDA inference on a vector given fixed topics.&lt;br/&gt;
UDFNumberRows - Number successive rows starting from 1. Counter resets to 1 whenever any of its parameters changes.&lt;br/&gt;
UDFPmax - Finds the maximum of a set of columns. e.g., PMAX(4, 5, 3) returns 5.&lt;br/&gt;
UDFRegexpExtractAll - Like REGEXP_EXTRACT except that it returns all matches in an array.&lt;br/&gt;
UDFUnescape - Returns the string unescaped (using C/Java style unescaping).&lt;br/&gt;
UDFWhich - Given a boolean array, return the indices which are TRUE.&lt;br/&gt;
UDFJaccard&lt;/p&gt;

&lt;p&gt;UDAFCollect - Takes all the values associated with a row and converts it into a list. Make sure to have: set hive.map.aggr = false;&lt;br/&gt;
UDAFCollectMap - Like collect except that it takes tuples and generates a map.&lt;br/&gt;
UDAFEntropy - Compute the entropy of a column.&lt;br/&gt;
UDAFPearson (BROKEN!!!) - Computes the pearson correlation between two columns.&lt;br/&gt;
UDAFTop - TOP(KEY, VAL) - returns the KEY associated with the largest value of VAL.&lt;br/&gt;
UDAFTopN (BROKEN!!!) - Like TOP except returns a list of the keys associated with the N (passed as the third parameter) largest values of VAL.&lt;br/&gt;
UDAFHistogram&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471758">HIVE-1545</key>
            <summary>Add a bunch of UDFs and UDAFs</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="jonchang">Jonathan Chang</assignee>
                                    <reporter username="jonchang">Jonathan Chang</reporter>
                        <labels>
                    </labels>
                <created>Mon, 16 Aug 2010 22:38:24 +0000</created>
                <updated>Thu, 5 Sep 2013 00:15:06 +0000</updated>
                                                                            <component>UDF</component>
                        <due></due>
                            <votes>3</votes>
                                    <watches>21</watches>
                                                                <comments>
                            <comment id="12899150" author="jonchang" created="Mon, 16 Aug 2010 22:40:31 +0000"  >&lt;p&gt;Here is a tarball of the poorly documented/tested udfs.&lt;/p&gt;</comment>
                            <comment id="12899495" author="hammer" created="Tue, 17 Aug 2010 17:56:35 +0000"  >&lt;p&gt;UDAFPearson looks quite similar to CORR(X, Y) proposed in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1549&quot; title=&quot;Add ANSI SQL correlation aggregate function CORR(X,Y).&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1549&quot;&gt;&lt;del&gt;HIVE-1549&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12917546" author="terjem" created="Mon, 4 Oct 2010 10:16:58 +0000"  >&lt;p&gt;Was just quickly looking at this and noticed that&lt;/p&gt;

&lt;p&gt;grep lib com/facebook/hive/udf/*java&lt;br/&gt;
com/facebook/hive/udf/UDAFHistogram.java:import com.facebook.hive.udf.lib.Counter;&lt;br/&gt;
com/facebook/hive/udf/UDFJaccard.java:import com.facebook.hive.udf.lib.SetOps;&lt;/p&gt;

&lt;p&gt;however, there is no com.facebook.hive.udf.lib included.&lt;/p&gt;


</comment>
                            <comment id="12918094" author="jonchang" created="Tue, 5 Oct 2010 18:06:09 +0000"  >&lt;p&gt;Sorry about that.  I&apos;ve uploaded a new tarball which should contain the lib directory along with some new UDFs.  UDAFPearson has also been removed since it&apos;s been obsoleted by CORR.&lt;/p&gt;</comment>
                            <comment id="13057517" author="jonchang" created="Wed, 29 Jun 2011 22:19:52 +0000"  >&lt;p&gt;Some UDFs for tomorrow&apos;s contributor meeting.  Summary of contents:&lt;/p&gt;


&lt;p&gt;Core:&lt;/p&gt;

&lt;p&gt;Basic functionality - CAST, HEX2DEC, MAP_GET&lt;br/&gt;
Date/time functions - DAY_OF_WEEK, DST_OFFSET&lt;br/&gt;
Multiple row manipulations - EXPLODE_INDEX, EXPLODE_MAP, REPEAT_ROWS&lt;br/&gt;
Extensions of existing aggregations - COUNT_WHERE, SUM_WHERE,&lt;br/&gt;
WEIGHTED_AVG, WEIGHTED_PERCENTILE&lt;br/&gt;
Aggregations for collecting - COLLECT, COLLECT_MAP, COLLECT_WHERE,&lt;br/&gt;
HISTOGRAM, UNION_MAP, UNION_SET&lt;br/&gt;
Basic mathematical operations - ARG_MIN, ARG_MAX, BUCKET, IS_FINITE, PMAX,&lt;br/&gt;
PMIN, PSUM&lt;br/&gt;
Generally useful aggregations - ALL, ANY, CHOOSE_ONE, TOP, TOP_N&lt;br/&gt;
JSON functionality - JSON_AS_ARRAY,  JSON_AS_MAP, MAKE_JSON_ARRAY,&lt;br/&gt;
MAKE_JSON_OBJ&lt;br/&gt;
Generally useful array ops - ARRAY_CONCAT, ARRAY_INTERSECT, ARRAY_JOIN,&lt;br/&gt;
ARRAY_SORT, ARRAY_SUBSET, ARRAY_UNION&lt;/p&gt;

&lt;p&gt;Ext:&lt;/p&gt;


&lt;p&gt;Maintaining state across rows - CUMPROD, CUMSUM, FILL, NUMBER_ROWS, PREV&lt;br/&gt;
Probability (narrowly focused) - CHOOSE, ENTROPY, KMEANS, LDA,&lt;br/&gt;
MAP_ENTROPY, PPOIS, RPOIS, SAMPLE, LINEAR_REGRESSION&lt;br/&gt;
Narrowly focused string ops - MD5, LEVENSHTEIN, LONGEST,&lt;br/&gt;
NORMALIZE_UNICODE, UNESCAPE, URL_QUOTE, GROUP_LONGEST, TITLECASE,&lt;br/&gt;
REGEXP_EXTRACT_ALL&lt;br/&gt;
More esoteric array/map ops - ARRAY_AGGREGATE, ARRAY_COUNT_OVERLAP,&lt;br/&gt;
ARRAY_EXCLUDE, ARRAY_SLICE, FIND_SEQUENCE_IN_ARRAY, MAP_EXCLUDE&lt;/p&gt;</comment>
                            <comment id="13095106" author="cyril.liao" created="Thu, 1 Sep 2011 04:01:58 +0000"  >&lt;p&gt;com.facebook.hive.udf.lib.UDFUtils is not included.&lt;/p&gt;

&lt;p&gt;Would you please upload it?&lt;/p&gt;</comment>
                            <comment id="13095417" author="jonchang" created="Thu, 1 Sep 2011 17:00:48 +0000"  >&lt;p&gt;Sure.  Can you let me know which functions are not included?  I think part of the resolution of this issue will be to port some of the UDFUtils-specific stuff to the UDF development package on github.&lt;/p&gt;</comment>
                            <comment id="13095419" author="jonchang" created="Thu, 1 Sep 2011 17:01:29 +0000"  >&lt;p&gt;Or maybe we should open another issue to track augmenting the other package with the necessary functionality?&lt;/p&gt;</comment>
                            <comment id="13095621" author="jvs" created="Thu, 1 Sep 2011 21:36:10 +0000"  >&lt;p&gt;I&apos;m way behind on the PDK (probably not gonna make it for 0.8), but I&apos;m planning to rework the UDFUtils into annotations as part of it.&lt;/p&gt;

&lt;p&gt;Cyril, I think they are mostly used for validation purposes, in which case you can just comment out the calls for now if you want to use the UDF without validation.&lt;/p&gt;</comment>
                            <comment id="13095738" author="cyril.liao" created="Fri, 2 Sep 2011 03:05:18 +0000"  >&lt;p&gt;Neither in core.tar.gz nor ext.tar.gz,there is a class named com.facebook.hive.udf.lib.UDFUtils,which is used by many UDFs.&lt;br/&gt;
In package com.facebook.hive.udf.lib ,only Counter and SetOps are included.&lt;/p&gt;</comment>
                            <comment id="13439780" author="jonchang" created="Wed, 22 Aug 2012 19:27:46 +0000"  >&lt;p&gt;5 string UDFs with Apache header&lt;/p&gt;</comment>
                            <comment id="13721125" author="jeffywu" created="Fri, 26 Jul 2013 19:38:20 +0000"  >&lt;p&gt;Trying to compile these and load the jar but the package com.facebook.hive.udf.tests isn&apos;t included. Can someone attach that?&lt;/p&gt;</comment>
                            <comment id="13721143" author="jonchang" created="Fri, 26 Jul 2013 19:58:53 +0000"  >&lt;p&gt;I think they should be migrated to use the equivalent facilities in the PDK?&lt;/p&gt;</comment>
                            <comment id="13721144" author="jonchang" created="Fri, 26 Jul 2013 19:59:23 +0000"  >&lt;p&gt;For the time being you can remove those packages (and the corresponding annotations) without affecting the functionality.&lt;/p&gt;</comment>
                            <comment id="13733976" author="brenden" created="Thu, 8 Aug 2013 21:02:16 +0000"  >&lt;p&gt;Where&apos;s the rest of the source?&lt;/p&gt;</comment>
                            <comment id="13734046" author="jonchang" created="Thu, 8 Aug 2013 21:42:03 +0000"  >&lt;p&gt;What are you looking for in particular?&lt;/p&gt;</comment>
                            <comment id="13734088" author="brenden" created="Thu, 8 Aug 2013 22:17:22 +0000"  >&lt;p&gt;There&apos;s a bunch of code missing.  Your code doesn&apos;t build without modifications.&lt;/p&gt;

&lt;p&gt;I&apos;ve made a copy of this which seems to work (minus the broken parts) here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/brndnmtthws/facebook-hive-udfs&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/brndnmtthws/facebook-hive-udfs&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13734306" author="appodictic" created="Fri, 9 Aug 2013 01:16:22 +0000"  >&lt;p&gt;The annotations and other things you are seeing are part of an internal testing framework at FB that was never open sourced, the hive plugin developer kit had similar annotations but they were removed. So the UDFS likely compilefine but the test cases will not.&lt;/p&gt;</comment>
                            <comment id="13734330" author="jonchang" created="Fri, 9 Aug 2013 02:05:38 +0000"  >&lt;p&gt;Awesome. Thanks for setting up that github (so much nicer than JIRA &lt;b&gt;ducks&lt;/b&gt;).  Lemme see if I can upload the bare minimum files to get the annotations compiling.  I have some open tasks internally to rewrite the testing framework &amp;#8212; it should be much easier to integrate into a standard testing flow once we do so.&lt;/p&gt;</comment>
                            <comment id="13734348" author="brenden" created="Fri, 9 Aug 2013 02:39:10 +0000"  >&lt;p&gt;There were a number of things missing.  For example, there are some validation utilities which aren&apos;t present, such as this one:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/brndnmtthws/facebook-hive-udfs/commit/bc6b3cc5ab4c413458f17ec3d981306b2b670946#L7L34&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/brndnmtthws/facebook-hive-udfs/commit/bc6b3cc5ab4c413458f17ec3d981306b2b670946#L7L34&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13735157" author="jonchang" created="Fri, 9 Aug 2013 19:14:51 +0000"  >&lt;p&gt;Ok, lemme work on getting everything uploaded.  Is it better to work off the github or would you prefer I continue to upload tarballs here.&lt;/p&gt;</comment>
                            <comment id="13735161" author="brenden" created="Fri, 9 Aug 2013 19:17:09 +0000"  >&lt;p&gt;Why don&apos;t we get everything into a good state on github first, then we can submit it here.  You can just shoot me a pull request when you want a review.&lt;/p&gt;

&lt;p&gt;Thanks Jonathan!&lt;/p&gt;</comment>
                            <comment id="13735638" author="jonchang" created="Sat, 10 Aug 2013 01:07:18 +0000"  >&lt;p&gt;Done.  Just to put the discussion here as well, I think the first steps will be to get a few simple string related ones in along with the corresponding tests (ignoring the fact that the tests are no-ops for now).  If this goes smoothly we can go subpackage by subpackage adding the necessary infrastructural bits a little bit at a time.&lt;/p&gt;</comment>
                            <comment id="13758552" author="jonchang" created="Thu, 5 Sep 2013 00:15:06 +0000"  >&lt;p&gt;Ok, I&apos;ve put a self-contained, compiling repo here: &lt;a href=&quot;https://github.com/slycoder/hive-udfs&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/slycoder/hive-udfs&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;What are the next steps?&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12471821">HIVE-1549</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12528584">HIVE-2523</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12528591">HIVE-2524</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12542018" name="UDFEndsWith.java" size="1804" author="jonchang" created="Wed, 22 Aug 2012 19:27:46 +0000"/>
                            <attachment id="12542017" name="UDFFindInString.java" size="1958" author="jonchang" created="Wed, 22 Aug 2012 19:27:46 +0000"/>
                            <attachment id="12542022" name="UDFLtrim.java" size="2823" author="jonchang" created="Wed, 22 Aug 2012 19:27:46 +0000"/>
                            <attachment id="12542021" name="UDFRtrim.java" size="2799" author="jonchang" created="Wed, 22 Aug 2012 19:27:46 +0000"/>
                            <attachment id="12542019" name="UDFStartsWith.java" size="1819" author="jonchang" created="Wed, 22 Aug 2012 19:27:46 +0000"/>
                            <attachment id="12542020" name="UDFTrim.java" size="3428" author="jonchang" created="Wed, 22 Aug 2012 19:27:46 +0000"/>
                            <attachment id="12484694" name="core.tar.gz" size="19669" author="jonchang" created="Wed, 29 Jun 2011 22:19:51 +0000"/>
                            <attachment id="12484695" name="ext.tar.gz" size="18970" author="jonchang" created="Wed, 29 Jun 2011 22:19:52 +0000"/>
                            <attachment id="12456413" name="udfs.tar.gz" size="11739" author="jonchang" created="Tue, 5 Oct 2010 18:05:08 +0000"/>
                            <attachment id="12452223" name="udfs.tar.gz" size="6999" author="jonchang" created="Mon, 16 Aug 2010 22:40:31 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>10.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 17 Aug 2010 17:56:35 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>42452</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 20 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfmf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123181</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>


<item>
            <title>[HIVE-1546] Ability to plug custom Semantic Analyzers for Hive Grammar</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1546</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;It will be useful if Semantic Analysis phase is made pluggable such that other projects can do custom analysis of hive queries before doing metastore operations on them. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12471764">HIVE-1546</key>
            <summary>Ability to plug custom Semantic Analyzers for Hive Grammar</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21140&amp;avatarType=issuetype">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ashutoshc">Ashutosh Chauhan</assignee>
                                    <reporter username="ashutoshc">Ashutosh Chauhan</reporter>
                        <labels>
                    </labels>
                <created>Tue, 17 Aug 2010 00:18:57 +0000</created>
                <updated>Fri, 16 Dec 2011 23:59:47 +0000</updated>
                            <resolved>Fri, 8 Oct 2010 17:59:05 +0000</resolved>
                                    <version>0.7.0</version>
                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Metastore</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="12899204" author="ashutoshc" created="Tue, 17 Aug 2010 00:21:22 +0000"  >&lt;p&gt;This will involve a bit of refactoring and adding interface points which other systems can latch on.&lt;/p&gt;</comment>
                            <comment id="12899206" author="jvs" created="Tue, 17 Aug 2010 00:27:59 +0000"  >&lt;p&gt;(Note for other Hive committers:  this JIRA originated with some back-channel discussions between me and Pradeep about how to make it possible for Howl to reuse Hive CLI functionality.)&lt;/p&gt;</comment>
                            <comment id="12900135" author="ashutoshc" created="Thu, 19 Aug 2010 01:06:47 +0000"  >&lt;p&gt;Attached patch adds the capability to Hive so that custom semantic analysis of query is possible before it is handed over to Hive. Plus there are few other miscellaneous refactoring around it. Changes include:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Addition of SemanticAnalyzerFactoryInterface. If conf has a particular variable specified, a custom analyzer will be loaded and used, otherwise existing Hive Semantic Analyzer will be used. So, default behavior is preserved.&lt;/li&gt;
	&lt;li&gt;Changed visibility of few methods in DDLSemanticAnalyzer and SemanticAnalyzer from private to protected as I wanted to override them in my custom analyzer.&lt;/li&gt;
	&lt;li&gt;Changed file format specification in grammar, so that it can optionally take two more parameters (InputDriver and OutputDriver) in addition to InputFormat and OutputFormat. These are optional, so preserves the default behavior.&lt;/li&gt;
	&lt;li&gt;In file format specification, currently SequenceFile, TextFile and RCFile are supported through keyword. Expanded that production so to accept an identifier so that its possible to provide support for more file formats without needing to change Hive grammar every time. Currently, that token results in exception since there are none, but when we add support for other file formats that could be changed. This preserves current behavior.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Note that there are no new test cases since its mostly code restructuring and doesnt add/modify current behavior, thus passing existing tests should suffice.  &lt;br/&gt;
I should point out most of these changes are driven by Howl and would like to thank John for suggesting the initial approach for these changes.&lt;/p&gt;
</comment>
                            <comment id="12900137" author="ashutoshc" created="Thu, 19 Aug 2010 01:09:10 +0000"  >&lt;p&gt;Btw, can someone assign this jira to me and add me to the list of contributors so that in future I can do that myself.&lt;/p&gt;</comment>
                            <comment id="12900428" author="jvs" created="Thu, 19 Aug 2010 20:05:38 +0000"  >&lt;p&gt;Thanks Ashutosh, I&apos;ve reassigned this one to you and will get back to you with some review comments.&lt;/p&gt;</comment>
                            <comment id="12901641" author="jvs" created="Mon, 23 Aug 2010 22:44:36 +0000"  >&lt;p&gt;I have published some review comments here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://review.cloudera.org/r/713/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/713/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In addition:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;We need a test for loading a variation on the default semantic analyzer in order to exercise the pluggable configuration.  You can create a subclass of the default analyzer (under ql/src/test/org/apache/hadoop/hive/ql/parse) to inject some mock behavior change.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;We need a test for the new INPUTDRIVER/OUTPUTDRIVER clauses.  Otherwise, people will wonder why they&apos;re in the grammar but not referenced elsewhere in Hive; the test will give you a chance to explain the Howl dependency.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;We need a negative test for unrecognized generic format.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Let me know if you need help with how to script new positive+negative test cases.&lt;/p&gt;

&lt;p&gt;(BTW, your patch file header had a glitch in it; we usually use svn diff format.)&lt;/p&gt;</comment>
                            <comment id="12901646" author="hbasereviewboard" created="Mon, 23 Aug 2010 22:51:02 +0000"  >&lt;p&gt;Message from: &quot;John Sichi&quot; &amp;lt;jsichi@facebook.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/713/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/713/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;Review request for Hive Developers.&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;review by JVS&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1546&quot; title=&quot;Ability to plug custom Semantic Analyzers for Hive Grammar&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1546&quot;&gt;&lt;del&gt;HIVE-1546&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/HIVE-1546&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HIVE-1546&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java&lt;/a&gt; 988318 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/HiveUtils.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/HiveUtils.java&lt;/a&gt; 988318 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java&lt;/a&gt; 988318 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java&lt;/a&gt; 988318 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ExplainSemanticAnalyzer.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ExplainSemanticAnalyzer.java&lt;/a&gt; 988318 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g&lt;/a&gt; 988318 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;/a&gt; 988318 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java&lt;/a&gt; 988318 &lt;br/&gt;
  &lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactoryInterface.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactoryInterface.java&lt;/a&gt; PRE-CREATION &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.cloudera.org/r/713/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/713/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;John&lt;/p&gt;

</comment>
                            <comment id="12901654" author="hbasereviewboard" created="Mon, 23 Aug 2010 23:00:29 +0000"  >&lt;p&gt;Message from: &quot;John Sichi&quot; &amp;lt;jsichi@facebook.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/713/#review1008&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/713/#review1008&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;



&lt;p&gt;&lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java&lt;/a&gt;&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/713/#comment3232&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/713/#comment3232&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Can you break this out into several statements for readability?&lt;/p&gt;



&lt;p&gt;&lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/HiveUtils.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/HiveUtils.java&lt;/a&gt;&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/713/#comment3233&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/713/#comment3233&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    This does not belong in HiveUtils.  Can&apos;t we just leave it where it is (in SemanticAnalyzerFactory) and add a public accessor method for it so that extensions can reuse it?&lt;/p&gt;




&lt;p&gt;&lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java&lt;/a&gt;&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/713/#comment3234&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/713/#comment3234&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Why does this return a String []?  The callers don&apos;t use it.&lt;/p&gt;



&lt;p&gt;&lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactoryInterface.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactoryInterface.java&lt;/a&gt;&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/713/#comment3231&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/713/#comment3231&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Putting &quot;Interface&quot; into the interface name is clunky.&lt;/p&gt;

&lt;p&gt;    Let&apos;s call the interface HiveSemanticAnalyzerFactory instead (matching the convention for other plugin interfaces such as HiveStorageHandler and HiveIndexHandler).&lt;/p&gt;

&lt;p&gt;    In addition, I think we should introduce a new interface HiveSemanticAnalyzer and have the factory produce that, since factories should generally produce interfaces rather than classes (e.g. so that dynamic proxies can be used).&lt;/p&gt;




&lt;p&gt;&lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactoryInterface.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactoryInterface.java&lt;/a&gt;&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/713/#comment3224&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/713/#comment3224&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    This configuration parameter needs to be defined in HiveConf.java following the pattern already in use there.&lt;/p&gt;

&lt;p&gt;    Also, it needs a new entry in conf/hive-default.xml&lt;/p&gt;




&lt;p&gt;&lt;a href=&quot;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactoryInterface.java&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/repos/asf/hadoop/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactoryInterface.java&lt;/a&gt;&lt;br/&gt;
&amp;lt;&lt;a href=&quot;http://review.cloudera.org/r/713/#comment3228&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/713/#comment3228&lt;/a&gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;    Our convention for existing Hive plugins is to make them extend org.apache.hadoop.conf.Configurable and pass in the configuration only once via setConf (rather than to individual methods such as get).&lt;/p&gt;

&lt;p&gt;    Inside a Configurable, you can get back to a HiveConf with:&lt;/p&gt;

&lt;p&gt;    new HiveConf(getConf(), YourClass.class)&lt;/p&gt;



&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;John&lt;/li&gt;
&lt;/ul&gt;



</comment>
                            <comment id="12902552" author="ashutoshc" created="Wed, 25 Aug 2010 18:15:34 +0000"  >&lt;p&gt;Attaching a new patch.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;In addition, I think we should introduce a new interface HiveSemanticAnalyzer and have the factory produce that, since factories should generally produce interfaces rather than classes (e.g. so that dynamic proxies can be used).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This got me thinking and I have redesigned the patch, so now we have factory producing factory enabling dynamic proxying (abstractions and extensibility !) Your other comments got affected by it because of it but I have taken care of them. &lt;/p&gt;

&lt;p&gt;Signature for method handleGenricFileFormat() was String[] because description for task and task itself is created in analyzeCreateTable() and analyzeTableFileFormat() so that method cant  be void, as it needs to return whatever information it gathered to its calling method. Since at present we have no such file format, return value is ignored by calling methods. However I changed it to Map&amp;lt;String,String&amp;gt; because that seems more useful then String[].&lt;/p&gt;

&lt;p&gt;Added test-cases for all three cases you suggested.&lt;/p&gt;</comment>
                            <comment id="12903035" author="jvs" created="Thu, 26 Aug 2010 20:44:58 +0000"  >&lt;p&gt;Thanks, I took a look.  But factory producing factory seems like overkill here.&lt;/p&gt;

&lt;p&gt;What I was thinking in my previous comment was as follows:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;only one level of factory&lt;/li&gt;
	&lt;li&gt;define new interface HiveSemanticAnalyzer (not an abstract class):  copy signatures of interface methods from public methods on BaseSemanticAnalyzer; add Javadoc (I can help with that if any of them are non-obvious)&lt;/li&gt;
	&lt;li&gt;when callers get new analyzer instance from factory, they refer to it via the HiveSemanticAnalyzer interface only&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;If that doesn&apos;t work for some reason, then we can just use your original pattern where the factory returns a class (BaseSemanticAnalyzer) instead of an interface.&lt;/p&gt;

&lt;p&gt;Regarding handleGenericFileFormat:  I still don&apos;t understand.  Your code in Hive is ignoring the return value (and the only implementation doesn&apos;t return anything, it just throws).   So, either&lt;/p&gt;

&lt;p&gt;(a) you&apos;re planning to do something inside of Howl with it; in that case, the Hive method is just a hook for you to intercept, and it should return void&lt;/p&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;p&gt;(b) you&apos;re planning to add some more code inside of Hive which actually does something with the return value (e.g. sets the serde+inputformat+outputformat); in that case, you need to keep working on the patch to make this happen&lt;/p&gt;</comment>
                            <comment id="12903660" author="ashutoshc" created="Fri, 27 Aug 2010 21:48:44 +0000"  >&lt;blockquote&gt;&lt;p&gt;What I was thinking in my previous comment was as follows:&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
	&lt;li&gt;only one level of factory&lt;/li&gt;
	&lt;li&gt;define new interface HiveSemanticAnalyzer (not an abstract class): copy signatures of interface methods from public methods on BaseSemanticAnalyzer; add Javadoc (I can help with that if any of them are non-obvious)&lt;/li&gt;
	&lt;li&gt;when callers get new analyzer instance from factory, they refer to it via the HiveSemanticAnalyzer interface only&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Are you envisioning something like this in Driver.java&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;HiveSemanticAnalyzer sem = HiveSemanticAnalyzerFactory.get(conf);

&lt;span class=&quot;code-comment&quot;&gt;// Do semantic analysis and plan generation
&lt;/span&gt;sem.analyze(tree, ctx);

&lt;span class=&quot;code-comment&quot;&gt;// validate the plan
&lt;/span&gt;sem.validate();

plan = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; QueryPlan(command, sem);

&lt;span class=&quot;code-comment&quot;&gt;// get the output schema
&lt;/span&gt;schema = getSchema(sem, conf);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;Note where &lt;/p&gt;
{sem}
&lt;p&gt; is used. If so, HiveSemanticAnalyzer interface needs to look like this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; HiveSemanticAnalyzer &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Configurable{

  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void analyze(ASTNode ast, Context ctx) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; SemanticException;

  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void validate() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; SemanticException;

  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; List&amp;lt;FieldSchema&amp;gt; getResultSchema();

  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; FetchTask getFetchTask();

  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; List&amp;lt;Task&amp;lt;? &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Serializable&amp;gt;&amp;gt; getRootTasks();

  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; HashSet&amp;lt;ReadEntity&amp;gt; getInputs();

  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; HashSet&amp;lt;WriteEntity&amp;gt; getOutputs();

  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; LineageInfo getLineageInfo();

  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; HashMap&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; getIdToTableNameMap();
}

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This to me look like an awkward interface, which has to expose internal details of the very class it is trying to hide.&lt;br/&gt;
But even if we make an effort to improve on it and try to come up with a  better interface, this will mean that I need to touch upon lot of critical code paths in BaseSemanticAnalyzer, SemanticAnalyzer and DDLSemanticAnalyzer which I am not sure I know enough of them to make changes. If this is not what you were envisioning then I have missed something in what you were suggesting.&lt;/p&gt;

&lt;p&gt;Assuming we dont go this route, I liked the approach in my second patch better then from my first patch. I think it provides better abstractions. But if you have different opinion, I am fine with the first one as well.&lt;/p&gt;

&lt;p&gt;Regarding handleGenericFileFormat, its the point (a). It cant be void, because in Howl where we override this it needs to return information to its caller which will work on that information. handleGenericFileFormat() can only make use of the token and provide back some information. Caller works on that information and modifies the task it has created which usually happens to be of type DDLWork. And even Hive will need to go through this same code flow if and when it decides to add more FileFormats.&lt;/p&gt;</comment>
                            <comment id="12903738" author="jvs" created="Sat, 28 Aug 2010 00:38:16 +0000"  >&lt;p&gt;Yes, that is what I was envisioning.  I think the interface as you&apos;ve specified it looks close to the abstract functionality of the semantic analyzer, which is what we want (although we should use interfaces such as Set in preference to concrete classes such as HashSet, something which is currently crufty throughout Hive).&lt;/p&gt;

&lt;p&gt;I agree that this could be too involved for your first patch, and we would probably need to evolve the HiveSemanticAnalyzer interface anyway.  So, if you&apos;re not comfortable going there, let&apos;s scale it back to the approach in the first patch (with HiveSemanticAnalyzerFactory returning BaseSemanticAnalyzer).&lt;/p&gt;

&lt;p&gt;handleGenericFileFormat:  if it&apos;s only a hook for Howl, then you can have a separate method inside of Howl which returns whatever you want, but wrap it with a void method which overrides a void one in Hive (and discards the return values).  Or, if the idea is to have Hive use this too, then go ahead and add Javadoc specifying exactly what the return map is supposed to contain, and then convert the existing SEQUENCEFILE/TEXTFILE/RCFILE cases so they go through the generic path.  (But still keep them as reserved words rather than literal strings for backwards compatibility.)&lt;/p&gt;</comment>
                            <comment id="12903746" author="jvs" created="Sat, 28 Aug 2010 01:04:41 +0000"  >&lt;p&gt;More specifically, for the last suggestion, where we currently have&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;      case HiveParser.TOK_TBLRCFILE:
        inputFormat = RCFILE_INPUT;
        outputFormat = RCFILE_OUTPUT;
        shared.serde = COLUMNAR_SERDE;
        storageFormat = true;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;instead do&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;      case HiveParser.TOK_TBLRCFILE:
          processGenericFileFormat(&quot;RCFILE&quot;);
          break;
      case HiveParser.TOK_FILEFORMAT_GENERIC:
          processGenericFileFormat(child.getChild(0).getText());
          break;

...

void processGenericFileFormat(String formatName) {
    Map&amp;lt;String, String&amp;gt; props = handleGenericFileFormat(formatName);
    inputFormat = props.get(Constants.FILE_INPUT_FORMAT);
    outputFormat = props.get(Constants.FILE_OUTPUT_FORMAT);
    shared.serde = props.get(Constants.META_TABLE_SERDE);
   ...
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then in Hive&apos;s version of handleGenericFileFormat, make it return the right info for SEQUENCEFILE/TEXTFILE/RCFILE.&lt;/p&gt;

&lt;p&gt;This is just a sketch, not the real code, but I hope it makes sense.&lt;/p&gt;</comment>
                            <comment id="12904354" author="ashutoshc" created="Mon, 30 Aug 2010 21:35:33 +0000"  >&lt;p&gt;Thanks for quick feedback, John.&lt;br/&gt;
New patch with the approach in first patch incorporating review comments that followed it. For method signature, I took the first suggestion you had and made it void and figured out a way how to deal with it in Howl. Test cases added.&lt;/p&gt;</comment>
                            <comment id="12904360" author="ashutoshc" created="Mon, 30 Aug 2010 21:45:36 +0000"  >&lt;p&gt;Missed changes in one of the file. Reattaching the patch.&lt;/p&gt;</comment>
                            <comment id="12904397" author="hbasereviewboard" created="Mon, 30 Aug 2010 22:55:32 +0000"  >&lt;p&gt;Message from: &quot;Carl Steinbach&quot; &amp;lt;carl@cloudera.com&amp;gt;&lt;/p&gt;

&lt;p&gt;-----------------------------------------------------------&lt;br/&gt;
This is an automatically generated e-mail. To reply, visit:&lt;br/&gt;
&lt;a href=&quot;http://review.cloudera.org/r/713/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/713/&lt;/a&gt;&lt;br/&gt;
-----------------------------------------------------------&lt;/p&gt;

&lt;p&gt;(Updated 2010-08-30 15:42:15.768310)&lt;/p&gt;


&lt;p&gt;Review request for Hive Developers.&lt;/p&gt;


&lt;p&gt;Changes&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;Updated diff with &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12453466/hive-1546-3.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12453466/hive-1546-3.patch&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Summary&lt;br/&gt;
-------&lt;/p&gt;

&lt;p&gt;review by JVS&lt;/p&gt;


&lt;p&gt;This addresses bug &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1546&quot; title=&quot;Ability to plug custom Semantic Analyzers for Hive Grammar&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1546&quot;&gt;&lt;del&gt;HIVE-1546&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    &lt;a href=&quot;http://issues.apache.org/jira/browse/HIVE-1546&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HIVE-1546&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Diffs (updated)&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;  trunk/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java 990934 &lt;br/&gt;
  trunk/conf/hive-default.xml 990934 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/Driver.java 990934 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/metadata/HiveUtils.java 990934 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java 990934 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java 990934 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ExplainSemanticAnalyzer.java 990934 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g 990934 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveSemanticAnalyzerFactory.java PRE-CREATION &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java 990934 &lt;br/&gt;
  trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java 990934 &lt;br/&gt;
  trunk/ql/src/test/org/apache/hadoop/hive/ql/metadata/DummySemanticAnalyzerFactory.java PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/org/apache/hadoop/hive/ql/metadata/TestSemanticAnalyzerLoading.java PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientnegative/genericFileFormat.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/queries/clientpositive/inoutdriver.q PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientnegative/genericFileFormat.q.out PRE-CREATION &lt;br/&gt;
  trunk/ql/src/test/results/clientpositive/inoutdriver.q.out PRE-CREATION &lt;/p&gt;

&lt;p&gt;Diff: &lt;a href=&quot;http://review.cloudera.org/r/713/diff&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://review.cloudera.org/r/713/diff&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Testing&lt;br/&gt;
-------&lt;/p&gt;


&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;John&lt;/p&gt;

</comment>
                            <comment id="12904834" author="jvs" created="Tue, 31 Aug 2010 23:52:24 +0000"  >&lt;p&gt;+1.  Will commit when tests pass.&lt;/p&gt;</comment>
                            <comment id="12905287" author="ashutoshc" created="Wed, 1 Sep 2010 22:44:48 +0000"  >&lt;p&gt;After some recent changes, It seems its necessary to do&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;conf.set(HiveConf.ConfVars.HIVE_SUPPORT_CONCURRENCY.varname, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;in the test-case, otherwise test-case just hangs. Added it in my test-case. No other changes in the patch (as compared to previous patch) otherwise.&lt;/p&gt;</comment>
                            <comment id="12905342" author="namit" created="Thu, 2 Sep 2010 00:36:51 +0000"  >&lt;p&gt;We need to debug this. &lt;br/&gt;
For tests, we should be able to turn concurrency on.&lt;/p&gt;

&lt;p&gt;Which test is hanging ?&lt;/p&gt;</comment>
                            <comment id="12905353" author="ashutoshc" created="Thu, 2 Sep 2010 00:47:11 +0000"  >&lt;p&gt;It is the new test that I wrote for this patch TestSemanticAnalyzerLoading.java If I dont have this line my test hangs but if I have it, testcase completes successfully. How should I go about debugging it?  Do I need to bring up zookeeper externally or something? &lt;/p&gt;</comment>
                            <comment id="12905390" author="cwsteinbach" created="Thu, 2 Sep 2010 04:00:31 +0000"  >&lt;p&gt;@Ashutosh: Can you provide some background on what you hope to accomplish with this? What is the motivating use case, i.e. what custom SemanticAnalyzer do you plan to write?&lt;/p&gt;

&lt;p&gt;Also, how are the new INPUTDRIVER and OUTPUTDRIVER properties used? By adding these to the Hive grammar it seems like we may be providing a mechanism for defining tables in the MetaStore that Hive can&apos;t read or write to. If that&apos;s the case what are your plans for adding this support to Hive?&lt;/p&gt;
</comment>
                            <comment id="12905406" author="cwsteinbach" created="Thu, 2 Sep 2010 05:12:27 +0000"  >&lt;p&gt;If the main motivation for this ticket is the ability to produce a crippled version of the HiveCLI that is only capable of executing DDL, then I think we should consider simpler approaches that don&apos;t involve making SemanticAnalyzer a public API. &lt;/p&gt;

&lt;p&gt;SemanticAnalyzer is in serious need of refactoring. Making this API public will severely restrict our ability to do this work in the future.&lt;/p&gt;



</comment>
                            <comment id="12905410" author="jvs" created="Thu, 2 Sep 2010 05:29:12 +0000"  >&lt;p&gt;Hi Carl,&lt;/p&gt;

&lt;p&gt;As mentioned above, this patch originated with some of the early discussions on Howl before we had mailing lists set up.&lt;/p&gt;</comment>
                            <comment id="12905411" author="cwsteinbach" created="Thu, 2 Sep 2010 05:34:52 +0000"  >&lt;p&gt;@ John: Good to know, but what&apos;s the motivation for this change? Was is it covered in the back-channel discussions you mentioned above? And is making SemanticAnalyzer a public API really a good idea?&lt;/p&gt;</comment>
                            <comment id="12905640" author="ashutoshc" created="Thu, 2 Sep 2010 19:09:08 +0000"  >&lt;p&gt;@Carl,&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Ya, the main motivating use case is to provide an alternate DDL CLI tool (hopefully not crippled &lt;b&gt;smiles&lt;/b&gt;). Reason for that is to enforce certain use-cases on DDL commands in Howl CLI. More details on that are here: &lt;a href=&quot;http://wiki.apache.org/pig/Howl/HowlCliFuncSpec&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/pig/Howl/HowlCliFuncSpec&lt;/a&gt; If you have questions why we are making such decisions in Howl, I will encourage you to post it on howl-dev list and we can discuss it there. howldev@yahoogroups.com&lt;/li&gt;
	&lt;li&gt;I dont understand what do you mean by making &quot;SemanticAnalyzer a public API&quot;. This patch is just letting other tools to do some semantic analysis of the query and then use Hive to do further processing (if tool chooses to do so). Important point here is &lt;b&gt;other tools&lt;/b&gt;. This in no way enforcing any changes to any Hive behavior. Hive can continue to have its own semantic analyzer and do any sort of semantic analysis of the query. Hive is making no guarantees to any tool.&lt;/li&gt;
	&lt;li&gt;Hive doesnt care about INPUTDRIVER and OUTPUTDRIVER and neither this patch is asking it to. I dont see any way that its providing any mechanism for defining tables in MetaStore that Hive cant read or write to.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@John,&lt;br/&gt;
Do you want to make me to any further changes or are we good to go?&lt;/p&gt;</comment>
                            <comment id="12905655" author="jvs" created="Thu, 2 Sep 2010 19:47:49 +0000"  >&lt;p&gt;@Carl:  I understand your concern, but this seemed like the least intrusive approach as opposed to continually patching Hive to refine what Howl&apos;s CLI wants to support at a given point in time (which really has nothing to do with Hive).  The override approach allows that behavior to be factored completely out into Howl.  A number of our existing extensibility interfaces (e.g. StorageHandler) already have similar issues regarding impact from continual refactoring, so I expect an across-the-board SPI stabilization effort to be required in the future (with corresponding migrations from old to new).  This will need to be part of that effort.&lt;/p&gt;

&lt;p&gt;@Ashutosh:  I hit the hang you mentioned, so I can retry tests with your latest patch.  But let&apos;s resolve the approach with Carl first.  In particular, can we get agreement from the Howl team that even though we&apos;re introducing this dependency now, we will not let its existence hinder future semantic analyzer refactoring within Hive?  As long as we all stay in frequent communication, we can make that work.&lt;/p&gt;

&lt;p&gt;@Both:  one possible refinement would be to limit the public interface to just validation (as opposed to full semantic analysis).  In that case, we would have HiveStmtValidatorFactory producing HiveStmtValidator with just a single method validate().  This would also remove the unpleasantness of having a factory returning a base class rather than an interface.  However, if CLI is going to need to do more than just validation, then this isn&apos;t good enough.&lt;/p&gt;</comment>
                            <comment id="12905656" author="jvs" created="Thu, 2 Sep 2010 19:51:04 +0000"  >&lt;p&gt;For the last sentence, I meant &quot;If Howl&apos;s CLI customized behavior is going to need to influence more than just validation&quot;&lt;/p&gt;</comment>
                            <comment id="12905665" author="cwsteinbach" created="Thu, 2 Sep 2010 20:24:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;Can we get agreement from the Howl team that even though we&apos;re introducing this dependency now, we will not let its existence hinder future semantic analyzer refactoring within Hive?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What about other projects that use this feature? How do we get them to agree to this, or how do we prevent them from using it? The new configuration property is documented in hive-default.xml, which implies that it&apos;s open to everyone.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;one possible refinement would be to limit the public interface to just validation (as opposed to full semantic analysis). In that case, we would have HiveStmtValidatorFactory producing HiveStmtValidator with just a single method validate().&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This reduces the scope of the dependency, but doesn&apos;t eliminate it. Plugins would presumably depend on the structure of the AST that they are trying to validate, which in turn would limit our ability to refactor the grammar or to replace ANTLR with another parser generator.&lt;/p&gt;</comment>
                            <comment id="12905675" author="jvs" created="Thu, 2 Sep 2010 21:12:59 +0000"  >&lt;p&gt;New dependencies:   we don&apos;t prevent anyone from using it, but we can Javadoc it as unstable.  We can work out the language now in an updated patch since there&apos;s currently no Javadoc on the factory interface.&lt;/p&gt;

&lt;p&gt;Dependencies on AST/ANTLR:  it does make such changes more expensive in terms of impact analysis and migration, but it doesn&apos;t really prevent us in any way, does it?&lt;/p&gt;

&lt;p&gt;Given that we&apos;ve agreed at the high level on the approach of creating Howl as a wrapper around Hive (reusing as much as possible of what&apos;s already there), can you suggest an alternative mechanism that addresses the requirements while minimizing the injection of Howl behavior directly into Hive itself?  If it were something generic like a bitmask of allowed operations, I could kind of see it, but the validation logic is more involved than that (and may become even more so over time).  I wasn&apos;t able to come up with anything clean on that front myself, which is why I suggested the factoring approach to Pradeep originally.  Apologies for not getting stuff aired out sooner.&lt;/p&gt;</comment>
                            <comment id="12905686" author="cwsteinbach" created="Thu, 2 Sep 2010 21:47:47 +0000"  >&lt;blockquote&gt;&lt;p&gt;we&apos;ve agreed at the high level on the approach of creating Howl as a wrapper around Hive&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I thought Howl was supposed to be a wrapper around (and replacement for) the Hive metastore, not all of Hive.&lt;/p&gt;

&lt;p&gt;I think there are clear advantages to Hive and Howl sharing the same metastore code as long as they access this facility through the public API, but can&apos;t say the same for the two projects using the same CLI code if it means allowing external projects to depend on loosely defined set of internal APIs. What benefits are we hoping to achieve by having Howl and Hive share the same CLI code, especially if Howl is only interested in a small part of it? What are the drawbacks of instead encouraging the Howl project to copy the CLI code and maintain their own version?&lt;/p&gt;</comment>
                            <comment id="12905687" author="jvs" created="Thu, 2 Sep 2010 21:55:42 +0000"  >&lt;p&gt;It&apos;s the usual tradeoffs on copy-and-paste vs factoring.  There&apos;s a significant amount of DDL processing code which can be shared, and that will continue to grow as we add new features (e.g. GRANT/REVOKE) which are applicable to both.&lt;/p&gt;</comment>
                            <comment id="12905692" author="cwsteinbach" created="Thu, 2 Sep 2010 22:14:55 +0000"  >&lt;p&gt;What do you think of this option: we check the Howl SemanticAnalyzer into the Hive source tree and provide a config option that optionally enables it? This gives Howl the features they need without making the SemanticAnalyzer API public.&lt;/p&gt;</comment>
                            <comment id="12905706" author="jvs" created="Thu, 2 Sep 2010 22:37:28 +0000"  >&lt;p&gt;That&apos;s fine with me if it doesn&apos;t drag in unrelated dependencies.  I would vote for contrib, with the plugin mechanism remaining the same as Ashutosh has defined it, but with the config parameter explicitly defining it as intended for internal use only for now.&lt;/p&gt;

&lt;p&gt;Ashutosh, could you run this proposal by the Howl team and see if that is acceptable?&lt;/p&gt;</comment>
                            <comment id="12905707" author="cwsteinbach" created="Thu, 2 Sep 2010 22:41:05 +0000"  >&lt;p&gt;I&apos;m +1 on the approach outlined by John.&lt;/p&gt;</comment>
                            <comment id="12905711" author="alangates" created="Thu, 2 Sep 2010 22:43:23 +0000"  >&lt;p&gt;Using the definitions given in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-5073&quot; title=&quot;Hadoop 1.0 Interface Classification - scope (visibility - public/private) and stability&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-5073&quot;&gt;&lt;del&gt;HADOOP-5073&lt;/del&gt;&lt;/a&gt;, can we call this interface limited private and evolving?  We (the Howl team) know it will continue to change, and we understand Hive&apos;s desire not to make this a public API.  But checking Howl code into Hive just muddles things and makes our build and release process harder.  &lt;/p&gt;</comment>
                            <comment id="12905752" author="namit" created="Fri, 3 Sep 2010 00:55:25 +0000"  >&lt;p&gt;Would it be possible to do it via a hook ?&lt;/p&gt;

&lt;p&gt;Do you want to allow a subset of operations ? The hook is not very advanced right now, and you cannot change the query plan etc.&lt;br/&gt;
But, it might be good enough for disallowing a class of statements. We can add more parameters to the hook if need be.&lt;/p&gt;

&lt;p&gt;That way, the change will be completely outside hive, and we will be able to use the existing client, but with a limited functionality.&lt;/p&gt;</comment>
                            <comment id="12905757" author="cwsteinbach" created="Fri, 3 Sep 2010 01:11:44 +0000"  >&lt;p&gt;I gather from Ashutosh&apos;s latest patch that you want to do the following:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Provide your own implementation of HiveSemanticAnalyzerFactory.&lt;/li&gt;
	&lt;li&gt;Subclass SemanticAnalyzer&lt;/li&gt;
	&lt;li&gt;Subclass DDLSemanticAnalzyer&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I looked at the public and protected members in these classes and think&lt;br/&gt;
that at a minimum we would have to mark the following classes as limited&lt;br/&gt;
private and evolving:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;HiveSemanticAnalyzerFactory&lt;/li&gt;
	&lt;li&gt;BaseSemanticAnalyzer&lt;/li&gt;
	&lt;li&gt;SemanticAnalyzer&lt;/li&gt;
	&lt;li&gt;DDLSemanticAnalyzer&lt;/li&gt;
	&lt;li&gt;ASTNode&lt;/li&gt;
	&lt;li&gt;HiveParser (i.e. Hive&apos;s ANTLR grammar)&lt;/li&gt;
	&lt;li&gt;SemanticAnalyzer Context (org.apache.hadoop.hive.ql.Context)&lt;/li&gt;
	&lt;li&gt;Task and FetchTask&lt;/li&gt;
	&lt;li&gt;QB&lt;/li&gt;
	&lt;li&gt;QBParseInfo&lt;/li&gt;
	&lt;li&gt;QBMetaData&lt;/li&gt;
	&lt;li&gt;QBJoinTree&lt;/li&gt;
	&lt;li&gt;CreateTableDesc&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So anytime we touch one of these classes we would need to coordinate with the Howl folks to make sure we aren&apos;t breaking one of their plugins? I don&apos;t think this is a good tradeoff if the main benefit we can expect is a simpler build and release process for Howl.&lt;/p&gt;</comment>
                            <comment id="12905767" author="namit" created="Fri, 3 Sep 2010 01:38:46 +0000"  >&lt;p&gt;Sorry on jumping on this late.&lt;/p&gt;

&lt;p&gt;I quickly reviewed &lt;a href=&quot;http://wiki.apache.org/pig/Howl/HowlCliFuncSpec&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/pig/Howl/HowlCliFuncSpec&lt;/a&gt;, and it seems like most of the functionality is already&lt;br/&gt;
present in hive. So, we need a way to restrict other types of statements - is that a fair statement ?&lt;/p&gt;

&lt;p&gt;If there is a slight change needed in hive (for some howl behavior), we can add it to hive ? &lt;br/&gt;
Why do we need a brand new client ?&lt;/p&gt;</comment>
                            <comment id="12906041" author="jvs" created="Fri, 3 Sep 2010 19:45:07 +0000"  >&lt;p&gt;@Namit:  the option of putting Howl directly into Hive was previously proposed but dropped for the same reasons Alan mentioned above.  Regarding hooks, could you point me to the hook you&apos;re referring to?  I don&apos;t believe Pre/Post have enough information currently, do they?&lt;/p&gt;

&lt;p&gt;@Carl: I don&apos;t think Howl cares about the query processing stuff like &lt;/p&gt;
{Task and FetchTask,QB,QBParseInfo,QBMetaData,QBJoinTree}
&lt;p&gt;.  For the others, it&apos;s not any time we touch them; it&apos;s only when we make breaking changes.  And since Howl is also open source, it&apos;s not like these are opaque dependencies.  We would need to do the same impact analysis if we used the contrib approach, right?  I don&apos;t see a big difference between the two except with contrib we get the convenience of immediate compilation errors to tell us something broke.  A continuous integration setup for Howl would take us close to that.&lt;/p&gt;

&lt;p&gt;@All:  maybe we should set up a f2f meeting to hash this out?&lt;/p&gt;</comment>
                            <comment id="12906185" author="namit" created="Sat, 4 Sep 2010 00:10:44 +0000"  >&lt;p&gt;I agree it would be good to have a meeting.&lt;/p&gt;

&lt;p&gt;btw, the hooks I was referrring to and Pre/Post Execution Statement level hooks, with the following signature:&lt;/p&gt;

&lt;p&gt;public interface PostExecute {&lt;/p&gt;

&lt;p&gt;  /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;The run command that is called just before the execution of the query.&lt;br/&gt;
   *&lt;/li&gt;
	&lt;li&gt;@param sess&lt;/li&gt;
	&lt;li&gt;The session state.&lt;/li&gt;
	&lt;li&gt;@param inputs&lt;/li&gt;
	&lt;li&gt;The set of input tables and partitions.&lt;/li&gt;
	&lt;li&gt;@param outputs&lt;/li&gt;
	&lt;li&gt;The set of output tables, partitions, local and hdfs directories.&lt;/li&gt;
	&lt;li&gt;@param lInfo&lt;/li&gt;
	&lt;li&gt;The column level lineage information.&lt;/li&gt;
	&lt;li&gt;@param ugi&lt;/li&gt;
	&lt;li&gt;The user group security information.&lt;br/&gt;
   */&lt;br/&gt;
  void run(SessionState sess, Set&amp;lt;ReadEntity&amp;gt; inputs,&lt;br/&gt;
      Set&amp;lt;WriteEntity&amp;gt; outputs, LineageInfo lInfo,&lt;br/&gt;
      UserGroupInformation ugi) throws Exception;&lt;br/&gt;
}&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Looking at the spec., it looks like a subset of DDLs need to be supported, which can be easily accomplished via the hook.&lt;br/&gt;
If need be, we can pass more info. in the hook - there was a plan to add job level hook also, which is not checked in,&lt;br/&gt;
but via which the configuration etc. can be changed.&lt;/p&gt;</comment>
                            <comment id="12907789" author="ashutoshc" created="Thu, 9 Sep 2010 21:12:21 +0000"  >&lt;p&gt;@Namit,&lt;br/&gt;
As far as I understand, Hooks were designed to run before or after the query executes, not while query is getting executing. By executing a query I mean (generating AST, doing semantic analysis of that AST which includes necessary metadata operations, building a query plan and running the plan). If that was how hook were intended to be used I am not clear how they will be used in this scenario. In Howl its not just a list of metadata operations that we want to allow or disallow, there is a bit more semantic analysis that we do which includes doing metadata operation on metadata repository. Its not really before or after query is executed, it is one of the parts of query processing itself. You also hinted that hooks can be modified and more information can be provided in those methods. If thats what we do then I think we are loosing semantics on hooks which is something which is fired before and after the query executes, as hook will now be running while query is executing. Its entirely possible that I have misunderstood hooks and their intended usage. You obviously know more then so feel free to correct me. &lt;br/&gt;
I am also attaching what semantic analysis that we are doing for everyone&apos;s reference for better context.&lt;/p&gt;</comment>
                            <comment id="12909318" author="ashutoshc" created="Tue, 14 Sep 2010 16:43:35 +0000"  >&lt;p&gt;@Namit,&lt;/p&gt;

&lt;p&gt;Continuing from discussion yesterday w.r.t new interface/hooks that you were suggesting. As far as I understood you have two primary concerns:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;You do not want to have config variable enabled SemanticAnalyzer factory producing different Analyzers. Rather, you want to have only one  HiveSemanticAnalyzer.&lt;/li&gt;
	&lt;li&gt;You also dont want others to extend SemanticAnalyzer, DDLSemanticAnalyzer and other Hive classes.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;As a solution to this, there will be new hooks introduced. These pre and post hooks will be called by Hive at different times during Semantic Analysis phase. To me, it seems there are few potential problems: &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Hive will need to call these hooks from each and every method of its Analyzer which opens up whole lot more integration points to external tools (like Howl) and burden on those Analyzers then the current approach of factory enabled instantiation and extending of those classes.&lt;/li&gt;
	&lt;li&gt;Either there will be a one generic hook or many different hooks. If there is only one generic hook, then passed in information also need to be generic and as a result it will be a root of AST Node. If so, in any particular hook I am using I need to traverse the whole AST to get the node I am interested in.&lt;/li&gt;
	&lt;li&gt;If the hooks are more specific, then more specific information can be passed in which is more useful, but then you will have long list of such hooks.&lt;/li&gt;
	&lt;li&gt;Even if these concerns are taken care of, it seems that all of Howl&apos;s requirements may not get satisfied (like getting hold of DDLTask and modifying it, doing metadata operations etc.) I can elaborate on them further once I can see what you are proposing.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Clearly from my description, you can see that I didnt get what you were envisioning and how is it better then current design. I must be missing something. Would you like to propose what you were suggesting? The attached patch and Howl classes on this jira should be sufficient to spec out Howl&apos;s requirements, if you need them.  &lt;/p&gt;</comment>
                            <comment id="12909432" author="jvs" created="Tue, 14 Sep 2010 20:33:08 +0000"  >&lt;p&gt;@Ashutosh:  I will get back to you soon with a proposal.  Based on what I see in your Howl_Semantic_Analysis.txt code, I think the interface can be very small.&lt;/p&gt;</comment>
                            <comment id="12909549" author="jvs" created="Wed, 15 Sep 2010 01:01:23 +0000"  >&lt;p&gt;I think we can start off with this interface:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;/**
 * HiveSemanticAnalyzerHook allows Hive to be extended with custom
 * logic for semantic analysis of QL statements.  This interface
 * and any Hive internals it exposes are currently 
 * &quot;limited private and evolving&quot; (unless otherwise stated elsewhere)
 * and intended mainly for use by the Howl project.
 *
 *&amp;lt;p&amp;gt;
 *
 * Note that the lifetime of an instantiated hook object is scoped to
 * the analysis of a single statement; hook instances are never reused.
 */
public interface HiveSemanticAnalyzerHook {
  /**
   * Invoked before Hive performs its own semantic analysis on
   * a statement.  The implementation may inspect the statement AST and
   * prevent its execution by throwing a SemanticException.
   * Optionally, it may also augment/rewrite the AST, but must produce
   * a form equivalent to one which could have
   * been returned directly from Hive&apos;s own parser.
   *
   * @param context context information for semantic analysis
   *
   * @param ast AST being analyzed and optionally rewritten
   *
   * @return replacement AST (typically the same as the original AST unless the
   * entire tree had to be replaced; must not be null)
   */
  public ASTNode preAnalyze(
    HiveSemanticAnalyzerHookContext context,
    ASTNode ast) throws SemanticException;

  /**
   * Invoked after Hive performs its own semantic analysis on a
   * statement (including optimization).  
   * Hive calls postAnalyze on the same hook object
   * as preAnalyze, so the hook can maintain state across the calls.
   *
   * @param context context information for semantic analysis
   *
   * @param rootTasks root tasks produced by semantic analysis;
   * the hook is free to modify this list or its contents
   */
  public void postAnalyze(
    HiveSemanticAnalyzerHookContext context,
    List&amp;lt;Task&amp;lt;? extends Serializable&amp;gt;&amp;gt; rootTasks) throws SemanticException;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Plus companion context interface to be passed in from Hive:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;/**
 * Context information provided by Hive to implementations of HiveSemanticAnalyzerHook.
 */
public interface HiveSemanticAnalyzerHookContext {
  /**
   * @return the Hive db instance; hook implementations can use this for purposes such as getting configuration information or making metastore calls
   */
  public Hive getHive();
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The reason for the context is so that later, if we need to make more information&lt;br/&gt;
available to the hook, we just add new getters to the context object&lt;br/&gt;
(rather than adding new parameters to methods such as preAnalyze,&lt;br/&gt;
which would break existing hook implementations).&lt;/p&gt;

&lt;p&gt;Unlike pre/post exec hooks, we will only allow one hook to be&lt;br/&gt;
configured (rather than a list).  If someone really wants to run&lt;br/&gt;
more than one, they can write a list hook implementation which delegates&lt;br/&gt;
to multiple.  The conf variable used to load the hook class will be&lt;br/&gt;
hive.semantic.analyzer.hook since it&apos;s no longer a factory.&lt;/p&gt;

&lt;p&gt;We also need an insulation class:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;public abstract class AbstractSemanticAnalyzerHook 
  implements HiveSemanticAnalyzerHook {

  public ASTNode preAnalyze(
    HiveSemanticAnalyzerHookContext context,
    ASTNode ast) throws SemanticException
  {
    return ast;
  }

  public void postAnalyze(
    HiveSemanticAnalyzerHookContext context,
    List&amp;lt;Task&amp;lt;? extends Serializable&amp;gt;&amp;gt; rootTasks) throws SemanticException
  {
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Hook implementations should extend this to avoid breaking when we add&lt;br/&gt;
new methods to the HiveSemanticAnalyzerHook interface later.&lt;/p&gt;

&lt;p&gt;By using the hook approach, we limit the dependency exposure: only ASTNodes,&lt;br/&gt;
Tasks, and the org.apache.hadoop.hive.ql.metadata.Hive class can be accessed&lt;br/&gt;
for now.  If we decide to open it up more later, that will be via an&lt;br/&gt;
agreed-upon decision in a new patch (rather than via ad hoc dependency&lt;br/&gt;
creep).&lt;/p&gt;

&lt;p&gt;Instead of invoking the hook from many different places inside of&lt;br/&gt;
SemanticAnalyzer, we&apos;ll start with just invoking it only pre- and post-&lt;br/&gt;
the call to sem.analyze.  More invocation points&lt;br/&gt;
(e.g. pre-optimization) can be added later on an as-needed basis.&lt;/p&gt;

&lt;p&gt;Howl&apos;s table property additions can be saved during the preAnalyze&lt;br/&gt;
call and then applied to the Task during the postAnalyze call (since&lt;br/&gt;
the hook is allowed to maintain state); this stays very close to the&lt;br/&gt;
approach in the current patch.  Another way to do this is to&lt;br/&gt;
not use a postAnalyze at all, and instead just rewrite the AST to&lt;br/&gt;
splice in the additional TBLPROPERTIES up front.  Both ways are a&lt;br/&gt;
little messy, but either way should be fine.&lt;/p&gt;

&lt;p&gt;For handleGenericFileFormat, I think we can deal with it by having&lt;br/&gt;
Howl edit the AST to delete the STORED AS clause entirely during&lt;br/&gt;
preAnalyze (in cases where it accepts the storage format).  That way&lt;br/&gt;
Hive can continue to reject it unconditionally, and we can avoid&lt;br/&gt;
adding a third interface method.&lt;/p&gt;

&lt;p&gt;(Likewise, Howl should delete INPUTDRIVER and OUTPUTDRIVER, and Hive&lt;br/&gt;
should reject them when it sees them, since they aren&apos;t currently&lt;br/&gt;
meaningful within Hive by itself.)&lt;/p&gt;

&lt;p&gt;The only other SemanticAnalyzer dependency I see is getColumns, and&lt;br/&gt;
that can be dealt with by moving it to become a static utility method&lt;br/&gt;
on ParseUtils.&lt;/p&gt;

&lt;p&gt;Let me know if I missed any other cases that need to be dealt with.&lt;/p&gt;</comment>
                            <comment id="12909799" author="ashutoshc" created="Wed, 15 Sep 2010 17:06:38 +0000"  >&lt;p&gt;@John,&lt;br/&gt;
I took a look at the proposed new interface. I didn&apos;t go full in-depth into it yet to ascertain whether this works for Howl as desired or not, but I got the high level idea. It is a major redesign from the current patch. It will require some amount of design and dev work. This also implies all our testing (both unit and integration) which we have done on this patch till now is redundant and we need to redo that again as well. &lt;/p&gt;</comment>
                            <comment id="12909822" author="jvs" created="Wed, 15 Sep 2010 17:53:25 +0000"  >&lt;p&gt;For the Hive part, it will be good if you can keep the same coverage as you have in the new unit tests from your last patch--the same cases can be validated regardless of hook vs factory.&lt;/p&gt;</comment>
                            <comment id="12916390" author="ashutoshc" created="Thu, 30 Sep 2010 06:28:21 +0000"  >&lt;p&gt;@John,&lt;/p&gt;

&lt;p&gt;Neat work with hook interfaces. I was able to use the proposed one as it is without any modifications.  Attaching the patch for incorporating these interfaces based on hooks in Hive. &lt;/p&gt;</comment>
                            <comment id="12916756" author="jvs" created="Fri, 1 Oct 2010 01:39:11 +0000"  >&lt;p&gt;Great.  I&apos;m actually out on vacation until the end of next week, so if you want to get this one committed before then, ping Namit (njain at facebook dot com) and get him to review.  Otherwise, I&apos;ll push it through once I get back.&lt;/p&gt;</comment>
                            <comment id="12916758" author="ashutoshc" created="Fri, 1 Oct 2010 02:04:13 +0000"  >&lt;p&gt;Hey Namit,&lt;/p&gt;

&lt;p&gt;Would you like to review it?&lt;/p&gt;</comment>
                            <comment id="12917677" author="namit" created="Mon, 4 Oct 2010 17:48:00 +0000"  >&lt;p&gt;I will take a look in more detail, but overall it looks good. I had the following comments:&lt;/p&gt;

&lt;p&gt;1. Instead of TestSemanticAnalyzerHookLoading.java, add tests in test/queries/clientpositive and test/queries/clientnegative&lt;br/&gt;
2. Do you want to set the value of hive.semantic.analyzer.hook to a dummy value in data/conf/hive-site.xml for the unit tests ?&lt;br/&gt;
    Can something meaningful be printed here, which can be used for comparing ?&lt;/p&gt;</comment>
                            <comment id="12917851" author="ashutoshc" created="Tue, 5 Oct 2010 01:31:29 +0000"  >&lt;p&gt;I did it in junit form because John suggested it that way in his earlier comment:&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
	&lt;li&gt;We need a test for loading a variation on the default semantic analyzer in order to exercise the pluggable configuration. You can create a subclass of the default analyzer (under ql/src/test/org/apache/hadoop/hive/ql/parse) to inject some mock behavior change.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;I also feel junit test is better suited for this kind of behavioral testing of code paths (which exercises interface points) rather then forcing through string comparison ways of test/queries/*  which are more end-to-end tests for hive. Further if we add dummy hook name in data/conf/hive-site.xml then that dummy hook will get loaded and all the subsequent tests will have it too. Do we want it that way?&lt;/p&gt;</comment>
                            <comment id="12918972" author="ashutoshc" created="Thu, 7 Oct 2010 16:57:53 +0000"  >&lt;p&gt;@Namit,&lt;/p&gt;

&lt;p&gt;Did you get a chance to take a look? I want to move forward and eager to contribute more to Hive, rather then stuck on this forever : )&lt;/p&gt;</comment>
                            <comment id="12919021" author="namit" created="Thu, 7 Oct 2010 19:02:05 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;Otherwise, the changes are good - the patch is not applying cleanly.&lt;/p&gt;

&lt;p&gt;Can you refresh and regenerate the patch ? I will take care of it&lt;/p&gt;</comment>
                            <comment id="12919126" author="ashutoshc" created="Fri, 8 Oct 2010 01:14:13 +0000"  >&lt;p&gt;Patch did apply cleanly for me. Anyways, I regenerated it on latest trunk (Revision: 1005669)&lt;br/&gt;
Hopefully, this one will make it in time.&lt;/p&gt;</comment>
                            <comment id="12919337" author="namit" created="Fri, 8 Oct 2010 17:59:05 +0000"  >&lt;p&gt;Committed. Thanks Ashutosh&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12454243" name="Howl_Semantic_Analysis.txt" size="13012" author="ashutoshc" created="Thu, 9 Sep 2010 21:12:21 +0000"/>
                            <attachment id="12453466" name="hive-1546-3.patch" size="24875" author="ashutoshc" created="Mon, 30 Aug 2010 21:45:36 +0000"/>
                            <attachment id="12453637" name="hive-1546-4.patch" size="24952" author="ashutoshc" created="Wed, 1 Sep 2010 22:44:48 +0000"/>
                            <attachment id="12452477" name="hive-1546.patch" size="18309" author="ashutoshc" created="Thu, 19 Aug 2010 01:06:47 +0000"/>
                            <attachment id="12453062" name="hive-1546_2.patch" size="28537" author="ashutoshc" created="Wed, 25 Aug 2010 18:15:34 +0000"/>
                            <attachment id="12455975" name="hooks.patch" size="31906" author="ashutoshc" created="Thu, 30 Sep 2010 06:28:21 +0000"/>
                            <attachment id="12456654" name="hooks2.patch" size="31975" author="ashutoshc" created="Fri, 8 Oct 2010 01:14:13 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 17 Aug 2010 00:27:59 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72846</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 16 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfmn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123182</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1547] Unarchiving operation throws NPE</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1547</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Unarchiving a partition throws a null pointer exception similar to the following:&lt;/p&gt;

&lt;p&gt;2010-08-16 12:44:18,801 ERROR exec.DDLTask (SessionState.java:printError(277)) - Failed with exception null&lt;br/&gt;
java.lang.NullPointerException&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.DDLTask.unarchive(DDLTask.java:729)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:195)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:108)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:55)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:609)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:478)&lt;br/&gt;
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:356)&lt;br/&gt;
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:140)&lt;br/&gt;
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:199)&lt;br/&gt;
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:351)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.util.RunJar.main(RunJar.java:156)&lt;/p&gt;

&lt;p&gt;This error seems to be DFS specific, as local file system in the unit tests don&apos;t catch this.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471770">HIVE-1547</key>
            <summary>Unarchiving operation throws NPE</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="pauly">Paul Yang</assignee>
                                    <reporter username="pauly">Paul Yang</reporter>
                        <labels>
                    </labels>
                <created>Tue, 17 Aug 2010 02:09:54 +0000</created>
                <updated>Sat, 17 Dec 2011 00:01:12 +0000</updated>
                            <resolved>Tue, 17 Aug 2010 20:58:16 +0000</resolved>
                                    <version>0.7.0</version>
                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12899297" author="namit" created="Tue, 17 Aug 2010 06:19:45 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="12899583" author="namit" created="Tue, 17 Aug 2010 20:58:16 +0000"  >&lt;p&gt;Committed. Thanks Paul&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12452244" name="HIVE-1547.1.patch" size="1787" author="pauly" created="Tue, 17 Aug 2010 02:11:39 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 17 Aug 2010 06:19:45 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72845</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 23 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfmv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123183</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1548] populate inputs and outputs for all statements</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1548</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Currently, they are only populated for queries - and not for most of the DDLs.&lt;/p&gt;

&lt;p&gt;The pre and post execution hooks do not get the correct values.&lt;br/&gt;
It would also be very useful for locking&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471782">HIVE-1548</key>
            <summary>populate inputs and outputs for all statements</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="namit">Namit Jain</assignee>
                                    <reporter username="namit">Namit Jain</reporter>
                        <labels>
                    </labels>
                <created>Tue, 17 Aug 2010 06:24:42 +0000</created>
                <updated>Sat, 17 Dec 2011 00:01:02 +0000</updated>
                            <resolved>Tue, 17 Aug 2010 22:35:07 +0000</resolved>
                                                    <fixVersion>0.7.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12899584" author="he yongqiang" created="Tue, 17 Aug 2010 21:02:06 +0000"  >&lt;p&gt;running test now.&lt;/p&gt;</comment>
                            <comment id="12899628" author="he yongqiang" created="Tue, 17 Aug 2010 22:35:07 +0000"  >&lt;p&gt;I just committed! Thanks namit!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                            <outwardlinks description="breaks">
                                        <issuelink>
            <issuekey id="12471921">HIVE-1556</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12471959">HIVE-1563</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12452321" name="hive.1548.1.patch" size="1288246" author="namit" created="Tue, 17 Aug 2010 20:52:48 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 17 Aug 2010 21:02:06 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72844</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 23 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfn3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123184</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1549] Add ANSI SQL correlation aggregate function CORR(X,Y).</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1549</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Aggregate function that computes the Pearson&apos;s coefficient of correlation between a set of number pairs.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471821">HIVE-1549</key>
            <summary>Add ANSI SQL correlation aggregate function CORR(X,Y).</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="p_huyn">Pierre Huyn</assignee>
                                    <reporter username="p_huyn">Pierre Huyn</reporter>
                        <labels>
                    </labels>
                <created>Tue, 17 Aug 2010 16:52:17 +0000</created>
                <updated>Sat, 9 Feb 2013 23:00:29 +0000</updated>
                            <resolved>Fri, 20 Aug 2010 01:04:42 +0000</resolved>
                                    <version>0.7.0</version>
                                    <fixVersion>0.7.0</fixVersion>
                                    <component>UDF</component>
                        <due>Sat, 21 Aug 2010 00:00:00 +0000</due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                    <timeoriginalestimate seconds="432000">120h</timeoriginalestimate>
                            <timeestimate seconds="432000">120h</timeestimate>
                                        <comments>
                            <comment id="12899538" author="jvs" created="Tue, 17 Aug 2010 19:25:49 +0000"  >&lt;p&gt;Note &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1545&quot; title=&quot;Add a bunch of UDFs and UDAFs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1545&quot;&gt;HIVE-1545&lt;/a&gt;.  Jonathan Chang (from Facebook data science) dropped in a bunch of code there which may or may not be reelvant.&lt;/p&gt;</comment>
                            <comment id="12899932" author="p_huyn" created="Wed, 18 Aug 2010 17:55:53 +0000"  >&lt;p&gt;This CORR  UDAF is implemented using a one-pass stable algorithm, very similar to the implementation of the COVAR_POP UPAF. This code release is now ready for review.&lt;/p&gt;</comment>
                            <comment id="12899934" author="p_huyn" created="Wed, 18 Aug 2010 17:58:18 +0000"  >&lt;p&gt;This release is ready for code review.&lt;/p&gt;</comment>
                            <comment id="12900009" author="jvs" created="Wed, 18 Aug 2010 20:07:00 +0000"  >&lt;p&gt;Mayank, if you get time, here&apos;s another one to take a look at.&lt;/p&gt;</comment>
                            <comment id="12900011" author="mayanklahiri" created="Wed, 18 Aug 2010 20:09:18 +0000"  >&lt;p&gt;No problem, reviewing it now...&lt;/p&gt;</comment>
                            <comment id="12900029" author="mayanklahiri" created="Wed, 18 Aug 2010 20:56:08 +0000"  >&lt;p&gt;Nice job Pierre! Just a couple of very trivial points:&lt;/p&gt;

&lt;p&gt;&amp;#8211; UDAF file, line #116 and line #123, could you amend the error message to indicate that only numeric types are accepted (string is also included as of now).&lt;/p&gt;

&lt;p&gt;&amp;#8211; I don&apos;t think you need the private boolean warned, line #273&lt;/p&gt;

&lt;p&gt;Otherwise, it looks good and the numbers work out.&lt;/p&gt;


&lt;p&gt;Incidentally, for the future, if your UDAF only stores a small number of values as a partial aggregation, you might just want to consider serializing the values as a list of doubles instead of a struct in terminatePartial() and merge(). It&apos;ll probably save you some time and reduce the amount of code in those parts. &lt;/p&gt;</comment>
                            <comment id="12900055" author="p_huyn" created="Wed, 18 Aug 2010 21:57:12 +0000"  >&lt;p&gt;Fixed the 2 issues from Mayank&apos;s review.&lt;/p&gt;</comment>
                            <comment id="12900062" author="p_huyn" created="Wed, 18 Aug 2010 22:03:27 +0000"  >&lt;p&gt;Thanks for your comments. The items have been taken care of in the patch #2.&lt;/p&gt;

</comment>
                            <comment id="12900075" author="mayanklahiri" created="Wed, 18 Aug 2010 22:35:22 +0000"  >&lt;p&gt;+1 looks good to me.&lt;/p&gt;</comment>
                            <comment id="12900098" author="jvs" created="Wed, 18 Aug 2010 23:13:44 +0000"  >&lt;p&gt;Will commit when tests pass.&lt;/p&gt;</comment>
                            <comment id="12900426" author="jvs" created="Thu, 19 Aug 2010 20:04:01 +0000"  >&lt;p&gt;Hi Pierre,&lt;/p&gt;

&lt;p&gt;I applied your patch (after resolving some trivial conflicts with a recent context_ngrams checkin from Mayank) but hit some test failures due to test output diffs from other changes which got committed recently in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1548&quot; title=&quot;populate inputs and outputs for all statements&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1548&quot;&gt;&lt;del&gt;HIVE-1548&lt;/del&gt;&lt;/a&gt; (not a problem in your patch).&lt;/p&gt;

&lt;p&gt;Could you upload a new patch which resolves the conflicts and updates the test output to match latest trunk?&lt;/p&gt;</comment>
                            <comment id="12900436" author="p_huyn" created="Thu, 19 Aug 2010 20:26:14 +0000"  >&lt;p&gt;New patch created to resolve conflicts with other commits. All I did was to refresh my working tree, recompile, and rerun test. Hope this works.&lt;/p&gt;</comment>
                            <comment id="12900446" author="p_huyn" created="Thu, 19 Aug 2010 20:42:51 +0000"  >&lt;p&gt;Hi John,&lt;/p&gt;

&lt;p&gt;I just uploaded a new patch. I assume the conflicts were caused by the particular ways svn works. Hope this patch resolves the conflicts (magically?).&lt;/p&gt;

&lt;p&gt;Regards&lt;br/&gt;
&amp;#8212; Pierre&lt;/p&gt;
</comment>
                            <comment id="12900450" author="jvs" created="Thu, 19 Aug 2010 20:52:16 +0000"  >&lt;p&gt;Hmmm, looking more closely...your patch includes changes to udaf_covar_pop.q.out and covar_samp.q.out (and those include conflict markers, which should never be there in a submitted patch).  But this change shouldn&apos;t actually affect those files at all, right?  I think if you just revert those before svn diff, all should be well.&lt;/p&gt;</comment>
                            <comment id="12900460" author="p_huyn" created="Thu, 19 Aug 2010 21:10:32 +0000"  >&lt;p&gt;Rebuilt patch after reverting udaf_covar_pop.q.out and udaf_covar_samp.q.out which are not relevant to this patch and should not have been inconsistent with the trunk.&lt;/p&gt;</comment>
                            <comment id="12900475" author="p_huyn" created="Thu, 19 Aug 2010 21:35:56 +0000"  >&lt;p&gt;Hi John,&lt;/p&gt;

&lt;p&gt;Please let me know how it goes.&lt;br/&gt;
&amp;#8212; Pierre&lt;/p&gt;
</comment>
                            <comment id="12900478" author="jvs" created="Thu, 19 Aug 2010 21:45:01 +0000"  >&lt;p&gt;Rerunning tests with latest.&lt;/p&gt;</comment>
                            <comment id="12900546" author="jvs" created="Fri, 20 Aug 2010 01:04:42 +0000"  >&lt;p&gt;Committed.  Thanks Pierre!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12607356">HIVE-3455</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12471758">HIVE-1545</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12452427" name="HIVE-1549.1.patch" size="32776" author="p_huyn" created="Wed, 18 Aug 2010 17:55:53 +0000"/>
                            <attachment id="12452458" name="HIVE-1549.2.patch" size="32583" author="p_huyn" created="Wed, 18 Aug 2010 21:57:12 +0000"/>
                            <attachment id="12452569" name="HIVE-1549.3.patch" size="32605" author="p_huyn" created="Thu, 19 Aug 2010 20:26:14 +0000"/>
                            <attachment id="12452575" name="HIVE-1549.4.patch" size="22816" author="p_huyn" created="Thu, 19 Aug 2010 21:10:32 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 17 Aug 2010 19:25:49 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72843</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 23 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfnb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123185</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>This CORR udaf is implemented using a stable one-pass algorithm, similar to the one used in the COVAR_POP udaf.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1550] Implement DROP VIEW IF EXISTS</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1550</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Implement the IF EXISTS clause for the DROP VIEW statement.&lt;/p&gt;

&lt;p&gt;See &lt;a href=&quot;http://dev.mysql.com/doc/refman/5.0/en/drop-view.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://dev.mysql.com/doc/refman/5.0/en/drop-view.html&lt;/a&gt;&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12471833">HIVE-1550</key>
            <summary>Implement DROP VIEW IF EXISTS</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21141&amp;avatarType=issuetype">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="marcelk">Marcel Kornacker</assignee>
                                    <reporter username="cwsteinbach">Carl Steinbach</reporter>
                        <labels>
                    </labels>
                <created>Tue, 17 Aug 2010 18:49:32 +0000</created>
                <updated>Sat, 4 Jun 2011 07:44:49 +0000</updated>
                            <resolved>Sat, 4 Jun 2011 07:44:49 +0000</resolved>
                                                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="12969428" author="eli" created="Wed, 8 Dec 2010 19:07:02 +0000"  >&lt;p&gt;Dupe of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1165&quot; title=&quot;Support `DROP TABLE XXX IF EXISTS`&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1165&quot;&gt;&lt;del&gt;HIVE-1165&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="12969603" author="cwsteinbach" created="Thu, 9 Dec 2010 01:55:53 +0000"  >&lt;p&gt;Nope, it&apos;s not a duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1165&quot; title=&quot;Support `DROP TABLE XXX IF EXISTS`&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1165&quot;&gt;&lt;del&gt;HIVE-1165&lt;/del&gt;&lt;/a&gt;, but the issues are related and it will be most efficient to fix both tickets at the same time.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12493708">HIVE-1856</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12493708">HIVE-1856</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12456202">HIVE-1165</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 8 Dec 2010 19:07:02 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72120</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 7 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfnj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123186</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>


<item>
            <title>[HIVE-1551] DROP VIEW should raise an error if the view does not exist</title>
                <link>https://issues.apache.org/jira/browse/HIVE-1551</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;See &lt;a href=&quot;http://dev.mysql.com/doc/refman/5.0/en/drop-view.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://dev.mysql.com/doc/refman/5.0/en/drop-view.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1542&quot; title=&quot;DROP TABLE &amp;lt;tablename&amp;gt; should raise an error when &amp;lt;tablename&amp;gt; does not exist&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1542&quot;&gt;HIVE-1542&lt;/a&gt;. As John noted in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1542&quot; title=&quot;DROP TABLE &amp;lt;tablename&amp;gt; should raise an error when &amp;lt;tablename&amp;gt; does not exist&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1542&quot;&gt;HIVE-1542&lt;/a&gt; we will need to introduce a configuration property that allows users to disable this error.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12471836">HIVE-1551</key>
            <summary>DROP VIEW should raise an error if the view does not exist</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="marcelk">Marcel Kornacker</assignee>
                                    <reporter username="cwsteinbach">Carl Steinbach</reporter>
                        <labels>
                    </labels>
                <created>Tue, 17 Aug 2010 18:54:38 +0000</created>
                <updated>Sat, 4 Jun 2011 07:47:29 +0000</updated>
                            <resolved>Sat, 4 Jun 2011 07:47:29 +0000</resolved>
                                                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="13044220" author="cwsteinbach" created="Sat, 4 Jun 2011 07:47:29 +0000"  >&lt;p&gt;Fixed in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1856&quot; title=&quot;Implement DROP TABLE/VIEW ... IF EXISTS &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-1856&quot;&gt;&lt;del&gt;HIVE-1856&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Error is raised only if hive.exec.drop.ignorenonexistent=false&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12471722">HIVE-1542</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12493708">HIVE-1856</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>72118</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 34 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lfnr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>123187</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                    </customfields>
    </item>
</channel>
</rss>
